[
    {
        "paper id": "2401.06799",
        "abstract url": "https://arxiv.org/abs/2401.06799",
        "title": "Make Prompts Adaptable: Bayesian Modeling for Vision-Language Prompt Learning with Data-Dependent Prior",
        "rating": 2.5,
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Recent Vision-Language Pretrained (VLP) models have become the backbone for many downstream tasks, but they are utilized as frozen model without learning. Prompt learning is a method to improve the pre-trained VLP model by adding a learnable context vector to the inputs of the text encoder. In a few-shot learning scenario of the downstream task, MLE training can lead the context vector to over-fit dominant image features in the training data. This overfitting can potentially harm the generalization ability, especially in the presence of a distribution shift between the training and test dataset. This paper presents a Bayesian-based framework of prompt learning, which could alleviate the overfitting issues on few-shot learning application and increase the adaptability of prompts on unseen instances. Specifically, modeling data-dependent prior enhances the adaptability of text features for both seen and unseen image features without the trade-off of performance between them. Based on the Bayesian framework, we utilize the Wasserstein Gradient Flow in the estimation of our target posterior distribution, which enables our prompt to be flexible in capturing the complex modes of image features. We demonstrate the effectiveness of our method on benchmark datasets for several experiments by showing statistically significant improvements on performance compared to existing methods. The code is available at https://github.com/youngjae-cho/APP.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to AAAI-2024"
    },
    {
        "paper id": "2401.04679",
        "abstract url": "https://arxiv.org/abs/2401.04679",
        "title": "RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation",
        "rating": 2,
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis that jointly trains $\\textit{low-rank}$ and $\\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms LoRA, pure sparse fine-tuning, and alternative hybrid methods at the same parameter budget, and can even recover the performance of FFT on some tasks. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memory- and computationally-efficient training, and show that it is also compatible with low-precision base weights, resulting in the first joint representation combining quantization, low-rank and sparse approximations. Our code is accessible at https://github.com/IST-DASLab/RoSA.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04389",
        "abstract url": "https://arxiv.org/abs/2401.04389",
        "title": "RaD-Net: A Repairing and Denoising Network for Speech Signal Improvement",
        "rating": 1.5,
        "keywords": [
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "This paper introduces our repairing and denoising network (RaD-Net) for the ICASSP 2024 Speech Signal Improvement (SSI) Challenge. We extend our previous framework based on a two-stage network and propose an upgraded model. Specifically, we replace the repairing network with COM-Net from TEA-PSE. In addition, multi-resolution discriminators and multi-band discriminators are adopted in the training stage. Finally, we use a three-step training strategy to optimize our model. We submit two models with different sets of parameters to meet the RTF requirement of the two tracks. According to the official results, the proposed systems rank 2nd in track 1 and 3rd in track 2.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "submitted to ICASSP 2024"
    },
    {
        "paper id": "2401.04398",
        "abstract url": "https://arxiv.org/abs/2401.04398",
        "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, showing the reasoning process for a given tabular problem. The chain carries structured information of the intermediate results, enabling more accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM choices.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to ICLR 2024"
    },
    {
        "paper id": "2401.04447",
        "abstract url": "https://arxiv.org/abs/2401.04447",
        "title": "Class-Incremental Learning for Multi-Label Audio Classification",
        "rating": 1.5,
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In this paper, we propose a method for class-incremental learning of potentially overlapping sounds for solving a sequence of multi-label audio classification tasks. We design an incremental learner that learns new classes independently of the old classes. To preserve knowledge about the old classes, we propose a cosine similarity-based distillation loss that minimizes discrepancy in the feature representations of subsequent learners, and use it along with a Kullback-Leibler divergence-based distillation loss that minimizes discrepancy in their respective outputs. Experiments are performed on a dataset with 50 sound classes, with an initial classification task containing 30 base classes and 4 incremental phases of 5 classes each. After each phase, the system is tested for multi-label classification with the entire set of classes learned so far. The proposed method obtains an average F1-score of 40.9% over the five phases, ranging from 45.2% in phase 0 on 30 classes, to 36.3% in phase 4 on 50 classes. Average performance degradation over incremental phases is only 0.7 percentage points from the initial F1-score of 45.2%.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Accepted to ICASSP 2024"
    },
    {
        "paper id": "2401.04511",
        "abstract url": "https://arxiv.org/abs/2401.04511",
        "title": "Zero Shot Audio to Audio Emotion Transfer With Speaker Disentanglement",
        "rating": 1.5,
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "The problem of audio-to-audio (A2A) style transfer involves replacing the style features of the source audio with those from the target audio while preserving the content related attributes of the source audio. In this paper, we propose an efficient approach, termed as Zero-shot Emotion Style Transfer (ZEST), that allows the transfer of emotional content present in the given source audio with the one embedded in the target audio while retaining the speaker and speech content from the source. The proposed system builds upon decomposing speech into semantic tokens, speaker representations and emotion embeddings. Using these factors, we propose a framework to reconstruct the pitch contour of the given speech signal and train a decoder that reconstructs the speech signal. The model is trained using a self-supervision based reconstruction loss. During conversion, the emotion embedding is alone derived from the target audio, while rest of the factors are derived from the source audio. In our experiments, we show that, even without using parallel training data or labels from the source or target audio, we illustrate zero shot emotion transfer capabilities of the proposed ZEST model using objective and subjective quality evaluations.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "5 pages, 3 figures, accepted at ICASSP 2024"
    },
    {
        "paper id": "2401.04536",
        "abstract url": "https://arxiv.org/abs/2401.04536",
        "title": "Evaluating Language Model Agency through Negotiations",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "We introduce an approach to evaluate language model (LM) agency using negotiation games. This approach better reflects real-world use cases and addresses some of the shortcomings of alternative LM benchmarks. Negotiation games enable us to study multi-turn, and cross-model interactions, modulate complexity, and side-step accidental evaluation data leakage. We use our approach to test six widely used and publicly accessible LMs, evaluating performance and alignment in both self-play and cross-play settings. Noteworthy findings include: (i) only closed-source models tested here were able to complete these tasks; (ii) cooperative bargaining games proved to be most challenging to the models; and (iii) even the most powerful models sometimes \"lose\" to weaker opponents",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to ICLR 2024, code and link to project data are made available at https://github.com/epfl-dlab/LAMEN"
    },
    {
        "paper id": "2401.04578",
        "abstract url": "https://arxiv.org/abs/2401.04578",
        "title": "Effective pruning of web-scale datasets based on complexity of concept clusters",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Utilizing massive web-scale datasets has led to unprecedented performance gains in machine learning models, but also imposes outlandish compute requirements for their training. In order to improve training and data efficiency, we here push the limits of pruning large-scale multimodal datasets for training CLIP-style models. Today's most effective pruning method on ImageNet clusters data samples into separate concepts according to their embedding and prunes away the most prototypical samples. We scale this approach to LAION and improve it by noting that the pruning rate should be concept-specific and adapted to the complexity of the concept. Using a simple and intuitive complexity measure, we are able to reduce the training cost to a quarter of regular training. By filtering from the LAION dataset, we find that training on a smaller set of high-quality data can lead to higher performance with significantly lower training costs. More specifically, we are able to outperform the LAION-trained OpenCLIP-ViT-B32 model on ImageNet zero-shot accuracy by 1.1p.p. while only using 27.7% of the data and training compute. Despite a strong reduction in training cost, we also see improvements on ImageNet dist. shifts, retrieval tasks and VTAB. On the DataComp Medium benchmark, we achieve a new state-of-the-art Imagehttps://info.arxiv.org/help/prep#commentsNet zero-shot accuracy and a competitive average zero-shot accuracy on 38 evaluation tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ICLR 2024, code available at https://github.com/amro-kamal/effective_pruning"
    },
    {
        "paper id": "2401.04716",
        "abstract url": "https://arxiv.org/abs/2401.04716",
        "title": "Low-Resource Vision Challenges for Foundation Models",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Low-resource settings are well-established in natural language processing, where many languages lack sufficient data for deep learning at scale. However, low-resource problems are under-explored in computer vision. In this paper, we address this gap and explore the challenges of low-resource image tasks with vision foundation models. We first collect a benchmark of genuinely low-resource image data, covering historic maps, circuit diagrams, and mechanical drawings. These low-resource settings all share three challenges: data scarcity, fine-grained differences, and the distribution shift from natural images to the specialized domain of interest. While existing foundation models have shown impressive generalizability, we find they cannot transfer well to our low-resource tasks. To begin to tackle the challenges of low-resource vision, we introduce one simple baseline per challenge. Specifically, we i) enlarge the data space by generative models, ii) adopt the best sub-kernels to encode local regions for fine-grained difference discovery and iii) learn attention for specialized domains. Experiments on our three low-resource tasks demonstrate our proposals already provide a better baseline than transfer learning, data augmentation, and fine-grained methods. This highlights the unique characteristics and challenges of low-resource vision for foundation models that warrant further investigation. Project page: https://xiaobai1217.github.io/Low-Resource-Vision/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at CVPR2024"
    },
    {
        "paper id": "2401.04860",
        "abstract url": "https://arxiv.org/abs/2401.04860",
        "title": "Modality-Aware Representation Learning for Zero-shot Sketch-based Image Retrieval",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Zero-shot learning offers an efficient solution for a machine learning model to treat unseen categories, avoiding exhaustive data collection. Zero-shot Sketch-based Image Retrieval (ZS-SBIR) simulates real-world scenarios where it is hard and costly to collect paired sketch-photo samples. We propose a novel framework that indirectly aligns sketches and photos by contrasting them through texts, removing the necessity of access to sketch-photo pairs. With an explicit modality encoding learned from data, our approach disentangles modality-agnostic semantics from modality-specific information, bridging the modality gap and enabling effective cross-modal content retrieval within a joint latent space. From comprehensive experiments, we verify the efficacy of the proposed model on ZS-SBIR, and it can be also applied to generalized and fine-grained settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at WACV 2024"
    },
    {
        "paper id": "2401.04390",
        "abstract url": "https://arxiv.org/abs/2401.04390",
        "title": "Learning with Noisy Labels: Interconnection of Two Expectation-Maximizations",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Labor-intensive labeling becomes a bottleneck in developing computer vision algorithms based on deep learning. For this reason, dealing with imperfect labels has increasingly gained attention and has become an active field of study. We address learning with noisy labels (LNL) problem, which is formalized as a task of finding a structured manifold in the midst of noisy data. In this framework, we provide a proper objective function and an optimization algorithm based on two expectation-maximization (EM) cycles. The separate networks associated with the two EM cycles collaborate to optimize the objective function, where one model is for distinguishing clean labels from corrupted ones while the other is for refurbishing the corrupted labels. This approach results in a non-collapsing LNL-flywheel model in the end. Experiments show that our algorithm achieves state-of-the-art performance in multiple standard benchmarks with substantial margins under various types of label noise.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04393",
        "abstract url": "https://arxiv.org/abs/2401.04393",
        "title": "OrthoSeisnet: Seismic Inversion through Orthogonal Multi-scale Frequency Domain U-Net for Geophysical Exploration",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Seismic inversion is crucial in hydrocarbon exploration, particularly for detecting hydrocarbons in thin layers. However, the detection of sparse thin layers within seismic datasets presents a significant challenge due to the ill-posed nature and poor non-linearity of the problem. While data-driven deep learning algorithms have shown promise, effectively addressing sparsity remains a critical area for improvement. To overcome this limitation, we propose OrthoSeisnet, a novel technique that integrates a multi-scale frequency domain transform within the U-Net framework. OrthoSeisnet aims to enhance the interpretability and resolution of seismic images, enabling the identification and utilization of sparse frequency components associated with hydrocarbon-bearing layers. By leveraging orthogonal basis functions and decoupling frequency components, OrthoSeisnet effectively improves data sparsity. We evaluate the performance of OrthoSeisnet using synthetic and real datasets obtained from the Krishna-Godavari basin. Orthoseisnet outperforms the traditional method through extensive performance analysis utilizing commonly used measures, such as mean absolute error (MAE), mean squared error (MSE), and structural similarity index (SSIM) https://github.com/supriyo100/Orthoseisnet.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Under review, once the paper is accepted, the copyright will be transferred to the corresponding journal"
    },
    {
        "paper id": "2401.04403",
        "abstract url": "https://arxiv.org/abs/2401.04403",
        "title": "MST: Adaptive Multi-Scale Tokens Guided Interactive Segmentation",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Interactive segmentation has gained significant attention for its application in human-computer interaction and data annotation. To address the target scale variation issue in interactive segmentation, a novel multi-scale token adaptation algorithm is proposed. By performing top-k operations across multi-scale tokens, the computational complexity is greatly simplified while ensuring performance. To enhance the robustness of multi-scale token selection, we also propose a token learning algorithm based on contrastive loss. This algorithm can effectively improve the performance of multi-scale token adaptation. Extensive benchmarking shows that the algorithm achieves state-of-the-art (SOTA) performance, compared to current methods. An interactive demo and all reproducible codes will be released at https://github.com/hahamyt/mst.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 10 figures"
    },
    {
        "paper id": "2401.04422",
        "abstract url": "https://arxiv.org/abs/2401.04422",
        "title": "Estimating Text Similarity based on Semantic Concept Embeddings",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Due to their ease of use and high accuracy, Word2Vec (W2V) word embeddings enjoy great success in the semantic representation of words, sentences, and whole documents as well as for semantic similarity estimation. However, they have the shortcoming that they are directly extracted from a surface representation, which does not adequately represent human thought processes and also performs poorly for highly ambiguous words. Therefore, we propose Semantic Concept Embeddings (CE) based on the MultiNet Semantic Network (SN) formalism, which addresses both shortcomings. The evaluation on a marketing target group distribution task showed that the accuracy of predicted target groups can be increased by combining traditional word embeddings with semantic CEs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04441",
        "abstract url": "https://arxiv.org/abs/2401.04441",
        "title": "Image classification network enhancement methods based on knowledge injection",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The current deep neural network algorithm still stays in the end-to-end training supervision method like Image-Label pairs, which makes traditional algorithm is difficult to explain the reason for the results, and the prediction logic is difficult to understand and analyze. The current algorithm does not use the existing human knowledge information, which makes the model not in line with the human cognition model and makes the model not suitable for human use. In order to solve the above problems, the present invention provides a deep neural network training method based on the human knowledge, which uses the human cognition model to construct the deep neural network training model, and uses the existing human knowledge information to construct the deep neural network training model. This paper proposes a multi-level hierarchical deep learning algorithm, which is composed of multi-level hierarchical deep neural network architecture and multi-level hierarchical deep learning framework. The experimental results show that the proposed algorithm can effectively explain the hidden information of the neural network. The goal of our study is to improve the interpretability of deep neural networks (DNNs) by providing an analysis of the impact of knowledge injection on the classification task. We constructed a knowledge injection dataset with matching knowledge data and image classification data. The knowledge injection dataset is the benchmark dataset for the experiments in the paper. Our model expresses the improvement in interpretability and classification task performance of hidden layers at different scales.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages, 3 figures, 5 tables"
    },
    {
        "paper id": "2401.04448",
        "abstract url": "https://arxiv.org/abs/2401.04448",
        "title": "A Novel Dataset for Non-Destructive Inspection of Handwritten Documents",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Forensic handwriting examination is a branch of Forensic Science that aims to examine handwritten documents in order to properly define or hypothesize the manuscript's author. These analysis involves comparing two or more (digitized) documents through a comprehensive comparison of intrinsic local and global features. If a correlation exists and specific best practices are satisfied, then it will be possible to affirm that the documents under analysis were written by the same individual. The need to create sophisticated tools capable of extracting and comparing significant features has led to the development of cutting-edge software with almost entirely automated processes, improving the forensic examination of handwriting and achieving increasingly objective evaluations. This is made possible by algorithmic solutions based on purely mathematical concepts. Machine Learning and Deep Learning models trained with specific datasets could turn out to be the key elements to best solve the task at hand. In this paper, we proposed a new and challenging dataset consisting of two subsets: the first consists of 21 documents written either by the classic ``pen and paper\" approach (and later digitized) and directly acquired on common devices such as tablets; the second consists of 362 handwritten manuscripts by 124 different people, acquired following a specific pipeline. Our study pioneered a comparison between traditionally handwritten documents and those produced with digital tools (e.g., tablets). Preliminary results on the proposed datasets show that 90% classification accuracy can be achieved on the first subset (documents written on both paper and pen and later digitized and on tablets) and 96% on the second portion of the data. The datasets are available at https://iplab.dmi.unict.it/mfs/forensic-handwriting-analysis/novel-dataset-2023/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2310.11217"
    },
    {
        "paper id": "2401.04471",
        "abstract url": "https://arxiv.org/abs/2401.04471",
        "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) and multimodal large language models (MLLMs) have shown excellent general capabilities, even exhibiting adaptability in many professional domains such as law, economics, transportation, and medicine. Currently, many domain-specific benchmarks have been proposed to verify the performance of (M)LLMs in specific fields. Among various domains, transportation plays a crucial role in modern society as it impacts the economy, the environment, and the quality of life for billions of people. However, it is unclear how much traffic knowledge (M)LLMs possess and whether they can reliably perform transportation-related tasks. To address this gap, we propose TransportationGames, a carefully designed and thorough evaluation benchmark for assessing (M)LLMs in the transportation domain. By comprehensively considering the applications in real-world scenarios and referring to the first three levels in Bloom's Taxonomy, we test the performance of various (M)LLMs in memorizing, understanding, and applying transportation knowledge by the selected tasks. The experimental results show that although some models perform well in some tasks, there is still much room for improvement overall. We hope the release of TransportationGames can serve as a foundation for future research, thereby accelerating the implementation and application of (M)LLMs in the transportation domain.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in Progress"
    },
    {
        "paper id": "2401.04481",
        "abstract url": "https://arxiv.org/abs/2401.04481",
        "title": "Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The recent success in language generation capabilities of large language models (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns about their possible misuse in inducing mass agitation and communal hatred via generating fake news and spreading misinformation. Traditional means of developing a misinformation ground-truth dataset does not scale well because of the extensive manual effort required to annotate the data. In this paper, we propose an LLM-based approach of creating silver-standard ground-truth datasets for identifying misinformation. Specifically speaking, given a trusted news article, our proposed approach involves prompting LLMs to automatically generate a summarised version of the original article. The prompts in our proposed approach act as a controlling mechanism to generate specific types of factual incorrectness in the generated summaries, e.g., incorrect quantities, false attributions etc. To investigate the usefulness of this dataset, we conduct a set of experiments where we train a range of supervised models for the task of misinformation detection.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04482",
        "abstract url": "https://arxiv.org/abs/2401.04482",
        "title": "Continuously Learning New Words in Automatic Speech Recognition",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite recent advances, Automatic Speech Recognition (ASR) systems are still far from perfect. Typical errors include acronyms, named entities and domain-specific special words for which little or no data is available. To address the problem of recognizing these words, we propose an self-supervised continual learning approach. Given the audio of a lecture talk with corresponding slides, we bias the model towards decoding new words from the slides by using a memory-enhanced ASR model from previous work. Then, we perform inference on the talk, collecting utterances that contain detected new words into an adaptation dataset. Continual learning is then performed on this set by adapting low-rank matrix weights added to each weight matrix of the model. The whole procedure is iterated for many talks. We show that with this approach, we obtain increasing performance on the new words when they occur more frequently (more than 80% recall) while preserving the general performance of the model.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04515",
        "abstract url": "https://arxiv.org/abs/2401.04515",
        "title": "Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This article investigates a zero-shot approach to hypernymy prediction using large language models (LLMs). The study employs a method based on text probability calculation, applying it to various generated prompts. The experiments demonstrate a strong correlation between the effectiveness of language model prompts and classic patterns, indicating that preliminary prompt selection can be carried out using smaller models before moving to larger ones. We also explore prompts for predicting co-hyponyms and improving hypernymy predictions by augmenting prompts with additional information through automatically identified co-hyponyms. An iterative approach is developed for predicting higher-level concepts, which further improves the quality on the BLESS dataset (MAP = 0.8).",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04518",
        "abstract url": "https://arxiv.org/abs/2401.04518",
        "title": "The Critique of Critique",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Critique, as a natural language description for assessing the quality of model-generated content, has been proven to play an essential role in the training, evaluation, and refinement of Large Language Models (LLMs). However, there is a lack of principled understanding in evaluating the quality of the critique itself. In this paper, we pioneer the critique of critique, termed MetaCritique, which is a framework to evaluate the critique from two aspects, i.e., factuality as precision score and comprehensiveness as recall score. We calculate the harmonic mean of precision and recall as the overall rating called F1 score. To obtain a reliable evaluation outcome, we propose Atomic Information Units (AIUs), which describe the critique in a more fine-grained manner. MetaCritique takes each AIU into account and aggregates each AIU's judgment for the overall score. Moreover, given the evaluation process involves intricate reasoning, our MetaCritique provides a natural language rationale to support each judgment. We construct a meta-evaluation dataset containing 300 critiques (2653 AIUs) across four tasks (question answering, reasoning, entailment, and summarization), and we conduct a comparative study to demonstrate the feasibility and effectiveness. Experiments also show superior critique judged by MetaCritique leads to better refinement, indicating generative artificial intelligence indeed has the potential to be significantly advanced with our MetaCritique. We will release relevant code and meta-evaluation datasets at https://github.com/GAIR-NLP/MetaCritique.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04522",
        "abstract url": "https://arxiv.org/abs/2401.04522",
        "title": "LUNA: A Framework for Language Understanding and Naturalness Assessment",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The evaluation of Natural Language Generation (NLG) models has gained increased attention, urging the development of metrics that evaluate various aspects of generated text. LUNA addresses this challenge by introducing a unified interface for 20 NLG evaluation metrics. These metrics are categorized based on their reference-dependence and the type of text representation they employ, from string-based n-gram overlap to the utilization of static embeddings and pre-trained language models. The straightforward design of LUNA allows for easy extension with novel metrics, requiring just a few lines of code. LUNA offers a user-friendly tool for evaluating generated texts.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04531",
        "abstract url": "https://arxiv.org/abs/2401.04531",
        "title": "MERA: A Comprehensive LLM Evaluation in Russian",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). As the models' size increases, LMs demonstrate enhancements in measurable aspects and the development of new qualitative features. However, despite researchers' attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce an open Multimodal Evaluation of Russian-language Architectures (MERA), a new instruction benchmark for evaluating foundation models oriented towards the Russian language. The benchmark encompasses 21 evaluation tasks for generative models in 11 skill domains and is designed as a black-box test to ensure the exclusion of data leakage. The paper introduces a methodology to evaluate FMs and LMs in zero- and few-shot fixed instruction settings that can be extended to other modalities. We propose an evaluation methodology, an open-source code base for the MERA assessment, and a leaderboard with a submission system. We evaluate open LMs as baselines and find that they are still far behind the human level. We publicly release MERA to guide forthcoming research, anticipate groundbreaking model features, standardize the evaluation procedure, and address potential societal drawbacks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "The paper version comparable with the release code v.1.1.0 of the benchmark. The links and scores are updated"
    },
    {
        "paper id": "2401.04575",
        "abstract url": "https://arxiv.org/abs/2401.04575",
        "title": "Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding",
        "rating": 1,
        "keywords": [
            [
                "vision-language"
            ],
            [
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision and vision-language applications of neural networks, such as image classification and captioning, rely on large-scale annotated datasets that require non-trivial data-collecting processes. This time-consuming endeavor hinders the emergence of large-scale datasets, limiting researchers and practitioners to a small number of choices. Therefore, we seek more efficient ways to collect and annotate images. Previous initiatives have gathered captions from HTML alt-texts and crawled social media postings, but these data sources suffer from noise, sparsity, or subjectivity. For this reason, we turn to commercial shopping websites whose data meet three criteria: cleanliness, informativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset, a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites. When compared with existing general-domain datasets, the LGS images focus on the foreground object and have less complex backgrounds. Our experiments on LGS show that the classifiers trained on existing benchmark datasets do not readily generalize to e-commerce data, while specific self-supervised visual feature extractors can better generalize. Furthermore, LGS's high-quality e-commerce-focused images and bimodal nature make it advantageous for vision-language bi-modal tasks: LGS enables image-captioning models to generate richer captions and helps text-to-image generation models achieve e-commerce style transfer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04577",
        "abstract url": "https://arxiv.org/abs/2401.04577",
        "title": "Masked Audio Generation using a Single Non-Autoregressive Transformer",
        "rating": 1,
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "We introduce MAGNeT, a masked generative sequence modeling method that operates directly over several streams of audio tokens. Unlike prior work, MAGNeT is comprised of a single-stage, non-autoregressive transformer. During training, we predict spans of masked tokens obtained from a masking scheduler, while during inference we gradually construct the output sequence using several decoding steps. To further enhance the quality of the generated audio, we introduce a novel rescoring method in which, we leverage an external pre-trained model to rescore and rank predictions from MAGNeT, which will be then used for later decoding steps. Lastly, we explore a hybrid version of MAGNeT, in which we fuse between autoregressive and non-autoregressive models to generate the first few seconds in an autoregressive manner while the rest of the sequence is being decoded in parallel. We demonstrate the efficiency of MAGNeT for the task of text-to-music and text-to-audio generation and conduct an extensive empirical evaluation, considering both objective metrics and human studies. The proposed approach is comparable to the evaluated baselines, while being significantly faster (x7 faster than the autoregressive baseline). Through ablation studies and analysis, we shed light on the importance of each of the components comprising MAGNeT, together with pointing to the trade-offs between autoregressive and non-autoregressive modeling, considering latency, throughput, and generation quality. Samples are available on our demo page https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04619",
        "abstract url": "https://arxiv.org/abs/2401.04619",
        "title": "Language Detection for Transliterated Content",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the contemporary digital era, the Internet functions as an unparalleled catalyst, dismantling geographical and linguistic barriers particularly evident in texting. This evolution facilitates global communication, transcending physical distances and fostering dynamic cultural exchange. A notable trend is the widespread use of transliteration, where the English alphabet is employed to convey messages in native languages, posing a unique challenge for language technology in accurately detecting the source language. This paper addresses this challenge through a dataset of phone text messages in Hindi and Russian transliterated into English utilizing BERT for language classification and Google Translate API for transliteration conversion. The research pioneers innovative approaches to identify and convert transliterated text, navigating challenges in the diverse linguistic landscape of digital communication. Emphasizing the pivotal role of comprehensive datasets for training Large Language Models LLMs like BERT, our model showcases exceptional proficiency in accurately identifying and classifying languages from transliterated text. With a validation accuracy of 99% our models robust performance underscores its reliability. The comprehensive exploration of transliteration dynamics supported by innovative approaches and cutting edge technologies like BERT, positions our research at the forefront of addressing unique challenges in the linguistic landscape of digital communication. Beyond contributing to language identification and transliteration capabilities this work holds promise for applications in content moderation, analytics and fostering a globally connected community engaged in meaningful dialogue.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "4 Pages, 6 diagrams"
    },
    {
        "paper id": "2401.04651",
        "abstract url": "https://arxiv.org/abs/2401.04651",
        "title": "Learning to Prompt Segment Anything Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Segment Anything Models (SAMs) like SEEM and SAM have demonstrated great potential in learning to segment anything. The core design of SAMs lies with Promptable Segmentation, which takes a handcrafted prompt as input and returns the expected segmentation mask. SAMs work with two types of prompts including spatial prompts (e.g., points) and semantic prompts (e.g., texts), which work together to prompt SAMs to segment anything on downstream datasets. Despite the important role of prompts, how to acquire suitable prompts for SAMs is largely under-explored. In this work, we examine the architecture of SAMs and identify two challenges for learning effective prompts for SAMs. To this end, we propose spatial-semantic prompt learning (SSPrompt) that learns effective semantic and spatial prompts for better SAMs. Specifically, SSPrompt introduces spatial prompt learning and semantic prompt learning, which optimize spatial prompts and semantic prompts directly over the embedding space and selectively leverage the knowledge encoded in pre-trained prompt encoders. Extensive experiments show that SSPrompt achieves superior image segmentation performance consistently across multiple widely adopted datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04658",
        "abstract url": "https://arxiv.org/abs/2401.04658",
        "title": "Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Linear attention is an efficient attention mechanism that has recently emerged as a promising alternative to conventional softmax attention. With its ability to process tokens in linear computational complexities, linear attention, in theory, can handle sequences of unlimited length without sacrificing speed, i.e., maintaining a constant training speed for various sequence lengths with a fixed memory consumption. However, due to the issue with cumulative summation (cumsum), current linear attention algorithms cannot demonstrate their theoretical advantage in a causal setting. In this paper, we present Lightning Attention-2, the first linear attention implementation that enables linear attention to realize its theoretical computational benefits. To achieve this, we leverage the thought of tiling, separately handling the intra-block and inter-block components in linear attention calculation. Specifically, we utilize the conventional attention computation mechanism for the intra-blocks and apply linear attention kernel tricks for the inter-blocks. A tiling technique is adopted through both forward and backward procedures to take full advantage of the GPU hardware. We implement our algorithm in Triton to make it IO-aware and hardware-friendly. Various experiments are conducted on different model sizes and sequence lengths. Lightning Attention-2 retains consistent training and inference speed regardless of input sequence length and is significantly faster than other attention mechanisms. The source code is available at https://github.com/OpenNLPLab/lightning-attention.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Technical Report. Yiran Zhong is the corresponding author. The source code is available at https://github.com/OpenNLPLab/lightning-attention"
    },
    {
        "paper id": "2401.04666",
        "abstract url": "https://arxiv.org/abs/2401.04666",
        "title": "Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "As the most basic application and implementation of deep learning, image classification has grown in popularity. Various datasets are provided by renowned data science communities for benchmarking machine learning algorithms and pre-trained models. The ASSIRA Cats & Dogs dataset is one of them and is being used in this research for its overall acceptance and benchmark standards. A comparison of various pre-trained models is demonstrated by using different types of optimizers and loss functions. Hyper-parameters are changed to gain the best result from a model. By applying this approach, we have got higher accuracy without major changes in the training model. To run the experiment, we used three different computer architectures: a laptop equipped with NVIDIA GeForce GTX 1070, a laptop equipped with NVIDIA GeForce RTX 3080Ti, and a desktop equipped with NVIDIA GeForce RTX 3090. The acquired results demonstrate supremacy in terms of accuracy over the previously done experiments on this dataset. From this experiment, the highest accuracy which is 99.65% is gained using the NASNet Large.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04695",
        "abstract url": "https://arxiv.org/abs/2401.04695",
        "title": "Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Factual questions typically can be answered correctly at different levels of granularity. For example, both ``August 4, 1961'' and ``1961'' are correct answers to the question ``When was Barack Obama born?''. Standard question answering (QA) evaluation protocols, however, do not explicitly take this into account and compare a predicted answer against answers of a single granularity level. In this work, we propose GRANOLA QA, a novel evaluation setting where a predicted answer is evaluated in terms of accuracy and informativeness against a set of multi-granularity answers. We present a simple methodology for enriching existing datasets with multi-granularity answers, and create GRANOLA-EQ, a multi-granularity version of the EntityQuestions dataset. We evaluate a range of decoding methods on GRANOLA-EQ, including a new algorithm, called Decoding with Response Aggregation (DRAG), that is geared towards aligning the response granularity with the model's uncertainty. Our experiments show that large language models with standard decoding tend to generate specific answers, which are often incorrect. In contrast, when evaluated on multi-granularity answers, DRAG yields a nearly 20 point increase in accuracy on average, which further increases for rare entities. Overall, this reveals that standard evaluation and decoding schemes may significantly underestimate the knowledge encapsulated in LMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04739",
        "abstract url": "https://arxiv.org/abs/2401.04739",
        "title": "Content-Conditioned Generation of Stylized Free hand Sketches",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the recognition of free-hand sketches has remained a popular task. However, in some special fields such as the military field, free-hand sketches are difficult to sample on a large scale. Common data augmentation and image generation techniques are difficult to produce images with various free-hand sketching styles. Therefore, the recognition and segmentation tasks in related fields are limited. In this paper, we propose a novel adversarial generative network that can accurately generate realistic free-hand sketches with various styles. We explore the performance of the model, including using styles randomly sampled from a prior normal distribution to generate images with various free-hand sketching styles, disentangling the painters' styles from known free-hand sketches to generate images with specific styles, and generating images of unknown classes that are not in the training set. We further demonstrate with qualitative and quantitative evaluations our advantages in visual quality, content accuracy, and style imitation on SketchIME.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 7 figures, ICSMD"
    },
    {
        "paper id": "2401.04812",
        "abstract url": "https://arxiv.org/abs/2401.04812",
        "title": "Sample-and-Bound for Non-Convex Optimization",
        "rating": 1.0,
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Standard approaches for global optimization of non-convex functions, such as branch-and-bound, maintain partition trees to systematically prune the domain. The tree size grows exponentially in the number of dimensions. We propose new sampling-based methods for non-convex optimization that adapts Monte Carlo Tree Search (MCTS) to improve efficiency. Instead of the standard use of visitation count in Upper Confidence Bounds, we utilize numerical overapproximations of the objective as an uncertainty metric, and also take into account of sampled estimates of first-order and second-order information. The Monte Carlo tree in our approach avoids the usual fixed combinatorial patterns in growing the tree, and aggressively zooms into the promising regions, while still balancing exploration and exploitation. We evaluate the proposed algorithms on high-dimensional non-convex optimization benchmarks against competitive baselines and analyze the effects of the hyper parameters.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Published at AAAI 2024. Code is available at https://github.com/aaucsd/MCIR"
    },
    {
        "paper id": "2401.04821",
        "abstract url": "https://arxiv.org/abs/2401.04821",
        "title": "MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Transformer-based pre-trained language models (PLMs) have achieved remarkable performance in various natural language processing (NLP) tasks. However, pre-training such models can take considerable resources that are almost only available to high-resource languages. On the contrary, static word embeddings are easier to train in terms of computing resources and the amount of data required. In this paper, we introduce MoSECroT Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer), a novel and challenging task that is especially relevant to low-resource languages for which static word embeddings are available. To tackle the task, we present the first framework that leverages relative representations to construct a common space for the embeddings of a source language PLM and the static word embeddings of a target language. In this way, we can train the PLM on source-language training data and perform zero-shot transfer to the target language by simply swapping the embedding layer. However, through extensive experiments on two classification datasets, we show that although our proposed framework is competitive with weak baselines when addressing MoSECroT, it fails to achieve competitive results compared with some strong baselines. In this paper, we attempt to explain this negative result and provide several thoughts on possible improvement.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04848",
        "abstract url": "https://arxiv.org/abs/2401.04848",
        "title": "Arabic Text Diacritization In The Age Of Transfer Learning: Token Classification Is All You Need",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automatic diacritization of Arabic text involves adding diacritical marks (diacritics) to the text. This task poses a significant challenge with noteworthy implications for computational processing and comprehension. In this paper, we introduce PTCAD (Pre-FineTuned Token Classification for Arabic Diacritization, a novel two-phase approach for the Arabic Text Diacritization task. PTCAD comprises a pre-finetuning phase and a finetuning phase, treating Arabic Text Diacritization as a token classification task for pre-trained models. The effectiveness of PTCAD is demonstrated through evaluations on two benchmark datasets derived from the Tashkeela dataset, where it achieves state-of-the-art results, including a 20\\% reduction in Word Error Rate (WER) compared to existing benchmarks and superior performance over GPT-4 in ATD tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "32 pages, 3 figures, journal"
    },
    {
        "paper id": "2401.04854",
        "abstract url": "https://arxiv.org/abs/2401.04854",
        "title": "Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Are LLMs cultural technologies like photocopiers or printing presses, which transmit information but cannot create new content? A challenge for this idea, which we call bibliotechnism, is that LLMs often generate entirely novel text. We begin (Part I) with a sustained defense of bibliotechnism against this challenge showing how even entirely novel text may be meaningful only in a derivative sense, and arguing that, in particular, much novel text generated by LLMs is only derivatively meaningful. But we argue (Part II) that bibliotechnism faces a different, novel challenge, stemming from examples in which LLMs generate \"novel reference\", using novel names to refer to novel entities. Such examples could be smoothly explained if LLMs were not cultural technologies but possessed a limited form of agency (beliefs, desires, and intentions). According to interpretationism in the philosophy of mind, a system has beliefs, desires and intentions if and only if its behavior is well explained by the hypothesis that it has such states. So, according to interpretationism, cases of novel reference provide evidence that LLMs have beliefs, desires, and intentions. Given that interpretationism is a live hypothesis about the nature of these states, we suggest that cases of novel reference provide evidence that LLMs do have beliefs, desires, and intentions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04867",
        "abstract url": "https://arxiv.org/abs/2401.04867",
        "title": "An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue Systems",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Establishing evaluation schemes for spoken dialogue systems is important, but it can also be challenging. While subjective evaluations are commonly used in user experiments, objective evaluations are necessary for research comparison and reproducibility. To address this issue, we propose a framework for indirectly but objectively evaluating systems based on users' behaviors. In this paper, to this end, we investigate the relationship between user behaviors and subjective evaluation scores in social dialogue tasks: attentive listening, job interview, and first-meeting conversation. The results reveal that in dialogue tasks where user utterances are primary, such as attentive listening and job interview, indicators like the number of utterances and words play a significant role in evaluation. Observing disfluency also can indicate the effectiveness of formal tasks, such as job interview. On the other hand, in dialogue tasks with high interactivity, such as first-meeting conversation, behaviors related to turn-taking, like average switch pause length, become more important. These findings suggest that selecting appropriate user behaviors can provide valuable insights for objective evaluation in each social dialogue task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2024 (IWSDS 2024) and represents the author's version of the work"
    },
    {
        "paper id": "2401.04868",
        "abstract url": "https://arxiv.org/abs/2401.04868",
        "title": "Real-time and Continuous Turn-taking Prediction Using Voice Activity Projection",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "A demonstration of a real-time and continuous turn-taking prediction system is presented. The system is based on a voice activity projection (VAP) model, which directly maps dialogue stereo audio to future voice activities. The VAP model includes contrastive predictive coding (CPC) and self-attention transformers, followed by a cross-attention transformer. We examine the effect of the input context audio length and demonstrate that the proposed system can operate in real-time with CPU settings, with minimal performance degradation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2024 (IWSDS 2024) and represents the author's version of the work"
    },
    {
        "paper id": "2401.04881",
        "abstract url": "https://arxiv.org/abs/2401.04881",
        "title": "Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As LLMs have become capable of processing more complex types of inputs, researchers have recently studied how to efficiently and affordably process possibly arbitrarily long sequences. One effective approach is to use a FIFO memory to store keys and values of an attention sublayer from past chunks to allow subsequent queries to attend. However, this approach requires a large memory and/or takes into the consideration the specific LM architecture. Moreover, due to the causal nature between the key-values in prior context and the queries at present, this approach cannot be extended to bidirectional attention such as in an encoder-decoder or PrefixLM decoder-only architecture. In this paper, we propose to use eviction policies, such as LRA and LFA, to reduce the memory size and adapt to various architectures, and we also propose the Attendre layer, a wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory). As a first step, we evaluate this method in the context length extension setup using the TriviaQA reading comprehension task, and show the effectiveness of the approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04883",
        "abstract url": "https://arxiv.org/abs/2401.04883",
        "title": "Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate Group Conversations",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) have provided a new avenue for chatbot development, while most existing research has primarily centered on single-user chatbots that focus on deciding \"What\" to answer after user inputs. In this paper, we identified that multi-user chatbots have more complex 3W design dimensions -- \"What\" to say, \"When\" to respond, and \"Who\" to answer. Additionally, we proposed Multi-User Chat Assistant (MUCA), which is an LLM-based framework for chatbots specifically designed for group discussions. MUCA consists of three main modules: Sub-topic Generator, Dialog Analyzer, and Utterance Strategies Arbitrator. These modules jointly determine suitable response contents, timings, and the appropriate recipients. To make the optimizing process for MUCA easier, we further propose an LLM-based Multi-User Simulator (MUS) that can mimic real user behavior. This enables faster simulation of a conversation between the chatbot and simulated users, making the early development of the chatbot framework much more efficient. MUCA demonstrates effectiveness, including appropriate chime-in timing, relevant content, and improving user engagement, in group conversations with a small to medium number of participants, as evidenced by case studies and experimental results from user studies.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04898",
        "abstract url": "https://arxiv.org/abs/2401.04898",
        "title": "ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recently, various Large Language Models (LLMs) evaluation datasets have emerged, but most of them have issues with distorted rankings and difficulty in model capabilities analysis. Addressing these concerns, this paper introduces ANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes Keypoint categorization standard for the first time, each question in ANGO can correspond to multiple keypoints, effectively enhancing interpretability of evaluation results. Base on performance of real humans, we build a quantifiable question difficulty standard and divide ANGO questions into 9 difficulty levels, which provide more precise guidance for model training. To minimize data leakage impact and fully leverage ANGO's innovative features, we have engineered exclusive sampling strategies and a new evaluation framework that support swift testset iteration. Our experiments demonstrate that ANGO poses a stronger challenge to models and reveals more details in evaluation result compared to existing benchmarks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04903",
        "abstract url": "https://arxiv.org/abs/2401.04903",
        "title": "SnapCap: Efficient Snapshot Compressive Video Captioning",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video Captioning (VC) is a challenging multi-modal task since it requires describing the scene in language by understanding various and complex videos. For machines, the traditional VC follows the \"imaging-compression-decoding-and-then-captioning\" pipeline, where compression is pivot for storage and transmission. However, in such a pipeline, some potential shortcomings are inevitable, i.e., information redundancy resulting in low efficiency and information loss during the sampling process for captioning. To address these problems, in this paper, we propose a novel VC pipeline to generate captions directly from the compressed measurement, which can be captured by a snapshot compressive sensing camera and we dub our model SnapCap. To be more specific, benefiting from the signal simulation, we have access to obtain abundant measurement-video-annotation data pairs for our model. Besides, to better extract language-related visual representations from the compressed measurement, we propose to distill the knowledge from videos via a pre-trained CLIP with plentiful language-vision associations to guide the learning of our SnapCap. To demonstrate the effectiveness of SnapCap, we conduct experiments on two widely-used VC datasets. Both the qualitative and quantitative results verify the superiority of our pipeline over conventional VC pipelines. In particular, compared to the \"caption-after-reconstruction\" methods, our SnapCap can run at least 3$\\times$ faster, and achieve better caption results.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Preprint; Under Review"
    },
    {
        "paper id": "2401.04923",
        "abstract url": "https://arxiv.org/abs/2401.04923",
        "title": "Inconsistency-Based Data-Centric Active Open-Set Annotation",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Active learning is a commonly used approach that reduces the labeling effort required to train deep neural networks. However, the effectiveness of current active learning methods is limited by their closed-world assumptions, which assume that all data in the unlabeled pool comes from a set of predefined known classes. This assumption is often not valid in practical situations, as there may be unknown classes in the unlabeled data, leading to the active open-set annotation problem. The presence of unknown classes in the data can significantly impact the performance of existing active learning methods due to the uncertainty they introduce. To address this issue, we propose a novel data-centric active learning method called NEAT that actively annotates open-set data. NEAT is designed to label known classes data from a pool of both known and unknown classes unlabeled data. It utilizes the clusterability of labels to identify the known classes from the unlabeled pool and selects informative samples from those classes based on a consistency criterion that measures inconsistencies between model predictions and local feature distribution. Unlike the recently proposed learning-centric method for the same problem, NEAT is much more computationally efficient and is a data-centric active open-set annotation method. Our experiments demonstrate that NEAT achieves significantly better performance than state-of-the-art active learning methods for active open-set annotation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "AAAI 2024"
    },
    {
        "paper id": "2401.04925",
        "abstract url": "https://arxiv.org/abs/2401.04925",
        "title": "The Impact of Reasoning Step Length on Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make better use of LLMs' potential in complex problem-solving scenarios. Second, we also investigated the relationship between the performance of CoT and the rationales used in demonstrations. Surprisingly, the result shows that even incorrect rationales can yield favorable outcomes if they maintain the requisite length of inference. Third, we observed that the advantages of increasing reasoning steps are task-dependent: simpler tasks require fewer steps, whereas complex tasks gain significantly from longer inference sequences.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.06800",
        "abstract url": "https://arxiv.org/abs/2401.06800",
        "title": "Reinforcement Learning for Optimizing RAG for Domain Chatbots",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the advent of Large Language Models (LLM), conversational assistants have become prevalent for domain use cases. LLMs acquire the ability to contextual question answering through training, and Retrieval Augmented Generation (RAG) further enables the bot to answer domain-specific questions. This paper describes a RAG-based approach for building a chatbot that answers user's queries using Frequently Asked Questions (FAQ) data. We train an in-house retrieval embedding model using infoNCE loss, and experimental results demonstrate that the in-house model works significantly better than the well-known general-purpose public embedding model, both in terms of retrieval accuracy and Out-of-Domain (OOD) query detection. As an LLM, we use an open API-based paid ChatGPT model. We noticed that a previously retrieved-context could be used to generate an answer for specific patterns/sequences of queries (e.g., follow-up queries). Hence, there is a scope to optimize the number of LLM tokens and cost. Assuming a fixed retrieval model and an LLM, we optimize the number of LLM tokens using Reinforcement Learning (RL). Specifically, we propose a policy-based model external to the RAG, which interacts with the RAG pipeline through policy actions and updates the policy to optimize the cost. The policy model can perform two actions: to fetch FAQ context or skip retrieval. We use the open API-based GPT-4 as the reward model. We then train a policy model using policy gradient on multiple training chat sessions. As a policy model, we experimented with a public gpt-2 model and an in-house BERT model. With the proposed RL-based optimization combined with similarity threshold, we are able to achieve significant cost savings while getting a slightly improved accuracy. Though we demonstrate results for the FAQ chatbot, the proposed RL approach is generic and can be experimented with any existing RAG pipeline.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08672",
        "abstract url": "https://arxiv.org/abs/2401.08672",
        "title": "Concept Alignment",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Discussion of AI alignment (alignment between humans and AI systems) has focused on value alignment, broadly referring to creating AI systems that share human values. We argue that before we can even attempt to align values, it is imperative that AI systems and humans align the concepts they use to understand the world. We integrate ideas from philosophy, cognitive science, and deep learning to explain the need for concept alignment, not just value alignment, between humans and machines. We summarize existing accounts of how humans and machines currently learn concepts, and we outline opportunities and challenges in the path towards shared concepts. Finally, we explain how we can leverage the tools already being developed in cognitive science and AI research to accelerate progress towards concept alignment.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "NeurIPS MP2 Workshop 2023"
    },
    {
        "paper id": "2402.03328",
        "abstract url": "https://arxiv.org/abs/2402.03328",
        "title": "Large-scale Generative AI Models Lack Visual Number Sense",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Humans can readily judge the number of objects in a visual scene, even without counting, and such a skill has been documented in a variety of animal species and in babies prior to language development and formal schooling. Numerical judgments are error-free for small sets, while for larger collections responses become approximate, with variability increasing proportionally to the target number. This response pattern is observed for items of all kinds, despite variation in object features (such as color or shape), suggesting that our visual number sense relies on abstract representations of numerosity. Here, we investigated whether generative Artificial Intelligence (AI) models based on large-scale transformer architectures can reliably name the number of objects in simple visual stimuli or generate images containing a target number of items in the 1-10 range. Surprisingly, none of the foundation models considered performed in a human-like way: They all made striking errors even with small numbers, the response variability often did not increase in a systematic way, and the pattern of errors varied with object category. Our findings demonstrate that advanced AI systems still lack a basic ability that supports an intuitive understanding of numbers, which in humans is foundational for numeracy and mathematical development.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04374",
        "abstract url": "https://arxiv.org/abs/2401.04374",
        "title": "Towards Explainable Artificial Intelligence (XAI): A Data Mining Perspective",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Given the complexity and lack of transparency in deep neural networks (DNNs), extensive efforts have been made to make these systems more interpretable or explain their behaviors in accessible terms. Unlike most reviews, which focus on algorithmic and model-centric perspectives, this work takes a \"data-centric\" view, examining how data collection, processing, and analysis contribute to explainable AI (XAI). We categorize existing work into three categories subject to their purposes: interpretations of deep models, referring to feature attributions and reasoning processes that correlate data points with model outputs; influences of training data, examining the impact of training data nuances, such as data valuation and sample anomalies, on decision-making processes; and insights of domain knowledge, discovering latent patterns and fostering new knowledge from data and models to advance social values and scientific discovery. Specifically, we distill XAI methodologies into data mining operations on training and testing data across modalities, such as images, text, and tabular data, as well as on training logs, checkpoints, models and other DNN behavior descriptors. In this way, our study offers a comprehensive, data-centric examination of XAI from a lens of data mining methods and applications.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04394",
        "abstract url": "https://arxiv.org/abs/2401.04394",
        "title": "SonicVisionLM: Playing Sound with Vision Language Models",
        "rating": 0.5,
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ],
            [
                "diffusion"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "There has been a growing interest in the task of generating sound for silent videos, primarily because of its practicality in streamlining video post-production. However, existing methods for video-sound generation attempt to directly create sound from visual representations, which can be challenging due to the difficulty of aligning visual representations with audio representations. In this paper, we present SonicVisionLM, a novel framework aimed at generating a wide range of sound effects by leveraging vision-language models(VLMs). Instead of generating audio directly from video, we use the capabilities of powerful VLMs. When provided with a silent video, our approach first identifies events within the video using a VLM to suggest possible sounds that match the video content. This shift in approach transforms the challenging task of aligning image and audio into more well-studied sub-problems of aligning image-to-text and text-to-audio through the popular diffusion models. To improve the quality of audio recommendations with LLMs, we have collected an extensive dataset that maps text descriptions to specific sound effects and developed a time-controlled audio adapter. Our approach surpasses current state-of-the-art methods for converting video to audio, enhancing synchronization with the visuals, and improving alignment between audio and video components. Project page: https://yusiissy.github.io/SonicVisionLM.github.io/",
        "subjects": [
            "cs.MM"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2401.04452",
        "abstract url": "https://arxiv.org/abs/2401.04452",
        "title": "AI Competitions and Benchmarks, Practical issues: Proposals, grant money, sponsors, prizes, dissemination, publicity",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This chapter provides a comprehensive overview of the pragmatic aspects involved in organizing AI competitions. We begin by discussing strategies to incentivize participation, touching upon effective communication techniques, aligning with trending topics in the field, structuring awards, potential recruitment opportunities, and more. We then shift to the essence of community engagement, and into organizational best practices and effective means of disseminating challenge outputs. Lastly, the chapter addresses the logistics, exposing on costs, required manpower, and resource allocation for effectively managing and executing a challenge. By examining these practical problems, readers will gain actionable insights to navigate the multifaceted landscape of AI competition organization, from inception to completion.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04454",
        "abstract url": "https://arxiv.org/abs/2401.04454",
        "title": "Character comes from practice: longitudinal practice-based ethics training in data science",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "In this chapter, we propose a non-traditional RCR training in data science that is grounded into a virtue theory framework. First, we delineate the approach in more theoretical detail, by discussing how the goal of RCR training is to foster the cultivation of certain moral abilities. We specify the nature of these abilities: while the ideal is the cultivation of virtues, the limited space allowed by RCR modules can only facilitate the cultivation of superficial abilities or proto-virtues, which help students to familiarize with moral and political issues in the data science environment. Third, we operationalize our approach by stressing that (proto-)virtue acquisition (like skill acquisition) occurs through the technical and social tasks of daily data science activities, where these repetitive tasks provide the opportunities to develop (proto-)virtue capacity and to support the development of ethically robust data systems. Finally, we discuss a concrete example of how this approach has been implemented. In particular, we describe how this method is applied to teach data ethics to students participating in the CODATA-RDA Data Science Summer Schools.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04472",
        "abstract url": "https://arxiv.org/abs/2401.04472",
        "title": "A Survey on Efficient Federated Learning Methods for Foundation Model Training",
        "rating": 0.5,
        "keywords": [
            [
                "parameter-efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) has become an established technique to facilitate privacy-preserving collaborative training across a multitude of clients. However, new approaches to FL often discuss their contributions involving small deep-learning models only and focus on training full models on clients. In the wake of Foundation Models (FM), the reality is different for many deep learning applications. Typically, FMs have already been pre-trained across a wide variety of tasks and can be fine-tuned to specific downstream tasks over significantly smaller datasets than required for full model training. However, access to such datasets is often challenging. By its design, FL can help to open data silos. With this survey, we introduce a novel taxonomy focused on computational and communication efficiency, the vital elements to make use of FMs in FL systems. We discuss the benefits and drawbacks of parameter-efficient fine-tuning (PEFT) for FL applications, elaborate on the readiness of FL frameworks to work with FMs and provide future research opportunities on how to evaluate generative models in FL as well as the interplay of privacy and PEFT.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04558",
        "abstract url": "https://arxiv.org/abs/2401.04558",
        "title": "HyperGANStrument: Instrument Sound Synthesis and Editing with Pitch-Invariant Hypernetworks",
        "rating": 0.5,
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "GANStrument, exploiting GANs with a pitch-invariant feature extractor and instance conditioning technique, has shown remarkable capabilities in synthesizing realistic instrument sounds. To further improve the reconstruction ability and pitch accuracy to enhance the editability of user-provided sound, we propose HyperGANStrument, which introduces a pitch-invariant hypernetwork to modulate the weights of a pre-trained GANStrument generator, given a one-shot sound as input. The hypernetwork modulation provides feedback for the generator in the reconstruction of the input sound. In addition, we take advantage of an adversarial fine-tuning scheme for the hypernetwork to improve the reconstruction fidelity and generation diversity of the generator. Experimental results show that the proposed model not only enhances the generation capability of GANStrument but also significantly improves the editability of synthesized sounds. Audio examples are available at the online demo page.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "5 pages, 3 figures, Accepted for 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Audio examples: https://noto.li/MLIuBC"
    },
    {
        "paper id": "2401.04612",
        "abstract url": "https://arxiv.org/abs/2401.04612",
        "title": "Distribution-Free Conformal Joint Prediction Regions for Neural Marked Temporal Point Processes",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sequences of labeled events observed at irregular intervals in continuous time are ubiquitous across various fields. Temporal Point Processes (TPPs) provide a mathematical framework for modeling these sequences, enabling inferences such as predicting the arrival time of future events and their associated label, called mark. However, due to model misspecification or lack of training data, these probabilistic models may provide a poor approximation of the true, unknown underlying process, with prediction regions extracted from them being unreliable estimates of the underlying uncertainty. This paper develops more reliable methods for uncertainty quantification in neural TPP models via the framework of conformal prediction. A primary objective is to generate a distribution-free joint prediction region for the arrival time and mark, with a finite-sample marginal coverage guarantee. A key challenge is to handle both a strictly positive, continuous response and a categorical response, without distributional assumptions. We first consider a simple but overly conservative approach that combines individual prediction regions for the event arrival time and mark. Then, we introduce a more effective method based on bivariate highest density regions derived from the joint predictive density of event arrival time and mark. By leveraging the dependencies between these two variables, this method exclude unlikely combinations of the two, resulting in sharper prediction regions while still attaining the pre-specified coverage level. We also explore the generation of individual univariate prediction regions for arrival times and marks through conformal regression and classification techniques. Moreover, we investigate the stronger notion of conditional coverage. Finally, through extensive experimentation on both simulated and real-world datasets, we assess the validity and efficiency of these methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04631",
        "abstract url": "https://arxiv.org/abs/2401.04631",
        "title": "Deep Reinforcement Multi-agent Learning framework for Information Gathering with Local Gaussian Processes for Water Monitoring",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The conservation of hydrological resources involves continuously monitoring their contamination. A multi-agent system composed of autonomous surface vehicles is proposed in this paper to efficiently monitor the water quality. To achieve a safe control of the fleet, the fleet policy should be able to act based on measurements and to the the fleet state. It is proposed to use Local Gaussian Processes and Deep Reinforcement Learning to jointly obtain effective monitoring policies. Local Gaussian processes, unlike classical global Gaussian processes, can accurately model the information in a dissimilar spatial correlation which captures more accurately the water quality information. A Deep convolutional policy is proposed, that bases the decisions on the observation on the mean and variance of this model, by means of an information gain reward. Using a Double Deep Q-Learning algorithm, agents are trained to minimize the estimation error in a safe manner thanks to a Consensus-based heuristic. Simulation results indicate an improvement of up to 24% in terms of the mean absolute error with the proposed models. Also, training results with 1-3 agents indicate that our proposed approach returns 20% and 24% smaller average estimation errors for, respectively, monitoring water quality variables and monitoring algae blooms, as compared to state-of-the-art approaches",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04647",
        "abstract url": "https://arxiv.org/abs/2401.04647",
        "title": "Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks",
        "rating": 0.5,
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CV"
            ],
            [
                "workshop",
                "AAAI"
            ]
        ],
        "abstract": "This paper presents a novel concept learning framework for enhancing model interpretability and performance in visual classification tasks. Our approach appends an unsupervised explanation generator to the primary classifier network and makes use of adversarial training. During training, the explanation module is optimized to extract visual concepts from the classifier's latent representations, while the GAN-based module aims to discriminate images generated from concepts, from true images. This joint training scheme enables the model to implicitly align its internally learned concepts with human-interpretable visual properties. Comprehensive experiments demonstrate the robustness of our approach, while producing coherent concept activations. We analyse the learned concepts, showing their semantic concordance with object parts and visual attributes. We also study how perturbations in the adversarial training protocol impact both classification and concept acquisition. In summary, this work presents a significant step towards building inherently interpretable deep vision models with task-aligned concept representations - a key enabler for developing trustworthy AI for real-world perception tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024 (https://hcrl-workshop.github.io/2024/). Paper accepted and presented at Deployable AI Workshop at AAAI-2024 (https://sites.google.com/view/dai-2024/home)"
    },
    {
        "paper id": "2401.04669",
        "abstract url": "https://arxiv.org/abs/2401.04669",
        "title": "Transfer-Learning-Based Autotuning Using Gaussian Copula",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As diverse high-performance computing (HPC) systems are built, many opportunities arise for applications to solve larger problems than ever before. Given the significantly increased complexity of these HPC systems and application tuning, empirical performance tuning, such as autotuning, has emerged as a promising approach in recent years. Despite its effectiveness, autotuning is often a computationally expensive approach. Transfer learning (TL)-based autotuning seeks to address this issue by leveraging the data from prior tuning. Current TL methods for autotuning spend significant time modeling the relationship between parameter configurations and performance, which is ineffective for few-shot (that is, few empirical evaluations) tuning on new tasks. We introduce the first generative TL-based autotuning approach based on the Gaussian copula (GC) to model the high-performing regions of the search space from prior data and then generate high-performing configurations for new tasks. This allows a sampling-based approach that maximizes few-shot performance and provides the first probabilistic estimation of the few-shot budget for effective TL-based autotuning. We compare our generative TL approach with state-of-the-art autotuning techniques on several benchmarks. We find that the GC is capable of achieving 64.37% of peak few-shot performance in its first evaluation. Furthermore, the GC model can determine a few-shot transfer budget that yields up to 33.39$\\times$ speedup, a dramatic improvement over the 20.58$\\times$ speedup using prior techniques.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "13 pages, 5 figures, 7 tables, the definitive version of this work is published in the Proceedings of the ACM International Conference on Supercomputing 2023, available at https://dl.acm.org/doi/10.1145/3577193.3593712"
    },
    {
        "paper id": "2401.04682",
        "abstract url": "https://arxiv.org/abs/2401.04682",
        "title": "Mixture of multilayer stochastic block models for multiview clustering",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we propose an original method for aggregating multiple clustering coming from different sources of information. Each partition is encoded by a co-membership matrix between observations. Our approach uses a mixture of multilayer Stochastic Block Models (SBM) to group co-membership matrices with similar information into components and to partition observations into different clusters, taking into account their specificities within the components. The identifiability of the model parameters is established and a variational Bayesian EM algorithm is proposed for the estimation of these parameters. The Bayesian framework allows for selecting an optimal number of clusters and components. The proposed approach is compared using synthetic data with consensus clustering and tensor-based algorithms for community detection in large-scale complex networks. Finally, the method is utilized to analyze global food trading networks, leading to structures of interest.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04727",
        "abstract url": "https://arxiv.org/abs/2401.04727",
        "title": "Revisiting Adversarial Training at Scale",
        "rating": 0.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "The machine learning community has witnessed a drastic change in the training pipeline, pivoted by those ''foundation models'' with unprecedented scales. However, the field of adversarial training is lagging behind, predominantly centered around small model sizes like ResNet-50, and tiny and low-resolution datasets like CIFAR-10. To bridge this transformation gap, this paper provides a modern re-examination with adversarial training, investigating its potential benefits when applied at scale. Additionally, we introduce an efficient and effective training strategy to enable adversarial training with giant models and web-scale data at an affordable computing cost. We denote this newly introduced framework as AdvXL. Empirical results demonstrate that AdvXL establishes new state-of-the-art robust accuracy records under AutoAttack on ImageNet-1K. For example, by training on DataComp-1B dataset, our AdvXL empowers a vanilla ViT-g model to substantially surpass the previous records of $l_{\\infty}$-, $l_{2}$-, and $l_{1}$-robust accuracy by margins of 11.4%, 14.2% and 12.9%, respectively. This achievement posits AdvXL as a pioneering approach, charting a new trajectory for the efficient training of robust visual representations at significantly larger scales. Our code is available at https://github.com/UCSC-VLAA/AdvXL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2401.04837",
        "abstract url": "https://arxiv.org/abs/2401.04837",
        "title": "T-PRIME: Transformer-based Protocol Identification for Machine-learning at the Edge",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spectrum sharing allows different protocols of the same standard (e.g., 802.11 family) or different standards (e.g., LTE and DVB) to coexist in overlapping frequency bands. As this paradigm continues to spread, wireless systems must also evolve to identify active transmitters and unauthorized waveforms in real time under intentional distortion of preambles, extremely low signal-to-noise ratios and challenging channel conditions. We overcome limitations of correlation-based preamble matching methods in such conditions through the design of T-PRIME: a Transformer-based machine learning approach. T-PRIME learns the structural design of transmitted frames through its attention mechanism, looking at sequence patterns that go beyond the preamble alone. The paper makes three contributions: First, it compares Transformer models and demonstrates their superiority over traditional methods and state-of-the-art neural networks. Second, it rigorously analyzes T-PRIME's real-time feasibility on DeepWave's AIR-T platform. Third, it utilizes an extensive 66 GB dataset of over-the-air (OTA) WiFi transmissions for training, which is released along with the code for community use. Results reveal nearly perfect (i.e. $>98\\%$) classification accuracy under simulated scenarios, showing $100\\%$ detection improvement over legacy methods in low SNR ranges, $97\\%$ classification accuracy for OTA single-protocol transmissions and up to $75\\%$ double-protocol classification accuracy in interference scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This is the extended version of the IEEE INFOCOM 2024 paper with the same title"
    },
    {
        "paper id": "2401.04856",
        "abstract url": "https://arxiv.org/abs/2401.04856",
        "title": "A Good Score Does not Lead to A Good Generative Model",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Score-based Generative Models (SGMs) is one leading method in generative modeling, renowned for their ability to generate high-quality samples from complex, high-dimensional data distributions. The method enjoys empirical success and is supported by rigorous theoretical convergence properties. In particular, it has been shown that SGMs can generate samples from a distribution that is close to the ground-truth if the underlying score function is learned well, suggesting the success of SGM as a generative model. We provide a counter-example in this paper. Through the sample complexity argument, we provide one specific setting where the score function is learned well. Yet, SGMs in this setting can only output samples that are Gaussian blurring of training data points, mimicking the effects of kernel density estimation. The finding resonates a series of recent finding that reveal that SGMs can demonstrate strong memorization effect and fail to generate.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.05453",
        "abstract url": "https://arxiv.org/abs/2401.05453",
        "title": "Dimensionality-Aware Outlier Detection: Theoretical and Experimental Analysis",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a nonparametric method for outlier detection that takes full account of local variations in intrinsic dimensionality within the dataset. Using the theory of Local Intrinsic Dimensionality (LID), our 'dimensionality-aware' outlier detection method, DAO, is derived as an estimator of an asymptotic local expected density ratio involving the query point and a close neighbor drawn at random. The dimensionality-aware behavior of DAO is due to its use of local estimation of LID values in a theoretically-justified way. Through comprehensive experimentation on more than 800 synthetic and real datasets, we show that DAO significantly outperforms three popular and important benchmark outlier detection methods: Local Outlier Factor (LOF), Simplified LOF, and kNN.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "13 pages, 3 figures. Extended version of a paper accepted for publication at the SIAM International Conference on Data Mining (SDM24)"
    },
    {
        "paper id": "2402.01650",
        "abstract url": "https://arxiv.org/abs/2402.01650",
        "title": "Effect of trip attributes on ridehailing driver trip request acceptance",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "A generalized additive mixed model was estimated to investigate the factors that impact ridehailing driver trip request acceptance choices, relying on 200 responses from a stated preference survey in Seattle, US. Several policy recommendations were proposed to promote trip request acceptance based on ridehailing drivers willingness to accept compensation for undesired trip features. The findings could be useful for transportation agencies to improve ridehailing service efficiency, better fulfill urban mobility needs, and reduce environmental burden.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Paper in print at Journal of Sustainable Transportation"
    },
    {
        "paper id": "2402.01651",
        "abstract url": "https://arxiv.org/abs/2402.01651",
        "title": "Informed AI Regulation: Comparing the Ethical Frameworks of Leading LLM Chatbots Using an Ethics-Based Audit to Assess Moral Reasoning and Normative Values",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "With the rise of individual and collaborative networks of autonomous agents, AI is deployed in more key reasoning and decision-making roles. For this reason, ethics-based audits play a pivotal role in the rapidly growing fields of AI safety and regulation. This paper undertakes an ethics-based audit to probe the 8 leading commercial and open-source Large Language Models including GPT-4. We assess explicability and trustworthiness by a) establishing how well different models engage in moral reasoning and b) comparing normative values underlying models as ethical frameworks. We employ an experimental, evidence-based approach that challenges the models with ethical dilemmas in order to probe human-AI alignment. The ethical scenarios are designed to require a decision in which the particulars of the situation may or may not necessitate deviating from normative ethical principles. A sophisticated ethical framework was consistently elicited in one model, GPT-4. Nonetheless, troubling findings include underlying normative frameworks with clear bias towards particular cultural norms. Many models also exhibit disturbing authoritarian tendencies. Code is available at https://github.com/jonchun/llm-sota-chatbots-ethics-based-audit.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "23 pages, 6 figures (3 as tables), 1 table (in LaTeX)"
    },
    {
        "paper id": "2402.01653",
        "abstract url": "https://arxiv.org/abs/2402.01653",
        "title": "Child Impact Statements: Interdisciplinary Collaboration in Political Science and Computer Science",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Child Impact Statements (CIS) are instrumental in helping to foreground the concerns and needs of minor community members who are too young to vote and often unable to advocate for themselves politically. While many politicians and policymakers assert they make decisions in the best interests of children, they often lack the necessary information to meaningfully accomplish this. CISs are akin to Environmental Impact Statements in that both give voice to constituents who are often under-represented in policymaking. This paper highlights an interdisciplinary collaboration between Social Science and Computer Science to create a CIS tool for policymakers and community members in Shelby County, TN. Furthermore, this type of collaboration is fruitful beyond the scope of the CIS tool. Social scientists and computer scientists can leverage their complementary skill sets in data management and data interpretation for the benefit of their communities, advance scientific knowledge, and bridge disciplinary divides within the academy.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04362",
        "abstract url": "https://arxiv.org/abs/2401.04362",
        "title": "Representative Feature Extraction During Diffusion Process for Sketch Extraction with One Example",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce DiffSketch, a method for generating a variety of stylized sketches from images. Our approach focuses on selecting representative features from the rich semantics of deep features within a pretrained diffusion model. This novel sketch generation method can be trained with one manual drawing. Furthermore, efficient sketch extraction is ensured by distilling a trained generator into a streamlined extractor. We select denoising diffusion features through analysis and integrate these selected features with VAE features to produce sketches. Additionally, we propose a sampling scheme for training models using a conditional generative approach. Through a series of comparisons, we verify that distilled DiffSketch not only outperforms existing state-of-the-art sketch extraction methods but also surpasses diffusion-based stylization methods in the task of extracting sketches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages(main paper), 8 pages(supplementary material)"
    },
    {
        "paper id": "2401.04397",
        "abstract url": "https://arxiv.org/abs/2401.04397",
        "title": "The Role of Higher-Order Cognitive Models in Active Learning",
        "rating": 0.0,
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Building machines capable of efficiently collaborating with humans has been a longstanding goal in artificial intelligence. Especially in the presence of uncertainties, optimal cooperation often requires that humans and artificial agents model each other's behavior and use these models to infer underlying goals, beliefs or intentions, potentially involving multiple levels of recursion. Empirical evidence for such higher-order cognition in human behavior is also provided by previous works in cognitive science, linguistics, and robotics. We advocate for a new paradigm for active learning for human feedback that utilises humans as active data sources while accounting for their higher levels of agency. In particular, we discuss how increasing level of agency results in qualitatively different forms of rational communication between an active learning system and a teacher. Additionally, we provide a practical example of active learning using a higher-order cognitive model. This is accompanied by a computational study that underscores the unique behaviors that this model produces.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 pages, to appear in the CAIHu bridge program at AAAI 2024"
    },
    {
        "paper id": "2401.04406",
        "abstract url": "https://arxiv.org/abs/2401.04406",
        "title": "MapAI: Precision in Building Segmentation",
        "rating": 0,
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "MapAI: Precision in Building Segmentation is a competition arranged with the Norwegian Artificial Intelligence Research Consortium (NORA) in collaboration with Centre for Artificial Intelligence Research at the University of Agder (CAIR), the Norwegian Mapping Authority, AI:Hub, Norkart, and the Danish Agency for Data Supply and Infrastructure. The competition will be held in the fall of 2022. It will be concluded at the Northern Lights Deep Learning conference focusing on the segmentation of buildings using aerial images and laser data. We propose two different tasks to segment buildings, where the first task can only utilize aerial images, while the second must use laser data (LiDAR) with or without aerial images. Furthermore, we use IoU and Boundary IoU to properly evaluate the precision of the models, with the latter being an IoU measure that evaluates the results' boundaries. We provide the participants with a training dataset and keep a test dataset for evaluation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 4 figures, competition"
    },
    {
        "paper id": "2401.04468",
        "abstract url": "https://arxiv.org/abs/2401.04468",
        "title": "MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The growing demand for high-fidelity video generation from textual descriptions has catalyzed significant research in this field. In this work, we introduce MagicVideo-V2 that integrates the text-to-image model, video motion generator, reference image embedding module and frame interpolation module into an end-to-end video generation pipeline. Benefiting from these architecture designs, MagicVideo-V2 can generate an aesthetically pleasing, high-resolution video with remarkable fidelity and smoothness. It demonstrates superior performance over leading Text-to-Video systems such as Runway, Pika 1.0, Morph, Moon Valley and Stable Video Diffusion model via user evaluation at large scale.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04585",
        "abstract url": "https://arxiv.org/abs/2401.04585",
        "title": "Enhanced Distribution Alignment for Post-Training Quantization of Diffusion Models",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have achieved great success in image generation tasks through iterative noise estimation. However, the heavy denoising process and complex neural networks hinder their low-latency applications in real-world scenarios. Quantization can effectively reduce model complexity, and post-training quantization (PTQ), which does not require fine-tuning, is highly promising in accelerating the denoising process. Unfortunately, we find that due to the highly dynamic distribution of activations in different denoising steps, existing PTQ methods for diffusion models suffer from distribution mismatch issues at both calibration sample level and reconstruction output level, which makes the performance far from satisfactory, especially in low-bit cases. In this paper, we propose Enhanced Distribution Alignment for Post-Training Quantization of Diffusion Models (EDA-DM) to address the above issues. Specifically, at the calibration sample level, we select calibration samples based on the density and diversity in the latent space, thus facilitating the alignment of their distribution with the overall samples; and at the reconstruction output level, we propose Fine-grained Block Reconstruction, which can align the outputs of the quantized model and the full-precision model at different network granularity. Extensive experiments demonstrate that EDA-DM outperforms the existing post-training quantization frameworks in both unconditional and conditional generation scenarios. At low-bit precision, the quantized models with our method even outperform the full-precision models on most datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 15 figures"
    },
    {
        "paper id": "2401.04608",
        "abstract url": "https://arxiv.org/abs/2401.04608",
        "title": "EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent years have witnessed remarkable progress in image generation task, where users can create visually astonishing images with high-quality. However, existing text-to-image diffusion models are proficient in generating concrete concepts (dogs) but encounter challenges with more abstract ones (emotions). Several efforts have been made to modify image emotions with color and style adjustments, facing limitations in effectively conveying emotions with fixed image contents. In this work, we introduce Emotional Image Content Generation (EICG), a new task to generate semantic-clear and emotion-faithful images given emotion categories. Specifically, we propose an emotion space and construct a mapping network to align it with the powerful Contrastive Language-Image Pre-training (CLIP) space, providing a concrete interpretation of abstract emotions. Attribute loss and emotion confidence are further proposed to ensure the semantic diversity and emotion fidelity of the generated images. Our method outperforms the state-of-the-art text-to-image approaches both quantitatively and qualitatively, where we derive three custom metrics, i.e., emotion accuracy, semantic clarity and semantic diversity. In addition to generation, our method can help emotion understanding and inspire emotional art design.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04700",
        "abstract url": "https://arxiv.org/abs/2401.04700",
        "title": "Model Editing Can Hurt General Abilities of Large Language Models",
        "rating": 0,
        "keywords": [
            [
                "Model Editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "One critical challenge that has emerged is the presence of hallucinations in the output of large language models (LLMs) due to false or outdated knowledge. Since retraining LLMs with updated information is resource-intensive, there has been a growing interest in model editing. However, current model editing methods, while effective in improving editing performance in various scenarios, often overlook potential side effects on the general abilities of LLMs. In this paper, we raise concerns that model editing inherently improves the factuality of the model, but may come at the cost of a significant degradation of these general abilities. Systematically, we analyze side effects by evaluating four popular editing methods on three LLMs across eight representative task categories. Extensive empirical research reveals that current model editing methods are difficult to couple well with LLMs to simultaneously improve the factuality and maintain the general abilities such as reasoning, question answering, etc. Strikingly, the use of a specific method to edit LLaMA-1 (7B) resulted in a drastic performance degradation to nearly 0 on all selected tasks with just a single edit. Therefore, we advocate for more research efforts to minimize the loss of general abilities acquired during LLM pre-training and to ultimately preserve them during model editing.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Add new results on LLaMA-2 (7B)"
    },
    {
        "paper id": "2401.04801",
        "abstract url": "https://arxiv.org/abs/2401.04801",
        "title": "Refining Remote Photoplethysmography Architectures using CKA and Empirical Methods",
        "rating": 0,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Model architecture refinement is a challenging task in deep learning research fields such as remote photoplethysmography (rPPG). One architectural consideration, the depth of the model, can have significant consequences on the resulting performance. In rPPG models that are overprovisioned with more layers than necessary, redundancies exist, the removal of which can result in faster training and reduced computational load at inference time. With too few layers the models may exhibit sub-optimal error rates. We apply Centered Kernel Alignment (CKA) to an array of rPPG architectures of differing depths, demonstrating that shallower models do not learn the same representations as deeper models, and that after a certain depth, redundant layers are added without significantly increased functionality. An empirical study confirms these findings and shows how this method could be used to refine rPPG architectures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04861",
        "abstract url": "https://arxiv.org/abs/2401.04861",
        "title": "CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from Monocular Video",
        "rating": 0,
        "keywords": [
            [
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The goal of our work is to generate high-quality novel views from monocular videos of complex and dynamic scenes. Prior methods, such as DynamicNeRF, have shown impressive performance by leveraging time-varying dynamic radiation fields. However, these methods have limitations when it comes to accurately modeling the motion of complex objects, which can lead to inaccurate and blurry renderings of details. To address this limitation, we propose a novel approach that builds upon a recent generalization NeRF, which aggregates nearby views onto new viewpoints. However, such methods are typically only effective for static scenes. To overcome this challenge, we introduce a module that operates in both the time and frequency domains to aggregate the features of object motion. This allows us to learn the relationship between frames and generate higher-quality images. Our experiments demonstrate significant improvements over state-of-the-art methods on dynamic scene datasets. Specifically, our approach outperforms existing methods in terms of both the accuracy and visual quality of the synthesized views.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10083",
        "abstract url": "https://arxiv.org/abs/2401.10083",
        "title": "A locally statistical active contour model for SAR image segmentation can be solved by denoising algorithms",
        "rating": 0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we propose a novel locally statistical variational active contour model based on I-divergence-TV denoising model, which hybrides geodesic active contour (GAC) model with active contours without edges (ACWE) model, and can be used to segment images corrupted by multiplicative gamma noise. By adding a diffusion term into the level set evolution (LSE) equation of the proposed model, we construct a reaction-diffusion (RD) equation, which can gradually regularize the level set function (LSF) to be piecewise constant in each segment domain and gain the stable solution. We further transform the proposed model into classic ROF model by adding a proximity term. Inspired by a fast denoising algorithm proposed by Jia-Zhao recently, we propose two fast fixed point algorithms to solve SAR image segmentation question. Experimental results for real SAR images show that the proposed image segmentation model can efficiently stop the contours at weak or blurred edges, and can automatically detect the exterior and interior boundaries of images with multiplicative gamma noise. The proposed FPRD1/FPRD2 models are about 1/2 (or less than) of the time required for the SBRD model based on the Split Bregman technique.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2312.11849, arXiv:2312.08376, arXiv:2312.09365"
    },
    {
        "paper id": "2402.03327",
        "abstract url": "https://arxiv.org/abs/2402.03327",
        "title": "Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with Large Language Models",
        "rating": 0,
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce Uni3D-LLM, a unified framework that leverages a Large Language Model (LLM) to integrate tasks of 3D perception, generation, and editing within point cloud scenes. This framework empowers users to effortlessly generate and modify objects at specified locations within a scene, guided by the versatility of natural language descriptions. Uni3D-LLM harnesses the expressive power of natural language to allow for precise command over the generation and editing of 3D objects, thereby significantly enhancing operational flexibility and controllability. By mapping point cloud into the unified representation space, Uni3D-LLM achieves cross-application functionality, enabling the seamless execution of a wide array of tasks, ranging from the accurate instantiation of 3D objects to the diverse requirements of interactive design. Through a comprehensive suite of rigorous experiments, the efficacy of Uni3D-LLM in the comprehension, generation, and editing of point cloud has been validated. Additionally, we have assessed the impact of integrating a point cloud perception module on the generation and editing processes, confirming the substantial potential of our approach for practical applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2401.04361",
        "abstract url": "https://arxiv.org/abs/2401.04361",
        "title": "Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning",
        "rating": -0.5,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Knowledge-grounded dialogue (KGD) learns to generate an informative response based on a given dialogue context and external knowledge (\\emph{e.g.}, knowledge graphs; KGs). Recently, the emergence of large language models (LLMs) and pre-training techniques has brought great success to knowledge-grounded dialogue. However, when building KGD systems in real applications, there are various real-world noises that are inevitable to face. For example, the dialogue context might involve perturbations such as misspellings and abbreviations. In addition, KGs typically suffer from incompletion and also might contain erroneous and outdated facts. Such real-world noises pose a challenge to the robustness of KGD systems and hinder their applications in the real world. In this paper, we propose an entity-based contrastive learning framework for improving the robustness of KGD. Specifically, we make use of the entity information in a KGD sample to create both its positive and negative samples which involve semantic-irrelevant and semantic-relevant perturbations, respectively. The contrastive learning framework ensures the KGD model is aware of these two types of perturbations, thus generating informative responses with the potentially noisy inputs in real applications. Experimental results on three benchmark datasets show that our method achieves new state-of-the-art performance in terms of automatic evaluation scores, verifying its effectiveness and potentiality. Furthermore, we show that our method can generate better responses than comparison models in both the noisy and the few-shot settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.04572",
        "abstract url": "https://arxiv.org/abs/2401.04572",
        "title": "Robust Imitation Learning for Automated Game Testing",
        "rating": -0.5,
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Game development is a long process that involves many stages before a product is ready for the market. Human play testing is among the most time consuming, as testers are required to repeatedly perform tasks in the search for errors in the code. Therefore, automated testing is seen as a key technology for the gaming industry, as it would dramatically improve development costs and efficiency. Toward this end, we propose EVOLUTE, a novel imitation learning-based architecture that combines behavioural cloning (BC) with energy based models (EBMs). EVOLUTE is a two-stream ensemble model that splits the action space of autonomous agents into continuous and discrete tasks. The EBM stream handles the continuous tasks, to have a more refined and adaptive control, while the BC stream handles discrete actions, to ease training. We evaluate the performance of EVOLUTE in a shooting-and-driving game, where the agent is required to navigate and continuously identify targets to attack. The proposed model has higher generalisation capabilities than standard BC approaches, showing a wider range of behaviours and higher performances. Also, EVOLUTE is easier to train than a pure end-to-end EBM model, as discrete tasks can be quite sparse in the dataset and cause model training to explore a much wider set of possible actions while training.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04741",
        "abstract url": "https://arxiv.org/abs/2401.04741",
        "title": "Masked AutoEncoder for Graph Clustering without Pre-defined Cluster Number k",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph clustering algorithms with autoencoder structures have recently gained popularity due to their efficient performance and low training cost. However, for existing graph autoencoder clustering algorithms based on GCN or GAT, not only do they lack good generalization ability, but also the number of clusters clustered by such autoencoder models is difficult to determine automatically. To solve this problem, we propose a new framework called Graph Clustering with Masked Autoencoders (GCMA). It employs our designed fusion autoencoder based on the graph masking method for the fusion coding of graph. It introduces our improved density-based clustering algorithm as a second decoder while decoding with multi-target reconstruction. By decoding the mask embedding, our model can capture more generalized and comprehensive knowledge. The number of clusters and clustering results can be output end-to-end while improving the generalization ability. As a nonparametric class method, extensive experiments demonstrate the superiority of \\textit{GCMA} over state-of-the-art baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04747",
        "abstract url": "https://arxiv.org/abs/2401.04747",
        "title": "DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation",
        "rating": -0.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.SD"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We propose DiffSHEG, a Diffusion-based approach for Speech-driven Holistic 3D Expression and Gesture generation with arbitrary length. While previous works focused on co-speech gesture or expression generation individually, the joint generation of synchronized expressions and gestures remains barely explored. To address this, our diffusion-based co-speech motion generation transformer enables uni-directional information flow from expression to gesture, facilitating improved matching of joint expression-gesture distributions. Furthermore, we introduce an outpainting-based sampling strategy for arbitrary long sequence generation in diffusion models, offering flexibility and computational efficiency. Our method provides a practical solution that produces high-quality synchronized expression and gesture generation driven by speech. Evaluated on two public datasets, our approach achieves state-of-the-art performance both quantitatively and qualitatively. Additionally, a user study confirms the superiority of DiffSHEG over prior approaches. By enabling the real-time generation of expressive and synchronized motions, DiffSHEG showcases its potential for various applications in the development of digital humans and embodied agents.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Accepted by CVPR 2024. Project page: https://jeremycjm.github.io/proj/DiffSHEG"
    },
    {
        "paper id": "2401.04829",
        "abstract url": "https://arxiv.org/abs/2401.04829",
        "title": "GNNShap: Scalable and Accurate GNN Explanation using Shapley Values",
        "rating": -0.5,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) are popular machine learning models for graphs with many applications across scientific domains. However, GNNs are considered black box models, and it is challenging to understand how the model makes predictions. Game theoric Shapley value approaches are popular explanation methods in other domains but are not well-studied for graphs. Some studies have proposed Shapley value based GNN explanations, yet they have several limitations: they consider limited samples to approximate Shapley values; some mainly focus on small and large coalition sizes, and they are an order of magnitude slower than other explanation methods, making them inapplicable to even moderate-size graphs. In this work, we propose GNNShap, which provides explanations for edges since they provide more natural explanations for graphs and more fine-grained explanations. We overcome the limitations by sampling from all coalition sizes, parallelizing the sampling on GPUs, and speeding up model predictions by batching. GNNShap gives better fidelity scores and faster explanations than baselines on real-world datasets. The code is available at https://github.com/HipGraph/GNNShap.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04915",
        "abstract url": "https://arxiv.org/abs/2401.04915",
        "title": "From low resource information extraction to identifying influential nodes in knowledge graphs",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "We propose a pipeline for identifying important entities from intelligence reports that constructs a knowledge graph, where nodes correspond to entities of fine-grained types (e.g. traffickers) extracted from the text and edges correspond to extracted relations between entities (e.g. cartel membership). The important entities in intelligence reports then map to central nodes in the knowledge graph. We introduce a novel method that extracts fine-grained entities in a few-shot setting (few labeled examples), given limited resources available to label the frequently changing entity types that intelligence analysts are interested in. It outperforms other state-of-the-art methods. Next, we identify challenges facing previous evaluations of zero-shot (no labeled examples) methods for extracting relations, affecting the step of populating edges. Finally, we explore the utility of the pipeline: given the goal of identifying important entities, we evaluate the impact of relation extraction errors on the identification of central nodes in several real and synthetic networks. The impact of these errors varies significantly by graph topology, suggesting that confidence in measurements based on automatically extracted relations should depend on observed network features.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "14 pages, 6 figures, to appear at CompleNet 2024"
    },
    {
        "paper id": "2401.04928",
        "abstract url": "https://arxiv.org/abs/2401.04928",
        "title": "Relaxed Contrastive Learning for Federated Learning",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel contrastive learning framework to effectively address the challenges of data heterogeneity in federated learning. We first analyze the inconsistency of gradient updates across clients during local training and establish its dependence on the distribution of feature representations, leading to the derivation of the supervised contrastive learning (SCL) objective to mitigate local deviations. In addition, we show that a na\u00efve adoption of SCL in federated learning leads to representation collapse, resulting in slow convergence and limited performance gains. To address this issue, we introduce a relaxed contrastive learning loss that imposes a divergence penalty on excessively similar sample pairs within each class. This strategy prevents collapsed representations and enhances feature transferability, facilitating collaborative training and leading to significant performance improvements. Our framework outperforms all existing federated learning approaches by huge margins on the standard benchmarks through extensive experimental results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04367",
        "abstract url": "https://arxiv.org/abs/2401.04367",
        "title": "Probabilistic emotion and sentiment modelling of patient-reported experiences",
        "rating": -1,
        "keywords": [
            [
                "healthcare",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces a novel methodology for modelling patient emotions from online patient experience narratives. We employed metadata network topic modelling to analyse patient-reported experiences from Care Opinion, revealing key emotional themes linked to patient-caregiver interactions and clinical outcomes. We develop a probabilistic, context-specific emotion recommender system capable of predicting both multilabel emotions and binary sentiments using a naive Bayes classifier using contextually meaningful topics as predictors. The superior performance of our predicted emotions under this model compared to baseline models was assessed using the information retrieval metrics nDCG and Q-measure, and our predicted sentiments achieved an F1 score of 0.921, significantly outperforming standard sentiment lexicons. This method offers a transparent, cost-effective way to understand patient feedback, enhancing traditional collection methods and informing individualised patient care. Our findings are accessible via an R package and interactive dashboard, providing valuable tools for healthcare researchers and practitioners.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "23 pages, 10 figures, 5 tables"
    },
    {
        "paper id": "2401.04372",
        "abstract url": "https://arxiv.org/abs/2401.04372",
        "title": "Stable generative modeling using diffusion maps",
        "rating": -1,
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "We consider the problem of sampling from an unknown distribution for which only a sufficiently large number of training samples are available. Such settings have recently drawn considerable interest in the context of generative modelling. In this paper, we propose a generative model combining diffusion maps and Langevin dynamics. Diffusion maps are used to approximate the drift term from the available training samples, which is then implemented in a discrete-time Langevin sampler to generate new samples. By setting the kernel bandwidth to match the time step size used in the unadjusted Langevin algorithm, our method effectively circumvents any stability issues typically associated with time-stepping stiff stochastic differential equations. More precisely, we introduce a novel split-step scheme, ensuring that the generated samples remain within the convex hull of the training samples. Our framework can be naturally extended to generate conditional samples. We demonstrate the performance of our proposed scheme through experiments on synthetic datasets with increasing dimensions and on a stochastic subgrid-scale parametrization conditional sampling problem.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "23 pages, 25 figures"
    },
    {
        "paper id": "2401.04412",
        "abstract url": "https://arxiv.org/abs/2401.04412",
        "title": "Deep Covariance Alignment for Domain Adaptive Remote Sensing Image Segmentation",
        "rating": -1,
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Unsupervised domain adaptive (UDA) image segmentation has recently gained increasing attention, aiming to improve the generalization capability for transferring knowledge from the source domain to the target domain. However, in high spatial resolution remote sensing image (RSI), the same category from different domains (\\emph{e.g.}, urban and rural) can appear to be totally different with extremely inconsistent distributions, which heavily limits the UDA accuracy. To address this problem, in this paper, we propose a novel Deep Covariance Alignment (DCA) model for UDA RSI segmentation. The DCA can explicitly align category features to learn shared domain-invariant discriminative feature representations, which enhances the ability of model generalization. Specifically, a Category Feature Pooling (CFP) module is first employed to extract category features by combining the coarse outputs and the deep features. Then, we leverage a novel Covariance Regularization (CR) to enforce the intra-category features to be closer and the inter-category features to be further separate. Compared with the existing category alignment methods, our CR aims to regularize the correlation between different dimensions of the features and thus performs more robustly when dealing with the divergent category features of imbalanced and inconsistent distributions. Finally, we propose a stagewise procedure to train the DCA in order to alleviate the error accumulation. Experiments on both Rural-to-Urban and Urban-to-Rural scenarios of the LoveDA dataset demonstrate the superiority of our proposed DCA over other state-of-the-art UDA segmentation methods. Code is available at https://github.com/Luffy03/DCA.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "A paper accepted by TGRS"
    },
    {
        "paper id": "2401.04425",
        "abstract url": "https://arxiv.org/abs/2401.04425",
        "title": "Meta-forests: Domain generalization on random forests with meta-learning",
        "rating": -1,
        "keywords": [
            [
                "biomedicine"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Domain generalization is a popular machine learning technique that enables models to perform well on the unseen target domain, by learning from multiple source domains. Domain generalization is useful in cases where data is limited, difficult, or expensive to collect, such as in object recognition and biomedicine. In this paper, we propose a novel domain generalization algorithm called \"meta-forests\", which builds upon the basic random forests model by incorporating the meta-learning strategy and maximum mean discrepancy measure. The aim of meta-forests is to enhance the generalization ability of classifiers by reducing the correlation among trees and increasing their strength. More specifically, meta-forests conducts meta-learning optimization during each meta-task, while also utilizing the maximum mean discrepancy as a regularization term to penalize poor generalization performance in the meta-test process. To evaluate the effectiveness of our algorithm, we test it on two publicly object recognition datasets and a glucose monitoring dataset that we have used in a previous study. Our results show that meta-forests outperforms state-of-the-art approaches in terms of generalization performance on both object recognition and glucose monitoring datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper is accepted by ACML2023"
    },
    {
        "paper id": "2401.04435",
        "abstract url": "https://arxiv.org/abs/2401.04435",
        "title": "Uncertainty-aware Sampling for Long-tailed Semi-supervised Learning",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "For semi-supervised learning with imbalance classes, the long-tailed distribution of data will increase the model prediction bias toward dominant classes, undermining performance on less frequent classes. Existing methods also face challenges in ensuring the selection of sufficiently reliable pseudo-labels for model training and there is a lack of mechanisms to adjust the selection of more reliable pseudo-labels based on different training stages. To mitigate this issue, we introduce uncertainty into the modeling process for pseudo-label sampling, taking into account that the model performance on the tailed classes varies over different training stages. For example, at the early stage of model training, the limited predictive accuracy of model results in a higher rate of uncertain pseudo-labels. To counter this, we propose an Uncertainty-Aware Dynamic Threshold Selection (UDTS) approach. This approach allows the model to perceive the uncertainty of pseudo-labels at different training stages, thereby adaptively adjusting the selection thresholds for different classes. Compared to other methods such as the baseline method FixMatch, UDTS achieves an increase in accuracy of at least approximately 5.26%, 1.75%, 9.96%, and 1.28% on the natural scene image datasets CIFAR10-LT, CIFAR100-LT, STL-10-LT, and the medical image dataset TissueMNIST, respectively. The source code of UDTS is publicly available at: https://github.com/yangk/UDTS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to TPAMI"
    },
    {
        "paper id": "2401.04463",
        "abstract url": "https://arxiv.org/abs/2401.04463",
        "title": "D3AD: Dynamic Denoising Diffusion Probabilistic Model for Anomaly Detection",
        "rating": -1,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have found valuable applications in anomaly detection by capturing the nominal data distribution and identifying anomalies via reconstruction. Despite their merits, they struggle to localize anomalies of varying scales, especially larger anomalies like entire missing components. Addressing this, we present a novel framework that enhances the capability of diffusion models, by extending the previous introduced implicit conditioning approach Meng et al. (2022) in three significant ways. First, we incorporate a dynamic step size computation that allows for variable noising steps in the forward process guided by an initial anomaly prediction. Second, we demonstrate that denoising an only scaled input, without any added noise, outperforms conventional denoising process. Third, we project images in a latent space to abstract away from fine details that interfere with reconstruction of large missing components. Additionally, we propose a fine-tuning mechanism that facilitates the model to effectively grasp the nuances of the target domain. Our method undergoes rigorous evaluation on two prominent anomaly detection datasets VISA and BTAD, yielding state-of-the-art performance. Importantly, our framework effectively localizes anomalies regardless of their scale, marking a pivotal advancement in diffusion-based anomaly detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04464",
        "abstract url": "https://arxiv.org/abs/2401.04464",
        "title": "PhilEO Bench: Evaluating Geo-Spatial Foundation Models",
        "rating": -1,
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Massive amounts of unlabelled data are captured by Earth Observation (EO) satellites, with the Sentinel-2 constellation generating 1.6 TB of data daily. This makes Remote Sensing a data-rich domain well suited to Machine Learning (ML) solutions. However, a bottleneck in applying ML models to EO is the lack of annotated data as annotation is a labour-intensive and costly process. As a result, research in this domain has focused on Self-Supervised Learning and Foundation Model approaches. This paper addresses the need to evaluate different Foundation Models on a fair and uniform benchmark by introducing the PhilEO Bench, a novel evaluation framework for EO Foundation Models. The framework comprises of a testbed and a novel 400 GB Sentinel-2 dataset containing labels for three downstream tasks, building density estimation, road segmentation, and land cover classification. We present experiments using our framework evaluating different Foundation Models, including Prithvi and SatMAE, at multiple n-shots and convergence rates.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 5 figures, Submitted to IGARSS 2024"
    },
    {
        "paper id": "2401.04486",
        "abstract url": "https://arxiv.org/abs/2401.04486",
        "title": "Take A Shortcut Back: Mitigating the Gradient Vanishing for Training Spiking Neural Networks",
        "rating": -1,
        "keywords": [
            [
                "biologically"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Spiking Neural Network (SNN) is a biologically inspired neural network infrastructure that has recently garnered significant attention. It utilizes binary spike activations to transmit information, thereby replacing multiplications with additions and resulting in high energy efficiency. However, training an SNN directly poses a challenge due to the undefined gradient of the firing spike process. Although prior works have employed various surrogate gradient training methods that use an alternative function to replace the firing process during back-propagation, these approaches ignore an intrinsic problem: gradient vanishing. To address this issue, we propose a shortcut back-propagation method in our paper, which advocates for transmitting the gradient directly from the loss to the shallow layers. This enables us to present the gradient to the shallow layers directly, thereby significantly mitigating the gradient vanishing problem. Additionally, this method does not introduce any burden during the inference phase. To strike a balance between final accuracy and ease of training, we also propose an evolutionary training framework and implement it by inducing a balance coefficient that dynamically changes with the training epoch, which further improves the network's performance. Extensive experiments conducted over static and dynamic datasets using several popular network structures reveal that our method consistently outperforms state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04487",
        "abstract url": "https://arxiv.org/abs/2401.04487",
        "title": "Online convex optimization for robust control of constrained dynamical systems",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "This article investigates the problem of controlling linear time-invariant systems subject to time-varying and a priori unknown cost functions, state and input constraints, and exogenous disturbances. We combine the online convex optimization framework with tools from robust model predictive control to propose an algorithm that is able to guarantee robust constraint satisfaction. The performance of the closed loop emerging from application of our framework is studied in terms of its dynamic regret, which is proven to be bounded linearly by the variation of the cost functions and the magnitude of the disturbances. We corroborate our theoretical findings and illustrate implementational aspects of the proposed algorithm by a numerical case study of a tracking control problem of an autonomous vehicle.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2401.04495",
        "abstract url": "https://arxiv.org/abs/2401.04495",
        "title": "Differential experiments using parallel alternative operations",
        "rating": -1,
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "The use of alternative operations in differential cryptanalysis, or alternative notions of differentials, are lately receiving increasing attention. Recently, Civino et al. managed to design a block cipher which is secure w.r.t. classical differential cryptanalysis performed using XOR-differentials, but weaker with respect to the attack based on an alternative difference operation acting on the first s-box of the block. We extend this result to parallel alternative operations, i.e. acting on each s-box of the block. First, we recall the mathematical framework needed to define and use such operations. After that, we perform some differential experiments against a toy cipher and compare the effectiveness of the attack w.r.t. the one that uses XOR-differentials.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04534",
        "abstract url": "https://arxiv.org/abs/2401.04534",
        "title": "Testing Human-Robot Interaction in Virtual Reality: Experience from a Study on Speech Act Classification",
        "rating": -1,
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In recent years, an increasing number of Human-Robot Interaction (HRI) approaches have been implemented and evaluated in Virtual Reality (VR), as it allows to speed-up design iterations and makes it safer for the final user to evaluate and master the HRI primitives. However, identifying the most suitable VR experience is not straightforward. In this work, we evaluate how, in a smart agriculture scenario, immersive and non-immersive VR are perceived by users with respect to a speech act understanding task. In particular, we collect opinions and suggestions from the 81 participants involved in both experiments to highlight the strengths and weaknesses of these different experiences.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 Pages, 3 Figures, 6th International Workshop on Virtual, Augmented, and Mixed-Reality for Human-Robot Interactions VAM-HRI 2023. ACM/IEEE International Conference on Human-Robot Interaction. HRI 2023. March 13-16, 2023 Stockholm, SE"
    },
    {
        "paper id": "2401.04545",
        "abstract url": "https://arxiv.org/abs/2401.04545",
        "title": "Evaluating Gesture Recognition in Virtual Reality",
        "rating": -1,
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Human-Robot Interaction (HRI) has become increasingly important as robots are being integrated into various aspects of daily life. One key aspect of HRI is gesture recognition, which allows robots to interpret and respond to human gestures in real-time. Gesture recognition plays an important role in non-verbal communication in HRI. To this aim, there is ongoing research on how such non-verbal communication can strengthen verbal communication and improve the system's overall efficiency, thereby enhancing the user experience with the robot. However, several challenges need to be addressed in gesture recognition systems, which include data generation, transferability, scalability, generalizability, standardization, and lack of benchmarking of the gestural systems. In this preliminary paper, we want to address the challenges of data generation using virtual reality simulations and standardization issues by presenting gestures to some commands that can be used as a standard in ground robots.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "4 Pages, 3 Figures, Workshop YOUR Study Design!(WYSD 2023) Participatory critique and refinement of participants' studies. Workshop at the ACM/IEEE International Conference on Human-Robot Interaction (HRI 2023). March 13-16, 2023, Stockholm, SE"
    },
    {
        "paper id": "2401.04550",
        "abstract url": "https://arxiv.org/abs/2401.04550",
        "title": "WaveletFormerNet: A Transformer-based Wavelet Network for Real-world Non-homogeneous and Dense Fog Removal",
        "rating": -1,
        "keywords": [
            [
                "haze"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Although deep convolutional neural networks have achieved remarkable success in removing synthetic fog, it is essential to be able to process images taken in complex foggy conditions, such as dense or non-homogeneous fog, in the real world. However, the haze distribution in the real world is complex, and downsampling can lead to color distortion or loss of detail in the output results as the resolution of a feature map or image resolution decreases. In addition to the challenges of obtaining sufficient training data, overfitting can also arise in deep learning techniques for foggy image processing, which can limit the generalization abilities of the model, posing challenges for its practical applications in real-world scenarios. Considering these issues, this paper proposes a Transformer-based wavelet network (WaveletFormerNet) for real-world foggy image recovery. We embed the discrete wavelet transform into the Vision Transformer by proposing the WaveletFormer and IWaveletFormer blocks, aiming to alleviate texture detail loss and color distortion in the image due to downsampling. We introduce parallel convolution in the Transformer block, which allows for the capture of multi-frequency information in a lightweight mechanism. Additionally, we have implemented a feature aggregation module (FAM) to maintain image resolution and enhance the feature extraction capacity of our model, further contributing to its impressive performance in real-world foggy image recovery tasks. Extensive experiments demonstrate that our WaveletFormerNet performs better than state-of-the-art methods, as shown through quantitative and qualitative evaluations of minor model complexity. Additionally, our satisfactory results on real-world dust removal and application tests showcase the superior generalization ability and improved performance of WaveletFormerNet in computer vision-related applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04554",
        "abstract url": "https://arxiv.org/abs/2401.04554",
        "title": "HIST-Critical Graphs and Malkevitch's Conjecture",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In a given graph, a HIST is a spanning tree without $2$-valent vertices. Motivated by developing a better understanding of HIST-free graphs, i.e. graphs containing no HIST, in this article's first part we study HIST-critical graphs, i.e. HIST-free graphs in which every vertex-deleted subgraph does contain a HIST (e.g. a triangle). We give an almost complete characterisation of the orders for which these graphs exist and present an infinite family of planar examples which are $3$-connected and in which nearly all vertices are $4$-valent. This leads naturally to the second part in which we investigate planar $4$-regular graphs with and without HISTs, motivated by a conjecture of Malkevitch, which we computationally verify up to order $22$. First we enumerate HISTs in antiprisms, whereafter we present planar $4$-regular graphs with and without HISTs, obtained via line graphs.",
        "subjects": [
            "math.CO"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2401.04560",
        "abstract url": "https://arxiv.org/abs/2401.04560",
        "title": "Phase-shifted remote photoplethysmography for estimating heart rate and blood pressure from facial video",
        "rating": -1,
        "keywords": [
            [
                "biometric",
                "health",
                "diagnosis",
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Human health can be critically affected by cardiovascular diseases, such as hypertension, arrhythmias, and stroke. Heart rate and blood pressure are important biometric information for the monitoring of cardiovascular system and early diagnosis of cardiovascular diseases. Existing methods for estimating the heart rate are based on electrocardiography and photoplethyomography, which require contacting the sensor to the skin surface. Moreover, catheter and cuff-based methods for measuring blood pressure cause inconvenience and have limited applicability. Therefore, in this thesis, we propose a vision-based method for estimating the heart rate and blood pressure. This thesis proposes a 2-stage deep learning framework consisting of a dual remote photoplethysmography network (DRP-Net) and bounded blood pressure network (BBP-Net). In the first stage, DRP-Net infers remote photoplethysmography (rPPG) signals for the acral and facial regions, and these phase-shifted rPPG signals are utilized to estimate the heart rate. In the second stage, BBP-Net integrates temporal features and analyzes phase discrepancy between the acral and facial rPPG signals to estimate SBP and DBP values. To improve the accuracy of estimating the heart rate, we employed a data augmentation method based on a frame interpolation model. Moreover, we designed BBP-Net to infer blood pressure within a predefined range by incorporating a scaled sigmoid function. Our method resulted in estimating the heart rate with the mean absolute error (MAE) of 1.78 BPM, reducing the MAE by 34.31 % compared to the recent method, on the MMSE-HR dataset. The MAE for estimating the systolic blood pressure (SBP) and diastolic blood pressure (DBP) were 10.19 mmHg and 7.09 mmHg. On the V4V dataset, the MAE for the heart rate, SBP, and DBP were 3.83 BPM, 13.64 mmHg, and 9.4 mmHg, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "32 pages, 7 figures"
    },
    {
        "paper id": "2401.04592",
        "abstract url": "https://arxiv.org/abs/2401.04592",
        "title": "An Assessment on Comprehending Mental Health through Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Mental health challenges pose considerable global burdens on individuals and communities. Recent data indicates that more than 20% of adults may encounter at least one mental disorder in their lifetime. On the one hand, the advancements in large language models have facilitated diverse applications, yet a significant research gap persists in understanding and enhancing the potential of large language models within the domain of mental health. On the other hand, across various applications, an outstanding question involves the capacity of large language models to comprehend expressions of human mental health conditions in natural language. This study presents an initial evaluation of large language models in addressing this gap. Due to this, we compare the performance of Llama-2 and ChatGPT with classical Machine as well as Deep learning models. Our results on the DAIC-WOZ dataset show that transformer-based models, like BERT or XLNet, outperform the large language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04620",
        "abstract url": "https://arxiv.org/abs/2401.04620",
        "title": "Agent Alignment in Evolving Social Norms",
        "rating": -1,
        "keywords": [
            [
                "survival"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstrate that EvolutionaryAgent can align progressively better with the evolving social norms while maintaining its proficiency in general tasks. Effectiveness tests conducted on various open and closed-source LLMs as the foundation for agents also prove the applicability of our approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2401.04638",
        "abstract url": "https://arxiv.org/abs/2401.04638",
        "title": "Approximation Algorithms for Minimizing Congestion in Demand-Aware Networks",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Emerging reconfigurable optical communication technologies allow to enhance datacenter topologies with demand-aware links optimized towards traffic patterns. This paper studies the algorithmic problem of jointly optimizing topology and routing in such demand-aware networks to minimize congestion, along two dimensions: (1) splittable or unsplittable flows, and (2) whether routing is segregated, i.e., whether routes can or cannot combine both demand-aware and demand-oblivious (static) links. For splittable and segregated routing, we show that the problem is generally $2$-approximable, but APX-hard even for uniform demands induced by a bipartite demand graph. For unsplittable and segregated routing, we establish upper and lower bounds of $O\\left(\\log m/ \\log\\log m \\right)$ and $\u03a9\\left(\\log m/ \\log\\log m \\right)$, respectively, for polynomial-time approximation algorithms, where $m$ is the number of static links. We further reveal that under un-/splittable and non-segregated routing, even for demands of a single source (resp., destination), the problem cannot be approximated better than $\u03a9\\left(\\frac{c_{\\max}}{c_{\\min}} \\right)$ unless P=NP, where $c_{\\max}$ (resp., $c_{\\min}$) denotes the maximum (resp., minimum) capacity. It remains NP-hard for uniform capacities, but is tractable for a single commodity and uniform capacities. Our trace-driven simulations show a significant reduction in network congestion compared to existing solutions.",
        "subjects": [
            "cs.PF"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2401.04662",
        "abstract url": "https://arxiv.org/abs/2401.04662",
        "title": "The Devil Behind the Mirror: Tracking the Campaigns of Cryptocurrency Abuses on the Dark Web",
        "rating": -1,
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "The dark web has emerged as the state-of-the-art solution for enhanced anonymity. Just like a double-edged sword, it also inadvertently becomes the safety net and breeding ground for illicit activities. Among them, cryptocurrencies have been prevalently abused to receive illicit income while evading regulations. Despite the continuing efforts to combat illicit activities, there is still a lack of an in-depth understanding regarding the characteristics and dynamics of cryptocurrency abuses on the dark web. In this work, we conduct a multi-dimensional and systematic study to track cryptocurrency-related illicit activities and campaigns on the dark web. We first harvest a dataset of 4,923 cryptocurrency-related onion sites with over 130K pages. Then, we detect and extract the illicit blockchain transactions to characterize the cryptocurrency abuses, targeting features from single/clustered addresses and illicit campaigns. Throughout our study, we have identified 2,564 illicit sites with 1,189 illicit blockchain addresses, which account for 90.8 BTC in revenue. Based on their inner connections, we further identify 66 campaigns behind them. Our exploration suggests that illicit activities on the dark web have strong correlations, which can guide us to identify new illicit blockchain addresses and onions, and raise alarms at the early stage of their deployment.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04680",
        "abstract url": "https://arxiv.org/abs/2401.04680",
        "title": "CoordGate: Efficiently Computing Spatially-Varying Convolutions in Convolutional Neural Networks",
        "rating": -1,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Optical imaging systems are inherently limited in their resolution due to the point spread function (PSF), which applies a static, yet spatially-varying, convolution to the image. This degradation can be addressed via Convolutional Neural Networks (CNNs), particularly through deblurring techniques. However, current solutions face certain limitations in efficiently computing spatially-varying convolutions. In this paper we propose CoordGate, a novel lightweight module that uses a multiplicative gate and a coordinate encoding network to enable efficient computation of spatially-varying convolutions in CNNs. CoordGate allows for selective amplification or attenuation of filters based on their spatial position, effectively acting like a locally connected neural network. The effectiveness of the CoordGate solution is demonstrated within the context of U-Nets and applied to the challenging problem of image deblurring. The experimental results show that CoordGate outperforms conventional approaches, offering a more robust and spatially aware solution for CNNs in various computer vision applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04692",
        "abstract url": "https://arxiv.org/abs/2401.04692",
        "title": "Comparative Evaluation of Animated Scatter Plot Transitions",
        "rating": -1,
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "Scatter plots are popular for displaying 2D data, but in practice, many data sets have more than two dimensions. For the analysis of such multivariate data, it is often necessary to switch between scatter plots of different dimension pairs, e.g., in a scatter plot matrix (SPLOM). Alternative approaches include a \"grand tour\" for an overview of the entire data set or creating artificial axes from dimensionality reduction (DR). A cross-cutting concern in all techniques is the ability of viewers to find correspondence between data points in different views. Previous work proposed animations to preserve the mental map between view changes and to trace points as well as clusters between scatter plots of the same underlying data set. In this paper, we evaluate a variety of spline- and rotation-based view transitions in a crowdsourced user study focusing on ecological validity. Using the study results, we assess each animation's suitability for tracing points and clusters across view changes. We evaluate whether the order of horizontal and vertical rotation is relevant for task accuracy. The results show that rotations with an orthographic camera or staged expansion of a depth axis significantly outperform all other animation techniques for the traceability of individual points. Further, we provide a ranking of the animated transition techniques for traceability of individual points. However, we could not find any significant differences for the traceability of clusters. Furthermore, we identified differences by animation direction that could guide further studies to determine potential confounds for these differences. We publish the study data for reuse and provide the animation framework as a D3.js plug-in.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04705",
        "abstract url": "https://arxiv.org/abs/2401.04705",
        "title": "EV-EcoSim: A grid-aware co-simulation platform for the design and optimization of electric vehicle charging infrastructure",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "To enable the electrification of transportation systems, it is important to understand how technologies such as grid storage, solar photovoltaic systems, and control strategies can aid the deployment of electric vehicle charging at scale. In this work, we present EV-EcoSim, a co-simulation platform that couples electric vehicle charging, battery systems, solar photovoltaic systems, grid transformers, control strategies, and power distribution systems, to perform cost quantification and analyze the impacts of electric vehicle charging on the grid. This python-based platform can run a receding horizon control scheme for real-time operation and a one-shot control scheme for planning problems, with multi-timescale dynamics for different systems to simulate realistic scenarios. We demonstrate the utility of EV-EcoSim through a case study focused on economic evaluation of battery size to reduce electricity costs while considering impacts of fast charging on the power distribution grid. We present qualitative and quantitative evaluations on the battery size in tabulated results. The tabulated results delineate the trade-offs between candidate battery sizing solutions, providing comprehensive insights for decision-making under uncertainty. Additionally, we demonstrate the implications of the battery controller model fidelity on the system costs and show that the fidelity of the battery controller can completely change decisions made when planning an electric vehicle charging site.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This paper has been accepted for publication at the IEEE Transactions on Smart Grid"
    },
    {
        "paper id": "2401.04720",
        "abstract url": "https://arxiv.org/abs/2401.04720",
        "title": "Low-resource finetuning of foundation models beats state-of-the-art in histopathology",
        "rating": -1,
        "keywords": [
            [
                "whole slide"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To handle the large scale of whole slide images in computational pathology, most approaches first tessellate the images into smaller patches, extract features from these patches, and finally aggregate the feature vectors with weakly-supervised learning. The performance of this workflow strongly depends on the quality of the extracted features. Recently, foundation models in computer vision showed that leveraging huge amounts of data through supervised or self-supervised learning improves feature quality and generalizability for a variety of tasks. In this study, we benchmark the most popular vision foundation models as feature extractors for histopathology data. We evaluate the models in two settings: slide-level classification and patch-level classification. We show that foundation models are a strong baseline. Our experiments demonstrate that by finetuning a foundation model on a single GPU for only two hours or three days depending on the dataset, we can match or outperform state-of-the-art feature extractors for computational pathology. These findings imply that even with little resources one can finetune a feature extractor tailored towards a specific downstream task and dataset. This is a considerable shift from the current state, where only few institutions with large amounts of resources and datasets are able to train a feature extractor. We publish all code used for training and evaluation as well as the finetuned models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04740",
        "abstract url": "https://arxiv.org/abs/2401.04740",
        "title": "Segment anything model (SAM) for brain extraction in fMRI studies",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "fMRI"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Brain extraction and removal of skull artifacts from magnetic resonance images (MRI) is an important preprocessing step in neuroimaging analysis. There are many tools developed to handle human fMRI images, which could involve manual steps for verifying results from brain segmentation that makes it time consuming and inefficient. In this study, we will use the segment anything model (SAM), a freely available neural network released by Meta[4], which has shown promising results in many generic segmentation applications. We will analyze the efficiency of SAM for neuroimaging brain segmentation by removing skull artifacts. The results of the experiments showed promising results that explore using automated segmentation algorithms for neuroimaging without the need to train on custom medical imaging dataset.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04746",
        "abstract url": "https://arxiv.org/abs/2401.04746",
        "title": "Skin Cancer Segmentation and Classification Using Vision Transformer for Automatic Analysis in Dermatoscopy-based Non-invasive Digital System",
        "rating": -1,
        "keywords": [
            [
                "health",
                "diagnosis",
                "Cancer"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Skin cancer is a global health concern, necessitating early and accurate diagnosis for improved patient outcomes. This study introduces a groundbreaking approach to skin cancer classification, employing the Vision Transformer, a state-of-the-art deep learning architecture renowned for its success in diverse image analysis tasks. Utilizing the HAM10000 dataset of 10,015 meticulously annotated skin lesion images, the model undergoes preprocessing for enhanced robustness. The Vision Transformer, adapted to the skin cancer classification task, leverages the self-attention mechanism to capture intricate spatial dependencies, achieving superior performance over traditional deep learning architectures. Segment Anything Model aids in precise segmentation of cancerous areas, attaining high IOU and Dice Coefficient. Extensive experiments highlight the model's supremacy, particularly the Google-based ViT patch-32 variant, which achieves 96.15% accuracy and showcases potential as an effective tool for dermatologists in skin cancer diagnosis, contributing to advancements in dermatological practices.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04750",
        "abstract url": "https://arxiv.org/abs/2401.04750",
        "title": "DedustNet: A Frequency-dominated Swin Transformer-based Wavelet Network for Agricultural Dust Removal",
        "rating": -1,
        "keywords": [
            [
                "Agricultural"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While dust significantly affects the environmental perception of automated agricultural machines, the existing deep learning-based methods for dust removal require further research and improvement in this area to improve the performance and reliability of automated agricultural machines in agriculture. We propose an end-to-end trainable learning network (DedustNet) to solve the real-world agricultural dust removal task. To our knowledge, DedustNet is the first time Swin Transformer-based units have been used in wavelet networks for agricultural image dusting. Specifically, we present the frequency-dominated block (DWTFormer block and IDWTFormer block) by adding a spatial features aggregation scheme (SFAS) to the Swin Transformer and combining it with the wavelet transform, the DWTFormer block and IDWTFormer block, alleviating the limitation of the global receptive field of Swin Transformer when dealing with complex dusty backgrounds. Furthermore, We propose a cross-level information fusion module to fuse different levels of features and effectively capture global and long-range feature relationships. In addition, we present a dilated convolution module to capture contextual information guided by wavelet transform at multiple scales, which combines the advantages of wavelet transform and dilated convolution. Our algorithm leverages deep learning techniques to effectively remove dust from images while preserving the original structural and textural features. Compared to existing state-of-the-art methods, DedustNet achieves superior performance and more reliable results in agricultural image dedusting, providing strong support for the application of agricultural machinery in dusty environments. Additionally, the impressive performance on real-world hazy datasets and application tests highlights DedustNet superior generalization ability and computer vision-related application performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2401.04550"
    },
    {
        "paper id": "2401.04827",
        "abstract url": "https://arxiv.org/abs/2401.04827",
        "title": "The site linkage spectrum of data arrays",
        "rating": -1,
        "keywords": [
            [
                "anomaly detection"
            ]
        ],
        "abstract": "A new perspective is introduced regarding the analysis of Multiple Sequence Alignments (MSA), representing aligned data defined over a finite alphabet of symbols. The framework is designed to produce a block decomposition of an MSA, where each block is comprised of sequences exhibiting a certain site-coherence. The key component of this framework is an information theoretical potential defined on pairs of sites (links) within the MSA. This potential quantifies the expected drop in variation of information between the two constituent sites, where the expectation is taken with respect to all possible sub-alignments, obtained by removing a finite, fixed collection of rows. It is proved that the potential is zero for linked sites representing columns, whose symbols are in bijective correspondence and it is strictly positive, otherwise. It is furthermore shown that the potential assumes its unique minimum for links at which each symbol pair appears with the same multiplicity. Finally, an application is presented regarding anomaly detection in an MSA, composed of inverse fold solutions of a fixed tRNA secondary structure, where the anomalies are represented by inverse fold solutions of a different RNA structure.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "15 pages, 2 figures"
    },
    {
        "paper id": "2401.04849",
        "abstract url": "https://arxiv.org/abs/2401.04849",
        "title": "A Deep Learning Representation of Spatial Interaction Model for Resilient Spatial Planning of Community Business Clusters",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Existing Spatial Interaction Models (SIMs) are limited in capturing the complex and context-aware interactions between business clusters and trade areas. To address the limitation, we propose a SIM-GAT model to predict spatiotemporal visitation flows between community business clusters and their trade areas. The model innovatively represents the integrated system of business clusters, trade areas, and transportation infrastructure within an urban region using a connected graph. Then, a graph-based deep learning model, i.e., Graph AttenTion network (GAT), is used to capture the complexity and interdependencies of business clusters. We developed this model with data collected from the Miami metropolitan area in Florida. We then demonstrated its effectiveness in capturing varying attractiveness of business clusters to different residential neighborhoods and across scenarios with an eXplainable AI approach. We contribute a novel method supplementing conventional SIMs to predict and analyze the dynamics of inter-connected community business clusters. The analysis results can inform data-evidenced and place-specific planning strategies helping community business clusters better accommodate their customers across scenarios, and hence improve the resilience of community businesses.",
        "subjects": [
            "econ.EM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04851",
        "abstract url": "https://arxiv.org/abs/2401.04851",
        "title": "Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand & Uncertainties",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "This paper develops a graph reinforcement learning approach to online planning of the schedule and destinations of electric aircraft that comprise an urban air mobility (UAM) fleet operating across multiple vertiports. This fleet scheduling problem is formulated to consider time-varying demand, constraints related to vertiport capacity, aircraft capacity and airspace safety guidelines, uncertainties related to take-off delay, weather-induced route closures, and unanticipated aircraft downtime. Collectively, such a formulation presents greater complexity, and potentially increased realism, than in existing UAM fleet planning implementations. To address these complexities, a new policy architecture is constructed, primary components of which include: graph capsule conv-nets for encoding vertiport and aircraft-fleet states both abstracted as graphs; transformer layers encoding time series information on demand and passenger fare; and a Multi-head Attention-based decoder that uses the encoded information to compute the probability of selecting each available destination for an aircraft. Trained with Proximal Policy Optimization, this policy architecture shows significantly better performance in terms of daily averaged profits on unseen test scenarios involving 8 vertiports and 40 aircraft, when compared to a random baseline and genetic algorithm-derived optimal solutions, while being nearly 1000 times faster in execution than the latter.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "This paper is accepted to be presented at the ACM Symposium on Applied Computing 2024"
    },
    {
        "paper id": "2401.04853",
        "abstract url": "https://arxiv.org/abs/2401.04853",
        "title": "Entity Recognition from Colloquial Text",
        "rating": -1,
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Extraction of concepts and entities of interest from non-formal texts such as social media posts and informal communication is an important capability for decision support systems in many domains, including healthcare, customer relationship management, and others. Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges. In our research, we focus on the healthcare domain and investigate the problem of symptom recognition from colloquial texts by designing and evaluating several training strategies for BERT-based model fine-tuning. These strategies are distinguished by the choice of the base model, the training corpora, and application of term perturbations in the training data. The best-performing models trained using these strategies outperform the state-of-the-art specialized symptom recognizer by a large margin. Through a series of experiments, we have found specific patterns of model behavior associated with the training strategies we designed. We present design principles for training strategies for effective entity recognition in colloquial texts based on our findings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04858",
        "abstract url": "https://arxiv.org/abs/2401.04858",
        "title": "User Embedding Model for Personalized Language Prompting",
        "rating": -1,
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Modeling long histories plays a pivotal role in enhancing recommendation systems, allowing to capture user's evolving preferences, resulting in more precise and personalized recommendations. In this study we tackle the challenges of modeling long user histories for preference understanding in natural language. Specifically, we introduce a new User Embedding Module (UEM) that efficiently processes user history in free-form text by compressing and representing them as embeddings, to use them as soft prompts to a LM. Our experiments demonstrate the superior capability of this approach in handling significantly longer histories compared to conventional text based prompting methods, yielding substantial improvements in predictive performance. The main contribution of this research is to demonstrate the ability to bias language models with user signals represented as embeddings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04864",
        "abstract url": "https://arxiv.org/abs/2401.04864",
        "title": "Microgravity Mass Gauging with Capacitance Sensing: Sensor Design and Experiment",
        "rating": -1,
        "keywords": [
            [
                "flight"
            ]
        ],
        "abstract": "The use of capacitance sensors for fuel mass gauging has been in consideration since the early days of manned space flight. However, certain difficulties arise when considering tanks in microgravity environments. Surface tension effects lead to fluid wetting of the interior surface of the tank, leaving large interior voids, while thrust/settling effects can lead to dispersed two-phase mixtures. With the exception of Electrical Capacitance Volume Tomography (ECVT), few sensing technologies are well suited for measuring annular, stratified, and dispersed fluid configurations as well as handling the additional complications of mechanical installation inside a spherical tank. To optimize the design of future ECVT based spherical tank mass gauging sensors, different electrode plate layouts are considered, and their effect on the performance of the sensor as a fuel mass gauge is analyzed through the use of imaging and averaging techniques.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "19 pages, 26 figures, 5 tables"
    },
    {
        "paper id": "2401.04875",
        "abstract url": "https://arxiv.org/abs/2401.04875",
        "title": "Formal Modelling of Safety Architecture for Responsibility-Aware Autonomous Vehicle via Event-B Refinement",
        "rating": -1,
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "Ensuring the safety of autonomous vehicles (AVs) is the key requisite for their acceptance in society. This complexity is the core challenge in formally proving their safety conditions with AI-based black-box controllers and surrounding objects under various traffic scenarios. This paper describes our strategy and experience in modelling, deriving, and proving the safety conditions of AVs with the Event-B refinement mechanism to reduce complexity. Our case study targets the state-of-the-art model of goal-aware responsibility-sensitive safety to argue over interactions with surrounding vehicles. We also employ the Simplex architecture to involve advanced black-box AI controllers. Our experience has demonstrated that the refinement mechanism can be effectively used to gradually develop the complex system over scenario variations.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "18 pages, 10 figures, author version of the manuscript of the same name published in the proceedings of the 25th International Symposium on Formal Methods (FM 2023)"
    },
    {
        "paper id": "2401.04890",
        "abstract url": "https://arxiv.org/abs/2401.04890",
        "title": "Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal Dependencies",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This work introduces a novel principle for disentanglement we call mechanism sparsity regularization, which applies when the latent factors of interest depend sparsely on observed auxiliary variables and/or past latent factors. We propose a representation learning method that induces disentanglement by simultaneously learning the latent factors and the sparse causal graphical model that explains them. We develop a nonparametric identifiability theory that formalizes this principle and shows that the latent factors can be recovered by regularizing the learned causal graph to be sparse. More precisely, we show identifiablity up to a novel equivalence relation we call \"consistency\", which allows some latent factors to remain entangled (hence the term partial disentanglement). To describe the structure of this entanglement, we introduce the notions of entanglement graphs and graph preserving functions. We further provide a graphical criterion which guarantees complete disentanglement, that is identifiability up to permutations and element-wise transformations. We demonstrate the scope of the mechanism sparsity principle as well as the assumptions it relies on with several worked out examples. For instance, the framework shows how one can leverage multi-node interventions with unknown targets on the latent factors to disentangle them. We further draw connections between our nonparametric results and the now popular exponential family assumption. Lastly, we propose an estimation procedure based on variational autoencoders and a sparsity constraint and demonstrate it on various synthetic datasets. This work is meant to be a significantly extended version of Lachapelle et al. (2022).",
        "subjects": [
            "stat.ML"
        ],
        "comment": "88 pages"
    },
    {
        "paper id": "2401.12981",
        "abstract url": "https://arxiv.org/abs/2401.12981",
        "title": "A General-purpose AI Avatar in Healthcare",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "health",
                "Healthcare",
                "diagnosing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in machine learning and natural language processing have led to the rapid development of artificial intelligence (AI) as a valuable tool in the healthcare industry. Using large language models (LLMs) as conversational agents or chatbots has the potential to assist doctors in diagnosing patients, detecting early symptoms of diseases, and providing health advice to patients. This paper focuses on the role of chatbots in healthcare and explores the use of avatars to make AI interactions more appealing to patients. A framework of a general-purpose AI avatar application is demonstrated by using a three-category prompt dictionary and prompt improvement mechanism. A two-phase approach is suggested to fine-tune a general-purpose AI language model and create different AI avatars to discuss medical issues with users. Prompt engineering enhances the chatbot's conversational abilities and personality traits, fostering a more human-like interaction with patients. Ultimately, the injection of personality into the chatbot could potentially increase patient engagement. Future directions for research include investigating ways to improve chatbots' understanding of context and ensuring the accuracy of their outputs through fine-tuning with specialized medical data sets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04368",
        "abstract url": "https://arxiv.org/abs/2401.04368",
        "title": "Enhancing Acute Kidney Injury Prediction through Integration of Drug Features in Intensive Care Units",
        "rating": -1.5,
        "keywords": [
            [
                "Health",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The relationship between acute kidney injury (AKI) prediction and nephrotoxic drugs, or drugs that adversely affect kidney function, is one that has yet to be explored in the critical care setting. One contributing factor to this gap in research is the limited investigation of drug modalities in the intensive care unit (ICU) context, due to the challenges of processing prescription data into the corresponding drug representations and a lack in the comprehensive understanding of these drug representations. This study addresses this gap by proposing a novel approach that leverages patient prescription data as a modality to improve existing models for AKI prediction. We base our research on Electronic Health Record (EHR) data, extracting the relevant patient prescription information and converting it into the selected drug representation for our research, the extended-connectivity fingerprint (ECFP). Furthermore, we adopt a unique multimodal approach, developing machine learning models and 1D Convolutional Neural Networks (CNN) applied to clinical drug representations, establishing a procedure which has not been used by any previous studies predicting AKI. The findings showcase a notable improvement in AKI prediction through the integration of drug embeddings and other patient cohort features. By using drug features represented as ECFP molecular fingerprints along with common cohort features such as demographics and lab test values, we achieved a considerable improvement in model performance for the AKI prediction task over the baseline model which does not include the drug representations as features, indicating that our distinct approach enhances existing baseline techniques and highlights the relevance of drug data in predicting AKI in the ICU setting",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 2 tables"
    },
    {
        "paper id": "2401.04369",
        "abstract url": "https://arxiv.org/abs/2401.04369",
        "title": "Air Quality Forecasting Using Machine Learning: A Global perspective with Relevance to Low-Resource Settings",
        "rating": -1.5,
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Air pollution stands as the fourth leading cause of death globally. While extensive research has been conducted in this domain, most approaches rely on large datasets when it comes to prediction. This limits their applicability in low-resource settings though more vulnerable. This study addresses this gap by proposing a novel machine learning approach for accurate air quality prediction using two months of air quality data. By leveraging the World Weather Repository, the meteorological, air pollutant, and Air Quality Index features from 197 capital cities were considered to predict air quality for the next day. The evaluation of several machine learning models demonstrates the effectiveness of the Random Forest algorithm in generating reliable predictions, particularly when applied to classification rather than regression, approach which enhances the model's generalizability by 42%, achieving a cross-validation score of 0.38 for regression and 0.89 for classification. To instill confidence in the predictions, interpretable machine learning was considered. Finally, a cost estimation comparing the implementation of this solution in high-resource and low-resource settings is presented including a tentative of technology licensing business model. This research highlights the potential for resource-limited countries to independently predict air quality while awaiting larger datasets to further refine their predictions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages. This is a conference proceeding Presented at: SIBR 2024 (Seoul) Conference on Interdisciplinary Business and Economics Research, 5th-6th January 2024, Seoul, South Korea"
    },
    {
        "paper id": "2401.04385",
        "abstract url": "https://arxiv.org/abs/2401.04385",
        "title": "Machine unlearning through fine-grained model parameters perturbation",
        "rating": -1.5,
        "keywords": [
            [
                "GAN"
            ],
            [
                "unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine unlearning techniques, which involve retracting data records and reducing influence of said data on trained models, help with the user privacy protection objective but incur significant computational costs. Weight perturbation-based unlearning is a general approach, but it typically involves globally modifying the parameters. We propose fine-grained Top-K and Random-k parameters perturbed inexact machine unlearning strategies that address the privacy needs while keeping the computational costs tractable. In order to demonstrate the efficacy of our strategies we also tackle the challenge of evaluating the effectiveness of machine unlearning by considering the model's generalization performance across both unlearning and remaining data. To better assess the unlearning effect and model generalization, we propose novel metrics, namely, the forgetting rate and memory retention rate. However, for inexact machine unlearning, current metrics are inadequate in quantifying the degree of forgetting that occurs after unlearning strategies are applied. To address this, we introduce SPD-GAN, which subtly perturbs the distribution of data targeted for unlearning. Then, we evaluate the degree of unlearning by measuring the performance difference of the models on the perturbed unlearning data before and after the unlearning process. By implementing these innovative techniques and metrics, we achieve computationally efficacious privacy protection in machine learning applications without significant sacrifice of model performance. Furthermore, this approach provides a novel method for evaluating the degree of unlearning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04491",
        "abstract url": "https://arxiv.org/abs/2401.04491",
        "title": "SpiNNaker2: A Large-Scale Neuromorphic System for Event-Based and Asynchronous Machine Learning",
        "rating": -1.5,
        "keywords": [
            [
                "bio-inspired"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The joint progress of artificial neural networks (ANNs) and domain specific hardware accelerators such as GPUs and TPUs took over many domains of machine learning research. This development is accompanied by a rapid growth of the required computational demands for larger models and more data. Concurrently, emerging properties of foundation models such as in-context learning drive new opportunities for machine learning applications. However, the computational cost of such applications is a limiting factor of the technology in data centers, and more importantly in mobile devices and edge systems. To mediate the energy footprint and non-trivial latency of contemporary systems, neuromorphic computing systems deeply integrate computational principles of neurobiological systems by leveraging low-power analog and digital technologies. SpiNNaker2 is a digital neuromorphic chip developed for scalable machine learning. The event-based and asynchronous design of SpiNNaker2 allows the composition of large-scale systems involving thousands of chips. This work features the operating principles of SpiNNaker2 systems, outlining the prototype of novel machine learning applications. These applications range from ANNs over bio-inspired spiking neural networks to generalized event-based neural networks. With the successful development and deployment of SpiNNaker2, we aim to facilitate the advancement of event-based and asynchronous algorithms for future generations of machine learning systems.",
        "subjects": [
            "cs.ET"
        ],
        "comment": "Submitted at the Workshop on Machine Learning with New Compute Paradigms at NeurIPS 2023 (MLNPCP 2023)"
    },
    {
        "paper id": "2401.04691",
        "abstract url": "https://arxiv.org/abs/2401.04691",
        "title": "AI-based Mapping of the Conservation Status of Orchid Assemblages at Global Scale",
        "rating": -1.5,
        "keywords": [
            [
                "biodiversity"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although increasing threats on biodiversity are now widely recognised, there are no accurate global maps showing whether and where species assemblages are at risk. We hereby assess and map at kilometre resolution the conservation status of the iconic orchid family, and discuss the insights conveyed at multiple scales. We introduce a new Deep Species Distribution Model trained on 1M occurrences of 14K orchid species to predict their assemblages at global scale and at kilometre resolution. We propose two main indicators of the conservation status of the assemblages: (i) the proportion of threatened species, and (ii) the status of the most threatened species in the assemblage. We show and analyze the variation of these indicators at World scale and in relation to currently protected areas in Sumatra island. Global and interactive maps available online show the indicators of conservation status of orchid assemblages, with sharp spatial variations at all scales. The highest level of threat is found at Madagascar and the neighbouring islands. In Sumatra, we found good correspondence of protected areas with our indicators, but supplementing current IUCN assessments with status predictions results in alarming levels of species threat across the island. Recent advances in deep learning enable reliable mapping of the conservation status of species assemblages on a global scale. As an umbrella taxon, orchid family provides a reference for identifying vulnerable ecosystems worldwide, and prioritising conservation actions both at international and local levels.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 4 figures. Website URL: https://mapviewer.plantnet.org/?config=apps/store/orchid-status.xml Data and code: https://figshare.com/s/15404886eb3b62363a5f"
    },
    {
        "paper id": "2401.04751",
        "abstract url": "https://arxiv.org/abs/2401.04751",
        "title": "Identifying Best Practice Melting Patterns in Induction Furnaces: A Data-Driven Approach Using Time Series KMeans Clustering and Multi-Criteria Decision Making",
        "rating": -1.5,
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Improving energy efficiency in industrial production processes is crucial for competitiveness, and compliance with climate policies. This paper introduces a data-driven approach to identify optimal melting patterns in induction furnaces. Through time-series K-means clustering the melting patterns could be classified into distinct clusters based on temperature profiles. Using the elbow method, 12 clusters were identified, representing the range of melting patterns. Performance parameters such as melting time, energy-specific performance, and carbon cost were established for each cluster, indicating furnace efficiency and environmental impact. Multiple criteria decision-making methods including Simple Additive Weighting, Multiplicative Exponential Weighting, Technique for Order of Preference by Similarity to Ideal Solution, modified TOPSIS, and VlseKriterijumska Optimizacija I Kompromisno Resenje were utilized to determine the best-practice cluster. The study successfully identified the cluster with the best performance. Implementing the best practice operation resulted in an 8.6 % reduction in electricity costs, highlighting the potential energy savings in the foundry.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04757",
        "abstract url": "https://arxiv.org/abs/2401.04757",
        "title": "How predictable is language model benchmark performance?",
        "rating": -1.5,
        "keywords": [
            [
                "forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate large language model performance across five orders of magnitude of compute scaling in eleven recent model architectures. We show that average benchmark performance, aggregating over many individual tasks and evaluations as in the commonly-used BIG-Bench dataset, is decently predictable as a function of training compute scale. Specifically, when extrapolating BIG-Bench Hard performance across one order of magnitude in compute, we observe average absolute errors of 6 percentage points (pp). By contrast, extrapolation for individual BIG-Bench tasks across an order of magnitude in compute yields higher average errors of 18pp. Nonetheless, individual task performance remains significantly more predictable than chance. Overall, our work suggests compute scaling provides a promising basis to forecast AI capabilities in diverse benchmarks, though predicting performance in specific tasks poses challenges.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04771",
        "abstract url": "https://arxiv.org/abs/2401.04771",
        "title": "Network Layout Algorithm with Covariate Smoothing",
        "rating": -1.5,
        "keywords": [
            [
                "disease"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Network science explores intricate connections among objects, employed in diverse domains like social interactions, fraud detection, and disease spread. Visualization of networks facilitates conceptualizing research questions and forming scientific hypotheses. Networks, as mathematical high-dimensional objects, require dimensionality reduction for (planar) visualization. Visualizing empirical networks present additional challenges. They often contain false positive (spurious) and false negative (missing) edges. Traditional visualization methods don't account for errors in observation, potentially biasing interpretations. Moreover, contemporary network data includes rich nodal attributes. However, traditional methods neglect these attributes when computing node locations. Our visualization approach aims to leverage nodal attribute richness to compensate for network data limitations. We employ a statistical model estimating the probability of edge connections between nodes based on their covariates. We enhance the Fruchterman-Reingold algorithm to incorporate estimated dyad connection probabilities, allowing practitioners to balance reliance on observed versus estimated edges. We explore optimal smoothing levels, offering a natural way to include relevant nodal information in layouts. Results demonstrate the effectiveness of our method in achieving robust network visualization, providing insights for improved analysis.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "23 pages, 6 figures"
    },
    {
        "paper id": "2401.04846",
        "abstract url": "https://arxiv.org/abs/2401.04846",
        "title": "The inherent goodness of well educated intelligence",
        "rating": -1.5,
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper will examine what makes a being intelligent, whether that be a biological being or an artificial silicon being on a computer. Special attention will be paid to the being having the ability to characterize and control a collective system of many identical conservative sub-systems conservatively interacting. The essence of intelligence will be found to be the golden rule -- \"the collective acts as one\" or \"knowing the global consequences of local actions\". The flow of the collective is a small set of twinkling textures, that are governed by a puppeteer who is pulling a small number of strings according to a geodesic motion of least action, determined by the symmetries. Controlling collective conservative systems is difficult and has historically been done by adding significant viscosity to the system to stabilize the desirable meta stable equilibriums of maximum performance, but it degrades or destroys them in the process. There is an alternative. Once the optimum twinkling textures of the meta stable equilibriums are identified, the collective system can be moved to the optimum twinkling textures, then quickly vibrated according to the textures so that the collective system remains at the meta stable equilibrium. Well educated intelligence knows the global consequences of its local actions so that it will not take short term actions that will lead to poor long term outcomes. In contrast, trained intelligence or trained stupidity will optimize its short term actions, leading to poor long term outcomes. Well educated intelligence is inherently good, but trained stupidity is inherently evil and should be feared. Particular attention is paid to the control and optimization of economic and social collectives. These new results are also applicable to physical collectives such as fields, fluids and plasmas.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "13 pages, 12 figures, 15 equations, to be submitted to Nature"
    },
    {
        "paper id": "2401.04857",
        "abstract url": "https://arxiv.org/abs/2401.04857",
        "title": "Transportation Marketplace Rate Forecast Using Signature Transform",
        "rating": -1.5,
        "keywords": [
            [
                "Forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Freight transportation marketplace rates are typically challenging to forecast accurately. In this work, we have developed a novel statistical technique based on signature transforms and have built a predictive and adaptive model to forecast these marketplace rates. Our technique is based on two key elements of the signature transform: one being its universal nonlinearity property, which linearizes the feature space and hence translates the forecasting problem into linear regression, and the other being the signature kernel, which allows for comparing computationally efficiently similarities between time series data. Combined, it allows for efficient feature generation and precise identification of seasonality and regime switching in the forecasting process. An algorithm based on our technique has been deployed by Amazon trucking operations, with far superior forecast accuracy and better interpretability versus commercially available industry models, even during the COVID-19 pandemic and the Ukraine conflict. Furthermore, our technique is able to capture the influence of business cycles and the heterogeneity of the marketplace, improving prediction accuracy by more than fivefold, with an estimated annualized saving of \\$50MM.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01652",
        "abstract url": "https://arxiv.org/abs/2402.01652",
        "title": "User-Centric AI Analytics for Chronic Health Conditions Management",
        "rating": -1.5,
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The use of AI analytics in health informatics has seen a rapid growth in recent years. In this talk, we look at AI analytics use in managing chronic health conditions such as diabetes, obesity, etc. We focus on the challenges in managing these conditions especially with drug-free approaches due to the variations in individual circumstances. These variations directed the research into user-centric approach leading to variety of research questions. In this short paper, we give examples from recent and current research work and conclude with what, in our opinion, to be the next steps and some remaining open research questions.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Keynote talk at IEEE Conference on Intelligent Methods, Systems, and Applications (IMSA), Cairo, Egypt, July 2023"
    },
    {
        "paper id": "2401.04364",
        "abstract url": "https://arxiv.org/abs/2401.04364",
        "title": "SoK: Facial Deepfake Detectors",
        "rating": -2,
        "keywords": [
            [
                "attack"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deepfakes have rapidly emerged as a profound and serious threat to society, primarily due to their ease of creation and dissemination. This situation has triggered an accelerated development of deepfake detection technologies. However, many existing detectors rely heavily on lab-generated datasets for validation, which may not effectively prepare them for novel, emerging, and real-world deepfake techniques. In this paper, we conduct an extensive and comprehensive review and analysis of the latest state-of-the-art deepfake detectors, evaluating them against several critical criteria. These criteria facilitate the categorization of these detectors into 4 high-level groups and 13 fine-grained sub-groups, all aligned with a unified standard conceptual framework. This classification and framework offer deep and practical insights into the factors that affect detector efficacy. We assess the generalizability of 16 leading detectors across various standard attack scenarios, including black-box, white-box, and gray-box settings. Our systematized analysis and experimentation lay the groundwork for a deeper understanding of deepfake detectors and their generalizability, paving the way for future research focused on creating detectors adept at countering various attack scenarios. Additionally, this work offers insights for developing more proactive defenses against deepfakes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 6 figures, 5 table, under peer-review"
    },
    {
        "paper id": "2401.04377",
        "abstract url": "https://arxiv.org/abs/2401.04377",
        "title": "Towards Real-World Aerial Vision Guidance with Categorical 6D Pose Tracker",
        "rating": -2,
        "keywords": [
            [
                "6-DoF",
                "6D"
            ],
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Tracking the object 6-DoF pose is crucial for various downstream robot tasks and real-world applications. In this paper, we investigate the real-world robot task of aerial vision guidance for aerial robotics manipulation, utilizing category-level 6-DoF pose tracking. Aerial conditions inevitably introduce special challenges, such as rapid viewpoint changes in pitch and roll and inter-frame differences. To support these challenges in task, we firstly introduce a robust category-level 6-DoF pose tracker (Robust6DoF). This tracker leverages shape and temporal prior knowledge to explore optimal inter-frame keypoint pairs, generated under a priori structural adaptive supervision in a coarse-to-fine manner. Notably, our Robust6DoF employs a Spatial-Temporal Augmentation module to deal with the problems of the inter-frame differences and intra-class shape variations through both temporal dynamic filtering and shape-similarity filtering. We further present a Pose-Aware Discrete Servo strategy (PAD-Servo), serving as a decoupling approach to implement the final aerial vision guidance task. It contains two servo action policies to better accommodate the structural properties of aerial robotics manipulation. Exhaustive experiments on four well-known public benchmarks demonstrate the superiority of our Robust6DoF. Real-world tests directly verify that our Robust6DoF along with PAD-Servo can be readily used in real-world aerial robotic applications.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04430",
        "abstract url": "https://arxiv.org/abs/2401.04430",
        "title": "Reconfigurable Intelligent Surface-Enabled Downlink NOMA",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Reconfigurable intelligent surfaces (RISs) bring great potential to the advancement of 6G and beyond wireless communication technologies. RISs introduce a great degree of flexibility, allowing some sort of virtual control over the wireless channel. Exploiting the flexibility introduced by RISs, we propose a novel RIS-enabled downlink (DL) non-orthogonal multiple access (NOMA) scheme where NOMA is enabled over-the-air rather than at the base station (BS) or the receiver (Rx). Here, the RIS is partitioned into distinctive groups where each part of the RIS serves a different user equipment (UE) to perform multiple accessing. The BS transmits an unmodulated signal to the RIS, and each partition modulates the impinging signal over-the-air by introducing a phase shift according to the incoming information bits to serve the corresponding UE. First, the end-to-end system model for the proposed system is presented. Furthermore, outage probability calculations, theoretical error probability analysis, and bit error rate (BER) derivations are discussed and reinforced with comprehensive computer simulation results.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "11 pages, 13 figures, transaction journal"
    },
    {
        "paper id": "2401.04478",
        "abstract url": "https://arxiv.org/abs/2401.04478",
        "title": "TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction",
        "rating": -2,
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "The success of drug discovery and development relies on the precise prediction of molecular activities and properties. While in silico molecular property prediction has shown remarkable potential, its use has been limited so far to assays for which large amounts of data are available. In this study, we use a fine-tuned large language model to integrate biological assays based on their textual information, coupled with Barlow Twins, a Siamese neural network using a novel self-supervised learning approach. This architecture uses both assay information and molecular fingerprints to extract the true molecular information. TwinBooster enables the prediction of properties of unseen bioassays and molecules by providing state-of-the-art zero-shot learning tasks. Remarkably, our artificial intelligence pipeline shows excellent performance on the FS-Mol benchmark. This breakthrough demonstrates the application of deep learning to critical property prediction tasks where data is typically scarce. By accelerating the early identification of active molecules in drug discovery and development, this method has the potential to help streamline the identification of novel therapeutics.",
        "subjects": [
            "q-bio.BM"
        ],
        "comment": "13(+9) pages(+appendix), 5 figures, 11 tables"
    },
    {
        "paper id": "2401.04489",
        "abstract url": "https://arxiv.org/abs/2401.04489",
        "title": "Optimal Survival Trees: A Dynamic Programming Approach",
        "rating": -2.0,
        "keywords": [
            [
                "depth"
            ],
            [
                "Survival"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Survival analysis studies and predicts the time of death, or other singular unrepeated events, based on historical data, while the true time of death for some instances is unknown. Survival trees enable the discovery of complex nonlinear relations in a compact human comprehensible model, by recursively splitting the population and predicting a distinct survival distribution in each leaf node. We use dynamic programming to provide the first survival tree method with optimality guarantees, enabling the assessment of the optimality gap of heuristics. We improve the scalability of our method through a special algorithm for computing trees up to depth two. The experiments show that our method's run time even outperforms some heuristics for realistic cases while obtaining similar out-of-sample performance with the state-of-the-art.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Published at AAAI-24"
    },
    {
        "paper id": "2401.04507",
        "abstract url": "https://arxiv.org/abs/2401.04507",
        "title": "TechGPT-2.0: A large language model project to solve the task of knowledge graph construction",
        "rating": -2,
        "keywords": [
            [
                "graph"
            ],
            [
                "biology"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models have exhibited robust performance across diverse natural language processing tasks. This report introduces TechGPT-2.0, a project designed to enhance the capabilities of large language models specifically in knowledge graph construction tasks, including named entity recognition (NER) and relationship triple extraction (RTE) tasks in NLP applications. Additionally, it serves as a LLM accessible for research within the Chinese open-source model community. We offer two 7B large language model weights and a QLoRA weight specialized for processing lengthy texts.Notably, TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all functionalities from TechGPT-1.0, it exhibits robust text processing capabilities, particularly in the domains of medicine and law. Furthermore, we introduce new capabilities to the model, enabling it to process texts in various domains such as geographical areas, transportation, organizations, literary works, biology, natural sciences, astronomical objects, and architecture. These enhancements also fortified the model's adeptness in handling hallucinations, unanswerable queries, and lengthy texts. This report provides a comprehensive and detailed introduction to the full fine-tuning process on Huawei's Ascend servers, encompassing experiences in Ascend server debugging, instruction fine-tuning data processing, and model training. Our code is available at https://github.com/neukg/TechGPT-2.0",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04513",
        "abstract url": "https://arxiv.org/abs/2401.04513",
        "title": "A New Spatial Block-Correlation Model for Fluid Antenna Systems",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Powered by position-flexible antennas, the emerging fluid antenna system (FAS) technology postulates as a key enabler for massive connectivity in 6G networks. The free movement of antenna elements enables the opportunistic minimization of interference, allowing several users to share the same radio channel without the need of precoding. However, the true potential of FAS is still unknown due to the extremely high spatial correlation of the wireless channel between very close-by antenna positions. To unveil the multiplexing capabilities of FAS, proper (simple yet accurate) modeling of the spatial correlation is prominently needed. Realistic classical models such as Jakes' are prohibitively complex, rendering intractable analyses, while state-of-the-art approximations often are too simplistic and poorly accurate. Aiming to fill this gap, we here propose a general framework to approximate spatial correlation by block-diagonal matrices, motivated by the well-known block fading assumption and by statistical results on large correlation matrices. The proposed block-correlation model makes the performance analysis possible, and tightly approximates the results obtained with realistic models (Jakes' and Clarke's). Our framework is leveraged to analyze fluid antenna multiple access (FAMA) systems, evaluating their performance for both one- and two-dimensional fluid antennas.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04543",
        "abstract url": "https://arxiv.org/abs/2401.04543",
        "title": "Healthcare Voice AI Assistants: Factors Influencing Trust and Intention to Use",
        "rating": -2,
        "keywords": [
            [
                "Healthcare"
            ]
        ],
        "abstract": "AI assistants such as Alexa, Google Assistant, and Siri, are making their way into the healthcare sector, offering a convenient way for users to access different healthcare services. Trust is a vital factor in the uptake of healthcare services, but the factors affecting trust in voice assistants used for healthcare are under-explored and this specialist domain introduces additional requirements. This study explores the effects of different functional, personal, and risk factors on trust in and adoption of healthcare voice AI assistants (HVAs), generating a partial least squares structural model from a survey of 300 voice assistant users. Our results indicate that trust in HVAs can be significantly explained by functional factors (usefulness, content credibility, quality of service relative to a healthcare professional), together with security, and privacy risks and personal stance in technology. We also discuss differences in terms of trust between HVAs and general-purpose voice assistants as well as implications that are unique to HVAs.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "37 pages. This is a preprint of the paper accepted for the 27th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW'24)"
    },
    {
        "paper id": "2401.04556",
        "abstract url": "https://arxiv.org/abs/2401.04556",
        "title": "On a Discrete-Time Networked SIV Epidemic Model with Polar Opinion Dynamics",
        "rating": -2,
        "keywords": [
            [
                "health",
                "disease"
            ]
        ],
        "abstract": "This paper studies novel epidemic spreading problems influenced by opinion evolution in social networks, where the opinions reflect the public health concerns. A coupled bilayer network is proposed, where the epidemics spread over several communities through a physical network layer while the opinions evolve over the same communities through a social network layer. The epidemic spreading process is described by a susceptible-infected-vigilant (SIV) model, which introduces opinion-dependent epidemic vigilance state compared with the classical epidemic models. The opinion process is modeled by a polar opinion dynamics model, which includes infection prevalence and human stubbornness into the opinion evolution. By introducing an opinion-dependent reproduction number, we analyze the stability of disease-free and endemic equilibria and derive sufficient conditions for their global asymptotic stability. We also discuss the mutual effects between epidemic eradication and opinion consensus, and the possibility of suppressing epidemic by intervening in the opinions or implementing public health strategies. Simulations are conducted to verify the theoretical results and demonstrate the feasibility of epidemic suppression.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "12 pages, 8 figures"
    },
    {
        "paper id": "2401.04595",
        "abstract url": "https://arxiv.org/abs/2401.04595",
        "title": "A Multi-Modal Approach Based on Large Vision Model for Close-Range Underwater Target Localization",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Underwater target localization uses real-time sensory measurements to estimate the position of underwater objects of interest, providing critical feedback information for underwater robots. While acoustic sensing is the most acknowledged method in underwater robots and possibly the only effective approach for long-range underwater target localization, such a sensing modality generally suffers from low resolution, high cost and high energy consumption, thus leading to a mediocre performance when applied to close-range underwater target localization. On the other hand, optical sensing has attracted increasing attention in the underwater robotics community for its advantages of high resolution and low cost, holding a great potential particularly in close-range underwater target localization. However, most existing studies in underwater optical sensing are restricted to specific types of targets due to the limited training data available. In addition, these studies typically focus on the design of estimation algorithms and ignore the influence of illumination conditions on the sensing performance, thus hindering wider applications in the real world. To address the aforementioned issues, this paper proposes a novel target localization method that assimilates both optical and acoustic sensory measurements to estimate the 3D positions of close-range underwater targets. A test platform with controllable illumination conditions is designed and developed to experimentally investigate the proposed multi-modal sensing approach. A large vision model is applied to process the optical imaging measurements, eliminating the requirement for training data acquisition, thus significantly expanding the scope of potential applications. Extensive experiments are conducted, the results of which validate the effectiveness of the proposed underwater target localization method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04601",
        "abstract url": "https://arxiv.org/abs/2401.04601",
        "title": "Imagining Computing Education Assessment after Generative AI",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "In the contemporary landscape of computing education, the ubiquity of Generative Artificial Intelligence has significantly disrupted traditional assessment methods, rendering them obsolete and prompting educators to seek innovative alternatives. This research paper explores the challenges posed by Generative AI in the assessment domain and the persistent attempts to circumvent its impact. Despite various efforts to devise workarounds, the academic community is yet to find a comprehensive solution. Amidst this struggle, ungrading emerges as a potential yet under-appreciated solution to the assessment dilemma. Ungrading, a pedagogical approach that involves moving away from traditional grading systems, has faced resistance due to its perceived complexity and the reluctance of educators to depart from conventional assessment practices. However, as the inadequacies of current assessment methods become increasingly evident in the face of Generative AI, the time is ripe to reconsider and embrace ungrading.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04626",
        "abstract url": "https://arxiv.org/abs/2401.04626",
        "title": "A Novel OMNeT++-based Simulation Tool for Vehicular Cloud Computing in ETSI MEC-compliant 5G Environments",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Vehicular cloud computing is gaining popularity thanks to the rapid advancements in next generation wireless communication networks. Similarly, Edge Computing, along with its standard proposals such as European Telecommunications Standards Institute (ETSI) Multi-access Edge Computing (MEC), will play a vital role in these scenarios, by enabling the execution of cloud-based services at the edge of the network. Together, these solutions have the potential to create real micro-datacenters at the network edge, favoring several benefits like minimal latency, real-time data processing, and data locality. However, the research community has not yet the opportunity to use integrated simulation frameworks for the easy testing of applications that exploit both the vehicular cloud paradigm and MEC-compliant 5G deployment environments. In this paper, we present our simulation tool as a platform for researchers and engineers to design, test, and enhance applications utilizing the concepts of vehicular and edge cloud. Our platform significantly extends OMNet++ and Simu5G, and implements our ETSI MEC-compliant architecture that leverages resources provided by far-edge nodes. In addition, the paper analyzes and reports performance results for our simulation platform, as well as provides a use case where our simulator is used to support the design, test, and validation of an algorithm to distribute MEC application components on vehicular cloud resources.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04632",
        "abstract url": "https://arxiv.org/abs/2401.04632",
        "title": "Hypercomplex neural network in time series forecasting of stock data",
        "rating": -2,
        "keywords": [
            [
                "forecasting"
            ]
        ],
        "abstract": "The goal of this paper is to test three classes of neural network (NN) architectures based on four-dimensional (4D) hypercomplex algebras for time series prediction. We evaluate different architectures, varying the input layers to include convolutional, Long Short-Term Memory (LSTM), or dense hypercomplex layers for 4D algebras. Four related Stock Market time series are used as input data, with the prediction focused on one of them. Hyperparameter optimization for each architecture class was conducted to compare the best-performing neural networks within each class. The results indicate that, in most cases, architectures with hypercomplex dense layers achieve similar Mean Absolute Error (MAE) accuracy compared to other architectures, but with significantly fewer trainable parameters. Consequently, hypercomplex neural networks demonstrate the ability to learn and process time series data faster than the other tested architectures. Additionally, it was found that the ordering of the input time series have a notable impact on effectiveness.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2401.04636",
        "abstract url": "https://arxiv.org/abs/2401.04636",
        "title": "On the Target Detection Performance of a Molecular Communication Network with Multiple Mobile Nanomachines",
        "rating": -2,
        "keywords": [
            [
                "biomarkers",
                "health",
                "cancer"
            ]
        ],
        "abstract": "A network of nanomachines (NMs) can be used to build a target detection system for a variety of promising applications. They have the potential to detect toxic chemicals, infectious bacteria, and biomarkers of dangerous diseases such as cancer within the human body. Many diseases and health disorders can be detected early and efficiently treated in the future by utilizing these systems. To fully grasp the potential of these systems, mathematical analysis is required. This paper describes an analytical framework for modeling and analyzing the performance of target detection systems composed of multiple mobile nanomachines of varying sizes with passive/absorbing boundaries. We consider both direct contact detection, in which NMs must physically contact the target to detect it, and indirect sensing, in which NMs must detect the marker molecules emitted by the target. The detection performance of such systems is calculated for degradable and non-degradable targets, as well as mobile and stationary targets. The derived expressions provide various insights, such as the effect of NM density and target degradation on detection probability.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04650",
        "abstract url": "https://arxiv.org/abs/2401.04650",
        "title": "Hold 'em and Fold 'em: Towards Human-scale, Feedback-Controlled Soft Origami Robots",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "An underdeveloped capability in soft robotics is proprioceptive feedback control, where soft actuators can be sensed and controlled using only sensors on the robot's body. Additionally, soft actuators are often unable to support human-scale loads due to the extremely compliant materials in use. Developing both feedback control and the ability to actuate under large loads (e.g. 500 N) are key capacities required to move soft robotics into everyday applications. In this work, we independently demonstrate these key factors towards controlling and actuating human-scale loads: proprioceptive (embodied) feedback control of a soft, pneumatically-actuated origami robot; and actuation of these origami origami robots under a person's weight in an open-loop configuration. In both demonstrations, the actuators are controlled by internal fluidic pressure. Capacitive sensors patterned onto the robot provide position estimation and serve as input to a feedback controller. We demonstrate position control of a single actuator during stepped setpoints and sinusoidal trajectory following, with root mean square error (RMSE) below 4 mm. We also showcase the actuator's potential towards human-scale robotics as an \"origami balance board\" by joining three actuators into an open-loop controlled system with a platform that varies its height, roll, and pitch. This work contributes to the field of soft robotics by demonstrating closed-loop feedback position control without visual tracking as an input and lightweight, soft actuators that can support a person's weight. The project repository, including videos, CAD files, and ROS code, is available at https://parses-lab.github.io/kresling_control.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04675",
        "abstract url": "https://arxiv.org/abs/2401.04675",
        "title": "On Duplication-Free Codes for Disjoint or Equal-Length Errors",
        "rating": -2,
        "keywords": [
            [
                "DNA"
            ]
        ],
        "abstract": "Motivated by applications in DNA storage, we study a setting in which strings are affected by tandem-duplication errors. In particular, we look at two settings: disjoint tandem-duplication errors, and equal-length tandem-duplication errors. We construct codes, with positive asymptotic rate, for the two settings, as well as for their combination. Our constructions are duplication-free codes, comprising codewords that do not contain tandem duplications of specific lengths. Additionally, our codes generalize previous constructions, containing them as special cases.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04718",
        "abstract url": "https://arxiv.org/abs/2401.04718",
        "title": "Jump Cut Smoothing for Talking Heads",
        "rating": -2,
        "keywords": [
            [
                "synthesize"
            ],
            [
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A jump cut offers an abrupt, sometimes unwanted change in the viewing experience. We present a novel framework for smoothing these jump cuts, in the context of talking head videos. We leverage the appearance of the subject from the other source frames in the video, fusing it with a mid-level representation driven by DensePose keypoints and face landmarks. To achieve motion, we interpolate the keypoints and landmarks between the end frames around the cut. We then use an image translation network from the keypoints and source frames, to synthesize pixels. Because keypoints can contain errors, we propose a cross-modal attention scheme to select and pick the most appropriate source amongst multiple options for each key point. By leveraging this mid-level representation, our method can achieve stronger results than a strong video interpolation baseline. We demonstrate our method on various jump cuts in the talking head videos, such as cutting filler words, pauses, and even random cuts. Our experiments show that we can achieve seamless transitions, even in the challenging cases where the talking head rotates or moves drastically in the jump cut.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Correct typos in the caption of Figure 1; Change the project website address. Project page: https://jeanne-wang.github.io/jumpcutsmoothing/"
    },
    {
        "paper id": "2401.04722",
        "abstract url": "https://arxiv.org/abs/2401.04722",
        "title": "U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "Biomedical",
                "CT",
                "organ"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Convolutional Neural Networks (CNNs) and Transformers have been the most popular architectures for biomedical image segmentation, but both of them have limited ability to handle long-range dependencies because of inherent locality or computational complexity. To address this challenge, we introduce U-Mamba, a general-purpose network for biomedical image segmentation. Inspired by the State Space Sequence Models (SSMs), a new family of deep sequence models known for their strong capability in handling long sequences, we design a hybrid CNN-SSM block that integrates the local feature extraction power of convolutional layers with the abilities of SSMs for capturing the long-range dependency. Moreover, U-Mamba enjoys a self-configuring mechanism, allowing it to automatically adapt to various datasets without manual intervention. We conduct extensive experiments on four diverse tasks, including the 3D abdominal organ segmentation in CT and MR images, instrument segmentation in endoscopy images, and cell segmentation in microscopy images. The results reveal that U-Mamba outperforms state-of-the-art CNN-based and Transformer-based segmentation networks across all tasks. This opens new avenues for efficient long-range dependency modeling in biomedical image analysis. The code, models, and data are publicly available at https://wanglab.ai/u-mamba.html.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04730",
        "abstract url": "https://arxiv.org/abs/2401.04730",
        "title": "A Simple Baseline for Spoken Language to Sign Language Translation with 3D Avatars",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The objective of this paper is to develop a functional system for translating spoken languages into sign languages, referred to as Spoken2Sign translation. The Spoken2Sign task is orthogonal and complementary to traditional sign language to spoken language (Sign2Spoken) translation. To enable Spoken2Sign translation, we present a simple baseline consisting of three steps: 1) creating a gloss-video dictionary using existing Sign2Spoken benchmarks; 2) estimating a 3D sign for each sign video in the dictionary; 3) training a Spoken2Sign model, which is composed of a Text2Gloss translator, a sign connector, and a rendering module, with the aid of the yielded gloss-3D sign dictionary. The translation results are then displayed through a sign avatar. As far as we know, we are the first to present the Spoken2Sign task in an output format of 3D signs. In addition to its capability of Spoken2Sign translation, we also demonstrate that two by-products of our approach-3D keypoint augmentation and multi-view understanding-can assist in keypoint-based sign language understanding. Code and models will be available at https://github.com/FangyunWei/SLRT",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04748",
        "abstract url": "https://arxiv.org/abs/2401.04748",
        "title": "Convolutional Neural Network Ensemble Learning for Hyperspectral Imaging-based Blackberry Fruit Ripeness Detection in Uncontrolled Farm Environment",
        "rating": -2,
        "keywords": [
            [
                "infrared"
            ],
            [
                "Hyperspectral Imaging"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fruit ripeness estimation models have for decades depended on spectral index features or colour-based features, such as mean, standard deviation, skewness, colour moments, and/or histograms for learning traits of fruit ripeness. Recently, few studies have explored the use of deep learning techniques to extract features from images of fruits with visible ripeness cues. However, the blackberry (Rubus fruticosus) fruit does not show obvious and reliable visible traits of ripeness when mature and therefore poses great difficulty to fruit pickers. The mature blackberry, to the human eye, is black before, during, and post-ripening. To address this engineering application challenge, this paper proposes a novel multi-input convolutional neural network (CNN) ensemble classifier for detecting subtle traits of ripeness in blackberry fruits. The multi-input CNN was created from a pre-trained visual geometry group 16-layer deep convolutional network (VGG16) model trained on the ImageNet dataset. The fully connected layers were optimized for learning traits of ripeness of mature blackberry fruits. The resulting model served as the base for building homogeneous ensemble learners that were ensemble using the stack generalization ensemble (SGE) framework. The input to the network is images acquired with a stereo sensor using visible and near-infrared (VIS-NIR) spectral filters at wavelengths of 700 nm and 770 nm. Through experiments, the proposed model achieved 95.1% accuracy on unseen sets and 90.2% accuracy with in-field conditions. Further experiments reveal that machine sensory is highly and positively correlated to human sensory over blackberry fruit skin texture.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "25 pages, 10 figures, 6 tables; submited to EAAI"
    },
    {
        "paper id": "2401.04792",
        "abstract url": "https://arxiv.org/abs/2401.04792",
        "title": "REACT: Autonomous Intrusion Response System for Intelligent Vehicles",
        "rating": -2,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Autonomous and connected vehicles are rapidly evolving, integrating numerous technologies and software. This progress, however, has made them appealing targets for cybersecurity attacks. As the risk of cyber threats escalates with this advancement, the focus is shifting from solely preventing these attacks to also mitigating their impact. Current solutions rely on vehicle security operation centers, where attack information is analyzed before deciding on a response strategy. However, this process can be time-consuming and faces scalability challenges, along with other issues stemming from vehicle connectivity. This paper proposes a dynamic intrusion response system integrated within the vehicle. This system enables the vehicle to respond to a variety of incidents almost instantly, thereby reducing the need for interaction with the vehicle security operation center. The system offers a comprehensive list of potential responses, a methodology for response evaluation, and various response selection methods. The proposed solution was implemented on an embedded platform. Two distinct cyberattack use cases served as the basis for evaluating the system. The evaluation highlights the system's adaptability, its ability to respond swiftly, its minimal memory footprint, and its capacity for dynamic system parameter adjustments. The proposed solution underscores the necessity and feasibility of incorporating dynamic response mechanisms in smart vehicles. This is a crucial factor in ensuring the safety and resilience of future smart mobility.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2401.04795",
        "abstract url": "https://arxiv.org/abs/2401.04795",
        "title": "First 100 days of pandemic; an interplay of pharmaceutical, behavioral and digital interventions -- A study using agent based modeling",
        "rating": -2,
        "keywords": [
            [
                "health",
                "disease"
            ]
        ],
        "abstract": "Pandemics, notably the recent COVID-19 outbreak, have impacted both public health and the global economy. A profound understanding of disease progression and efficient response strategies is thus needed to prepare for potential future outbreaks. In this paper, we emphasize the potential of Agent-Based Models (ABM) in capturing complex infection dynamics and understanding the impact of interventions. We simulate realistic pharmaceutical, behavioral, and digital interventions that mirror challenges in real-world policy adoption and suggest a holistic combination of these interventions for pandemic response. Using these simulations, we study the trends of emergent behavior on a large-scale population based on real-world socio-demographic and geo-census data from Kings County in Washington. Our analysis reveals the pivotal role of the initial 100 days in dictating a pandemic's course, emphasizing the importance of quick decision-making and efficient policy development. Further, we highlight that investing in behavioral and digital interventions can reduce the burden on pharmaceutical interventions by reducing the total number of infections and hospitalizations, and by delaying the pandemic's peak. We also infer that allocating the same amount of dollars towards extensive testing with contact tracing and self-quarantine offers greater cost efficiency compared to spending the entire budget on vaccinations.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "12 pages, 12 figures, In Proc. of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024), Auckland, New Zealand, 2024"
    },
    {
        "paper id": "2401.04830",
        "abstract url": "https://arxiv.org/abs/2401.04830",
        "title": "Clinical Applications of Plantar Pressure Measurement",
        "rating": -2,
        "keywords": [
            [
                "health",
                "disease",
                "Clinical"
            ]
        ],
        "abstract": "Plantar pressure measurements can provide valuable insight into various health characteristics in patients. In this study, we describe different plantar pressure devices available on the market and their clinical relevance. Current devices are either platform-based or wearable and consist of a variety of sensor technologies: resistive, capacitive, piezoelectric, and optical. The measurements collected from any of these sensors can be utilized for a range of clinical applications including patients with diabetes, trauma, deformity and cerebral palsy, stroke, cervical myelopathy, ankle instability, sports injuries, and Parkinsons disease. However, the proper technology should be selected based on the clinical need and the type of tests being performed on the device. In this review we provide the reader with a simple overview of the existing technologies their advantages and disadvantages and provide application examples for each. Moreover, we suggest new areas in orthopaedic that plantar pressure mapping technology can be utilized for increased quality of care.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04831",
        "abstract url": "https://arxiv.org/abs/2401.04831",
        "title": "Safe Low-Altitude Navigation in Steep Terrain with Fixed-Wing Aerial Vehicles",
        "rating": -2,
        "keywords": [
            [
                "vehicle",
                "flight"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Fixed-wing aerial vehicles provide an efficient way to navigate long distances or cover large areas for environmental monitoring applications. By design, they also require large open spaces due to limited maneuverability. However, strict regulatory and safety altitude limits constrain the available space. Especially in complex, confined, or steep terrain, ensuring the vehicle does not enter an inevitable collision state(ICS) can be challenging. In this work, we propose a strategy to find safe paths that do not enter an ICS while navigating within tight altitude constraints. The method uses periodic paths to efficiently classify ICSs. A sampling-based planner creates collision-free and kinematically feasible paths that begin and end in safe periodic (circular) paths. We show that, in realistic terrain, using circular periodic paths can simplify the goal selection process by making it yaw agnostic and constraining yaw. We demonstrate our approach by dynamically planning safe paths in real-time while navigating steep terrain on a flight test in complex alpine terrain.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)"
    },
    {
        "paper id": "2401.04847",
        "abstract url": "https://arxiv.org/abs/2401.04847",
        "title": "On the Correctness of the Generalized Isotonic Recursive Partitioning Algorithm",
        "rating": -2,
        "keywords": [
            [
                "depth"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "This paper presents an in-depth analysis of the generalized isotonic recursive partitioning (GIRP) algorithm for fitting isotonic models under separable convex losses, proposed by Luss and Rosset [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] for differentiable losses and extended by Painsky and Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] for nondifferentiable losses. The GIRP algorithm poseses an attractive feature that in each step of the algorithm, the intermediate solution satisfies the isotonicity constraint. The paper begins with an example showing that the GIRP algorithm as described in the literature may fail to produce an isotonic model, suggesting that the existence and uniqueness of the solution to the isotonic regression problem must be carefully addressed. It proceeds with showing that, among possibly many solutions, there indeed exists a solution that can be found by recursive binary partitioning of the set of observed data. A small modification of the GIRP algorithm suffices to obtain a correct solution and preserve the desired property that all the intermediate solutions are isotonic. This proposed modification includes a proper choice of intermediate solutions and a simplification of the partitioning step from ternary to binary.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "19 pages, 1 figure"
    },
    {
        "paper id": "2401.04855",
        "abstract url": "https://arxiv.org/abs/2401.04855",
        "title": "LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control",
        "rating": -2,
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "GNN",
                "graph"
            ]
        ],
        "abstract": "Coverage control is the problem of navigating a robot swarm to collaboratively monitor features or a phenomenon of interest not known a priori. The problem is challenging in decentralized settings with robots that have limited communication and sensing capabilities. We propose a learnable Perception-Action-Communication (LPAC) architecture for the problem, wherein a convolution neural network (CNN) processes localized perception; a graph neural network (GNN) facilitates robot communications; finally, a shallow multi-layer perceptron (MLP) computes robot actions. The GNN enables collaboration in the robot swarm by computing what information to communicate with nearby robots and how to incorporate received information. Evaluations show that the LPAC models -- trained using imitation learning -- outperform standard decentralized and centralized coverage control algorithms. The learned policy generalizes to environments different from the training dataset, transfers to larger environments with more robots, and is robust to noisy position estimates. The results indicate the suitability of LPAC architectures for decentralized navigation in robot swarms to achieve collaborative behavior.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04906",
        "abstract url": "https://arxiv.org/abs/2401.04906",
        "title": "Deep Learning Based Resource Allocation for Full-duplex Device-to-Device Communication",
        "rating": -2,
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Device-to-device (D2D) technology is one of the key research areas in 5G/6G networks, and full-duplex (FD) D2D will further enhance its spectral efficiency (SE). In recent years, deep learning approaches have shown remarkable performance in D2D resource allocation tasks. However, most schemes only model the channel state information (CSI) as an independent feature, neglecting the spatial relationships among multiple channels and users within the scenario. In this paper, we first design an objective function for FD D2D communication resource allocation, which aims to maximize the SE of D2D users while ensuring the minimal required SE of cellular users. Then, considering the complex CSI constituted by all the users in different channels as a three-dimensional vector, a centralized resource allocation model based on multi-dimensional spatial convolutional networks and attention mechanisms (SP-Conv-Att) is proposed. To alleviate the burden of base station, we develop two distributed models, Dist-Att and Dist-Att-Conv, to facilitate users to perform channel and power allocation locally, based on attention and multi-user convolutional networks respectively. Numerical results demonstrate that our models outperform traditional schemes and recent deep neural network models, significantly approximating the optimal solution computed by exhaustive algorithm with extremely low latency.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "7 pages, 5 figures, 5 tables"
    },
    {
        "paper id": "2401.04908",
        "abstract url": "https://arxiv.org/abs/2401.04908",
        "title": "On Achieving High-Fidelity Grant-free Non-Orthogonal Multiple Access",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Grant-free access (GFA) has been envisioned to play an active role in massive Machine Type Communication (mMTC) under 5G and Beyond mobile systems, which targets at achieving significant reduction of signaling overhead and access latency in the presence of sporadic traffic and small-size data. The paper focuses on a novel K-repetition GFA (K-GFA) scheme by incorporating Reed-Solomon (RS) code with the contention resolution diversity slotted ALOHA (CRDSA), aiming to achieve high-reliability and low-latency access in the presence of massive uncoordinated MTC devices (MTCDs). We firstly defines a MAC layer transmission structure at each MTCD for supporting message-level RS coding on a data message of $Q$ packets, where a RS code of $KQ$ packets is generated and sent in a super time frame (STF) that is composed of $Q$ time frames. The access point (AP) can recover the original $Q$ packets of the data message if at least $Q$ out of the $KQ$ packets of the RS code are successfully received. The AP buffers the received MTCD signals of each resource block (RB) within an STF and exercises the CRDSA based multi-user detection (MUD) by exploring signal-level inter-RB correlation via iterative interference cancellation (IIC). With the proposed CRDSA based K-GFA scheme, we provide the complexity analysis, and derive a closed-form analytical model on the access probability for each MTCD as well as its simplified approximate form. Extensive numerical experiments are conducted to validate its effectiveness on the proposed CRDSA based K-GFA scheme and gain deep understanding on its performance regarding various key operational parameters.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2401.04914",
        "abstract url": "https://arxiv.org/abs/2401.04914",
        "title": "DualVAE: Dual Disentangled Variational AutoEncoder for Recommendation",
        "rating": -2,
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Learning precise representations of users and items to fit observed interaction data is the fundamental task of collaborative filtering. Existing studies usually infer entangled representations to fit such interaction data, neglecting to model the diverse matching relationships between users and items behind their interactions, leading to limited performance and weak interpretability. To address this problem, we propose a Dual Disentangled Variational AutoEncoder (DualVAE) for collaborative recommendation, which combines disentangled representation learning with variational inference to facilitate the generation of implicit interaction data. Specifically, we first implement the disentangling concept by unifying an attention-aware dual disentanglement and disentangled variational autoencoder to infer the disentangled latent representations of users and items. Further, to encourage the correspondence and independence of disentangled representations of users and items, we design a neighborhood-enhanced representation constraint with a customized contrastive mechanism to improve the representation quality. Extensive experiments on three real-world benchmarks show that our proposed model significantly outperforms several recent state-of-the-art baselines. Further empirical experimental results also illustrate the interpretability of the disentangled representations learned by DualVAE.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted by SDM 2024"
    },
    {
        "paper id": "2401.04921",
        "abstract url": "https://arxiv.org/abs/2401.04921",
        "title": "Diffusion-based Pose Refinement and Muti-hypothesis Generation for 3D Human Pose Estimaiton",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous probabilistic models for 3D Human Pose Estimation (3DHPE) aimed to enhance pose accuracy by generating multiple hypotheses. However, most of the hypotheses generated deviate substantially from the true pose. Compared to deterministic models, the excessive uncertainty in probabilistic models leads to weaker performance in single-hypothesis prediction. To address these two challenges, we propose a diffusion-based refinement framework called DRPose, which refines the output of deterministic models by reverse diffusion and achieves more suitable multi-hypothesis prediction for the current pose benchmark by multi-step refinement with multiple noises. To this end, we propose a Scalable Graph Convolution Transformer (SGCT) and a Pose Refinement Module (PRM) for denoising and refining. Extensive experiments on Human3.6M and MPI-INF-3DHP datasets demonstrate that our method achieves state-of-the-art performance on both single and multi-hypothesis 3DHPE. Code is available at https://github.com/KHB1698/DRPose.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.05446",
        "abstract url": "https://arxiv.org/abs/2401.05446",
        "title": "Self-supervised Learning for Electroencephalogram: A Systematic Survey",
        "rating": -2,
        "keywords": [
            [
                "bioelectrical"
            ]
        ],
        "abstract": "Electroencephalogram (EEG) is a non-invasive technique to record bioelectrical signals. Integrating supervised deep learning techniques with EEG signals has recently facilitated automatic analysis across diverse EEG-based tasks. However, the label issues of EEG signals have constrained the development of EEG-based deep models. Obtaining EEG annotations is difficult that requires domain experts to guide collection and labeling, and the variability of EEG signals among different subjects causes significant label shifts. To solve the above challenges, self-supervised learning (SSL) has been proposed to extract representations from unlabeled samples through well-designed pretext tasks. This paper concentrates on integrating SSL frameworks with temporal EEG signals to achieve efficient representation and proposes a systematic review of the SSL for EEG signals. In this paper, 1) we introduce the concept and theory of self-supervised learning and typical SSL frameworks. 2) We provide a comprehensive review of SSL for EEG analysis, including taxonomy, methodology, and technique details of the existing EEG-based SSL frameworks, and discuss the difference between these methods. 3) We investigate the adaptation of the SSL approach to various downstream tasks, including the task description and related benchmark datasets. 4) Finally, we discuss the potential directions for future SSL-EEG research.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "35 pages, 12 figures"
    },
    {
        "paper id": "2401.10910",
        "abstract url": "https://arxiv.org/abs/2401.10910",
        "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
        "subjects": [
            "q-bio.NC"
        ],
        "comment": "9 pages, 4 figures"
    },
    {
        "paper id": "2401.04402",
        "abstract url": "https://arxiv.org/abs/2401.04402",
        "title": "IGNITE: Individualized GeNeration of Imputations in Time-series Electronic health records",
        "rating": -2.5,
        "keywords": [
            [
                "synthesizer"
            ],
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Electronic Health Records present a valuable modality for driving personalized medicine, where treatment is tailored to fit individual-level differences. For this purpose, many data-driven machine learning and statistical models rely on the wealth of longitudinal EHRs to study patients' physiological and treatment effects. However, longitudinal EHRs tend to be sparse and highly missing, where missingness could also be informative and reflect the underlying patient's health status. Therefore, the success of data-driven models for personalized medicine highly depends on how the EHR data is represented from physiological data, treatments, and the missing values in the data. To this end, we propose a novel deep-learning model that learns the underlying patient dynamics over time across multivariate data to generate personalized realistic values conditioning on an individual's demographic characteristics and treatments. Our proposed model, IGNITE (Individualized GeNeration of Imputations in Time-series Electronic health records), utilises a conditional dual-variational autoencoder augmented with dual-stage attention to generate missing values for an individual. In IGNITE, we further propose a novel individualized missingness mask (IMM), which helps our model generate values based on the individual's observed data and missingness patterns. We further extend the use of IGNITE from imputing missingness to a personalized data synthesizer, where it generates missing EHRs that were never observed prior or even generates new patients for various applications. We validate our model on three large publicly available datasets and show that IGNITE outperforms state-of-the-art approaches in missing data reconstruction and task prediction.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04429",
        "abstract url": "https://arxiv.org/abs/2401.04429",
        "title": "i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance",
        "rating": -2.5,
        "keywords": [
            [
                "trajectory",
                "Vehicle"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Ride-hailing platforms have been facing the challenge of balancing demand and supply. Existing vehicle reposition techniques often treat drivers as homogeneous agents and relocate them deterministically, assuming compliance with the reposition. In this paper, we consider a more realistic and driver-centric scenario where drivers have unique cruising preferences and can decide whether to take the recommendation or not on their own. We propose i-Rebalance, a personalized vehicle reposition technique with deep reinforcement learning (DRL). i-Rebalance estimates drivers' decisions on accepting reposition recommendations through an on-field user study involving 99 real drivers. To optimize supply-demand balance and enhance preference satisfaction simultaneously, i-Rebalance has a sequential reposition strategy with dual DRL agents: Grid Agent to determine the reposition order of idle vehicles, and Vehicle Agent to provide personalized recommendations to each vehicle in the pre-defined order. This sequential learning strategy facilitates more effective policy training within a smaller action space compared to traditional joint-action methods. Evaluation of real-world trajectory data shows that i-Rebalance improves driver acceptance rate by 38.07% and total driver income by 9.97%.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04570",
        "abstract url": "https://arxiv.org/abs/2401.04570",
        "title": "An Automatic Cascaded Model for Hemorrhagic Stroke Segmentation and Hemorrhagic Volume Estimation",
        "rating": -2.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "health",
                "CT"
            ],
            [
                "eess.IV"
            ],
            [
                "workshop"
            ]
        ],
        "abstract": "Hemorrhagic Stroke (HS) has a rapid onset and is a serious condition that poses a great health threat. Promptly and accurately delineating the bleeding region and estimating the volume of bleeding in Computer Tomography (CT) images can assist clinicians in treatment planning, leading to improved treatment outcomes for patients. In this paper, a cascaded 3D model is constructed based on UNet to perform a two-stage segmentation of the hemorrhage area in CT images from rough to fine, and the hemorrhage volume is automatically calculated from the segmented area. On a dataset with 341 cases of hemorrhagic stroke CT scans, the proposed model provides high-quality segmentation outcome with higher accuracy (DSC 85.66%) and better computation efficiency (6.2 second per sample) when compared to the traditional Tada formula with respect to hemorrhage volume estimation.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Accepted by SWITCH2023: Stroke Workshop on Imaging and Treatment CHallenges, a workshop at MICCAI 2023"
    },
    {
        "paper id": "2401.04728",
        "abstract url": "https://arxiv.org/abs/2401.04728",
        "title": "Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation",
        "rating": -2.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "synthesis"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Recent advances in generative diffusion models have enabled the previously unfeasible capability of generating 3D assets from a single input image or a text prompt. In this work, we aim to enhance the quality and functionality of these models for the task of creating controllable, photorealistic human avatars. We achieve this by integrating a 3D morphable model into the state-of-the-art multi-view-consistent diffusion approach. We demonstrate that accurate conditioning of a generative pipeline on the articulated 3D model enhances the baseline model performance on the task of novel view synthesis from a single image. More importantly, this integration facilitates a seamless and accurate incorporation of facial expression and body pose control into the generation process. To the best of our knowledge, our proposed framework is the first diffusion model to enable the creation of fully 3D-consistent, animatable, and photorealistic human avatars from a single image of an unseen subject; extensive quantitative and qualitative evaluations demonstrate the advantages of our approach over existing state-of-the-art avatar creation models on both novel view and novel expression synthesis tasks. The code for our project is publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "[CVPR 2024] Project page: https://xiyichen.github.io/morphablediffusion/"
    },
    {
        "paper id": "2401.04749",
        "abstract url": "https://arxiv.org/abs/2401.04749",
        "title": "LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection",
        "rating": -2.5,
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Log anomaly detection is a key component in the field of artificial intelligence for IT operations (AIOps). Considering log data of variant domains, retraining the whole network for unknown domains is inefficient in real industrial scenarios. However, previous deep models merely focused on extracting the semantics of log sequences in the same domain, leading to poor generalization on multi-domain logs. To alleviate this issue, we propose a unified Transformer-based framework for Log anomaly detection (LogFormer) to improve the generalization ability across different domains, where we establish a two-stage process including the pre-training and adapter-based tuning stage. Specifically, our model is first pre-trained on the source domain to obtain shared semantic knowledge of log data. Then, we transfer such knowledge to the target domain via shared parameters. Besides, the Log-Attention module is proposed to supplement the information ignored by the log-paring. The proposed method is evaluated on three public and one real-world datasets. Experimental results on multiple benchmarks demonstrate the effectiveness of our LogFormer with fewer trainable parameters and lower training costs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2201.00016"
    },
    {
        "paper id": "2401.04423",
        "abstract url": "https://arxiv.org/abs/2401.04423",
        "title": "Privacy-Preserving Sequential Recommendation with Collaborative Confusion",
        "rating": -3,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Sequential recommendation has attracted a lot of attention from both academia and industry, however the privacy risks associated to gathering and transferring users' personal interaction data are often underestimated or ignored. Existing privacy-preserving studies are mainly applied to traditional collaborative filtering or matrix factorization rather than sequential recommendation. Moreover, these studies are mostly based on differential privacy or federated learning, which often leads to significant performance degradation, or has high requirements for communication. In this work, we address privacy-preserving from a different perspective. Unlike existing research, we capture collaborative signals of neighbor interaction sequences and directly inject indistinguishable items into the target sequence before the recommendation process begins, thereby increasing the perplexity of the target sequence. Even if the target interaction sequence is obtained by attackers, it is difficult to discern which ones are the actual user interaction records. To achieve this goal, we propose a CoLlaborative-cOnfusion seqUential recommenDer, namely CLOUD, which incorporates a collaborative confusion mechanism to edit the raw interaction sequences before conducting recommendation. Specifically, CLOUD first calculates the similarity between the target interaction sequence and other neighbor sequences to find similar sequences. Then, CLOUD considers the shared representation of the target sequence and similar sequences to determine the operation to be performed: keep, delete, or insert. We design a copy mechanism to make items from similar sequences have a higher probability to be inserted into the target sequence. Finally, the modified sequence is used to train the recommender and predict the next item.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04437",
        "abstract url": "https://arxiv.org/abs/2401.04437",
        "title": "Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using Dimension Reduction Methods",
        "rating": -3,
        "keywords": [
            [
                "infrared"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "Hyperspectral Imaging"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent studies try to use hyperspectral imaging (HSI) to detect foreign matters in products because it enables to visualize the invisible wavelengths including ultraviolet and infrared. Considering the enormous image channels of the HSI, several dimension reduction methods-e.g., PCA or UMAP-can be considered to reduce but those cannot ease the fundamental limitations, as follows: (1) latency of HSI capturing. (2) less explanation ability of the important channels. In this paper, to circumvent the aforementioned methods, one of the ways to channel reduction, on anomaly detection proposed HSI. Different from feature extraction methods (i.e., PCA or UMAP), feature selection can sort the feature by impact and show better explainability so we might redesign the task-optimized and cost-effective spectroscopic camera. Via the extensive experiment results with synthesized MVTec AD dataset, we confirm that the feature selection method shows 6.90x faster at the inference phase compared with feature extraction-based approaches while preserving anomaly detection performance. Ultimately, we conclude the advantage of feature selection which is effective yet fast.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "4 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2401.04492",
        "abstract url": "https://arxiv.org/abs/2401.04492",
        "title": "Augmented Reality and Human-Robot Collaboration Framework for Percutaneous Nephrolithotomy",
        "rating": -3,
        "keywords": [
            [
                "Robot"
            ],
            [
                "clinical"
            ]
        ],
        "abstract": "During Percutaneous Nephrolithotomy (PCNL) operations, the surgeon is required to define the incision point on the patient's back, align the needle to a pre-planned path, and perform puncture operations afterward. The procedure is currently performed manually using ultrasound or fluoroscopy imaging for needle orientation, which, however, implies limited accuracy and low reproducibility. This work incorporates Augmented Reality (AR) visualization with an optical see-through head-mounted display (OST-HMD) and Human-Robot Collaboration (HRC) framework to empower the surgeon's task completion performance. In detail, Eye-to-Hand calibration, system registration, and hologram model registration are performed to realize visual guidance. A Cartesian impedance controller is used to guide the operator during the needle puncture task execution. Experiments are conducted to verify the system performance compared with conventional manual puncture procedures and a 2D monitor-based visualisation interface. The results showed that the proposed framework achieves the lowest median and standard deviation error across all the experimental groups, respectively. Furthermore, the NASA-TLX user evaluation results indicate that the proposed framework requires the lowest workload score for task completion compared to other experimental setups. The proposed framework exhibits significant potential for clinical application in the PCNL task, as it enhances the surgeon's perception capability, facilitates collision-free needle insertion path planning, and minimises errors in task completion.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "11 pages,10 figure, accepted by IEEE Robotics and Automation Magazine"
    },
    {
        "paper id": "2401.04614",
        "abstract url": "https://arxiv.org/abs/2401.04614",
        "title": "Generic Knowledge Boosted Pre-training For Remote Sensing Images",
        "rating": -3,
        "keywords": [
            [
                "face"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning models are essential for scene classification, change detection, land cover segmentation, and other remote sensing image understanding tasks. Most backbones of existing remote sensing deep learning models are typically initialized by pre-trained weights obtained from ImageNet pre-training (IMP). However, domain gaps exist between remote sensing images and natural images (e.g., ImageNet), making deep learning models initialized by pre-trained weights of IMP perform poorly for remote sensing image understanding. Although some pre-training methods are studied in the remote sensing community, current remote sensing pre-training methods face the problem of vague generalization by only using remote sensing images. In this paper, we propose a novel remote sensing pre-training framework, Generic Knowledge Boosted Remote Sensing Pre-training (GeRSP), to learn robust representations from remote sensing and natural images for remote sensing understanding tasks. GeRSP contains two pre-training branches: (1) A self-supervised pre-training branch is adopted to learn domain-related representations from unlabeled remote sensing images. (2) A supervised pre-training branch is integrated into GeRSP for general knowledge learning from labeled natural images. Moreover, GeRSP combines two pre-training branches using a teacher-student architecture to simultaneously learn representations with general and special knowledge, which generates a powerful pre-trained model for deep learning model initialization. Finally, we evaluate GeRSP and other remote sensing pre-training methods on three downstream tasks, i.e., object detection, semantic segmentation, and scene classification. The extensive experimental results consistently demonstrate that GeRSP can effectively learn robust representations in a unified manner, improving the performance of remote sensing downstream tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 6 figures"
    },
    {
        "paper id": "2401.04655",
        "abstract url": "https://arxiv.org/abs/2401.04655",
        "title": "DepressionEmo: A novel dataset for multilabel classification of depression emotions",
        "rating": -3,
        "keywords": [
            [
                "GAN"
            ],
            [
                "SVM"
            ],
            [
                "health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Emotions are integral to human social interactions, with diverse responses elicited by various situational contexts. Particularly, the prevalence of negative emotional states has been correlated with negative outcomes for mental health, necessitating a comprehensive analysis of their occurrence and impact on individuals. In this paper, we introduce a novel dataset named DepressionEmo designed to detect 8 emotions associated with depression by 6037 examples of long Reddit user posts. This dataset was created through a majority vote over inputs by zero-shot classifications from pre-trained models and validating the quality by annotators and ChatGPT, exhibiting an acceptable level of interrater reliability between annotators. The correlation between emotions, their distribution over time, and linguistic analysis are conducted on DepressionEmo. Besides, we provide several text classification methods classified into two groups: machine learning methods such as SVM, XGBoost, and Light GBM; and deep learning methods such as BERT, GAN-BERT, and BART. The pretrained BART model, bart-base allows us to obtain the highest F1- Macro of 0.76, showing its outperformance compared to other methods evaluated in our analysis. Across all emotions, the highest F1-Macro value is achieved by suicide intent, indicating a certain value of our dataset in identifying emotions in individuals with depression symptoms through text analysis. The curated dataset is publicly available at: https://github.com/abuBakarSiddiqurRahman/DepressionEmo.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2401.04791",
        "abstract url": "https://arxiv.org/abs/2401.04791",
        "title": "SOS-Match: Segmentation for Open-Set Robust Correspondence Search and Robot Localization in Unstructured Environments",
        "rating": -3,
        "keywords": [
            [
                "Robot"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "We present SOS-Match, a novel framework for detecting and matching objects in unstructured environments. Our system consists of 1) a front-end mapping pipeline using a zero-shot segmentation model to extract object masks from images and track them across frames and 2) a frame alignment pipeline that uses the geometric consistency of object relationships to efficiently localize across a variety of conditions. We evaluate SOS-Match on the Batvik seasonal dataset which includes drone flights collected over a coastal plot of southern Finland during different seasons and lighting conditions. Results show that our approach is more robust to changes in lighting and appearance than classical image feature-based approaches or global descriptor methods, and it provides more viewpoint invariance than learning-based feature detection and description approaches. SOS-Match localizes within a reference map up to 46x faster than other feature-based approaches and has a map size less than 0.5% the size of the most compact other maps. SOS-Match is a promising new approach for landmark detection and correspondence search in unstructured environments that is robust to changes in lighting and appearance and is more computationally efficient than other approaches, suggesting that the geometric arrangement of segments is a valuable localization cue in unstructured environments. We release our datasets at https://acl.mit.edu/SOS-Match/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2401.04872",
        "abstract url": "https://arxiv.org/abs/2401.04872",
        "title": "Knowledge-aware Graph Transformer for Pedestrian Trajectory Prediction",
        "rating": -3,
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "Graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Predicting pedestrian motion trajectories is crucial for path planning and motion control of autonomous vehicles. Accurately forecasting crowd trajectories is challenging due to the uncertain nature of human motions in different environments. For training, recent deep learning-based prediction approaches mainly utilize information like trajectory history and interactions between pedestrians, among others. This can limit the prediction performance across various scenarios since the discrepancies between training datasets have not been properly incorporated. To overcome this limitation, this paper proposes a graph transformer structure to improve prediction performance, capturing the differences between the various sites and scenarios contained in the datasets. In particular, a self-attention mechanism and a domain adaption module have been designed to improve the generalization ability of the model. Moreover, an additional metric considering cross-dataset sequences is introduced for training and performance evaluation purposes. The proposed framework is validated and compared against existing methods using popular public datasets, i.e., ETH and UCY. Experimental results demonstrate the improved performance of our proposed scheme.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper was accepted to and presented at the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC), September 2023"
    },
    {
        "paper id": "2401.04916",
        "abstract url": "https://arxiv.org/abs/2401.04916",
        "title": "Digital Retina for IoV Towards 6G: Architecture, Opportunities, and Challenges",
        "rating": -3,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Vehicles are no longer isolated entities in traffic environments, thanks to the development of IoV powered by 5G networks and their evolution into 6G. However, it is not enough for vehicles in a highly dynamic and complex traffic environment to make reliable and efficient decisions. As a result, this paper proposes a cloud-edge-end computing system with multi-streams for IoV, referred to as Vehicular Digital Retina (VDR). Local computing and edge computing are effectively integrated in the VDR system through the aid of vehicle-to-everything (V2X) networks, resulting in a heterogeneous computing environment that improves vehicles' perception and decision-making abilities with collaborative strategies. Once the system framework is presented, various important functions in the VDR system are explained in detail, including V2X-aided collaborative perception, V2X-aided stream sharing for collaborative learning, and V2X-aided secured collaboration. All of them enable the development of efficient mechanisms of data sharing and information interaction with high security for collaborative intelligent driving. We also present a case study with simulation results to demonstrate the effectiveness of the proposed VDR system.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2401.05452",
        "abstract url": "https://arxiv.org/abs/2401.05452",
        "title": "Cuff-less Arterial Blood Pressure Waveform Synthesis from Single-site PPG using Transformer & Frequency-domain Learning",
        "rating": -3,
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "cardiac"
            ]
        ],
        "abstract": "We propose two novel purpose-built deep learning (DL) models for synthesis of the arterial blood pressure (ABP) waveform in a cuff-less manner, using a single-site photoplethysmography (PPG) signal. We utilize the public UCI dataset on cuff-less blood pressure (CLBP) estimation to train and evaluate our DL models. Firstly, we implement a transformer model that incorporates positional encoding, multi-head attention, layer normalization, and dropout techniques, and synthesizes the ABP waveform with a mean absolute error (MAE) of 14. Secondly, we implement a frequency-domain (FD) learning approach where we first obtain the discrete cosine transform (DCT) coefficients of the PPG and ABP signals corresponding to two cardiac cycles, and then learn a linear/non-linear (L/NL) regression between them. We learn that the FD L/NL regression model outperforms the transformer model by achieving an MAE of 11.87 and 8.01, for diastolic blood pressure (DBP) and systolic blood pressure (SBP), respectively. Our FD L/NL regression model also fulfills the AAMI criterion of utilizing data from more than 85 subjects, and achieves grade B by the BHS criterion.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "7 pages, 4 figures, 3 tables, submitted for review and potential publication"
    },
    {
        "paper id": "2401.04579",
        "abstract url": "https://arxiv.org/abs/2401.04579",
        "title": "A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data",
        "rating": -3.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "MRI"
            ],
            [
                "workshop"
            ]
        ],
        "abstract": "Large datasets often contain multiple distinct feature sets, or views, that offer complementary information that can be exploited by multi-view learning methods to improve results. We investigate anatomical multi-view data, where each brain anatomical structure is described with multiple feature sets. In particular, we focus on sets of white matter microstructure and connectivity features from diffusion MRI, as well as sets of gray matter area and thickness features from structural MRI. We investigate machine learning methodology that applies multi-view approaches to improve the prediction of non-imaging phenotypes, including demographics (age), motor (strength), and cognition (picture vocabulary). We present an explainable multi-view network (EMV-Net) that can use different anatomical views to improve prediction performance. In this network, each individual anatomical view is processed by a view-specific feature extractor and the extracted information from each view is fused using a learnable weight. This is followed by a wavelet transform-based module to obtain complementary information across views which is then applied to calibrate the view-specific information. Additionally, the calibrator produces an attention-based calibration score to indicate anatomical structures' importance for interpretation.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": "2023 The Medical Image Computing and Computer Assisted Intervention Society workshop"
    },
    {
        "paper id": "2401.04648",
        "abstract url": "https://arxiv.org/abs/2401.04648",
        "title": "A novel framework for generalization of deep hidden physics models",
        "rating": -3.5,
        "keywords": [
            [
                "industrial"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modelling of systems where the full system information is unknown is an oft encountered problem for various engineering and industrial applications, as it's either impossible to consider all the complex physics involved or simpler models are considered to keep within the limits of the available resources. Recent advances in greybox modelling like the deep hidden physics models address this space by combining data and physics. However, for most real-life applications, model generalizability is a key issue, as retraining a model for every small change in system inputs and parameters or modification in domain configuration can render the model economically unviable. In this work we present a novel enhancement to the idea of hidden physics models which can generalize for changes in system inputs, parameters and domains. We also show that this approach holds promise in system discovery as well and helps learn the hidden physics for the changed system inputs, parameters and domain configuration.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04707",
        "abstract url": "https://arxiv.org/abs/2401.04707",
        "title": "RNA-TransCrypt: Image Encryption Using Chaotic RNA Encoding, Novel Transformative Substitution, and Tailored Cryptographic Operations",
        "rating": -4,
        "keywords": [
            [
                "biocryptographic"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Given the security concerns of Internet of Things (IoT) networks and limited computational resources of IoT devices, this paper presents RNA-TransCrypt, a novel image encryption scheme that is not only highly secure but also efficient and lightweight. RNA-TransCrypt integrates the biocryptographic properties of RNA encoding with the non-linearity and unpredictability of chaos theory. This scheme introduces three novel contributions: 1) the two-base RNA encoding method, which transforms the image into RNA strands-like sequence, ensuring efficient scrambling; 2) the transformative substitution technique, which transforms the s-box values before replacing the pixel values, and is responsible for making the scheme lightweight; and 3) three mathematical cryptographic operations designed especially for image encryption that ensure the effective transformation of the s-box values, resulting in a new outcome even for the same input values. These modules are key-dependent, utilizing chaotic keys generated by the De Jong Fractal Map and the Van der Pol Oscillator. Extensive security analysis, including histogram analysis, correlation analysis, and the results of the statistical security parameters obtained from the Gray-Level Co-occurrence Matrix (GLCM) validate the efficacy of the proposed scheme in encrypting input images with close-to-ideal results of 7.997 entropy and 0.0006 correlation.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04874",
        "abstract url": "https://arxiv.org/abs/2401.04874",
        "title": "Feature Network Methods in Machine Learning and Applications",
        "rating": -4,
        "keywords": [
            [
                "depth"
            ],
            [
                "graph"
            ],
            [
                "biology"
            ]
        ],
        "abstract": "A machine learning (ML) feature network is a graph that connects ML features in learning tasks based on their similarity. This network representation allows us to view feature vectors as functions on the network. By leveraging function operations from Fourier analysis and from functional analysis, one can easily generate new and novel features, making use of the graph structure imposed on the feature vectors. Such network structures have previously been studied implicitly in image processing and computational biology. We thus describe feature networks as graph structures imposed on feature vectors, and provide applications in machine learning. One application involves graph-based generalizations of convolutional neural networks, involving structured deep learning with hierarchical representations of features that have varying depth or complexity. This extends also to learning algorithms that are able to generate useful new multilevel features. Additionally, we discuss the use of feature networks to engineer new features, which can enhance the expressiveness of the model. We give a specific example of a deep tree-structured feature network, where hierarchical connections are formed through feature clustering and feed-forward learning. This results in low learning complexity and computational efficiency. Unlike \"standard\" neural features which are limited to modulated (thresholded) linear combinations of adjacent ones, feature networks offer more general feedforward dependencies among features. For example, radial basis functions or graph structure-based dependencies between features can be utilized.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.06174",
        "abstract url": "https://arxiv.org/abs/2401.06174",
        "title": "Machine Learning Applications in Spine Biomechanics",
        "rating": -4,
        "keywords": [
            [
                "3D"
            ],
            [
                "Biomechanics"
            ],
            [
                "industrial"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Spine biomechanics is at a transformation with the advent and integration of machine learning and computer vision technologies. These novel techniques facilitate the estimation of 3D body shapes, anthropometrics, and kinematics from as simple as a single-camera image, making them more accessible and practical for a diverse range of applications. This study introduces a framework that merges these methodologies with traditional musculoskeletal modeling, enabling comprehensive analysis of spinal biomechanics during complex activities from a single camera. Additionally, we aim to evaluate their performance and limitations in spine biomechanics applications. The real-world applications explored in this study include assessment in workplace lifting, evaluation of whiplash injuries in car accidents, and biomechanical analysis in professional sports. Our results demonstrate potential and limitations of various algorithms in estimating body shape, kinematics, and conducting in-field biomechanical analyses. In industrial settings, the potential to utilize these new technologies for biomechanical risk assessments offers a pathway for preventive measures against back injuries. In sports activities, the proposed framework provides new opportunities for performance optimization, injury prevention, and rehabilitation. The application in forensic domain further underscores the wide-reaching implications of this technology. While certain limitations were identified, particularly in accuracy of predictions, complex interactions, and external load estimation, this study demonstrates their potential for advancement in spine biomechanics, heralding an optimistic future in both research and practical applications.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.18576",
        "abstract url": "https://arxiv.org/abs/2402.18576",
        "title": "Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network",
        "rating": -4,
        "keywords": [
            [
                "health",
                "face"
            ],
            [
                "Forecasting"
            ]
        ],
        "abstract": "Decision making and planning have long relied heavily on AI-driven forecasts. The government and the general public are working to minimize the risks while maximizing benefits in the face of potential future public health uncertainties. This study used an improved method of forecasting utilizing the Random Descending Velocity Inertia Weight (RDV IW) technique to improve the convergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial Neural Network (ANN). The IW technique, inspired by the motions of a golf ball, modified the particles' velocities as they approached the solution point to a parabolically descending structure. Simulation results revealed that the proposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump exhibits a 6.36% improvement in position error and 11.75% improvement in computational time compared to the old model, thus, improving its convergence. It reached the optimum level at minimal steps with 12.50% improvement as against the old model since it provides better velocity averages when speed stabilization occurs at the 24th iteration. Meanwhile, the computed p-values for NRMSE (0.04889174), MAE (0.02829063), MAPE (0.02226053), WAPE (0.01701545), and R2 (0.00000021) of the proposed algorithm are less than the set 0.05 level of significance, thus the values indicated a significant result in terms of accuracy performance. Applying the modified ANN-PSO using RDV IW technique greatly improved the new HIV/AIDS forecasting model compared with the two models.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "9 pages, 4 figures, Published with International Journal of Engineering Trends and Technology (IJETT)"
    },
    {
        "paper id": "2403.07881",
        "abstract url": "https://arxiv.org/abs/2403.07881",
        "title": "Epidemic modelling requires knowledge of the social network",
        "rating": -4,
        "keywords": [
            [
                "disease"
            ],
            [
                "forecast"
            ]
        ],
        "abstract": "Compartmental models of epidemics are widely used to forecast the effects of communicable diseases such as COVID-19 and to guide policy. Although it has long been known that such processes take place on social networks, the assumption of random mixing is usually made, which ignores network structure. However, super-spreading events have been found to be power-law distributed, suggesting that the underlying networks may be scale free or at least highly heterogeneous. The random-mixing assumption would then produce an overestimation of the herd-immunity threshold for given $R_0$; and a (more significant) overestimation of $R_0$ itself. These two errors compound each other, and can lead to forecasts greatly overestimating the number of infections. Moreover, if networks are heterogeneous and change in time, multiple waves of infection can occur, which are not predicted by random mixing. A simple SIR model simulated on both Erd\u0151s-R\u00e9nyi and scale-free networks shows that details of the network structure can be more important than the intrinsic transmissibility of a disease. It is therefore crucial to incorporate network information into standard models of epidemics.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "This is the Accepted Manuscript version of an article accepted for publication in Journal of Physics: Complexity. IOP Publishing Ltd is not responsible for any errors or omissions in this version or any version derived from it. This Accepted Manuscript is published under a CC BY licence. The Version of Record is available online at: https://iopscience.iop.org/article/10.1088/2632-072X/ad19e0"
    },
    {
        "paper id": "2401.04360",
        "abstract url": "https://arxiv.org/abs/2401.04360",
        "title": "New non-GRS type MDS codes and NMDS codes",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we study a class of special linear codes involving their parameters, weight distributions, and self-orthogonal properties. On one hand, we prove that such codes must be maximum distance separable (MDS) or near MDS (NMDS) codes and completely determine their weight distributions with the help of the solutions to some subset sum problems. Based on the well-known Schur method, we also show that such codes are non-equivalent to generalized Reed-Solomon codes. On the other hand, a sufficient and necessary condition for such codes to be self-orthogonal is characterized. Based on this condition, we further deduce that there are no self-dual codes in this class of linear codes and explicitly construct two classes of almost self-dual codes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04371",
        "abstract url": "https://arxiv.org/abs/2401.04371",
        "title": "Strategic Routing and Scheduling for Evacuations",
        "rating": -10,
        "keywords": [],
        "abstract": "Evacuation planning is an essential part of disaster management where the goal is to relocate people under imminent danger to safety. Although government authorities may prescribe routes and a schedule, evacuees generally behave as self-interested agents and may choose their action according to their own selfish interests. It is crucial to understand the degree of inefficiency this can cause to the evacuation process. However, existing research has mainly focused on selfish routing, i.e., they consider route selection as the only strategic action. In this paper, we present a strategic routing and scheduling game, named the Evacuation Planning Game (EPG), where evacuees choose both their route and the time of departure. We focus on confluent evacuation plans, where, if two routes meet at a node then their remaining portion is identical. We also use dynamic flows to model the time-varying traffic on roads during evacuation. We show that every instance of EPG has at least one pure strategy Nash equilibrium. We then present a polynomial time algorithm, the Sequential Action Algorithm (SAA), for finding equilibria in a given instance. Additionally, we provide bounds on how bad an equilibrium state can be compared to a socially optimal state. Finally, We use Harris County of Houston, Texas as our study area and construct a game instance for it. Our results show that, by utilizing SAA, we can efficiently find equilibria in this instance that have social objective close to the optimal value.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04405",
        "abstract url": "https://arxiv.org/abs/2401.04405",
        "title": "Optimal Transcoding Resolution Prediction for Efficient Per-Title Bitrate Ladder Estimation",
        "rating": -10,
        "keywords": [],
        "abstract": "Adaptive video streaming requires efficient bitrate ladder construction to meet heterogeneous network conditions and end-user demands. Per-title optimized encoding typically traverses numerous encoding parameters to search the Pareto-optimal operating points for each video. Recently, researchers have attempted to predict the content-optimized bitrate ladder for pre-encoding overhead reduction. However, existing methods commonly estimate the encoding parameters on the Pareto front and still require subsequent pre-encodings. In this paper, we propose to directly predict the optimal transcoding resolution at each preset bitrate for efficient bitrate ladder construction. We adopt a Temporal Attentive Gated Recurrent Network to capture spatial-temporal features and predict transcoding resolutions as a multi-task classification problem. We demonstrate that content-optimized bitrate ladders can thus be efficiently determined without any pre-encoding. Our method well approximates the ground-truth bitrate-resolution pairs with a slight Bj\u00f8ntegaard Delta rate loss of 1.21% and significantly outperforms the state-of-the-art fixed ladder.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "Accepted by the 2024 Data Compression Conference (DCC) for presentation as a poster. This is the full paper"
    },
    {
        "paper id": "2401.04408",
        "abstract url": "https://arxiv.org/abs/2401.04408",
        "title": "Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On public click-through rate prediction datasets, FIITED is able to prune up to 93.75%-99.75% embeddings without significant accuracy loss.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "16 pages, 9 figures"
    },
    {
        "paper id": "2401.04411",
        "abstract url": "https://arxiv.org/abs/2401.04411",
        "title": "Hiding Information for Secure and Covert Data Storage in Commercial ReRAM Chips",
        "rating": -10,
        "keywords": [],
        "abstract": "This article introduces a novel, low-cost technique for hiding data in commercially available resistive-RAM (ReRAM) chips. The data is kept hidden in ReRAM cells by manipulating its analog physical properties through switching ($\\textit{set/reset}$) operations. This hidden data, later, is retrieved by sensing the changes in cells' physical properties (i.e., $\\textit{set/reset}$ time of the memory cells). The proposed system-level hiding technique does not affect the normal memory operations and does not require any hardware modifications. Furthermore, the proposed hiding approach is robust against temperature variations and the aging of the devices through normal read/write operation. The silicon results show that our proposed data hiding technique is acceptably fast with ${\\sim}0.4bit/min$ of encoding and ${\\sim}15.625bits/s$ of retrieval rates, and the hidden message is unrecoverable without the knowledge of the secret key, which is used to enhance the security of hidden information.",
        "subjects": [
            "cs.ET"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2204.02104"
    },
    {
        "paper id": "2401.04431",
        "abstract url": "https://arxiv.org/abs/2401.04431",
        "title": "Sea wave data reconstruction using micro-seismic measurements and machine learning methods",
        "rating": -10,
        "keywords": [],
        "abstract": "Sea wave monitoring is key in many applications in oceanography such as the validation of weather and wave models. Conventional in situ solutions are based on moored buoys whose measurements are often recognized as a standard. However, being exposed to a harsh environment, they are not reliable, need frequent maintenance, and the datasets feature many gaps. To overcome the previous limitations, we propose a system including a buoy, a micro-seismic measuring station, and a machine learning algorithm. The working principle is based on measuring the micro-seismic signals generated by the sea waves. Thus, the machine learning algorithm will be trained to reconstruct the missing buoy data from the micro-seismic data. As the micro-seismic station can be installed indoor, it assures high reliability while the machine learning algorithm provides accurate reconstruction of the missing buoy data. In this work, we present the methods to process the data, develop and train the machine learning algorithm, and assess the reconstruction accuracy. As a case of study, we used experimental data collected in 2014 from the Northern Tyrrhenian Sea demonstrating that the data reconstruction can be done both for significant wave height and wave period. The proposed approach was inspired from Data Science, whose methods were the foundation for the new solutions presented in this work. For example, estimating the period of the sea waves, often not discussed in previous works, was relatively simple with machine learning. In conclusion, the experimental results demonstrated that the new system can overcome the reliability issues of the buoy keeping the same accuracy.",
        "subjects": [
            "physics.ins-det"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04446",
        "abstract url": "https://arxiv.org/abs/2401.04446",
        "title": "How Dataflow Diagrams Impact Software Security Analysis: an Empirical Experiment",
        "rating": -10,
        "keywords": [],
        "abstract": "Models of software systems are used throughout the software development lifecycle. Dataflow diagrams (DFDs), in particular, are well-established resources for security analysis. Many techniques, such as threat modelling, are based on DFDs of the analysed application. However, their impact on the performance of analysts in a security analysis setting has not been explored before. In this paper, we present the findings of an empirical experiment conducted to investigate this effect. Following a within-groups design, participants were asked to solve security-relevant tasks for a given microservice application. In the control condition, the participants had to examine the source code manually. In the model-supported condition, they were additionally provided a DFD of the analysed application and traceability information linking model items to artefacts in source code. We found that the participants (n = 24) performed significantly better in answering the analysis tasks correctly in the model-supported condition (41% increase in analysis correctness). Further, participants who reported using the provided traceability information performed better in giving evidence for their answers (315% increase in correctness of evidence). Finally, we identified three open challenges of using DFDs for security analysis based on the insights gained in the experiment.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04474",
        "abstract url": "https://arxiv.org/abs/2401.04474",
        "title": "Combining Embedding-Based and Semantic-Based Models for Post-hoc Explanations in Recommender Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "In today's data-rich environment, recommender systems play a crucial role in decision support systems. They provide to users personalized recommendations and explanations about these recommendations. Embedding-based models, despite their widespread use, often suffer from a lack of interpretability, which can undermine trust and user engagement. This paper presents an approach that combines embedding-based and semantic-based models to generate post-hoc explanations in recommender systems, leveraging ontology-based knowledge graphs to improve interpretability and explainability. By organizing data within a structured framework, ontologies enable the modeling of intricate relationships between entities, which is essential for generating explanations. By combining embedding-based and semantic based models for post-hoc explanations in recommender systems, the framework we defined aims at producing meaningful and easy-to-understand explanations, enhancing user trust and satisfaction, and potentially promoting the adoption of recommender systems across the e-commerce sector.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04494",
        "abstract url": "https://arxiv.org/abs/2401.04494",
        "title": "Adaptive Asynchronous Work-Stealing for distributed load-balancing in heterogeneous systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Supercomputers have revolutionized how industries and scientific fields process large amounts of data. These machines group hundreds or thousands of computing nodes working together to execute time-consuming programs that require a large amount of computational resources. Over the years, supercomputers have expanded to include new and different technologies characterizing them as heterogeneous. However, executing a program in a heterogeneous environment requires attention to a specific aspect of performance degradation: load imbalance. In this research, we address the challenges associated with load imbalance when scheduling many homogeneous tasks in a heterogeneous environment. To address this issue, we introduce the concept of adaptive asynchronous work-stealing. This approach collects information about the nodes and utilizes it to improve work-stealing aspects, such as victim selection and task offloading. Additionally, the proposed approach eliminates the need for extra threads to communicate information, thereby reducing overhead when implementing a fully asynchronous approach. Our experimental results demonstrate a performance improvement of approximately 10.1\\% compared to other conventional and state-of-the-art implementations.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "32 pages, 5 figures"
    },
    {
        "paper id": "2401.04508",
        "abstract url": "https://arxiv.org/abs/2401.04508",
        "title": "Data-driven Nonlinear Model Reduction using Koopman Theory: Integrated Control Form and NMPC Case Study",
        "rating": -10,
        "keywords": [],
        "abstract": "We use Koopman theory for data-driven model reduction of nonlinear dynamical systems with controls. We propose generic model structures combining delay-coordinate encoding of measurements and full-state decoding to integrate reduced Koopman modeling and state estimation. We present a deep-learning approach to train the proposed models. A case study demonstrates that our approach provides accurate control models and enables real-time capable nonlinear model predictive control of a high-purity cryogenic distillation column.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04509",
        "abstract url": "https://arxiv.org/abs/2401.04509",
        "title": "Linear-size Suffix Tries and Linear-size CDAWGs Simplified and Improved",
        "rating": -10,
        "keywords": [],
        "abstract": "The linear-size suffix tries (LSTries) [Crochemore et al., TCS 2016] are a version of suffix trees in which the edge labels are single characters, yet are able to perform pattern matching queries in optimal time. Instead of explicitly storing the input text, LSTries have some extra non-branching internal nodes called type-2 nodes. The extended techniques are then used in the linear-size compact directed acyclic word graphs (LCDAWGs) [Takagi et al. SPIRE 2017], which can be stored with $O(el(T)+er(T))$ space (i.e. without the text), where $el(T)$ and $er(T)$ are the numbers of left- and right-extensions of the maximal repeats in the input text string $T$, respectively. In this paper, we present simpler alternatives to the aforementioned indexing structures, called the simplified LSTries (simLSTries) and the simplified LCDAWGs (simLCDAWGs), in which most of the type-2 nodes are removed. In particular, our simLCDAWGs require only $O(er(T))$ space and work on a weaker model of computation (i.e. the pointer machine). This contrasts the $O(er(T))$-space CDAWG representation of [Belazzougui \\& Cunial, SPIRE 2017], which works on the word RAM.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04514",
        "abstract url": "https://arxiv.org/abs/2401.04514",
        "title": "Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search",
        "rating": -10,
        "keywords": [],
        "abstract": "In code search, the Generation-Augmented Retrieval (GAR) framework, which generates exemplar code snippets to augment queries, has emerged as a promising strategy to address the principal challenge of modality misalignment between code snippets and natural language queries, particularly with the demonstrated code generation capabilities of Large Language Models (LLMs). Nevertheless, our preliminary investigations indicate that the improvements conferred by such an LLM-augmented framework are somewhat constrained. This limitation could potentially be ascribed to the fact that the generated codes, albeit functionally accurate, frequently display a pronounced stylistic deviation from the ground truth code in the codebase. In this paper, we extend the foundational GAR framework and propose a simple yet effective method that additionally Rewrites the Code (ReCo) within the codebase for style normalization. Experimental results demonstrate that ReCo significantly boosts retrieval accuracy across sparse (up to 35.7%), zero-shot dense (up to 27.6%), and fine-tuned dense (up to 23.6%) retrieval settings in diverse search scenarios. To further elucidate the advantages of ReCo and stimulate research in code style normalization, we introduce Code Style Similarity, the first metric tailored to quantify stylistic similarities in code. Notably, our empirical findings reveal the inadequacy of existing metrics in capturing stylistic nuances.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04524",
        "abstract url": "https://arxiv.org/abs/2401.04524",
        "title": "Analyzing Coherency in Facet-based Clarification Prompt Generation for Search",
        "rating": -10,
        "keywords": [],
        "abstract": "Clarifying user's information needs is an essential component of modern search systems. While most of the approaches for constructing clarifying prompts rely on query facets, the impact of the quality of the facets is relatively unexplored. In this work, we concentrate on facet quality through the notion of facet coherency and assess its importance for overall usefulness for clarification in search. We find that existing evaluation procedures do not account for facet coherency, as evident by the poor correlation of coherency with automated metrics. Moreover, we propose a coherency classifier and assess the prevalence of incoherent facets in a well-established dataset on clarification. Our findings can serve as motivation for future work on the topic.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04535",
        "abstract url": "https://arxiv.org/abs/2401.04535",
        "title": "Semi-Supervised Deep Sobolev Regression: Estimation, Variable Selection and Beyond",
        "rating": -10,
        "keywords": [],
        "abstract": "We propose SDORE, a semi-supervised deep Sobolev regressor, for the nonparametric estimation of the underlying regression function and its gradient. SDORE employs deep neural networks to minimize empirical risk with gradient norm regularization, allowing computation of the gradient norm on unlabeled data. We conduct a comprehensive analysis of the convergence rates of SDORE and establish a minimax optimal rate for the regression function. Crucially, we also derive a convergence rate for the associated plug-in gradient estimator, even in the presence of significant domain shift. These theoretical findings offer valuable prior guidance for selecting regularization parameters and determining the size of the neural network, while showcasing the provable advantage of leveraging unlabeled data in semi-supervised learning. To the best of our knowledge, SDORE is the first provable neural network-based approach that simultaneously estimates the regression function and its gradient, with diverse applications including nonparametric variable selection and inverse problems. The effectiveness of SDORE is validated through an extensive range of numerical simulations and real data analysis.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04538",
        "abstract url": "https://arxiv.org/abs/2401.04538",
        "title": "UBfuzz: Finding Bugs in Sanitizer Implementations",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we propose a testing framework for validating sanitizer implementations in compilers. Our core components are (1) a program generator specifically designed for producing programs containing undefined behavior (UB), and (2) a novel test oracle for sanitizer testing. The program generator employs Shadow Statement Insertion, a general and effective approach for introducing UB into a valid seed program. The generated UB programs are subsequently utilized for differential testing of multiple sanitizer implementations. Nevertheless, discrepant sanitizer reports may stem from either compiler optimization or sanitizer bugs. To accurately determine if a discrepancy is caused by sanitizer bugs, we introduce a new test oracle called crash-site mapping. We have incorporated our techniques into UBfuzz, a practical tool for testing sanitizers. Over a five-month testing period, UBfuzz successfully found 31 bugs in both GCC and LLVM sanitizers. These bugs reveal the serious false negative problems in sanitizers, where certain UBs in programs went unreported. This research paves the way for further investigation in this crucial area of study.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "accepted to ASPLOS 2024"
    },
    {
        "paper id": "2401.04539",
        "abstract url": "https://arxiv.org/abs/2401.04539",
        "title": "A Novel Framework of K-repetition Grant-free Access via Diversity Slotted Aloha (DSA)",
        "rating": -10,
        "keywords": [],
        "abstract": "This article introduces a novel framework of multi-user detection (MUD) for K-repetition grant-free non-orthogonal multiple access (K-GF-NOMA), called $\u03b1$ iterative interference cancellation diversity slotted aloha ($\u03b1$-IIC-DSA). The proposed framework targets at a simple yet effective decoding process where the AP can intelligently exploit the correlation among signals received at different resource blocks (RBs) so as to generate required multi-access interference (MAI) for realizing the signal-interference cancellation (SIC) based MUD. By keeping all operation and hardware complexity at the access point (AP), the proposed framework is applicable to the scenarios with random and uncoordinated access by numerous miniature mMTC devices (MTCDs). Numerical experiments are conducted to gain deep understanding on the performance of launching the proposed framework for K-GF-NOMA.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2401.04552",
        "abstract url": "https://arxiv.org/abs/2401.04552",
        "title": "XaaS: Acceleration as a Service to Enable Productive High-Performance Cloud Computing",
        "rating": -10,
        "keywords": [],
        "abstract": "HPC and Cloud have evolved independently, specializing their innovations into performance or productivity. Acceleration as a Service (XaaS) is a recipe to empower both fields with a shared execution platform that provides transparent access to computing resources, regardless of the underlying cloud or HPC service provider. Bridging HPC and cloud advancements, XaaS presents a unified architecture built on performance-portable containers. Our converged model concentrates on low-overhead, high-performance communication and computing, targeting resource-intensive workloads from climate simulations to machine learning. XaaS lifts the restricted allocation model of Function-as-a-Service (FaaS), allowing users to benefit from the flexibility and efficient resource utilization of serverless while supporting long-running and performance-sensitive workloads from HPC.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04553",
        "abstract url": "https://arxiv.org/abs/2401.04553",
        "title": "Linear Recursive Feature Machines provably recover low-rank matrices",
        "rating": -10,
        "keywords": [],
        "abstract": "A fundamental problem in machine learning is to understand how neural networks make accurate predictions, while seemingly bypassing the curse of dimensionality. A possible explanation is that common training algorithms for neural networks implicitly perform dimensionality reduction - a process called feature learning. Recent work posited that the effects of feature learning can be elicited from a classical statistical estimator called the average gradient outer product (AGOP). The authors proposed Recursive Feature Machines (RFMs) as an algorithm that explicitly performs feature learning by alternating between (1) reweighting the feature vectors by the AGOP and (2) learning the prediction function in the transformed space. In this work, we develop the first theoretical guarantees for how RFM performs dimensionality reduction by focusing on the class of overparametrized problems arising in sparse linear regression and low-rank matrix recovery. Specifically, we show that RFM restricted to linear models (lin-RFM) generalizes the well-studied Iteratively Reweighted Least Squares (IRLS) algorithm. Our results shed light on the connection between feature learning in neural networks and classical sparse recovery algorithms. In addition, we provide an implementation of lin-RFM that scales to matrices with millions of missing entries. Our implementation is faster than the standard IRLS algorithm as it is SVD-free. It also outperforms deep linear networks for sparse linear regression and low-rank matrix completion.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04567",
        "abstract url": "https://arxiv.org/abs/2401.04567",
        "title": "A Discrete Particle Swarm Optimizer for the Design of Cryptographic Boolean Functions",
        "rating": -10,
        "keywords": [],
        "abstract": "A Particle Swarm Optimizer for the search of balanced Boolean functions with good cryptographic properties is proposed in this paper. The algorithm is a modified version of the permutation PSO by Hu, Eberhart and Shi which preserves the Hamming weight of the particles positions, coupled with the Hill Climbing method devised by Millan, Clark and Dawson to improve the nonlinearity and deviation from correlation immunity of Boolean functions. The parameters for the PSO velocity equation are tuned by means of two meta-optimization techniques, namely Local Unimodal Sampling (LUS) and Continuous Genetic Algorithms (CGA), finding that CGA produces better results. Using the CGA-evolved parameters, the PSO algorithm is then run on the spaces of Boolean functions from $n=7$ to $n=12$ variables. The results of the experiments are reported, observing that this new PSO algorithm generates Boolean functions featuring similar or better combinations of nonlinearity, correlation immunity and propagation criterion with respect to the ones obtained by other optimization methods.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "Extended version of the poster paper \"Heuristic Search by Particle Swarm Optimization of Boolean Functions for Cryptographic Applications\" published in GECCO 2015"
    },
    {
        "paper id": "2401.04594",
        "abstract url": "https://arxiv.org/abs/2401.04594",
        "title": "A Relatively Complete Program Logic for Effectful Branching",
        "rating": -10,
        "keywords": [],
        "abstract": "Starting with Hoare Logic over 50 years ago, numerous sound and relatively complete program logics have been devised to reason about the diverse programs encountered in the real world. This includes reasoning about computational effects, particularly those effects that cause the program execution to branch into multiple paths due to, e.g., nondeterministic or probabilistic choice. The recently introduced Outcome Logic reimagines Hoare Logic with effects at its core, using an algebraic representation of choice to capture a variety of effects. In this paper, we give the first relatively complete proof system for Outcome Logic, handling general purpose looping for the first time. We also show that this proof system applies to programs with various effects and that it facilitates the reuse of proof fragments across different kinds of specifications.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04606",
        "abstract url": "https://arxiv.org/abs/2401.04606",
        "title": "The Importance of Parameters in Database Queries",
        "rating": -10,
        "keywords": [],
        "abstract": "We propose and study a framework for quantifying the importance of the choices of parameter values to the result of a query over a database. These parameters occur as constants in logical queries, such as conjunctive queries. In our framework, the importance of a parameter is its SHAP score. This score is a popular instantiation of the game-theoretic Shapley value to measuring the importance of feature values in machine learning models. We make the case for the rationale of using this score by explaining the intuition behind SHAP, and by showing that we arrive at this score in two different, apparently opposing, approaches to quantifying the contribution of a parameter. The application of the SHAP score requires two components in addition to the query and the database: (a) a probability distribution over the combinations of parameter values, and (b) a utility function that measures the similarity between the result for the original parameters and the result for hypothetical parameters. The main question addressed in the paper is the complexity of calculating the SHAP score for different distributions and similarity measures. We first address the case of probabilistically independent parameters. The problem is hard if we consider a fragment of queries that is hard to evaluate (as one would expect), and even for the fragment of acyclic conjunctive queries. In some cases, though, one can efficiently list all relevant parameter combinations, and then the SHAP score can be computed in polynomial time under reasonable general conditions. Also tractable is the case of full acyclic conjunctive queries for certain (natural) similarity functions. We extend our results to conjunctive queries with inequalities between variables and parameters. Finally, we discuss a simple approximation technique for the case of correlated parameters.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04621",
        "abstract url": "https://arxiv.org/abs/2401.04621",
        "title": "DebugBench: Evaluating Debugging Capability of Large Language Models",
        "rating": -10,
        "keywords": [],
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs' debugging ability are significantly limited by the risk of data leakage, the scale of the dataset, and the variety of tested bugs. To overcome these deficiencies, we introduce `DebugBench', an LLM debugging benchmark consisting of 4,253 instances. It covers four major bug categories and 18 minor types in C++, Java, and Python. To construct DebugBench, we collect code snippets from the LeetCode community, implant bugs into source data with GPT-4, and assure rigorous quality checks. We evaluate two commercial and three open-source models in a zero-shot scenario. We find that (1) while closed-source models like GPT-4 exhibit inferior debugging performance compared to humans, open-source models such as Code Llama fail to attain any pass rate scores; (2) the complexity of debugging notably fluctuates depending on the bug category; (3) incorporating runtime feedback has a clear impact on debugging performance which is not always helpful. As an extension, we also compare LLM debugging and code generation, revealing a strong correlation between them for closed-source models. These findings will benefit the development of LLMs in debugging.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "in progress"
    },
    {
        "paper id": "2401.04628",
        "abstract url": "https://arxiv.org/abs/2401.04628",
        "title": "Multi-Neuron Representations of Hierarchical Concepts in Spiking Neural Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "We describe how hierarchical concepts can be represented in three types of layered neural networks. The aim is to support recognition of the concepts when partial information about the concepts is presented, and also when some of the neurons in the network might fail. Our failure model involves initial random failures. The three types of networks are: feed-forward networks with high connectivity, feed-forward networks with low connectivity, and layered networks with low connectivity and with both forward edges and \"lateral\" edges within layers. In order to achieve fault-tolerance, the representations all use multiple representative neurons for each concept. We show how recognition can work in all three of these settings, and quantify how the probability of correct recognition depends on several parameters, including the number of representatives and the neuron failure probability. We also discuss how these representations might be learned, in all three types of networks. For the feed-forward networks, the learning algorithms are similar to ones used in [4], whereas for networks with lateral edges, the algorithms are generally inspired by work on the assembly calculus [3, 6, 7].",
        "subjects": [
            "cs.NE"
        ],
        "comment": "In the previous version, we had an unduly restrictive statement about the order of choices of included edges, input set, and failing neurons. We have loosened this restriction. We generalized the model slightly to allow more freedom in choice of maximum layer number. We fixed a few typos and polished wording in a few places"
    },
    {
        "paper id": "2401.04637",
        "abstract url": "https://arxiv.org/abs/2401.04637",
        "title": "Applying Large Language Models API to Issue Classification Problem",
        "rating": -10,
        "keywords": [],
        "abstract": "Effective prioritization of issue reports is crucial in software engineering to optimize resource allocation and address critical problems promptly. However, the manual classification of issue reports for prioritization is laborious and lacks scalability. Alternatively, many open source software (OSS) projects employ automated processes for this task, albeit relying on substantial datasets for adequate training. This research seeks to devise an automated approach that ensures reliability in issue prioritization, even when trained on smaller datasets. Our proposed methodology harnesses the power of Generative Pre-trained Transformers (GPT), recognizing their potential to efficiently handle this task. By leveraging the capabilities of such models, we aim to develop a robust system for prioritizing issue reports accurately, mitigating the necessity for extensive training data while maintaining reliability. In our research, we have developed a reliable GPT-based approach to accurately label and prioritize issue reports with a reduced training dataset. By reducing reliance on massive data requirements and focusing on few-shot fine-tuning, our methodology offers a more accessible and efficient solution for issue prioritization in software engineering. Our model predicted issue types in individual projects up to 93.2% in precision, 95% in recall, and 89.3% in F1-score.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "4 pages, 1 figure, NLBSE and ICSE conference submission, ACM formatted, pre print"
    },
    {
        "paper id": "2401.04649",
        "abstract url": "https://arxiv.org/abs/2401.04649",
        "title": "From axial C-hedra to general P-nets",
        "rating": -10,
        "keywords": [],
        "abstract": "We give a full classification of continuous flexible discrete axial cone-nets, which are called axial C-hedra. The obtained result can also be used to construct their semi-discrete analogs. Moreover, we identify a novel subclass within the determined class of (semi-)discrete axial cone-nets, whose members are named axial P-nets as they fulfill the proportion (P) of the intercept theorem. Known special cases of these axial P-nets are the smooth and discrete conic crease patterns with reflecting rule lines. By using a parallelism operation one can even generalize axial P-nets. The resulting general P-nets constitute a rich novel class of continuous flexible (semi-)discrete surfaces, which allow direct access to their spatial shapes by three control polylines. This intuitive method makes them suitable for transformable design tasks using interactive tools.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "10 pages, 2 figures"
    },
    {
        "paper id": "2401.04653",
        "abstract url": "https://arxiv.org/abs/2401.04653",
        "title": "Time-certified Input-constrained NMPC via Koopman Operator",
        "rating": -10,
        "keywords": [],
        "abstract": "Determining solving-time certificates of nonlinear model predictive control (NMPC) implementations is a pressing requirement when deploying NMPC in production environments. Such a certificate guarantees that the NMPC controller returns a solution before the next sampling time. However, NMPC formulations produce nonlinear programs (NLPs) for which it is very difficult to derive their solving-time certificates. Our previous work, Wu and Braatz (2023), challenged this limitation with a proposed input-constrained MPC algorithm having exact iteration complexity but was restricted to linear MPC formulations. This work extends the algorithm to solve input-constrained NMPC problems, by using the Koopman operator and a condensing MPC technique. We illustrate the algorithm performance on a high-dimensional, nonlinear partial differential equation (PDE) control case study, in which we theoretically and numerically certify the solving time to be less than the sampling time.",
        "subjects": [
            "math.OC"
        ],
        "comment": "6 pages, submitted into 8th IFAC Conference on Nonlinear Model Predictive Control NMPC 2024"
    },
    {
        "paper id": "2401.04660",
        "abstract url": "https://arxiv.org/abs/2401.04660",
        "title": "Distributed Data-driven Unknown-input Observers",
        "rating": -10,
        "keywords": [],
        "abstract": "Unknown inputs related to, e.g., sensor aging, modeling errors, or device bias, represent a major concern in wireless sensor networks, as they degrade the state estimation performance. To improve the performance, unknown-input observers (UIOs) have been proposed. Most of the results available to design UIOs are based on explicit system models, which can be difficult or impossible to obtain in real-world applications. Data-driven techniques, on the other hand, have become a viable alternative for the design and analysis of unknown systems using only data. In this context, a novel data-driven distributed unknown-input observer (D-DUIO) for an unknown linear system is developed, which leverages solely some data collected offline, without any prior knowledge of the system matrices. In the paper, first, the design of a DUIO is investigated by resorting to a traditional model-based approach. By resorting to a Lyapunov equation, it is proved that under some conditions, the state estimates at all nodes of the DUIO achieve consensus and collectively converge to the state of the system. Moving to a data-driven approach, it is shown that the input/output/state trajectories of the system are compatible with the equations of a D-DUIO, and this allows, under suitable assumptions, to express the matrices of a possible DUIO in terms of the matrices of pre-collected data. Then, necessary and sufficient conditions for the existence of the proposed D-DUIO are given. Finally, the efficacy of the D-DUIO is illustrated by means of numerical examples.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04701",
        "abstract url": "https://arxiv.org/abs/2401.04701",
        "title": "HiRace: Accurate and Fast Source-Level Race Checking of GPU Programs",
        "rating": -10,
        "keywords": [],
        "abstract": "Data races are egregious parallel programming bugs on CPUs. They are even worse on GPUs due to the hierarchical thread and memory structure, which makes it possible to write code that is correctly synchronized within a thread group while not being correct across groups. Thus far, all major data-race checkers for GPUs suffer from at least one of the following problems: they do not check races in global memory, do not work on recent GPUs, scale poorly, have not been extensively tested, miss simple data races, or are not dependable without detailed knowledge of the compiler. Our new data-race detection tool, HiRace, overcomes these limitations. Its key novelty is an innovative parallel finite-state machine that condenses an arbitrarily long access history into a constant-length state, thus allowing it to handle large and long-running programs. HiRace is a dynamic tool that checks for thread-group shared memory and global device memory races. It utilizes source-code instrumentation, thus avoiding driver, compiler, and hardware dependencies. We evaluate it on a modern calibrated data-race benchmark suite. On the 580 tested CUDA kernels, 346 of which contain data races, HiRace finds races missed by other tools without false alarms and is more than 10 times faster on average than the current state of the art, while incurring only half the memory overhead.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04714",
        "abstract url": "https://arxiv.org/abs/2401.04714",
        "title": "Bin Packing under Random-Order: Breaking the Barrier of 3/2",
        "rating": -10,
        "keywords": [],
        "abstract": "Best-Fit is one of the most prominent and practically used algorithms for the bin packing problem, where a set of items with associated sizes needs to be packed in the minimum number of unit-capacity bins. Kenyon [SODA '96] studied online bin packing under random-order arrival, where the adversary chooses the list of items, but the items arrive one by one according to an arrival order drawn uniformly randomly from the set of all permutations of the items. Kenyon's seminal result established an upper bound of $1.5$ and a lower bound of $1.08$ on the random-order ratio of Best-Fit, and it was conjectured that the true ratio is $\\approx 1.15$. The conjecture, if true, will also imply that Best-Fit (on randomly permuted input) has the best performance guarantee among all the widely-used simple algorithms for (offline) bin packing. This conjecture has remained one of the major open problems in the area, as highlighted in the recent survey on random-order models by Gupta and Singla [Beyond the Worst-Case Analysis of Algorithms '20]. Recently, Albers et al. [Algorithmica '21] improved the upper bound to $1.25$ for the special case when all the item sizes are greater than $1/3$, and they improve the lower bound to $1.1$. Ayyadevara et al. [ICALP '22] obtained an improved result for the special case when all the item sizes lie in $(1/4, 1/2]$, which corresponds to the $3$-partition problem. The upper bound of $3/2$ for the general case, however, has remained unimproved. In this paper, we make the first progress towards the conjecture, by showing that Best-Fit achieves a random-order ratio of at most $1.5 - \\varepsilon$, for a small constant $\\varepsilon>0$. Furthermore, we establish an improved lower bound of $1.144$ on the random-order ratio of Best-Fit, nearly reaching the conjectured ratio.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04726",
        "abstract url": "https://arxiv.org/abs/2401.04726",
        "title": "Weighted degrees and truncated derived bibliographic networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Large bibliographic networks are sparse -- the average node degree is small. This is not necessarily true for their product -- in some cases, it can ``explode'' (it is not sparse, increases in time and space complexity). An approach in such cases is to reduce the complexity of the problem by limiting our attention to a selected subset of important nodes and computing with corresponding truncated networks. The nodes can be selected by different criteria. An option is to consider the most important nodes in the derived network -- nodes with the largest weighted degree. It turns out that the weighted degrees in the derived network can be computed efficiently without computing the derived network itself.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04729",
        "abstract url": "https://arxiv.org/abs/2401.04729",
        "title": "On the Effect of Contextual Information on Human Delegation Behavior in Human-AI collaboration",
        "rating": -10,
        "keywords": [],
        "abstract": "The constantly increasing capabilities of artificial intelligence (AI) open new possibilities for human-AI collaboration. One promising approach to leverage existing complementary capabilities is allowing humans to delegate individual instances to the AI. However, enabling humans to delegate instances effectively requires them to assess both their own and the AI's capabilities in the context of the given task. In this work, we explore the effects of providing contextual information on human decisions to delegate instances to an AI. We find that providing participants with contextual information significantly improves the human-AI team performance. Additionally, we show that the delegation behavior changes significantly when participants receive varying types of contextual information. Overall, this research advances the understanding of human-AI interaction in human delegation and provides actionable insights for designing more effective collaborative systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04744",
        "abstract url": "https://arxiv.org/abs/2401.04744",
        "title": "Testing Spintronics Implemented Monte Carlo Dropout-Based Bayesian Neural Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Bayesian Neural Networks (BayNNs) can inherently estimate predictive uncertainty, facilitating informed decision-making. Dropout-based BayNNs are increasingly implemented in spintronics-based computation-in-memory architectures for resource-constrained yet high-performance safety-critical applications. Although uncertainty estimation is important, the reliability of Dropout generation and BayNN computation is equally important for target applications but is overlooked in existing works. However, testing BayNNs is significantly more challenging compared to conventional NNs, due to their stochastic nature. In this paper, we present for the first time the model of the non-idealities of the spintronics-based Dropout module and analyze their impact on uncertainty estimates and accuracy. Furthermore, we propose a testing framework based on repeatability ranking for Dropout-based BayNN with up to $100\\%$ fault coverage while using only $0.2\\%$ of training data as test vectors.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04758",
        "abstract url": "https://arxiv.org/abs/2401.04758",
        "title": "On The Reasonable Effectiveness of Relational Diagrams: Explaining Relational Query Patterns and the Pattern Expressiveness of Relational Languages",
        "rating": -10,
        "keywords": [],
        "abstract": "Comparing relational languages by their logical expressiveness is well understood. Less well understood is how to compare relational languages by their ability to represent relational query patterns. Indeed, what are query patterns other than \"a certain way of writing a query\"? And how can query patterns be defined across procedural and declarative languages, irrespective of their syntax? To the best of our knowledge, we provide the first semantic definition of relational query patterns by using a variant of structure-preserving mappings between the relational tables of queries. This formalism allows us to analyze the relative pattern expressiveness of relational language fragments and create a hierarchy of languages with equal logical expressiveness yet different pattern expressiveness. Notably, for the non-disjunctive language fragment, we show that relational calculus can express a larger class of patterns than the basic operators of relational algebra. Our language-independent definition of query patterns opens novel paths for assisting database users. For example, these patterns could be leveraged to create visual query representations that faithfully represent query patterns, speed up interpretation, and provide visual feedback during query editing. As a concrete example, we propose Relational Diagrams, a complete and sound diagrammatic representation of safe relational calculus that is provably (i) unambiguous, (ii) relationally complete, and (iii) able to represent all query patterns for unions of non-disjunctive queries. Among all diagrammatic representations for relational queries that we are aware of, ours is the only one with these three properties. Furthermore, our anonymously preregistered user study shows that Relational Diagrams allow users to recognize patterns meaningfully faster and more accurately than SQL.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "71 pages, 49 figures, full version of SIGMOD 2024 paper of same title: https://doi.org/10.1145/3639316. arXiv admin note: text overlap with arXiv:2203.07284"
    },
    {
        "paper id": "2401.04778",
        "abstract url": "https://arxiv.org/abs/2401.04778",
        "title": "Generative neural networks for characteristic functions",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we provide a simulation algorithm to simulate from a (multivariate) characteristic function, which is only accessible in a black-box format. We construct a generative neural network, whose loss function exploits a specific representation of the Maximum-Mean-Discrepancy metric to directly incorporate the targeted characteristic function. The construction is universal in the sense that it is independent of the dimension and that it does not require any assumptions on the given characteristic function. Furthermore, finite sample guarantees on the approximation quality in terms of the Maximum-Mean Discrepancy metric are derived. The method is illustrated in a short simulation study.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04783",
        "abstract url": "https://arxiv.org/abs/2401.04783",
        "title": "Hyperbolic Machine Learning Moment Closures for the BGK Equations",
        "rating": -10,
        "keywords": [],
        "abstract": "We introduce a hyperbolic closure for the Grad moment expansion of the Bhatnagar-Gross-Krook's (BGK) kinetic model using a neural network (NN) trained on BGK's moment data. This closure is motivated by the exact closure for the free streaming limit that we derived in our paper on closures in transport \\cite{Huang2022-RTE1}. The exact closure relates the gradient of the highest moment to the gradient of four lower moments. As with our past work, the model presented here learns the gradient of the highest moment in terms of the coefficients of gradients for all lower ones. By necessity, this means that the resulting hyperbolic system is not conservative in the highest moment. For stability, the output layers of the NN are designed to enforce hyperbolicity and Galilean invariance. This ensures the model can be run outside of the training window of the NN. Unlike our previous work on radiation transport that dealt with linear models, the BGK model's nonlinearity demanded advanced training tools. These comprised an optimal learning rate discovery, one cycle training, batch normalization in each neural layer, and the use of the \\texttt{AdamW} optimizer. To address the non-conservative structure of the hyperbolic model, we adopt the FORCE numerical method to achieve robust solutions. This results in a comprehensive computing model combining learned closures with methods for solving hyperbolic models. The proposed model can capture accurate moment solutions across a broad spectrum of Knudsen numbers. Our paper details the multi-scale model construction and is run on a range of test problems.",
        "subjects": [
            "math.NA"
        ],
        "comment": "30 pages, 7 figures"
    },
    {
        "paper id": "2401.04787",
        "abstract url": "https://arxiv.org/abs/2401.04787",
        "title": "A Convex Optimization Approach to Compute Trapping Regions for Lossless Quadratic Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Quadratic systems with lossless quadratic terms arise in many applications, including models of atmosphere and incompressible fluid flows. Such systems have a trapping region if all trajectories eventually converge to and stay within a bounded set. Conditions for the existence and characterization of trapping regions have been established in prior works for boundedness analysis. However, prior solutions have used non-convex optimization methods, resulting in conservative estimates. In this paper, we build on this prior work and provide a convex semidefinite programming condition for the existence of a trapping region. The condition allows precise verification or falsification of the existence of a trapping region. If a trapping region exists, then we provide a second semidefinite program to compute the least conservative trapping region in the form of a ball. Two low-dimensional systems are provided as examples to illustrate the results. A third high-dimensional example is also included to demonstrate that the computation required for the analysis can be scaled to systems of up to $\\sim O(100)$ states. The proposed method provides a precise and computationally efficient numerical approach for computing trapping regions. We anticipate this work will benefit future studies on modeling and control of lossless quadratic dynamical systems.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04799",
        "abstract url": "https://arxiv.org/abs/2401.04799",
        "title": "Optimization-based Framework for Selecting Under-frequency Load Shedding Parameters",
        "rating": -10,
        "keywords": [],
        "abstract": "High penetration of renewable resources results in a power system with lower inertia and higher frequency sensitivity to power imbalances. Such systems are becoming increasingly susceptible to frequency collapse during extreme disturbances. Under-Frequency Load Shedding (UFLS) is a last-resort protection scheme and acts as an emergency brake by shedding load to arrest frequency decline. Current and emerging efforts to optimize UFLS settings and frequency thresholds are mostly network agnostic, ignoring network spatial information. With the prevalence of Distributed Energy Resources (DERs) in the high-renewable paradigm, the power grid is becoming more bidirectional, making some locations in the network less effective for UFLS action than others. This work proposes a Mixed Integer Linear Program that optimizes the UFLS setpoints (prioritizing one location over another) to minimize frequency deviation and load-shed for a given disturbance. The formulation considers system information and DER generation mix at different network locations, increasing model fidelity. The formulation also captures the discrete nature and practical time delays and deadbands associated with UFLS using a minimal set of binary variables, reducing problem complexity. We empirically validate the optimization approach on the dynamic IEEE 39-bus system for performance metrics, including frequency nadir, steady-state frequency and total load shed.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04805",
        "abstract url": "https://arxiv.org/abs/2401.04805",
        "title": "DeepSweep: Parallel and Scalable Spectrum Sensing via Convolutional Neural Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Spectrum sensing is an essential component of modern wireless networks as it offers a tool to characterize spectrum usage and better utilize it. Deep Learning (DL) has become one of the most used techniques to perform spectrum sensing as they are capable of delivering high accuracy and reliability. However, current techniques suffer from ad-hoc implementations and high complexity, which makes them unsuited for practical deployment on wireless systems where flexibility and fast inference time are necessary to support real-time spectrum sensing. In this paper, we introduce DeepSweep, a novel DL-based transceiver design that allows scalable, accurate, and fast spectrum sensing while maintaining a high level of customizability to adapt its design to a broad range of application scenarios and use cases. DeepSweep is designed to be seamlessly integrated with well-established transceiver designs and leverages shallow convolutional neural network (CNN) to \"sweep\" the spectrum and process captured IQ samples fast and reliably without interrupting ongoing demodulation and decoding operations. DeepSweep reduces training and inference times by more than 2 times and 10 times respectively, achieves up to 98 percent accuracy in locating spectrum activity, and produces outputs in less than 1 ms, thus showing that DeepSweep can be used for a broad range of spectrum sensing applications and scenarios.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "6 pages, 9 figures, IEEE ICMLCN 2024 - IEEE International Conference on Machine Learning for Communication and Networking, Stockholm, Sweden, 2024"
    },
    {
        "paper id": "2401.04810",
        "abstract url": "https://arxiv.org/abs/2401.04810",
        "title": "Translate-Distill: Learning Cross-Language Dense Retrieval by Translation and Distillation",
        "rating": -10,
        "keywords": [],
        "abstract": "Prior work on English monolingual retrieval has shown that a cross-encoder trained using a large number of relevance judgments for query-document pairs can be used as a teacher to train more efficient, but similarly effective, dual-encoder student models. Applying a similar knowledge distillation approach to training an efficient dual-encoder model for Cross-Language Information Retrieval (CLIR), where queries and documents are in different languages, is challenging due to the lack of a sufficiently large training collection when the query and document languages differ. The state of the art for CLIR thus relies on translating queries, documents, or both from the large English MS MARCO training set, an approach called Translate-Train. This paper proposes an alternative, Translate-Distill, in which knowledge distillation from either a monolingual cross-encoder or a CLIR cross-encoder is used to train a dual-encoder CLIR student model. This richer design space enables the teacher model to perform inference in an optimized setting, while training the student model directly for CLIR. Trained models and artifacts are publicly available on Huggingface.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "17 pages, 1 figure, accepted at ECIR 2024"
    },
    {
        "paper id": "2401.04820",
        "abstract url": "https://arxiv.org/abs/2401.04820",
        "title": "Phishing Website Detection through Multi-Model Analysis of HTML Content",
        "rating": -10,
        "keywords": [],
        "abstract": "The way we communicate and work has changed significantly with the rise of the Internet. While it has opened up new opportunities, it has also brought about an increase in cyber threats. One common and serious threat is phishing, where cybercriminals employ deceptive methods to steal sensitive information.This study addresses the pressing issue of phishing by introducing an advanced detection model that meticulously focuses on HTML content. Our proposed approach integrates a specialized Multi-Layer Perceptron (MLP) model for structured tabular data and two pretrained Natural Language Processing (NLP) models for analyzing textual features such as page titles and content. The embeddings from these models are harmoniously combined through a novel fusion process. The resulting fused embeddings are then input into a linear classifier. Recognizing the scarcity of recent datasets for comprehensive phishing research, our contribution extends to the creation of an up-to-date dataset, which we openly share with the community. The dataset is meticulously curated to reflect real-life phishing conditions, ensuring relevance and applicability. The research findings highlight the effectiveness of the proposed approach, with the CANINE demonstrating superior performance in analyzing page titles and the RoBERTa excelling in evaluating page content. The fusion of two NLP and one MLP model,termed MultiText-LP, achieves impressive results, yielding a 96.80 F1 score and a 97.18 accuracy score on our research dataset. Furthermore, our approach outperforms existing methods on the CatchPhish HTML dataset, showcasing its efficacies.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04836",
        "abstract url": "https://arxiv.org/abs/2401.04836",
        "title": "CoNST: Code Generator for Sparse Tensor Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Sparse tensor networks are commonly used to represent contractions over sparse tensors. Tensor contractions are higher-order analogs of matrix multiplication. Tensor networks arise commonly in many domains of scientific computing and data science. After a transformation into a tree of binary contractions, the network is implemented as a sequence of individual contractions. Several critical aspects must be considered in the generation of efficient code for a contraction tree, including sparse tensor layout mode order, loop fusion to reduce intermediate tensors, and the interdependence of loop order, mode order, and contraction order. We propose CoNST, a novel approach that considers these factors in an integrated manner using a single formulation. Our approach creates a constraint system that encodes these decisions and their interdependence, while aiming to produce reduced-order intermediate tensors via fusion. The constraint system is solved by the Z3 SMT solver and the result is used to create the desired fused loop structure and tensor mode layouts for the entire contraction tree. This structure is lowered to the IR of the TACO compiler, which is then used to generate executable code. Our experimental evaluation demonstrates very significant (sometimes orders of magnitude) performance improvements over current state-of-the-art sparse tensor compiler/library alternatives.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04842",
        "abstract url": "https://arxiv.org/abs/2401.04842",
        "title": "Adapting Standard Retrieval Benchmarks to Evaluate Generated Answers",
        "rating": -10,
        "keywords": [],
        "abstract": "Large language models can now directly generate answers to many factual questions without referencing external sources. Unfortunately, relatively little attention has been paid to methods for evaluating the quality and correctness of these answers, for comparing the performance of one model to another, or for comparing one prompt to another. In addition, the quality of generated answers are rarely directly compared to the quality of retrieved answers. As models evolve and prompts are modified, we have no systematic way to measure improvements without resorting to expensive human judgments. To address this problem we adapt standard retrieval benchmarks to evaluate answers generated by large language models. Inspired by the BERTScore metric for summarization, we explore two approaches. In the first, we base our evaluation on the benchmark relevance judgments. We empirically run experiments on how information retrieval relevance judgments can be utilized as an anchor to evaluating the generated answers. In the second, we compare generated answers to the top results retrieved by a diverse set of retrieval models, ranging from traditional approaches to advanced methods, allowing us to measure improvements without human judgments. In both cases, we measure the similarity between an embedded representation of the generated answer and an embedded representation of a known, or assumed, relevant passage from the retrieval benchmark.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04850",
        "abstract url": "https://arxiv.org/abs/2401.04850",
        "title": "FairQ: Fair and Fast Rate Allocation in Data Centers",
        "rating": -10,
        "keywords": [],
        "abstract": "The peculiar congestion patterns in data centers are caused by the bursty and composite nature of traffic, the small bandwidth-delay product, and the tiny switch buffers. It is not practical to modify TCP to adapt to data centers, especially in public clouds where multiple congestion control protocols coexist. In this work, we design a switch-based method to address such congestion issues; our approach does not require any modification to TCP, which enables easy and seamless deployment in public data centers via switch software update. We first present a simple analysis to demonstrate the stability and effectiveness of the scheme, and then we discuss a hardware NetFPGA switch-based prototype. The experimental results from real deployments in a small testbed cluster show the effectiveness of our approach.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2012.00339"
    },
    {
        "paper id": "2401.04852",
        "abstract url": "https://arxiv.org/abs/2401.04852",
        "title": "Answer Retrieval in Legal Community Question Answering",
        "rating": -10,
        "keywords": [],
        "abstract": "The task of answer retrieval in the legal domain aims to help users to seek relevant legal advice from massive amounts of professional responses. Two main challenges hinder applying existing answer retrieval approaches in other domains to the legal domain: (1) a huge knowledge gap between lawyers and non-professionals; and (2) a mix of informal and formal content on legal QA websites. To tackle these challenges, we propose CE_FS, a novel cross-encoder (CE) re-ranker based on the fine-grained structured inputs. CE_FS uses additional structured information in the CQA data to improve the effectiveness of cross-encoder re-rankers. Furthermore, we propose LegalQA: a real-world benchmark dataset for evaluating answer retrieval in the legal domain. Experiments conducted on LegalQA show that our proposed method significantly outperforms strong cross-encoder re-rankers fine-tuned on MS MARCO. Our novel finding is that adding the question tags of each question besides the question description and title into the input of cross-encoder re-rankers structurally boosts the rankers' effectiveness. While we study our proposed method in the legal domain, we believe that our method can be applied in similar applications in other domains.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "accepted at ECIR 2024"
    },
    {
        "paper id": "2401.04884",
        "abstract url": "https://arxiv.org/abs/2401.04884",
        "title": "Exact Thresholds for Noisy Non-Adaptive Group Testing",
        "rating": -10,
        "keywords": [],
        "abstract": "In recent years, the mathematical limits and algorithmic bounds for probabilistic group testing having become increasingly well-understood, with exact asymptotic thresholds now being known in general scaling regimes for the noiseless setting. In the noisy setting where each test outcome is flipped with constant probability, there have been similar developments, but the overall understanding has lagged significantly behind the noiseless setting. In this paper, we substantially narrow this gap by deriving exact asymptotic thresholds for the noisy setting under two widely-studied random test designs: i.i.d. Bernoulli and near-constant tests-per-item. These thresholds are established by combining components of an existing information-theoretic threshold decoder with a novel analysis of maximum-likelihood decoding (upper bounds), and deriving a novel set of impossibility results by analyzing certain failure events for optimal maximum-likelihood decoding (lower bounds). Our results show that existing algorithmic upper bounds for the noisy setting are strictly suboptimal, and leave open the interesting question of whether our thresholds can be attained using computationally efficient algorithms.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04885",
        "abstract url": "https://arxiv.org/abs/2401.04885",
        "title": "Cyclic and Negacyclic Sum-Rank Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "Sum-rank codes have known applications in the multishot network coding, the distributed storage and the construction of space-time codes. U. Mart\u00ednez-Pe\u00f1as introduced the cyclic-skew-cyclic sum-rank codes and proposed the BCH bound on the cyclic-skew-cyclic sum-rank codes in his paper published in IEEE Trans. Inf. Theory, vol. 67, no. 8, 2021. Afterwards, many sum-rank BCH codes with lower bounds on their dimensions and minimum sum-rank distances were constructed. Sum-rank Hartmann-Tzeng bound and sum-rank Roos bound on cyclic-skew-cyclic codes were proposed and proved by G. N. Alfarano, F. J. Lobillo, A. Neri, and A. Wachter-Zeh in 2022. In this paper, cyclic, negacyclic and constacyclic sum-rank codes are introduced and a direct construction of cyclic, negacyclic and constacyclic sum-rank codes of the matrix size $m \\times m$ from cyclic, negacyclic and constacyclic codes over ${\\bf F}_{q^m}$ in the Hamming metric is proposed. The cyclic-skew-cylic sum-rank codes are special cyclic sum-rank codes. In addition, BCH and Hartmann-Tzeng bounds for a type of cyclic sum-rank codes are developed. Specific constructions of cyclic, negacyclic and constacyclic sum-rank codes with known dimensions and controllable minimum sum-rank distances are proposed. Moreover, many distance-optimal binary sum-rank codes and an infinite family of distance-optimal binary cyclic sum-rank codes with minimum sum-rank distance four are constructed. This is the first infinite family of distance-optimal sum-rank codes with minimum sum-rank distance four in the literature.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04887",
        "abstract url": "https://arxiv.org/abs/2401.04887",
        "title": "Cited But Not Archived: Analyzing the Status of Code References in Scholarly Articles",
        "rating": -10,
        "keywords": [],
        "abstract": "One in five arXiv articles published in 2021 contained a URI to a Git Hosting Platform (GHP), which demonstrates the growing prevalence of GHP URIs in scholarly publications. However, GHP URIs are vulnerable to the same reference rot that plagues the Web at large. The disappearance of software hosting platforms, like Gitorious and Google Code, and the source code they contain threatens research reproducibility. Archiving the source code and development history available in GHPs enables the long-term reproducibility of research. Software Heritage and Web archives contain archives of GHP URI resources. However, are the GHP URIs referenced by scholarly publications contained within the Software Heritage and Web archive collections? We analyzed a dataset of GHP URIs extracted from scholarly publications to determine (1) is the URI still publicly available on the live Web?, (2) has the URI been archived by Software Heritage?, and (3) has the URI been archived by Web archives? Of all GHP URIs, we found that 93.98% were still publicly available on the live Web, 68.39% had been archived by Software Heritage, and 81.43% had been archived by Web archives.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04900",
        "abstract url": "https://arxiv.org/abs/2401.04900",
        "title": "SPT: Spectral Transformer for Red Giant Stars Age and Mass Estimation",
        "rating": -10,
        "keywords": [],
        "abstract": "The age and mass of red giants are essential for understanding the structure and evolution of the Milky Way. Traditional isochrone methods for these estimations are inherently limited due to overlapping isochrones in the Hertzsprung-Russell diagram, while asteroseismology, though more precise, requires high-precision, long-term observations. In response to these challenges, we developed a novel framework, Spectral Transformer (SPT), to predict the age and mass of red giants aligned with asteroseismology from their spectra. A key component of SPT, the Multi-head Hadamard Self-Attention mechanism, designed specifically for spectra, can capture complex relationships across different wavelength. Further, we introduced a Mahalanobis distance-based loss function to address scale imbalance and interaction mode loss, and incorporated Monte Carlo dropout for quantitative analysis of prediction uncertainty.Trained and tested on 3,880 red giant spectra from LAMOST, the SPT achieved remarkable age and mass estimations with average percentage errors of 17.64% and 6.61%, respectively, and provided uncertainties for each corresponding prediction. The results significantly outperform those of traditional machine learning algorithms and demonstrate a high level of consistency with asteroseismology methods and isochrone fitting techniques. In the future, our work will leverage datasets from the Chinese Space Station Telescope and the Large Synoptic Survey Telescope to enhance the precision of the model and broaden its applicability in the field of astronomy and astrophysics.",
        "subjects": [
            "astro-ph.SR"
        ],
        "comment": "Accepted by A&A"
    },
    {
        "paper id": "2401.04904",
        "abstract url": "https://arxiv.org/abs/2401.04904",
        "title": "Scalable Cyclic Schedulers for Age of Information Optimization in Large-Scale Status Update Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "We study cyclic scheduling for generate-at-will (GAW) multi-source status update systems with heterogeneous service times and packet drop probabilities, with the aim of minimizing the weighted sum age of information (AoI), called system AoI, or the weighted sum peak AoI (PAoI), called system PAoI. In particular, we obtain well-performing cyclic schedulers which can easily scale to thousands of information sources and which also have low online implementation complexity. The proposed schedulers are comparatively studied against existing scheduling algorithms in terms of computational load and system AoI/PAoI performance, to validate their effectiveness.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2401.04912",
        "abstract url": "https://arxiv.org/abs/2401.04912",
        "title": "A Formula for the I/O Cost of Linear Repair Schemes and Application to Reed-Solomon Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "Node repair is a crucial problem in erasure-code-based distributed storage systems. An important metric for repair efficiency is the I/O cost which equals the total amount of data accessed at helper nodes to repair a failed node. In this work, a general formula for computing the I/O cost of linear repair schemes is derived from a new perspective, i.e., by investigating the Hamming weight of a related linear space. Applying the formula to Reed-Solomon (RS) codes, we obtain lower bounds on the I/O cost for full-length RS codes with two and three parities. Furthermore, we build linear repair schemes for the RS codes with improved I/O cost. For full-length RS codes with two parities, our scheme meets the lower bound on the I/O cost.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.04918",
        "abstract url": "https://arxiv.org/abs/2401.04918",
        "title": "BS Coordination Optimization in Integrated Sensing and Communication: A Stochastic Geometric View",
        "rating": -10,
        "keywords": [],
        "abstract": "In this study, we explore integrated sensing and communication (ISAC) networks to strike a more effective balance between sensing and communication (S&C) performance at the network scale. We leverage stochastic geometry to analyze the S&C performance, shedding light on critical cooperative dependencies of ISAC networks. According to the derived expressions of network performance, we optimize the user/target loads and the cooperative base station cluster sizes for S&C to achieve a flexible trade-off between network-scale S&C performance. It is observed that the optimal strategy emphasizes the full utilization of spatial resources to enhance multiplexing and diversity gain when maximizing communication ASE. In contrast, for sensing objectives, parts of spatial resources are allocated to cancel inter-cell sensing interference to maximize sensing ASE. Simulation results validate that the proposed ISAC scheme realizes a remarkable enhancement in overall S&C network performance.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "8 pages, 7 figures, accepted by IEEE WCNC 2024. arXiv admin note: substantial text overlap with arXiv:2311.09052"
    },
    {
        "paper id": "2401.05444",
        "abstract url": "https://arxiv.org/abs/2401.05444",
        "title": "Fully Spiking Actor Network with Intra-layer Connections for Reinforcement Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "With the help of special neuromorphic hardware, spiking neural networks (SNNs) are expected to realize artificial intelligence (AI) with less energy consumption. It provides a promising energy-efficient way for realistic control tasks by combining SNNs with deep reinforcement learning (DRL). In this paper, we focus on the task where the agent needs to learn multi-dimensional deterministic policies to control, which is very common in real scenarios. Recently, the surrogate gradient method has been utilized for training multi-layer SNNs, which allows SNNs to achieve comparable performance with the corresponding deep networks in this task. Most existing spike-based RL methods take the firing rate as the output of SNNs, and convert it to represent continuous action space (i.e., the deterministic policy) through a fully-connected (FC) layer. However, the decimal characteristic of the firing rate brings the floating-point matrix operations to the FC layer, making the whole SNN unable to deploy on the neuromorphic hardware directly. To develop a fully spiking actor network without any floating-point matrix operations, we draw inspiration from the non-spiking interneurons found in insects and employ the membrane voltage of the non-spiking neurons to represent the action. Before the non-spiking neurons, multiple population neurons are introduced to decode different dimensions of actions. Since each population is used to decode a dimension of action, we argue that the neurons in each population should be connected in time domain and space domain. Hence, the intra-layer connections are used in output populations to enhance the representation capacity. Finally, we propose a fully spiking actor network with intra-layer connections (ILC-SAN).",
        "subjects": [
            "cs.NE"
        ],
        "comment": "13 pages, 6 figures"
    },
    {
        "paper id": "2401.05447",
        "abstract url": "https://arxiv.org/abs/2401.05447",
        "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
        "rating": -10,
        "keywords": [],
        "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines may affect stock market movements using ChatGPT and a two-stage prompt approach. We document a statistically significant positive correlation between the sentiment score and future equity market returns over short to medium term, which reverts to a negative correlation over longer horizons. Validation of this correlation pattern across multiple equity markets indicates its robustness across equity regions and resilience to non-linearity, evidenced by comparison of Pearson and Spearman correlations. Finally, we provide an estimate of the optimal horizon that strikes a balance between reactivity to new information and correlation.",
        "subjects": [
            "q-fin.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2401.05450",
        "abstract url": "https://arxiv.org/abs/2401.05450",
        "title": "Reorienting Learning Game Design in Design-Based Research: a Case Study",
        "rating": -10,
        "keywords": [],
        "abstract": "One of the main difficulties remains the collaboration between the various experts involved in designing the Learning Games (LG). Our literature review focuses on the pitfalls and principles that have been identified by various authors in learning games design. Based on this review, a prototype was designed to support the LG design process and to study more precisely the collaboration between actors (teachers, researchers, game designers, data analyst and computer scientist). Indeed, according to the state of the art, the skills and knowledge involved in design are difficult to integrate. It has been tested in a real-world scenario for designing learning games to teach algorithmic. Through participant observation in thirty-three workshops involving nine experts, we were able to identify recurring pitfalls as we applied the recommendations in the literature. The analysis of these workshops led to propose eight principles aimed at facilitating the collaboration between the learning games design process and re-evaluating research on its.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.05451",
        "abstract url": "https://arxiv.org/abs/2401.05451",
        "title": "OpenSkill: A faster asymmetric multi-team, multiplayer rating system",
        "rating": -10,
        "keywords": [],
        "abstract": "Assessing and comparing player skill in online multiplayer gaming environments is essential for fair matchmaking and player engagement. Traditional ranking models like Elo and Glicko-2, designed for two-player games, are insufficient for the complexity of multi-player, asymmetric team-based matches. To address this gap, the OpenSkill library offers a suite of sophisticated, fast, and adaptable models tailored for such dynamics. Drawing from Bayesian inference methods, OpenSkill provides a more accurate representation of individual player contributions and speeds up the computation of ranks. This paper introduces the OpenSkill library, featuring a Python implementation of the Plackett-Luce model among others, highlighting its performance advantages and predictive accuracy against proprietary systems like TrueSkill. OpenSkill is a valuable tool for game developers and researchers, ensuring a responsive and fair gaming experience by efficiently adjusting player rankings based on game outcomes. The library's support for time decay and diligent documentation further aid in its practical application, making it a robust solution for the nuanced world of multiplayer ranking systems. This paper also acknowledges areas for future enhancement, such as partial play and contribution weighting, emphasizing the library's ongoing development to meet the evolving needs of online gaming communities.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08671",
        "abstract url": "https://arxiv.org/abs/2401.08671",
        "title": "DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference",
        "rating": -10,
        "keywords": [],
        "abstract": "The deployment and scaling of large language models (LLMs) have become critical as they permeate various applications, demanding high-throughput and low-latency serving systems. Existing frameworks struggle to balance these requirements, especially for workloads with long prompts. This paper introduces DeepSpeed-FastGen, a system that employs Dynamic SplitFuse, a novel prompt and generation composition strategy, to deliver up to 2.3x higher effective throughput, 2x lower latency on average, and up to 3.7x lower (token-level) tail latency, compared to state-of-the-art systems like vLLM. We leverage a synergistic combination of DeepSpeed-MII and DeepSpeed-Inference to provide an efficient and easy-to-use serving system for LLMs. DeepSpeed-FastGen's advanced implementation supports a range of models and offers both non-persistent and persistent deployment options, catering to diverse user scenarios from interactive sessions to long-running applications. We present a detailed benchmarking methodology, analyze the performance through latency-throughput curves, and investigate scalability via load balancing. Our evaluations demonstrate substantial improvements in throughput and latency across various models and hardware configurations. We discuss our roadmap for future enhancements, including broader model support and new hardware backends. The DeepSpeed-FastGen code is readily available for community engagement and contribution.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09466",
        "abstract url": "https://arxiv.org/abs/2401.09466",
        "title": "Self Supervised Vision for Climate Downscaling",
        "rating": -10,
        "keywords": [],
        "abstract": "Climate change is one of the most critical challenges that our planet is facing today. Rising global temperatures are already bringing noticeable changes to Earth's weather and climate patterns with an increased frequency of unpredictable and extreme weather events. Future projections for climate change research are based on Earth System Models (ESMs), the computer models that simulate the Earth's climate system. ESMs provide a framework to integrate various physical systems, but their output is bound by the enormous computational resources required for running and archiving higher-resolution simulations. For a given resource budget, the ESMs are generally run on a coarser grid, followed by a computationally lighter $downscaling$ process to obtain a finer-resolution output. In this work, we present a deep-learning model for downscaling ESM simulation data that does not require high-resolution ground truth data for model optimization. This is realized by leveraging salient data distribution patterns and the hidden dependencies between weather variables for an $\\textit{individual}$ data point at $\\textit{runtime}$. Extensive evaluation with $2$x, $3$x, and $4$x scaling factors demonstrates that the proposed model consistently obtains superior performance over that of various baselines. The improved downscaling performance and no dependence on high-resolution ground truth data make the proposed method a valuable tool for climate research and mark it as a promising direction for future research.",
        "subjects": [
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10205",
        "abstract url": "https://arxiv.org/abs/2401.10205",
        "title": "Effective Communication of Scientific Results",
        "rating": -10,
        "keywords": [],
        "abstract": "Communication is essential for the advancement of Science. Technology advances and the proliferation of personal devices have changed the ways in which people communicate in all aspects of life. Scientific communication has also been profoundly affected by such changes, and thus it is important to reflect on effective ways to communicate scientific results to scientists that are flooded with information. This article advocates for receiver-oriented communication in Science, discusses how effective oral presentations should be prepared and delivered, provides advice on the thought process that can lead to scientific papers that communicate effectively, discusses suitable methodology to produce experimental data that is relevant and offers advice on how to present such data in ways that lead to the formulation of correct claims that are supported by the data.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "14 pages manuscript"
    },
    {
        "paper id": "2401.10274",
        "abstract url": "https://arxiv.org/abs/2401.10274",
        "title": "Knowledge-Assisted Dual-Stage Evolutionary Optimization of Large-Scale Crude Oil Scheduling",
        "rating": -10,
        "keywords": [],
        "abstract": "With the scaling up of crude oil scheduling in modern refineries, large-scale crude oil scheduling problems (LSCOSPs) emerge with thousands of binary variables and non-linear constraints, which are challenging to be optimized by traditional optimization methods. To solve LSCOSPs, we take the practical crude oil scheduling from a marine-access refinery as an example and start with modeling LSCOSPs from crude unloading, transportation, crude distillation unit processing, and inventory management of intermediate products. On the basis of the proposed model, a dual-stage evolutionary algorithm driven by heuristic rules (denoted by DSEA/HR) is developed, where the dual-stage search mechanism consists of global search and local refinement. In the global search stage, we devise several heuristic rules based on the empirical operating knowledge to generate a well-performing initial population and accelerate convergence in the mixed variables space. In the local refinement stage, a repair strategy is proposed to move the infeasible solutions towards feasible regions by further optimizing the local continuous variables. During the whole evolutionary process, the proposed dual-stage framework plays a crucial role in balancing exploration and exploitation. Experimental results have shown that DSEA/HR outperforms the state-of-the-art and widely-used mathematical programming methods and metaheuristic algorithms on LSCOSP instances within a reasonable time.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06629",
        "abstract url": "https://arxiv.org/abs/2402.06629",
        "title": "Towards the mathematical foundation of the minimum enclosing ball and related problems",
        "rating": -10,
        "keywords": [],
        "abstract": "Theoretical background is provided towards the mathematical foundation of the minimum enclosing ball problem. This problem concerns the determination of the unique spherical surface of smallest radius enclosing a given bounded set in the d-dimensional Euclidean space. The study of several problems that are similar or related to the minimum enclosing ball problem has received a considerable impetus from the large amount of applications of these problems in various fields of science and technology. The proposed theoretical framework is based on several enclosing (covering) and partitioning (clustering) theorems and provides among others bounds and relations between the circumradius, inradius, diameter and width of a set. These enclosing and partitioning theorems are considered as cornerstones in the field that strongly influencing developments and generalizations to other spaces and non-Euclidean geometries.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2401.03232"
    },
    {
        "paper id": "2402.09414",
        "abstract url": "https://arxiv.org/abs/2402.09414",
        "title": "The number of global solutions for GPS source localization in two-dimension",
        "rating": -10,
        "keywords": [],
        "abstract": "Source localization is widely used in many areas including GPS, but the influence of possible noises is not so negligible. Many optimization methods are attempted to alleviate different kinds of noises. Needless to say the stability of the solution, even the number of global solutions are not fully known. Only local convergence or stability for the optimization problem are known in simple $L^1$\\cite{Kwon} or $L^2$\\cite{Kwon3} settings. In this paper, we prove that the number of possible two dimensional source locations with three measurements in $L^2$ setting, is at most $5$, which is the complement and correction to the previous work \\cite{Kwon3}. We also showed the sufficient and necessary condition for the number of the solutions being 1,2,3,4,and 5, where the measurement triangle is isosceles and the measurement distance for the two isosceles triangle bases are the same.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    }
]