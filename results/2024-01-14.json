[
    {
        "paper id": "2401.07457",
        "abstract url": "https://arxiv.org/abs/2401.07457",
        "title": "Concept-Guided Prompt Learning for Generalization in Vision-Language Models",
        "rating": "2.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Contrastive Language-Image Pretraining (CLIP) model has exhibited remarkable efficacy in establishing cross-modal connections between texts and images, yielding impressive performance across a broad spectrum of downstream applications through fine-tuning. However, for generalization tasks, the current fine-tuning methods for CLIP, such as CoOp and CoCoOp, demonstrate relatively low performance on some fine-grained datasets. We recognize the underlying reason is that these previous methods only projected global features into the prompt, neglecting the various visual concepts, such as colors, shapes, and sizes, which are naturally transferable across domains and play a crucial role in generalization tasks. To address this issue, in this work, we propose Concept-Guided Prompt Learning (CPL) for vision-language models. Specifically, we leverage the well-learned knowledge of CLIP to create a visual concept cache to enable concept-guided prompting. In order to refine the text features, we further develop a projector that transforms multi-level visual features into text features. We observe that this concept-guided prompt learning approach is able to achieve enhanced consistency between visual and linguistic modalities. Extensive experimental results demonstrate that our CPL method significantly improves generalization capabilities compared to the current state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.07284",
        "abstract url": "https://arxiv.org/abs/2401.07284",
        "title": "Improving Domain Adaptation through Extended-Text Reading Comprehension",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "To enhance the domain-specific capabilities of large language models, continued pre-training on a domain-specific corpus is a prevalent method. Recent work demonstrates that adapting models using reading comprehension data formatted by regex-based patterns can significantly improve performance on domain-specific tasks. However, regex-based patterns are incapable of parsing raw corpora using domain-specific knowledge. Furthermore, the question and answer pairs are extracted directly from the corpus in predefined formats offers limited context. To address this limitation, we improve reading comprehension via LLM and clustering. LLM focuses on leveraging domain knowledge within the corpus to refine comprehension stage, while clustering supplies relevant knowledge by extending the context to enrich reading stage. Additionally, our method incorporates parameter-efficient fine-tuning to improve the efficiency of domain adaptation. In comparison to AdaptLLM, our method achieves an improvement exceeding 5% in domain-specific tasks. Our code will available at https://github.com/microsoft/LMOps.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in Progress"
    },
    {
        "paper id": "2401.07363",
        "abstract url": "https://arxiv.org/abs/2401.07363",
        "title": "PersonalityChat: Conversation Distillation for Personalized Dialog Modeling with Facts and Traits",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "workshop",
                "EMNLP"
            ]
        ],
        "abstract": "The new wave of Large Language Models (LLM) has offered an efficient tool to curate sizeable conversational datasets. So far studies have mainly focused on task-oriented or generic open-domain dialogs, and have not fully explored the ability of LLMs in following complicated prompts. In this work, we focus on personalization, and employ LLMs to curate a dataset which is difficult and costly to crowd-source: PersonalityChat is a synthetic conversational dataset based upon the popular PersonaChat dataset, but conditioned on both personas and (Big-5) personality traits. Evaluating models fine-tuned on this dataset, we show that the personality trait labels can be used for trait-based personalization of generative dialogue models. We also perform a head-to-head comparison between PersonalityChat and PersonaChat, and show that training on the distilled dataset results in more fluent and coherent dialog agents in the small-model regime.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "GEM workshop @ EMNLP23"
    },
    {
        "paper id": "2401.07207",
        "abstract url": "https://arxiv.org/abs/2401.07207",
        "title": "Unsupervised Domain Adaptation Using Compact Internal Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "A major technique for tackling unsupervised domain adaptation involves mapping data points from both the source and target domains into a shared embedding space. The mapping encoder to the embedding space is trained such that the embedding space becomes domain agnostic, allowing a classifier trained on the source domain to generalize well on the target domain. To further enhance the performance of unsupervised domain adaptation (UDA), we develop an additional technique which makes the internal distribution of the source domain more compact, thereby improving the model's ability to generalize in the target domain.We demonstrate that by increasing the margins between data representations for different classes in the embedding space, we can improve the model performance for UDA. To make the internal representation more compact, we estimate the internally learned multi-modal distribution of the source domain as Gaussian mixture model (GMM). Utilizing the estimated GMM, we enhance the separation between different classes in the source domain, thereby mitigating the effects of domain shift. We offer theoretical analysis to support outperofrmance of our method. To evaluate the effectiveness of our approach, we conduct experiments on widely used UDA benchmark UDA datasets. The results indicate that our method enhances model generalizability and outperforms existing techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07208",
        "abstract url": "https://arxiv.org/abs/2401.07208",
        "title": "Enhanced Few-Shot Class-Incremental Learning via Ensemble Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot class-incremental learning (FSCIL) aims to continually fit new classes with limited training data, while maintaining the performance of previously learned classes. The main challenges are overfitting the rare new training samples and forgetting old classes. While catastrophic forgetting has been extensively studied, the overfitting problem has attracted less attention in FSCIL. To tackle overfitting challenge, we design a new ensemble model framework cooperated with data augmentation to boost generalization. In this way, the enhanced model works as a library storing abundant features to guarantee fast adaptation to downstream tasks. Specifically, the multi-input multi-output ensemble structure is applied with a spatial-aware data augmentation strategy, aiming at diversifying the feature extractor and alleviating overfitting in incremental sessions. Moreover, self-supervised learning is also integrated to further improve the model generalization. Comprehensive experimental results show that the proposed method can indeed mitigate the overfitting problem in FSCIL, and outperform the state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07286",
        "abstract url": "https://arxiv.org/abs/2401.07286",
        "title": "CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The sequential process of conceptualization and instantiation is essential to generalizable commonsense reasoning as it allows the application of existing knowledge to unfamiliar scenarios. However, existing works tend to undervalue the step of instantiation and heavily rely on pre-built concept taxonomies and human annotations to collect both types of knowledge, resulting in a lack of instantiated knowledge to complete reasoning, high cost, and limited scalability. To tackle these challenges, we introduce CANDLE, a distillation framework that iteratively performs contextualized conceptualization and instantiation over commonsense knowledge bases by instructing large language models to generate both types of knowledge with critic filtering. By applying CANDLE to ATOMIC, we construct a comprehensive knowledge base comprising six million conceptualizations and instantiated commonsense knowledge triples. Both types of knowledge are firmly rooted in the original ATOMIC dataset, and intrinsic evaluations demonstrate their exceptional quality and diversity. Empirical results indicate that distilling CANDLE on student models provides benefits across four downstream tasks. Our code, data, and models are publicly available at https://github.com/HKUST-KnowComp/CANDLE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07301",
        "abstract url": "https://arxiv.org/abs/2401.07301",
        "title": "Small Language Model Can Self-correct",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Generative Language Models (LMs) such as ChatGPT have exhibited remarkable performance across various downstream tasks. Nevertheless, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. Previous studies have devised sophisticated pipelines and prompts to induce large LMs to exhibit the capability for self-correction. However, large LMs are explicitly prompted to verify and modify its answers separately rather than completing all steps spontaneously like humans. Moreover, these complex prompts are extremely challenging for small LMs to follow. In this paper, we introduce the \\underline{I}ntrinsic \\underline{S}elf-\\underline{C}orrection (ISC) in generative language models, aiming to correct the initial output of LMs in a self-triggered manner, even for those small LMs with 6 billion parameters. Specifically, we devise a pipeline for constructing self-correction data and propose Partial Answer Masking (PAM), aiming to endow the model with the capability for intrinsic self-correction through fine-tuning. We conduct experiments using LMs with parameters sizes ranging from 6 billion to 13 billion in two tasks, including commonsense reasoning and factual knowledge reasoning. Our experiments demonstrate that the outputs generated using ISC outperform those generated without self-correction. We believe that the output quality of even small LMs can be further improved by empowering them with the ability to intrinsic self-correct.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07340",
        "abstract url": "https://arxiv.org/abs/2401.07340",
        "title": "The Afterlives of Shakespeare and Company in Online Social Readership",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The growth of social reading platforms such as Goodreads and LibraryThing enables us to analyze reading activity at very large scale and in remarkable detail. But twenty-first century systems give us a perspective only on contemporary readers. Meanwhile, the digitization of the lending library records of Shakespeare and Company provides a window into the reading activity of an earlier, smaller community in interwar Paris. In this article, we explore the extent to which we can make comparisons between the Shakespeare and Company and Goodreads communities. By quantifying similarities and differences, we can identify patterns in how works have risen or fallen in popularity across these datasets. We can also measure differences in how works are received by measuring similarities and differences in co-reading patterns. Finally, by examining the complete networks of co-readership, we can observe changes in the overall structures of literary reception.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07342",
        "abstract url": "https://arxiv.org/abs/2401.07342",
        "title": "Who Said What? An Automated Approach to Analyzing Speech in Preschool Classrooms",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Young children spend substantial portions of their waking hours in noisy preschool classrooms. In these environments, children's vocal interactions with teachers are critical contributors to their language outcomes, but manually transcribing these interactions is prohibitive. Using audio from child- and teacher-worn recorders, we propose an automated framework that uses open source software both to classify speakers (ALICE) and to transcribe their utterances (Whisper). We compare results from our framework to those from a human expert for 110 minutes of classroom recordings, including 85 minutes from child-word microphones (n=4 children) and 25 minutes from teacher-worn microphones (n=2 teachers). The overall proportion of agreement, that is, the proportion of correctly classified teacher and child utterances, was .76, with an error-corrected kappa of .50 and a weighted F1 of .76. The word error rate for both teacher and child transcriptions was .15, meaning that 15% of words would need to be deleted, added, or changed to equate the Whisper and expert transcriptions. Moreover, speech features such as the mean length of utterances in words, the proportion of teacher and child utterances that were questions, and the proportion of utterances that were responded to within 2.5 seconds were similar when calculated separately from expert and automated transcriptions. The results suggest substantial progress in analyzing classroom speech that may support children's language development. Future research using natural language processing is under way to improve speaker classification and to analyze results from the application of the automated framework to a larger dataset containing classroom recordings from 13 children and 3 teachers observed on 17 occasions over one year.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "8 pages, 4 figures, 3 tables, The paper has been accepted to 2024 IEEE International Conference on Development and Learning (ICDL) as a full oral presentation and will appear in the IEEE ICDL proceedings"
    },
    {
        "paper id": "2401.07360",
        "abstract url": "https://arxiv.org/abs/2401.07360",
        "title": "Promptformer: Prompted Conformer Transducer for ASR",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Context cues carry information which can improve multi-turn interactions in automatic speech recognition (ASR) systems. In this paper, we introduce a novel mechanism inspired by hyper-prompting to fuse textual context with acoustic representations in the attention mechanism. Results on a test set with multi-turn interactions show that our method achieves 5.9% relative word error rate reduction (rWERR) over a strong baseline. We show that our method does not degrade in the absence of context and leads to improvements even if the model is trained without context. We further show that leveraging a pre-trained sentence-piece model for context embedding generation can outperform an external BERT model.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07367",
        "abstract url": "https://arxiv.org/abs/2401.07367",
        "title": "Active Learning for NLP with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Human annotation of training samples is expensive, laborious, and sometimes challenging, especially for Natural Language Processing (NLP) tasks. To reduce the labeling cost and enhance the sample efficiency, Active Learning (AL) technique can be used to label as few samples as possible to reach a reasonable or similar results. To reduce even more costs and with the significant advances of Large Language Models (LLMs), LLMs can be a good candidate to annotate samples. This work investigates the accuracy and cost of using LLMs (GPT-3.5 and GPT-4) to label samples on 3 different datasets. A consistency-based strategy is proposed to select samples that are potentially incorrectly labeled so that human annotations can be used for those samples in AL settings, and we call it mixed annotation strategy. Then we test performance of AL under two different settings: (1) using human annotations only; (2) using the proposed mixed annotation strategy. The accuracy of AL models under 3 AL query strategies are reported on 3 text classification datasets, i.e., AG's News, TREC-6, and Rotten Tomatoes. On AG's News and Rotten Tomatoes, the models trained with the mixed annotation strategy achieves similar or better results compared to that with human annotations. The method reveals great potentials of LLMs as annotators in terms of accuracy and cost efficiency in active learning settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "init report"
    },
    {
        "paper id": "2401.07370",
        "abstract url": "https://arxiv.org/abs/2401.07370",
        "title": "Generation of Synthetic Images for Pedestrian Detection Using a Sequence of GANs",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Creating annotated datasets demands a substantial amount of manual effort. In this proof-of-concept work, we address this issue by proposing a novel image generation pipeline. The pipeline consists of three distinct generative adversarial networks (previously published), combined in a novel way to augment a dataset for pedestrian detection. Despite the fact that the generated images are not always visually pleasant to the human eye, our detection benchmark reveals that the results substantially surpass the baseline. The presented proof-of-concept work was done in 2020 and is now published as a technical report after a three years retention period.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07378",
        "abstract url": "https://arxiv.org/abs/2401.07378",
        "title": "Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Earth Mover's Distance (EMD) is an important similarity measure between two distributions, used in computer vision and many other application domains. However, its exact calculation is computationally and memory intensive, which hinders its scalability and applicability for large-scale problems. Various approximate EMD algorithms have been proposed to reduce computational costs, but they suffer lower accuracy and may require additional memory usage or manual parameter tuning. In this paper, we present a novel approach, NNS-EMD, to approximate EMD using Nearest Neighbor Search (NNS), in order to achieve high accuracy, low time complexity, and high memory efficiency. The NNS operation reduces the number of data points compared in each NNS iteration and offers opportunities for parallel processing. We further accelerate NNS-EMD via vectorization on GPU, which is especially beneficial for large datasets. We compare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD algorithms on image classification and retrieval tasks. We also apply NNS-EMD to calculate transport mapping and realize color transfer between images. NNS-EMD can be 44x to 135x faster than the exact EMD implementation, and achieves superior accuracy, speedup, and memory efficiency over existing approximate EMD methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07382",
        "abstract url": "https://arxiv.org/abs/2401.07382",
        "title": "Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Reinforcement learning (RL) can align language models with non-differentiable reward signals, such as human preferences. However, a major challenge arises from the sparsity of these reward signals - typically, there is only a single reward for an entire output. This sparsity of rewards can lead to inefficient and unstable learning. To address this challenge, our paper introduces an novel framework that utilizes the critique capability of Large Language Models (LLMs) to produce intermediate-step rewards during RL training. Our method involves coupling a policy model with a critic language model, which is responsible for providing comprehensive feedback of each part of the output. This feedback is then translated into token or span-level rewards that can be used to guide the RL training process. We investigate this approach under two different settings: one where the policy model is smaller and is paired with a more powerful critic model, and another where a single language model fulfills both roles. We assess our approach on three text generation tasks: sentiment control, language model detoxification, and summarization. Experimental results show that incorporating artificial intrinsic rewards significantly improve both sample efficiency and the overall performance of the policy model, supported by both automatic and human evaluation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07392",
        "abstract url": "https://arxiv.org/abs/2401.07392",
        "title": "A Strong Inductive Bias: Gzip for binary image classification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning networks have become the de-facto standard in Computer Vision for industry and research. However, recent developments in their cousin, Natural Language Processing (NLP), have shown that there are areas where parameter-less models with strong inductive biases can serve as computationally cheaper and simpler alternatives. We propose such a model for binary image classification: a nearest neighbor classifier combined with a general purpose compressor like Gzip. We test and compare it against popular deep learning networks like Resnet, EfficientNet and Mobilenet and show that it achieves better accuracy and utilizes significantly less space, more than two order of magnitude, within a few-shot setting. As a result, we believe that this underlines the untapped potential of models with stronger inductive biases in few-shot scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07395",
        "abstract url": "https://arxiv.org/abs/2401.07395",
        "title": "Harnessing the Power of Beta Scoring in Deep Active Learning for Multi-Label Text Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Within the scope of natural language processing, the domain of multi-label text classification is uniquely challenging due to its expansive and uneven label distribution. The complexity deepens due to the demand for an extensive set of annotated data for training an advanced deep learning model, especially in specialized fields where the labeling task can be labor-intensive and often requires domain-specific knowledge. Addressing these challenges, our study introduces a novel deep active learning strategy, capitalizing on the Beta family of proper scoring rules within the Expected Loss Reduction framework. It computes the expected increase in scores using the Beta Scoring Rules, which are then transformed into sample vector representations. These vector representations guide the diverse selection of informative samples, directly linking this process to the model's expected proper score. Comprehensive evaluations across both synthetic and real datasets reveal our method's capability to often outperform established acquisition techniques in multi-label text classification, presenting encouraging outcomes across various architectural and dataset scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 pages AAAI 2024"
    },
    {
        "paper id": "2401.07402",
        "abstract url": "https://arxiv.org/abs/2401.07402",
        "title": "Improved Implicit Neural Representation with Fourier Bases Reparameterized Training",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Implicit Neural Representation (INR) as a mighty representation paradigm has achieved success in various computer vision tasks recently. Due to the low-frequency bias issue of vanilla multi-layer perceptron (MLP), existing methods have investigated advanced techniques, such as positional encoding and periodic activation function, to improve the accuracy of INR. In this paper, we connect the network training bias with the reparameterization technique and theoretically prove that weight reparameterization could provide us a chance to alleviate the spectral bias of MLP. Based on our theoretical analysis, we propose a Fourier reparameterization method which learns coefficient matrix of fixed Fourier bases to compose the weights of MLP. We evaluate the proposed Fourier reparameterization method on different INR tasks with various MLP architectures, including vanilla MLP, MLP with positional encoding and MLP with advanced activation function, etc. The superiority approximation results on different MLP architectures clearly validate the advantage of our proposed method. Armed with our Fourier reparameterization method, better INR with more textures and less artifacts can be learned from the training data.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07414",
        "abstract url": "https://arxiv.org/abs/2401.07414",
        "title": "Leveraging the power of transformers for guilt detection in text",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, language models and deep learning techniques have revolutionized natural language processing tasks, including emotion detection. However, the specific emotion of guilt has received limited attention in this field. In this research, we explore the applicability of three transformer-based language models for detecting guilt in text and compare their performance for general emotion detection and guilt detection. Our proposed model outformed BERT and RoBERTa models by two and one points respectively. Additionally, we analyze the challenges in developing accurate guilt-detection models and evaluate our model's effectiveness in detecting related emotions like \"shame\" through qualitative analysis of results.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07426",
        "abstract url": "https://arxiv.org/abs/2401.07426",
        "title": "Generalized Planning for the Abstraction and Reasoning Corpus",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "The Abstraction and Reasoning Corpus (ARC) is a general artificial intelligence benchmark that poses difficulties for pure machine learning methods due to its requirement for fluid intelligence with a focus on reasoning and abstraction. In this work, we introduce an ARC solver, Generalized Planning for Abstract Reasoning (GPAR). It casts an ARC problem as a generalized planning (GP) problem, where a solution is formalized as a planning program with pointers. We express each ARC problem using the standard Planning Domain Definition Language (PDDL) coupled with external functions representing object-centric abstractions. We show how to scale up GP solvers via domain knowledge specific to ARC in the form of restrictions over the actions model, predicates, arguments and valid structure of planning programs. Our experiments demonstrate that GPAR outperforms the state-of-the-art solvers on the object-centric tasks of the ARC, showing the effectiveness of GP and the expressiveness of PDDL to model ARC problems. The challenges provided by the ARC benchmark motivate research to advance existing GP solvers and understand new relations with other planning computational models. Code is available at github.com/you68681/GPAR.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted at AAAI 2024 (extended version)"
    },
    {
        "paper id": "2401.07437",
        "abstract url": "https://arxiv.org/abs/2401.07437",
        "title": "BoNuS: Boundary Mining for Nuclei Segmentation with Partial Point Labels",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Nuclei segmentation is a fundamental prerequisite in the digital pathology workflow. The development of automated methods for nuclei segmentation enables quantitative analysis of the wide existence and large variances in nuclei morphometry in histopathology images. However, manual annotation of tens of thousands of nuclei is tedious and time-consuming, which requires significant amount of human effort and domain-specific expertise. To alleviate this problem, in this paper, we propose a weakly-supervised nuclei segmentation method that only requires partial point labels of nuclei. Specifically, we propose a novel boundary mining framework for nuclei segmentation, named BoNuS, which simultaneously learns nuclei interior and boundary information from the point labels. To achieve this goal, we propose a novel boundary mining loss, which guides the model to learn the boundary information by exploring the pairwise pixel affinity in a multiple-instance learning manner. Then, we consider a more challenging problem, i.e., partial point label, where we propose a nuclei detection module with curriculum learning to detect the missing nuclei with prior morphological knowledge. The proposed method is validated on three public datasets, MoNuSeg, CPM, and CoNIC datasets. Experimental results demonstrate the superior performance of our method to the state-of-the-art weakly-supervised nuclei segmentation methods. Code: https://github.com/hust-linyi/bonus.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE Transactions on Medical Imaging"
    },
    {
        "paper id": "2401.07459",
        "abstract url": "https://arxiv.org/abs/2401.07459",
        "title": "Semantic Segmentation in Multiple Adverse Weather Conditions with Domain Knowledge Retention",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semantic segmentation's performance is often compromised when applied to unlabeled adverse weather conditions. Unsupervised domain adaptation is a potential approach to enhancing the model's adaptability and robustness to adverse weather. However, existing methods encounter difficulties when sequentially adapting the model to multiple unlabeled adverse weather conditions. They struggle to acquire new knowledge while also retaining previously learned knowledge.To address these problems, we propose a semantic segmentation method for multiple adverse weather conditions that incorporates adaptive knowledge acquisition, pseudolabel blending, and weather composition replay. Our adaptive knowledge acquisition enables the model to avoid learning from extreme images that could potentially cause the model to forget. In our approach of blending pseudo-labels, we not only utilize the current model but also integrate the previously learned model into the ongoing learning process. This collaboration between the current teacher and the previous model enhances the robustness of the pseudo-labels for the current target. Our weather composition replay mechanism allows the model to continuously refine its previously learned weather information while simultaneously learning from the new target domain. Our method consistently outperforms the stateof-the-art methods, and obtains the best performance with averaged mIoU (%) of 65.7 and the lowest forgetting (%) of 3.6 against 60.1 and 11.3, on the ACDC datasets for a four-target continual multi-target domain adaptation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07469",
        "abstract url": "https://arxiv.org/abs/2401.07469",
        "title": "A Deep Hierarchical Feature Sparse Framework for Occluded Person Re-Identification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most existing methods tackle the problem of occluded person re-identification (ReID) by utilizing auxiliary models, resulting in a complicated and inefficient ReID framework that is unacceptable for real-time applications. In this work, a speed-up person ReID framework named SUReID is proposed to mitigate occlusion interference while speeding up inference. The SUReID consists of three key components: hierarchical token sparsification (HTS) strategy, non-parametric feature alignment knowledge distillation (NPKD), and noise occlusion data augmentation (NODA). The HTS strategy works by pruning the redundant tokens in the vision transformer to achieve highly effective self-attention computation and eliminate interference from occlusions or background noise. However, the pruned tokens may contain human part features that contaminate the feature representation and degrade the performance. To solve this problem, the NPKD is employed to supervise the HTS strategy, retaining more discriminative tokens and discarding meaningless ones. Furthermore, the NODA is designed to introduce more noisy samples, which further trains the ability of the HTS to disentangle different tokens. Experimental results show that the SUReID achieves superior performance with surprisingly fast inference.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 6 figures"
    },
    {
        "paper id": "2401.07212",
        "abstract url": "https://arxiv.org/abs/2401.07212",
        "title": "HiHPQ: Hierarchical Hyperbolic Product Quantization for Unsupervised Image Retrieval",
        "rating": "0.5",
        "keywords": [
            [
                "AAAI"
            ]
        ],
        "abstract": "Existing unsupervised deep product quantization methods primarily aim for the increased similarity between different views of the identical image, whereas the delicate multi-level semantic similarities preserved between images are overlooked. Moreover, these methods predominantly focus on the Euclidean space for computational convenience, compromising their ability to map the multi-level semantic relationships between images effectively. To mitigate these shortcomings, we propose a novel unsupervised product quantization method dubbed \\textbf{Hi}erarchical \\textbf{H}yperbolic \\textbf{P}roduct \\textbf{Q}uantization (HiHPQ), which learns quantized representations by incorporating hierarchical semantic similarity within hyperbolic geometry. Specifically, we propose a hyperbolic product quantizer, where the hyperbolic codebook attention mechanism and the quantized contrastive learning on the hyperbolic product manifold are introduced to expedite quantization. Furthermore, we propose a hierarchical semantics learning module, designed to enhance the distinction between similar and non-matching images for a query by utilizing the extracted hierarchical semantics as an additional training supervision. Experiments on benchmarks show that our proposed method outperforms state-of-the-art baselines.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.07231",
        "abstract url": "https://arxiv.org/abs/2401.07231",
        "title": "Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes two methods for causal additive models with unobserved variables (CAM-UV). CAM-UV assumes that the causal functions take the form of generalized additive models and that latent confounders are present. First, we propose a method that leverages prior knowledge for efficient causal discovery. Then, we propose an extension of this method for inferring causality in time series data. The original CAM-UV algorithm differs from other existing causal function models in that it does not seek the causal order between observed variables, but rather aims to identify the causes for each observed variable. Therefore, the first proposed method in this paper utilizes prior knowledge, such as understanding that certain variables cannot be causes of specific others. Moreover, by incorporating the prior knowledge that causes precedes their effects in time, we extend the first algorithm to the second method for causal discovery in time series data. We validate the first proposed method by using simulated data to demonstrate that the accuracy of causal discovery increases as more prior knowledge is accumulated. Additionally, we test the second proposed method by comparing it with existing time series causal discovery methods, using both simulated data and real-world data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07249",
        "abstract url": "https://arxiv.org/abs/2401.07249",
        "title": "Imputation with Inter-Series Information from Prototypes for Irregular Sampled Time Series",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Irregularly sampled time series are ubiquitous, presenting significant challenges for analysis due to missing values. Despite existing methods address imputation, they predominantly focus on leveraging intra-series information, neglecting the potential benefits that inter-series information could provide, such as reducing uncertainty and memorization effect. To bridge this gap, we propose PRIME, a Prototype Recurrent Imputation ModEl, which integrates both intra-series and inter-series information for imputing missing values in irregularly sampled time series. Our framework comprises a prototype memory module for learning inter-series information, a bidirectional gated recurrent unit utilizing prototype information for imputation, and an attentive prototypical refinement module for adjusting imputations. We conducted extensive experiments on three datasets, and the results underscore PRIME's superiority over the state-of-the-art models by up to 26% relative improvement on mean square error.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07250",
        "abstract url": "https://arxiv.org/abs/2401.07250",
        "title": "Stabilizing Sharpness-aware Minimization Through A Simple Renormalization Strategy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, sharpness-aware minimization (SAM) has attracted a lot of attention because of its surprising effectiveness in improving generalization performance.However, training neural networks with SAM can be highly unstable since the loss does not decrease along the direction of the exact gradient at the current point, but instead follows the direction of a surrogate gradient evaluated at another point nearby. To address this issue, we propose a simple renormalization strategy, dubbed StableSAM, so that the norm of the surrogate gradient maintains the same as that of the exact gradient. Our strategy is easy to implement and flexible enough to integrate with SAM and its variants, almost at no computational cost. With elementary tools from convex optimization and learning theory, we also conduct a theoretical analysis of sharpness-aware training, revealing that compared to stochastic gradient descent (SGD), the effectiveness of SAM is only assured in a limited regime of learning rate. In contrast, we show how StableSAM extends this regime of learning rate and when it can consistently perform better than SAM with minor modification. Finally, we demonstrate the improved performance of StableSAM on several representative data sets and tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2401.07255",
        "abstract url": "https://arxiv.org/abs/2401.07255",
        "title": "Trust from Ethical Point of View: Exploring Dynamics Through Multiagent-Driven Cognitive Modeling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The paper begins by exploring the rationality of ethical trust as a foundational concept. This involves distinguishing between trust and trustworthiness and delving into scenarios where trust is both rational and moral. It lays the groundwork for understanding the complexities of trust dynamics in decision-making scenarios. Following this theoretical groundwork, we introduce an agent-based simulation framework that investigates these dynamics of ethical trust, specifically in the context of a disaster response scenario. These agents, utilizing emotional models like Plutchik's Wheel of Emotions and memory learning mechanisms, are tasked with allocating limited resources in disaster-affected areas. The model, which embodies the principles discussed in the first section, integrates cognitive load management, Big Five personality traits, and structured interactions within networked or hierarchical settings. It also includes feedback loops and simulates external events to evaluate their impact on the formation and evolution of trust among agents. Through our simulations, we demonstrate the intricate interplay of cognitive, emotional, and social factors in ethical decision-making. These insights shed light on the behaviors and resilience of trust networks in crisis situations, emphasizing the role of rational and moral considerations in the development of trust among autonomous agents. This study contributes to the field by offering an understanding of trust dynamics in socio-technical systems and by providing a robust, adaptable framework capable of addressing ethical dilemmas in disaster response and beyond. The implementation of the algorithms presented in this paper is available at this GitHub repository: \\url{https://github.com/abbas-tari/ethical-trust-cognitive-modeling}.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "10 pages, 8 figures"
    },
    {
        "paper id": "2401.07263",
        "abstract url": "https://arxiv.org/abs/2401.07263",
        "title": "BET: Explaining Deep Reinforcement Learning through The Error-Prone Decisions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the impressive capabilities of Deep Reinforcement Learning (DRL) agents in many challenging scenarios, their black-box decision-making process significantly limits their deployment in safety-sensitive domains. Several previous self-interpretable works focus on revealing the critical states of the agent's decision. However, they cannot pinpoint the error-prone states. To address this issue, we propose a novel self-interpretable structure, named Backbone Extract Tree (BET), to better explain the agent's behavior by identify the error-prone states. At a high level, BET hypothesizes that states in which the agent consistently executes uniform decisions exhibit a reduced propensity for errors. To effectively model this phenomenon, BET expresses these states within neighborhoods, each defined by a curated set of representative states. Therefore, states positioned at a greater distance from these representative benchmarks are more prone to error. We evaluate BET in various popular RL environments and show its superiority over existing self-interpretable models in terms of explanation fidelity. Furthermore, we demonstrate a use case for providing explanations for the agents in StarCraft II, a sophisticated multi-agent cooperative game. To the best of our knowledge, we are the first to explain such a complex scenarios using a fully transparent structure.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This is an early version of a paper that submitted to IJCAI 2024 8 pages, 4 figures and 1 table"
    },
    {
        "paper id": "2401.07298",
        "abstract url": "https://arxiv.org/abs/2401.07298",
        "title": "Efficient Frameworks for Generalized Low-Rank Matrix Bandit Problems",
        "rating": "0.5",
        "keywords": [
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In the stochastic contextual low-rank matrix bandit problem, the expected reward of an action is given by the inner product between the action's feature matrix and some fixed, but initially unknown $d_1$ by $d_2$ matrix $\u0398^*$ with rank $r \\ll \\{d_1, d_2\\}$, and an agent sequentially takes actions based on past experience to maximize the cumulative reward. In this paper, we study the generalized low-rank matrix bandit problem, which has been recently proposed in \\cite{lu2021low} under the Generalized Linear Model (GLM) framework. To overcome the computational infeasibility and theoretical restrain of existing algorithms on this problem, we first propose the G-ESTT framework that modifies the idea from \\cite{jun2019bilinear} by using Stein's method on the subspace estimation and then leverage the estimated subspaces via a regularization idea. Furthermore, we remarkably improve the efficiency of G-ESTT by using a novel exclusion idea on the estimated subspace instead, and propose the G-ESTS framework. We also show that G-ESTT can achieve the $\\tilde{O}(\\sqrt{(d_1+d_2)MrT})$ bound of regret while G-ESTS can achineve the $\\tilde{O}(\\sqrt{(d_1+d_2)^{3/2}Mr^{3/2}T})$ bound of regret under mild assumption up to logarithm terms, where $M$ is some problem dependent value. Under a reasonable assumption that $M = O((d_1+d_2)^2)$ in our problem setting, the regret of G-ESTT is consistent with the current best regret of $\\tilde{O}((d_1+d_2)^{3/2} \\sqrt{rT}/D_{rr})$~\\citep{lu2021low} ($D_{rr}$ will be defined later). For completeness, we conduct experiments to illustrate that our proposed algorithms, especially G-ESTS, are also computationally tractable and consistently outperform other state-of-the-art (generalized) linear matrix bandit methods based on a suite of simulations.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "Revision of the paper accepted by NeurIPS 2022"
    },
    {
        "paper id": "2401.07324",
        "abstract url": "https://arxiv.org/abs/2401.07324",
        "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "On progress, github repo: https://github.com/X-PLUG/Multi-LLM-Agent"
    },
    {
        "paper id": "2401.07348",
        "abstract url": "https://arxiv.org/abs/2401.07348",
        "title": "Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The advent of Generative AI, particularly through Large Language Models (LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI landscape. Advanced LLMs exhibit multimodality, handling diverse data formats, thereby broadening their application scope. However, the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance. This paper delves into the legal and regulatory implications of Generative AI and LLMs in the European Union context, analyzing aspects of liability, privacy, intellectual property, and cybersecurity. It critically examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA) draft, in addressing the unique challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the legislative framework and proposes recommendations to ensure the safe and compliant deployment of generative models, ensuring they align with the EU's evolving digital landscape and legal standards.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07359",
        "abstract url": "https://arxiv.org/abs/2401.07359",
        "title": "Reliability and Interpretability in Science and Deep Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In recent years, the question of the reliability of Machine Learning (ML) methods has acquired significant importance, and the analysis of the associated uncertainties has motivated a growing amount of research. However, most of these studies have applied standard error analysis to ML models, and in particular Deep Neural Network (DNN) models, which represent a rather significant departure from standard scientific modelling. It is therefore necessary to integrate the standard error analysis with a deeper epistemological analysis of the possible differences between DNN models and standard scientific modelling and the possible implications of these differences in the assessment of reliability. This article offers several contributions. First, it emphasises the ubiquitous role of model assumptions (both in ML and traditional Science) against the illusion of theory-free science. Secondly, model assumptions are analysed from the point of view of their (epistemic) complexity, which is shown to be language-independent. It is argued that the high epistemic complexity of DNN models hinders the estimate of their reliability and also their prospect of long-term progress. Some potential ways forward are suggested. Thirdly, this article identifies the close relation between a model's epistemic complexity and its interpretability, as introduced in the context of responsible AI. This clarifies in which sense, and to what extent, the lack of understanding of a model (black-box problem) impacts its interpretability in a way that is independent of individual skills. It also clarifies how interpretability is a precondition for assessing the reliability of any model, which cannot be based on statistical analysis alone. This article focuses on the comparison between traditional scientific models and DNN models. But, Random Forest and Logistic Regression models are also briefly considered.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Minor clarifications in Sec. 4.1. Misleading table removed"
    },
    {
        "paper id": "2401.07364",
        "abstract url": "https://arxiv.org/abs/2401.07364",
        "title": "PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Can we build a single large model for a wide range of PDE-related scientific learning tasks? Can this model generalize to new PDEs, even of new forms, without any fine-tuning? In-context operator learning and the corresponding model In-Context Operator Networks (ICON) represent an initial exploration of these questions. The capability of ICON regarding the first question has been demonstrated previously. In this paper, we present a detailed methodology for solving PDE problems with ICON, and show how a single ICON model can make forward and reverse predictions for different equations with different strides, provided with appropriately designed data prompts. We show the positive evidence to the second question, i.e., ICON can generalize well to some PDEs with new forms without any fine-tuning. This is exemplified through a study on 1D scalar nonlinear conservation laws, a family of PDEs with temporal evolution. We also show how to broaden the range of problems that an ICON model can address, by transforming functions and equations to ICON's capability scope. We believe that the progress in this paper is a significant step towards the goal of training a foundation model for PDE-related tasks under the in-context operator learning framework.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07369",
        "abstract url": "https://arxiv.org/abs/2401.07369",
        "title": "CoVO-MPC: Theoretical Analysis of Sampling-based MPC and Optimal Covariance Design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sampling-based Model Predictive Control (MPC) has been a practical and effective approach in many domains, notably model-based reinforcement learning, thanks to its flexibility and parallelizability. Despite its appealing empirical performance, the theoretical understanding, particularly in terms of convergence analysis and hyperparameter tuning, remains absent. In this paper, we characterize the convergence property of a widely used sampling-based MPC method, Model Predictive Path Integral Control (MPPI). We show that MPPI enjoys at least linear convergence rates when the optimization is quadratic, which covers time-varying LQR systems. We then extend to more general nonlinear systems. Our theoretical analysis directly leads to a novel sampling-based MPC algorithm, CoVariance-Optimal MPC (CoVo-MPC) that optimally schedules the sampling covariance to optimize the convergence rate. Empirically, CoVo-MPC significantly outperforms standard MPPI by 43-54% in both simulations and real-world quadrotor agile control tasks. Videos and Appendices are available at \\url{https://lecar-lab.github.io/CoVO-MPC/}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "32 pages, 4 figures"
    },
    {
        "paper id": "2401.07386",
        "abstract url": "https://arxiv.org/abs/2401.07386",
        "title": "How do machines learn? Evaluating the AIcon2abs method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper evaluates AI from concrete to Abstract (Queiroz et al. 2021), a recently proposed method that enables awareness among the general public on machine learning. Such is possible due to the use of WiSARD, an easily understandable machine learning mechanism, thus requiring little effort and no technical background from the target users. WiSARD is adherent to digital computing; training consists of writing to RAM-type memories, and classification consists of reading from these memories. The model enables easy visualization and understanding of training and classification tasks' internal realization through ludic activities. Furthermore, the WiSARD model does not require an Internet connection for training and classification, and it can learn from a few or one example. WiSARD can also create \"mental images\" of what it has learned so far, evidencing key features pertaining to a given class. The AIcon2abs method's effectiveness was assessed through the evaluation of a remote course with a workload of approximately 6 hours. It was completed by thirty-four Brazilian subjects: 5 children between 8 and 11 years old; 5 adolescents between 12 and 17 years old; and 24 adults between 21 and 72 years old. The collected data was analyzed from two perspectives: (i) from the perspective of a pre-experiment (of a mixed methods nature) and (ii) from a phenomenological perspective (of a qualitative nature). AIcon2abs was well-rated by almost 100% of the research subjects, and the data collected revealed quite satisfactory results concerning the intended outcomes. This research has been approved by the CEP/HUCFF/FM/UFRJ Human Research Ethics Committee.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07387",
        "abstract url": "https://arxiv.org/abs/2401.07387",
        "title": "Optimising network interactions through device agnostic models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physically implemented neural networks hold the potential to achieve the performance of deep learning models by exploiting the innate physical properties of devices as computational tools. This exploration of physical processes for computation requires to also consider their intrinsic dynamics, which can serve as valuable resources to process information. However, existing computational methods are unable to extend the success of deep learning techniques to parameters influencing device dynamics, which often lack a precise mathematical description. In this work, we formulate a universal framework to optimise interactions with dynamic physical systems in a fully data-driven fashion. The framework adopts neural stochastic differential equations as differentiable digital twins, effectively capturing both deterministic and stochastic behaviours of devices. Employing differentiation through the trained models provides the essential mathematical estimates for optimizing a physical neural network, harnessing the intrinsic temporal computation abilities of its physical nodes. To accurately model real devices' behaviours, we formulated neural-SDE variants that can operate under a variety of experimental settings. Our work demonstrates the framework's applicability through simulations and physical implementations of interacting dynamic devices, while highlighting the importance of accurately capturing system stochasticity for the successful deployment of a physically defined neural network.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07390",
        "abstract url": "https://arxiv.org/abs/2401.07390",
        "title": "Knee or ROC",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Self-attention transformers have demonstrated accuracy for image classification with smaller data sets. However, a limitation is that tests to-date are based upon single class image detection with known representation of image populations. For instances where the input image classes may be greater than one and test sets that lack full information on representation of image populations, accuracy calculations must adapt. The Receiver Operating Characteristic (ROC) accuracy thresh-old can address the instances of multi-class input images. However, this approach is unsuitable in instances where image population representation is unknown. We consider calculating accuracy using the knee method to determine threshold values on an ad-hoc basis. Results of ROC curve and knee thresholds for a multi-class data set, created from CIFAR-10 images, are discussed for multi-class image detection.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2401.07468",
        "abstract url": "https://arxiv.org/abs/2401.07468",
        "title": "CarSpeedNet: A Deep Neural Network-based Car Speed Estimation from Smartphone Accelerometer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, a novel deep neural network (DNN) architecture, CarSpeedNet, is introduced to estimate car speed using three-axis accelerometer data from smartphones. Utilizing 13 hours of data collected from smartphones mounted in vehicles navigating through various regions in Israel, the CarSpeedNet effectively learns the relationship between measured smartphone acceleration and car speed. Ground truth speed data was obtained at 1[Hz] from the GPS receiver in the smartphones. The proposed model enables high-frequency speed estimation, incorporating historical inputs. Our trained model demonstrates exceptional accuracy in car speed estimation, achieving a precision of less than 0.72[m/s] during an extended driving test, solely relying on smartphone accelerometer data without any connectivity to the car.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2401.08703",
        "abstract url": "https://arxiv.org/abs/2401.08703",
        "title": "Decoupled Prototype Learning for Reliable Test-Time Adaptation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Test-time adaptation (TTA) is a task that continually adapts a pre-trained source model to the target domain during inference. One popular approach involves fine-tuning model with cross-entropy loss according to estimated pseudo-labels. However, its performance is significantly affected by noisy pseudo-labels. This study reveals that minimizing the classification error of each sample causes the cross-entropy loss's vulnerability to label noise. To address this issue, we propose a novel Decoupled Prototype Learning (DPL) method that features prototype-centric loss computation. First, we decouple the optimization of class prototypes. For each class prototype, we reduce its distance with positive samples and enlarge its distance with negative samples in a contrastive manner. This strategy prevents the model from overfitting to noisy pseudo-labels. Second, we propose a memory-based strategy to enhance DPL's robustness for the small batch sizes often encountered in TTA. We update each class's pseudo-feature from a memory in a momentum manner and insert an additional DPL loss. Finally, we introduce a consistency regularization-based approach to leverage samples with unconfident pseudo-labels. This approach transfers feature styles of samples with unconfident pseudo-labels to those with confident pseudo-labels. Thus, more reliable samples for TTA are created. The experimental results demonstrate that our methods achieve state-of-the-art performance on domain generalization benchmarks, and reliably improve the performance of self-training-based methods on image corruption benchmarks. The code will be released.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 5 figures"
    },
    {
        "paper id": "2401.07218",
        "abstract url": "https://arxiv.org/abs/2401.07218",
        "title": "Self-supervised Event-based Monocular Depth Estimation using Cross-modal Consistency",
        "rating": "0",
        "keywords": [
            [
                "Depth",
                "event camera"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "An event camera is a novel vision sensor that can capture per-pixel brightness changes and output a stream of asynchronous ``events''. It has advantages over conventional cameras in those scenes with high-speed motions and challenging lighting conditions because of the high temporal resolution, high dynamic range, low bandwidth, low power consumption, and no motion blur. Therefore, several supervised monocular depth estimation from events is proposed to address scenes difficult for conventional cameras. However, depth annotation is costly and time-consuming. In this paper, to lower the annotation cost, we propose a self-supervised event-based monocular depth estimation framework named EMoDepth. EMoDepth constrains the training process using the cross-modal consistency from intensity frames that are aligned with events in the pixel coordinate. Moreover, in inference, only events are used for monocular depth prediction. Additionally, we design a multi-scale skip-connection architecture to effectively fuse features for depth estimation while maintaining high inference speed. Experiments on MVSEC and DSEC datasets demonstrate that our contributions are effective and that the accuracy can outperform existing supervised event-based and unsupervised frame-based methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IROS2023"
    },
    {
        "paper id": "2401.07237",
        "abstract url": "https://arxiv.org/abs/2401.07237",
        "title": "Distilling Event Sequence Knowledge From Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Event sequence models have been found to be highly effective in the analysis and prediction of events. Building such models requires availability of abundant high-quality event sequence data. In certain applications, however, clean structured event sequences are not available, and automated sequence extraction results in data that is too noisy and incomplete. In this work, we explore the use of Large Language Models (LLMs) to generate event sequences that can effectively be used for probabilistic event model construction. This can be viewed as a mechanism of distilling event sequence knowledge from LLMs. Our approach relies on a Knowledge Graph (KG) of event concepts with partial causal relations to guide the generative language model for causal event sequence generation. We show that our approach can generate high-quality event sequences, filling a knowledge gap in the input KG. Furthermore, we explore how the generated sequences can be leveraged to discover useful and more complex structured knowledge from pattern mining and probabilistic event models. We release our sequence generation code and evaluation framework, as well as corpus of event sequence data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2401.07240",
        "abstract url": "https://arxiv.org/abs/2401.07240",
        "title": "DCDet: Dynamic Cross-based 3D Object Detector",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, significant progress has been made in the research of 3D object detection. However, most prior studies have focused on the utilization of center-based or anchor-based label assignment schemes. Alternative label assignment strategies remain unexplored in 3D object detection. We find that the center-based label assignment often fails to generate sufficient positive samples for training, while the anchor-based label assignment tends to encounter an imbalanced issue when handling objects of varying scales. To solve these issues, we introduce a dynamic cross label assignment (DCLA) scheme, which dynamically assigns positive samples for each object from a cross-shaped region, thus providing sufficient and balanced positive samples for training. Furthermore, to address the challenge of accurately regressing objects with varying scales, we put forth a rotation-weighted Intersection over Union (RWIoU) metric to replace the widely used L1 metric in regression loss. Extensive experiments demonstrate the generality and effectiveness of our DCLA and RWIoU-based regression loss. The Code will be available at https://github.com/Say2L/DCDet.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07251",
        "abstract url": "https://arxiv.org/abs/2401.07251",
        "title": "3D Landmark Detection on Human Point Clouds: A Benchmark and A Dual Cascade Point Transformer Framework",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D landmark detection plays a pivotal role in various applications such as 3D registration, pose estimation, and virtual try-on. While considerable success has been achieved in 2D human landmark detection or pose estimation, there is a notable scarcity of reported works on landmark detection in unordered 3D point clouds. This paper introduces a novel challenge, namely 3D landmark detection on human point clouds, presenting two primary contributions. Firstly, we establish a comprehensive human point cloud dataset, named HPoint103, designed to support the 3D landmark detection community. This dataset comprises 103 human point clouds created with commercial software and actors, each manually annotated with 11 stable landmarks. Secondly, we propose a Dual Cascade Point Transformer (D-CPT) model for precise point-based landmark detection. D-CPT gradually refines the landmarks through cascade Transformer decoder layers across the entire point cloud stream, simultaneously enhancing landmark coordinates with a RefineNet over local regions. Comparative evaluations with popular point-based methods on HPoint103 and the public dataset DHP19 demonstrate the dramatic outperformance of our D-CPT. Additionally, the integration of our RefineNet into existing methods consistently improves performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07272",
        "abstract url": "https://arxiv.org/abs/2401.07272",
        "title": "City Scene Super-Resolution via Geometric Error Minimization",
        "rating": "0",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Super-resolution techniques are crucial in improving image granularity, particularly in complex urban scenes, where preserving geometric structures is vital for data-informed cultural heritage applications. In this paper, we propose a city scene super-resolution method via geometric error minimization. The geometric-consistent mechanism leverages the Hough Transform to extract regular geometric features in city scenes, enabling the computation of geometric errors between low-resolution and high-resolution images. By minimizing mixed mean square error and geometric align error during the super-resolution process, the proposed method efficiently restores details and geometric regularities. Extensive validations on the SET14, BSD300, Cityscapes and GSV-Cities datasets demonstrate that the proposed method outperforms existing state-of-the-art methods, especially in urban scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "26 pages, 10 figures"
    },
    {
        "paper id": "2401.07322",
        "abstract url": "https://arxiv.org/abs/2401.07322",
        "title": "RSUD20K: A Dataset for Road Scene Understanding In Autonomous Driving",
        "rating": "0",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Road scene understanding is crucial in autonomous driving, enabling machines to perceive the visual environment. However, recent object detectors tailored for learning on datasets collected from certain geographical locations struggle to generalize across different locations. In this paper, we present RSUD20K, a new dataset for road scene understanding, comprised of over 20K high-resolution images from the driving perspective on Bangladesh roads, and includes 130K bounding box annotations for 13 objects. This challenging dataset encompasses diverse road scenes, narrow streets and highways, featuring objects from different viewpoints and scenes from crowded environments with densely cluttered objects and various weather conditions. Our work significantly improves upon previous efforts, providing detailed annotations and increased object complexity. We thoroughly examine the dataset, benchmarking various state-of-the-art object detectors and exploring large vision models as image annotators.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07323",
        "abstract url": "https://arxiv.org/abs/2401.07323",
        "title": "MapNeXt: Revisiting Training and Scaling Practices for Online Vectorized HD Map Construction",
        "rating": "0",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "High-Definition (HD) maps are pivotal to autopilot navigation. Integrating the capability of lightweight HD map construction at runtime into a self-driving system recently emerges as a promising direction. In this surge, vision-only perception stands out, as a camera rig can still perceive the stereo information, let alone its appealing signature of portability and economy. The latest MapTR architecture solves the online HD map construction task in an end-to-end fashion but its potential is yet to be explored. In this work, we present a full-scale upgrade of MapTR and propose MapNeXt, the next generation of HD map learning architecture, delivering major contributions from the model training and scaling perspectives. After shedding light on the training dynamics of MapTR and exploiting the supervision from map elements thoroughly, MapNeXt-Tiny raises the mAP of MapTR-Tiny from 49.0% to 54.8%, without any architectural modifications. Enjoying the fruit of map segmentation pre-training, MapNeXt-Base further lifts the mAP up to 63.9% that has already outperformed the prior art, a multi-modality MapTR, by 1.4% while being $\\sim1.8\\times$ faster. Towards pushing the performance frontier to the next level, we draw two conclusions on practical model scaling: increased query favors a larger decoder network for adequate digestion; a large backbone steadily promotes the final accuracy without bells and whistles. Building upon these two rules of thumb, MapNeXt-Huge achieves state-of-the-art performance on the challenging nuScenes benchmark. Specifically, we push the mapless vision-only single-model performance to be over 78% for the first time, exceeding the best model from existing methods by 16%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07326",
        "abstract url": "https://arxiv.org/abs/2401.07326",
        "title": "Beyond Traditional Approaches: Multi-Task Network for Breast Ultrasound Diagnosis",
        "rating": "0",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "Diagnosis",
                "cancer",
                "tumor"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Breast Ultrasound plays a vital role in cancer diagnosis as a non-invasive approach with cost-effective. In recent years, with the development of deep learning, many CNN-based approaches have been widely researched in both tumor localization and cancer classification tasks. Even though previous single models achieved great performance in both tasks, these methods have some limitations in inference time, GPU requirement, and separate fine-tuning for each model. In this study, we aim to redesign and build end-to-end multi-task architecture to conduct both segmentation and classification. With our proposed approach, we achieved outstanding performance and time efficiency, with 79.8% and 86.4% in DeepLabV3+ architecture in the segmentation task.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "7 pages, 3 figures"
    },
    {
        "paper id": "2401.07358",
        "abstract url": "https://arxiv.org/abs/2401.07358",
        "title": "Harnessing Machine Learning for Discerning AI-Generated Synthetic Images",
        "rating": "0",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of digital media, the advent of AI-generated synthetic images has introduced significant challenges in distinguishing between real and fabricated visual content. These images, often indistinguishable from authentic ones, pose a threat to the credibility of digital media, with potential implications for disinformation and fraud. Our research addresses this challenge by employing machine learning techniques to discern between AI-generated and genuine images. Central to our approach is the CIFAKE dataset, a comprehensive collection of images labeled as \"Real\" and \"Fake\". We refine and adapt advanced deep learning architectures like ResNet, VGGNet, and DenseNet, utilizing transfer learning to enhance their precision in identifying synthetic images. We also compare these with a baseline model comprising a vanilla Support Vector Machine (SVM) and a custom Convolutional Neural Network (CNN). The experimental results were significant, demonstrating that our optimized deep learning models outperform traditional methods, with DenseNet achieving an accuracy of 97.74%. Our application study contributes by applying and optimizing these advanced models for synthetic image detection, conducting a comparative analysis using various metrics, and demonstrating their superior capability in identifying AI-generated images over traditional machine learning techniques. This research not only advances the field of digital media integrity but also sets a foundation for future explorations into the ethical and technical dimensions of AI-generated content in digital media.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07439",
        "abstract url": "https://arxiv.org/abs/2401.07439",
        "title": "Mask-adaptive Gated Convolution and Bi-directional Progressive Fusion Network for Depth Completion",
        "rating": "0",
        "keywords": [
            [
                "RGB-D",
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Depth completion is a critical task for handling depth images with missing pixels, which can negatively impact further applications. Recent approaches have utilized Convolutional Neural Networks (CNNs) to reconstruct depth images with the assistance of color images. However, vanilla convolution has non-negligible drawbacks in handling missing pixels. To solve this problem, we propose a new model for depth completion based on an encoder-decoder structure. Our model introduces two key components: the Mask-adaptive Gated Convolution (MagaConv) architecture and the Bi-directional Progressive Fusion (BP-Fusion) module. The MagaConv architecture is designed to acquire precise depth features by modulating convolution operations with iteratively updated masks, while the BP-Fusion module progressively integrates depth and color features, utilizing consecutive bi-directional fusion structures in a global perspective. Extensive experiments on popular benchmarks, including NYU-Depth V2, DIML, and SUN RGB-D, demonstrate the superiority of our model over state-of-the-art methods. We achieved remarkable performance in completing depth maps and outperformed existing approaches in terms of accuracy and reliability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07441",
        "abstract url": "https://arxiv.org/abs/2401.07441",
        "title": "Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality Assurance",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the era of large AI models, the complex architecture and vast parameters present substantial challenges for effective AI quality management (AIQM), e.g. large language model (LLM). This paper focuses on investigating the quality assurance of a specific LLM-based AI product--a ChatGPT-based sentiment analysis system. The study delves into stability issues related to both the operation and robustness of the expansive AI model on which ChatGPT is based. Experimental analysis is conducted using benchmark datasets for sentiment analysis. The results reveal that the constructed ChatGPT-based sentiment analysis system exhibits uncertainty, which is attributed to various operational factors. It demonstrated that the system also exhibits stability issues in handling conventional small text attacks involving robustness.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07450",
        "abstract url": "https://arxiv.org/abs/2401.07450",
        "title": "Hierarchical Fashion Design with Multi-stage Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cross-modal fashion synthesis and editing offer intelligent support to fashion designers by enabling the automatic generation and local modification of design drafts.While current diffusion models demonstrate commendable stability and controllability in image synthesis,they still face significant challenges in generating fashion design from abstract design elements and fine-grained editing.Abstract sensory expressions, \\eg office, business, and party, form the high-level design concepts, while measurable aspects like sleeve length, collar type, and pant length are considered the low-level attributes of clothing.Controlling and editing fashion images using lengthy text descriptions poses a difficulty.In this paper, we propose HieraFashDiff,a novel fashion design method using the shared multi-stage diffusion model encompassing high-level design concepts and low-level clothing attributes in a hierarchical structure.Specifically, we categorized the input text into different levels and fed them in different time step to the diffusion model according to the criteria of professional clothing designers.HieraFashDiff allows designers to add low-level attributes after high-level prompts for interactive editing incrementally.In addition, we design a differentiable loss function in the sampling process with a mask to keep non-edit areas.Comprehensive experiments performed on our newly conducted Hierarchical fashion dataset,demonstrate that our proposed method outperforms other state-of-the-art competitors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07453",
        "abstract url": "https://arxiv.org/abs/2401.07453",
        "title": "Model Editing at Scale leads to Gradual and Catastrophic Forgetting",
        "rating": "0",
        "keywords": [
            [
                "Model Editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgetting phase. Both gradual and catastrophic forgetting limit the usefulness of model editing methods at scale -- the former making model editing less effective as multiple edits are made to the model while the latter caps the scalability of such model editing methods. Our analysis also highlights other key limitations of ROME and MEMIT at scale. With our work, we push for the development and evaluation of model editing methods keeping scalability in mind.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Added experiments with GPT-J and appendix for all samples and ablations"
    },
    {
        "paper id": "2401.07456",
        "abstract url": "https://arxiv.org/abs/2401.07456",
        "title": "Only Send What You Need: Learning to Communicate Efficiently in Federated Multilingual Machine Translation",
        "rating": "0",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Federated learning (FL) is a promising approach for solving multilingual tasks, potentially enabling clients with their own language-specific data to collaboratively construct a high-quality neural machine translation (NMT) model. However, communication constraints in practical network systems present challenges for exchanging large-scale NMT engines between FL parties. In this paper, we propose a meta-learning-based adaptive parameter selection methodology, MetaSend, that improves the communication efficiency of model transmissions from clients during FL-based multilingual NMT training. Our approach learns a dynamic threshold for filtering parameters prior to transmission without compromising the NMT model quality, based on the tensor deviations of clients between different FL rounds. Through experiments on two NMT datasets with different language distributions, we demonstrate that MetaSend obtains substantial improvements over baselines in translation quality in the presence of a limited communication budget.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07314",
        "abstract url": "https://arxiv.org/abs/2401.07314",
        "title": "MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation",
        "rating": "-0.5",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Embodied agents equipped with GPT as their brain have exhibited extraordinary decision-making and generalization abilities across various tasks. However, existing zero-shot agents for vision-and-language navigation (VLN) only prompt the GPT-4 to select potential locations within localized environments, without constructing an effective \"global-view\" for the agent to understand the overall environment. In this work, we present a novel map-guided GPT-based agent, dubbed MapGPT, which introduces an online linguistic-formed map to encourage the global exploration. Specifically, we build an online map and incorporate it into the prompts that include node information and topological relationships, to help GPT understand the spatial environment. Benefiting from this design, we further propose an adaptive planning mechanism to assist the agent in performing multi-step path planning based on a map, systematically exploring multiple candidate nodes or sub-goals step by step. Extensive experiments demonstrate that our MapGPT is applicable to both GPT-4 and GPT-4V, achieving state-of-the-art zero-shot performance on the R2R and REVERIE simultaneously (~10% and ~12% improvements in SR), and showcasing the newly emerged global thinking and path planning abilities of the GPT.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07316",
        "abstract url": "https://arxiv.org/abs/2401.07316",
        "title": "Finding Privacy-relevant Source Code",
        "rating": "-0.5",
        "keywords": [
            [
                "Workshop"
            ]
        ],
        "abstract": "Privacy code review is a critical process that enables developers and legal experts to ensure compliance with data protection regulations. However, the task is challenging due to resource constraints. To address this, we introduce the concept of privacy-relevant methods - specific methods in code that are directly involved in the processing of personal data. We then present an automated approach to assist in code review by identifying and categorizing these privacy-relevant methods in source code. Using static analysis, we identify a set of methods based on their occurrences in 50 commonly used libraries. We then rank these methods according to their frequency of invocation with actual personal data in the top 30 GitHub applications. The highest-ranked methods are the ones we designate as privacy-relevant in practice. For our evaluation, we examined 100 open-source applications and found that our approach identifies fewer than 5% of the methods as privacy-relevant for personal data processing. This reduces the time required for code reviews. Case studies on Signal Desktop and Cal.com further validate the effectiveness of our approach in aiding code reviewers to produce enhanced reports that facilitate compliance with privacy regulations.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by the 2nd International Workshop on Mining Software Repositories Applications for Privacy and Security"
    },
    {
        "paper id": "2401.07371",
        "abstract url": "https://arxiv.org/abs/2401.07371",
        "title": "A Data-driven Resilience Framework of Directionality Configuration based on Topological Credentials in Road Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Roadway reconfiguration is a crucial aspect of transportation planning, aiming to enhance traffic flow, reduce congestion, and improve overall road network performance with existing infrastructure and resources. This paper presents a novel roadway reconfiguration technique by integrating optimization based Brute Force search approach and decision support framework to rank various roadway configurations for better performance. The proposed framework incorporates a multi-criteria decision analysis (MCDA) approach, combining input from generated scenarios during the optimization process. By utilizing data from optimization, the model identifies total betweenness centrality (TBC), system travel time (STT), and total link traffic flow (TLTF) as the most influential decision variables. The developed framework leverages graph theory to model the transportation network topology and apply network science metrics as well as stochastic user equilibrium traffic assignment to assess the impact of each roadway configuration on the overall network performance. To rank the roadway configurations, the framework employs machine learning algorithms, such as ridge regression, to determine the optimal weights for each criterion (i.e., TBC, STT, TLTF). Moreover, the network-based analysis ensures that the selected configurations not only optimize individual roadway segments but also enhance system-level efficiency, which is particularly helpful as the increasing frequency and intensity of natural disasters and other disruptive events underscore the critical need for resilient transportation networks. By integrating multi-criteria decision analysis, machine learning, and network science metrics, the proposed framework would enable transportation planners to make informed and data-driven decisions, leading to more sustainable, efficient, and resilient roadway configurations.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "103rd Transportation Research Board (TRB) Annual Meeting"
    },
    {
        "paper id": "2401.07410",
        "abstract url": "https://arxiv.org/abs/2401.07410",
        "title": "Multi-Task DNS Security Analysis via High-Order Heterogeneous Graph Embedding",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "DNS is an essential Internet infrastructure to support network applications and services, but is also a significant tool exploited by various cyberattacks. Existing DNS security analysis techniques mostly focus on one specific task associated with one single entity (e.g., domain) via conventional feature engineering. They rely heavily on the labor-intensive feature selection and largely ignore the intrinsic correlations among the heterogeneous DNS entities (e.g., domain and IP). In this paper, I explore the potential of heterogeneous graph embedding to automatically learn the behavior features of multiple DNS entities, and to simultaneously support more than one security tasks. Considering the joint optimization of malicious domain detection and IP reputation evaluation as an example, I propose a novel joint DNS embedding (JDE) model to formulate the DNS query behavior via a similarity-enhanced graph with heterogeneous entities. The random walk technique is applied to the heterogeneous graph to comprehensively explore the hidden homogeneous and heterogeneous high-order proximities among domains and IPs. Extensive experiments on real DNS traffic demonstrate that the joint optimization of multiple tasks with the latent high-order proximities can lead to better security analysis performance for all the tasks than respectively optimizing each single task with the observable low-order proximity.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07448",
        "abstract url": "https://arxiv.org/abs/2401.07448",
        "title": "Formal Logic Enabled Personalized Federated Learning Through Property Inference",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advancements in federated learning (FL) have greatly facilitated the development of decentralized collaborative applications, particularly in the domain of Artificial Intelligence of Things (AIoT). However, a critical aspect missing from the current research landscape is the ability to enable data-driven client models with symbolic reasoning capabilities. Specifically, the inherent heterogeneity of participating client devices poses a significant challenge, as each client exhibits unique logic reasoning properties. Failing to consider these device-specific specifications can result in critical properties being missed in the client predictions, leading to suboptimal performance. In this work, we propose a new training paradigm that leverages temporal logic reasoning to address this issue. Our approach involves enhancing the training process by incorporating mechanically generated logic expressions for each FL client. Additionally, we introduce the concept of aggregation clusters and develop a partitioning algorithm to effectively group clients based on the alignment of their temporal reasoning properties. We evaluate the proposed method on two tasks: a real-world traffic volume prediction task consisting of sensory data from fifteen states and a smart city multi-task prediction utilizing synthetic data. The evaluation results exhibit clear improvements, with performance accuracy improved by up to 54% across all sequential prediction models.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01662",
        "abstract url": "https://arxiv.org/abs/2402.01662",
        "title": "Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "As AI systems quickly improve in both breadth and depth of performance, they lend themselves to creating increasingly powerful and realistic agents, including the possibility of agents modeled on specific people. We anticipate that within our lifetimes it may become common practice for people to create a custom AI agent to interact with loved ones and/or the broader world after death. We call these generative ghosts, since such agents will be capable of generating novel content rather than merely parroting content produced by their creator while living. In this paper, we first discuss the design space of potential implementations of generative ghosts. We then discuss the practical and ethical implications of generative ghosts, including potential positive and negative impacts on individuals and society. Based on these considerations, we lay out a research agenda for the AI and HCI research communities to empower people to create and interact with AI afterlives in a safe and beneficial manner.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "version 2, updated May 8, 2024 to included updated references and new case study pointers as the trend of generative ghosts accelerates"
    },
    {
        "paper id": "2401.07222",
        "abstract url": "https://arxiv.org/abs/2401.07222",
        "title": "Robust Data-Driven Predictive Control for Unknown Linear Time-Invariant Systems",
        "rating": "-1",
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "This paper presents a new robust data-driven predictive control scheme for unknown linear time-invariant systems by using input-state-output or input-output data based on whether the state is measurable. To remove the need for the persistently exciting (PE) condition of a sufficiently high order on pre-collected data, a set containing all systems capable of generating such data is constructed. Then, at each time step, an upper bound of a given objective function is derived for all systems in the set, and a feedback controller is designed to minimize this bound. The optimal control gain at each time step is determined by solving a set of linear matrix inequalities. We prove that if the synthesis problem is feasible at the initial time step, it remains feasible for all future time steps. Unlike current data-driven predictive control schemes based on behavioral system theory, our approach requires less stringent conditions for the pre-collected data, facilitating easier implementation. Further, the proposed predictive control scheme features an infinite prediction horizon, potentially resulting in superior overall control performance compared to existing methods with finite prediction horizons. The effectiveness of our proposed methods is demonstrated through application to an unknown and unstable batch reactor.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07245",
        "abstract url": "https://arxiv.org/abs/2401.07245",
        "title": "MIMIC: Mask Image Pre-training with Mix Contrastive Fine-tuning for Facial Expression Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cutting-edge research in facial expression recognition (FER) currently favors the utilization of convolutional neural networks (CNNs) backbone which is supervisedly pre-trained on face recognition datasets for feature extraction. However, due to the vast scale of face recognition datasets and the high cost associated with collecting facial labels, this pre-training paradigm incurs significant expenses. Towards this end, we propose to pre-train vision Transformers (ViTs) through a self-supervised approach on a mid-scale general image dataset. In addition, when compared with the domain disparity existing between face datasets and FER datasets, the divergence between general datasets and FER datasets is more pronounced. Therefore, we propose a contrastive fine-tuning approach to effectively mitigate this domain disparity. Specifically, we introduce a novel FER training paradigm named Mask Image pre-training with MIx Contrastive fine-tuning (MIMIC). In the initial phase, we pre-train the ViT via masked image reconstruction on general images. Subsequently, in the fine-tuning stage, we introduce a mix-supervised contrastive learning process, which enhances the model with a more extensive range of positive samples by the mixing strategy. Through extensive experiments conducted on three benchmark datasets, we demonstrate that our MIMIC outperforms the previous training paradigm, showing its capability to learn better representations. Remarkably, the results indicate that the vanilla ViT can achieve impressive performance without the need for intricate, auxiliary-designed modules. Moreover, when scaling up the model size, MIMIC exhibits no performance saturation and is superior to the current state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07261",
        "abstract url": "https://arxiv.org/abs/2401.07261",
        "title": "LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "DeFi incidents stemming from various smart contract vulnerabilities have culminated in financial damages exceeding 3 billion USD. The attacks causing such incidents commonly commence with the deployment of adversarial contracts, subsequently leveraging these contracts to execute adversarial transactions that exploit vulnerabilities in victim contracts. Existing defense mechanisms leverage heuristic or machine learning algorithms to detect adversarial transactions, but they face significant challenges in detecting private adversarial transactions. Namely, attackers can send adversarial transactions directly to miners, evading visibility within the blockchain network and effectively bypassing the detection. In this paper, we propose a new direction for detecting DeFi attacks, i.e., detecting adversarial contracts instead of adversarial transactions, allowing us to proactively identify potential attack intentions, even if they employ private adversarial transactions. Specifically, we observe that most adversarial contracts follow a similar pattern, e.g., anonymous fund source, closed-source, frequent token-related function calls. Based on this observation, we build a machine learning classifier that can effectively distinguish adversarial contracts from benign ones. We build a dataset consists of features extracted from 269 adversarial contracts and 13,000 benign contracts. Based on this dataset, we evaluate different classifiers, the results of which show that our method for identifying DeFi adversarial contracts performs exceptionally well. For example, the F1-Score for LightGBM-based classifier is 0.9541, with a remarkably low false positive rate of only 0.15%.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "14 pages, 11 figures"
    },
    {
        "paper id": "2401.07278",
        "abstract url": "https://arxiv.org/abs/2401.07278",
        "title": "Semi-Supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cells",
        "rating": "-1",
        "keywords": [
            [
                "healthcare",
                "diagnosis",
                "cancer"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) in healthcare, especially in white blood cell cancer diagnosis, is hindered by two primary challenges: the lack of large-scale labeled datasets for white blood cell (WBC) segmentation and outdated segmentation methods. These challenges inhibit the development of more accurate and modern techniques to diagnose cancer relating to white blood cells. To address the first challenge, a semi-supervised learning framework should be devised to efficiently capitalize on the scarcity of the dataset available. In this work, we address this issue by proposing a novel self-training pipeline with the incorporation of FixMatch. Self-training is a technique that utilizes the model trained on labeled data to generate pseudo-labels for the unlabeled data and then re-train on both of them. FixMatch is a consistency-regularization algorithm to enforce the model's robustness against variations in the input image. We discover that by incorporating FixMatch in the self-training pipeline, the performance improves in the majority of cases. Our performance achieved the best performance with the self-training scheme with consistency on DeepLab-V3 architecture and ResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC datasets, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07310",
        "abstract url": "https://arxiv.org/abs/2401.07310",
        "title": "Harnessing Large Language Models Over Transformer Models for Detecting Bengali Depressive Social Media Text: A Comprehensive Study",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In an era where the silent struggle of underdiagnosed depression pervades globally, our research delves into the crucial link between mental health and social media. This work focuses on early detection of depression, particularly in extroverted social media users, using LLMs such as GPT 3.5, GPT 4 and our proposed GPT 3.5 fine-tuned model DepGPT, as well as advanced Deep learning models(LSTM, Bi-LSTM, GRU, BiGRU) and Transformer models(BERT, BanglaBERT, SahajBERT, BanglaBERT-Base). The study categorized Reddit and X datasets into \"Depressive\" and \"Non-Depressive\" segments, translated into Bengali by native speakers with expertise in mental health, resulting in the creation of the Bengali Social Media Depressive Dataset (BSMDD). Our work provides full architecture details for each model and a methodical way to assess their performance in Bengali depressive text categorization using zero-shot and few-shot learning techniques. Our work demonstrates the superiority of SahajBERT and Bi-LSTM with FastText embeddings in their respective domains also tackles explainability issues with transformer models and emphasizes the effectiveness of LLMs, especially DepGPT, demonstrating flexibility and competence in a range of learning contexts. According to the experiment results, the proposed model, DepGPT, outperformed not only Alpaca Lora 7B in zero-shot and few-shot scenarios but also every other model, achieving a near-perfect accuracy of 0.9796 and an F1-score of 0.9804, high recall, and exceptional precision. Although competitive, GPT-3.5 Turbo and Alpaca Lora 7B show relatively poorer effectiveness in zero-shot and few-shot situations. The work emphasizes the effectiveness and flexibility of LLMs in a variety of linguistic circumstances, providing insightful information about the complex field of depression detection models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07333",
        "abstract url": "https://arxiv.org/abs/2401.07333",
        "title": "ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering",
        "rating": "-1",
        "keywords": [
            [
                "Neural Codec"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The language model (LM) approach based on acoustic and linguistic prompts, such as VALL-E, has achieved remarkable progress in the field of zero-shot audio generation. However, existing methods still have some limitations: 1) repetitions, transpositions, and omissions in the output synthesized speech due to limited alignment constraints between audio and phoneme tokens; 2) challenges of fine-grained control over the synthesized speech with autoregressive (AR) language model; 3) infinite silence generation due to the nature of AR-based decoding, especially under the greedy strategy. To alleviate these issues, we propose ELLA-V, a simple but efficient LM-based zero-shot text-to-speech (TTS) framework, which enables fine-grained control over synthesized audio at the phoneme level. The key to ELLA-V is interleaving sequences of acoustic and phoneme tokens, where phoneme tokens appear ahead of the corresponding acoustic tokens. The experimental findings reveal that our model outperforms VALL-E in terms of accuracy and delivers more stable results using both greedy and sampling-based decoding strategies. The code of ELLA-V will be open-sourced after cleanups. Audio samples are available at https://ereboas.github.io/ELLAV/.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Working in progress"
    },
    {
        "paper id": "2401.07339",
        "abstract url": "https://arxiv.org/abs/2401.07339",
        "title": "CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges",
        "rating": "-1",
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown promise in automated code generation but typically excel only in simpler tasks such as generating standalone code units. Real-world software development, however, often involves complex code repositories (named repo) with complex dependencies and extensive documentation. To fill this gap, our research pivots towards evaluating LLMs in a more realistic setting -- real-world repo-level code generation. We introduce CodeAgentBench, a manually curated benchmark for repo-level code generation. This benchmark comprises five high-quality Python projects, encompassing a total of 101 samples. We assess nine leading LLMs on repo-level tasks and observe a decline in their performance. To tackle this, we present CodeAgent, a novel LLM-based agent framework that employs external tools for effective repo-level code generation. CodeAgent integrates five programming tools, enabling interaction with software artifacts for information retrieval, code symbol navigation, and code testing. We implement four agent strategies to optimize these tools' usage. Our experiments on CodeAgentBench show that CodeAgent enhances LLM performance significantly, with improvements ranging from 18.1\\% to 250\\%. Further tests on the HumanEval benchmark confirm CodeAgent's adaptability and efficacy across various code generation tasks. Notably, CodeAgent outperforms commercial products like Github Copilot, showcasing superior accuracy and efficiency. These results demonstrate CodeAgent's robust capabilities in code generation, highlighting its potential for real-world repo-level coding challenges.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07341",
        "abstract url": "https://arxiv.org/abs/2401.07341",
        "title": "Binary weights spanning trees and the $k$-red spanning tree problem in linear time",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We address here spanning tree problems on a graph with binary edge weights. For a general weighted graph the minimum spanning tree is solved in super-linear running time, even when the edges of the graph are pre-sorted. A related problem, of finding a spanning tree with a pre-specified sum of weights, is NP-hard. In contrast, for a graph with binary weights associated with the edges, it is shown that the minimum spanning tree and finding a spanning tree with a given total sum, are solvable in linear time with simple algorithms.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07398",
        "abstract url": "https://arxiv.org/abs/2401.07398",
        "title": "Cross Domain Early Crop Mapping using CropSTGAN",
        "rating": "-1",
        "keywords": [
            [
                "satellite",
                "agricultural"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Driven by abundant satellite imagery, machine learning-based approaches have recently been promoted to generate high-resolution crop cultivation maps to support many agricultural applications. One of the major challenges faced by these approaches is the limited availability of ground truth labels. In the absence of ground truth, existing work usually adopts the \"direct transfer strategy\" that trains a classifier using historical labels collected from other regions and then applies the trained model to the target region. Unfortunately, the spectral features of crops exhibit inter-region and inter-annual variability due to changes in soil composition, climate conditions, and crop progress, the resultant models perform poorly on new and unseen regions or years. Despite recent efforts, such as the application of the deep adaptation neural network (DANN) model structure in the deep adaptation crop classification network (DACCN), to tackle the above cross-domain challenges, their effectiveness diminishes significantly when there is a large dissimilarity between the source and target regions. This paper introduces the Crop Mapping Spectral-temporal Generative Adversarial Neural Network (CropSTGAN), a novel solution for cross-domain challenges, that doesn't require target domain labels. CropSTGAN learns to transform the target domain's spectral features to those of the source domain, effectively bridging large dissimilarities. Additionally, it employs an identity loss to maintain the intrinsic local structure of the data. Comprehensive experiments across various regions and years demonstrate the benefits and effectiveness of the proposed approach. In experiments, CropSTGAN is benchmarked against various state-of-the-art (SOTA) methods. Notably, CropSTGAN significantly outperforms these methods in scenarios with large data distribution dissimilarities between the target and source domains.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07408",
        "abstract url": "https://arxiv.org/abs/2401.07408",
        "title": "Multimodal Language and Graph Learning of Adsorption Configuration in Catalysis",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ]
        ],
        "abstract": "Adsorption energy, a reactivity descriptor, should be accurately assessed for efficient catalyst screening. This evaluation requires determining the lowest energy across various adsorption configurations on the catalytic surface. While graph neural networks (GNNs) have gained popularity as a machine learning approach for computing the energy of catalyst systems, they rely heavily on atomic spatial coordinates and often lack clarity in their interpretations. Recent advancements in language models have broadened their applicability to predicting catalytic properties, allowing us to bypass the complexities of graph representation. These models are adept at handling textual data, making it possible to incorporate observable features in a human-readable format. However, language models encounter challenges in accurately predicting the energy of adsorption configurations, typically showing a high mean absolute error (MAE) of about 0.71 eV. Our study addresses this limitation by introducing a self-supervised multi-modal learning approach, termed graph-assisted pretraining. This method significantly reduces the MAE to 0.35 eV through a combination of data augmentation, achieving comparable accuracy with DimeNet++ while using 0.4% of its training data size. Furthermore, the Transformer encoder at the core of the language model can provide insights into the feature focus through its attention scores. This analysis shows that our multimodal training effectively redirects the model's attention toward relevant adsorption configurations from adsorbate-related features, enhancing prediction accuracy and interpretability.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "28 pages, 6 figures, supplementary information added"
    },
    {
        "paper id": "2401.07427",
        "abstract url": "https://arxiv.org/abs/2401.07427",
        "title": "AMC'24 \"Analysis and Synthesis of the Disturbance Observer-based Robust Force Control Systems in State Space\"",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "This paper extends the result of my previous papers on the analysis and synthesis of disturbance observer based robust control systems in state space.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07430",
        "abstract url": "https://arxiv.org/abs/2401.07430",
        "title": "AMC'24 \"A Novel Stiffness Modulation Mechanism for Energy Efficient Variable Stiffness Actuators\"",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper presents a new stiffness modulation mechanism that enables infinite-range stiffness modulation in a fast manner. The proposed stiffness modulation mechanism can help improve many robot environment interaction applications such as human-robot collaboration and robotic rehabilitation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07444",
        "abstract url": "https://arxiv.org/abs/2401.07444",
        "title": "Low-cost, Lightweight Electronic Flow Regulators for Throttling Liquid Rocket Engines",
        "rating": "-1",
        "keywords": [
            [
                "flight"
            ]
        ],
        "abstract": "For small-scale liquid rockets, pressure-fed systems are commonly favoured due to their simplicity and low weight. In such systems, accurate regulation of both tank and injector pressures over a wide range of upstream pressures is critical $-$ more accurate regulation allows for higher engine efficiency and minimal tank mass, thus improving flight performance. However, existing methods such as dome-loaded pressure regulators are inflexible, or require extensive characterization to function accurately. These methods also suffer from limited orifice size, droop, and slow reaction times, making them unsuitable for throttling by adjusting pressures in flight, which are increasingly important as propulsively landing rockets become more common. To overcome these challenges, we designed an electronic pressure regulator (eReg), a multi-input multi-output system utilising closed loop feedback to accurately control downstream pressures. Our design is simple, low-cost and robust: with a single ball valve actuated by a motor, we regulate both gaseous pressurant and cryogenic liquid propellant at high flow rates (1.14 kg/s of liquid; 0.39 kg/s of gas) and upstream pressures (310 bar). Using 2 eRegs to regulate propellant tank pressures, and 2 eRegs for regulating propellant flow to the engine, we demonstrated our system's ability, in a static fire test, to regulate pressures accurately (within 0.2 bar) while simultaneously throttling our engine. To the best of our knowledge, this is the first time any undergraduate team has successfully throttled a liquid bipropellant engine.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 15 figures, Presented at the 74th International Astronautical Congress (IAC), Baku, Azerbaijan, 2-6 October 2023"
    },
    {
        "paper id": "2401.07447",
        "abstract url": "https://arxiv.org/abs/2401.07447",
        "title": "Taec: a Manually annotated text dataset for trait and phenotype extraction and entity linking in wheat breeding literature",
        "rating": "-1",
        "keywords": [
            [
                "Biotechnology",
                "disease"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Wheat varieties show a large diversity of traits and phenotypes. Linking them to genetic variability is essential for shorter and more efficient wheat breeding programs. Newly desirable wheat variety traits include disease resistance to reduce pesticide use, adaptation to climate change, resistance to heat and drought stresses, or low gluten content of grains. Wheat breeding experiments are documented by a large body of scientific literature and observational data obtained in-field and under controlled conditions. The cross-referencing of complementary information from the literature and observational data is essential to the study of the genotype-phenotype relationship and to the improvement of wheat selection. The scientific literature on genetic marker-assisted selection describes much information about the genotype-phenotype relationship. However, the variety of expressions used to refer to traits and phenotype values in scientific articles is a hinder to finding information and cross-referencing it. When trained adequately by annotated examples, recent text mining methods perform highly in named entity recognition and linking in the scientific domain. While several corpora contain annotations of human and animal phenotypes, currently, no corpus is available for training and evaluating named entity recognition and entity-linking methods in plant phenotype literature. The Triticum aestivum trait Corpus is a new gold standard for traits and phenotypes of wheat. It consists of 540 PubMed references fully annotated for trait, phenotype, and species named entities using the Wheat Trait and Phenotype Ontology and the species taxonomy of the National Center for Biotechnology Information. A study of the performance of tools trained on the Triticum aestivum trait Corpus shows that the corpus is suitable for the training and evaluation of named entity recognition and linking.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2401.07455",
        "abstract url": "https://arxiv.org/abs/2401.07455",
        "title": "Stability analysis of a departure time choice problem with atomic vehicle models",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "In this study, we analyse the global stability of the equilibrium in a departure time choice problem using a game-theoretic approach that deals with atomic users. We first formulate the departure time choice problem as a strategic game in which atomic users select departure times to minimise their trip cost; we call this game the 'departure time choice game'. The concept of the epsilon-Nash equilibrium is introduced to ensure the existence of pure-strategy equilibrium corresponding to the departure time choice equilibrium in conventional fluid models. Then, we prove that the departure time choice game is a weakly acyclic game. By analysing the convergent better responses, we clarify the mechanisms of global convergence to equilibrium. This means that the epsilon-Nash equilibrium is achieved by sequential better responses of users, which are departure time changes to improve their own utility, in an appropriate order. Specifically, the following behavioural rules are important to ensure global convergence: (i) the adjustment of the departure time of the first user departing from the origin to the corresponding equilibrium departure time and (ii) the fixation of users to their equilibrium departure times in order (starting with the earliest). Using convergence mechanisms, we construct evolutionary dynamics under which global stability is guaranteed. We also investigate the stable and unstable dynamics studied in the literature based on convergence mechanisms, and gain insight into the factors influencing the different stability results. Finally, numerical experiments are conducted to demonstrate the theoretical results.",
        "subjects": [
            "math.OC"
        ],
        "comment": "33 pages, 11figures"
    },
    {
        "paper id": "2401.07463",
        "abstract url": "https://arxiv.org/abs/2401.07463",
        "title": "Consistency of semi-supervised learning, stochastic tug-of-war games, and the p-Laplacian",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper we give a broad overview of the intersection of partial differential equations (PDEs) and graph-based semi-supervised learning. The overview is focused on a large body of recent work on PDE continuum limits of graph-based learning, which have been used to prove well-posedness of semi-supervised learning algorithms in the large data limit. We highlight some interesting research directions revolving around consistency of graph-based semi-supervised learning, and present some new results on the consistency of p-Laplacian semi-supervised learning using the stochastic tug-of-war game interpretation of the p-Laplacian. We also present the results of some numerical experiments that illustrate our results and suggest directions for future work.",
        "subjects": [
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08699",
        "abstract url": "https://arxiv.org/abs/2401.08699",
        "title": "On Image Search in Histopathology",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "whole slide",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Pathology images of histopathology can be acquired from camera-mounted microscopes or whole slide scanners. Utilizing similarity calculations to match patients based on these images holds significant potential in research and clinical contexts. Recent advancements in search technologies allow for implicit quantification of tissue morphology across diverse primary sites, facilitating comparisons and enabling inferences about diagnosis, and potentially prognosis, and predictions for new patients when compared against a curated database of diagnosed and treated cases. In this paper, we comprehensively review the latest developments in image search technologies for histopathology, offering a concise overview tailored for computational pathology researchers seeking effective, fast and efficient image search methods in their work.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "A chapter in the Book \"Artificial INtelligence in Digital Pathology\" by Cohen and Chauhan, 2024"
    },
    {
        "paper id": "2401.07389",
        "abstract url": "https://arxiv.org/abs/2401.07389",
        "title": "A Rapid Review of Clustering Algorithms",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Clustering algorithms aim to organize data into groups or clusters based on the inherent patterns and similarities within the data. They play an important role in today's life, such as in marketing and e-commerce, healthcare, data organization and analysis, and social media. Numerous clustering algorithms exist, with ongoing developments introducing new ones. Each algorithm possesses its own set of strengths and weaknesses, and as of now, there is no universally applicable algorithm for all tasks. In this work, we analyzed existing clustering algorithms and classify mainstream algorithms across five different dimensions: underlying principles and characteristics, data point assignment to clusters, dataset capacity, predefined cluster numbers and application area. This classification facilitates researchers in understanding clustering algorithms from various perspectives and helps them identify algorithms suitable for solving specific tasks. Finally, we discussed the current trends and potential future directions in clustering algorithms. We also identified and discussed open challenges and unresolved issues in the field.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "25 pages, 7 figures, 3 tables"
    },
    {
        "paper id": "2402.01663",
        "abstract url": "https://arxiv.org/abs/2402.01663",
        "title": "Killer Apps: Low-Speed, Large-Scale AI Weapons",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The accelerating advancements in Artificial Intelligence (AI) and Machine Learning (ML), highlighted by the development of cutting-edge Generative Pre-trained Transformer (GPT) models by organizations such as OpenAI, Meta, and Anthropic, present new challenges and opportunities in warfare and security. Much of the current focus is on AI's integration within weapons systems and its role in rapid decision-making in kinetic conflict. However, an equally important but often overlooked aspect is the potential of AI-based psychological manipulation at internet scales within the information domain. These capabilities could pose significant threats to individuals, organizations, and societies globally. This paper explores the concept of AI weapons, their deployment, detection, and potential countermeasures.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "10 pages with 10 pages of appendices. 3 Figures, 2 code listings"
    },
    {
        "paper id": "2402.18583",
        "abstract url": "https://arxiv.org/abs/2402.18583",
        "title": "Binding-Adaptive Diffusion Models for Structure-Based Drug Design",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Structure-based drug design (SBDD) aims to generate 3D ligand molecules that bind to specific protein targets. Existing 3D deep generative models including diffusion models have shown great promise for SBDD. However, it is complex to capture the essential protein-ligand interactions exactly in 3D space for molecular generation. To address this problem, we propose a novel framework, namely Binding-Adaptive Diffusion Models (BindDM). In BindDM, we adaptively extract subcomplex, the essential part of binding sites responsible for protein-ligand interactions. Then the selected protein-ligand subcomplex is processed with SE(3)-equivariant neural networks, and transmitted back to each atom of the complex for augmenting the target-aware 3D molecule diffusion generation with binding interaction information. We iterate this hierarchical complex-subcomplex process with cross-hierarchy interaction node for adequately fusing global binding context between the complex and its corresponding subcomplex. Empirical studies on the CrossDocked2020 dataset show BindDM can generate molecules with more realistic 3D structures and higher binding affinities towards the protein targets, with up to -5.92 Avg. Vina Score, while maintaining proper molecular properties. Our code is available at https://github.com/YangLing0818/BindDM",
        "subjects": [
            "q-bio.BM"
        ],
        "comment": "Accepted by AAAI 2024. Project: https://github.com/YangLing0818/BindDM"
    },
    {
        "paper id": "2401.07206",
        "abstract url": "https://arxiv.org/abs/2401.07206",
        "title": "Probabilistic Reduced-Dimensional Vector Autoregressive Modeling with Oblique Projections",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "Chemical"
            ]
        ],
        "abstract": "In this paper, we propose a probabilistic reduced-dimensional vector autoregressive (PredVAR) model to extract low-dimensional dynamics from high-dimensional noisy data. The model utilizes an oblique projection to partition the measurement space into a subspace that accommodates the reduced-dimensional dynamics and a complementary static subspace. An optimal oblique decomposition is derived for the best predictability regarding prediction error covariance. Building on this, we develop an iterative PredVAR algorithm using maximum likelihood and the expectation-maximization (EM) framework. This algorithm alternately updates the estimates of the latent dynamics and optimal oblique projection, yielding dynamic latent variables with rank-ordered predictability and an explicit latent VAR model that is consistent with the outer projection model. The superior performance and efficiency of the proposed approach are demonstrated using data sets from a synthesized Lorenz system and an industrial process from Eastman Chemical.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "16pages, 5 figures"
    },
    {
        "paper id": "2401.07211",
        "abstract url": "https://arxiv.org/abs/2401.07211",
        "title": "A Comparative Analysis of Smartphone and Standard Tools for Touch Perception Assessment Across Multiple Body Sites",
        "rating": "-2",
        "keywords": [
            [
                "medical",
                "disease"
            ]
        ],
        "abstract": "Tactile perception plays an important role in activities of daily living, and it can be impaired in individuals with certain medical conditions. The most common tools used to assess tactile sensation, the Semmes-Weinstein monofilaments and the 128 Hz tuning fork, have poor repeatability and resolution. Long term, we aim to provide a repeatable, high-resolution testing platform that can be used to assess vibrotactile perception through smartphones without the need for an experimenter to be present to conduct the test. We present a smartphone-based vibration perception measurement platform and compare its performance to measurements from standard monofilament and tuning fork tests. We conducted a user study with 36 healthy adults in which we tested each tool on the hand, wrist, and foot, to assess how well our smartphone-based vibration perception thresholds (VPTs) detect known trends obtained from standard tests. The smartphone platform detected statistically significant changes in VPT between the index finger and foot and also between the feet of younger adults and older adults. Our smartphone-based VPT had a moderate correlation to tuning fork-based VPT. Our overarching objective is to develop an accessible smartphone-based platform that can eventually be used to measure disease progression and regression.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted for publication in IEEE Transactions on Haptics 2024"
    },
    {
        "paper id": "2401.07213",
        "abstract url": "https://arxiv.org/abs/2401.07213",
        "title": "Depth-agnostic Single Image Dehazing",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "haze",
                "Dehazing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Single image dehazing is a challenging ill-posed problem. Existing datasets for training deep learning-based methods can be generated by hand-crafted or synthetic schemes. However, the former often suffers from small scales, while the latter forces models to learn scene depth instead of haze distribution, decreasing their dehazing ability. To overcome the problem, we propose a simple yet novel synthetic method to decouple the relationship between haze density and scene depth, by which a depth-agnostic dataset (DA-HAZE) is generated. Meanwhile, a Global Shuffle Strategy (GSS) is proposed for generating differently scaled datasets, thereby enhancing the generalization ability of the model. Extensive experiments indicate that models trained on DA-HAZE achieve significant improvements on real-world benchmarks, with less discrepancy between SOTS and DA-SOTS (the test set of DA-HAZE). Additionally, Depth-agnostic dehazing is a more complicated task because of the lack of depth prior. Therefore, an efficient architecture with stronger feature modeling ability and fewer computational costs is necessary. We revisit the U-Net-based architectures for dehazing, in which dedicatedly designed blocks are incorporated. However, the performances of blocks are constrained by limited feature fusion methods. To this end, we propose a Convolutional Skip Connection (CSC) module, allowing vanilla feature fusion methods to achieve promising results with minimal costs. Extensive experimental results demonstrate that current state-of-the-art methods. equipped with CSC can achieve better performance and reasonable computational expense, whether the haze distribution is relevant to the scene depth.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07220",
        "abstract url": "https://arxiv.org/abs/2401.07220",
        "title": "Application of 2D Homography for High Resolution Traffic Data Collection using CCTV Cameras",
        "rating": "-2",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "bird's-eye view",
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traffic cameras remain the primary source data for surveillance activities such as congestion and incident monitoring. To date, State agencies continue to rely on manual effort to extract data from networked cameras due to limitations of the current automatic vision systems including requirements for complex camera calibration and inability to generate high resolution data. This study implements a three-stage video analytics framework for extracting high-resolution traffic data such vehicle counts, speed, and acceleration from infrastructure-mounted CCTV cameras. The key components of the framework include object recognition, perspective transformation, and vehicle trajectory reconstruction for traffic data collection. First, a state-of-the-art vehicle recognition model is implemented to detect and classify vehicles. Next, to correct for camera distortion and reduce partial occlusion, an algorithm inspired by two-point linear perspective is utilized to extracts the region of interest (ROI) automatically, while a 2D homography technique transforms the CCTV view to bird's-eye view (BEV). Cameras are calibrated with a two-layer matrix system to enable the extraction of speed and acceleration by converting image coordinates to real-world measurements. Individual vehicle trajectories are constructed and compared in BEV using two time-space-feature-based object trackers, namely Motpy and BYTETrack. The results of the current study showed about +/- 4.5% error rate for directional traffic counts, less than 10% MSE for speed bias between camera estimates in comparison to estimates from probe data sources. Extracting high-resolution data from traffic cameras has several implications, ranging from improvements in traffic management and identify dangerous driving behavior, high-risk areas for accidents, and other safety concerns, enabling proactive measures to reduce accidents and fatalities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "25 pages, 9 figures, this paper was submitted for consideration for presentation at the 102nd Annual Meeting of the Transportation Research Board, January 2023"
    },
    {
        "paper id": "2401.07230",
        "abstract url": "https://arxiv.org/abs/2401.07230",
        "title": "Understanding Emotional Disclosure via Diary-keeping in Quarantine on Social Media",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "Quarantine is a widely-adopted measure during health crises caused by highly-contagious diseases like COVID-19, yet it poses critical challenges to public mental health. Given this context, emotional disclosure on social media in the form of keeping a diary emerges as a popular way for individuals to express emotions and record their mental health status. However, the exploration of emotional disclosure via diary-keeping on social media during quarantine is underexplored, understanding which could be beneficial to facilitate emotional connections and enlighten health intervention measures. Focusing on this particular form of self-disclosure, this work proposes a quantitative approach to figure out the prevalence and changing patterns of emotional disclosure during quarantine, and the possible factors contributing to the negative emotions. We collected 58, 796 posts with the \"Quarantine Diary\" keyword on Weibo, a popular social media website in China. Through text classification, we capture diverse emotion categories that characterize public emotion disclosure during quarantine, such as annoyed, anxious, boring, happy, hopeful and appreciative. Based on temporal analysis, we uncover the changing patterns of emotional disclosure from long-term perspectives and period-based perspectives (e.g., the gradual decline of all negative emotions and the upsurge of the annoyed emotion near the end of quarantine). Leveraging topic modeling, we also encapsulate the possible influencing factors of negative emotions, such as freedom restriction and solitude, and uncertainty of infection and supply. We reflect on how our findings could deepen the understanding of mental health on social media and further provide practical and design implications to mitigate mental health issues during quarantine.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "13 pages, 6 figures, In Proceedings of The Eleventh International Symposium of Chinese CHI (Chinese CHI 2023)"
    },
    {
        "paper id": "2401.07257",
        "abstract url": "https://arxiv.org/abs/2401.07257",
        "title": "Lightweight Modality Adaptation to Sequential Recommendation via Correlation Supervision",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "In Sequential Recommenders (SR), encoding and utilizing modalities in an end-to-end manner is costly in terms of modality encoder sizes. Two-stage approaches can mitigate such concerns, but they suffer from poor performance due to modality forgetting, where the sequential objective overshadows modality representation. We propose a lightweight knowledge distillation solution that preserves both merits: retaining modality information and maintaining high efficiency. Specifically, we introduce a novel method that enhances the learning of embeddings in SR through the supervision of modality correlations. The supervision signals are distilled from the original modality representations, including both (1) holistic correlations, which quantify their overall associations, and (2) dissected correlation types, which refine their relationship facets (honing in on specific aspects like color or shape consistency). To further address the issue of modality forgetting, we propose an asynchronous learning step, allowing the original information to be retained longer for training the representation learning module. Our approach is compatible with various backbone architectures and outperforms the top baselines by 6.8% on average. We empirically demonstrate that preserving original feature associations from modality encoders significantly boosts task-specific recommendation adaptation. Additionally, we find that larger modality encoders (e.g., Large Language Models) contain richer feature sets which necessitate more fine-grained modeling to reach their full performance potential.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted by ECIR 2024"
    },
    {
        "paper id": "2401.07271",
        "abstract url": "https://arxiv.org/abs/2401.07271",
        "title": "SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning and Uncertainty Estimation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosing",
                "CT",
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vertebrae identification in arbitrary fields-of-view plays a crucial role in diagnosing spine disease. Most spine CT contain only local regions, such as the neck, chest, and abdomen. Therefore, identification should not depend on specific vertebrae or a particular number of vertebrae being visible. Existing methods at the spine-level are unable to meet this challenge. In this paper, we propose a three-stage method to address the challenges in 3D CT vertebrae identification at vertebrae-level. By sequentially performing the tasks of vertebrae localization, segmentation, and identification, the anatomical prior information of the vertebrae is effectively utilized throughout the process. Specifically, we introduce a dual-factor density clustering algorithm to acquire localization information for individual vertebra, thereby facilitating subsequent segmentation and identification processes. In addition, to tackle the issue of interclass similarity and intra-class variability, we pre-train our identification network by using a supervised contrastive learning method. To further optimize the identification results, we estimated the uncertainty of the classification network and utilized the message fusion module to combine the uncertainty scores, while aggregating global information about the spine. Our method achieves state-of-the-art results on the VerSe19 and VerSe20 challenge benchmarks. Additionally, our approach demonstrates outstanding generalization performance on an collected dataset containing a wide range of abnormal cases.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07329",
        "abstract url": "https://arxiv.org/abs/2401.07329",
        "title": "Attention-based UNet enabled Lightweight Image Semantic Communication System over Internet of Things",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "This paper studies the problem of the lightweight image semantic communication system that is deployed on Internet of Things (IoT) devices. In the considered system model, devices must use semantic communication techniques to support user behavior recognition in ultimate video service with high data transmission efficiency. However, it is computationally expensive for IoT devices to deploy semantic codecs due to the complex calculation processes of deep learning (DL) based codec training and inference. To make it affordable for IoT devices to deploy semantic communication systems, we propose an attention-based UNet enabled lightweight image semantic communication (LSSC) system, which achieves low computational complexity and small model size. In particular, we first let the LSSC system train the codec at the edge server to reduce the training computation load on IoT devices. Then, we introduce the convolutional block attention module (CBAM) to extract the image semantic features and decrease the number of downsampling layers thus reducing the floating-point operations (FLOPs). Finally, we experimentally adjust the structure of the codec and find out the optimal number of downsampling layers. Simulation results show that the proposed LSSC system can reduce the semantic codec FLOPs by 14%, and reduce the model size by 55%, with a sacrifice of 3% accuracy, compared to the baseline. Moreover, the proposed scheme can achieve a higher transmission accuracy than the traditional communication scheme in the low channel signal-to-noise (SNR) region.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "6 pages, 6 figures, accepted by IEEE WCNC 2024"
    },
    {
        "paper id": "2401.07331",
        "abstract url": "https://arxiv.org/abs/2401.07331",
        "title": "Rapid Estimation of Left Ventricular Contractility with a Physics-Informed Neural Network Inverse Modeling Approach",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "Physics-based computer models based on numerical solution of the governing equations generally cannot make rapid predictions, which in turn, limits their applications in the clinic. To address this issue, we developed a physics-informed neural network (PINN) model that encodes the physics of a closed-loop blood circulation system embedding a left ventricle (LV). The PINN model is trained to satisfy a system of ordinary differential equations (ODEs) associated with a lumped parameter description of the circulatory system. The model predictions have a maximum error of less than 5% when compared to those obtained by solving the ODEs numerically. An inverse modeling approach using the PINN model is also developed to rapidly estimate model parameters (in $\\sim$ 3 mins) from single-beat LV pressure and volume waveforms. Using synthetic LV pressure and volume waveforms generated by the PINN model with different model parameter values, we show that the inverse modeling approach can recover the corresponding ground truth values, which suggests that the model parameters are unique. The PINN inverse modeling approach is then applied to estimate LV contractility indexed by the end-systolic elastance $E_{es}$ using waveforms acquired from 11 swine models, including waveforms acquired before and after administration of dobutamine (an inotropic agent) in 3 animals. The estimated $E_{es}$ is about 58% to 284% higher for the data associated with dobutamine compared to those without, which implies that this approach can be used to estimate LV contractility using single-beat measurements. The PINN inverse modeling can potentially be used in the clinic to simultaneously estimate LV contractility and other physiological parameters from single-beat measurements.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07336",
        "abstract url": "https://arxiv.org/abs/2401.07336",
        "title": "Construction and Evaluation of Mandarin Multimodal Emotional Speech Database",
        "rating": "-2",
        "keywords": [
            [
                "SVM"
            ],
            [
                "facial",
                "psychological"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "A multi-modal emotional speech Mandarin database including articulatory kinematics, acoustics, glottal and facial micro-expressions is designed and established, which is described in detail from the aspects of corpus design, subject selection, recording details and data processing. Where signals are labeled with discrete emotion labels (neutral, happy, pleasant, indifferent, angry, sad, grief) and dimensional emotion labels (pleasure, arousal, dominance). In this paper, the validity of dimension annotation is verified by statistical analysis of dimension annotation data. The SCL-90 scale data of annotators are verified and combined with PAD annotation data for analysis, so as to explore the internal relationship between the outlier phenomenon in annotation and the psychological state of annotators. In order to verify the speech quality and emotion discrimination of the database, this paper uses 3 basic models of SVM, CNN and DNN to calculate the recognition rate of these seven emotions. The results show that the average recognition rate of seven emotions is about 82% when using acoustic data alone. When using glottal data alone, the average recognition rate is about 72%. Using kinematics data alone, the average recognition rate also reaches 55.7%. Therefore, the database is of high quality and can be used as an important source for speech analysis research, especially for the task of multimodal emotional speech analysis.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07393",
        "abstract url": "https://arxiv.org/abs/2401.07393",
        "title": "A Novel Optimization Algorithm for Buffer and Splitter Minimization in Phase-Skipping Adiabatic Quantum-Flux-Parametron Circuits",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Adiabatic Quantum-Flux-Parametron (AQFP) logic is a promising emerging device technology that promises six orders of magnitude lower power than CMOS. However, AQFP is challenged by operation at only ultra-low temperatures, has high latency and area, and requires a complex clocking scheme. In particular, every logic gate, buffer, and splitter must be clocked and each pair of connected clocked gates requires overlapping alternating current (AC) clock signals. In particular, clocked buffers need to be used to balance re-convergent logic paths, a problem that is exacerbated by every multi-node fanout needing a tree of clocked splitters. To reduce circuit area many works have proposed buffer and splitter insertion optimization algorithms and recent works have demonstrated a phase-skipping clocking scheme that reduces latency and area. This paper proposes the first algorithm to optimize buffer and splitter insertion for circuits that adopt phase-skipping and demonstrate the resulting performance improvements for a suite of AQFP benchmark circuits.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08696",
        "abstract url": "https://arxiv.org/abs/2401.08696",
        "title": "Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis with GNNs",
        "rating": "-2",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "GNNs",
                "graph"
            ]
        ],
        "abstract": "High-level synthesis (HLS) notably speeds up the hardware design process by avoiding RTL programming. However, the turnaround time of HLS increases significantly when post-route quality of results (QoR) are considered during optimization. To tackle this issue, we propose a hierarchical post-route QoR prediction approach for FPGA HLS, which features: (1) a modeling flow that directly estimates latency and post-route resource usage from C/C++ programs; (2) a graph construction method that effectively represents the control and data flow graph of source code and effects of HLS pragmas; and (3) a hierarchical GNN training and prediction method capable of capturing the impact of loop hierarchies. Experimental results show that our method presents a prediction error of less than 10% for different types of QoR metrics, which gains tremendous improvement compared with the state-of-the-art GNN methods. By adopting our proposed methodology, the runtime for design space exploration in HLS is shortened to tens of minutes and the achieved ADRS is reduced to 6.91% on average.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Accepted for publication at DATE 2024"
    },
    {
        "paper id": "2401.10283",
        "abstract url": "https://arxiv.org/abs/2401.10283",
        "title": "Window Stacking Meta-Models for Clinical EEG Classification",
        "rating": "-2",
        "keywords": [
            [
                "EEG",
                "Clinical"
            ]
        ],
        "abstract": "Windowing is a common technique in EEG machine learning classification and other time series tasks. However, a challenge arises when employing this technique: computational expense inhibits learning global relationships across an entire recording or set of recordings. Furthermore, the labels inherited by windows from their parent recordings may not accurately reflect the content of that window in isolation. To resolve these issues, we introduce a multi-stage model architecture, incorporating meta-learning principles tailored to time-windowed data aggregation. We further tested two distinct strategies to alleviate these issues: lengthening the window and utilizing overlapping to augment data. Our methods, when tested on the Temple University Hospital Abnormal EEG Corpus (TUAB), dramatically boosted the benchmark accuracy from 89.8 percent to 99.0 percent. This breakthrough performance surpasses prior performance projections for this dataset and paves the way for clinical applications of machine learning solutions to EEG interpretation challenges. On a broader and more varied dataset from the Temple University Hospital EEG Corpus (TUEG), we attained an accuracy of 86.7%, nearing the assumed performance ceiling set by variable inter-rater agreement on such datasets.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "17 pages, 10 figures"
    },
    {
        "paper id": "2402.06630",
        "abstract url": "https://arxiv.org/abs/2402.06630",
        "title": "The Dilemma of Standardizing Indoor Photovoltaic Characterisation: Embracing Diversity for Powering the IoT",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "In this viewpoint contribution, we argue that the emerging landscape of indoor photovoltaics poses unique challenges that transcend the capabilities of a singular standard, unlike what the community has become accustomed with the success of the AM1.x standard for outdoor application. We aim at illustrating the pitfalls associated with a one-size-fits-all approach to standardisation, emphasising the necessity for a concerted and nuanced methodology tailored to the complexities of indoor energy utilisation, and particularly in the context of the various needs of the Internet of Things. Acknowledging the inherent variability in indoor illumination conditions, and using simple numerical modelling and real-life examples to illustrate how it influences the output of indoor cells, we advocate for a shift from conventional standards to comprehensive guidelines that will better accommodate and evaluate the diverse interplays between photovoltaic device, internet of things sensors, and illumination sources. Our proposed methodology is not merely a set of rules but a strategic framework for the community to build upon, inviting researchers and industry stakeholders to collaborate and establish a unified foundation for assessing the performance of photovoltaic devices indoors. By fostering a collective approach and steering clear of rigid standards, this viewpoint lays the groundwork for future studies to better assess the performance and usability of indoor photovoltaics, thus ensuring innovation, adaptability, and reliable analyses in this very fast evolving and increasingly relevant field.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "References are currently missing"
    },
    {
        "paper id": "2401.07234",
        "abstract url": "https://arxiv.org/abs/2401.07234",
        "title": "The Effects of Data Imbalance Under a Federated Learning Approach for Credit Risk Forecasting",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Credit risk forecasting plays a crucial role for commercial banks and other financial institutions in granting loans to customers and minimise the potential loss. However, traditional machine learning methods require the sharing of sensitive client information with an external server to build a global model, potentially posing a risk of security threats and privacy leakage. A newly developed privacy-preserving distributed machine learning technique known as Federated Learning (FL) allows the training of a global model without the necessity of accessing private local data directly. This investigation examined the feasibility of federated learning in credit risk assessment and showed the effects of data imbalance on model performance. Two neural network architectures, Multilayer Perceptron (MLP) and Long Short-Term Memory (LSTM), and one tree ensemble architecture, Extreme Gradient Boosting (XGBoost), were explored across three different datasets under various scenarios involving different numbers of clients and data distribution configurations. We demonstrate that federated models consistently outperform local models on non-dominant clients with smaller datasets. This trend is especially pronounced in highly imbalanced data scenarios, yielding a remarkable average improvement of 17.92% in model performance. However, for dominant clients (clients with more data), federated models may not exhibit superior performance, suggesting the need for special incentives for this type of clients to encourage their participation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07205",
        "abstract url": "https://arxiv.org/abs/2401.07205",
        "title": "Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Facial"
            ]
        ],
        "abstract": "With the increased capabilities at the edge (e.g., mobile device) and more stringent privacy requirement, it becomes a recent trend for deep learning-enabled applications to pre-process sensitive raw data at the edge and transmit the features to the backend cloud for further processing. A typical application is to run machine learning (ML) services on facial images collected from different individuals. To prevent identity theft, conventional methods commonly rely on an adversarial game-based approach to shed the identity information from the feature. However, such methods can not defend against adaptive attacks, in which an attacker takes a countermove against a known defence strategy. We propose Crafter, a feature crafting mechanism deployed at the edge, to protect the identity information from adaptive model inversion attacks while ensuring the ML tasks are properly carried out in the cloud. The key defence strategy is to mislead the attacker to a non-private prior from which the attacker gains little about the private identity. In this case, the crafted features act like poison training samples for attackers with adaptive model updates. Experimental results indicate that Crafter successfully defends both basic and possible adaptive attacks, which can not be achieved by state-of-the-art adversarial game-based methods.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07256",
        "abstract url": "https://arxiv.org/abs/2401.07256",
        "title": "Emergency Localization for Mobile Ground Users: An Adaptive UAV Trajectory Planning Method",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In emergency search and rescue scenarios, the quick location of trapped people is essential. However, disasters can render the Global Positioning System (GPS) unusable. Unmanned aerial vehicles (UAVs) with localization devices can serve as mobile anchors due to their agility and high line-of-sight (LoS) probability. Nonetheless, the number of available UAVs during the initial stages of disaster relief is limited, and innovative methods are needed to quickly plan UAV trajectories to locate non-uniformly distributed dynamic targets while ensuring localization accuracy. To address this challenge, we design a single UAV localization method without hovering, use the maximum likelihood estimation (MLE) method to estimate the location of mobile users and define the upper bound of the localization error by considering users' movement.Combining this localization method and localization error-index, we utilize the enhanced particle swarm optimization (EPSO) algorithm and edge access strategy to develop a low complexity localization-oriented adaptive trajectory planning algorithm. Simulation results demonstrate that our method outperforms other baseline algorithms, enabling faster localization without compromising localization accuracy.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07258",
        "abstract url": "https://arxiv.org/abs/2401.07258",
        "title": "Diagnosing epilepsy using entropy measures and embedding parameters of EEG signals",
        "rating": "-3",
        "keywords": [
            [
                "SVM"
            ],
            [
                "Diagnosing",
                "EEG"
            ]
        ],
        "abstract": "Epilepsy is a neurological disorder that affects normal neural activity. These electrical activities can be recorded as signals containing information about the brain known as Electroencephalography (EEG) signals. Analysis of the EEG signals by individuals for epilepsy diagnosis is subjective and time-consuming. So, an automatic classification system with high detection accuracy is required to overcome possible errors. In this study, the discrete wavelet transform has been applied to EEG signals. Then, entropy measures and embedding parameters have been extracted. These features have been investigated individually to find the most discriminating ones. The significance level of each feature was evaluated by statistical analysis. Consequently, LDA and SVM algorithms have been employed to categorize the EEG signals. The results have indicated that the features of Embedding parameters, PermutationEntropy, FuzzyEntropy, SampleEntropy, NormEntropy, SureEntropy, LogEntropy, and ThresholdEntropy have the potential to discriminate epileptic patients from healthy subjects significantly. Also, SVM classifier has achieved the highest classification accuracy. In this study, we could find effective embedding-based and entropy-based features as appropriate single measures for identifying abnormal activities that can efficiently discriminate the EEG signals of epileptics from healthy individuals. According to the results, they can be used for automatic classification of epileptic EEG signals that are difficult to examine visually.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07282",
        "abstract url": "https://arxiv.org/abs/2401.07282",
        "title": "Half-Space Modeling with Reflecting Surface in Molecular Communication",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "In Molecular Communications via Diffusion (MCvD), messenger molecules are emitted by a transmitter and propagate randomly through the fluidic environment. In biological systems, the environment can be considered a bounded space, surrounded by various structures such as tissues and organs. The propagation of molecules is affected by these structures, which reflect the molecules upon collision. Deriving the channel response of MCvD systems with an absorbing spherical receiver requires solving the 3-D diffusion equation in the presence of reflecting and absorbing boundary conditions, which is extremely challenging. In this paper, the method of images is brought to molecular communication (MC) realm to find a closed-form solution to the channel response of a single-input single-output (SISO) system near an infinite reflecting surface. We showed that a molecular SISO system in a 3-D half-space with an infinite reflecting surface could be approximated as a molecular single-input multiple-output (SIMO) system in a 3-D space, which consists of two symmetrically located, with respect to the reflecting surface, identical absorbing spherical receivers.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "9 pages, 10 figures"
    },
    {
        "paper id": "2401.07343",
        "abstract url": "https://arxiv.org/abs/2401.07343",
        "title": "Privacy-Preserving Intrusion Detection in Software-defined VANET using Federated Learning with BERT",
        "rating": "-3",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Federated Learning"
            ],
            [
                "attack"
            ]
        ],
        "abstract": "The absence of robust security protocols renders the VANET (Vehicle ad-hoc Networks) network open to cyber threats by compromising passengers and road safety. Intrusion Detection Systems (IDS) are widely employed to detect network security threats. With vehicles' high mobility on the road and diverse environments, VANETs devise ever-changing network topologies, lack privacy and security, and have limited bandwidth efficiency. The absence of privacy precautions, End-to-End Encryption methods, and Local Data Processing systems in VANET also present many privacy and security difficulties. So, assessing whether a novel real-time processing IDS approach can be utilized for this emerging technology is crucial. The present study introduces a novel approach for intrusion detection using Federated Learning (FL) capabilities in conjunction with the BERT model for sequence classification (FL-BERT). The significance of data privacy is duly recognized. According to FL methodology, each client has its own local model and dataset. They train their models locally and then send the model's weights to the server. After aggregation, the server aggregates the weights from all clients to update a global model. After aggregation, the global model's weights are shared with the clients. This practice guarantees the secure storage of sensitive raw data on individual clients' devices, effectively protecting privacy. After conducting the federated learning procedure, we assessed our models' performance using a separate test dataset. The FL-BERT technique has yielded promising results, opening avenues for further investigation in this particular area of research. We reached the result of our approaches by comparing existing research works and found that FL-BERT is more effective for privacy and security concerns. Our results suggest that FL-BERT is a promising technique for enhancing attack detection.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07353",
        "abstract url": "https://arxiv.org/abs/2401.07353",
        "title": "Towards Engineering Fair and Equitable Software Systems for Managing Low-Altitude Airspace Authorizations",
        "rating": "-3",
        "keywords": [
            [
                "flight"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "Small Unmanned Aircraft Systems (sUAS) have gained widespread adoption across a diverse range of applications. This has introduced operational complexities within shared airspaces and an increase in reported incidents, raising safety concerns. In response, the U.S. Federal Aviation Administration (FAA) is developing a UAS Traffic Management (UTM) system to control access to airspace based on an sUAS's predicted ability to safely complete its mission. However, a fully automated system capable of swiftly approving or denying flight requests can be prone to bias and must consider safety, transparency, and fairness to diverse stakeholders. In this paper, we present an initial study that explores stakeholders' perspectives on factors that should be considered in an automated system. Results indicate flight characteristics and environmental conditions were perceived as most important but pilot and drone capabilities should also be considered. Further, several respondents indicated an aversion to any AI-supported automation, highlighting the need for full transparency in automated decision-making. Results provide a societal perspective on the challenges of automating UTM flight authorization decisions and help frame the ongoing design of a solution acceptable to the broader sUAS community.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07445",
        "abstract url": "https://arxiv.org/abs/2401.07445",
        "title": "GACE: Learning Graph-Based Cross-Page Ads Embedding For Click-Through Rate Prediction",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "Predicting click-through rate (CTR) is the core task of many ads online recommendation systems, which helps improve user experience and increase platform revenue. In this type of recommendation system, we often encounter two main problems: the joint usage of multi-page historical advertising data and the cold start of new ads. In this paper, we proposed GACE, a graph-based cross-page ads embedding generation method. It can warm up and generate the representation embedding of cold-start and existing ads across various pages. Specifically, we carefully build linkages and a weighted undirected graph model considering semantic and page-type attributes to guide the direction of feature fusion and generation. We designed a variational auto-encoding task as pre-training module and generated embedding representations for new and old ads based on this task. The results evaluated in the public dataset AliEC from RecBole and the real-world industry dataset from Alipay show that our GACE method is significantly superior to the SOTA method. In the online A/B test, the click-through rate on three real-world pages from Alipay has increased by 3.6%, 2.13%, and 3.02%, respectively. Especially in the cold-start task, the CTR increased by 9.96%, 7.51%, and 8.97%, respectively.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "15 pages, 3 figures"
    },
    {
        "paper id": "2401.07464",
        "abstract url": "https://arxiv.org/abs/2401.07464",
        "title": "Quantum Privacy Aggregation of Teacher Ensembles (QPATE) for Privacy-preserving Quantum Machine Learning",
        "rating": "-3",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "The utility of machine learning has rapidly expanded in the last two decades and presents an ethical challenge. Papernot et. al. developed a technique, known as Private Aggregation of Teacher Ensembles (PATE) to enable federated learning in which multiple teacher models are trained on disjoint datasets. This study is the first to apply PATE to an ensemble of quantum neural networks (QNN) to pave a new way of ensuring privacy in quantum machine learning (QML) models.",
        "subjects": [
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07224",
        "abstract url": "https://arxiv.org/abs/2401.07224",
        "title": "Vehicle Selection for C-V2X Mode 4 Based Federated Edge Learning Systems",
        "rating": "-4",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Federated learning"
            ],
            [
                "survival"
            ]
        ],
        "abstract": "Federated learning (FL) is a promising technology for vehicular networks to protect vehicles' privacy in Internet of Vehicles (IoV). Vehicles with limited computation capacity may face a large computational burden associated with FL. Federated edge learning (FEEL) systems are introduced to solve such a problem. In FEEL systems, vehicles adopt the cellular-vehicle to everything (C-V2X) mode 4 to upload encrypted data to road side units' (RSUs)' cache queue. Then RSUs train the data transmitted by vehicles, update the locally model hyperparameters and send back results to vehicles, thus vehicles' computational burden can be released. However, each RSU has limited cache queue. To maintain the stability of cache queue and maximize the accuracy of model, it is essential to select appropriate vehicles to upload data. The vehicle selection method for FEEL systems faces challenges due to the random departure of data from the cache queue caused by the stochastic channel and the different system status of vehicles, such as remaining data amount, transmission delay, packet collision probability and survival ability. This paper proposes a vehicle selection method for FEEL systems that aims to maximize the accuracy of model while keeping the cache queue stable. Extensive simulation experiments demonstrate that our proposed method outperforms other baseline selection methods.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "This paper has been submitted to IEEE Systems Journal. The source code has been released at: https://github.com/qiongwu86/Vehicle-selection-for-C-V2X.git"
    },
    {
        "paper id": "2401.07379",
        "abstract url": "https://arxiv.org/abs/2401.07379",
        "title": "Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks",
        "rating": "-4",
        "keywords": [
            [
                "biology"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "One of the main goals of developmental biology is to reveal the gene regulatory networks (GRNs) underlying the robust differentiation of multipotent progenitors into precisely specified cell types. Most existing methods to infer GRNs from experimental data have limited predictive power as the inferred GRNs merely reflect gene expression similarity or correlation. Here, we demonstrate, how physics-informed neural networks (PINNs) can be used to infer the parameters of predictive, dynamical GRNs that provide mechanistic understanding of biological processes. Specifically we study GRNs that exhibit bifurcation behavior and can therefore model cell differentiation. We show that PINNs outperform regular feed-forward neural networks on the parameter inference task and analyze two relevant experimental scenarios: 1. a system with cell communication for which gene expression trajectories are available and 2. snapshot measurements of a cell population in which cell communication is absent. Our analysis will inform the design of future experiments to be analyzed with PINNs and provides a starting point to explore this powerful class of neural network models further.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": "25 pages, 8 figures"
    },
    {
        "paper id": "2401.07252",
        "abstract url": "https://arxiv.org/abs/2401.07252",
        "title": "Nanoantennas and Nanoradars: The Future of Integrated Sensing and Communication at the Nanoscale",
        "rating": "-5",
        "keywords": [
            [
                "Radar"
            ],
            [
                "medical",
                "healthcare"
            ],
            [
                "6G",
                "IoT"
            ]
        ],
        "abstract": "Nanoantennas, operating at optical frequencies, are a transformative technology with broad applications in 6G wireless communication, IoT, smart cities, healthcare, and medical imaging. This paper explores their fundamental aspects, applications, and advancements, aiming for a comprehensive understanding of their potential in various applications. It begins by investigating macroscopic and microscopic Maxwell's equations governing electromagnetic wave propagation at different scales. The study emphasizes the critical role of Surface Plasmon Polariton (SPP) wave propagation in enhancing light-matter interactions, contributing to high data rates, and enabling miniaturization. Additionally, it explores using two-dimensional materials like graphene for enhanced control in terahertz communication and sensing. The paper also introduces the employment of nanoantennas as the main building blocks of Nano-scale Radar (NR) systems for the first time in the literature. NRs, integrated with communication signals, promise accurate radar sensing for nanoparticles inside a nano-channel, making them a potential future application in integrated sensing and communication (ISAC) systems. These nano-scale radar systems detect and extract physical or electrical properties of nanoparticles through transmitting, receiving, and processing electromagnetic waves at ultra-high frequencies in the optical range. This task requires nanoantennas as transmitters/receivers/transceivers, sharing the same frequency band and hardware for high-performance sensing and resolution.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07368",
        "abstract url": "https://arxiv.org/abs/2401.07368",
        "title": "A Novel Zero-Trust Machine Learning Green Architecture for Healthcare IoT Cybersecurity: Review, Analysis, and Implementation",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Healthcare"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "The integration of Internet of Things (IoT) devices in healthcare applications has revolutionized patient care, monitoring, and data management. The Global IoT in Healthcare Market value is $252.2 Billion in 2023. However, the rapid involvement of these devices brings information security concerns that pose critical threats to patient privacy and the integrity of healthcare data. This paper introduces a novel machine learning (ML) based architecture explicitly designed to address and mitigate security vulnerabilities in IoT devices within healthcare applications. By leveraging advanced convolution ML architecture, the proposed architecture aims to proactively monitor and detect potential threats, ensuring the confidentiality and integrity of sensitive healthcare information while minimizing the cost and increasing the portability specialized for healthcare and emergency environments. The experimental results underscore the accuracy of up to 93.6% for predicting various attacks based on the results demonstrate a zero-day detection accuracy simulated using the CICIoT2023 dataset and reduces the cost by a factor of x10. The significance of our approach is in fortifying the security posture of IoT devices and maintaining a robust implementation of trustful healthcare systems.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "7 pages, 7 figures, 4 tables, under review"
    },
    {
        "paper id": "2401.07209",
        "abstract url": "https://arxiv.org/abs/2401.07209",
        "title": "Designing Visual Learning Analytics for Supporting Equity in STEM Classrooms",
        "rating": "-10",
        "keywords": [],
        "abstract": "Supporting equitable instruction is an important issue for teachers attending diverse STEM classrooms. Visual learning analytics along with effective student survey measures can support providing on time feedback to teachers in making instruction more culturally relevant to all students. We adopted a user-centered approach, where we engaged seven middle school science teachers in iterative testing of thirty data visualizations disaggregated over markers such as gender and race for implementation of selected displays in a visual learning analytics tool- Student Electronic Exit Ticket (SEET). This process helped us gather insights into teachers' sensemaking in identifying patterns of student data related to gender and race, selecting and improving the design of the feedback displays for the SEET [10].",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07216",
        "abstract url": "https://arxiv.org/abs/2401.07216",
        "title": "Walert: Putting Conversational Search Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot",
        "rating": "-10",
        "keywords": [],
        "abstract": "Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals' practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted at 2024 ACM SIGIR CHIIR"
    },
    {
        "paper id": "2401.07232",
        "abstract url": "https://arxiv.org/abs/2401.07232",
        "title": "Polariton lattices as binarized neuromorphic networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a novel neuromorphic network architecture based on a lattice of exciton-polariton condensates, intricately interconnected and energized through non-resonant optical pumping. The network employs a binary framework, where each neuron, facilitated by the spatial coherence of pairwise coupled condensates, performs binary operations. This coherence, emerging from the ballistic propagation of polaritons, ensures efficient, network-wide communication. The binary neuron switching mechanism, driven by the nonlinear repulsion through the excitonic component of polaritons, offers computational efficiency and scalability advantages over continuous weight neural networks. Our network enables parallel processing, enhancing computational speed compared to sequential or pulse-coded binary systems. The system's performance was evaluated using the MNIST dataset for handwritten digit recognition, showcasing the potential to outperform existing polaritonic neuromorphic systems, as demonstrated by its impressive predicted classification accuracy of up to 97.5%.",
        "subjects": [
            "cond-mat.dis-nn"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07242",
        "abstract url": "https://arxiv.org/abs/2401.07242",
        "title": "Testing Sumsets is Hard",
        "rating": "-10",
        "keywords": [],
        "abstract": "A subset $S$ of the Boolean hypercube $\\mathbb{F}_2^n$ is a sumset if $S = \\{a + b : a, b\\in A\\}$ for some $A \\subseteq \\mathbb{F}_2^n$. Sumsets are central objects of study in additive combinatorics, featuring in several influential results. We prove a lower bound of $\u03a9(2^{n/2})$ for the number of queries needed to test whether a Boolean function $f:\\mathbb{F}_2^n \\to \\{0,1\\}$ is the indicator function of a sumset. Our lower bound for testing sumsets follows from sharp bounds on the related problem of shift testing, which may be of independent interest. We also give a near-optimal $2^{n/2} \\cdot \\mathrm{poly}(n)$-query algorithm for a smoothed analysis formulation of the sumset refutation problem.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2401.07246",
        "abstract url": "https://arxiv.org/abs/2401.07246",
        "title": "Delayed finite-dimensional observer-based control of 2D linear parabolic PDEs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, a constructive method was suggested for finite-dimensional observer-based control of 1D linear heat equation, which is robust to input/output delays. In this paper, we aim to extend this method to the 2D case with general time-varying input/output delays (known output delay and unknown input delay) or sawtooth delays (that correspond to network-based control). We use the modal decomposition approach and consider boundary or non-local sensing together with non-local actuation, or Neumann actuation with non-local sensing. To compensate the output delay that appears in the infinite-dimensional part of the closed-loop system, for the first time for delayed PDEs we suggest a vector Lyapunov functional combined with the recently introduced vector Halanay inequality. We provide linear matrix inequality (LMI) conditions for finding the observer dimension and upper bounds on delays that preserve the exponential stability. We prove that the LMIs are always feasible for large enough observer dimension and small enough upper bounds on delays. A numerical example demonstrates the efficiency of our method and shows that the employment of vector Halanay's inequality allows for larger delays than the classical scalar Halanay inequality for comparatively large observer dimension.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07276",
        "abstract url": "https://arxiv.org/abs/2401.07276",
        "title": "Inkjet printed intelligent reflecting surface (IRS) for indoor applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "A passive, low-cost, paper-based intelligent reflecting surface (IRS) is designed to reflect a signal in a desired direction to overcome non-line-of-sight scenarios in indoor environments. The IRS is fabricated using conductive silver ink printed on a paper with a specific nanoparticle arrangement, yielding a cost effective paper-based IRS that can easily be mass-produced. Full-wave numerical simulation results were consistent with measurements results, demonstrating the IRS's ability to reflect incident wave into a desired nonspecular direction based on the inkjet-printed design and materials.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07283",
        "abstract url": "https://arxiv.org/abs/2401.07283",
        "title": "FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF Acquisition",
        "rating": "-10",
        "keywords": [],
        "abstract": "Efficient and accurate BRDF acquisition of real world materials is a challenging research problem that requires sampling millions of incident light and viewing directions. To accelerate the acquisition process, one needs to find a minimal set of sampling directions such that the recovery of the full BRDF is accurate and robust given such samples. In this paper, we formulate BRDF acquisition as a compressed sensing problem, where the sensing operator is one that performs sub-sampling of the BRDF signal according to a set of optimal sample directions. To solve this problem, we propose the Fast and Robust Optimal Sampling Technique (FROST) for designing a provably optimal sub-sampling operator that places light-view samples such that the recovery error is minimized. FROST casts the problem of designing an optimal sub-sampling operator for compressed sensing into a sparse representation formulation under the Multiple Measurement Vector (MMV) signal model. The proposed reformulation is exact, i.e. without any approximations, hence it converts an intractable combinatorial problem into one that can be solved with standard optimization techniques. As a result, FROST is accompanied by strong theoretical guarantees from the field of compressed sensing. We perform a thorough analysis of FROST-BRDF using a 10-fold cross-validation with publicly available BRDF datasets and show significant advantages compared to the state-of-the-art with respect to reconstruction quality. Finally, FROST is simple, both conceptually and in terms of implementation, it produces consistent results at each run, and it is at least two orders of magnitude faster than the prior art.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "Submitted to IEEE Transactions on Visualization and Computer Graphics (IEEE TVCG)"
    },
    {
        "paper id": "2401.07288",
        "abstract url": "https://arxiv.org/abs/2401.07288",
        "title": "Hybrid Coded-Uncoded Caching in Multi-Access Networks with Non-uniform Demands",
        "rating": "-10",
        "keywords": [],
        "abstract": "To address the massive growth of data traffic over cellular networks, increasing spatial reuse of the frequency spectrum by the deployment of small base stations (SBSs) has been considered. For rapid deployment of SBSs in the networks, caching popular content along with new coded caching schemes are proposed. To maximize the cellular network's capacity, densifying it with small base stations is inevitable. In ultra-dense cellular networks, coverage of SBSs may overlap. To this aim, the multi-access caching system, where users potentially can access multiple cache nodes simultaneously, has attracted more attention in recent years. Most previous works on multi-access coded caching, only consider specific conditions such as cyclic wrap-around network topologies. In this paper, we investigate caching in ultra-dense cellular networks, where different users can access different numbers of caches under non-uniform content popularity distribution, and propose Multi-Access Hybrid coded-uncoded Caching (MAHC). We formulate the optimization problem of the proposed scheme for general network topologies and evaluate it for 2-SBS network scenarios. The numerical and simulation results show that the proposed MAHC scheme outperforms optimal conventional uncoded and previous multi-access coded caching (MACC) schemes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2401.07290",
        "abstract url": "https://arxiv.org/abs/2401.07290",
        "title": "Optimizing a Data Science System for Text Reuse Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Text reuse is a methodological element of fundamental importance in humanities research: pieces of text that re-appear across different documents, verbatim or paraphrased, provide invaluable information about the historical spread and evolution of ideas. Large modern digitized corpora enable the joint analysis of text collections that span entire centuries and the detection of large-scale patterns, impossible to detect with traditional small-scale analysis. For this opportunity to materialize, it is necessary to develop efficient data science systems that perform the corresponding analysis tasks. In this paper, we share insights from ReceptionReader, a system for analyzing text reuse in large historical corpora. The system is built upon billions of instances of text reuses from large digitized corpora of 18th-century texts. Its main functionality is to perform downstream text reuse analysis tasks, such as finding reuses that stem from a given article or identifying the most reused quotes from a set of documents, with each task expressed as a database query. For the purposes of the paper, we discuss the related design choices including various database normalization levels and query execution frameworks, such as distributed data processing (Apache Spark), indexed row store engine (MariaDB Aria), and compressed column store engine (MariaDB Columnstore). Moreover, we present an extensive evaluation with various metrics of interest (latency, storage size, and computing costs) for varying workloads, and we offer insights from the trade-offs we observed and the choices that emerged as optimal in our setting. In summary, our results show that (1) for the workloads that are most relevant to text-reuse analysis, the MariaDB Aria framework emerges as the overall optimal choice, (2) big data processing (Apache Spark) is irreplaceable for all processing stages of the system's pipeline.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "Early Draft"
    },
    {
        "paper id": "2401.07305",
        "abstract url": "https://arxiv.org/abs/2401.07305",
        "title": "Detecting Service Slowdown using Observational Data",
        "rating": "-10",
        "keywords": [],
        "abstract": "Being able to detect service slowdowns is crucial to many operational problems. We study how to use observational congestion data to detect service slowdown in a multi-server system, and in particular, the statistical implications of running adaptive congestion control mechanisms in such settings. We show that a commonly used summary statistic that relies on the marginal congestion measured at individual servers can be highly inaccurate in the presence of adaptive congestion control. We propose a new statistic based on potential routing actions, and show it provides a much more robust signal for server slowdown in these settings. Unlike the marginal statistic, potential action aims to detect changes in the routing actions, and is able to uncover slowdowns even when they do not reflect in marginal congestion. Our work highlights the complexity in performing observational statistical analysis for service systems in the presence of adaptive congestion control. Our results also suggest that practitioners may want to combine multiple, orthogonal statistics to achieve reliable slowdown detection.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07308",
        "abstract url": "https://arxiv.org/abs/2401.07308",
        "title": "Structured Acyclic Nets",
        "rating": "-10",
        "keywords": [],
        "abstract": "The concept of structured occurrence nets is an extension of that of occurrence nets which are directed acyclic graphs that represent causality and concurrency information concerning a single execution of a distributed system. The formalism of structured occurrence nets has been introduced to facilitate the portrayal and analysis of the behaviours, and in particular failures, of complex evolving systems. Such systems are composed of a large number of sub-systems which may proceed concurrently and interact with each other and with the external environment while their behaviour is subject to modification by other systems. The purpose of this paper is to provide an extension of structured occurrence nets to include models built up of acyclic nets rather than occurrence nets.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07312",
        "abstract url": "https://arxiv.org/abs/2401.07312",
        "title": "Understanding Nonlinear Collaboration between Human and AI Agents: A Co-design Framework for Creative Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Creative design is a nonlinear process where designers generate diverse ideas in the pursuit of an open-ended goal and converge towards consensus through iterative remixing. In contrast, AI-powered design tools often employ a linear sequence of incremental and precise instructions to approximate design objectives. Such operations violate customary creative design practices and thus hinder AI agents' ability to complete creative design tasks. To explore better human-AI co-design tools, we first summarize human designers' practices through a formative study with 12 design experts. Taking graphic design as a representative scenario, we formulate a nonlinear human-AI co-design framework and develop a proof-of-concept prototype, OptiMuse. We evaluate OptiMuse and validate the nonlinear framework through a comparative study. We notice a subconscious change in people's attitudes towards AI agents, shifting from perceiving them as mere executors to regarding them as opinionated colleagues. This shift effectively fostered the exploration and reflection processes of individual designers.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "to be published in CHI 2024"
    },
    {
        "paper id": "2401.07319",
        "abstract url": "https://arxiv.org/abs/2401.07319",
        "title": "The MacWilliams Identity for Krawtchouk Association Schemes",
        "rating": "-10",
        "keywords": [],
        "abstract": "The MacWilliams Identity is a well established theorem relating the weight enumerator of a code to the weight enumerator of its dual. The ability to use a known weight enumerator to generate the weight enumerator of another through a simple transform proved highly effective and efficient. An equivalent relation was also developed by Delsarte which linked the eigenvalues of any association scheme to the eigenvalues of it's dual association scheme but this was less practical to use in reality. A functional transform was developed for some specific association schemes including those based on the rank metric, the skew rank metric and Hermitian matrices. In this paper those results are unified into a single consistent theory applied to these \"Krawtchouk association schemes\" using a $b$-algebra. The derivatives formed using the $b$-algebra have also been applied to derive the moments of the weight distribution for any code within these association schemes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "48 pages"
    },
    {
        "paper id": "2401.07337",
        "abstract url": "https://arxiv.org/abs/2401.07337",
        "title": "Individual and Collective Welfare in Risk Sharing with Many States",
        "rating": "-10",
        "keywords": [],
        "abstract": "We provide a quantitative assessment of welfare in the classical model of risk-sharing and exchange under uncertainty. We prove three kinds of results. First, that in an equilibrium allocation, the scope for improving individual welfare by a given margin (an $\\varepsilon$-improvement) vanishes as the number of states increases. Second, that the scope for a change in aggregate resources that may be distributed to enhance individual welfare by a given margin also vanishes. Equivalently: in an inefficient allocation, for a given level of resource sub-optimality (as measured by the coefficient of resource under-utilization), the possibilities for enhancing welfare by perturbing aggregate resources decrease exponentially to zero with the number of states. Finally, we consider efficient risk-sharing in standard models of uncertainty aversion with multiple priors, and show that, in an inefficient allocation, certain sets of priors shrink with the size of the state space.",
        "subjects": [
            "econ.TH"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07356",
        "abstract url": "https://arxiv.org/abs/2401.07356",
        "title": "BUGSPHP: A dataset for Automated Program Repair in PHP",
        "rating": "-10",
        "keywords": [],
        "abstract": "Automated Program Repair (APR) improves developer productivity by saving debugging and bug-fixing time. While APR has been extensively explored for C/C++ and Java programs, there is little research on bugs in PHP programs due to the lack of a benchmark PHP bug dataset. This is surprising given that PHP has been one of the most widely used server-side languages for over two decades, being used in a variety of contexts such as e-commerce, social networking, and content management. This paper presents a benchmark dataset of PHP bugs on real-world applications called BUGSPHP, which can enable research on analysis, testing, and repair for PHP programs. The dataset consists of training and test datasets, separately curated from GitHub and processed locally. The training dataset includes more than 600,000 bug-fixing commits. The test dataset contains 513 manually validated bug-fixing commits equipped with developer-provided test cases to assess patch correctness.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07381",
        "abstract url": "https://arxiv.org/abs/2401.07381",
        "title": "Diagrammatic Rules for Triad Census",
        "rating": "-10",
        "keywords": [],
        "abstract": "In network theory, a triad census is a method designed to categorize and enumerate the various types of subgraphs with three nodes and their connecting edges within a network. Triads serve as fundamental building blocks for comprehending the structure and dynamics of networks, and the triad census offers a systematic approach to their classification. Typically, triad counts are obtained numerically, but lesser-known methods have been developed to precisely evaluate them without the need for sampling. In our study, we build upon Moody's matrix approach, presenting general diagrammatic rules that systematically and intuitively generate closed formulas for the occurrence numbers of triads in a network.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "15 pages, 1 figures"
    },
    {
        "paper id": "2401.07404",
        "abstract url": "https://arxiv.org/abs/2401.07404",
        "title": "Fairness-aware Photovoltaic Generation Limits for Voltage Regulation in Power Distribution Networks using Conservative Linear Approximations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes a framework for fairly curtailing photovoltaic (PV) plants in response to the over-voltage problem in PV-rich distribution networks. The framework imposes PV generation limits to avoid overvoltages. These limits are computed a day ahead of real-time operations by solving an offline stochastic optimization problem using forecasted scenarios for PV generation and load demand. The framework minimizes the overall curtailment while considering fairness by reducing disparities in curtailments among different PV owners. We model the distribution grid constraints using a conservative linear approximation (CLA) of the AC power flow equations which is computed using a set of sampled power injections from the day-ahead predicted scenarios. The proposed framework is numerically validated on a CIGRE benchmark network interfaced with a large number of PV plants. We compare the performance of the proposed framework versus an alternative formulation that does not incorporate fairness considerations. To this end, we assess tradeoffs between fairness, as quantified with the Jain Fairness Index (JFI), and the total curtailed energy.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages (to appear in the 8th Texas Power and Energy Conference, February 12-13, 2024.)"
    },
    {
        "paper id": "2401.07411",
        "abstract url": "https://arxiv.org/abs/2401.07411",
        "title": "Startup Delay Aware Short Video Ordering: Problem, Model, and A Reinforcement Learning based Algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "Short video applications have attracted billions of users on the Internet and can satisfy diverse users' fragmented spare time with content-rich and duration-short videos. To achieve fast playback at user side, existing short video systems typically enforce burst transmission of initial segment of each video when being requested for improved quality of user experiences. However, such a way of burst transmissions can cause unexpected large startup delays at user side. This is because users may frequently switch videos when sequentially watching a list of short videos recommended by the server side, which can cause excessive burst transmissions of initial segments of different short videos and thus quickly deplete the network transmission capacity. In this paper, we adopt token bucket to characterize the video transmission path between video server and each user, and accordingly study how to effectively reduce the startup delay of short videos by effectively arranging the viewing order of a video list at the server side. We formulate the optimal video ordering problem for minimizing the maximum video startup delay as a combinatorial optimization problem and prove its NP-hardness. We accordingly propose a Partially Shared Actor Critic reinforcement learning algorithm (PSAC) to learn optimized video ordering strategy. Numerical results based on a real dataset provided by a large-scale short video service provider demonstrate that the proposed PSAC algorithm can significantly reduce the video startup delay compared to baseline algorithms.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07417",
        "abstract url": "https://arxiv.org/abs/2401.07417",
        "title": "A Comparative Examination of Network and Contract-Based Blockchain Storage Solutions for Decentralized Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Decentralized applications (DApps), which are innovative blockchain-powered software systems designed to serve as the fundamental building blocks for the next generation of Internet services, have witnessed exponential growth in recent years. This paper thoroughly compares and analyzes two blockchain-based decentralized storage networks (DSNs), which are crucial foundations for DApp and blockchain ecosystems. The study examines their respective mechanisms for data persistence, strategies for enforcing data retention, and token economics. In addition to delving into technical details, the suitability of each storage solution for decentralized application development is assessed, taking into consideration network performance, storage costs, and existing use cases. By evaluating these factors, the paper aims to provide insights into the effectiveness of these technologies in supporting the desirable properties of truly decentralized blockchain applications. In conclusion, the findings of this research are discussed and synthesized, offering valuable perspectives on the capabilities of these technologies. It sheds light on their potential to facilitate the development of DApps and provides an understanding of the ongoing trends in blockchain development.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "13 pages, 1 figure, published in Proceedings of the 3rd International Conference on Digital Economy and Computer Application (DECA 2023)"
    },
    {
        "paper id": "2401.07422",
        "abstract url": "https://arxiv.org/abs/2401.07422",
        "title": "Multiperson Detection and Vital-Sign Sensing Empowered by Space-Time-Coding RISs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Passive human sensing using wireless signals has attracted increasing attention due to its superiorities of non-contact and robustness in various lighting conditions. However, when multiple human individuals are present, their reflected signals could be intertwined in the time, frequency and spatial domains, making it challenging to separate them. To address this issue, this paper proposes a novel system for multiperson detection and monitoring of vital signs (i.e., respiration and heartbeat) with the assistance of space-time-coding (STC) reconfigurable intelligent metasurfaces (RISs). Specifically, the proposed system scans the area of interest (AoI) for human detection by using the harmonic beams generated by the STC RIS. Simultaneously, frequencyorthogonal beams are assigned to each detected person for accurate estimation of their respiration rate (RR) and heartbeat rate (HR). Furthermore, to efficiently extract the respiration signal and the much weaker heartbeat signal, we propose an improved variational mode decomposition (VMD) algorithm to accurately decompose the complex reflected signals into a smaller number of intrinsic mode functions (IMFs). We build a prototype to validate the proposed multiperson detection and vital-sign monitoring system. Experimental results demonstrate that the proposed system can simultaneously monitor the vital signs of up to four persons. The errors of RR and HR estimation using the improved VMD algorithm are below 1 RPM (respiration per minute) and 5 BPM (beats per minute), respectively. Further analysis reveals that the flexible beam controlling mechanism empowered by the STC RIS can reduce the noise reflected from other irrelative objects on the physical layer, and improve the signal-to-noise ratio of echoes from the human chest.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07425",
        "abstract url": "https://arxiv.org/abs/2401.07425",
        "title": "ZEH-oriented Linear Programming for the Sizing Problem of Photovoltaic Panels and Batteries",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we explore the concept of net-Zero Energy Houses (ZEH) - houses designed to have an annual net energy consumption around zero. To achieve this, we present a constrained optimization problem whose objective is finding the optimal sizing of photovoltaic panels and a battery system to be integrated at home. The original optimization problem is nonlinear with nonconvex constraints. Nevertheless, by applying a series of transformations, it is possible to find an equivalent Linear Programming (LP) problem which is computationally tractable. The attainment of ZEH can be tackled by introducing a single constraint in the optimization problem. Additionally, we propose a sharing economy approach to the investment problem, a strategy that carries the potential to reduce the cost of the investment and facilitate the attainment of ZEH in a more efficient manner. Finally, we apply the proposed frameworks to a neighborhood in Japan as a case study, demonstrating the potential for long-term ZEH attainment. The results show the importance of choosing an appropriate incentive to motivate residents towards achieving ZEH.",
        "subjects": [
            "math.OC"
        ],
        "comment": "11 pages, 13 figures, 5 tables"
    },
    {
        "paper id": "2401.07429",
        "abstract url": "https://arxiv.org/abs/2401.07429",
        "title": "Accelerating Boolean Constraint Propagation for Efficient SAT-Solving on FPGAs",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a hardware-accelerated SAT solver targeting processor/Field Programmable Gate Arrays (FPGA) SoCs. Our solution accelerates the most expensive subroutine of the Davis-Putnam-Logemann-Loveland (DPLL) algorithm, Boolean Constraint Propagation (BCP) through fine-grained FPGA parallelism. Unlike prior state-of-the-art solutions, our solver eliminates costly clause look-up operations by assigning clauses directly to clause processors on the FPGA and dividing large formulas into smaller partitions manageable by FPGA. Partitions are hot-swapped during runtime as required and the supported formula size is limited only by available external memory, not on-chip FPGA memory. We evaluate our solver on a Xilinx Zynq platform with results showing quicker execution time across various formula sizes, subject to formula partitioning strategy. Compared to prior state-of-the-art, we achieve 1.7x and 1.1x speed up on BCP for 2 representative benchmarks and up to 6x total speedup over software-only implementation.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Accepted at ACM GLSVLSI 2024"
    },
    {
        "paper id": "2401.07433",
        "abstract url": "https://arxiv.org/abs/2401.07433",
        "title": "Fast Successive-Cancellation Decoding of 2 x 2 Kernel Non-Binary Polar Codes: Identification, Decoding and Simplification",
        "rating": "-10",
        "keywords": [],
        "abstract": "Non-binary polar codes (NBPCs) decoded by successive cancellation (SC) algorithm have remarkable bit-error-rate performance compared to the binary polar codes (BPCs). Due to the serial nature, SC decoding suffers from large latency. The latency issue in BPCs has been the topic of extensive research and it has been notably resolved by the introduction of fast SC-based decoders. However, the vast majority of research on NBPCs is devoted to issues concerning design and efficient implementation. In this paper, we propose fast SC decoding for NBPCs constructed based on 2 x 2 kernels. In particular, we identify various non-binary special nodes in the SC decoding tree of NBPCs and propose their fast decoding. This way, we avoid traversing the full decoding tree and significantly reduce the decoding delay compared to symbol-by-symbol SC decoding. We also propose a simplified NBPC structure that facilitates the procedure of non-binary fast SC decoding. Using our proposed fast non-binary decoder, we observed an improvement of up to 95% in latency concerning the original SC decoding. This is while our proposed fast SC decoder for NBPCs incurs no error-rate loss.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07435",
        "abstract url": "https://arxiv.org/abs/2401.07435",
        "title": "Manifolds from Partitions",
        "rating": "-10",
        "keywords": [],
        "abstract": "If f maps a discrete d-manifold G onto a (k+1)-partite complex P then H(G,f,P),the set of simplices x in G such that f(x) contains at least one facet in P defines a (d-k)-manifold.",
        "subjects": [
            "math.GT"
        ],
        "comment": "12 pages, 8 figures, added more code and statistics example"
    },
    {
        "paper id": "2401.07440",
        "abstract url": "https://arxiv.org/abs/2401.07440",
        "title": "The Fairness of Redistricting Ghost",
        "rating": "-10",
        "keywords": [],
        "abstract": "We explore the fairness of a redistricting game introduced by Mixon and Villar, which provides a two-party protocol for dividing a state into electoral districts, without the participation of an independent authority. We analyze the game in an abstract setting that ignores the geographic distribution of voters and assumes that voter preferences are fixed and known. We show that the minority player can always win at least $p-1$ districts, where $p$ is proportional to the percentage of minority voters. We give an upper bound on the number of districts won by the minority based on a \"cracking\" strategy for the majority.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07446",
        "abstract url": "https://arxiv.org/abs/2401.07446",
        "title": "Quantized RIS-aided mmWave Massive MIMO Channel Estimation with Uniform Planar Arrays",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate a cascaded channel estimation method for a millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) system aided by a reconfigurable intelligent surface (RIS) with the BS equipped with low-resolution analog-to-digital converters (ADCs), where the BS and the RIS are both equipped with a uniform planar array (UPA). Due to the sparse property of mmWave channel, the channel estimation can be solved as a compressed sensing (CS) problem. However, the low-resolution quantization cause severe information loss of signals, and traditional CS algorithms are unable to work well. To recovery the signal and the sparse angular domain channel from quantization, we introduce Bayesian inference and efficient vector approximate message passing (VAMP) algorithm to solve the quantize output CS problem. To further improve the efficiency of the VAMP algorithm, a Fast Fourier Transform (FFT) based fast computation method is derived. Simulation results demonstrate the effectiveness and the accuracy of the proposed cascaded channel estimation method for the RIS-aided mmWave massive MIMO system with few-bit ADCs. Furthermore, the proposed channel estimation method can reach an acceptable performance gap between the low-resolution ADCs and the infinite ADCs for the low signal-to-noise ratio (SNR), which implies the applicability of few-bit ADCs in practice.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07451",
        "abstract url": "https://arxiv.org/abs/2401.07451",
        "title": "Zone-Specific CSI Feedback for Massive MIMO: A Situation-Aware Deep Learning Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Massive MIMO basestations, operating with frequency-division duplexing (FDD), require the users to feedback their channel state information (CSI) in order to design the precoding matrices. Given the powerful capabilities of deep neural networks in learning quantization codebooks, utilizing these networks in compressing the channels and reducing the massive MIMO CSI feedback overhead has recently gained increased interest. Learning one model, however, for the full cell or sector may not be optimal as the channel distribution could change significantly from one \\textit{zone} (an area or region) to another. In this letter, we introduce the concept of \\textit{zone-specific} CSI feedback. By partitioning the site space into multiple channel zones, the underlying channel distribution can be efficiently leveraged to reduce the CSI feedback. This concept leverages the implicit or explicit user position information to select the right zone-specific model and its parameters. To facilitate the evaluation of associated overhead, we introduce two novel metrics named \\textit{model parameters transmission rate} (MPTR) and \\textit{model parameters update rate} (MPUR). They jointly provide important insights and guidance for the system design and deployment. Simulation results show that significant gains could be achieved by the proposed framework. For example, using the large-scale Boston downtown scenario of DeepMIMO, the proposed zone-specific CSI feedback approach can on average achieve around 6dB NMSE gain compared to the other solutions, while keeping the same model complexity.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Datasets and code files will be available on the DeepMIMO website: https://www.deepmimo.net/"
    },
    {
        "paper id": "2401.07454",
        "abstract url": "https://arxiv.org/abs/2401.07454",
        "title": "Evolutionary Multi-Objective Diversity Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Creating diverse sets of high quality solutions has become an important problem in recent years. Previous works on diverse solutions problems consider solutions' objective quality and diversity where one is regarded as the optimization goal and the other as the constraint. In this paper, we treat this problem as a bi-objective optimization problem, which is to obtain a range of quality-diversity trade-offs. To address this problem, we frame the evolutionary process as evolving a population of populations, and present a suitable general implementation scheme that is compatible with existing evolutionary multi-objective search methods. We realize the scheme in NSGA-II and SPEA2, and test the methods on various instances of maximum coverage, maximum cut and minimum vertex cover problems. The resulting non-dominated populations exhibit rich qualitative features, giving insights into the optimization instances and the quality-diversity trade-offs they induce.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "12 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2401.07465",
        "abstract url": "https://arxiv.org/abs/2401.07465",
        "title": "Power Flow Analysis Using Deep Neural Networks in Three-Phase Unbalanced Smart Distribution Grids",
        "rating": "-10",
        "keywords": [],
        "abstract": "Most power systems' approaches are currently tending towards stochastic and probabilistic methods due to the high variability of renewable sources and the stochastic nature of loads. Conventional power flow (PF) approaches such as forward-backward sweep (FBS) and Newton-Raphson require a high number of iterations to solve non-linear PF equations making them computationally very intensive. PF is the most important study performed by utility, required in all stages of the power system, especially in operations and planning. This paper discusses the applications of deep learning (DL) to predict PF solutions for three-phase unbalanced power distribution grids. Three deep neural networks (DNNs); Radial Basis Function Network (RBFnet), Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN), are proposed in this paper to predict PF solutions. The PF problem is formulated as a multi-output regression model where two or more output values are predicted based on the inputs. The training and testing data are generated through the OpenDSS-MATLAB COM interface. These methods are completely data-driven where the training relies on reducing the mismatch at each node without the need for the knowledge of the system. The novelty of the proposed methodology is that the models can accurately predict the PF solutions for the unbalanced distribution grids with mutual coupling and are robust to different R/X ratios, topology changes as well as generation and load variability introduced by the integration of distributed energy resources (DERs) and electric vehicles (EVs). To test the efficacy of the DNN models, they are applied to IEEE 4-node and 123-node test cases, and the American Electric Power (AEP) feeder model. The PF results for RBFnet, MLP, and CNN models are discussed in this paper demonstrating that all three DNN models provide highly accurate results in predicting PF solutions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07466",
        "abstract url": "https://arxiv.org/abs/2401.07466",
        "title": "Your Instructions Are Not Always Helpful: Assessing the Efficacy of Instruction Fine-tuning for Software Vulnerability Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software, while beneficial, poses potential cybersecurity risks due to inherent vulnerabilities. Detecting these vulnerabilities is crucial, and deep learning has shown promise as an effective tool for this task due to its ability to perform well without extensive feature engineering. However, a challenge in deploying deep learning for vulnerability detection is the limited availability of training data. Recent research highlights the deep learning efficacy in diverse tasks. This success is attributed to instruction fine-tuning, a technique that remains under-explored in the context of vulnerability detection. This paper investigates the capability of models, specifically a recent language model, to generalize beyond the programming languages used in their training data. It also examines the role of natural language instructions in enhancing this generalization. Our study evaluates the model performance on a real-world dataset to predict vulnerable code. We present key insights and lessons learned, contributing to understanding the deep learning application in software vulnerability detection.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07467",
        "abstract url": "https://arxiv.org/abs/2401.07467",
        "title": "Selection Improvements for the Parallel Iterative Algorithm for Stable Matching",
        "rating": "-10",
        "keywords": [],
        "abstract": "Sequential algorithms for the Stable Matching Problem are often too slow in the context of some large scale applications like switch scheduling. Parallel architectures can offer a notable decrease in runtime complexity. We propose a stable matching algorithm using n^2 processors that converges in O(nlog(n)) average runtime. The algorithm is structurally based on the Parallel Iterative Improvement (PII) algorithm, where we improve the convergence from 90% to 100%. We suggest alternative selection methods for pairs in the PII algorithm, called Right-Minimum and Dynamic Selection, resulting in full convergence over 3.3 million trials and generally much faster termination.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08700",
        "abstract url": "https://arxiv.org/abs/2401.08700",
        "title": "Computationally Efficient Optimisation of Elbow-Type Draft Tube Using Neural Network Surrogates",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study aims to provide a comprehensive assessment of single-objective and multi-objective optimisation algorithms for the design of an elbow-type draft tube, as well as to introduce a computationally efficient optimisation workflow. The proposed workflow leverages deep neural network surrogates trained on data obtained from numerical simulations. The use of surrogates allows for a more flexible and faster evaluation of novel designs. The success history-based adaptive differential evolution with linear reduction and the multi-objective evolutionary algorithm based on decomposition were identified as the best-performing algorithms and used to determine the influence of different objectives in the single-objective optimisation and their combined impact on the draft tube design in the multi-objective optimisation. The results for the single-objective algorithm are consistent with those of the multi-objective algorithm when the objectives are considered separately. Multi-objective approach, however, should typically be chosen, especially for computationally inexpensive surrogates. A multi-criteria decision analysis method was used to obtain optimal multi-objective results, showing an improvement of 1.5% and 17% for the pressure recovery factor and drag coefficient, respectively. The difference between the predictions and the numerical results is less than 0.5% for the pressure recovery factor and 3% for the drag coefficient. As the demand for renewable energy continues to increase, the relevance of data-driven optimisation workflows, as discussed in this study, will become increasingly important, especially in the context of global sustainability efforts.",
        "subjects": [
            "math.OC"
        ],
        "comment": "41 pages, brief appendix"
    },
    {
        "paper id": "2401.08702",
        "abstract url": "https://arxiv.org/abs/2401.08702",
        "title": "Do We Really Even Need Data?",
        "rating": "-10",
        "keywords": [],
        "abstract": "As artificial intelligence and machine learning tools become more accessible, and scientists face new obstacles to data collection (e.g. rising costs, declining survey response rates), researchers increasingly use predictions from pre-trained algorithms as outcome variables. Though appealing for financial and logistical reasons, using standard tools for inference can misrepresent the association between independent variables and the outcome of interest when the true, unobserved outcome is replaced by a predicted value. In this paper, we characterize the statistical challenges inherent to this so-called ``inference with predicted data'' problem and elucidate three potential sources of error: (i) the relationship between predicted outcomes and their true, unobserved counterparts, (ii) robustness of the machine learning model to resampling or uncertainty about the training data, and (iii) appropriately propagating not just bias but also uncertainty from predictions into the ultimate inference procedure.",
        "subjects": [
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10284",
        "abstract url": "https://arxiv.org/abs/2401.10284",
        "title": "MorpheusNet: Resource efficient sleep stage classifier for embedded on-line systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Sleep Stage Classification (SSC) is a labor-intensive task, requiring experts to examine hours of electrophysiological recordings for manual classification. This is a limiting factor when it comes to leveraging sleep stages for therapeutic purposes. With increasing affordability and expansion of wearable devices, automating SSC may enable deployment of sleep-based therapies at scale. Deep Learning has gained increasing attention as a potential method to automate this process. Previous research has shown accuracy comparable to manual expert scores. However, previous approaches require sizable amount of memory and computational resources. This constrains the ability to classify in real time and deploy models on the edge. To address this gap, we aim to provide a model capable of predicting sleep stages in real-time, without requiring access to external computational sources (e.g., mobile phone, cloud). The algorithm is power efficient to enable use on embedded battery powered systems. Our compact sleep stage classifier can be deployed on most off-the-shelf microcontrollers (MCU) with constrained hardware settings. This is due to the memory footprint of our approach requiring significantly fewer operations. The model was tested on three publicly available data bases and achieved performance comparable to the state of the art, whilst reducing model complexity by orders of magnitude (up to 280 times smaller compared to state of the art). We further optimized the model with quantization of parameters to 8 bits with only an average drop of 0.95% in accuracy. When implemented in firmware, the quantized model achieves a latency of 1.6 seconds on an Arm CortexM4 processor, allowing its use for on-line SSC-based therapies.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This paper was presented at the 2023 IEEE conference on Systems, Man, and Cybernetics (SMC)"
    },
    {
        "paper id": "2402.18581",
        "abstract url": "https://arxiv.org/abs/2402.18581",
        "title": "Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The significance of transportation efficiency, safety, and related services is increasing in urban vehicular networks. Within such networks, roadside units (RSUs) serve as intermediates in facilitating communication. Therefore, the deployment of RSUs is of utmost importance in ensuring the quality of communication services. However, the optimization objectives, such as time delay and deployment cost, are commonly developed from diverse perspectives. As a result, it is possible that conflicts may arise among the objectives. Furthermore, in urban environments, the presence of various obstacles, such as buildings, gardens, lakes, and other infrastructure, poses challenges for the deployment of RSUs. Hence, the deployment encounters significant difficulties due to the existence of multiple objectives, constraints imposed by obstacles, and the necessity to explore a large-scale optimization space. To address this issue, two versions of multi-objective optimization algorithms are proposed in this paper. By utilizing a multi-population strategy and an adaptive exploration technique, the methods efficiently explore a large-scale decision-variable space. In order to mitigate the issue of an overcrowded deployment of RSUs, a calibrating mechanism is adopted to adjust RSU density during the optimization procedures. The proposed methods also take care of data offloading between vehicles and RSUs by setting up an iterative best response sequence game (IBRSG). By comparing the proposed algorithms with several state-of-the-art algorithms, the results demonstrate that our strategies perform better in both high-density and low-density urban scenarios. The results also indicate that the proposed solutions substantially improve the efficiency of vehicular networks.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "This manuscript has been submitted to the journal of IEEE Transactions on Vehicular Technology"
    },
    {
        "paper id": "2402.18582",
        "abstract url": "https://arxiv.org/abs/2402.18582",
        "title": "Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API",
        "rating": "-10",
        "keywords": [],
        "abstract": "The escalating volume of academic literature presents a formidable challenge in staying updated with the newest research developments. Addressing this, this study introduces a pioneering AI-based tool, configured specifically to streamline the efficiency of the article selection phase in Systematic Literature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4 Assistant API, the tool successfully homogenizes the article selection process across a broad array of academic disciplines. Implemented through a tripartite approach consisting of data preparation, AI-mediated article assessment, and structured result presentation, this tool significantly accelerates the time-consuming task of literature reviews. Importantly, this tool could be highly beneficial in fields such as management and economics, where the SLR process involves substantial human judgment. The adoption of a standard GPT model can substantially reduce potential biases and enhance the speed and precision of the SLR selection phase. This not only amplifies researcher productivity and accuracy but also denotes a considerable stride forward in the way academic research is conducted amidst the surging body of scholarly publications.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "11 pages, 5 figures"
    }
]