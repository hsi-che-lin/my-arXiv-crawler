[
    {
        "paper id": "2401.07853",
        "abstract url": "https://arxiv.org/abs/2401.07853",
        "title": "VeCAF: Vision-language Collaborative Active Finetuning with Training Objective Awareness",
        "rating": "3",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Finetuning a pretrained vision model (PVM) is a common technique for learning downstream vision tasks. However, the conventional finetuning process with randomly sampled data points results in diminished training efficiency. To address this drawback, we propose a novel approach, Vision-language Collaborative Active Finetuning (VeCAF). With the emerging availability of labels and natural language annotations of images through web-scale crawling or controlled generation, VeCAF makes use of these information to perform parametric data selection for PVM finetuning. VeCAF incorporates the finetuning objective to select significant data points that effectively guide the PVM towards faster convergence to meet the performance goal. This process is assisted by the inherent semantic richness of the text embedding space which we use to augment image features. Furthermore, the flexibility of text-domain augmentation allows VeCAF to handle out-of-distribution scenarios without external data. Extensive experiments show the leading performance and high computational efficiency of VeCAF that is superior to baselines in both in-distribution and out-of-distribution image classification tasks. On ImageNet, VeCAF uses up to 3.3x less training batches to reach the target performance compared to full finetuning, and achieves an accuracy improvement of 2.7% over the state-of-the-art active finetuning method with the same number of batches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2401.07598",
        "abstract url": "https://arxiv.org/abs/2401.07598",
        "title": "MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "Parameter Efficient",
                "PEFT",
                "Efficient Finetuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Parameter Efficient Finetuning (PEFT) has emerged as a viable solution for improving the performance of Large Language Models (LLMs) without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages. Further, there is also a large gap between the performance of smaller open-source models and larger LLMs. Finetuning can be an effective way to bridge this gap and make language models more equitable. In this work, we finetune the LLama-2-7B and Mistral-7B models on two synthetic multilingual instruction tuning datasets to determine its effect on model performance on six downstream tasks covering forty languages in all. Additionally, we experiment with various parameters, such as rank for low-rank adaptation and values of quantisation to determine their effects on downstream performance and find that higher rank and higher quantisation values benefit low-resource languages. We find that PEFT of smaller open-source models sometimes bridges the gap between the performance of these models and the larger ones, however, English performance can take a hit. We also find that finetuning sometimes improves performance on low-resource languages, while degrading performance on high-resource languages.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "46 pages, 23 figures, 45 tables"
    },
    {
        "paper id": "2401.07669",
        "abstract url": "https://arxiv.org/abs/2401.07669",
        "title": "FiGCLIP: Fine-Grained CLIP Adaptation via Densely Annotated Videos",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While contrastive language image pretraining (CLIP) have exhibited impressive performance by learning highly semantic and generalized representations, recent works have exposed a fundamental drawback in its syntactic properties, that includes interpreting fine-grained attributes, actions, spatial relations, states, and details that require compositional reasoning. One reason for this is that natural captions often do not capture all the visual details of a scene. This leads to unaddressed visual concepts being misattributed to the wrong words. And the pooled image and text features, ends up acting as a bag of words, hence losing the syntactic information. In this work, we ask: Is it possible to enhance CLIP's fine-grained and syntactic abilities without compromising its semantic properties? We show that this is possible by adapting CLIP efficiently on a high-quality, comprehensive, and relatively small dataset. We demonstrate our adaptation strategy on VidSitu, a video situation recognition dataset annotated with verbs and rich semantic role labels (SRL). We use the SRL and verb information to create rule-based detailed captions, making sure they capture most of the visual concepts. Combined with hard negatives and hierarchical losses, these annotations allow us to learn a powerful visual representation, dubbed Fine-Grained CLIP (FiGCLIP), that preserves semantic understanding while being detail-oriented. We evaluate on five diverse vision-language tasks in both fine-tuning and zero-shot settings, achieving consistent improvements over the base CLIP model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08052",
        "abstract url": "https://arxiv.org/abs/2401.08052",
        "title": "Multi-Input Multi-Output Target-Speaker Voice Activity Detection For Unified, Flexible, and Robust Audio-Visual Speaker Diarization",
        "rating": "2",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "Audio-visual learning has demonstrated promising results in many classical speech tasks (e.g., speech separation, automatic speech recognition, wake-word spotting). We believe that introducing visual modality will also benefit speaker diarization. To date, Target-Speaker Voice Activity Detection (TS-VAD) plays an important role in highly accurate speaker diarization. However, previous TS-VAD models take audio features and utilize the speaker's acoustic footprint to distinguish his or her personal speech activities, which is easily affected by overlapped speech in multi-speaker scenarios. Although visual information naturally tolerates overlapped speech, it suffers from spatial occlusion, low resolution, etc. The potential modality-missing problem blocks TS-VAD towards an audio-visual approach. This paper proposes a novel Multi-Input Multi-Output Target-Speaker Voice Activity Detection (MIMO-TSVAD) framework for speaker diarization. The proposed method can take audio-visual input and leverage the speaker's acoustic footprint or lip track to flexibly conduct audio-based, video-based, and audio-visual speaker diarization in a unified sequence-to-sequence framework. Experimental results show that the MIMO-TSVAD framework demonstrates state-of-the-art performance on the VoxConverse, DIHARD-III, and MISP 2022 datasets under corresponding evaluation metrics, obtaining the Diarization Error Rates (DERs) of 4.18%, 10.10%, and 8.15%, respectively. In addition, it can perform robustly in heavy lip-missing scenarios.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Under review of IEEE/ACM Transactions on Audio, Speech, and Language Processing"
    },
    {
        "paper id": "2401.07532",
        "abstract url": "https://arxiv.org/abs/2401.07532",
        "title": "Multi-view MidiVAE: Fusing Track- and Bar-view Representations for Long Multi-track Symbolic Music Generation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Variational Autoencoders (VAEs) constitute a crucial component of neural symbolic music generation, among which some works have yielded outstanding results and attracted considerable attention. Nevertheless, previous VAEs still encounter issues with overly long feature sequences and generated results lack contextual coherence, thus the challenge of modeling long multi-track symbolic music still remains unaddressed. To this end, we propose Multi-view MidiVAE, as one of the pioneers in VAE methods that effectively model and generate long multi-track symbolic music. The Multi-view MidiVAE utilizes the two-dimensional (2-D) representation, OctupleMIDI, to capture relationships among notes while reducing the feature sequences length. Moreover, we focus on instrumental characteristics and harmony as well as global and local information about the musical composition by employing a hybrid variational encoding-decoding strategy to integrate both Track- and Bar-view MidiVAE features. Objective and subjective experimental results on the CocoChorales dataset demonstrate that, compared to the baseline, Multi-view MidiVAE exhibits significant improvements in terms of modeling long multi-track symbolic music.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2401.07629",
        "abstract url": "https://arxiv.org/abs/2401.07629",
        "title": "Fine-Grained Prototypes Distillation for Few-Shot Object Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Few-shot object detection (FSOD) aims at extending a generic detector for novel object detection with only a few training examples. It attracts great concerns recently due to the practical meanings. Meta-learning has been demonstrated to be an effective paradigm for this task. In general, methods based on meta-learning employ an additional support branch to encode novel examples (a.k.a. support images) into class prototypes, which are then fused with query branch to facilitate the model prediction. However, the class-level prototypes are difficult to precisely generate, and they also lack detailed information, leading to instability in performance.New methods are required to capture the distinctive local context for more robust novel object detection. To this end, we propose to distill the most representative support features into fine-grained prototypes. These prototypes are then assigned into query feature maps based on the matching results, modeling the detailed feature relations between two branches. This process is realized by our Fine-Grained Feature Aggregation (FFA) module. Moreover, in terms of high-level feature fusion, we propose Balanced Class-Agnostic Sampling (B-CAS) strategy and Non-Linear Fusion (NLF) module from differenct perspectives. They are complementary to each other and depict the high-level feature relations more effectively. Extensive experiments on PASCAL VOC and MS COCO benchmarks show that our method sets a new state-of-the-art performance in most settings. Our code is available at https://github.com/wangchen1801/FPD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI2024"
    },
    {
        "paper id": "2401.07681",
        "abstract url": "https://arxiv.org/abs/2401.07681",
        "title": "Effect of target signals and delays on spatially selective active noise control for open-fitting hearables",
        "rating": "1.5",
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Spatially selective active noise control (ANC) hearables are designed to reduce unwanted noise from certain directions while preserving desired sounds from other directions. In previous studies, the target signal has been defined either as the delayed desired component in one of the reference microphone signals or as the desired component in the error microphone signal without any delay. In this paper, we systematically investigate the influence of delays in different target signals on the ANC performance and provide an intuitive explanation for how the system obtains the desired signal. Simulations were conducted on a pair of open-fitting hearables for localized speech and noise sources in an anechoic environment. The performance was assessed in terms of noise reduction, signal quality and control effort. Results indicate that optimal performance is achieved without delays when the target signal is defined at the error microphone, whereas causality necessitates delays when the target signal is defined at the reference microphone. The optimal delay is found to be the acoustic delay between this reference microphone and the error microphone from the desired source.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "ICASSP 2024 (c) 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2401.07849",
        "abstract url": "https://arxiv.org/abs/2401.07849",
        "title": "Comparison of Frequency-Fusion Mechanisms for Binaural Direction-of-Arrival Estimation for Multiple Speakers",
        "rating": "1.5",
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "To estimate the direction of arrival (DOA) of multiple speakers with methods that use prototype transfer functions, frequency-dependent spatial spectra (SPS) are usually constructed. To make the DOA estimation robust, SPS from different frequencies can be combined. According to how the SPS are combined, frequency fusion mechanisms are categorized into narrowband, broadband, or speaker-grouped, where the latter mechanism requires a speaker-wise grouping of frequencies. For a binaural hearing aid setup, in this paper we propose an interaural time difference (ITD)-based speaker-grouped frequency fusion mechanism. By exploiting the DOA dependence of ITDs, frequencies can be grouped according to a common ITD and be used for DOA estimation of the respective speaker. We apply the proposed ITD-based speaker-grouped frequency fusion mechanism for different DOA estimation methods, namely the multiple signal classification, steered response power and a recently published method based on relative transfer function (RTF) vectors. In our experiments, we compare DOA estimation with different fusion mechanisms. For all considered DOA estimation methods, the proposed ITD-based speaker-grouped frequency fusion mechanism results in a higher DOA estimation accuracy compared with the narrowband and broadband fusion mechanisms.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Accepted for ICASSP 2024"
    },
    {
        "paper id": "2401.07879",
        "abstract url": "https://arxiv.org/abs/2401.07879",
        "title": "Decoupled Spatial and Temporal Processing for Resource Efficient Multichannel Speech Enhancement",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "We present a novel model designed for resource-efficient multichannel speech enhancement in the time domain, with a focus on low latency, lightweight, and low computational requirements. The proposed model incorporates explicit spatial and temporal processing within deep neural network (DNN) layers. Inspired by frequency-dependent multichannel filtering, our spatial filtering process applies multiple trainable filters to each hidden unit across the spatial dimension, resulting in a multichannel output. The temporal processing is applied over a single-channel output stream from the spatial processing using a Long Short-Term Memory (LSTM) network. The output from the temporal processing stage is then further integrated into the spatial dimension through elementwise multiplication. This explicit separation of spatial and temporal processing results in a resource-efficient network design. Empirical findings from our experiments show that our proposed model significantly outperforms robust baseline models while demanding far fewer parameters and computations, while achieving an ultra-low algorithmic latency of just 2 milliseconds.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Accepted for publication at ICASSP"
    },
    {
        "paper id": "2401.08025",
        "abstract url": "https://arxiv.org/abs/2401.08025",
        "title": "Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination",
        "rating": "1.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The potential of Vision-Language Models (VLMs) often remains underutilized in handling complex text-based problems, particularly when these problems could benefit from visual representation. Resonating with humans' ability to solve complex text-based problems by (1) creating a visual diagram from the problem and (2) deducing what steps they need to take to solve it, we propose Self-Imagine. We leverage a single Vision-Language Model (VLM) to generate a structured representation of the question using HTML, then render the HTML as an image, and finally use the same VLM to answer the question using both the question and the image. Our approach does not require any additional training data or training. We evaluate our approach on three mathematics tasks and nine general-purpose reasoning tasks using state-of-the-art (LLAVA-1.5 and GEMINI PRO) VLMs. Our approach boosts the performance of LLAVA-1.5 and GEMINI PRO on all math tasks (on average GSM8K: +3.1%; ASDIV: +3.2%; SVAMP: +6.9%) and the majority of the general-purpose reasoning tasks by 3.2% to 6.0% on average.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "18 pages, 9 figures, 12 tables"
    },
    {
        "paper id": "2401.08096",
        "abstract url": "https://arxiv.org/abs/2401.08096",
        "title": "Learning Disentangled Speech Representations with Contrastive Learning and Time-Invariant Retrieval",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Voice conversion refers to transferring speaker identity with well-preserved content. Better disentanglement of speech representations leads to better voice conversion. Recent studies have found that phonetic information from input audio has the potential ability to well represent content. Besides, the speaker-style modeling with pre-trained models making the process more complex. To tackle these issues, we introduce a new method named \"CTVC\" which utilizes disentangled speech representations with contrastive learning and time-invariant retrieval. Specifically, a similarity-based compression module is used to facilitate a more intimate connection between the frame-level hidden features and linguistic information at phoneme-level. Additionally, a time-invariant retrieval is proposed for timbre extraction based on multiple segmentations and mutual information. Experimental results demonstrate that \"CTVC\" outperforms previous studies and improves the sound quality and similarity of converted results.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Accepted by 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2024)"
    },
    {
        "paper id": "2401.07470",
        "abstract url": "https://arxiv.org/abs/2401.07470",
        "title": "Utilizing deep learning models for the identification of enhancers and super-enhancers based on genomic and epigenomic features",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper provides an extensive examination of a sizable dataset of English tweets focusing on nine widely recognized cryptocurrencies, specifically Cardano, Binance, Bitcoin, Dogecoin, Ethereum, Fantom, Matic, Shiba, and Ripple. Our primary objective was to conduct a psycholinguistic and emotion analysis of social media content associated with these cryptocurrencies. To enable investigators to make more informed decisions. The study involved comparing linguistic characteristics across the diverse digital coins, shedding light on the distinctive linguistic patterns that emerge within each coin's community. To achieve this, we utilized advanced text analysis techniques. Additionally, our work unveiled an intriguing Understanding of the interplay between these digital assets within the cryptocurrency community. By examining which coin pairs are mentioned together most frequently in the dataset, we established correlations between different cryptocurrencies. To ensure the reliability of our findings, we initially gathered a total of 832,559 tweets from Twitter. These tweets underwent a rigorous preprocessing stage, resulting in a refined dataset of 115,899 tweets that were used for our analysis. Overall, our research offers valuable Perception into the linguistic nuances of various digital coins' online communities and provides a deeper understanding of their interactions in the cryptocurrency space.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "13 pages, 7 figures, 6 Tables"
    },
    {
        "paper id": "2401.07475",
        "abstract url": "https://arxiv.org/abs/2401.07475",
        "title": "GWPT: A Green Word-Embedding-based POS Tagger",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As a fundamental tool for natural language processing (NLP), the part-of-speech (POS) tagger assigns the POS label to each word in a sentence. A novel lightweight POS tagger based on word embeddings is proposed and named GWPT (green word-embedding-based POS tagger) in this work. Following the green learning (GL) methodology, GWPT contains three modules in cascade: 1) representation learning, 2) feature learning, and 3) decision learning modules. The main novelty of GWPT lies in representation learning. It uses non-contextual or contextual word embeddings, partitions embedding dimension indices into low-, medium-, and high-frequency sets, and represents them with different N-grams. It is shown by experimental results that GWPT offers state-of-the-art accuracies with fewer model parameters and significantly lower computational complexity in both training and inference as compared with deep-learning-based methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07502",
        "abstract url": "https://arxiv.org/abs/2401.07502",
        "title": "Compositional Oil Spill Detection Based on Object Detector and Adapted Segment Anything Model from SAR Images",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semantic segmentation-based methods have attracted extensive attention in oil spill detection from SAR images. However, the existing approaches require a large number of finely annotated segmentation samples in the training stage. To alleviate this issue, we propose a composite oil spill detection framework, SAM-OIL, comprising an object detector (e.g., YOLOv8), an adapted Segment Anything Model (SAM), and an Ordered Mask Fusion (OMF) module. SAM-OIL is the first application of the powerful SAM in oil spill detection. Specifically, the SAM-OIL strategy uses YOLOv8 to obtain the categories and bounding boxes of oil spill-related objects, then inputs bounding boxes into the adapted SAM to retrieve category-agnostic masks, and finally adopts the Ordered Mask Fusion (OMF) module to fuse the masks and categories. The adapted SAM, combining a frozen SAM with a learnable Adapter module, can enhance SAM's ability to segment ambiguous objects. The OMF module, a parameter-free method, can effectively resolve pixel category conflicts within SAM. Experimental results demonstrate that SAM-OIL surpasses existing semantic segmentation-based oil spill detection methods, achieving mIoU of 69.52%. The results also indicated that both OMF and Adapter modules can effectively improve the accuracy in SAM-OIL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2401.07506",
        "abstract url": "https://arxiv.org/abs/2401.07506",
        "title": "SeMaScore : a new evaluation metric for automatic speech recognition tasks",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "In this study, we present SeMaScore, generated using a segment-wise mapping and scoring algorithm that serves as an evaluation metric for automatic speech recognition tasks. SeMaScore leverages both the error rate and a more robust similarity score. We show that our algorithm's score generation improves upon the state-of-the-art BERTscore. Our experimental results show that SeMaScore corresponds well with expert human assessments, signal-to-noise ratio levels, and other natural language metrics. We outperform BERTscore by 41x in metric computation speed. Overall, we demonstrate that SeMaScore serves as a more dependable evaluation metric, particularly in real-world situations involving atypical speech patterns.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07529",
        "abstract url": "https://arxiv.org/abs/2401.07529",
        "title": "MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception and understanding. However, these models also suffer from hallucinations, which limit their reliability as AI systems. We believe that these hallucinations are partially due to the models' struggle with understanding what they can and cannot perceive from images, a capability we refer to as self-awareness in perception. Despite its importance, this aspect of MLLMs has been overlooked in prior studies. In this paper, we aim to define and evaluate the self-awareness of MLLMs in perception. To do this, we first introduce the knowledge quadrant in perception, which helps define what MLLMs know and do not know about images. Using this framework, we propose a novel benchmark, the Self-Awareness in Perception for MLLMs (MM-SAP), specifically designed to assess this capability. We apply MM-SAP to a variety of popular MLLMs, offering a comprehensive analysis of their self-awareness and providing detailed insights. The experiment results reveal that current MLLMs possess limited self-awareness capabilities, pointing to a crucial area for future advancement in the development of trustworthy MLLMs. Code and data are available at https://github.com/YHWmz/MM-SAP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07544",
        "abstract url": "https://arxiv.org/abs/2401.07544",
        "title": "See the Unseen: Better Context-Consistent Knowledge-Editing by Noises",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge-editing updates knowledge of large language models (LLMs) and contributes to the interpretability and application of LLMs. However, knowledge applying is context-consistent: LLMs can recall the same knowledge in different contexts. Existing works ignore this property and the editing lacks generalization. In this paper, we empirically find that the effects of different contexts upon LLMs in recalling the same knowledge follow a Gaussian-like distribution. We then sample Gaussian noises to simulate the effects of different contexts when updating LLMs. By such, we can make LLMs see the unseen contexts where the edited knowledge will be applied, therefore improving the editing generalization. Experimental results on three LLMs demonstrate the effectiveness of our methods and also distinguish our methods from the others of fine-tuning LLMs by noises.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07575",
        "abstract url": "https://arxiv.org/abs/2401.07575",
        "title": "Cascaded Cross-Modal Transformer for Audio-Textual Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Speech classification tasks often require powerful language understanding models to grasp useful features, which becomes problematic when limited training data is available. To attain superior classification performance, we propose to harness the inherent value of multimodal representations by transcribing speech using automatic speech recognition (ASR) models and translating the transcripts into different languages via pretrained translation models. We thus obtain an audio-textual (multimodal) representation for each data sample. Subsequently, we combine language-specific Bidirectional Encoder Representations from Transformers (BERT) with Wav2Vec2.0 audio features via a novel cascaded cross-modal transformer (CCMT). Our model is based on two cascaded transformer blocks. The first one combines text-specific features from distinct languages, while the second one combines acoustic features with multilingual features previously learned by the first transformer block. We employed our system in the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge. CCMT was declared the winning solution, obtaining an unweighted average recall (UAR) of 65.41% and 85.87% for complaint and request detection, respectively. Moreover, we applied our framework on the Speech Commands v2 and HarperValleyBank dialog data sets, surpassing previous studies reporting results on these benchmarks. Our code is freely available for download at: https://github.com/ristea/ccmt.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07586",
        "abstract url": "https://arxiv.org/abs/2401.07586",
        "title": "Curriculum for Crowd Counting -- Is it Worthy?",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in deep learning techniques have achieved remarkable performance in several computer vision problems. A notably intuitive technique called Curriculum Learning (CL) has been introduced recently for training deep learning models. Surprisingly, curriculum learning achieves significantly improved results in some tasks but marginal or no improvement in others. Hence, there is still a debate about its adoption as a standard method to train supervised learning models. In this work, we investigate the impact of curriculum learning in crowd counting using the density estimation method. We performed detailed investigations by conducting 112 experiments using six different CL settings using eight different crowd models. Our experiments show that curriculum learning improves the model learning performance and shortens the convergence time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted version of the paper in 19th International Conference on Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-19 February 2024"
    },
    {
        "paper id": "2401.07639",
        "abstract url": "https://arxiv.org/abs/2401.07639",
        "title": "Compute-Efficient Active Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "Workshop",
                "NeurIPS"
            ]
        ],
        "abstract": "Active learning, a powerful paradigm in machine learning, aims at reducing labeling costs by selecting the most informative samples from an unlabeled dataset. However, the traditional active learning process often demands extensive computational resources, hindering scalability and efficiency. In this paper, we address this critical issue by presenting a novel method designed to alleviate the computational burden associated with active learning on massive datasets. To achieve this goal, we introduce a simple, yet effective method-agnostic framework that outlines how to strategically choose and annotate data points, optimizing the process for efficiency while maintaining model performance. Through case studies, we demonstrate the effectiveness of our proposed method in reducing computational costs while maintaining or, in some cases, even surpassing baseline model outcomes. Code is available at https://github.com/aimotive/Compute-Efficient-Active-Learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World"
    },
    {
        "paper id": "2401.07641",
        "abstract url": "https://arxiv.org/abs/2401.07641",
        "title": "SwinTextSpotter v2: Towards Better Synergy for Scene Text Spotting",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "End-to-end scene text spotting, which aims to read the text in natural images, has garnered significant attention in recent years. However, recent state-of-the-art methods usually incorporate detection and recognition simply by sharing the backbone, which does not directly take advantage of the feature interaction between the two tasks. In this paper, we propose a new end-to-end scene text spotting framework termed SwinTextSpotter v2, which seeks to find a better synergy between text detection and recognition. Specifically, we enhance the relationship between two tasks using novel Recognition Conversion and Recognition Alignment modules. Recognition Conversion explicitly guides text localization through recognition loss, while Recognition Alignment dynamically extracts text features for recognition through the detection predictions. This simple yet effective design results in a concise framework that requires neither an additional rectification module nor character-level annotations for the arbitrarily-shaped text. Furthermore, the parameters of the detector are greatly reduced without performance degradation by introducing a Box Selection Schedule. Qualitative and quantitative experiments demonstrate that SwinTextSpotter v2 achieved state-of-the-art performance on various multilingual (English, Chinese, and Vietnamese) benchmarks. The code will be available at \\href{https://github.com/mxin262/SwinTextSpotterv2}{SwinTextSpotter v2}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2203.10209"
    },
    {
        "paper id": "2401.07711",
        "abstract url": "https://arxiv.org/abs/2401.07711",
        "title": "Efficient Nonparametric Tensor Decomposition for Binary and Count Data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "In numerous applications, binary reactions or event counts are observed and stored within high-order tensors. Tensor decompositions (TDs) serve as a powerful tool to handle such high-dimensional and sparse data. However, many traditional TDs are explicitly or implicitly designed based on the Gaussian distribution, which is unsuitable for discrete data. Moreover, most TDs rely on predefined multi-linear structures, such as CP and Tucker formats. Therefore, they may not be effective enough to handle complex real-world datasets. To address these issues, we propose ENTED, an \\underline{E}fficient \\underline{N}onparametric \\underline{TE}nsor \\underline{D}ecomposition for binary and count tensors. Specifically, we first employ a nonparametric Gaussian process (GP) to replace traditional multi-linear structures. Next, we utilize the \\pg augmentation which provides a unified framework to establish conjugate models for binary and count distributions. Finally, to address the computational issue of GPs, we enhance the model by incorporating sparse orthogonal variational inference of inducing points, which offers a more effective covariance approximation within GPs and stochastic natural gradient updates for nonparametric models. We evaluate our model on several real-world tensor completion tasks, considering binary and count datasets. The results manifest both better performance and computational advantages of the proposed model.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "AAAI-24"
    },
    {
        "paper id": "2401.07760",
        "abstract url": "https://arxiv.org/abs/2401.07760",
        "title": "On the importance of Data Scale in Pretraining Arabic Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Pretraining monolingual language models have been proven to be vital for performance in Arabic Natural Language Processing (NLP) tasks. In this paper, we conduct a comprehensive study on the role of data in Arabic Pretrained Language Models (PLMs). More precisely, we reassess the performance of a suite of state-of-the-art Arabic PLMs by retraining them on massive-scale, high-quality Arabic corpora. We have significantly improved the performance of the leading Arabic encoder-only BERT-base and encoder-decoder T5-base models on the ALUE and ORCA leaderboards, thereby reporting state-of-the-art results in their respective model categories. In addition, our analysis strongly suggests that pretraining data by far is the primary contributor to performance, surpassing other factors. Our models and source code are publicly available at https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07770",
        "abstract url": "https://arxiv.org/abs/2401.07770",
        "title": "Seeing the Unseen: Visual Common Sense for Semantic Placement",
        "rating": "1",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Computer vision tasks typically involve describing what is present in an image (e.g. classification, detection, segmentation, and captioning). We study a visual common sense task that requires understanding what is not present. Specifically, given an image (e.g. of a living room) and name of an object (\"cushion\"), a vision system is asked to predict semantically-meaningful regions (masks or bounding boxes) in the image where that object could be placed or is likely be placed by humans (e.g. on the sofa). We call this task: Semantic Placement (SP) and believe that such common-sense visual understanding is critical for assitive robots (tidying a house), and AR devices (automatically rendering an object in the user's space). Studying the invisible is hard. Datasets for image description are typically constructed by curating relevant images and asking humans to annotate the contents of the image; neither of those two steps are straightforward for objects not present in the image. We overcome this challenge by operating in the opposite direction: we start with an image of an object in context from web, and then remove that object from the image via inpainting. This automated pipeline converts unstructured web data into a dataset comprising pairs of images with/without the object. Using this, we collect a novel dataset, with ${\\sim}1.3$M images across $9$ object categories, and train a SP prediction model called CLIP-UNet. CLIP-UNet outperforms existing VLMs and baselines that combine semantic priors with object detectors on real-world and simulated images. In our user studies, we find that the SP masks predicted by CLIP-UNet are favored $43.7\\%$ and $31.3\\%$ times when comparing against the $4$ SP baselines on real and simulated images. In addition, we demonstrate leveraging SP mask predictions from CLIP-UNet enables downstream applications like building tidying robots in indoor environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07787",
        "abstract url": "https://arxiv.org/abs/2401.07787",
        "title": "Improving OCR Quality in 19th Century Historical Documents Using a Combined Machine Learning Based Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper addresses a major challenge to historical research on the 19th century. Large quantities of sources have become digitally available for the first time, while extraction techniques are lagging behind. Therefore, we researched machine learning (ML) models to recognise and extract complex data structures in a high-value historical primary source, the Schematismus. It records every single person in the Habsburg civil service above a certain hierarchical level between 1702 and 1918 and documents the genesis of the central administration over two centuries. Its complex and intricate structure as well as its enormous size have so far made any more comprehensive analysis of the administrative and social structure of the later Habsburg Empire on the basis of this source impossible. We pursued two central objectives: Primarily, the improvement of the OCR quality, for which we considered an improved structure recognition to be essential; in the further course, it turned out that this also made the extraction of the data structure possible. We chose Faster R-CNN as base for the ML architecture for structure recognition. In order to obtain the required amount of training data quickly and economically, we synthesised Hof- und Staatsschematismus-style data, which we used to train our model. The model was then fine-tuned with a smaller set of manually annotated historical source data. We then used Tesseract-OCR, which was further optimised for the style of our documents, to complete the combined structure extraction and OCR process. Results show a significant decrease in the two standard parameters of OCR-performance, WER and CER (where lower values are better). Combined structure detection and fine-tuned OCR improved CER and WER values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER).",
        "subjects": [
            "cs.CV"
        ],
        "comment": "29 pages, 23 figures, 7 tables"
    },
    {
        "paper id": "2401.07793",
        "abstract url": "https://arxiv.org/abs/2401.07793",
        "title": "Flexibly Scaling Large Language Models Contexts Through Extensible Tokenization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are in need of sufficient contexts to handle many critical applications, such as retrieval augmented generation and few-shot learning. However, due to the constrained window size, the LLMs can only access to the information within a limited context. Although the size of context window can be extended by fine-tuning, it will result in a substantial cost in both training and inference stage. In this paper, we present Extensible Tokenization as an alternative method which realizes the flexible scaling of LLMs' context. Extensible Tokenization stands as a midware in between of the tokenized context and the LLM, which transforms the raw token embeddings into the extensible embeddings. Such embeddings provide a more compact representation for the long context, on top of which the LLM is able to perceive more information with the same context window. Extensible Tokenization is also featured by its flexibility: the scaling factor can be flexibly determined within a feasible scope, leading to the extension of an arbitrary context length at the inference time. Besides, Extensible Tokenization is introduced as a drop-in component, which can be seamlessly plugged into not only the LLM itself and but also its fine-tuned derivatives, bringing in the extended contextual information while fully preserving the LLM's existing capabilities. We perform comprehensive experiments on long-context language modeling and understanding tasks, which verify Extensible Tokenization as an effective, efficient, flexible, and compatible method to extend LLM's context. Our model and source code will be made publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07803",
        "abstract url": "https://arxiv.org/abs/2401.07803",
        "title": "Uncovering the Full Potential of Visual Grounding Methods in VQA",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by strengthening a model's reliance on question-relevant visual information. The presence of such relevant information in the visual input is typically assumed in training and testing. This assumption, however, is inherently flawed when dealing with imperfect image representations common in large-scale VQA, where the information carried by visual features frequently deviates from expected ground-truth contents. As a result, training and testing of VG-methods is performed with largely inaccurate data, which obstructs proper assessment of their potential benefits. In this study, we demonstrate that current evaluation schemes for VG-methods are problematic due to the flawed assumption of availability of relevant visual information. Our experiments show that these methods can be much more effective when evaluation conditions are corrected. Code is provided on GitHub.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07810",
        "abstract url": "https://arxiv.org/abs/2401.07810",
        "title": "Consolidating Strategies for Countering Hate Speech Using Persuasive Dialogues",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Hateful comments are prevalent on social media platforms. Although tools for automatically detecting, flagging, and blocking such false, offensive, and harmful content online have lately matured, such reactive and brute force methods alone provide short-term and superficial remedies while the perpetrators persist. With the public availability of large language models which can generate articulate synthetic and engaging content at scale, there are concerns about the rapid growth of dissemination of such malicious content on the web. There is now a need to focus on deeper, long-term solutions that involve engaging with the human perpetrator behind the source of the content to change their viewpoint or at least bring down the rhetoric using persuasive means. To do that, we propose defining and experimenting with controllable strategies for generating counter-arguments to hateful comments in online conversations. We experiment with controlling response generation using features based on (i) argument structure and reasoning-based Walton argument schemes, (ii) counter-argument speech acts, and (iii) human characteristics-based qualities such as Big-5 personality traits and human values. Using automatic and human evaluations, we determine the best combination of features that generate fluent, argumentative, and logically sound arguments for countering hate. We further share the developed computational models for automatically annotating text with such features, and a silver-standard annotated version of an existing hate speech dialog corpora.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07817",
        "abstract url": "https://arxiv.org/abs/2401.07817",
        "title": "Question Translation Training for Better Multilingual Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into all languages of interest, and then train on the resulting multilingual data, which is called translate-training. This approach not only incurs high cost, but also results in poorly translated data due to the non-standard formatting of mathematical chain-of-thought. In this paper, we explore the benefits of question alignment, where we train the model to translate reasoning questions into English by finetuning on X-English parallel question data. In this way we perform targeted, in-domain language alignment which makes best use of English instruction data to unlock the LLMs' multilingual reasoning abilities. Experimental results on LLaMA2-13B show that question alignment leads to consistent improvements over the translate-training approach: an average improvement of 11.3% and 16.1% accuracy across ten languages on the MGSM and MSVAMP multilingual reasoning benchmarks. The project will be available at: https://github.com/NJUNLP/QAlign.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07847",
        "abstract url": "https://arxiv.org/abs/2401.07847",
        "title": "Milestones in Bengali Sentiment Analysis leveraging Transformer-models: Fundamentals, Challenges and Future Directions",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Sentiment Analysis (SA) refers to the task of associating a view polarity (usually, positive, negative, or neutral; or even fine-grained such as slightly angry, sad, etc.) to a given text, essentially breaking it down to a supervised (since we have the view labels apriori) classification task. Although heavily studied in resource-rich languages such as English thus pushing the SOTA by leaps and bounds, owing to the arrival of the Transformer architecture, the same cannot be said for resource-poor languages such as Bengali (BN). For a language spoken by roughly 300 million people, the technology enabling them to run trials on their favored tongue is severely lacking. In this paper, we analyze the SOTA for SA in Bengali, particularly, Transformer-based models. We discuss available datasets, their drawbacks, the nuances associated with Bengali i.e. what makes this a challenging language to apply SA on, and finally provide insights for future direction to mitigate the limitations in the field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07851",
        "abstract url": "https://arxiv.org/abs/2401.07851",
        "title": "Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "To mitigate the high inference latency stemming from autoregressive decoding in Large Language Models (LLMs), Speculative Decoding has emerged as a novel decoding paradigm for LLM inference. In each decoding step, this method first drafts several future tokens efficiently and then verifies them in parallel. Unlike autoregressive decoding, Speculative Decoding facilitates the simultaneous decoding of multiple tokens per step, thereby accelerating inference. This paper presents a comprehensive overview and analysis of this promising decoding paradigm. We begin by providing a formal definition and formulation of Speculative Decoding. Then, we organize in-depth discussions on its key facets, such as drafter selection and verification strategies. Furthermore, we present a comparative analysis of leading methods under third-party testing environments. We aim for this work to serve as a catalyst for further research on Speculative Decoding, ultimately contributing to more efficient LLM inference.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07870",
        "abstract url": "https://arxiv.org/abs/2401.07870",
        "title": "JumpCoder: Go Beyond Autoregressive Coder via Online Modification",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "While existing code large language models (code LLMs) exhibit impressive capabilities in code generation, their autoregressive sequential generation inherently lacks reversibility. This limitation hinders them from timely correcting previous missing statements during coding as humans do, often leading to error propagation and suboptimal performance. We introduce JumpCoder, a novel modelagnostic framework that enables online modification and non-sequential generation to augment the code LLMs. The key idea behind JumpCoder is to insert new code into the currently generated code when necessary during generation, which is achieved through an auxiliary infilling model that works in tandem with the code LLM. Since identifying the best infill position beforehand is intractable, we adopt an infill-first, judge-later strategy, which experiments with filling at the $k$ most critical positions following the generation of each line, and uses an Abstract Syntax Tree (AST) parser alongside the Generation Model Scoring to effectively judge the validity of each potential infill. Extensive experiments using six state-of-the-art code LLMs across multiple benchmarks consistently indicate significant improvements over all baselines. Notably, JumpCoder assists code LLMs in achieving up to a 3.6% increase in Pass@1 for Python, 6.3% for Java, and 3.7% for C++ in the multilingual HumanEval benchmarks. Our code is public at https://github.com/Keytoyze/JumpCoder.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07872",
        "abstract url": "https://arxiv.org/abs/2401.07872",
        "title": "The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The advent of Large Language Models (LLMs) represents a notable breakthrough in Natural Language Processing (NLP), contributing to substantial progress in both text comprehension and generation. However, amidst these advancements, it is noteworthy that LLMs often face a limitation in terms of context length extrapolation. Understanding and extending the context length for LLMs is crucial in enhancing their performance across various NLP applications. In this survey paper, we delve into the multifaceted aspects of exploring why it is essential, and the potential transformations that superior techniques could bring to NLP applications. We study the inherent challenges associated with extending context length and present an organized overview of the existing strategies employed by researchers. Additionally, we discuss the intricacies of evaluating context extension techniques and highlight the open challenges that researchers face in this domain. Furthermore, we explore whether there is a consensus within the research community regarding evaluation standards and identify areas where further agreement is needed. This comprehensive survey aims to serve as a valuable resource for researchers, guiding them through the nuances of context length extension techniques and fostering discussions on future advancements in this evolving field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07923",
        "abstract url": "https://arxiv.org/abs/2401.07923",
        "title": "Word Boundary Information Isn't Useful for Encoder Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "All existing transformer-based approaches to NLP using subword tokenisation algorithms encode whitespace (word boundary information) through the use of special space symbols (such as \\#\\# or \\_) forming part of tokens. These symbols have been shown to a) lead to reduced morphological validity of tokenisations, and b) give substantial vocabulary redundancy. As such, removing these symbols has been shown to have a beneficial effect on the processing of morphologically complex words for transformer encoders in the pretrain-finetune paradigm. In this work, we explore whether word boundary information is at all useful to such models. In particular, we train transformer encoders across four different training scales, and investigate several alternative approaches to including word boundary information, evaluating on a range of tasks across different domains and problem set-ups: GLUE (for sentence-level classification), NER (for token-level classification), and two classification datasets involving complex words (Superbizarre and FLOTA). Overall, through an extensive experimental setup that includes the pre-training of 29 models, we find no substantial improvements from our alternative approaches, suggesting that modifying tokenisers to remove word boundary information isn't leading to a loss of useful information.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2401.07927",
        "abstract url": "https://arxiv.org/abs/2401.07927",
        "title": "Are self-explanations from Large Language Models faithful?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Instruction-tuned Large Language Models (LLMs) excel at many tasks and will even explain their reasoning, so-called self-explanations. However, convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk. Therefore, it's important to measure if self-explanations truly reflect the model's behavior. Such a measure is called interpretability-faithfulness and is challenging to perform since the ground truth is inaccessible, and many LLMs only have an inference API. To address this, we propose employing self-consistency checks to measure faithfulness. For example, if an LLM says a set of words is important for making a prediction, then it should not be able to make its prediction without these words. While self-consistency checks are a common approach to faithfulness, they have not previously been successfully applied to LLM self-explanations for counterfactual, importance measure, and redaction explanations. Our results demonstrate that faithfulness is explanation, model, and task-dependent, showing self-explanations should not be trusted in general. For example, with sentiment classification, counterfactuals are more faithful for Llama2, importance measures for Mistral, and redaction for Falcon 40B.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07928",
        "abstract url": "https://arxiv.org/abs/2401.07928",
        "title": "A Lexicon for Studying Radicalization in Incel Communities",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Incels are an extremist online community of men who believe in an ideology rooted in misogyny, racism, the glorification of violence, and dehumanization. In their online forums, they use an extensive, evolving cryptolect - a set of ingroup terms that have meaning within the group, reflect the ideology, demonstrate membership in the community, and are difficult for outsiders to understand. This paper presents a lexicon with terms and definitions for common incel root words, prefixes, and affixes. The lexicon is text-based for use in automated analysis and is derived via a Qualitative Content Analysis of the most frequent incel words, their structure, and their meaning on five of the most active incel communities from 2016 to 2023. This lexicon will support future work examining radicalization and deradicalization/disengagement within the community.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "6 pages, 1 figure"
    },
    {
        "paper id": "2401.07929",
        "abstract url": "https://arxiv.org/abs/2401.07929",
        "title": "Machine Learning Based Object Tracking",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Machine learning based object detection as well as tracking that object have been performed in this paper. The authors were able to set a range of interest (ROI) around an object using Open Computer Vision, better known as OpenCV. Next a tracking algorithm has been used to maintain tracking on an object while simultaneously operating two servo motors to keep the object centered in the frame. Detailed procedure and code are included in this paper.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07944",
        "abstract url": "https://arxiv.org/abs/2401.07944",
        "title": "SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper uses the BERT model, which is a transformer-based architecture, to solve task 4A, English Language, Sentiment Analysis in Twitter of SemEval2017. BERT is a very powerful large language model for classification tasks when the amount of training data is small. For this experiment, we have used the BERT{\\textsubscript{\\tiny BASE}} model, which has 12 hidden layers. This model provides better accuracy, precision, recall, and f1 score than the Naive Bayes baseline model. It performs better in binary classification subtasks than the multi-class classification subtasks. We also considered all kinds of ethical issues during this experiment, as Twitter data contains personal and sensible information. The dataset and code used in our experiment can be found in this GitHub repository.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07951",
        "abstract url": "https://arxiv.org/abs/2401.07951",
        "title": "Image Similarity using An Ensemble of Context-Sensitive Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image similarity has been extensively studied in computer vision. In recently years, machine-learned models have shown their ability to encode more semantics than traditional multivariate metrics. However, in labelling similarity, assigning a numerical score to a pair of images is less intuitive than determining if an image A is closer to a reference image R than another image B. In this work, we present a novel approach for building an image similarity model based on labelled data in the form of A:R vs B:R. We address the challenges of sparse sampling in the image space (R, A, B) and biases in the models trained with context-based data by using an ensemble model. In particular, we employed two ML techniques to construct such an ensemble model, namely dimensionality reduction and MLP regressors. Our testing results show that the ensemble model constructed performs ~5% better than the best individual context-sensitive models. They also performed better than the model trained with mixed imagery data as well as existing similarity models, e.g., CLIP and DINO. This work demonstrate that context-based labelling and model training can be effective when an appropriate ensemble approach is used to alleviate the limitation due to sparse sampling.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07955",
        "abstract url": "https://arxiv.org/abs/2401.07955",
        "title": "A Study on Large Language Models' Limitations in Multiple-Choice Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The widespread adoption of Large Language Models (LLMs) has become commonplace, particularly with the emergence of open-source models. More importantly, smaller models are well-suited for integration into consumer devices and are frequently employed either as standalone solutions or as subroutines in various AI tasks. Despite their ubiquitous use, there is no systematic analysis of their specific capabilities and limitations. In this study, we tackle one of the most widely used tasks - answering Multiple Choice Question (MCQ). We analyze 26 small open-source models and find that 65% of the models do not understand the task, only 4 models properly select an answer from the given choices, and only 5 of these models are choice order independent. These results are rather alarming given the extensive use of MCQ tests with these models. We recommend exercising caution and testing task understanding before using MCQ to evaluate LLMs in any field whatsoever.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07957",
        "abstract url": "https://arxiv.org/abs/2401.07957",
        "title": "Machine Perceptual Quality: Evaluating the Impact of Severe Lossy Compression on Audio and Image Models",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "In the field of neural data compression, the prevailing focus has been on optimizing algorithms for either classical distortion metrics, such as PSNR or SSIM, or human perceptual quality. With increasing amounts of data consumed by machines rather than humans, a new paradigm of machine-oriented compression$\\unicode{x2013}$which prioritizes the retention of features salient for machine perception over traditional human-centric criteria$\\unicode{x2013}$has emerged, creating several new challenges to the development, evaluation, and deployment of systems utilizing lossy compression. In particular, it is unclear how different approaches to lossy compression will affect the performance of downstream machine perception tasks. To address this under-explored area, we evaluate various perception models$\\unicode{x2013}$including image classification, image segmentation, speech recognition, and music source separation$\\unicode{x2013}$under severe lossy compression. We utilize several popular codecs spanning conventional, neural, and generative compression architectures. Our results indicate three key findings: (1) using generative compression, it is feasible to leverage highly compressed data while incurring a negligible impact on machine perceptual quality; (2) machine perceptual quality correlates strongly with deep similarity metrics, indicating a crucial role of these metrics in the development of machine-oriented codecs; and (3) using lossy compressed datasets, (e.g. ImageNet) for pre-training can lead to counter-intuitive scenarios where lossy compression increases machine perceptual quality rather than degrading it. To encourage engagement on this growing area of research, our code and experiments are available at: https://github.com/danjacobellis/MPQ.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "10 pages; abridged version published in IEEE Data Compression Conference 2024"
    },
    {
        "paper id": "2401.07967",
        "abstract url": "https://arxiv.org/abs/2401.07967",
        "title": "MCMChaos: Improvising Rap Music with MCMC Methods and Chaos Theory",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "A novel freestyle rap software, MCMChaos 0.0.1, based on rap music transcriptions created in previous research is presented. The software has three different versions, each making use of different mathematical simulation methods: collapsed gibbs sampler and lorenz attractor simulation. As far as we know, these simulation methods have never been used in rap music generation before. The software implements Python Text-to-Speech processing (pyttxs) to convert text wrangled from the MCFlow corpus into English speech. In each version, values simulated from each respective mathematical model alter the rate of speech, volume, and (in the multiple voice case) the voice of the text-to-speech engine on a line-by-line basis. The user of the software is presented with a real-time graphical user interface (GUI) which instantaneously changes the initial values read into the mathematical simulation methods. Future research might attempt to allow for more user control and autonomy.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08003",
        "abstract url": "https://arxiv.org/abs/2401.08003",
        "title": "Jewelry Recognition via Encoder-Decoder Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Jewelry recognition is a complex task due to the different styles and designs of accessories. Precise descriptions of the various accessories is something that today can only be achieved by experts in the field of jewelry. In this work, we propose an approach for jewelry recognition using computer vision techniques and image captioning, trying to simulate this expert human behavior of analyzing accessories. The proposed methodology consist on using different image captioning models to detect the jewels from an image and generate a natural language description of the accessory. Then, this description is also utilized to classify the accessories at different levels of detail. The generated caption includes details such as the type of jewel, color, material, and design. To demonstrate the effectiveness of the proposed method in accurately recognizing different types of jewels, a dataset consisting of images of accessories belonging to jewelry stores in C\u00f3rdoba (Spain) has been created. After testing the different image captioning architectures designed, the final model achieves a captioning accuracy of 95\\%. The proposed methodology has the potential to be used in various applications such as jewelry e-commerce, inventory management or automatic jewels recognition to analyze people's tastes and social status.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 5 figures, MetroXRAINE 2023 Conference"
    },
    {
        "paper id": "2401.08014",
        "abstract url": "https://arxiv.org/abs/2401.08014",
        "title": "Convolutional Neural Network Compression via Dynamic Parameter Rank Pruning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "While Convolutional Neural Networks (CNNs) excel at learning complex latent-space representations, their over-parameterization can lead to overfitting and reduced performance, particularly with limited data. This, alongside their high computational and memory demands, limits the applicability of CNNs for edge deployment. Low-rank matrix approximation has emerged as a promising approach to reduce CNN parameters, but its application presents challenges including rank selection and performance loss. To address these issues, we propose an efficient training method for CNN compression via dynamic parameter rank pruning. Our approach integrates efficient matrix factorization and novel regularization techniques, forming a robust framework for dynamic rank reduction and model compression. We use Singular Value Decomposition (SVD) to model low-rank convolutional filters and dense weight matrices and we achieve model compression by training the SVD factors with back-propagation in an end-to-end way. We evaluate our method on an array of modern CNNs, including ResNet-18, ResNet-20, and ResNet-32, and datasets like CIFAR-10, CIFAR-100, and ImageNet (2012), showcasing its applicability in computer vision. Our experiments show that the proposed method can yield substantial storage savings while maintaining or even enhancing classification performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 6 figures"
    },
    {
        "paper id": "2401.08017",
        "abstract url": "https://arxiv.org/abs/2401.08017",
        "title": "Small Object Detection by DETR via Information Augmentation and Adaptive Feature Fusion",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The main challenge for small object detection algorithms is to ensure accuracy while pursuing real-time performance. The RT-DETR model performs well in real-time object detection, but performs poorly in small object detection accuracy. In order to compensate for the shortcomings of the RT-DETR model in small object detection, two key improvements are proposed in this study. Firstly, The RT-DETR utilises a Transformer that receives input solely from the final layer of Backbone features. This means that the Transformer's input only receives semantic information from the highest level of abstraction in the Deep Network, and ignores detailed information such as edges, texture or color gradients that are critical to the location of small objects at lower levels of abstraction. Including only deep features can introduce additional background noise. This can have a negative impact on the accuracy of small object detection. To address this issue, we propose the fine-grained path augmentation method. This method helps to locate small objects more accurately by providing detailed information to the deep network. So, the input to the transformer contains both semantic and detailed information. Secondly, In RT-DETR, the decoder takes feature maps of different levels as input after concatenating them with equal weight. However, this operation is not effective in dealing with the complex relationship of multi-scale information captured by feature maps of different sizes. Therefore, we propose an adaptive feature fusion algorithm that assigns learnable parameters to each feature map from different levels. This allows the model to adaptively fuse feature maps from different levels and effectively integrate feature information from different scales. This enhances the model's ability to capture object features at different scales, thereby improving the accuracy of detecting small objects.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08026",
        "abstract url": "https://arxiv.org/abs/2401.08026",
        "title": "JustiLM: Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Justification is an explanation that supports the veracity assigned to a claim in fact-checking. However, the task of justification generation is previously oversimplified as summarization of fact-check article authored by fact-checkers. Therefore, we propose a realistic approach to generate justification based on retrieved evidence. We present a new benchmark dataset called ExClaim for \\underline{Ex}plainable fact-checking of real-world \\underline{Claim}s, and introduce JustiLM, a novel few-shot \\underline{Justi}fication generation based on retrieval-augmented \\underline{L}anguage \\underline{M}odel by using fact-check articles as auxiliary resource during training only. Experiments show that JustiLM achieves promising performance in justification generation compared to strong baselines, and can also enhance veracity classification with a straightforward extension.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted in TACL. This is a pre-MIT Press publication version"
    },
    {
        "paper id": "2401.08035",
        "abstract url": "https://arxiv.org/abs/2401.08035",
        "title": "BanglaNet: Bangla Handwritten Character Recognition using Ensembling of Convolutional Neural Network",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Handwritten character recognition is a crucial task because of its abundant applications. The recognition task of Bangla handwritten characters is especially challenging because of the cursive nature of Bangla characters and the presence of compound characters with more than one way of writing. In this paper, a classification model based on the ensembling of several Convolutional Neural Networks (CNN), namely, BanglaNet is proposed to classify Bangla basic characters, compound characters, numerals, and modifiers. Three different models based on the idea of state-of-the-art CNN models like Inception, ResNet, and DenseNet have been trained with both augmented and non-augmented inputs. Finally, all these models are averaged or ensembled to get the finishing model. Rigorous experimentation on three benchmark Bangla handwritten characters datasets, namely, CMATERdb, BanglaLekha-Isolated, and Ekush has exhibited significant recognition accuracies compared to some recent CNN-based research. The top-1 recognition accuracies obtained are 98.40%, 97.65%, and 97.32%, and the top-3 accuracies are 99.79%, 99.74%, and 99.56% for CMATERdb, BanglaLekha-Isolated, and Ekush datasets respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08038",
        "abstract url": "https://arxiv.org/abs/2401.08038",
        "title": "Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with Crowdsourcing and Active Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "A significant challenge to training accurate deep learning models on privacy policies is the cost and difficulty of obtaining a large and comprehensive set of training data. To address these challenges, we present Calpric , which combines automatic text selection and segmentation, active learning and the use of crowdsourced annotators to generate a large, balanced training set for privacy policies at low cost. Automated text selection and segmentation simplifies the labeling task, enabling untrained annotators from crowdsourcing platforms, like Amazon's Mechanical Turk, to be competitive with trained annotators, such as law students, and also reduces inter-annotator agreement, which decreases labeling cost. Having reliable labels for training enables the use of active learning, which uses fewer training samples to efficiently cover the input space, further reducing cost and improving class and data category balance in the data set. The combination of these techniques allows Calpric to produce models that are accurate over a wider range of data categories, and provide more detailed, fine-grain labels than previous work. Our crowdsourcing process enables Calpric to attain reliable labeled data at a cost of roughly $0.92-$1.71 per labeled text segment. Calpric 's training process also generates a labeled data set of 16K privacy policy text segments across 9 Data categories with balanced positive and negative samples.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "published at USENIX Security 2023; associated website: https://www.usenix.org/conference/usenixsecurity23/presentation/qiu"
    },
    {
        "paper id": "2401.08046",
        "abstract url": "https://arxiv.org/abs/2401.08046",
        "title": "Enhancing Robustness of LLM-Synthetic Text Detectors for Academic Writing: A Comprehensive Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The emergence of large language models (LLMs), such as Generative Pre-trained Transformer 4 (GPT-4) used by ChatGPT, has profoundly impacted the academic and broader community. While these models offer numerous advantages in terms of revolutionizing work and study methods, they have also garnered significant attention due to their potential negative consequences. One example is generating academic reports or papers with little to no human contribution. Consequently, researchers have focused on developing detectors to address the misuse of LLMs. However, most existing methods prioritize achieving higher accuracy on restricted datasets, neglecting the crucial aspect of generalizability. This limitation hinders their practical application in real-life scenarios where reliability is paramount. In this paper, we present a comprehensive analysis of the impact of prompts on the text generated by LLMs and highlight the potential lack of robustness in one of the current state-of-the-art GPT detectors. To mitigate these issues concerning the misuse of LLMs in academic writing, we propose a reference-based Siamese detector named Synthetic-Siamese which takes a pair of texts, one as the inquiry and the other as the reference. Our method effectively addresses the lack of robustness of previous detectors (OpenAI detector and DetectGPT) and significantly improves the baseline performances in realistic academic writing scenarios by approximately 67% to 95%.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08047",
        "abstract url": "https://arxiv.org/abs/2401.08047",
        "title": "Incremental Extractive Opinion Summarization Using Cover Trees",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Extractive opinion summarization involves automatically producing a summary of text about an entity (e.g., a product's reviews) by extracting representative sentences that capture prevalent opinions in the review set. Typically, in online marketplaces user reviews accumulate over time, and opinion summaries need to be updated periodically to provide customers with up-to-date information. In this work, we study the task of extractive opinion summarization in an incremental setting, where the underlying review set evolves over time. Many of the state-of-the-art extractive opinion summarization approaches are centrality-based, such as CentroidRank (Radev et al., 2004; Chowdhury et al., 2022). CentroidRank performs extractive summarization by selecting a subset of review sentences closest to the centroid in the representation space as the summary. However, these methods are not capable of operating efficiently in an incremental setting, where reviews arrive one at a time. In this paper, we present an efficient algorithm for accurately computing the CentroidRank summaries in an incremental setting. Our approach, CoverSumm, relies on indexing review representations in a cover tree and maintaining a reservoir of candidate summary review sentences. CoverSumm's efficacy is supported by a theoretical and empirical analysis of running time. Empirically, on a diverse collection of data (both real and synthetically created to illustrate scaling considerations), we demonstrate that CoverSumm is up to 36x faster than baseline methods, and capable of adapting to nuanced changes in data distribution. We also conduct human evaluations of the generated summaries and find that CoverSumm is capable of producing informative summaries consistent with the underlying review set.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at TMLR"
    },
    {
        "paper id": "2401.08088",
        "abstract url": "https://arxiv.org/abs/2401.08088",
        "title": "Enhancing Document-level Translation of Large Language Model via Translation Mixed-instructions",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Existing large language models (LLMs) for machine translation are typically fine-tuned on sentence-level translation instructions and achieve satisfactory performance at the sentence level. However, when applied to document-level translation, these models face a significant challenge, particularly when dealing with documents containing over 512 tokens. This challenge arises from the issue of sentence-level coverage, where subsequent sentences in the document remain untranslated. As a result, the document-level translation capability of LLMs fine-tuned on sentence-level translation instructions is significantly limited. We conjecture that the primary cause of LLMs' weak document-level translation performance is the absence of document-to-document mapping ability. To address the issue, we propose an approach that combines sentence-level and document-level translation instructions of varying lengths to fine-tune LLMs. Our proposed translation mixed-instructions enable LLMs (Llama-2~7B and 13B) to maintain consistent translation performance from the sentence level to documents containing as many as 2048 tokens. Extensive experimental results show that the proposed approach significantly enhances the document-level translation capabilities of LLMs on 10 language pairs, effectively mitigating the sentence-level coverage issue in document-level translation. Experimentation on discourse phenomena has demonstrated that our document-level translation approach significantly improves translation quality, both in terms of BLEU score and discourse coherence.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2401.08095",
        "abstract url": "https://arxiv.org/abs/2401.08095",
        "title": "DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Emotional voice conversion (EVC) seeks to modify the emotional tone of a speaker's voice while preserving the original linguistic content and the speaker's unique vocal characteristics. Recent advancements in EVC have involved the simultaneous modeling of pitch and duration, utilizing the potential of sequence-to-sequence (seq2seq) models. To enhance reliability and efficiency in conversion, this study shifts focus towards parallel speech generation. We introduce Duration-Flexible EVC (DurFlex-EVC), which integrates a style autoencoder and unit aligner. Traditional models, while incorporating self-supervised learning (SSL) representations that contain both linguistic and paralinguistic information, have neglected this dual nature, leading to reduced controllability. Addressing this issue, we implement cross-attention to synchronize these representations with various emotions. Additionally, a style autoencoder is developed for the disentanglement and manipulation of style elements. The efficacy of our approach is validated through both subjective and objective evaluations, establishing its superiority over existing models in the field.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "13 pages, 9 figures, 8 tables"
    },
    {
        "paper id": "2401.08111",
        "abstract url": "https://arxiv.org/abs/2401.08111",
        "title": "Mobile Contactless Palmprint Recognition: Use of Multiscale, Multimodel Embeddings",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Contactless palmprints are comprised of both global and local discriminative features. Most prior work focuses on extracting global features or local features alone for palmprint matching, whereas this research introduces a novel framework that combines global and local features for enhanced palmprint matching accuracy. Leveraging recent advancements in deep learning, this study integrates a vision transformer (ViT) and a convolutional neural network (CNN) to extract complementary local and global features. Next, a mobile-based, end-to-end palmprint recognition system is developed, referred to as Palm-ID. On top of the ViT and CNN features, Palm-ID incorporates a palmprint enhancement module and efficient dimensionality reduction (for faster matching). Palm-ID balances the trade-off between accuracy and latency, requiring just 18ms to extract a template of size 516 bytes, which can be efficiently searched against a 10,000 palmprint gallery in 0.33ms on an AMD EPYC 7543 32-Core CPU utilizing 128-threads. Cross-database matching protocols and evaluations on large-scale operational datasets demonstrate the robustness of the proposed method, achieving a TAR of 98.06% at FAR=0.01% on a newly collected, time-separated dataset. To show a practical deployment of the end-to-end system, the entire recognition pipeline is embedded within a mobile device for enhanced user privacy and security.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10286",
        "abstract url": "https://arxiv.org/abs/2401.10286",
        "title": "Code-Based English Models Surprising Performance on Chinese QA Pair Extraction Task",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In previous studies, code-based models have consistently outperformed text-based models in reasoning-intensive scenarios. When generating our knowledge base for Retrieval-Augmented Generation (RAG), we observed that code-based models also perform exceptionally well in Chinese QA Pair Extraction task. Further, our experiments and the metrics we designed discovered that code-based models containing a certain amount of Chinese data achieve even better performance. Additionally, the capabilities of code-based English models in specified Chinese tasks offer a distinct perspective for discussion on the philosophical \"Chinese Room\" thought experiment.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12985",
        "abstract url": "https://arxiv.org/abs/2401.12985",
        "title": "The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make it problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also consider a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish as intermediate languages reduces the bias (up to 68% reduction) in human-generated data while, in synthetic data, it takes a surprising turn by increasing the bias! Our findings will help researchers and practitioners refine their SAS testing strategies and foster trust as SASs are considered part of more mission-critical applications for global use.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2302.02038"
    },
    {
        "paper id": "2401.12986",
        "abstract url": "https://arxiv.org/abs/2401.12986",
        "title": "Crowdsourced Adaptive Surveys",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Public opinion surveys are vital for informing democratic decision-making, but responding to rapidly changing information environments and measuring beliefs within niche communities can be challenging for traditional survey methods. This paper introduces a crowdsourced adaptive survey methodology (CSAS) that unites advances in natural language processing and adaptive algorithms to generate question banks that evolve with user input. The CSAS method converts open-ended text provided by participants into Likert-style items and applies a multi-armed bandit algorithm to determine user-provided questions that should be prioritized in the survey. The method's adaptive nature allows for the exploration of new survey questions, while imposing minimal costs in survey length. Applications in the domains of Latino information environments and issue importance showcase CSAS's ability to identify claims or issues that might otherwise be difficult to track using standard approaches. I conclude by discussing the method's potential for studying topics where participant-generated content might improve our understanding of public opinion.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "25 pages, 5 figures"
    },
    {
        "paper id": "2402.04925",
        "abstract url": "https://arxiv.org/abs/2402.04925",
        "title": "TP-Aware Dequantization",
        "rating": "1",
        "keywords": [
            [
                "GPU memory"
            ]
        ],
        "abstract": "In this paper, we present a novel method that reduces model inference latency during distributed deployment of Large Language Models (LLMs). Our contribution is an optimized inference deployment scheme that address the current limitations of state-of-the-art quantization kernels when used in conjunction with Tensor Parallel (TP). Our method preserves data locality in GPU memory access patterns and exploits a priori knowledge of TP to reduce global communication. We demonstrate an up to 1.81x speedup over existing methods for Llama-70B and up to 1.78x speedup for IBM WatsonX's Granite-20B MLP layer problem sizes on A100 and H100 NVIDIA DGX Systems for a variety of TP settings.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.12057",
        "abstract url": "https://arxiv.org/abs/2403.12057",
        "title": "Discriminative Consensus Mining with A Thousand Groups for More Accurate Co-Salient Object Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Co-Salient Object Detection (CoSOD) is a rapidly growing task, extended from Salient Object Detection (SOD) and Common Object Segmentation (Co-Segmentation). It is aimed at detecting the co-occurring salient object in the given image group. Many effective approaches have been proposed on the basis of existing datasets. However, there is still no standard and efficient training set in CoSOD, which makes it chaotic to choose training sets in the recently proposed CoSOD methods. First, the drawbacks of existing training sets in CoSOD are analyzed in a comprehensive way, and potential improvements are provided to solve existing problems to some extent. In particular, in this thesis, a new CoSOD training set is introduced, named Co-Saliency of ImageNet (CoSINe) dataset. The proposed CoSINe is the largest number of groups among all existing CoSOD datasets. The images obtained here span a wide variety in terms of categories, object sizes, etc. In experiments, models trained on CoSINe can achieve significantly better performance with fewer images compared to all existing datasets. Second, to make the most of the proposed CoSINe, a novel CoSOD approach named Hierarchical Instance-aware COnsensus MinEr (HICOME) is proposed, which efficiently mines the consensus feature from different feature levels and discriminates objects of different classes in an object-aware contrastive way. As extensive experiments show, the proposed HICOME achieves SoTA performance on all the existing CoSOD test sets. Several useful training tricks suitable for training CoSOD models are also provided. Third, practical applications are given using the CoSOD technique to show the effectiveness. Finally, the remaining challenges and potential improvements of CoSOD are discussed to inspire related work in the future. The source code, the dataset, and the online demo will be publicly available at github.com/ZhengPeng7/CoSINe.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Master's thesis of the M.S. program at Aalto University and University of Trento, v1. The source codes, the dataset, and the demos will not be released until the conference/journal version is finished and made public"
    },
    {
        "paper id": "2401.07482",
        "abstract url": "https://arxiv.org/abs/2401.07482",
        "title": "A Contrast Based Feature Selection Algorithm for High-dimensional Data set in Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Feature selection is an important process in machine learning and knowledge discovery. By selecting the most informative features and eliminating irrelevant ones, the performance of learning algorithms can be improved and the extraction of meaningful patterns and insights from data can be facilitated. However, most existing feature selection methods, when applied to large datasets, encountered the bottleneck of high computation costs. To address this problem, we propose a novel filter feature selection method, ContrastFS, which selects discriminative features based on the discrepancies features shown between different classes. We introduce a dimensionless quantity as a surrogate representation to summarize the distributional individuality of certain classes, based on this quantity we evaluate features and study the correlation among them. We validate effectiveness and efficiency of our approach on several widely studied benchmark datasets, results show that the new method performs favorably with negligible computation in comparison with other state-of-the-art feature selection methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07488",
        "abstract url": "https://arxiv.org/abs/2401.07488",
        "title": "Feature Selection via Maximizing Distances between Class Conditional Distributions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "For many data-intensive tasks, feature selection is an important preprocessing step. However, most existing methods do not directly and intuitively explore the intrinsic discriminative information of features. We propose a novel feature selection framework based on the distance between class conditional distributions, measured by integral probability metrics (IPMs). Our framework directly explores the discriminative information of features in the sense of distributions for supervised classification. We analyze the theoretical and practical aspects of IPMs for feature selection, construct criteria based on IPMs. We propose several variant feature selection methods of our framework based on the 1-Wasserstein distance and implement them on real datasets from different domains. Experimental results show that our framework can outperform state-of-the-art methods in terms of classification accuracy and robustness to perturbations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07540",
        "abstract url": "https://arxiv.org/abs/2401.07540",
        "title": "Study Features via Exploring Distribution Structure",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present a novel framework for data redundancy measurement based on probabilistic modeling of datasets, and a new criterion for redundancy detection that is resilient to noise. We also develop new methods for data redundancy reduction using both deterministic and stochastic optimization techniques. Our framework is flexible and can handle different types of features, and our experiments on benchmark datasets demonstrate the effectiveness of our methods. We provide a new perspective on feature selection, and propose effective and robust approaches for both supervised and unsupervised learning problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07551",
        "abstract url": "https://arxiv.org/abs/2401.07551",
        "title": "Robust Semi-Supervised Learning for Self-learning Open-World Classes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Existing semi-supervised learning (SSL) methods assume that labeled and unlabeled data share the same class space. However, in real-world applications, unlabeled data always contain classes not present in the labeled set, which may cause classification performance degradation of known classes. Therefore, open-world SSL approaches are researched to handle the presence of multiple unknown classes in the unlabeled data, which aims to accurately classify known classes while fine-grained distinguishing different unknown classes. To address this challenge, in this paper, we propose an open-world SSL method for Self-learning Open-world Classes (SSOC), which can explicitly self-learn multiple unknown classes. Specifically, SSOC first defines class center tokens for both known and unknown classes and autonomously learns token representations according to all samples with the cross-attention mechanism. To effectively discover novel classes, SSOC further designs a pairwise similarity loss in addition to the entropy loss, which can wisely exploit the information available in unlabeled data from instances' predictions and relationships. Extensive experiments demonstrate that SSOC outperforms the state-of-the-art baselines on multiple popular classification benchmarks. Specifically, on the ImageNet-100 dataset with a novel ratio of 90%, SSOC achieves a remarkable 22% improvement.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07567",
        "abstract url": "https://arxiv.org/abs/2401.07567",
        "title": "Bias-Conflict Sample Synthesis and Adversarial Removal Debias Strategy for Temporal Sentence Grounding in Video",
        "rating": "0.5",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Temporal Sentence Grounding in Video (TSGV) is troubled by dataset bias issue, which is caused by the uneven temporal distribution of the target moments for samples with similar semantic components in input videos or query texts. Existing methods resort to utilizing prior knowledge about bias to artificially break this uneven distribution, which only removes a limited amount of significant language biases. In this work, we propose the bias-conflict sample synthesis and adversarial removal debias strategy (BSSARD), which dynamically generates bias-conflict samples by explicitly leveraging potentially spurious correlations between single-modality features and the temporal position of the target moments. Through adversarial training, its bias generators continuously introduce biases and generate bias-conflict samples to deceive its grounding model. Meanwhile, the grounding model continuously eliminates the introduced biases, which requires it to model multi-modality alignment information. BSSARD will cover most kinds of coupling relationships and disrupt language and visual biases simultaneously. Extensive experiments on Charades-CD and ActivityNet-CD demonstrate the promising debiasing capability of BSSARD. Source codes are available at https://github.com/qzhb/BSSARD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by AAAI 2024"
    },
    {
        "paper id": "2401.07595",
        "abstract url": "https://arxiv.org/abs/2401.07595",
        "title": "E3x: $\\mathrm{E}(3)$-Equivariant Deep Learning Made Easy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work introduces E3x, a software package for building neural networks that are equivariant with respect to the Euclidean group $\\mathrm{E}(3)$, consisting of translations, rotations, and reflections of three-dimensional space. Compared to ordinary neural networks, $\\mathrm{E}(3)$-equivariant models promise benefits whenever input and/or output data are quantities associated with three-dimensional objects. This is because the numeric values of such quantities (e.g. positions) typically depend on the chosen coordinate system. Under transformations of the reference frame, the values change predictably, but the underlying rules can be difficult to learn for ordinary machine learning models. With built-in $\\mathrm{E}(3)$-equivariance, neural networks are guaranteed to satisfy the relevant transformation rules exactly, resulting in superior data efficiency and accuracy. The code for E3x is available from https://github.com/google-research/e3x, detailed documentation and usage examples can be found on https://e3x.readthedocs.io.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07599",
        "abstract url": "https://arxiv.org/abs/2401.07599",
        "title": "The Koo Dataset: An Indian Microblogging Platform With Global Ambitions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Increasingly, alternative platforms are playing a key role in the social media ecosystem. Koo, a microblogging platform based in India, has emerged as a major new social network hosting high profile politicians from several countries (India, Brazil, Nigeria) and many internationally renowned celebrities. This paper presents the largest publicly available Koo dataset, spanning from the platform's founding in early 2020 to September 2023, providing detailed metadata for 72M posts, 75M comments, 40M shares, 284M likes and 1.4M user profiles. Along with the release of the dataset, we provide an overview of the platform including a discussion of the news ecosystem on the platform, hashtag usage and user engagement. Our results highlight the pivotal role that new platforms play in shaping online communities in emerging economies and the Global South, connecting local politicians and public figures with their followers. With Koo's ambition to become the town hall for diverse non-English speaking communities, our dataset offers new opportunities for studying social media beyond a Western context.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "10 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2401.07606",
        "abstract url": "https://arxiv.org/abs/2401.07606",
        "title": "RedEx: Beyond Fixed Representation Methods via Convex Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Optimizing Neural networks is a difficult task which is still not well understood. On the other hand, fixed representation methods such as kernels and random features have provable optimization guarantees but inferior performance due to their inherent inability to learn the representations. In this paper, we aim at bridging this gap by presenting a novel architecture called RedEx (Reduced Expander Extractor) that is as expressive as neural networks and can also be trained in a layer-wise fashion via a convex program with semi-definite constraints and optimization guarantees. We also show that RedEx provably surpasses fixed representation methods, in the sense that it can efficiently learn a family of target functions which fixed representation methods cannot.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07643",
        "abstract url": "https://arxiv.org/abs/2401.07643",
        "title": "Machine Learning-based xApp for Dynamic Resource Allocation in O-RAN Networks",
        "rating": "0.5",
        "keywords": [
            [
                "ICML"
            ]
        ],
        "abstract": "The disaggregated, distributed and virtualised implementation of radio access networks allows for dynamic resource allocation. These attributes can be realised by virtue of the Open Radio Access Networks (O-RAN) architecture. In this article, we tackle the issue of dynamic resource allocation using a data-driven approach by employing Machine Learning (ML). We present an xApp-based implementation for the proposed ML algorithm. The core aim of this work is to optimise resource allocation and fulfil Service Level Specifications (SLS). This is accomplished by dynamically adjusting the allocation of Physical Resource Blocks (PRBs) based on traffic demand and Quality of Service (QoS) requirements. The proposed ML model effectively selects the best allocation policy for each base station and enhances the performance of scheduler functionality in O-RAN - Distributed Unit (O-DU). We show that an xApp implementing the Random Forest Classifier can yield high (85\\%) performance accuracy for optimal policy selection. This can be attained using the O-RAN instance state input parameters over a short training duration.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 6 figures, 2024 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN)"
    },
    {
        "paper id": "2401.07682",
        "abstract url": "https://arxiv.org/abs/2401.07682",
        "title": "Cash and Card Acceptance in Retail Payments: Motivations and Factors",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "34 pages, 19 figures, 5 tables"
    },
    {
        "paper id": "2401.07697",
        "abstract url": "https://arxiv.org/abs/2401.07697",
        "title": "Data vs. Model Machine Learning Fairness Testing: An Empirical Study",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although several fairness definitions and bias mitigation techniques exist in the literature, all existing solutions evaluate fairness of Machine Learning (ML) systems after the training stage. In this paper, we take the first steps towards evaluating a more holistic approach by testing for fairness both before and after model training. We evaluate the effectiveness of the proposed approach and position it within the ML development lifecycle, using an empirical analysis of the relationship between model dependent and independent fairness metrics. The study uses 2 fairness metrics, 4 ML algorithms, 5 real-world datasets and 1600 fairness evaluation cycles. We find a linear relationship between data and model fairness metrics when the distribution and the size of the training data changes. Our results indicate that testing for fairness prior to training can be a ``cheap'' and effective means of catching a biased data collection process early; detecting data drifts in production systems and minimising execution of full training cycles thus reducing development time and costs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07709",
        "abstract url": "https://arxiv.org/abs/2401.07709",
        "title": "Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "Image Editing",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which often applies a semantic mask to control the target area for diffusion-based editing. However, most existing solutions obtain these masks via manual operations or off-line processing, greatly reducing their efficiency. In this paper, we propose a novel and efficient image editing method for Text-to-Image (T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In particular, InstDiffEdit aims to employ the cross-modal attention ability of existing diffusion models to achieve instant mask guidance during the diffusion steps. To reduce the noise of attention maps and realize the full automatics, we equip InstDiffEdit with a training-free refinement scheme to adaptively aggregate the attention distributions for the automatic yet accurate mask generation. Meanwhile, to supplement the existing evaluations of DIE, we propose a new benchmark called Editing-Mask to examine the mask accuracy and local editing ability of existing methods. To validate InstDiffEdit, we also conduct extensive experiments on ImageNet and Imagen, and compare it with a bunch of the SOTA methods. The experimental results show that InstDiffEdit not only outperforms the SOTA methods in both image quality and editing results, but also has a much faster inference speed, i.e., +5 to +6 times.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI2024"
    },
    {
        "paper id": "2401.07710",
        "abstract url": "https://arxiv.org/abs/2401.07710",
        "title": "Go-Explore for Residential Energy Management",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Reinforcement learning is commonly applied in residential energy management, particularly for optimizing energy costs. However, RL agents often face challenges when dealing with deceptive and sparse rewards in the energy control domain, especially with stochastic rewards. In such situations, thorough exploration becomes crucial for learning an optimal policy. Unfortunately, the exploration mechanism can be misled by deceptive reward signals, making thorough exploration difficult. Go-Explore is a family of algorithms which combines planning methods and reinforcement learning methods to achieve efficient exploration. We use the Go-Explore algorithm to solve the cost-saving task in residential energy management problems and achieve an improvement of up to 19.84\\% compared to the well-known reinforcement learning algorithms.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07721",
        "abstract url": "https://arxiv.org/abs/2401.07721",
        "title": "Graph Transformer GANs with Graph Masked Modeling for Architectural Layout Generation",
        "rating": "0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We present a novel graph Transformer generative adversarial network (GTGAN) to learn effective graph node relations in an end-to-end fashion for challenging graph-constrained architectural layout generation tasks. The proposed graph-Transformer-based generator includes a novel graph Transformer encoder that combines graph convolutions and self-attentions in a Transformer to model both local and global interactions across connected and non-connected graph nodes. Specifically, the proposed connected node attention (CNA) and non-connected node attention (NNA) aim to capture the global relations across connected nodes and non-connected nodes in the input graph, respectively. The proposed graph modeling block (GMB) aims to exploit local vertex interactions based on a house layout topology. Moreover, we propose a new node classification-based discriminator to preserve the high-level semantic and discriminative node features for different house components. To maintain the relative spatial relationships between ground truth and predicted graphs, we also propose a novel graph-based cycle-consistency loss. Finally, we propose a novel self-guided pre-training method for graph representation learning. This approach involves simultaneous masking of nodes and edges at an elevated mask ratio (i.e., 40%) and their subsequent reconstruction using an asymmetric graph-centric autoencoder architecture. This method markedly improves the model's learning proficiency and expediency. Experiments on three challenging graph-constrained architectural layout generation tasks (i.e., house layout generation, house roof generation, and building layout generation) with three public datasets demonstrate the effectiveness of the proposed method in terms of objective quantitative scores and subjective visual realism. New state-of-the-art results are established by large margins on these three tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to TPAMI, an extended version of a paper published in CVPR2023. arXiv admin note: substantial text overlap with arXiv:2303.08225"
    },
    {
        "paper id": "2401.07722",
        "abstract url": "https://arxiv.org/abs/2401.07722",
        "title": "Inferring Preferences from Demonstrations in Multi-Objective Residential Energy Management",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "It is often challenging for a user to articulate their preferences accurately in multi-objective decision-making problems. Demonstration-based preference inference (DemoPI) is a promising approach to mitigate this problem. Understanding the behaviours and values of energy customers is an example of a scenario where preference inference can be used to gain insights into the values of energy customers with multiple objectives, e.g. cost and comfort. In this work, we applied the state-of-art DemoPI method, i.e., the dynamic weight-based preference inference (DWPI) algorithm in a multi-objective residential energy consumption setting to infer preferences from energy consumption demonstrations by simulated users following a rule-based approach. According to our experimental results, the DWPI model achieves accurate demonstration-based preference inferring in three scenarios. These advancements enhance the usability and effectiveness of multi-objective reinforcement learning (MORL) in energy management, enabling more intuitive and user-friendly preference specifications, and opening the door for DWPI to be applied in real-world settings.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07744",
        "abstract url": "https://arxiv.org/abs/2401.07744",
        "title": "Combining Machine Learning and Ontology: A Systematic Literature Review",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Motivated by the desire to explore the process of combining inductive and deductive reasoning, we conducted a systematic literature review of articles that investigate the integration of machine learning and ontologies. The objective was to identify diverse techniques that incorporate both inductive reasoning (performed by machine learning) and deductive reasoning (performed by ontologies) into artificial intelligence systems. Our review, which included the analysis of 128 studies, allowed us to identify three main categories of hybridization between machine learning and ontologies: learning-enhanced ontologies, semantic data mining, and learning and reasoning systems. We provide a comprehensive examination of all these categories, emphasizing the various machine learning algorithms utilized in the studies. Furthermore, we compared our classification with similar recent work in the field of hybrid AI and neuro-symbolic approaches.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07788",
        "abstract url": "https://arxiv.org/abs/2401.07788",
        "title": "Activations and Gradients Compression for Model-Parallel Training",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large neural networks require enormous computational clusters of machines. Model-parallel training, when the model architecture is partitioned sequentially between workers, is a popular approach for training modern models. Information compression can be applied to decrease workers communication time, as it is often a bottleneck in such systems. This work explores how simultaneous compression of activations and gradients in model-parallel distributed training setup affects convergence. We analyze compression methods such as quantization and TopK compression, and also experiment with error compensation techniques. Moreover, we employ TopK with AQ-SGD per-batch error feedback approach. We conduct experiments on image classification and language model fine-tuning tasks. Our findings demonstrate that gradients require milder compression rates than activations. We observe that $K=10\\%$ is the lowest TopK compression level, which does not harm model convergence severely. Experiments also show that models trained with TopK perform well only when compression is also applied during inference. We find that error feedback techniques do not improve model-parallel training compared to plain compression, but allow model inference without compression with almost no quality drop. Finally, when applied with the AQ-SGD approach, TopK stronger than with $ K=30\\%$ worsens model performance significantly.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 6 figures, 5 tables"
    },
    {
        "paper id": "2401.07836",
        "abstract url": "https://arxiv.org/abs/2401.07836",
        "title": "Two Types of AI Existential Risk: Decisive and Accumulative",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The conventional discourse on existential risks (x-risks) from AI typically focuses on abrupt, dire events caused by advanced AI systems, particularly those that might achieve or surpass human-level intelligence. These events have severe consequences that either lead to human extinction or irreversibly cripple human civilization to a point beyond recovery. This discourse, however, often neglects the serious possibility of AI x-risks manifesting incrementally through a series of smaller yet interconnected disruptions, gradually crossing critical thresholds over time. This paper contrasts the conventional \"decisive AI x-risk hypothesis\" with an \"accumulative AI x-risk hypothesis.\" While the former envisions an overt AI takeover pathway, characterized by scenarios like uncontrollable superintelligence, the latter suggests a different causal pathway to existential catastrophes. This involves a gradual accumulation of critical AI-induced threats such as severe vulnerabilities and systemic erosion of econopolitical structures. The accumulative hypothesis suggests a boiling frog scenario where incremental AI risks slowly converge, undermining resilience until a triggering event results in irreversible collapse. Through systems analysis, this paper examines the distinct assumptions differentiating these two hypotheses. It is then argued that the accumulative view reconciles seemingly incompatible perspectives on AI risks. The implications of differentiating between these causal pathways -- the decisive and the accumulative -- for the governance of AI risks as well as long-term AI safety are discussed.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07844",
        "abstract url": "https://arxiv.org/abs/2401.07844",
        "title": "The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of strong law of large numbers and a commonly used V4 Lyapunov drift condition and trivially holds if the Markov chain is finite and irreducible.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07871",
        "abstract url": "https://arxiv.org/abs/2401.07871",
        "title": "Explainable Predictive Maintenance: A Survey of Current Methods, Challenges and Opportunities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Predictive maintenance is a well studied collection of techniques that aims to prolong the life of a mechanical system by using artificial intelligence and machine learning to predict the optimal time to perform maintenance. The methods allow maintainers of systems and hardware to reduce financial and time costs of upkeep. As these methods are adopted for more serious and potentially life-threatening applications, the human operators need trust the predictive system. This attracts the field of Explainable AI (XAI) to introduce explainability and interpretability into the predictive system. XAI brings methods to the field of predictive maintenance that can amplify trust in the users while maintaining well-performing systems. This survey on explainable predictive maintenance (XPM) discusses and presents the current methods of XAI as applied to predictive maintenance while following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines. We categorize the different XPM methods into groups that follow the XAI literature. Additionally, we include current challenges and a discussion on future research directions in XPM.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07874",
        "abstract url": "https://arxiv.org/abs/2401.07874",
        "title": "Do stable neural networks exist for classification problems? -- A new view on stability in AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In deep learning (DL) the instability phenomenon is widespread and well documented, most commonly using the classical measure of stability, the Lipschitz constant. While a small Lipchitz constant is traditionally viewed as guarantying stability, it does not capture the instability phenomenon in DL for classification well. The reason is that a classification function -- which is the target function to be approximated -- is necessarily discontinuous, thus having an 'infinite' Lipchitz constant. As a result, the classical approach will deem every classification function unstable, yet basic classification functions a la 'is there a cat in the image?' will typically be locally very 'flat' -- and thus locally stable -- except at the decision boundary. The lack of an appropriate measure of stability hinders a rigorous theory for stability in DL, and consequently, there are no proper approximation theoretic results that can guarantee the existence of stable networks for classification functions. In this paper we introduce a novel stability measure $\\mathscr{S}(f)$, for any classification function $f$, appropriate to study the stability of discontinuous functions and their approximations. We further prove two approximation theorems: First, for any $\u03b5> 0$ and any classification function $f$ on a \\emph{compact set}, there is a neural network (NN) $\u03c8$, such that $\u03c8- f \\neq 0$ only on a set of measure $< \u03b5$, moreover, $\\mathscr{S}(\u03c8) \\geq \\mathscr{S}(f) - \u03b5$ (as accurate and stable as $f$ up to $\u03b5$). Second, for any classification function $f$ and $\u03b5> 0$, there exists a NN $\u03c8$ such that $\u03c8= f$ on the set of points that are at least $\u03b5$ away from the decision boundary.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07882",
        "abstract url": "https://arxiv.org/abs/2401.07882",
        "title": "On the Importance of Neural Wiener Filter for Resource Efficient Multichannel Speech Enhancement",
        "rating": "0.5",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "We introduce a time-domain framework for efficient multichannel speech enhancement, emphasizing low latency and computational efficiency. This framework incorporates two compact deep neural networks (DNNs) surrounding a multichannel neural Wiener filter (NWF). The first DNN enhances the speech signal to estimate NWF coefficients, while the second DNN refines the output from the NWF. The NWF, while conceptually similar to the traditional frequency-domain Wiener filter, undergoes a training process optimized for low-latency speech enhancement, involving fine-tuning of both analysis and synthesis transforms. Our research results illustrate that the NWF output, having minimal nonlinear distortions, attains performance levels akin to those of the first DNN, deviating from conventional Wiener filter paradigms. Training all components jointly outperforms sequential training, despite its simplicity. Consequently, this framework achieves superior performance with fewer parameters and reduced computational demands, making it a compelling solution for resource-efficient multichannel speech enhancement.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Accepted for publication at ICASSP"
    },
    {
        "paper id": "2401.07883",
        "abstract url": "https://arxiv.org/abs/2401.07883",
        "title": "The Chronicles of RAG: The Retriever, the Chunk and the Generator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Retrieval Augmented Generation (RAG) has become one of the most popular paradigms for enabling LLMs to access external data, and also as a mechanism for grounding to mitigate against hallucinations. When implementing RAG you can face several challenges like effective integration of retrieval models, efficient representation learning, data diversity, computational efficiency optimization, evaluation, and quality of text generation. Given all these challenges, every day a new technique to improve RAG appears, making it unfeasible to experiment with all combinations for your problem. In this context, this paper presents good practices to implement, optimize, and evaluate RAG for the Brazilian Portuguese language, focusing on the establishment of a simple pipeline for inference and experiments. We explored a diverse set of methods to answer questions about the first Harry Potter book. To generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview, gpt-3.5-turbo-1106, and Google's Gemini Pro. Focusing on the quality of the retriever, our approach achieved an improvement of MRR@10 by 35.4% compared to the baseline. When optimizing the input size in the application, we observed that it is possible to further enhance it by 2.4%. Finally, we present the complete architecture of the RAG with our recommendations. As result, we moved from a baseline of 57.88% to a maximum relative score of 98.61%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 15 figures, 9 tables"
    },
    {
        "paper id": "2401.07886",
        "abstract url": "https://arxiv.org/abs/2401.07886",
        "title": "Learned Best-Effort LLM Serving",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many applications must provide low-latency LLM service to users or risk unacceptable user experience. However, over-provisioning resources to serve fluctuating request patterns is often prohibitively expensive. In this work, we present a best-effort serving system that employs deep reinforcement learning to adjust service quality based on the task distribution and system load. Our best-effort system can maintain availability with over 10x higher client request rates, serves above 96% of peak performance 4.1x more often, and serves above 98% of peak performance 2.3x more often than static serving on unpredictable workloads. Our learned router is robust to shifts in both the arrival and task distribution. Compared to static serving, learned best-effort serving allows for cost-efficient serving through increased hardware utility. Additionally, we argue that learned best-effort LLM serving is applicable in wide variety of settings and provides application developers great flexibility to meet their specific needs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07889",
        "abstract url": "https://arxiv.org/abs/2401.07889",
        "title": "Machine Learning Techniques to Identify Hand Gestures amidst Forearm Muscle Signals",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study investigated the use of forearm EMG data for distinguishing eight hand gestures, employing the Neural Network and Random Forest algorithms on data from ten participants. The Neural Network achieved 97 percent accuracy with 1000-millisecond windows, while the Random Forest achieved 85 percent accuracy with 200-millisecond windows. Larger window sizes improved gesture classification due to increased temporal resolution. The Random Forest exhibited faster processing at 92 milliseconds, compared to the Neural Network's 124 milliseconds. In conclusion, the study identified a Neural Network with a 1000-millisecond stream as the most accurate (97 percent), and a Random Forest with a 200-millisecond stream as the most efficient (85 percent). Future research should focus on increasing sample size, incorporating more hand gestures, and exploring different feature extraction methods and modeling algorithms to enhance system accuracy and efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 7 figures"
    },
    {
        "paper id": "2401.07936",
        "abstract url": "https://arxiv.org/abs/2401.07936",
        "title": "A Globally Convergent Algorithm for Neural Network Parameter Optimization Based on Difference-of-Convex Functions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose an algorithm for optimizing the parameters of single hidden layer neural networks. Specifically, we derive a blockwise difference-of-convex (DC) functions representation of the objective function. Based on the latter, we propose a block coordinate descent (BCD) approach that we combine with a tailored difference-of-convex functions algorithm (DCA). We prove global convergence of the proposed algorithm. Furthermore, we mathematically analyze the convergence rate of parameters and the convergence rate in value (i.e., the training loss). We give conditions under which our algorithm converges linearly or even faster depending on the local shape of the loss function. We confirm our theoretical derivations numerically and compare our algorithm against state-of-the-art gradient-based solvers in terms of both training loss and test loss.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "accepted by TMLR"
    },
    {
        "paper id": "2401.07964",
        "abstract url": "https://arxiv.org/abs/2401.07964",
        "title": "AI-as-exploration: Navigating intelligence space",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial Intelligence is a field that lives many lives, and the term has come to encompass a motley collection of scientific and commercial endeavours. In this paper, I articulate the contours of a rather neglected but central scientific role that AI has to play, which I dub `AI-as-exploration'.The basic thrust of AI-as-exploration is that of creating and studying systems that can reveal candidate building blocks of intelligence that may differ from the forms of human and animal intelligence we are familiar with. In other words, I suggest that AI is one of the best tools we have for exploring intelligence space, namely the space of possible intelligent systems. I illustrate the value of AI-as-exploration by focusing on a specific case study, i.e., recent work on the capacity to combine novel and invented concepts in humans and Large Language Models. I show that the latter, despite showing human-level accuracy in such a task, most probably solve it in ways radically different, but no less relevant to intelligence research, to those hypothesised for humans.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07988",
        "abstract url": "https://arxiv.org/abs/2401.07988",
        "title": "Metasurface-Based Receivers with $1$-bit ADCs for Multi-User Uplink Communications",
        "rating": "0.5",
        "keywords": [
            [
                "ICASSP"
            ]
        ],
        "abstract": "The massive Multiple-Input Multiple-Output (mMIMO) concept has been recently moving forward to extreme scales to address the envisioned requirements of next generation networks. However, the extension of conventional architectures will result in significant cost and power consumption. To this end, metasurface-based transceivers, consisting of microstrips of metamaterials, have recently emerged as an efficient enabler of extreme mMIMO systems. In this paper, we consider metasurface-based receivers with a $1$-bit Analog-to-Digital Converter (ADC) per microstrip and develop an analytical framework for the optimization of the analog and digital combining matrices. Our numerical results, including comparisons with fully digital, infinite-resolution MIMO, provide useful insights into the role of various system parameters.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures, to be presented in IEEE ICASSP 2024"
    },
    {
        "paper id": "2401.07993",
        "abstract url": "https://arxiv.org/abs/2401.07993",
        "title": "Carrying over algorithm in transformers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Addition is perhaps one of the simplest arithmetic tasks one can think of and is usually performed using the carrying over algorithm. This algorithm consists of two tasks: adding digits in the same position and carrying over a one whenever necessary. We study how transformer models implement this algorithm and how the two aforementioned tasks are allocated to different parts of the network. We first focus on two-layer encoder-only models and show that the carrying over algorithm is implemented in a modular fashion. The first layer is mostly responsible for adding digits in the same position. The second layer first decides, in the attention, which positions need a carried one or not, and then performs the carrying of the one in the final MLP. We provide a simple way of precisely identifying which neurons are responsible for that task. This implementation of the carrying over algorithm occurs across a range of hyperparameters for two as well as three-layer models. For small decoder-only models, we observe the same implementation and provide suggestive evidence for its existence in three 7B large language models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Comments welcome!"
    },
    {
        "paper id": "2401.08016",
        "abstract url": "https://arxiv.org/abs/2401.08016",
        "title": "Contextual Bandits with Stage-wise Constraints",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study contextual bandits in the presence of a stage-wise constraint (a constraint at each round), when the constraint must be satisfied both with high probability and in expectation. Obviously the setting where the constraint is in expectation is a relaxation of the one with high probability. We start with the linear case where both the contextual bandit problem (reward function) and the stage-wise constraint (cost function) are linear. In each of the high probability and in expectation settings, we propose an upper-confidence bound algorithm for the problem and prove a $T$-round regret bound for it. Our algorithms balance exploration and constraint satisfaction using a novel idea that scales the radii of the reward and cost confidence sets with different scaling factors. We also prove a lower-bound for this constrained problem, show how our algorithms and analyses can be extended to multiple constraints, and provide simulations to validate our theoretical results. In the high probability setting, we describe the minimum requirements for the action set in order for our algorithm to be tractable. In the setting that the constraint is in expectation, we further specialize our results to multi-armed bandits and propose a computationally efficient algorithm for this setting with regret analysis. Finally, we extend our results to the case where the reward and cost functions are both non-linear. We propose an algorithm for this case and prove a regret bound for it that characterize the function class complexity by the eluder dimension.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "53 pages. arXiv admin note: text overlap with arXiv:2006.10185"
    },
    {
        "paper id": "2401.08103",
        "abstract url": "https://arxiv.org/abs/2401.08103",
        "title": "Resolving Ethics Trade-offs in Implementing Responsible AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "While the operationalisation of high-level AI ethics principles into practical AI/ML systems has made progress, there is still a theory-practice gap in managing tensions between the underlying AI ethics aspects. We cover five approaches for addressing the tensions via trade-offs, ranging from rudimentary to complex. The approaches differ in the types of considered context, scope, methods for measuring contexts, and degree of justification. None of the approaches is likely to be appropriate for all organisations, systems, or applications. To address this, we propose a framework which consists of: (i) proactive identification of tensions, (ii) prioritisation and weighting of ethics aspects, (iii) justification and documentation of trade-off decisions. The proposed framework aims to facilitate the implementation of well-rounded AI/ML systems that are appropriate for potential regulatory requirements.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08715",
        "abstract url": "https://arxiv.org/abs/2401.08715",
        "title": "Selecting Subsets of Source Data for Transfer Learning with Applications in Metal Additive Manufacturing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Considering data insufficiency in metal additive manufacturing (AM), transfer learning (TL) has been adopted to extract knowledge from source domains (e.g., completed printings) to improve the modeling performance in target domains (e.g., new printings). Current applications use all accessible source data directly in TL with no regard to the similarity between source and target data. This paper proposes a systematic method to find appropriate subsets of source data based on similarities between the source and target datasets for a given set of limited target domain data. Such similarity is characterized by the spatial and model distance metrics. A Pareto frontier-based source data selection method is developed, where the source data located on the Pareto frontier defined by two similarity distance metrics are selected iteratively. The method is integrated into an instance-based TL method (decision tree regression model) and a model-based TL method (fine-tuned artificial neural network). Both models are then tested on several regression tasks in metal AM. Comparison results demonstrate that 1) the source data selection method is general and supports integration with various TL methods and distance metrics, 2) compared with using all source data, the proposed method can find a small subset of source data from the same domain with better TL performance in metal AM regression tasks involving different processes and machines, and 3) when multiple source domains exist, the source data selection method could find the subset from one source domain to obtain comparable or better TL performance than the model constructed using data from all source domains.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "26 pages, 9 figures"
    },
    {
        "paper id": "2401.12228",
        "abstract url": "https://arxiv.org/abs/2401.12228",
        "title": "Topics evolution through multilayer networks; Analysing 2M tweets from 2022 Qatar FIFA World Cup",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In this study, we conducted a comprehensive data collection on the 2022 Qatar FIFA World Cup event and used a multilayer network approach to visualize the main topics, while considering their context and meaning relationships. We structured the data into layers that corresponded with the stages of the tournament and utilized Gephi software to generate the multilayer networks. Our visualizations displayed both the relationships between topics and words, showing the word-context relationship, as well as the dynamics and changes over time by layer of the most frequently discussed topics.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "8 pages, 1 figure, 1 table, 3 link"
    },
    {
        "paper id": "2402.01667",
        "abstract url": "https://arxiv.org/abs/2402.01667",
        "title": "Students' accommodation allocation: A Multicriteria Decision Support System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The social life of students at university has an impact on their educational success. The allocation of accommodation is part of this aspect. This article presents our proposal to improve students' allocation accommodation. We aim to support university administrative departments for the selection of students for housing. Therefore, we propose a decision support system based on multi-criteria decision support methods. To calculate the weights of the criteria, we use the AHP method. Then, to rank the students, AHP, Weighted Sum Method and PROMETHEE methods are used. The aim is to find the most adequate method to rank the students. The result is achieved because the AHP is able to calculate the weight of criteria and the AHP, SWM and PROMETHEE are able to rank the students.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.12381",
        "abstract url": "https://arxiv.org/abs/2402.12381",
        "title": "Constrained Multi-objective Optimization with Deep Reinforcement Learning Assisted Operator Selection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Solving constrained multi-objective optimization problems with evolutionary algorithms has attracted considerable attention. Various constrained multi-objective optimization evolutionary algorithms (CMOEAs) have been developed with the use of different algorithmic strategies, evolutionary operators, and constraint-handling techniques. The performance of CMOEAs may be heavily dependent on the operators used, however, it is usually difficult to select suitable operators for the problem at hand. Hence, improving operator selection is promising and necessary for CMOEAs. This work proposes an online operator selection framework assisted by Deep Reinforcement Learning. The dynamics of the population, including convergence, diversity, and feasibility, are regarded as the state; the candidate operators are considered as actions; and the improvement of the population state is treated as the reward. By using a Q-Network to learn a policy to estimate the Q-values of all actions, the proposed approach can adaptively select an operator that maximizes the improvement of the population according to the current state and thereby improve the algorithmic performance. The framework is embedded into four popular CMOEAs and assessed on 42 benchmark problems. The experimental results reveal that the proposed Deep Reinforcement Learning-assisted operator selection significantly improves the performance of these CMOEAs and the resulting algorithm obtains better versatility compared to nine state-of-the-art CMOEAs.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07477",
        "abstract url": "https://arxiv.org/abs/2401.07477",
        "title": "CascadeV-Det: Cascade Point Voting for 3D Object Detection",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "RGB-D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Anchor-free object detectors are highly efficient in performing point-based prediction without the need for extra post-processing of anchors. However, different from the 2D grids, the 3D points used in these detectors are often far from the ground truth center, making it challenging to accurately regress the bounding boxes. To address this issue, we propose a Cascade Voting (CascadeV) strategy that provides high-quality 3D object detection with point-based prediction. Specifically, CascadeV performs cascade detection using a novel Cascade Voting decoder that combines two new components: Instance Aware Voting (IA-Voting) and a Cascade Point Assignment (CPA) module. The IA-Voting module updates the object features of updated proposal points within the bounding box using conditional inverse distance weighting. This approach prevents features from being aggregated outside the instance and helps improve the accuracy of object detection. Additionally, since model training can suffer from a lack of proposal points with high centerness, we have developed the CPA module to narrow down the positive assignment threshold with cascade stages. This approach relaxes the dependence on proposal centerness in the early stages while ensuring an ample quantity of positives with high centerness in the later stages. Experiments show that FCAF3D with our CascadeV achieves state-of-the-art 3D object detection results with 70.4\\% mAP@0.25 and 51.6\\% mAP@0.5 on SUN RGB-D and competitive results on ScanNet. Code will be released at https://github.com/Sharpiless/CascadeV-Det",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07503",
        "abstract url": "https://arxiv.org/abs/2401.07503",
        "title": "PolMERLIN: Self-Supervised Polarimetric Complex SAR Image Despeckling with Masked Networks",
        "rating": "0",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despeckling is a crucial noise reduction task in improving the quality of synthetic aperture radar (SAR) images. Directly obtaining noise-free SAR images is a challenging task that has hindered the development of accurate despeckling algorithms. The advent of deep learning has facilitated the study of denoising models that learn from only noisy SAR images. However, existing methods deal solely with single-polarization images and cannot handle the multi-polarization images captured by modern satellites. In this work, we present an extension of the existing model for generating single-polarization SAR images to handle multi-polarization SAR images. Specifically, we propose a novel self-supervised despeckling approach called channel masking, which exploits the relationship between polarizations. Additionally, we utilize a spatial masking method that addresses pixel-to-pixel correlations to further enhance the performance of our approach. By effectively incorporating multiple polarization information, our method surpasses current state-of-the-art methods in quantitative evaluation in both synthetic and real-world scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To appear on IEEE Geoscience and Remote Sensing Letters"
    },
    {
        "paper id": "2401.07526",
        "abstract url": "https://arxiv.org/abs/2401.07526",
        "title": "Editing Arbitrary Propositions in LLMs without Subject Labels",
        "rating": "0",
        "keywords": [
            [
                "Model Editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Model (LLM) editing modifies factual information in LLMs. Locate-and-Edit (L\\&E) methods accomplish this by finding where relevant information is stored within the neural network, and editing the weights at that location. The goal of editing is to modify the response of an LLM to a proposition independently of its phrasing, while not modifying its response to other related propositions. Existing methods are limited to binary propositions, which represent straightforward binary relations between a subject and an object. Furthermore, existing methods rely on semantic subject labels, which may not be available or even be well-defined in practice. In this paper, we show that both of these issues can be effectively skirted with a simple and fast localization method called Gradient Tracing (GT). This localization method allows editing arbitrary propositions instead of just binary ones, and does so without the need for subject labels. As propositions always have a truth value, our experiments prompt an LLM as a boolean classifier, and edit its T/F response to propositions. Our method applies GT for location tracing, and then edit the model at that location using a mild variant of Rank-One Model Editing (ROME). On datasets of binary propositions derived from the CounterFact dataset, we show that our method -- without access to subject labels -- performs close to state-of-the-art L\\&E methods which has access subject labels. We then introduce a new dataset, Factual Accuracy Classification Test (FACT), which includes non-binary propositions and for which subject labels are not generally applicable, and therefore is beyond the scope of existing L\\&E methods. Nevertheless, we show that with our method editing is possible on FACT.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07572",
        "abstract url": "https://arxiv.org/abs/2401.07572",
        "title": "Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this study, we tackle the challenge of classifying the object category in point clouds, which previous works like PointCLIP struggle to address due to the inherent limitations of the CLIP architecture. Our approach leverages GPT-4 Vision (GPT-4V) to overcome these challenges by employing its advanced generative abilities, enabling a more adaptive and robust classification process. We adapt the application of GPT-4V to process complex 3D data, enabling it to achieve zero-shot recognition capabilities without altering the underlying model architecture. Our methodology also includes a systematic strategy for point cloud image visualization, mitigating domain gap and enhancing GPT-4V's efficiency. Experimental validation demonstrates our approach's superiority in diverse scenarios, setting a new benchmark in zero-shot point cloud classification.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07584",
        "abstract url": "https://arxiv.org/abs/2401.07584",
        "title": "Collaboratively Self-supervised Video Representation Learning for Action Recognition",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Considering the close connection between action recognition and human pose estimation, we design a Collaboratively Self-supervised Video Representation (CSVR) learning framework specific to action recognition by jointly considering generative pose prediction and discriminative context matching as pretext tasks. Specifically, our CSVR consists of three branches: a generative pose prediction branch, a discriminative context matching branch, and a video generating branch. Among them, the first one encodes dynamic motion feature by utilizing Conditional-GAN to predict the human poses of future frames, and the second branch extracts static context features by pulling the representations of clips and compressed key frames from the same video together while pushing apart the pairs from different videos. The third branch is designed to recover the current video frames and predict the future ones, for the purpose of collaboratively improving dynamic motion features and static context features. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the UCF101 and HMDB51 datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07781",
        "abstract url": "https://arxiv.org/abs/2401.07781",
        "title": "Towards A Better Metric for Text-to-Video Generation",
        "rating": "0",
        "keywords": [
            [
                "synthesizing",
                "Text-to-Video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generative models have demonstrated remarkable capability in synthesizing high-quality text, images, and videos. For video generation, contemporary text-to-video models exhibit impressive capabilities, crafting visually stunning videos. Nonetheless, evaluating such videos poses significant challenges. Current research predominantly employs automated metrics such as FVD, IS, and CLIP Score. However, these metrics provide an incomplete analysis, particularly in the temporal assessment of video content, thus rendering them unreliable indicators of true video quality. Furthermore, while user studies have the potential to reflect human perception accurately, they are hampered by their time-intensive and laborious nature, with outcomes that are often tainted by subjective bias. In this paper, we investigate the limitations inherent in existing metrics and introduce a novel evaluation pipeline, the Text-to-Video Score (T2VScore). This metric integrates two pivotal criteria: (1) Text-Video Alignment, which scrutinizes the fidelity of the video in representing the given text description, and (2) Video Quality, which evaluates the video's overall production caliber with a mixture of experts. Moreover, to evaluate the proposed metrics and facilitate future improvements on them, we present the TVGE dataset, collecting human judgements of 2,543 text-to-video generated videos on the two criteria. Experiments on the TVGE dataset demonstrate the superiority of the proposed T2VScore on offering a better metric for text-to-video generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://showlab.github.io/T2VScore/"
    },
    {
        "paper id": "2401.07801",
        "abstract url": "https://arxiv.org/abs/2401.07801",
        "title": "Pedestrian Detection in Low-Light Conditions: A Comprehensive Survey",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Pedestrian detection remains a critical problem in various domains, such as computer vision, surveillance, and autonomous driving. In particular, accurate and instant detection of pedestrians in low-light conditions and reduced visibility is of utmost importance for autonomous vehicles to prevent accidents and save lives. This paper aims to comprehensively survey various pedestrian detection approaches, baselines, and datasets that specifically target low-light conditions. The survey discusses the challenges faced in detecting pedestrians at night and explores state-of-the-art methodologies proposed in recent years to address this issue. These methodologies encompass a diverse range, including deep learning-based, feature-based, and hybrid approaches, which have shown promising results in enhancing pedestrian detection performance under challenging lighting conditions. Furthermore, the paper highlights current research directions in the field and identifies potential solutions that merit further investigation by researchers. By thoroughly examining pedestrian detection techniques in low-light conditions, this survey seeks to contribute to the advancement of safer and more reliable autonomous driving systems and other applications related to pedestrian safety. Accordingly, most of the current approaches in the field use deep learning-based image fusion methodologies (i.e., early, halfway, and late fusion) for accurate and reliable pedestrian detection. Moreover, the majority of the works in the field (approximately 48%) have been evaluated on the KAIST dataset, while the real-world video feeds recorded by authors have been used in less than six percent of the works.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages, 3 tables, 10 figures"
    },
    {
        "paper id": "2401.07812",
        "abstract url": "https://arxiv.org/abs/2401.07812",
        "title": "Wikidata as a seed for Web Extraction",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Wikidata has grown to a knowledge graph with an impressive size. To date, it contains more than 17 billion triples collecting information about people, places, films, stars, publications, proteins, and many more. On the other side, most of the information on the Web is not published in highly structured data repositories like Wikidata, but rather as unstructured and semi-structured content, more concretely in HTML pages containing text and tables. Finding, monitoring, and organizing this data in a knowledge graph is requiring considerable work from human editors. The volume and complexity of the data make this task difficult and time-consuming. In this work, we present a framework that is able to identify and extract new facts that are published under multiple Web domains so that they can be proposed for validation by Wikidata editors. The framework is relying on question-answering technologies. We take inspiration from ideas that are used to extract facts from textual collections and adapt them to extract facts from Web pages. For achieving this, we demonstrate that language models can be adapted to extract facts not only from textual collections but also from Web pages. By exploiting the information already contained in Wikidata the proposed framework can be trained without the need for any additional learning signals and can extract new facts for a wide range of properties and domains. Following this path, Wikidata can be used as a seed to extract facts on the Web. Our experiments show that we can achieve a mean performance of 84.07 at F1-score. Moreover, our estimations show that we can potentially extract millions of facts that can be proposed for human validation. The goal is to help editors in their daily tasks and contribute to the completion of the Wikidata knowledge graph.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07867",
        "abstract url": "https://arxiv.org/abs/2401.07867",
        "title": "Authorship Obfuscation in Multilingual Machine-Generated Text Detection",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "High-quality text generation capability of latest Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation). Machine-generated text (MGT) detection is important to cope with such threats. However, it is susceptible to authorship obfuscation (AO) methods, such as paraphrasing, which can cause MGTs to evade detection. So far, this was evaluated only in monolingual settings. Thus, the susceptibility of recently proposed multilingual detectors is still unknown. We fill this gap by comprehensively benchmarking the performance of 10 well-known AO methods, attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10 $\\times$ 37 $\\times$ 11 = 4,070 combinations). We also evaluate the effect of data augmentation on adversarial robustness using obfuscated texts. The results indicate that all tested AO methods can cause detection evasion in all tested languages, where homoglyph attacks are especially successful.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07897",
        "abstract url": "https://arxiv.org/abs/2401.07897",
        "title": "The Pitfalls of Defining Hallucination",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite impressive advances in Natural Language Generation (NLG) and Large Language Models (LLMs), researchers are still unclear about important aspects of NLG evaluation. To substantiate this claim, I examine current classifications of hallucination and omission in Data-text NLG, and I propose a logic-based synthesis of these classfications. I conclude by highlighting some remaining limitations of all current thinking about hallucination and by discussing implications for LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted for publication in Computational Linguistics on 30 Dec. 2023. (9 Pages.)"
    },
    {
        "paper id": "2401.07931",
        "abstract url": "https://arxiv.org/abs/2401.07931",
        "title": "Vertical Federated Image Segmentation",
        "rating": "0",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the popularization of AI solutions for image based problems, there has been a growing concern for both data privacy and acquisition. In a large number of cases, information is located on separate data silos and it can be difficult for a developer to consolidate all of it in a fashion that is appropriate for machine learning model development. Alongside this, a portion of these localized data regions may not have access to a labelled ground truth. This indicates that they have the capacity to reach conclusions numerically, but are not able to assign classifications amid a lack of pertinent information. Such a determination is often negligible, especially when attempting to develop image based solutions that often necessitate this capability. With this being the case, we propose an innovative vertical federated learning (VFL) model architecture that can operate under this common set of conditions. This is the first (and currently the only) implementation of a system that can work under the constraints of a VFL environment and perform image segmentation while maintaining nominal accuracies. We achieved this by utilizing an FCN that boasts the ability to operate on federates that lack labelled data and privately share the respective weights with a central server, that of which hosts the necessary features for classification. Tests were conducted on the CamVid dataset in order to determine the impact of heavy feature compression required for the transfer of information between federates, as well as to reach nominal conclusions about the overall performance metrics when working under such constraints.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2401.07942",
        "abstract url": "https://arxiv.org/abs/2401.07942",
        "title": "Transformer-based Video Saliency Prediction with High Temporal Dimension Decoding",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, finding an effective and efficient strategy for exploiting spatial and temporal information has been a hot research topic in video saliency prediction (VSP). With the emergence of spatio-temporal transformers, the weakness of the prior strategies, e.g., 3D convolutional networks and LSTM-based networks, for capturing long-range dependencies has been effectively compensated. While VSP has drawn benefits from spatio-temporal transformers, finding the most effective way for aggregating temporal features is still challenging. To address this concern, we propose a transformer-based video saliency prediction approach with high temporal dimension decoding network (THTD-Net). This strategy accounts for the lack of complex hierarchical interactions between features that are extracted from the transformer-based spatio-temporal encoder: in particular, it does not require multiple decoders and aims at gradually reducing temporal features' dimensions in the decoder. This decoder-based architecture yields comparable performance to multi-branch and over-complicated models on common benchmarks such as DHF1K, UCF-sports and Hollywood-2.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 2 figures, 3 tables"
    },
    {
        "paper id": "2401.07991",
        "abstract url": "https://arxiv.org/abs/2401.07991",
        "title": "Robustness Against Adversarial Attacks via Learning Confined Adversarial Polytopes",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) could be deceived by generating human-imperceptible perturbations of clean samples. Therefore, enhancing the robustness of DNNs against adversarial attacks is a crucial task. In this paper, we aim to train robust DNNs by limiting the set of outputs reachable via a norm-bounded perturbation added to a clean sample. We refer to this set as adversarial polytope, and each clean sample has a respective adversarial polytope. Indeed, if the respective polytopes for all the samples are compact such that they do not intersect the decision boundaries of the DNN, then the DNN is robust against adversarial samples. Hence, the inner-working of our algorithm is based on learning \\textbf{c}onfined \\textbf{a}dversarial \\textbf{p}olytopes (CAP). By conducting a thorough set of experiments, we demonstrate the effectiveness of CAP over existing adversarial robustness methods in improving the robustness of models against state-of-the-art attacks including AutoAttack.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "The paper has been accepted in ICASSP 2024"
    },
    {
        "paper id": "2401.08053",
        "abstract url": "https://arxiv.org/abs/2401.08053",
        "title": "SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate representation in media is known to improve the well-being of the people who consume it. Generative image models trained on large web-crawled datasets such as LAION are known to produce images with harmful stereotypes and misrepresentations of cultures. We improve inclusive representation in generated images by (1) engaging with communities to collect a culturally representative dataset that we call the Cross-Cultural Understanding Benchmark (CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method that leverages the model's known biases to self-improve. SCoFT is designed to prevent overfitting on small datasets, encode only high-level information from the data, and shift the generated distribution away from misrepresentations encoded in a pretrained model. Our user study conducted on 51 participants from 5 different countries based on their self-selected national cultural affiliation shows that fine-tuning on CCUB consistently generates images with higher cultural relevance and fewer stereotypes when compared to the Stable Diffusion baseline, which is further improved with our SCoFT technique.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08068",
        "abstract url": "https://arxiv.org/abs/2401.08068",
        "title": "Representation Learning on Event Stream via an Elastic Net-incorporated Tensor Network",
        "rating": "0",
        "keywords": [
            [
                "Event cameras"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Event cameras are neuromorphic sensors that capture asynchronous and sparse event stream when per-pixel brightness changes. The state-of-the-art processing methods for event signals typically aggregate events into a frame or a grid. However, events are dense in time, these works are limited to local information of events due to the stacking. In this paper, we present a novel spatiotemporal representation learning method which can capture the global correlations of all events in the event stream simultaneously by tensor decomposition. In addition, with the events are sparse in space, we propose an Elastic Net-incorporated tensor network (ENTN) model to obtain more spatial and temporal details about event stream. Empirically, the results indicate that our method can represent the spatiotemporal correlation of events with high quality, and can achieve effective results in applications like filtering noise compared with the state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages, 3 figure"
    },
    {
        "paper id": "2401.08079",
        "abstract url": "https://arxiv.org/abs/2401.08079",
        "title": "Adversarial Masking Contrastive Learning for vein recognition",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vein recognition has received increasing attention due to its high security and privacy. Recently, deep neural networks such as Convolutional neural networks (CNN) and Transformers have been introduced for vein recognition and achieved state-of-the-art performance. Despite the recent advances, however, existing solutions for finger-vein feature extraction are still not optimal due to scarce training image samples. To overcome this problem, in this paper, we propose an adversarial masking contrastive learning (AMCL) approach, that generates challenging samples to train a more robust contrastive learning model for the downstream palm-vein recognition task, by alternatively optimizing the encoder in the contrastive learning model and a set of latent variables. First, a huge number of masks are generated to train a robust generative adversarial network (GAN). The trained generator transforms a latent variable from the latent variable space into a mask space. Then, we combine the trained generator with a contrastive learning model to obtain our AMCL, where the generator produces challenging masking images to increase the contrastive loss and the contrastive learning model is trained based on the harder images to learn a more robust feature representation. After training, the trained encoder in the contrastive learning model is combined with a classification layer to build a classifier, which is further fine-tuned on labeled training data for vein recognition. The experimental results on three databases demonstrate that our approach outperforms existing contrastive learning approaches in terms of improving identification accuracy of vein classifiers and achieves state-of-the-art recognition results.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08086",
        "abstract url": "https://arxiv.org/abs/2401.08086",
        "title": "Spatial-Semantic Collaborative Cropping for User Generated Content",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A large amount of User Generated Content (UGC) is uploaded to the Internet daily and displayed to people world-widely through the client side (e.g., mobile and PC). This requires the cropping algorithms to produce the aesthetic thumbnail within a specific aspect ratio on different devices. However, existing image cropping works mainly focus on landmark or landscape images, which fail to model the relations among the multi-objects with the complex background in UGC. Besides, previous methods merely consider the aesthetics of the cropped images while ignoring the content integrity, which is crucial for UGC cropping. In this paper, we propose a Spatial-Semantic Collaborative cropping network (S2CNet) for arbitrary user generated content accompanied by a new cropping benchmark. Specifically, we first mine the visual genes of the potential objects. Then, the suggested adaptive attention graph recasts this task as a procedure of information association over visual nodes. The underlying spatial and semantic relations are ultimately centralized to the crop candidate through differentiable message passing, which helps our network efficiently to preserve both the aesthetics and the content integrity. Extensive experiments on the proposed UGCrop5K and other public datasets demonstrate the superiority of our approach over state-of-the-art counterparts. Our project is available at https://github.com/suyukun666/S2CNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08089",
        "abstract url": "https://arxiv.org/abs/2401.08089",
        "title": "A Study on Training and Developing Large Language Models for Behavior Tree Generation",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks. The conventional manual BT generation method is inefficient and heavily reliant on domain expertise. On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability. In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs. The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification. Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance. In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy. Additionally, we explore a range of agent design and development schemes with LLM as the central element. We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08099",
        "abstract url": "https://arxiv.org/abs/2401.08099",
        "title": "Inpainting Normal Maps for Lightstage data",
        "rating": "0",
        "keywords": [
            [
                "GAN",
                "synthesize",
                "Inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study introduces a novel method for inpainting normal maps using a generative adversarial network (GAN). Normal maps, often derived from a lightstage, are crucial in performance capture but can have obscured areas due to movement (e.g., by arms, hair, or props). Inpainting fills these missing areas with plausible data. Our approach extends previous general image inpainting techniques, employing a bow tie-like generator network and a discriminator network, with alternating training phases. The generator aims to synthesize images aligning with the ground truth and deceive the discriminator, which differentiates between real and processed images. Periodically, the discriminator undergoes retraining to enhance its ability to identify processed images. Importantly, our method adapts to the unique characteristics of normal map data, necessitating modifications to the loss function. We utilize a cosine loss instead of mean squared error loss for generator training. Limited training data availability, even with synthetic datasets, demands significant augmentation, considering the specific nature of the input data. This includes appropriate image flipping and in-plane rotations to accurately alter normal vectors. Throughout training, we monitored key metrics such as average loss, Structural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio (PSNR) for the generator, along with average loss and accuracy for the discriminator. Our findings suggest that the proposed model effectively generates high-quality, realistic inpainted normal maps, suitable for performance capture applications. These results establish a foundation for future research, potentially involving more advanced networks and comparisons with inpainting of source images used to create the normal maps.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 4 figures, CGVC Conference, The Eurographics Association"
    },
    {
        "paper id": "2401.08102",
        "abstract url": "https://arxiv.org/abs/2401.08102",
        "title": "DIFFRENT: A Diffusion Model for Recording Environment Transfer of Speech",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Properly setting up recording conditions, including microphone type and placement, room acoustics, and ambient noise, is essential to obtaining the desired acoustic characteristics of speech. In this paper, we propose Diff-R-EN-T, a Diffusion model for Recording ENvironment Transfer which transforms the input speech to have the recording conditions of a reference speech while preserving the speech content. Our model comprises the content enhancer, the recording environment encoder, and the diffusion decoder which generates the target mel-spectrogram by utilizing both enhancer and encoder as input conditions. We evaluate DiffRENT in the speech enhancement and acoustic matching scenarios. The results show that DiffRENT generalizes well to unseen environments and new speakers. Also, the proposed model achieves superior performances in objective and subjective evaluation. Sound examples of our proposed model are available online.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "4 pages, 2 figures"
    },
    {
        "paper id": "2401.08717",
        "abstract url": "https://arxiv.org/abs/2401.08717",
        "title": "Robust DOA estimation using deep acoustic imaging",
        "rating": "0",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Direction of arrival estimation (DoAE) aims at tracking a sound in azimuth and elevation. Recent advancements include data-driven models with inputs derived from ambisonics intensity vectors or correlations between channels in a microphone array. A spherical intensity map (SIM), or acoustic image, is an alternative input representation that remains underexplored. SIMs benefit from high-resolution microphone arrays, yet most DoAE datasets use low-resolution ones. Therefore, we first propose a super-resolution method to upsample low-resolution microphones. Next, we benchmark DoAE models that use SIMs as input. We arrive to a model that uses SIMs for DoAE estimation and outperforms a baseline and a state-of-the-art model. Our study highlights the relevance of acoustic imaging for DoAE tasks.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07516",
        "abstract url": "https://arxiv.org/abs/2401.07516",
        "title": "Temporal Link Prediction Using Graph Embedding Dynamics",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graphs are a powerful representation tool in machine learning applications, with link prediction being a key task in graph learning. Temporal link prediction in dynamic networks is of particular interest due to its potential for solving complex scientific and real-world problems. Traditional approaches to temporal link prediction have focused on finding the aggregation of dynamics of the network as a unified output. In this study, we propose a novel perspective on temporal link prediction by defining nodes as Newtonian objects and incorporating the concept of velocity to predict network dynamics. By computing more specific dynamics of each node, rather than overall dynamics, we improve both accuracy and explainability in predicting future connections. We demonstrate the effectiveness of our approach using two datasets, including 17 years of co-authorship data from PubMed. Experimental results show that our temporal graph embedding dynamics approach improves downstream classification models' ability to predict future collaboration efficacy in co-authorship networks by 17.34% (AUROC improvement relative to the baseline model). Furthermore, our approach offers an interpretable layer over traditional approaches to address the temporal link prediction problem.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07525",
        "abstract url": "https://arxiv.org/abs/2401.07525",
        "title": "TAROT: A Hierarchical Framework with Multitask Co-Pretraining on Semi-Structured Data towards Effective Person-Job Fit",
        "rating": "-0.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Person-job fit is an essential part of online recruitment platforms in serving various downstream applications like Job Search and Candidate Recommendation. Recently, pretrained large language models have further enhanced the effectiveness by leveraging richer textual information in user profiles and job descriptions apart from user behavior features and job metadata. However, the general domain-oriented design struggles to capture the unique structural information within user profiles and job descriptions, leading to a loss of latent semantic correlations. We propose TAROT, a hierarchical multitask co-pretraining framework, to better utilize structural and semantic information for informative text embeddings. TAROT targets semi-structured text in profiles and jobs, and it is co-pretained with multi-grained pretraining tasks to constrain the acquired semantic information at each level. Experiments on a real-world LinkedIn dataset show significant performance improvements, proving its effectiveness in person-job fit tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ICASSP 2024 camera ready. 5 pages, 1 figure, 3 tables"
    },
    {
        "paper id": "2401.07553",
        "abstract url": "https://arxiv.org/abs/2401.07553",
        "title": "Safe Reinforcement Learning with Free-form Natural Language Constraints and Pre-Trained Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Safe reinforcement learning (RL) agents accomplish given tasks while adhering to specific constraints. Employing constraints expressed via easily-understandable human language offers considerable potential for real-world applications due to its accessibility and non-reliance on domain expertise. Previous safe RL methods with natural language constraints typically adopt a recurrent neural network, which leads to limited capabilities when dealing with various forms of human language input. Furthermore, these methods often require a ground-truth cost function, necessitating domain expertise for the conversion of language constraints into a well-defined cost function that determines constraint violation. To address these issues, we proposes to use pre-trained language models (LM) to facilitate RL agents' comprehension of natural language constraints and allow them to infer costs for safe policy learning. Through the use of pre-trained LMs and the elimination of the need for a ground-truth cost, our method enhances safe policy learning under a diverse set of human-derived free-form natural language constraints. Experiments on grid-world navigation and robot control show that the proposed method can achieve strong performance while adhering to given constraints. The usage of pre-trained LMs allows our method to comprehend complicated constraints and learn safe policies without the need for ground-truth cost at any stage of training or evaluation. Extensive ablation studies are conducted to demonstrate the efficacy of each part of our method.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07571",
        "abstract url": "https://arxiv.org/abs/2401.07571",
        "title": "A Bi-Pyramid Multimodal Fusion Method for the Diagnosis of Bipolar Disorders",
        "rating": "-0.5",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "fMRI",
                "clinical"
            ],
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Previous research on the diagnosis of Bipolar disorder has mainly focused on resting-state functional magnetic resonance imaging. However, their accuracy can not meet the requirements of clinical diagnosis. Efficient multimodal fusion strategies have great potential for applications in multimodal data and can further improve the performance of medical diagnosis models. In this work, we utilize both sMRI and fMRI data and propose a novel multimodal diagnosis model for bipolar disorder. The proposed Patch Pyramid Feature Extraction Module extracts sMRI features, and the spatio-temporal pyramid structure extracts the fMRI features. Finally, they are fused by a fusion module to output diagnosis results with a classifier. Extensive experiments show that our proposed method outperforms others in balanced accuracy from 0.657 to 0.732 on the OpenfMRI dataset, and achieves the state of the art.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE ICASSP 2024"
    },
    {
        "paper id": "2401.07578",
        "abstract url": "https://arxiv.org/abs/2401.07578",
        "title": "Confounded Budgeted Causal Bandits",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of learning 'good' interventions in a stochastic environment modeled by its underlying causal graph. Good interventions refer to interventions that maximize rewards. Specifically, we consider the setting of a pre-specified budget constraint, where interventions can have non-uniform costs. We show that this problem can be formulated as maximizing the expected reward for a stochastic multi-armed bandit with side information. We propose an algorithm to minimize the cumulative regret in general causal graphs. This algorithm trades off observations and interventions based on their costs to achieve the optimal reward. This algorithm generalizes the state-of-the-art methods by allowing non-uniform costs and hidden confounders in the causal graph. Furthermore, we develop an algorithm to minimize the simple regret in the budgeted setting with non-uniform costs and also general causal graphs. We provide theoretical guarantees, including both upper and lower bounds, as well as empirical evaluations of our algorithms. Our empirical results showcase that our algorithms outperform the state of the art.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07656",
        "abstract url": "https://arxiv.org/abs/2401.07656",
        "title": "Learning Explainable and Better Performing Representations of POMDP Strategies",
        "rating": "-0.5",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Strategies for partially observable Markov decision processes (POMDP) typically require memory. One way to represent this memory is via automata. We present a method to learn an automaton representation of a strategy using a modification of the L*-algorithm. Compared to the tabular representation of a strategy, the resulting automaton is dramatically smaller and thus also more explainable. Moreover, in the learning process, our heuristics may even improve the strategy's performance. In contrast to approaches that synthesize an automaton directly from the POMDP thereby solving it, our approach is incomparably more scalable.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Technical report for the submission to TACAS 24"
    },
    {
        "paper id": "2401.07674",
        "abstract url": "https://arxiv.org/abs/2401.07674",
        "title": "Performance Evaluation of Kubernetes Networking Approaches across Constraint Edge Environments",
        "rating": "-0.5",
        "keywords": [
            [
                "Workshop"
            ]
        ],
        "abstract": "Kubernetes (K8s) serves as a mature orchestration system for the seamless deployment and management of containerized applications spanning across cloud and edge environments. Since high-performance connectivity and minimal resource utilization become critical factors as we approach the edge, evaluating the performance of K8s networking in this context is essential. This paper contributes to this effort, by conducting a qualitative and quantitative performance evaluation of diverse Container Network Interface (CNI) plugins within different K8s environments, incorporating lightweight implementations designed for the Edge. Our experimental assessment was conducted in two distinct (intra- and inter-host) scenarios, revealing interesting insights for both researchers and practitioners. For example, the deployment of plugins across lightweight distributions does not necessarily lead to resource utilization improvements, e.g., in terms of CPU/memory or throughput.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted: Proc. IEEE Int. Conf. Comput. Commun. ICCN Workshops (INFOCOM ICCN WKSHPS), Vancouver, Canada, 2024"
    },
    {
        "paper id": "2401.07756",
        "abstract url": "https://arxiv.org/abs/2401.07756",
        "title": "Joint Probability Selection and Power Allocation for Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we study the performance of federated learning over wireless networks, where devices with a limited energy budget train a machine learning model. The federated learning performance depends on the selection of the clients participating in the learning at each round. Most existing studies suggest deterministic approaches for the client selection, resulting in challenging optimization problems that are usually solved using heuristics, and therefore without guarantees on the quality of the final solution. We formulate a new probabilistic approach to jointly select clients and allocate power optimally so that the expected number of participating clients is maximized. To solve the problem, a new alternating algorithm is proposed, where at each step, the closed-form solutions for user selection probabilities and power allocations are obtained. Our numerical results show that the proposed approach achieves a significant performance in terms of energy consumption, completion time and accuracy as compared to the studied benchmarks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08083",
        "abstract url": "https://arxiv.org/abs/2401.08083",
        "title": "UV-SAM: Adapting Segment Anything Model for Urban Village Identification",
        "rating": "-0.5",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Urban villages, defined as informal residential areas in or around urban centers, are characterized by inadequate infrastructures and poor living conditions, closely related to the Sustainable Development Goals (SDGs) on poverty, adequate housing, and sustainable cities. Traditionally, governments heavily depend on field survey methods to monitor the urban villages, which however are time-consuming, labor-intensive, and possibly delayed. Thanks to widely available and timely updated satellite images, recent studies develop computer vision techniques to detect urban villages efficiently. However, existing studies either focus on simple urban village image classification or fail to provide accurate boundary information. To accurately identify urban village boundaries from satellite images, we harness the power of the vision foundation model and adapt the Segment Anything Model (SAM) to urban village segmentation, named UV-SAM. Specifically, UV-SAM first leverages a small-sized semantic segmentation model to produce mixed prompts for urban villages, including mask, bounding box, and image representations, which are then fed into SAM for fine-grained boundary identification. Extensive experimental results on two datasets in China demonstrate that UV-SAM outperforms existing baselines, and identification results over multiple years show that both the number and area of urban villages are decreasing over time, providing deeper insights into the development trends of urban villages and sheds light on the vision foundation models for sustainable cities. The dataset and codes of this study are available at https://github.com/tsinghua-fib-lab/UV-SAM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.08092",
        "abstract url": "https://arxiv.org/abs/2401.08092",
        "title": "A Survey of Resource-efficient LLM and Multimodal Foundation Models",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large foundation models, including large language models (LLMs), vision transformers (ViTs), diffusion, and LLM-based multimodal models, are revolutionizing the entire machine learning lifecycle, from training to deployment. However, the substantial advancements in versatility and performance these models offer come at a significant cost in terms of hardware resources. To support the growth of these large models in a scalable and environmentally sustainable way, there has been a considerable focus on developing resource-efficient strategies. This survey delves into the critical importance of such research, examining both algorithmic and systemic aspects. It offers a comprehensive analysis and valuable insights gleaned from existing literature, encompassing a broad array of topics from cutting-edge model architectures and training/serving algorithms to practical system designs and implementations. The goal of this survey is to provide an overarching understanding of how current approaches are tackling the resource challenges posed by large foundation models and to potentially inspire future breakthroughs in this field.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07496",
        "abstract url": "https://arxiv.org/abs/2401.07496",
        "title": "Low-Rank Gradient Compression with Error Feedback for MIMO Wireless Federated Learning",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "This paper presents a novel approach to enhance the communication efficiency of federated learning (FL) in multiple input and multiple output (MIMO) wireless systems. The proposed method centers on a low-rank matrix factorization strategy for local gradient compression based on alternating least squares, along with over-the-air computation and error feedback. The proposed protocol, termed over-the-air low-rank compression (Ota-LC), is demonstrated to have lower computation cost and lower communication overhead as compared to existing benchmarks while guaranteeing the same inference performance. As an example, when targeting a test accuracy of 80% on the Cifar-10 dataset, Ota-LC achieves a reduction in total communication costs of at least 30% when contrasted with benchmark schemes, while also reducing the computational complexity order by a factor equal to the sum of the dimension of the gradients.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "5 pages, 3 figures, 27 references, submitted"
    },
    {
        "paper id": "2401.07500",
        "abstract url": "https://arxiv.org/abs/2401.07500",
        "title": "Harnessing Deep Learning and Satellite Imagery for Post-Buyout Land Cover Mapping",
        "rating": "-1",
        "keywords": [
            [
                "Satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Environmental disasters such as floods, hurricanes, and wildfires have increasingly threatened communities worldwide, prompting various mitigation strategies. Among these, property buyouts have emerged as a prominent approach to reducing vulnerability to future disasters. This strategy involves governments purchasing at-risk properties from willing sellers and converting the land into open space, ostensibly reducing future disaster risk and impact. However, the aftermath of these buyouts, particularly concerning land-use patterns and community impacts, remains under-explored. This research aims to fill this gap by employing innovative techniques like satellite imagery analysis and deep learning to study these patterns. To achieve this goal, we employed FEMA's Hazard Mitigation Grant Program (HMGP) buyout dataset, encompassing over 41,004 addresses of these buyout properties from 1989 to 2017. Leveraging Google's Maps Static API, we gathered 40,053 satellite images corresponding to these buyout lands. Subsequently, we implemented five cutting-edge machine learning models to evaluate their performance in classifying land cover types. Notably, this task involved multi-class classification, and our model achieved an outstanding ROC-AUC score of 98.86%",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07510",
        "abstract url": "https://arxiv.org/abs/2401.07510",
        "title": "Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering",
        "rating": "-1",
        "keywords": [
            [
                "Biology",
                "medical",
                "healthcare",
                "diagnosis"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "ChatGPT explores a strategic blueprint of question answering (QA) in delivering medical diagnosis, treatment recommendations, and other healthcare support. This is achieved through the increasing incorporation of medical domain data via natural language processing (NLP) and multimodal paradigms. By transitioning the distribution of text, images, videos, and other modalities from the general domain to the medical domain, these techniques have expedited the progress of medical domain question answering (MDQA). They bridge the gap between human natural language and sophisticated medical domain knowledge or expert manual annotations, handling large-scale, diverse, unbalanced, or even unlabeled data analysis scenarios in medical contexts. Central to our focus is the utilizing of language models and multimodal paradigms for medical question answering, aiming to guide the research community in selecting appropriate mechanisms for their specific medical research requirements. Specialized tasks such as unimodal-related question answering, reading comprehension, reasoning, diagnosis, relation extraction, probability modeling, and others, as well as multimodal-related tasks like vision question answering, image caption, cross-modal retrieval, report summarization, and generation, are discussed in detail. Each section delves into the intricate specifics of the respective method under consideration. This paper highlights the structures and advancements of medical domain explorations against general domain methods, emphasizing their applications across different tasks and datasets. It also outlines current challenges and opportunities for future medical domain research, paving the way for continued innovation and application in this rapidly evolving field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "50 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2401.07518",
        "abstract url": "https://arxiv.org/abs/2401.07518",
        "title": "Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Natural Language Processing (NLP) aims to analyze text or speech via techniques in the computer science field. It serves the applications in domains of healthcare, commerce, education and so on. Particularly, NLP has been widely applied to the education domain and its applications have enormous potential to help teaching and learning. In this survey, we review recent advances in NLP with the focus on solving problems relevant to the education domain. In detail, we begin with introducing the related background and the real-world scenarios in education where NLP techniques could contribute. Then, we present a taxonomy of NLP in the education domain and highlight typical NLP applications including question answering, question construction, automated assessment, and error correction. Next, we illustrate the task definition, challenges, and corresponding cutting-edge techniques based on the above taxonomy. In particular, LLM-involved methods are included for discussion due to the wide usage of LLMs in diverse NLP applications. After that, we showcase some off-the-shelf demonstrations in this domain. At last, we conclude with six promising directions for future research, including more datasets in education domain, controllable usage of LLMs, intervention of difficulty-level control, interpretable educational NLP, methods with adaptive learning, and integrated systems for education. We organize all relevant datasets and papers in the open-available Github Link for better review~\\url{https://github.com/LiXinyuan1015/NLP-for-Education}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07527",
        "abstract url": "https://arxiv.org/abs/2401.07527",
        "title": "One for All: Toward Unified Foundation Models for Earth Vision",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Foundation models characterized by extensive parameters and trained on large-scale datasets have demonstrated remarkable efficacy across various downstream tasks for remote sensing data. Current remote sensing foundation models typically specialize in a single modality or a specific spatial resolution range, limiting their versatility for downstream datasets. While there have been attempts to develop multi-modal remote sensing foundation models, they typically employ separate vision encoders for each modality or spatial resolution, necessitating a switch in backbones contingent upon the input data. To address this issue, we introduce a simple yet effective method, termed OFA-Net (One-For-All Network): employing a single, shared Transformer backbone for multiple data modalities with different spatial resolutions. Using the masked image modeling mechanism, we pre-train a single Transformer backbone on a curated multi-modal dataset with this simple design. Then the backbone model can be used in different downstream tasks, thus forging a path towards a unified foundation backbone model in Earth vision. The proposed method is evaluated on 12 distinct downstream tasks and demonstrates promising performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2401.07542",
        "abstract url": "https://arxiv.org/abs/2401.07542",
        "title": "Combining Image- and Geometric-based Deep Learning for Shape Regression: A Comparison to Pixel-level Methods for Segmentation in Chest X-Ray",
        "rating": "-1",
        "keywords": [
            [
                "X-Ray"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "When solving a segmentation task, shaped-base methods can be beneficial compared to pixelwise classification due to geometric understanding of the target object as shape, preventing the generation of anatomical implausible predictions in particular for corrupted data. In this work, we propose a novel hybrid method that combines a lightweight CNN backbone with a geometric neural network (Point Transformer) for shape regression. Using the same CNN encoder, the Point Transformer reaches segmentation quality on per with current state-of-the-art convolutional decoders ($4\\pm1.9$ vs $3.9\\pm2.9$ error in mm and $85\\pm13$ vs $88\\pm10$ Dice), but crucially, is more stable w.r.t image distortion, starting to outperform them at a corruption level of 30%. Furthermore, we include the nnU-Net as an upper baseline, which has $3.7\\times$ more trainable parameters than our proposed method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to German Conference on Medical Image Computing 2024"
    },
    {
        "paper id": "2401.07565",
        "abstract url": "https://arxiv.org/abs/2401.07565",
        "title": "Call graph discovery in binary programs from unknown instruction set architectures",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This study addresses the challenge of reverse engineering binaries from unknown instruction set architectures, a complex task with potential implications for software maintenance and cyber-security. We focus on the tasks of detecting candidate call and return opcodes for automatic extraction of call graphs in order to simplify the reverse engineering process. Empirical testing on a small dataset of binary files from different architectures demonstrates that the approach can accurately detect specific opcodes under conditions of noisy data. The method lays the groundwork for a valuable tool for reverse engineering where the reverse engineer has minimal a priori knowledge of the underlying instruction set architecture.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07577",
        "abstract url": "https://arxiv.org/abs/2401.07577",
        "title": "A greedy heuristic for graph burning",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Given a graph $G$, the optimization version of the graph burning problem seeks for a sequence of vertices, $(u_1,u_2,...,u_k) \\in V(G)^k$, with minimum $k$ and such that every $v \\in V(G)$ has distance at most $k-i$ to some vertex $u_i$. The length $k$ of the optimal solution is known as the burning number and is denoted by $b(G)$, an invariant that helps quantify the graph's vulnerability to contagion. This paper explores the advantages and limitations of an $\\mathcal{O}(mn + kn^2)$ deterministic greedy heuristic for this problem, where $n$ is the graph's order, $m$ is the graph's size, and $k$ is a guess on $b(G)$. This heuristic is based on the relationship between the graph burning problem and the clustered maximum coverage problem, and despite having limitations on paths and cycles, it found most of the optimal and best-known solutions of benchmark and synthetic graphs with up to 102400 vertices.",
        "subjects": [
            "cs.DM"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2401.07582",
        "abstract url": "https://arxiv.org/abs/2401.07582",
        "title": "Geo-locating Road Objects using Inverse Haversine Formula with NVIDIA Driveworks",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving"
            ]
        ],
        "abstract": "Geolocation is integral to the seamless functioning of autonomous vehicles and advanced traffic monitoring infrastructures. This paper introduces a methodology to geolocate road objects using a monocular camera, leveraging the NVIDIA DriveWorks platform. We use the Centimeter Positioning Service (CPOS) and the inverse Haversine formula to geo-locate road objects accurately. The real-time algorithm processing capability of the NVIDIA DriveWorks platform enables instantaneous object recognition and spatial localization for Advanced Driver Assistance Systems (ADAS) and autonomous driving platforms. We present a measurement pipeline suitable for autonomous driving (AD) platforms and provide detailed guidelines for calibrating cameras using NVIDIA DriveWorks. Experiments were carried out to validate the accuracy of the proposed method for geolocating targets in both controlled and dynamic settings. We show that our approach can locate targets with less than 1m error when the AD platform is stationary and less than 4m error at higher speeds (i.e. up to 60km/h) within a 15m radius.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07611",
        "abstract url": "https://arxiv.org/abs/2401.07611",
        "title": "A Practical Near Optimal Deployment of Service Function Chains in Edge-to-Cloud Networks",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Mobile edge computing offers a myriad of opportunities to innovate and introduce novel applications, thereby enhancing user experiences considerably. A critical issue extensively investigated in this domain is efficient deployment of Service Function Chains (SFCs) across the physical network, spanning from the edge to the cloud. This problem is known to be NP-hard. As a result of its practical importance, there is significant interest in the development of high-quality sub-optimal solutions. In this paper, we consider this problem and propose a novel near-optimal heuristic that is extremely efficient and scalable. We compare our solution to the state-of-the-art heuristic and to the theoretical optimum. In our large-scale evaluations, we use realistic topologies which were previously reported in the literature. We demonstrate that the execution time offered by our solution grows slowly as the number of Virtual Network Function (VNF) forwarding graph embedding requests grows, and it handles one million requests in slightly more than 20 seconds for 100 nodes and 150 edges physical topology.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted to IEEE INFOCOM 2024"
    },
    {
        "paper id": "2401.07612",
        "abstract url": "https://arxiv.org/abs/2401.07612",
        "title": "Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Applications",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "The critical challenge of prompt injection attacks in Large Language Models (LLMs) integrated applications, a growing concern in the Artificial Intelligence (AI) field. Such attacks, which manipulate LLMs through natural language inputs, pose a significant threat to the security of these applications. Traditional defense strategies, including output and input filtering, as well as delimiter use, have proven inadequate. This paper introduces the 'Signed-Prompt' method as a novel solution. The study involves signing sensitive instructions within command segments by authorized users, enabling the LLM to discern trusted instruction sources. The paper presents a comprehensive analysis of prompt injection attack patterns, followed by a detailed explanation of the Signed-Prompt concept, including its basic architecture and implementation through both prompt engineering and fine-tuning of LLMs. Experiments demonstrate the effectiveness of the Signed-Prompt method, showing substantial resistance to various types of prompt injection attacks, thus validating its potential as a robust defense strategy in AI security.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07636",
        "abstract url": "https://arxiv.org/abs/2401.07636",
        "title": "Isomorphism Testing of Rooted Trees in Linear Time",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The AHU-algorithm solves the computationally difficult graph isomorphism problem for rooted trees, and does so with a linear time complexity. Although the AHU-algorithm has remained state of the art for almost 50 years, it has been criticized for being unclearly presented, and no complete proof of correctness has been given. In this text, that gap is filled: we formalize the algorithm's main point of assigning and compressing labels to provide a characterization of isomorphic rooted trees, and then proceed with proving the correctness and optimal runtime of the AHU-algorithm.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2401.07654",
        "abstract url": "https://arxiv.org/abs/2401.07654",
        "title": "Foundation Models for Biomedical Image Segmentation: A Survey",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical",
                "medical",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in biomedical image analysis have been significantly driven by the Segment Anything Model (SAM). This transformative technology, originally developed for general-purpose computer vision, has found rapid application in medical image processing. Within the last year, marked by over 100 publications, SAM has demonstrated its prowess in zero-shot learning adaptations for medical imaging. The fundamental premise of SAM lies in its capability to segment or identify objects in images without prior knowledge of the object type or imaging modality. This approach aligns well with tasks achievable by the human visual system, though its application in non-biological vision contexts remains more theoretically challenging. A notable feature of SAM is its ability to adjust segmentation according to a specified resolution scale or area of interest, akin to semantic priming. This adaptability has spurred a wave of creativity and innovation in applying SAM to medical imaging. Our review focuses on the period from April 1, 2023, to September 30, 2023, a critical first six months post-initial publication. We examine the adaptations and integrations of SAM necessary to address longstanding clinical challenges, particularly in the context of 33 open datasets covered in our analysis. While SAM approaches or achieves state-of-the-art performance in numerous applications, it falls short in certain areas, such as segmentation of the carotid artery, adrenal glands, optic nerve, and mandible bone. Our survey delves into the innovative techniques where SAM's foundational approach excels and explores the core concepts in translating and applying these models effectively in diverse medical imaging scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "22 pages, 4 figures, 7 tables"
    },
    {
        "paper id": "2401.07657",
        "abstract url": "https://arxiv.org/abs/2401.07657",
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "rating": "-1",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ],
            [
                "workshop",
                "AAAI"
            ]
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)"
    },
    {
        "paper id": "2401.07702",
        "abstract url": "https://arxiv.org/abs/2401.07702",
        "title": "Prompting open-source and commercial language models for grammatical error correction of English learner text",
        "rating": "-1",
        "keywords": [
            [
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Thanks to recent advances in generative AI, we are able to prompt large language models (LLMs) to produce texts which are fluent and grammatical. In addition, it has been shown that we can elicit attempts at grammatical error correction (GEC) from LLMs when prompted with ungrammatical input sentences. We evaluate how well LLMs can perform at GEC by measuring their performance on established benchmark datasets. We go beyond previous studies, which only examined GPT* models on a selection of English GEC datasets, by evaluating seven open-source and three commercial LLMs on four established GEC benchmarks. We investigate model performance and report results against individual error types. Our results indicate that LLMs do not always outperform supervised English GEC models except in specific contexts -- namely commercial LLMs on benchmarks annotated with fluency corrections as opposed to minimal edits. We find that several open-source models outperform commercial ones on minimal edit benchmarks, and that in some settings zero-shot prompting is just as competitive as few-shot prompting.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages with appendices"
    },
    {
        "paper id": "2401.07727",
        "abstract url": "https://arxiv.org/abs/2401.07727",
        "title": "HexaGen3D: StableDiffusion is just one step away from Fast and Diverse Text-to-3D Generation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the latest remarkable advances in generative modeling, efficient generation of high-quality 3D assets from textual prompts remains a difficult task. A key challenge lies in data scarcity: the most extensive 3D datasets encompass merely millions of assets, while their 2D counterparts contain billions of text-image pairs. To address this, we propose a novel approach which harnesses the power of large, pretrained 2D diffusion models. More specifically, our approach, HexaGen3D, fine-tunes a pretrained text-to-image model to jointly predict 6 orthographic projections and the corresponding latent triplane. We then decode these latents to generate a textured mesh. HexaGen3D does not require per-sample optimization, and can infer high-quality and diverse objects from textual prompts in 7 seconds, offering significantly better quality-to-latency trade-offs when comparing to existing approaches. Furthermore, HexaGen3D demonstrates strong generalization to new objects or compositions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2401.07745",
        "abstract url": "https://arxiv.org/abs/2401.07745",
        "title": "MaskClustering: View Consensus based Mask Graph Clustering for Open-Vocabulary 3D Instance Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Open-vocabulary 3D instance segmentation is cutting-edge for its ability to segment 3D instances without predefined categories. However, progress in 3D lags behind its 2D counterpart due to limited annotated 3D data. To address this, recent works first generate 2D open-vocabulary masks through 2D models and then merge them into 3D instances based on metrics calculated between two neighboring frames. In contrast to these local metrics, we propose a novel metric, view consensus rate, to enhance the utilization of multi-view observations. The key insight is that two 2D masks should be deemed part of the same 3D instance if a significant number of other 2D masks from different views contain both these two masks. Using this metric as edge weight, we construct a global mask graph where each mask is a node. Through iterative clustering of masks showing high view consensus, we generate a series of clusters, each representing a distinct 3D instance. Notably, our model is training-free. Through extensive experiments on publicly available datasets, including ScanNet++, ScanNet200 and MatterPort3D, we demonstrate that our method achieves state-of-the-art performance in open-vocabulary 3D instance segmentation. Our project page is at https://pku-epic.github.io/MaskClustering.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07751",
        "abstract url": "https://arxiv.org/abs/2401.07751",
        "title": "DeepThalamus: A novel deep learning method for automatic segmentation of brain thalamic nuclei from multimodal ultra-high resolution MRI",
        "rating": "-1",
        "keywords": [
            [
                "MRI"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The implication of the thalamus in multiple neurological pathologies makes it a structure of interest for volumetric analysis. In the present work, we have designed and implemented a multimodal volumetric deep neural network for the segmentation of thalamic nuclei at ultra-high resolution (0.125 mm3). Current tools either operate at standard resolution (1 mm3) or use monomodal data. To achieve the proposed objective, first, a database of semiautomatically segmented thalamic nuclei was created using ultra-high resolution T1, T2 and White Matter nulled (WMn) images. Then, a novel Deep learning based strategy was designed to obtain the automatic segmentations and trained to improve its robustness and accuaracy using a semisupervised approach. The proposed method was compared with a related state-of-the-art method showing competitive results both in terms of segmentation quality and efficiency. To make the proposed method fully available to the scientific community, a full pipeline able to work with monomodal standard resolution T1 images is also proposed.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07753",
        "abstract url": "https://arxiv.org/abs/2401.07753",
        "title": "Low-light Stereo Image Enhancement and De-noising in the Low-frequency Information Enhanced Image Space",
        "rating": "-1",
        "keywords": [
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unlike single image task, stereo image enhancement can use another view information, and its key stage is how to perform cross-view feature interaction to extract useful information from another view. However, complex noise in low-light image and its impact on subsequent feature encoding and interaction are ignored by the existing methods. In this paper, a method is proposed to perform enhancement and de-noising simultaneously. First, to reduce unwanted noise interference, a low-frequency information enhanced module (IEM) is proposed to suppress noise and produce a new image space. Additionally, a cross-channel and spatial context information mining module (CSM) is proposed to encode long-range spatial dependencies and to enhance inter-channel feature interaction. Relying on CSM, an encoder-decoder structure is constructed, incorporating cross-view and cross-scale feature interactions to perform enhancement in the new image space. Finally, the network is trained with the constraints of both spatial and frequency domain losses. Extensive experiments on both synthesized and real datasets show that our method obtains better detail recovery and noise removal compared with state-of-the-art methods. In addition, a real stereo image enhancement dataset is captured with stereo camera ZED2. The code and dataset are publicly available at: https://www.github.com/noportraits/LFENet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07776",
        "abstract url": "https://arxiv.org/abs/2401.07776",
        "title": "Computing the clique number of tournaments",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The clique number of a tournament is the maximum clique number of a graph formed by keeping backwards arcs in an ordering of its vertices. We study the time complexity of computing the clique number of a tournament and prove that, for any integer $k \\geq 3$, deciding whether a tournament has clique number at most $k$ is NP-complete. This answers an interrogation of Nguyen, Scott and Seymour. To do so, we make use of a construction which we then modify to provide a counterexample to a conjecture of Aboulker, Aubian, Charbit and Lopes.",
        "subjects": [
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07777",
        "abstract url": "https://arxiv.org/abs/2401.07777",
        "title": "Quantum Transfer Learning for Acceptability Judgements",
        "rating": "-1",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Hybrid quantum-classical classifiers promise to positively impact critical aspects of natural language processing tasks, particularly classification-related ones. Among the possibilities currently investigated, quantum transfer learning, i.e., using a quantum circuit for fine-tuning pre-trained classical models for a specific task, is attracting significant attention as a potential platform for proving quantum advantage. This work shows potential advantages, both in terms of performance and expressiveness, of quantum transfer learning algorithms trained on embedding vectors extracted from a large language model to perform classification on a classical Linguistics task: acceptability judgments. Acceptability judgment is the ability to determine whether a sentence is considered natural and well-formed by a native speaker. The approach has been tested on sentences extracted from ItaCoLa, a corpus that collects Italian sentences labeled with their acceptability judgment. The evaluation phase shows results for the quantum transfer learning pipeline comparable to state-of-the-art classical transfer learning algorithms, proving current quantum computers' capabilities to tackle NLP tasks for ready-to-use applications. Furthermore, a qualitative linguistic analysis, aided by explainable AI methods, reveals the capabilities of quantum transfer learning algorithms to correctly classify complex and more structured sentences, compared to their classical counterpart. This finding sets the ground for a quantifiable quantum advantage in NLP in the near future.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07782",
        "abstract url": "https://arxiv.org/abs/2401.07782",
        "title": "Exploring Masked Autoencoders for Sensor-Agnostic Image Retrieval in Remote Sensing",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Self-supervised learning through masked autoencoders (MAEs) has recently attracted great attention for remote sensing (RS) image representation learning, and thus embodies a significant potential for content-based image retrieval (CBIR) from ever-growing RS image archives. However, the existing studies on MAEs in RS assume that the considered RS images are acquired by a single image sensor, and thus are only suitable for uni-modal CBIR problems. The effectiveness of MAEs for cross-sensor CBIR, which aims to search semantically similar images across different image modalities, has not been explored yet. In this paper, we take the first step to explore the effectiveness of MAEs for sensor-agnostic CBIR in RS. To this end, we present a systematic overview on the possible adaptations of the vanilla MAE to exploit masked image modeling on multi-sensor RS image archives (denoted as cross-sensor masked autoencoders [CSMAEs]). Based on different adjustments applied to the vanilla MAE, we introduce different CSMAE models. We also provide an extensive experimental analysis of these CSMAE models. We finally derive a guideline to exploit masked image modeling for uni-modal and cross-modal CBIR problems in RS. The code of this work is publicly available at https://github.com/jakhac/CSMAE.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Our code is available at https://github.com/jakhac/CSMAE"
    },
    {
        "paper id": "2401.07796",
        "abstract url": "https://arxiv.org/abs/2401.07796",
        "title": "Fusing Echocardiography Images and Medical Records for Continuous Patient Stratification",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "health",
                "clinical",
                "cardiac",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning now enables automatic and robust extraction of cardiac function descriptors from echocardiographic sequences, such as ejection fraction or strain. These descriptors provide fine-grained information that physicians consider, in conjunction with more global variables from the clinical record, to assess patients' condition. Drawing on novel transformer models applied to tabular data (e.g., variables from electronic health records), we propose a method that considers all descriptors extracted from medical records and echocardiograms to learn the representation of a difficult-to-characterize cardiovascular pathology, namely hypertension. Our method first projects each variable into its own representation space using modality-specific approaches. These standardized representations of multimodal data are then fed to a transformer encoder, which learns to merge them into a comprehensive representation of the patient through a pretext task of predicting a clinical rating. This pretext task is formulated as an ordinal classification to enforce a pathological continuum in the representation space. We observe the major trends along this continuum for a cohort of 239 hypertensive patients to describe, with unprecedented gradation, the effect of hypertension on a number of cardiac function descriptors. Our analysis shows that i) pretrained weights from a foundation model allow to reach good performance (83% accuracy) even with limited data (less than 200 training samples), ii) trends across the population are reproducible between trainings, and iii) for descriptors whose interactions with hypertension are well documented, patterns are consistent with prior physiological knowledge.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, submitted to IEEE TMI"
    },
    {
        "paper id": "2401.07819",
        "abstract url": "https://arxiv.org/abs/2401.07819",
        "title": "Enforcing contraction via data",
        "rating": "-1",
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "We present data-based conditions for enforcing contractivity via feedback control and obtain desired asymptotic properties of the closed-loop system. We focus on unknown nonlinear control systems whose vector fields are expressible via a dictionary of functions and derive data-dependent semidefinite programs whose solution returns the controller that guarantees contractivity. When data are perturbed by disturbances that are linear combination of sinusoids of known frequencies (but unknown amplitude and phase) and constants, we remarkably obtain conditions for contractivity that do not depend on the magnitude of the disturbances, with imaginable positive consequences for the synthesis of the controller. Finally, we show how to design from data an integral controller for nonlinear systems that achieves constant reference tracking and constant disturbance rejection.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07855",
        "abstract url": "https://arxiv.org/abs/2401.07855",
        "title": "Deformable Tip Mount for Soft Growing Eversion Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Here we present a flexible tip mount for eversion (vine) robots. This soft cap allows attaching a payload to an eversion robot while allowing moving through narrow openings, as well as the eversion of protruding objects, and expanded surfaces.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07875",
        "abstract url": "https://arxiv.org/abs/2401.07875",
        "title": "Safely and Autonomously Cutting Meat with a Collaborative Robot Arm",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Labor shortages in the United States are impacting a number of industries including the meat processing sector. Collaborative technologies that work alongside humans while increasing production abilities may support the industry by enhancing automation and improving job quality. However, existing automation technologies used in the meat industry have limited collaboration potential, low flexibility, and high cost. The objective of this work was to explore the use of a robot arm to collaboratively work alongside a human and complete tasks performed in a meat processing facility. Toward this objective, we demonstrated proof-of-concept approaches to ensure human safety while exploring the capacity of the robot arm to perform example meat processing tasks. In support of human safety, we developed a knife instrumentation system to detect when the cutting implement comes into contact with meat within the collaborative space. To demonstrate the capability of the system to flexibly conduct a variety of basic meat processing tasks, we developed vision and control protocols to execute slicing, trimming, and cubing of pork loins. We also collected a subjective evaluation of the actions from experts within the U.S. meat processing industry. On average the experts rated the robot's performance as adequate. Moreover, the experts generally preferred the cuts performed in collaboration with a human worker to cuts completed autonomously, highlighting the benefits of robotic technologies that assist human workers rather than replace them. Video demonstrations of our proposed framework can be found here: https://youtu.be/56mdHjjYMVc",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07877",
        "abstract url": "https://arxiv.org/abs/2401.07877",
        "title": "EMBRE: Entity-aware Masking for Biomedical Relation Extraction",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Information extraction techniques, including named entity recognition (NER) and relation extraction (RE), are crucial in many domains to support making sense of vast amounts of unstructured text data by identifying and connecting relevant information. Such techniques can assist researchers in extracting valuable insights. In this paper, we introduce the Entity-aware Masking for Biomedical Relation Extraction (EMBRE) method for biomedical relation extraction, as applied in the context of the BioRED challenge Task 1, in which human-annotated entities are provided as input. Specifically, we integrate entity knowledge into a deep neural network by pretraining the backbone model with an entity masking objective. We randomly mask named entities for each instance and let the model identify the masked entity along with its type. In this way, the model is capable of learning more specific knowledge and more robust representations. Then, we utilize the pre-trained model as our backbone to encode language representations and feed these representations into two multilayer perceptron (MLPs) to predict the logits for relation and novelty, respectively. The experimental results demonstrate that our proposed method can improve the performances of entity pair, relation and novelty extraction over our baseline.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2401.07935",
        "abstract url": "https://arxiv.org/abs/2401.07935",
        "title": "6-DoF Grasp Pose Evaluation and Optimization via Transfer Learning from NeRFs",
        "rating": "-1",
        "keywords": [
            [
                "6-DoF",
                "NeRF"
            ]
        ],
        "abstract": "We address the problem of robotic grasping of known and unknown objects using implicit behavior cloning. We train a grasp evaluation model from a small number of demonstrations that outputs higher values for grasp candidates that are more likely to succeed in grasping. This evaluation model serves as an objective function, that we maximize to identify successful grasps. Key to our approach is the utilization of learned implicit representations of visual and geometric features derived from a pre-trained NeRF. Though trained exclusively in a simulated environment with simplified objects and 4-DoF top-down grasps, our evaluation model and optimization procedure demonstrate generalization to 6-DoF grasps and novel objects both in simulation and in real-world settings, without the need for additional data. Supplementary material is available at: https://gergely-soti.github.io/grasp",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07960",
        "abstract url": "https://arxiv.org/abs/2401.07960",
        "title": "ADMIn: Attacks on Dataset, Model and Input. A Threat Model for AI Based Software",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Machine learning (ML) and artificial intelligence (AI) techniques have now become commonplace in software products and services. When threat modelling a system, it is therefore important that we consider threats unique to ML and AI techniques, in addition to threats to our software. In this paper, we present a threat model that can be used to systematically uncover threats to AI based software. The threat model consists of two main parts, a model of the software development process for AI based software and an attack taxonomy that has been developed using attacks found in adversarial AI research. We apply the threat model to two real life AI based software and discuss the process and the threats found.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07974",
        "abstract url": "https://arxiv.org/abs/2401.07974",
        "title": "The Space-Time Cost of Purifying Quantum Computations",
        "rating": "-1",
        "keywords": [
            [
                "time efficient"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "General quantum computation consists of unitary operations and also measurements. It is well known that intermediate quantum measurements can be deferred to the end of the computation, resulting in an equivalent purely unitary computation. While time efficient, this transformation blows up the space to linear in the running time, which could be super-polynomial for low-space algorithms. Fefferman and Remscrim (STOC'21) and Girish, Raz and Zhan (ICALP'21) show different transformations which are space efficient, but blow up the running time by a factor that is exponential in the space. This leaves the case of algorithms with small-but-super-logarithmic space as incurring a large blowup in either time or space complexity. We show that such a blowup is likely inherent, demonstrating that any \"black-box\" transformation which removes intermediate measurements must significantly blow up either space or time.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "ITCS'24"
    },
    {
        "paper id": "2401.07977",
        "abstract url": "https://arxiv.org/abs/2401.07977",
        "title": "Leveraging External Knowledge Resources to Enable Domain-Specific Comprehension",
        "rating": "-1",
        "keywords": [
            [
                "Bio/Sci-BERT"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Machine Reading Comprehension (MRC) has been a long-standing problem in NLP and, with the recent introduction of the BERT family of transformer based language models, it has come a long way to getting solved. Unfortunately, however, when BERT variants trained on general text corpora are applied to domain-specific text, their performance inevitably degrades on account of the domain shift i.e. genre/subject matter discrepancy between the training and downstream application data. Knowledge graphs act as reservoirs for either open or closed domain information and prior studies have shown that they can be used to improve the performance of general-purpose transformers in domain-specific applications. Building on existing work, we introduce a method using Multi-Layer Perceptrons (MLPs) for aligning and integrating embeddings extracted from knowledge graphs with the embeddings spaces of pre-trained language models (LMs). We fuse the aligned embeddings with open-domain LMs BERT and RoBERTa, and fine-tune them for two MRC tasks namely span detection (COVID-QA) and multiple-choice questions (PubMedQA). On the COVID-QA dataset, we see that our approach allows these models to perform similar to their domain-specific counterparts, Bio/Sci-BERT, as evidenced by the Exact Match (EM) metric. With regards to PubMedQA, we observe an overall improvement in accuracy while the F1 stays relatively the same over the domain-specific models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07990",
        "abstract url": "https://arxiv.org/abs/2401.07990",
        "title": "How does self-supervised pretraining improve robustness against noisy labels across various medical image classification datasets?",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Noisy labels can significantly impact medical image classification, particularly in deep learning, by corrupting learned features. Self-supervised pretraining, which doesn't rely on labeled data, can enhance robustness against noisy labels. However, this robustness varies based on factors like the number of classes, dataset complexity, and training size. In medical images, subtle inter-class differences and modality-specific characteristics add complexity. Previous research hasn't comprehensively explored the interplay between self-supervised learning and robustness against noisy labels in medical image classification, considering all these factors. In this study, we address three key questions: i) How does label noise impact various medical image classification datasets? ii) Which types of medical image datasets are more challenging to learn and more affected by label noise? iii) How do different self-supervised pretraining methods enhance robustness across various medical image datasets? Our results show that DermNet, among five datasets (Fetal plane, DermNet, COVID-DU-Ex, MURA, NCT-CRC-HE-100K), is the most challenging but exhibits greater robustness against noisy labels. Additionally, contrastive learning stands out among the eight self-supervised methods as the most effective approach to enhance robustness against noisy labels.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07995",
        "abstract url": "https://arxiv.org/abs/2401.07995",
        "title": "The Pulse of Fileless Cryptojacking Attacks: Malicious PowerShell Scripts",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Fileless malware predominantly relies on PowerShell scripts, leveraging the native capabilities of Windows systems to execute stealthy attacks that leave no traces on the victim's system. The effectiveness of the fileless method lies in its ability to remain operational on victim endpoints through memory execution, even if the attacks are detected, and the original malicious scripts are removed. Threat actors have increasingly utilized this technique, particularly since 2017, to conduct cryptojacking attacks. With the emergence of new Remote Code Execution (RCE) vulnerabilities in ubiquitous libraries, widespread cryptocurrency mining attacks have become prevalent, often employing fileless techniques. This paper provides a comprehensive analysis of PowerShell scripts of fileless cryptojacking, dissecting the common malicious patterns based on the MITRE ATT&CK framework.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "10 pages, 1 figure"
    },
    {
        "paper id": "2401.08019",
        "abstract url": "https://arxiv.org/abs/2401.08019",
        "title": "Centrality of shortest paths: Algorithms and complexity results",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The degree centrality of a node, defined as the number of nodes adjacent to it, is often used as a measure of importance of a node to the structure of a network. This metric can be extended to paths in a network, where the degree centrality of a path is defined as the number of nodes adjacent to it. In this paper, we reconsider the problem of finding the most degree-central shortest path in an unweighted network. We propose a polynomial algorithm with the worst-case running time of $O(|E||V|^2\u0394(G))$, where $|V|$ is the number of vertices in the network, $|E|$ is the number of edges in the network, and $\u0394(G)$ is the maximum degree of the graph. We conduct a numerical study of our algorithm on synthetic and real-world networks and compare our results to the existing literature. In addition, we show that the same problem is NP-hard when a weighted graph is considered. Furthermore, we consider other centrality measures, such as the betweenness and closeness centrality, showing that the problem of finding the most betweenness-central shortest path is solvable in polynomial time and finding the most closeness-central shortest path is NP-hard, regardless of whether the graph is weighted or not.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08032",
        "abstract url": "https://arxiv.org/abs/2401.08032",
        "title": "Structure-based out-of-distribution (OOD) materials property prediction: a benchmark study",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "graph"
            ]
        ],
        "abstract": "In real-world material research, machine learning (ML) models are usually expected to predict and discover novel exceptional materials that deviate from the known materials. It is thus a pressing question to provide an objective evaluation of ML model performances in property prediction of out-of-distribution (OOD) materials that are different from the training set distribution. Traditional performance evaluation of materials property prediction models through random splitting of the dataset frequently results in artificially high performance assessments due to the inherent redundancy of typical material datasets. Here we present a comprehensive benchmark study of structure-based graph neural networks (GNNs) for extrapolative OOD materials property prediction. We formulate five different categories of OOD ML problems for three benchmark datasets from the MatBench study. Our extensive experiments show that current state-of-the-art GNN algorithms significantly underperform for the OOD property prediction tasks on average compared to their baselines in the MatBench study, demonstrating a crucial generalization gap in realistic material prediction tasks. We further examine the latent physical spaces of these GNN models and identify the sources of CGCNN, ALIGNN, and DeeperGATGNN's significantly more robust OOD performance than those of the current best models in the MatBench study (coGN and coNGN), and provide insights to improve their performance.",
        "subjects": [
            "cond-mat.mtrl-sci"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2401.08036",
        "abstract url": "https://arxiv.org/abs/2401.08036",
        "title": "3D Lane Detection from Front or Surround-View using Joint-Modeling & Matching",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D lanes offer a more comprehensive understanding of the road surface geometry than 2D lanes, thereby providing crucial references for driving decisions and trajectory planning. While many efforts aim to improve prediction accuracy, we recognize that an efficient network can bring results closer to lane modeling. However, if the modeling data is imprecise, the results might not accurately capture the real-world scenario. Therefore, accurate lane modeling is essential to align prediction results closely with the environment. This study centers on efficient and accurate lane modeling, proposing a joint modeling approach that combines Bezier curves and interpolation methods. Furthermore, based on this lane modeling approach, we developed a Global2Local Lane Matching method with Bezier Control-Point and Key-Point, which serve as a comprehensive solution that leverages hierarchical features with two mathematical models to ensure a precise match. We also introduce a novel 3D Spatial Constructor, representing an exploration of 3D surround-view lane detection research. The framework is suitable for front-view or surround-view 3D lane detection. By directly outputting the key points of lanes in 3D space, it overcomes the limitations of anchor-based methods, enabling accurate prediction of closed-loop or U-shaped lanes and effective adaptation to complex road conditions. This innovative method establishes a new benchmark in front-view 3D lane detection on the Openlane dataset and achieves competitive performance in surround-view 2D lane detection on the Argoverse2 dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08056",
        "abstract url": "https://arxiv.org/abs/2401.08056",
        "title": "Robust Tiny Object Detection in Aerial Images amidst Label Noise",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Precise detection of tiny objects in remote sensing imagery remains a significant challenge due to their limited visual information and frequent occurrence within scenes. This challenge is further exacerbated by the practical burden and inherent errors associated with manual annotation: annotating tiny objects is laborious and prone to errors (i.e., label noise). Training detectors for such objects using noisy labels often leads to suboptimal performance, with networks tending to overfit on noisy labels. In this study, we address the intricate issue of tiny object detection under noisy label supervision. We systematically investigate the impact of various types of noise on network training, revealing the vulnerability of object detectors to class shifts and inaccurate bounding boxes for tiny objects. To mitigate these challenges, we propose a DeNoising Tiny Object Detector (DN-TOD), which incorporates a Class-aware Label Correction (CLC) scheme to address class shifts and a Trend-guided Learning Strategy (TLS) to handle bounding box noise. CLC mitigates inaccurate class supervision by identifying and filtering out class-shifted positive samples, while TLS reduces noisy box-induced erroneous supervision through sample reweighting and bounding box regeneration. Additionally, Our method can be seamlessly integrated into both one-stage and two-stage object detection pipelines. Comprehensive experiments conducted on synthetic (i.e., noisy AI-TOD-v2.0 and DOTA-v2.0) and real-world (i.e., AI-TOD) noisy datasets demonstrate the robustness of DN-TOD under various types of label noise. Notably, when applied to the strong baseline RFLA, DN-TOD exhibits a noteworthy performance improvement of 4.9 points under 40% mixed noise. Datasets, codes, and models will be made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08058",
        "abstract url": "https://arxiv.org/abs/2401.08058",
        "title": "Toward Clinically Trustworthy Deep Learning: Applying Conformal Prediction to Intracranial Hemorrhage Detection",
        "rating": "-1",
        "keywords": [
            [
                "clinical",
                "radiology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As deep learning (DL) continues to demonstrate its ability in radiological tasks, it is critical that we optimize clinical DL solutions to include safety. One of the principal concerns in the clinical adoption of DL tools is trust. This study aims to apply conformal prediction as a step toward trustworthiness for DL in radiology. This is a retrospective study of 491 non-contrast head CTs from the CQ500 dataset, in which three senior radiologists annotated slices containing intracranial hemorrhage (ICH). The dataset was split into definite and challenging subsets, where challenging images were defined to those in which there was disagreement among readers. A DL model was trained on 146 patients (10,815 slices) from the definite data (training dataset) to perform ICH localization and classification for five classes of ICH. To develop an uncertainty-aware DL model, 1,546 cases of the definite data (calibration dataset) was used for Mondrian conformal prediction (MCP). The uncertainty-aware DL model was tested on 8,401 definite and challenging cases to assess its ability to identify challenging cases. After the MCP procedure, the model achieved an F1 score of 0.920 for ICH classification on the test dataset. Additionally, it correctly identified 6,837 of the 6,856 total challenging cases as challenging (99.7% accuracy). It did not incorrectly label any definite cases as challenging. The uncertainty-aware ICH detector performs on par with state-of-the-art models. MCP's performance in detecting challenging cases demonstrates that it is useful in automated ICH detection and promising for trustworthiness in radiological DL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 6 figures, 4 tables"
    },
    {
        "paper id": "2401.08061",
        "abstract url": "https://arxiv.org/abs/2401.08061",
        "title": "Augmenting Ground-Level PM2.5 Prediction via Kriging-Based Pseudo-Label Generation",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG"
            ],
            [
                "Workshop",
                "NeurIPS"
            ]
        ],
        "abstract": "Fusing abundant satellite data with sparse ground measurements constitutes a major challenge in climate modeling. To address this, we propose a strategy to augment the training dataset by introducing unlabeled satellite images paired with pseudo-labels generated through a spatial interpolation technique known as ordinary kriging, thereby making full use of the available satellite data resources. We show that the proposed data augmentation strategy helps enhance the performance of the state-of-the-art convolutional neural network-random forest (CNN-RF) model by a reasonable amount, resulting in a noteworthy improvement in spatial correlation and a reduction in prediction error.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 4 figures, NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning"
    },
    {
        "paper id": "2401.08066",
        "abstract url": "https://arxiv.org/abs/2401.08066",
        "title": "Achieve Fairness without Demographics for Dermatological Disease Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "Disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In medical image diagnosis, fairness has become increasingly crucial. Without bias mitigation, deploying unfair AI would harm the interests of the underprivileged population and potentially tear society apart. Recent research addresses prediction biases in deep learning models concerning demographic groups (e.g., gender, age, and race) by utilizing demographic (sensitive attribute) information during training. However, many sensitive attributes naturally exist in dermatological disease images. If the trained model only targets fairness for a specific attribute, it remains unfair for other attributes. Moreover, training a model that can accommodate multiple sensitive attributes is impractical due to privacy concerns. To overcome this, we propose a method enabling fair predictions for sensitive attributes during the testing phase without using such information during training. Inspired by prior work highlighting the impact of feature entanglement on fairness, we enhance the model features by capturing the features related to the sensitive and target attributes and regularizing the feature entanglement between corresponding classes. This ensures that the model can only classify based on the features related to the target attribute without relying on features associated with sensitive attributes, thereby improving fairness and accuracy. Additionally, we use disease masks from the Segment Anything Model (SAM) to enhance the quality of the learned feature. Experimental results demonstrate that the proposed method can improve fairness in classification compared to state-of-the-art methods in two dermatological disease datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08098",
        "abstract url": "https://arxiv.org/abs/2401.08098",
        "title": "Attention-Based CNN-BiLSTM for Sleep State Classification of Spatiotemporal Wide-Field Calcium Imaging Data",
        "rating": "-1",
        "keywords": [
            [
                "EEG"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Background: Wide-field calcium imaging (WFCI) with genetically encoded calcium indicators allows for spatiotemporal recordings of neuronal activity in mice. When applied to the study of sleep, WFCI data are manually scored into the sleep states of wakefulness, non-REM (NREM) and REM by use of adjunct EEG and EMG recordings. However, this process is time-consuming, invasive and often suffers from low inter- and intra-rater reliability. Therefore, an automated sleep state classification method that operates on spatiotemporal WFCI data is desired. New Method: A hybrid network architecture consisting of a convolutional neural network (CNN) to extract spatial features of image frames and a bidirectional long short-term memory network (BiLSTM) with attention mechanism to identify temporal dependencies among different time points was proposed to classify WFCI data into states of wakefulness, NREM and REM sleep. Results: Sleep states were classified with an accuracy of 84% and Cohen's kappa of 0.64. Gradient-weighted class activation maps revealed that the frontal region of the cortex carries more importance when classifying WFCI data into NREM sleep while posterior area contributes most to the identification of wakefulness. The attention scores indicated that the proposed network focuses on short- and long-range temporal dependency in a state-specific manner. Comparison with Existing Method: On a 3-hour WFCI recording, the CNN-BiLSTM achieved a kappa of 0.67, comparable to a kappa of 0.65 corresponding to the human EEG/EMG-based scoring. Conclusions: The CNN-BiLSTM effectively classifies sleep states from spatiotemporal WFCI data and will enable broader application of WFCI in sleep.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08100",
        "abstract url": "https://arxiv.org/abs/2401.08100",
        "title": "KTVIC: A Vietnamese Image Captioning Dataset on the Life Domain",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image captioning is a crucial task with applications in a wide range of domains, including healthcare and education. Despite extensive research on English image captioning datasets, the availability of such datasets for Vietnamese remains limited, with only two existing datasets. In this study, we introduce KTVIC, a comprehensive Vietnamese Image Captioning dataset focused on the life domain, covering a wide range of daily activities. This dataset comprises 4,327 images and 21,635 Vietnamese captions, serving as a valuable resource for advancing image captioning in the Vietnamese language. We conduct experiments using various deep neural networks as the baselines on our dataset, evaluating them using the standard image captioning metrics, including BLEU, METEOR, CIDEr, and ROUGE. Our findings underscore the effectiveness of the proposed dataset and its potential contributions to the field of image captioning in the Vietnamese context.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08105",
        "abstract url": "https://arxiv.org/abs/2401.08105",
        "title": "Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone Networks",
        "rating": "-1",
        "keywords": [
            [
                "Drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Early wildfire detection in remote and forest areas is crucial for minimizing devastation and preserving ecosystems. Autonomous drones offer agile access to remote, challenging terrains, equipped with advanced imaging technology that delivers both high-temporal and detailed spatial resolution, making them valuable assets in the early detection and monitoring of wildfires. However, the limited computation and battery resources of Unmanned Aerial Vehicles (UAVs) pose significant challenges in implementing robust and efficient image classification models. Current works in this domain often operate offline, emphasizing the need for solutions that can perform inference in real time, given the constraints of UAVs. To address these challenges, this paper aims to develop a real-time image classification and fire segmentation model. It presents a comprehensive investigation into hardware acceleration using the Jetson Nano P3450 and the implications of TensorRT, NVIDIA's high-performance deep-learning inference library, on fire classification accuracy and speed. The study includes implementations of Quantization Aware Training (QAT), Automatic Mixed Precision (AMP), and post-training mechanisms, comparing them against the latest baselines for fire segmentation and classification. All experiments utilize the FLAME dataset - an image dataset collected by low-altitude drones during a prescribed forest fire. This work contributes to the ongoing efforts to enable real-time, on-board wildfire detection capabilities for UAVs, addressing speed and the computational and energy constraints of these crucial monitoring systems. The results show a 13% increase in classification speed compared to similar models without hardware optimization. Comparatively, loss and accuracy are within 1.225% of the original values.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 7 figures, NETROBOTICS conference submission"
    },
    {
        "paper id": "2401.08107",
        "abstract url": "https://arxiv.org/abs/2401.08107",
        "title": "Deep Shape-Texture Statistics for Completely Blind Image Quality Evaluation",
        "rating": "-1",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Opinion-Unaware Blind Image Quality Assessment (OU-BIQA) models aim to predict image quality without training on reference images and subjective quality scores. Thereinto, image statistical comparison is a classic paradigm, while the performance is limited by the representation ability of visual descriptors. Deep features as visual descriptors have advanced IQA in recent research, but they are discovered to be highly texture-biased and lack of shape-bias. On this basis, we find out that image shape and texture cues respond differently towards distortions, and the absence of either one results in an incomplete image representation. Therefore, to formulate a well-round statistical description for images, we utilize the shapebiased and texture-biased deep features produced by Deep Neural Networks (DNNs) simultaneously. More specifically, we design a Shape-Texture Adaptive Fusion (STAF) module to merge shape and texture information, based on which we formulate qualityrelevant image statistics. The perceptual quality is quantified by the variant Mahalanobis Distance between the inner and outer Shape-Texture Statistics (DSTS), wherein the inner and outer statistics respectively describe the quality fingerprints of the distorted image and natural images. The proposed DSTS delicately utilizes shape-texture statistical relations between different data scales in the deep domain, and achieves state-of-the-art (SOTA) quality prediction performance on images with artificial and authentic distortions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09479",
        "abstract url": "https://arxiv.org/abs/2401.09479",
        "title": "Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The risk of hardware Trojans being inserted at various stages of chip production has increased in a zero-trust fabless era. To counter this, various machine learning solutions have been developed for the detection of hardware Trojans. While most of the focus has been on either a statistical or deep learning approach, the limited number of Trojan-infected benchmarks affects the detection accuracy and restricts the possibility of detecting zero-day Trojans. To close the gap, we first employ generative adversarial networks to amplify our data in two alternative representation modalities, a graph and a tabular, ensuring that the dataset is distributed in a representative manner. Further, we propose a multimodal deep learning approach to detect hardware Trojans and evaluate the results from both early fusion and late fusion strategies. We also estimate the uncertainty quantification metrics of each prediction for risk-aware decision-making. The outcomes not only confirms the efficacy of our proposed hardware Trojan detection method but also opens a new door for future studies employing multimodality and uncertainty quantification to address other hardware security challenges.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "2024 Design, Automation and Test in Europe Conference | The European Event for Electronic System Design & Test (accepted)"
    },
    {
        "paper id": "2401.09481",
        "abstract url": "https://arxiv.org/abs/2401.09481",
        "title": "3DMASC: Accessible, explainable 3D point clouds classification. Application to Bi-spectral Topo-bathymetric lidar data",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "lidar"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Three-dimensional data have become increasingly present in earth observation over the last decades. However, many 3D surveys are still underexploited due to the lack of accessible and explainable automatic classification methods, for example, new topo-bathymetric lidar data. In this work, we introduce explainable machine learning for 3D data classification using Multiple Attributes, Scales, and Clouds under 3DMASC, a new workflow. This workflow introduces multi-cloud classification through dual-cloud features, encrypting local spectral and geometrical ratios and differences. 3DMASC uses classical multi-scale descriptors adapted to all types of 3D point clouds and new ones based on their spatial variations. In this paper, we present the performances of 3DMASC for multi-class classification of topo-bathymetric lidar data in coastal and fluvial environments. We show how multivariate and embedded feature selection allows the building of optimized predictor sets of reduced complexity, and we identify features particularly relevant for coastal and riverine scene descriptions. Our results show the importance of dual-cloud features, lidar return-based attributes averaged over specific scales, and of statistics of dimensionality-based and spectral features. Additionally, they indicate that small to medium spherical neighbourhood diameters (<7 m) are sufficient to build effective classifiers, namely when combined with distance-to-ground or distance-to-water-surface features. Without using optional RGB information, and with a maximum of 37 descriptors, we obtain classification accuracies between 91 % for complex multi-class tasks and 98 % for lower-level processing using models trained on less than 2000 samples per class. Comparisons with classical point cloud classification methods show that 3DMASC features have a significantly improved descriptive power. Our contributions are made available through a plugin in the CloudCompare software, allowing non-specialist users to create classifiers for any type of 3D data characterized by 1 or 2 point clouds (airborne or terrestrial lidar, structure from motion), and two labelled topo-bathymetric lidar datasets, available on https://opentopography.org/.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10927",
        "abstract url": "https://arxiv.org/abs/2401.10927",
        "title": "Debiasing and a local analysis for population clustering using semidefinite programming",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper, we consider the problem of partitioning a small data sample of size $n$ drawn from a mixture of $2$ sub-gaussian distributions. In particular, we analyze computational efficient algorithms proposed by the same author, to partition data into two groups approximately according to their population of origin given a small sample. This work is motivated by the application of clustering individuals according to their population of origin using $p$ markers, when the divergence between any two of the populations is small. We build upon the semidefinite relaxation of an integer quadratic program that is formulated essentially as finding the maximum cut on a graph, where edge weights in the cut represent dissimilarity scores between two nodes based on their $p$ features. Here we use $\u0394^2 :=p \u03b3$ to denote the $\\ell_2^2$ distance between two centers (mean vectors), namely, $\u03bc^{(1)}$, $\u03bc^{(2)}$ $\\in$ $\\mathbb{R}^p$. The goal is to allow a full range of tradeoffs between $n, p, \u03b3$ in the sense that partial recovery (success rate $< 100\\%$) is feasible once the signal to noise ratio $s^2 := \\min\\{np \u03b3^2, \u0394^2\\}$ is lower bounded by a constant. Importantly, we prove that the misclassification error decays exponentially with respect to the SNR $s^2$. This result was introduced earlier without a full proof. We therefore present the full proof in the present work. Finally, for balanced partitions, we consider a variant of the SDP1, and show that the new estimator has a superb debiasing property. This is novel to the best of our knowledge.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2301.00344"
    },
    {
        "paper id": "2402.00879",
        "abstract url": "https://arxiv.org/abs/2402.00879",
        "title": "Graph Representation Learning for Contention and Interference Management in Wireless Networks",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Restricted access window (RAW) in Wi-Fi 802.11ah networks manages contention and interference by grouping users and allocating periodic time slots for each group's transmissions. We will find the optimal user grouping decisions in RAW to maximize the network's worst-case user throughput. We review existing user grouping approaches and highlight their performance limitations in the above problem. We propose formulating user grouping as a graph construction problem where vertices represent users and edge weights indicate the contention and interference. This formulation leverages the graph's max cut to group users and optimizes edge weights to construct the optimal graph whose max cut yields the optimal grouping decisions. To achieve this optimal graph construction, we design an actor-critic graph representation learning (AC-GRL) algorithm. Specifically, the actor neural network (NN) is trained to estimate the optimal graph's edge weights using path losses between users and access points. A graph cut procedure uses semidefinite programming to solve the max cut efficiently and return the grouping decisions for the given weights. The critic NN approximates user throughput achieved by the above-returned decisions and is used to improve the actor. Additionally, we present an architecture that uses the online-measured throughput and path losses to fine-tune the decisions in response to changes in user populations and their locations. Simulations show that our methods achieve $30\\%\\sim80\\%$ higher worst-case user throughput than the existing approaches and that the proposed architecture can further improve the worst-case user throughput by $5\\%\\sim30\\%$ while ensuring timely updates of grouping decisions.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "This work has been accepted in the IEEE/ACM Transactions on Networking. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2403.18825",
        "abstract url": "https://arxiv.org/abs/2403.18825",
        "title": "Numerical evaluation of code live-load models for estimating the forces caused by actual vehicles that act on bridge substructures",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "The present paper assesses the efficacy of code live-load models in accurately estimating the vehicular loads transferred to bridge substructures, such as abutments, piers, and foundations. Realistic traffic vehicle data are represented using four Weigh-in-Motion databases, which provide an authentic representation of vehicle information, thus providing a realistic basis for the examination of the bridges studied. The evaluation includes various bridge models, such as single-span girder bridges and two-, three-, and four-span continuous pinned-support girder bridges. By analyzing exceedance rates, the study compares the extreme force values obtained for vehicles in the databases with those predicted by selected code live-load models. These exceedance rates are presented in spectra format, as a function of the span length. The significant variations observed in the exceedance rates highlight the need for improving existing code live-load models to achieve more accurate estimations of the forces transferred to bridge substructures. Such improvements would lead to more uniform reliability levels for any limit state, such as resistance, fatigue, serviceability, and cracking.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07494",
        "abstract url": "https://arxiv.org/abs/2401.07494",
        "title": "Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering Tasks",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Computational efficiency and non-adversarial robustness are critical factors in real-world engineering applications. Yet, conventional neural networks often fall short in addressing both simultaneously, or even separately. Drawing insights from natural physical systems and existing literature, it is known that an input convex architecture enhances computational efficiency, while a Lipschitz-constrained architecture bolsters non-adversarial robustness. By leveraging the strengths of convexity and Lipschitz continuity, we develop a novel network architecture, termed Input Convex Lipschitz Recurrent Neural Networks. This model is explicitly designed for fast and robust optimization-based tasks and outperforms existing recurrent units across a spectrum of engineering tasks in terms of computational efficiency and non-adversarial robustness, including real-world solar irradiance prediction for Solar PV system planning at LHT Holdings in Singapore and real-time Model Predictive Control optimization for a nonlinear chemical reactor.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07604",
        "abstract url": "https://arxiv.org/abs/2401.07604",
        "title": "Data Assimilation using ERA5, ASOS, and the U-STN model for Weather Forecasting over the UK",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "Workshop",
                "NeurIPS"
            ]
        ],
        "abstract": "In recent years, the convergence of data-driven machine learning models with Data Assimilation (DA) offers a promising avenue for enhancing weather forecasting. This study delves into this emerging trend, presenting our methodologies and outcomes. We harnessed the UK's local ERA5 850 hPa temperature data and refined the U-STN12 global weather forecasting model, tailoring its predictions to the UK's climate nuances. From the ASOS network, we sourced T2m data, representing ground observations across the UK. We employed the advanced kriging method with a polynomial drift term for consistent spatial resolution. Furthermore, Gaussian noise was superimposed on the ERA5 T850 data, setting the stage for ensuing multi-time step synthetic observations. Probing into the assimilation impacts, the ASOS T2m data was integrated with the ERA5 T850 dataset. Our insights reveal that while global forecast models can adapt to specific regions, incorporating atmospheric data in DA significantly bolsters model accuracy. Conversely, the direct assimilation of surface temperature data tends to mitigate this enhancement, tempering the model's predictive prowess.",
        "subjects": [
            "physics.ao-ph"
        ],
        "comment": "Accepted in the Tackling Climate Change with Machine Learning Workshop@NeurIPS 2023, 8 pages, 2 figures"
    },
    {
        "paper id": "2401.07717",
        "abstract url": "https://arxiv.org/abs/2401.07717",
        "title": "A Pragmatical Approach to Anomaly Detection Evaluation in Edge Cloud Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Anomaly detection (AD) has been recently employed in the context of edge cloud computing, e.g., for intrusion detection and identification of performance issues. However, state-of-the-art anomaly detection procedures do not systematically consider restrictions and performance requirements inherent to the edge, such as system responsiveness and resource consumption. In this paper, we attempt to investigate the performance of change-point based detectors, i.e., a class of lightweight and accurate AD methods, in relation to the requirements of edge cloud systems. Firstly, we review the theoretical properties of two major categories of change point approaches, i.e., Bayesian and cumulative sum (CUSUM), also discussing their suitability for edge systems. Secondly, we introduce a novel experimental methodology and apply it over two distinct edge cloud test-beds to evaluate the performance of such mechanisms in real-world edge environments. Our experimental results reveal important insights and trade-offs for the applicability and the online performance of the selected change point detectors.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted: Proc. IEEE Int. Conf. Comput. Commun. ICCN Workshops (INFOCOM ICCN WKSHPS), Vancouver, Canada, 2024"
    },
    {
        "paper id": "2401.07718",
        "abstract url": "https://arxiv.org/abs/2401.07718",
        "title": "How Social Media Big Data Can Improve Suicide Prevention",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "In the light of increasing clues on social media impact on self-harm and suicide risks, there is still no evidence on who are and how factually engaged in suicide-related online behaviors. This study reports new findings of high-performance supercomputing investigation of publicly accessible big data sourced from one of the world-largest social networking site. Three-month supercomputer searching resulted in 570,156 young adult users who consumed suicide-related information on social media. Most of them were 21-24 year olds with higher share of females (58%) of predominantly younger age. Every eight user was alarmingly engrossed with up to 15 suicide-related online groups. Evidently, suicide groups on social media are highly underrated public health issue that might weaken the prevention efforts. Suicide prevention strategies that target social media users must be implemented extensively. While major gap in functional understanding of technologies relevance for use in public mental health still exists, current findings act for better understanding digital technologies utility for translational advance and offer relevant evidence-based framework for improving suicide prevention in general population.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "7 pages, 1 figure, 1 table"
    },
    {
        "paper id": "2401.07890",
        "abstract url": "https://arxiv.org/abs/2401.07890",
        "title": "A Strategy for Implementing description Temporal Dynamic Algorithms in Dynamic Knowledge Graphs by SPIN",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Planning and reasoning about actions and processes, in addition to reasoning about propositions, are important issues in recent logical and computer science studies. The widespread use of actions in everyday life such as IoT, semantic web services, etc., and the limitations and issues in the action formalisms are two factors that lead us to study how actions are represented. Since 2007, there have been some ideas to integrate Description Logic (DL) and action formalisms for representing both static and dynamic knowledge. Meanwhile, time is an important factor in dynamic situations, and actions change states over time. In this study, on the one hand, we examined related logical structures such as extensions of description logics (DLs), temporal formalisms, and action formalisms. On the other hand, we analyzed possible tools for designing and developing the Knowledge and Action Base (KAB). For representation and reasoning about actions, we embedded actions into DLs (such as Dynamic-ALC and its extensions). We propose a terminable algorithm for action projection, planning, checking the satisfiability, consistency, realizability, and executability, and also querying from KAB. Actions in this framework were modeled with SPIN and added to state space. This framework has also been implemented as a plugin for the Prot\u00e9g\u00e9 ontology editor. During the last two decades, various algorithms have been presented, but due to the high computational complexity, we face many problems in implementing dynamic ontologies. In addition, an algorithm to detect the inconsistency of actions' effects was not explicitly stated. In the proposed strategy, the interactions of actions with other parts of modeled knowledge, and a method to check consistency between the effects of actions are presented. With this framework, the ramification problem can be well handled in future works.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08002",
        "abstract url": "https://arxiv.org/abs/2401.08002",
        "title": "Discovery of Generalizable TBI Phenotypes Using Multivariate Time-Series Clustering",
        "rating": "-1.5",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traumatic Brain Injury (TBI) presents a broad spectrum of clinical presentations and outcomes due to its inherent heterogeneity, leading to diverse recovery trajectories and varied therapeutic responses. While many studies have delved into TBI phenotyping for distinct patient populations, identifying TBI phenotypes that consistently generalize across various settings and populations remains a critical research gap. Our research addresses this by employing multivariate time-series clustering to unveil TBI's dynamic intricates. Utilizing a self-supervised learning-based approach to clustering multivariate time-Series data with missing values (SLAC-Time), we analyzed both the research-centric TRACK-TBI and the real-world MIMIC-IV datasets. Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of clusters remained consistent across these datasets, underscoring SLAC-Time's stability across heterogeneous datasets. Our analysis revealed three generalizable TBI phenotypes (\u03b1, \\b{eta}, and \u03b3), each exhibiting distinct non-temporal features during emergency department visits, and temporal feature profiles throughout ICU stays. Specifically, phenotype \u03b1 represents mild TBI with a remarkably consistent clinical presentation. In contrast, phenotype \\b{eta} signifies severe TBI with diverse clinical manifestations, and phenotype \u03b3 represents a moderate TBI profile in terms of severity and clinical diversity. Age is a significant determinant of TBI outcomes, with older cohorts recording higher mortality rates. Importantly, while certain features varied by age, the core characteristics of TBI manifestations tied to each phenotype remain consistent across diverse populations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "25 pages, 10 figures, 4 tables, submitted to Computers in Biology and Medicine"
    },
    {
        "paper id": "2401.08008",
        "abstract url": "https://arxiv.org/abs/2401.08008",
        "title": "Analysing the Needs of Homeless People Using Feature Selection and Mining Association Rules",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Homelessness is a social and health problem with great repercussions in Europe. Many non-governmental organisations help homeless people by collecting and analysing large amounts of information about them. However, these tasks are not always easy to perform, and hinder other of the organisations duties. The SINTECH project was created to tackle this issue proposing two different tools: a mobile application to quickly and easily collect data; and a software based on artificial intelligence which obtains interesting information from the collected data. The first one has been distributed to some Spanish organisations which are using it to conduct surveys of homeless people. The second tool implements different feature selection and association rules mining methods. These artificial intelligence techniques have allowed us to identify the most relevant features and some interesting association rules from previously collected homeless data.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "6 pages, 4 figures, 4 tables, MetroXRAINE 2022"
    },
    {
        "paper id": "2401.08049",
        "abstract url": "https://arxiv.org/abs/2401.08049",
        "title": "EmoTalker: Emotionally Editable Talking Face Generation via Diffusion Model",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In recent years, the field of talking faces generation has attracted considerable attention, with certain methods adept at generating virtual faces that convincingly imitate human expressions. However, existing methods face challenges related to limited generalization, particularly when dealing with challenging identities. Furthermore, methods for editing expressions are often confined to a singular emotion, failing to adapt to intricate emotions. To overcome these challenges, this paper proposes EmoTalker, an emotionally editable portraits animation approach based on the diffusion model. EmoTalker modifies the denoising process to ensure preservation of the original portrait's identity during inference. To enhance emotion comprehension from text input, Emotion Intensity Block is introduced to analyze fine-grained emotions and strengths derived from prompts. Additionally, a crafted dataset is harnessed to enhance emotion comprehension within prompts. Experiments show the effectiveness of EmoTalker in generating high-quality, emotionally customizable facial expressions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2024)"
    },
    {
        "paper id": "2401.08077",
        "abstract url": "https://arxiv.org/abs/2401.08077",
        "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2401.08081",
        "abstract url": "https://arxiv.org/abs/2401.08081",
        "title": "Predicting Next Useful Location With Context-Awareness: The State-Of-The-Art",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predicting the future location of mobile objects reinforces location-aware services with proactive intelligence and helps businesses and decision-makers with better planning and near real-time scheduling in different applications such as traffic congestion control, location-aware advertisements, and monitoring public health and well-being. The recent developments in the smartphone and location sensors technology and the prevalence of using location-based social networks alongside the improvements in artificial intelligence and machine learning techniques provide an excellent opportunity to exploit massive amounts of historical and real-time contextual information to recognise mobility patterns and achieve more accurate and intelligent predictions. This survey provides a comprehensive overview of the next useful location prediction problem with context-awareness. First, we explain the concepts of context and context-awareness and define the next location prediction problem. Then we analyse nearly thirty studies in this field concerning the prediction method, the challenges addressed, the datasets and metrics used for training and evaluating the model, and the types of context incorporated. Finally, we discuss the advantages and disadvantages of different approaches, focusing on the usefulness of the predicted location and identifying the open challenges and future work on this subject by introducing two potential use cases of next location prediction in the automotive industry.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01666",
        "abstract url": "https://arxiv.org/abs/2402.01666",
        "title": "A Comprehensive Exploration of Personalized Learning in Smart Education: From Student Modeling to Personalized Recommendations",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "With the development of artificial intelligence, personalized learning has attracted much attention as an integral part of intelligent education. China, the United States, the European Union, and others have put forward the importance of personalized learning in recent years, emphasizing the realization of the organic combination of large-scale education and personalized training. The development of a personalized learning system oriented to learners' preferences and suited to learners' needs should be accelerated. This review provides a comprehensive analysis of the current situation of personalized learning and its key role in education. It discusses the research on personalized learning from multiple perspectives, combining definitions, goals, and related educational theories to provide an in-depth understanding of personalized learning from an educational perspective, analyzing the implications of different theories on personalized learning, and highlighting the potential of personalized learning to meet the needs of individuals and to enhance their abilities. Data applications and assessment indicators in personalized learning are described in detail, providing a solid data foundation and evaluation system for subsequent research. Meanwhile, we start from both student modeling and recommendation algorithms and deeply analyze the cognitive and non-cognitive perspectives and the contribution of personalized recommendations to personalized learning. Finally, we explore the challenges and future trajectories of personalized learning. This review provides a multidimensional analysis of personalized learning through a more comprehensive study, providing academics and practitioners with cutting-edge explorations to promote continuous progress in the field of personalized learning.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "82 pages,5 figures"
    },
    {
        "paper id": "2402.01668",
        "abstract url": "https://arxiv.org/abs/2402.01668",
        "title": "Determining the Difficulties of Students With Dyslexia via Virtual Reality and Artificial Intelligence: An Exploratory Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Learning disorders are neurological conditions that affect the brain's ability to interconnect communication areas. Dyslexic students experience problems with reading, memorizing, and exposing concepts; however the magnitude of these can be mitigated through both therapies and the creation of compensatory mechanisms. Several efforts have been made to mitigate these issues, leading to the creation of digital resources for students with specific learning disorders attending primary and secondary education levels. Conversely, a standard approach is still missed in higher education. The VRAIlexia project has been created to tackle this issue by proposing two different tools: a mobile application integrating virtual reality (VR) to collect data quickly and easily, and an artificial intelligencebased software (AI) to analyze the collected data for customizing the supporting methodology for each student. The first one has been created and is being distributed among dyslexic students in Higher Education Institutions, for the conduction of specific psychological and psychometric tests. The second tool applies specific artificial intelligence algorithms to the data gathered via the application and other surveys. These AI techniques have allowed us to identify the most relevant difficulties faced by the students' cohort. Our different models have obtained around 90\\% mean accuracy for predicting the support tools and learning strategies.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "7 pages, 5 figures, 3 tables, MetroXRAINE 2022 Conference, VRAILEXIA european project"
    },
    {
        "paper id": "2401.07487",
        "abstract url": "https://arxiv.org/abs/2401.07487",
        "title": "Robo-ABC: Affordance Generalization Beyond Categories via Semantic Correspondence for Robot Manipulation",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Enabling robotic manipulation that generalizes to out-of-distribution scenes is a crucial step toward open-world embodied intelligence. For human beings, this ability is rooted in the understanding of semantic correspondence among objects, which naturally transfers the interaction experience of familiar objects to novel ones. Although robots lack such a reservoir of interaction experience, the vast availability of human videos on the Internet may serve as a valuable resource, from which we extract an affordance memory including the contact points. Inspired by the natural way humans think, we propose Robo-ABC: when confronted with unfamiliar objects that require generalization, the robot can acquire affordance by retrieving objects that share visual or semantic similarities from the affordance memory. The next step is to map the contact points of the retrieved objects to the new object. While establishing this correspondence may present formidable challenges at first glance, recent research finds it naturally arises from pre-trained diffusion models, enabling affordance mapping even across disparate object categories. Through the Robo-ABC framework, robots may generalize to manipulate out-of-category objects in a zero-shot manner without any manual annotation, additional training, part segmentation, pre-coded knowledge, or viewpoint restrictions. Quantitatively, Robo-ABC significantly enhances the accuracy of visual affordance retrieval by a large margin of 31.6% compared to state-of-the-art (SOTA) end-to-end affordance models. We also conduct real-world experiments of cross-category object-grasping tasks. Robo-ABC achieved a success rate of 85.7%, proving its capacity for real-world tasks.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07489",
        "abstract url": "https://arxiv.org/abs/2401.07489",
        "title": "The Principle of Minimum Pressure Gradient: An Alternative Basis for Physics-Informed Learning of Incompressible Fluid Mechanics",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "Recent advances in the application of physics-informed learning into the field of fluid mechanics have been predominantly grounded in the Newtonian framework, primarly leveraging Navier-Stokes Equation or one of its various derivative to train a neural network. Here, we propose an alternative approach based on variational methods. The proposed approach uses the principle of minimum pressure gradient combined with the continuity constraint to train a neural network and predict the flow field in incompressible fluids. We describe the underlying principles of the proposed approach, then use a demonstrative example to illustrate its implementation and show that it reduces the computational time per training epoch when compared to the conventional approach.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07517",
        "abstract url": "https://arxiv.org/abs/2401.07517",
        "title": "Multi-Protocol Location Forwarding (MPLF) for Space Routing",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "The structure and routing architecture design is critical for achieving low latency and high capacity in future LEO space networks (SNs). Existing studies mainly focus on topologies of space networks, but there is a lack of analysis on constellation structures, which can greatly affect network performance. In addition, some routing architectures are designed for networks with a small number of network nodes such as Iridium while they introduce significant network overhead for high-density networks (i.e., mega-constellation networks containing thousands of satellites). In this paper, we conduct the quantitatively study on the design of network structure and routing architecture in space. The high density, high dynamics, and large scale nature of emerging Space Networks (SNs) pose significant challenges, such as unstable routing paths, low network reachability, high latency, and large jitter. To alleviate the above challenges, we design the structure of space network to maximum the connectivity through wisely adjusting the inter-plane inter satellite link. We further propose Multi-Protocol Location Forwarding (MPLF), a distributed routing architecture, targeting at minimizing the propagation latency with a distributed, convergence-free routing paradigm, while keeping routing stable and maximum the path diversity. Comprehensive experiments are conducted on a customized platform \\textit{Space Networking Kits} (SNK) which demonstrate that our solution can outperform existing related schemes by about 14\\% reduction of propagation latency and 66\\% reduction of hops-count on average, while sustaining a high path diversity with only $O(1)$ time complexity.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2401.07519",
        "abstract url": "https://arxiv.org/abs/2401.07519",
        "title": "InstantID: Zero-shot Identity-Preserving Generation in Seconds",
        "rating": "-2",
        "keywords": [
            [
                "diffusion",
                "synthesis",
                "text-to-image"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA. Yet, their real-world applicability is hindered by high storage demands, lengthy fine-tuning processes, and the need for multiple reference images. Conversely, existing ID embedding-based methods, while requiring only a single forward inference, face challenges: they either necessitate extensive fine-tuning across numerous model parameters, lack compatibility with community pre-trained models, or fail to maintain high face fidelity. Addressing these limitations, we introduce InstantID, a powerful diffusion model-based solution. Our plug-and-play module adeptly handles image personalization in various styles using just a single facial image, while ensuring high fidelity. To achieve this, we design a novel IdentityNet by imposing strong semantic and weak spatial conditions, integrating facial and landmark images with textual prompts to steer the image generation. InstantID demonstrates exceptional performance and efficiency, proving highly beneficial in real-world applications where identity preservation is paramount. Moreover, our work seamlessly integrates with popular pre-trained text-to-image diffusion models like SD1.5 and SDXL, serving as an adaptable plugin. Our codes and pre-trained checkpoints will be available at https://github.com/InstantID/InstantID.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Technical Report, project page available at https://instantid.github.io/"
    },
    {
        "paper id": "2401.07521",
        "abstract url": "https://arxiv.org/abs/2401.07521",
        "title": "CREAD: A Classification-Restoration Framework with Error Adaptive Discretization for Watch Time Prediction in Video Recommender Systems",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "The watch time is a significant indicator of user satisfaction in video recommender systems. However, the prediction of watch time as a target variable is often hindered by its highly imbalanced distribution with a scarcity of observations for larger target values and over-populated samples for small values. State-of-the-art watch time prediction models discretize the continuous watch time into a set of buckets in order to consider the distribution of watch time. However, it is highly uninvestigated how these discrete buckets should be created from the continuous watch time distribution, and existing discretization approaches suffer from either a large learning error or a large restoration error. To address this challenge, we propose a Classification-Restoration framework with Error-Adaptive-Discretization (CREAD) to accurately predict the watch time. The proposed framework contains a discretization module, a classification module, and a restoration module. It predicts the watch time through multiple classification problems. The discretization process is a key contribution of the CREAD framework. We theoretically analyze the impacts of the discretization on the learning error and the restoration error, and then propose the error-adaptive discretization (EAD) technique to better balance the two errors, which achieves better performance over traditional discretization approaches. We conduct detailed offline evaluations on a public dataset and an industrial dataset, both showing performance gains through the proposed approach. Moreover, We have fully launched our framework to Kwai App, an online video platform, which resulted in a significant increase in users' video watch time by 0.29% through A/B testing. These results highlight the effectiveness of the CREAD framework in watch time prediction in video recommender systems.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2401.07528",
        "abstract url": "https://arxiv.org/abs/2401.07528",
        "title": "Automatic characterization of boulders on planetary surfaces from high-resolution satellite images",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "Boulders form from a variety of geological processes, which their size, shape, and orientation may help us better understand. Furthermore, they represent potential hazards to spacecraft landing that need to be characterized. However, mapping individual boulders across vast areas is extremely labor-intensive, often limiting the extent over which they are characterized and the statistical robustness of obtained boulder morphometrics. To automate boulder characterization, we use an instance segmentation neural network, Mask R-CNN, to detect and outline boulders in high-resolution satellite images. Our neural network, BoulderNet, was trained from a dataset of > 33,000 boulders in > 750 image tiles from Earth, the Moon, and Mars. BoulderNet not only correctly detects the majority of boulders in images, but it identifies the outline of boulders with high fidelity, achieving average precision and recall values of 72% and 64% relative to manually digitized boulders from the test dataset, when only detections with intersection-over-union ratios > 50% are considered valid. These values are similar to those obtained by human mappers. On Earth, equivalent boulder diameters, aspect ratios, and orientations extracted from predictions were benchmarked against ground measurements and yield values within 15%, 0.20, and 20 degrees of their ground-truth values, respectively. BoulderNet achieves better boulder detection and characterization performance relative to existing methods, providing a versatile open-source tool to characterize entire boulder fields on planetary surfaces.",
        "subjects": [
            "astro-ph.EP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07543",
        "abstract url": "https://arxiv.org/abs/2401.07543",
        "title": "Must: Maximizing Latent Capacity of Spatial Transcriptomics Data",
        "rating": "-2",
        "keywords": [
            [
                "biology"
            ]
        ],
        "abstract": "Spatial transcriptomics (ST) technologies have revolutionized the study of gene expression patterns in tissues by providing multimodality data in transcriptomic, spatial, and morphological, offering opportunities for understanding tissue biology beyond transcriptomics. However, we identify the modality bias phenomenon in ST data species, i.e., the inconsistent contribution of different modalities to the labels leads to a tendency for the analysis methods to retain the information of the dominant modality. How to mitigate the adverse effects of modality bias to satisfy various downstream tasks remains a fundamental challenge. This paper introduces Multiple-modality Structure Transformation, named MuST, a novel methodology to tackle the challenge. MuST integrates the multi-modality information contained in the ST data effectively into a uniform latent space to provide a foundation for all the downstream tasks. It learns intrinsic local structures by topology discovery strategy and topology fusion loss function to solve the inconsistencies among different modalities. Thus, these topology-based and deep learning techniques provide a solid foundation for a variety of analytical tasks while coordinating different modalities. The effectiveness of MuST is assessed by performance metrics and biological significance. The results show that it outperforms existing state-of-the-art methods with clear advantages in the precision of identifying and preserving structures of tissues and biomarkers. MuST offers a versatile toolkit for the intricate analysis of complex biological systems.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "30 pages and 6 figures, plus 27 pages and 14 figures in appendices"
    },
    {
        "paper id": "2401.07558",
        "abstract url": "https://arxiv.org/abs/2401.07558",
        "title": "FedRFQ: Prototype-Based Federated Learning with Reduced Redundancy, Minimal Failure, and Enhanced Quality",
        "rating": "-2",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Federated learning is a powerful technique that enables collaborative learning among different clients. Prototype-based federated learning is a specific approach that improves the performance of local models under non-IID (non-Independently and Identically Distributed) settings by integrating class prototypes. However, prototype-based federated learning faces several challenges, such as prototype redundancy and prototype failure, which limit its accuracy. It is also susceptible to poisoning attacks and server malfunctions, which can degrade the prototype quality. To address these issues, we propose FedRFQ, a prototype-based federated learning approach that aims to reduce redundancy, minimize failures, and improve \\underline{q}uality. FedRFQ leverages a SoftPool mechanism, which effectively mitigates prototype redundancy and prototype failure on non-IID data. Furthermore, we introduce the BFT-detect, a BFT (Byzantine Fault Tolerance) detectable aggregation algorithm, to ensure the security of FedRFQ against poisoning attacks and server malfunctions. Finally, we conduct experiments on three different datasets, namely MNIST, FEMNIST, and CIFAR-10, and the results demonstrate that FedRFQ outperforms existing baselines in terms of accuracy when handling non-IID data.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07579",
        "abstract url": "https://arxiv.org/abs/2401.07579",
        "title": "PMFSNet: Polarized Multi-scale Feature Self-attention Network For Lightweight Medical Image Segmentation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "CT",
                "skin lesions"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current state-of-the-art medical image segmentation methods prioritize accuracy but often at the expense of increased computational demands and larger model sizes. Applying these large-scale models to the relatively limited scale of medical image datasets tends to induce redundant computation, complicating the process without the necessary benefits. This approach not only adds complexity but also presents challenges for the integration and deployment of lightweight models on edge devices. For instance, recent transformer-based models have excelled in 2D and 3D medical image segmentation due to their extensive receptive fields and high parameter count. However, their effectiveness comes with a risk of overfitting when applied to small datasets and often neglects the vital inductive biases of Convolutional Neural Networks (CNNs), essential for local feature representation. In this work, we propose PMFSNet, a novel medical imaging segmentation model that effectively balances global and local feature processing while avoiding the computational redundancy typical in larger models. PMFSNet streamlines the UNet-based hierarchical structure and simplifies the self-attention mechanism's computational complexity, making it suitable for lightweight applications. It incorporates a plug-and-play PMFS block, a multi-scale feature enhancement module based on attention mechanisms, to capture long-term dependencies. Extensive comprehensive results demonstrate that even with a model (less than 1 million parameters), our method achieves superior performance in various segmentation tasks across different data scales. It achieves (IoU) metrics of 84.68%, 82.02%, and 78.82% on public datasets of teeth CT (CBCT), ovarian tumors ultrasound(MMOTU), and skin lesions dermoscopy images (ISIC 2018), respectively. The source code is available at https://github.com/yykzjh/PMFSNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07583",
        "abstract url": "https://arxiv.org/abs/2401.07583",
        "title": "Small Quantum Codes from Algebraic Extensions of Generalized Bicycle Codes",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum error correction is rapidly seeing first experimental implementations, but there is a significant gap between asymptotically optimal error-correcting codes and codes that are experimentally feasible. Quantum LDPC codes range from the surface code, which has a vanishing encoding rate, to very promising codes with constant encoding rate and linear distance. In this work, motivated by current small-scale experimental quantum processing units, we devise small quantum codes that are inspired by a subset of quantum LDPC codes, known as generalized bicycle (GB) codes. We introduce a code construction based on algebraic manipulation of the parity-check matrix of GB codes, rather than manipulation of Tanner graphs. Our construction leads to families of quantum LDPC codes of small size, and we demonstrate numerically that their performance scales comparably to the performance of surface codes for similar sizes under a phenomenological noise model. The advantage of our code family is that they encode many logical qubits in one code, at the expense of non-local connectivity. We then explore three variants of the code construction focusing on reducing the long-range connectivity by bringing it closer to the current experimental capabilities of short-range connectivity devices.",
        "subjects": [
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07589",
        "abstract url": "https://arxiv.org/abs/2401.07589",
        "title": "Semantic Scene Segmentation for Robotics",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "Robotics",
                "robot"
            ]
        ],
        "abstract": "Comprehensive scene understanding is a critical enabler of robot autonomy. Semantic segmentation is one of the key scene understanding tasks which is pivotal for several robotics applications including autonomous driving, domestic service robotics, last mile delivery, amongst many others. Semantic segmentation is a dense prediction task that aims to provide a scene representation in which each pixel of an image is assigned a semantic class label. Therefore, semantic segmentation considers the full scene context, incorporating the object category, location, and shape of all the scene elements, including the background. Numerous algorithms have been proposed for semantic segmentation over the years. However, the recent advances in deep learning combined with the boost in the computational capacity and the availability of large-scale labeled datasets have led to significant advances in semantic segmentation. In this chapter, we introduce the task of semantic segmentation and present the deep learning techniques that have been proposed to address this task over the years. We first define the task of semantic segmentation and contrast it with other closely related scene understanding problems. We detail different algorithms and architectures for semantic segmentation and the commonly employed loss functions. Furthermore, we present an overview of datasets, benchmarks, and metrics that are used in semantic segmentation. We conclude the chapter with a discussion of challenges and opportunities for further research in this area.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07603",
        "abstract url": "https://arxiv.org/abs/2401.07603",
        "title": "Multi-task real-robot data with gaze attention for dual-arm fine manipulation",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "In the field of robotic manipulation, deep imitation learning is recognized as a promising approach for acquiring manipulation skills. Additionally, learning from diverse robot datasets is considered a viable method to achieve versatility and adaptability. In such research, by learning various tasks, robots achieved generality across multiple objects. However, such multi-task robot datasets have mainly focused on single-arm tasks that are relatively imprecise, not addressing the fine-grained object manipulation that robots are expected to perform in the real world. This paper introduces a dataset of diverse object manipulations that includes dual-arm tasks and/or tasks requiring fine manipulation. To this end, we have generated dataset with 224k episodes (150 hours, 1,104 language instructions) which includes dual-arm fine tasks such as bowl-moving, pencil-case opening or banana-peeling, and this data is publicly available. Additionally, this dataset includes visual attention signals as well as dual-action labels, a signal that separates actions into a robust reaching trajectory and precise interaction with objects, and language instructions to achieve robust and precise object manipulation. We applied the dataset to our Dual-Action and Attention (DAA), a model designed for fine-grained dual arm manipulation tasks and robust against covariate shifts. The model was tested with over 7k total trials in real robot manipulation tasks, demonstrating its capability in fine manipulation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "10 pages, The dataset is available at https://sites.google.com/view/multi-task-fine"
    },
    {
        "paper id": "2401.07644",
        "abstract url": "https://arxiv.org/abs/2401.07644",
        "title": "Resource Allocation in STAR-RIS-Aided SWIPT with RSMA via Meta-Learning",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) is a cutting-edge concept for the sixth-generation (6G) wireless networks. In this paper, we propose a novel system that incorporates STAR-RIS with simultaneous wireless information and power transfer (SWIPT) using rate splitting multiple access (RSMA). The proposed system facilitates communication from a multi-antenna base station (BS) to single-antenna users in a downlink transmission. The BS concurrently sends energy and information signals to multiple energy harvesting receivers (EHRs) and information data receivers (IDRs) with the support of a deployed STAR-RIS. Furthermore, an optimization is introduced to strike a balance between users' sum rate and the total harvested energy. To achieve this, an optimization problem is formulated to optimize the energy/information beamforming vectors at the BS, the phase shifts at the STAR-RIS, and the common message rate. Subsequently, we employ a meta deep deterministic policy gradient (Meta-DDPG) approach to solve the complex problem. Simulation results validate that the proposed algorithm significantly enhances both data rate and harvested energy in comparison to conventional DDPG.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07646",
        "abstract url": "https://arxiv.org/abs/2401.07646",
        "title": "Multifractal-spectral features enhance classification of anomalous diffusion",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "trajectory"
            ]
        ],
        "abstract": "Anomalous diffusion processes pose a unique challenge in classification and characterization. Previously (Mangalam et al., 2023, Physical Review Research 5, 023144), we established a framework for understanding anomalous diffusion using multifractal formalism. The present study delves into the potential of multifractal spectral features for effectively distinguishing anomalous diffusion trajectories from five widely used models: fractional Brownian motion, scaled Brownian motion, continuous time random walk, annealed transient time motion, and L\u00e9vy walk. To accomplish this, we generate extensive datasets comprising $10^6$ trajectories from these five anomalous diffusion models and extract multiple multifractal spectra from each trajectory. Our investigation entails a thorough analysis of neural network performance, encompassing features derived from varying numbers of spectra. Furthermore, we explore the integration of multifractal spectra into traditional feature datasets, enabling us to assess their impact comprehensively. To ensure a statistically meaningful comparison, we categorize features into concept groups and train neural networks using features from each designated group. Notably, several feature groups demonstrate similar levels of accuracy, with the highest performance observed in groups utilizing moving-window characteristics and $p$-variation features. Multifractal spectral features, particularly those derived from three spectra involving different timescales and cutoffs, closely follow, highlighting their robust discriminatory potential. Remarkably, a neural network exclusively trained on features from a single multifractal spectrum exhibits commendable performance, surpassing other feature groups. Our findings underscore the diverse and potent efficacy of multifractal spectral features in enhancing classification of anomalous diffusion.",
        "subjects": [
            "nlin.AO"
        ],
        "comment": "23 pages, 6 figures"
    },
    {
        "paper id": "2401.07655",
        "abstract url": "https://arxiv.org/abs/2401.07655",
        "title": "MLAD: A Unified Model for Multi-system Log Anomaly Detection",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "In spite of the rapid advancements in unsupervised log anomaly detection techniques, the current mainstream models still necessitate specific training for individual system datasets, resulting in costly procedures and limited scalability due to dataset size, thereby leading to performance bottlenecks. Furthermore, numerous models lack cognitive reasoning capabilities, posing challenges in direct transferability to similar systems for effective anomaly detection. Additionally, akin to reconstruction networks, these models often encounter the \"identical shortcut\" predicament, wherein the majority of system logs are classified as normal, erroneously predicting normal classes when confronted with rare anomaly logs due to reconstruction errors. To address the aforementioned issues, we propose MLAD, a novel anomaly detection model that incorporates semantic relational reasoning across multiple systems. Specifically, we employ Sentence-bert to capture the similarities between log sequences and convert them into highly-dimensional learnable semantic vectors. Subsequently, we revamp the formulas of the Attention layer to discern the significance of each keyword in the sequence and model the overall distribution of the multi-system dataset through appropriate vector space diffusion. Lastly, we employ a Gaussian mixture model to highlight the uncertainty of rare words pertaining to the \"identical shortcut\" problem, optimizing the vector space of the samples using the maximum expectation model. Experiments on three real-world datasets demonstrate the superiority of MLAD.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07658",
        "abstract url": "https://arxiv.org/abs/2401.07658",
        "title": "Robustness Evaluation of Localization Techniques for Autonomous Racing",
        "rating": "-2",
        "keywords": [
            [
                "vehicle",
                "SLAM"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "This work introduces SynPF, an MCL-based algorithm tailored for high-speed racing environments. Benchmarked against Cartographer, a state-of-the-art pose-graph SLAM algorithm, SynPF leverages synergies from previous particle-filtering methods and synthesizes them for the high-performance racing domain. Our extensive in-field evaluations reveal that while Cartographer excels under nominal conditions, it struggles when subjected to wheel-slip, a common phenomenon in a racing scenario due to varying grip levels and aggressive driving behaviour. Conversely, SynPF demonstrates robustness in these challenging conditions and a low-latency computation time of 1.25 ms on on-board computers without a GPU. Using the F1TENTH platform, a 1:10 scaled autonomous racing vehicle, this work not only highlights the vulnerabilities of existing algorithms in high-speed scenarios, tested up until 7.6 m/s, but also emphasizes the potential of SynPF as a viable alternative, especially in deteriorating odometry conditions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at the Design, Automation and Test in Europe Conference 2024 as an extended abstract"
    },
    {
        "paper id": "2401.07663",
        "abstract url": "https://arxiv.org/abs/2401.07663",
        "title": "Selene: Pioneering Automated Proof in Software Verification",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Ensuring correctness is a pivotal aspect of software engineering. Among the various strategies available, software verification offers a definitive assurance of correctness. Nevertheless, writing verification proofs is resource-intensive and manpower-consuming, and there is a great need to automate this process. We introduce Selene in this paper, which is the first project-level automated proof benchmark constructed based on the real-world industrial-level project of the seL4 operating system microkernel. Selene provides a comprehensive framework for end-to-end evaluation and a lightweight verification environment. Our experimental results with advanced LLMs, such as GPT-3.5-turbo and GPT-4, highlight the capabilities of large language models (LLMs) in the domain of automated proof generation. Additionally, our further proposed augmentations indicate that the challenges presented by Selene can be mitigated in future research endeavors.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07683",
        "abstract url": "https://arxiv.org/abs/2401.07683",
        "title": "Assisted Knowledge Graph Authoring: Human-Supervised Knowledge Graph Construction from Natural Language",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Encyclopedic knowledge graphs, such as Wikidata, host an extensive repository of millions of knowledge statements. However, domain-specific knowledge from fields such as history, physics, or medicine is significantly underrepresented in those graphs. Although few domain-specific knowledge graphs exist (e.g., Pubmed for medicine), developing specialized retrieval applications for many domains still requires constructing knowledge graphs from scratch. To facilitate knowledge graph construction, we introduce WAKA: a Web application that allows domain experts to create knowledge graphs through the medium with which they are most familiar: natural language.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "accepted at CHIIR 2024"
    },
    {
        "paper id": "2401.07685",
        "abstract url": "https://arxiv.org/abs/2401.07685",
        "title": "A Human-Powered Public Display that Nudges Social Biking via Motion Gesturing",
        "rating": "-2",
        "keywords": [
            [
                "grammar"
            ]
        ],
        "abstract": "The WeWatt bike serves as an energy station that enables passers-by to charge their mobile devices through physical activity. However, despite multiple people using it simultaneously, the bike is typically used individually. To address this limitation, we developed the WeWattTree, an installation utilising human-powered energy to filter environmental air. Through the orchestration of subtle motion gestures, our goal is to entice passers-by to participate and encourage them to socially interact, synchronising their pace. In this work-in-progress, we provide insights into the prototyping process, combining physical experimentation and computational simulation, and delve into the underlying concepts of our grammar of motion gestures. We highlight how a single design effectively merged multiple functionalities, how the role of material characteristics shaped the interaction design, and discuss the potential for social performances as captivating public displays.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07691",
        "abstract url": "https://arxiv.org/abs/2401.07691",
        "title": "Privacy-Aware Single-Nucleotide Polymorphisms (SNPs) using Bilinear Group Accumulators in Batch Mode",
        "rating": "-2",
        "keywords": [
            [
                "Biometric",
                "DNA"
            ]
        ],
        "abstract": "Biometric data is often highly sensitive, and a leak of this data can lead to serious privacy breaches. Some of the most sensitive of this type of data relates to the usage of DNA data on individuals. A leak of this type of data without consent could lead to privacy breaches of data protection laws. Along with this, there have been several recent data breaches related to the leak of DNA information, including from 23andMe and Ancestry. It is thus fundamental that a citizen should have the right to know if their DNA data is contained within a DNA database and ask for it to be removed if they are concerned about its usage. This paper outlines a method of hashing the core information contained within the data stores - known as Single-Nucleotide Polymorphisms (SNPs) - into a bilinear group accumulator in batch mode, which can then be searched by a trusted entity for matches. The time to create the witness proof and to verify were measured at 0.86 ms and 10.90 ms, respectively.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07700",
        "abstract url": "https://arxiv.org/abs/2401.07700",
        "title": "From OTFS to AFDM: A Comparative Study of Next-Generation Waveforms for ISAC in Doubly-Dispersive Channels",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Next-generation wireless systems will offer integrated sensing and communications (ISAC) functionalities not only in order to enable new applications, but also as a means to mitigate challenges such as doubly-dispersive channels, which arise in high mobility scenarios and/or at millimeter-wave (mmWave) and Terahertz (THz) bands. An emerging approach to accomplish these goals is the design of new waveforms, which draw from the inherent relationship between the doubly-dispersive nature of time-variant (TV) channels and the environmental features of scatterers manifested in the form of multi-path delays and Doppler shifts. Examples of such waveforms are the delay-Doppler domain orthogonal time frequency space (OTFS) and the recently proposed chirp domain affine frequency division multiplexing (AFDM), both of which seek to simultaneously combat the detrimental effects of double selectivity and exploit them for the estimation (or sensing) of environmental information. This article aims to provide a consolidated and comprehensive overview of the signal processing techniques required to support reliable ISAC over doubly-dispersive channels in beyond fifth generation (B5G)/sixth generation (6G) systems, with an emphasis on OTFS and AFDM waveforms, as those, together with the traditional orthogonal frequency division multiplexing (OFDM) waveform, suffice to elaborate on the most relevant properties of the trend. The analysis shows that OTFS and AFDM indeed enable significantly improved robustness against inter-carrier interference (ICI) arising from Doppler shifts compared to OFDM. In addition, the inherent delay-Doppler domain orthogonality of the OTFS and AFDM effective channels is found to provide significant advantages for the design and the performance of integrated sensing functionalities.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07725",
        "abstract url": "https://arxiv.org/abs/2401.07725",
        "title": "Effects Investigation of MAC and PHY Layer Parameters on the Performance of IEEE 802.15.6 CSMA/CA",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "The recently released IEEE 802.15.6 standard specifies several physical (PHY) layer and medium access control (MAC) layer protocols for variety of medical and non-medical applications of Wireless Body Area Networks (WBAN). The most suitable way for enhancing network performance is to be the choice of different MAC and PHY parameters based on quality of service (QoS) requirements of different applications. The impact of different MAC and PHY parameters on the network performance and the trade-off relationship between the parameters are essential to overcome the limitations of exiting carrier sense multiple access with collision avoidance (CSMA/CA) scheme of IEEE 802.15.6 standard. To address this issue, we develop a Markov chain-based analytical model of IEEE 802.15.6 CSMA/CA for all user priorities (UPs) and apply this general model to different network scenarios to investigate the effects of the packet arrival rate, channel condition, payload size, access phase length, access mechanism and number of nodes on the performance parameters viz. reliability, normalized throughput, energy consumption and average access delay. Moreover, we conclude the effectiveness of different access phases, access mechanisms and user priorities of intra-WBAN.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "22 pages. arXiv admin note: substantial text overlap with arXiv:2209.00247"
    },
    {
        "paper id": "2401.07726",
        "abstract url": "https://arxiv.org/abs/2401.07726",
        "title": "Preserving Power Optimizations Across the High Level Synthesis of Distinct Application-Specific Circuits",
        "rating": "-2",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "We evaluate the use of software interpretation to push High Level Synthesis of application-specific accelerators toward a higher level of abstraction. Our methodology is supported by a formal power consumption model that computes the power consumption of accelerator components, accurately predicting the power consumption on new designs from prior optimization estimations. We demonstrate how our approach simplifies the re-use of power optimizations across distinct designs, by leveraging the higher level of design abstraction, using two accelerators representative of the robotics domain, implemented through the Bambu High Level Synthesis tool. Results support the research hypothesis, achieving predictions accurate within +/- 1%.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07729",
        "abstract url": "https://arxiv.org/abs/2401.07729",
        "title": "SSL-Interactions: Pretext Tasks for Interactive Trajectory Prediction",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "forecasting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper addresses motion forecasting in multi-agent environments, pivotal for ensuring safety of autonomous vehicles. Traditional as well as recent data-driven marginal trajectory prediction methods struggle to properly learn non-linear agent-to-agent interactions. We present SSL-Interactions that proposes pretext tasks to enhance interaction modeling for trajectory prediction. We introduce four interaction-aware pretext tasks to encapsulate various aspects of agent interactions: range gap prediction, closest distance prediction, direction of movement prediction, and type of interaction prediction. We further propose an approach to curate interaction-heavy scenarios from datasets. This curated data has two advantages: it provides a stronger learning signal to the interaction model, and facilitates generation of pseudo-labels for interaction-centric pretext tasks. We also propose three new metrics specifically designed to evaluate predictions in interactive scenes. Our empirical evaluations indicate SSL-Interactions outperforms state-of-the-art motion forecasting methods quantitatively with up to 8% improvement, and qualitatively, for interaction-heavy scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 5 figures, submitted to IV-2024"
    },
    {
        "paper id": "2401.07733",
        "abstract url": "https://arxiv.org/abs/2401.07733",
        "title": "Conformal Approach To Gaussian Process Surrogate Evaluation With Coverage Guarantees",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Gaussian processes (GPs) are a Bayesian machine learning approach widely used to construct surrogate models for the uncertainty quantification of computer simulation codes in industrial applications. It provides both a mean predictor and an estimate of the posterior prediction variance, the latter being used to produce Bayesian credibility intervals. Interpreting these intervals relies on the Gaussianity of the simulation model as well as the well-specification of the priors which are not always appropriate. We propose to address this issue with the help of conformal prediction. In the present work, a method for building adaptive cross-conformal prediction intervals is proposed by weighting the non-conformity score with the posterior standard deviation of the GP. The resulting conformal prediction intervals exhibit a level of adaptivity akin to Bayesian credibility sets and display a significant correlation with the surrogate model local approximation error, while being free from the underlying model assumptions and having frequentist coverage guarantees. These estimators can thus be used for evaluating the quality of a GP surrogate model and can assist a decision-maker in the choice of the best prior for the specific application of the GP. The performance of the method is illustrated through a panel of numerical examples based on various reference databases. Moreover, the potential applicability of the method is demonstrated in the context of surrogate modeling of an expensive-to-evaluate simulator of the clogging phenomenon in steam generators of nuclear reactors.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07743",
        "abstract url": "https://arxiv.org/abs/2401.07743",
        "title": "Simulating and model checking membrane systems using strategies in Maude",
        "rating": "-2",
        "keywords": [
            [
                "biologically-inspired"
            ]
        ],
        "abstract": "Membrane systems are a biologically-inspired computational model based on the structure of biological cells and the way chemicals interact and traverse their membranes. Although their dynamics are described by rules, encoding membrane systems into rewriting logic is not straightforward due to its complex control mechanisms. Multiple alternatives have been proposed in the literature and implemented in the Maude specification language. The recent release of the Maude strategy language and its associated strategy-aware model checker allow specifying these systems more easily, so that they become executable and verifiable for free. An easily-extensible interactive environment transforms membrane specifications into rewrite theories controlled by appropriate strategies, and allows simulating and verifying membrane computations by means of them.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07746",
        "abstract url": "https://arxiv.org/abs/2401.07746",
        "title": "Sparsity-based background removal for STORM super-resolution images",
        "rating": "-2",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "biological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Single-molecule localization microscopy techniques, like stochastic optical reconstruction microscopy (STORM), visualize biological specimens by stochastically exciting sparse blinking emitters. The raw images suffer from unwanted background fluorescence, which must be removed to achieve super-resolution. We introduce a sparsity-based background removal method by adapting a neural network (SLNet) from a different microscopy domain. The SLNet computes a low-rank representation of the images, and then, by subtracting it from the raw images, the sparse component is computed, representing the frames without the background. We compared our approach with widely used background removal methods, such as the median background removal or the rolling ball algorithm, on two commonly used STORM datasets, one glial cell, and one microtubule dataset. The SLNet delivers STORM frames with less background, leading to higher emitters' localization precision and higher-resolution reconstructed images than commonly used methods. Notably, the SLNet is lightweight and easily trainable (<5 min). Since it is trained in an unsupervised manner, no prior information is required and can be applied to any STORM dataset. We uploaded a pre-trained SLNet to the Bioimage model zoo, easily accessible through ImageJ. Our results show that our sparse decomposition method could be an essential and efficient STORM pre-processing tool.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07769",
        "abstract url": "https://arxiv.org/abs/2401.07769",
        "title": "Deep Evolutional Instant Interest Network for CTR Prediction in Trigger-Induced Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ]
        ],
        "abstract": "The recommendation has been playing a key role in many industries, e.g., e-commerce, streaming media, social media, etc. Recently, a new recommendation scenario, called Trigger-Induced Recommendation (TIR), where users are able to explicitly express their instant interests via trigger items, is emerging as an essential role in many e-commerce platforms, e.g., Alibaba.com and Amazon. Without explicitly modeling the user's instant interest, traditional recommendation methods usually obtain sub-optimal results in TIR. Even though there are a few methods considering the trigger and target items simultaneously to solve this problem, they still haven't taken into account temporal information of user behaviors, the dynamic change of user instant interest when the user scrolls down and the interactions between the trigger and target items. To tackle these problems, we propose a novel method -- Deep Evolutional Instant Interest Network (DEI2N), for click-through rate prediction in TIR scenarios. Specifically, we design a User Instant Interest Modeling Layer to predict the dynamic change of the intensity of instant interest when the user scrolls down. Temporal information is utilized in user behavior modeling. Moreover, an Interaction Layer is introduced to learn better interactions between the trigger and target items. We evaluate our method on several offline and real-world industrial datasets. Experimental results show that our proposed DEI2N outperforms state-of-the-art baselines. In addition, online A/B testing demonstrates the superiority over the existing baseline in real-world production environments.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "7 pages, 3 figures, accepted by the 17th ACM International Conference on Web Search and Data Mining(WSDM'2024)"
    },
    {
        "paper id": "2401.07784",
        "abstract url": "https://arxiv.org/abs/2401.07784",
        "title": "Certifiable Mutual Localization and Trajectory Planning for Bearing-Based Robot Swarm",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Bearing measurements,as the most common modality in nature, have recently gained traction in multi-robot systems to enhance mutual localization and swarm collaboration. Despite their advantages, challenges such as sensory noise, obstacle occlusion, and uncoordinated swarm motion persist in real-world scenarios, potentially leading to erroneous state estimation and undermining the system's flexibility, practicality, and robustness.In response to these challenges, in this paper we address theoretical and practical problem related to both mutual localization and swarm planning.Firstly, we propose a certifiable mutual localization algorithm.It features a concise problem formulation coupled with lossless convex relaxation, enabling independence from initial values and globally optimal relative pose recovery.Then, to explore how detection noise and swarm motion influence estimation optimality, we conduct a comprehensive analysis on the interplay between robots' mutual spatial relationship and mutual localization. We develop a differentiable metric correlated with swarm trajectories to explicitly evaluate the noise resistance of optimal estimation.By establishing a finite and pre-computable threshold for this metric and accordingly generating swarm trajectories, the estimation optimality can be strictly guaranteed under arbitrary noise. Based on these findings, an optimization-based swarm planner is proposed to generate safe and smooth trajectories, with consideration of both inter-robot visibility and estimation optimality.Through numerical simulations, we evaluate the optimality and certifiablity of our estimator, and underscore the significance of our planner in enhancing estimation performance.The results exhibit considerable potential of our methods to pave the way for advanced closed-loop intelligence in swarm systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07791",
        "abstract url": "https://arxiv.org/abs/2401.07791",
        "title": "Near-Far Field Channel Modeling for Holographic MIMO Using Expectation-Maximization Methods",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Holographic Multiple-Input Multiple-Output (HMIMO), which densely integrates numerous antennas into a limited space, is anticipated to provide higher rates for future 6G wireless communications. The increase in antenna aperture size makes the near-field region enlarge, causing some users to be located in the near-field region. Thus, we are facing a hybrid near-field and far-field communication problem, where conventional far-field modeling methods may not work well. In this paper, we propose a near-far field channel model that does not presuppose whether each path is near-field or far-field, different from the existing work requiring the ratio of the number of near-field paths to that of far-field paths as prior knowledge. However, this gives rise to a new challenge for accurately modeling the channel, as conventional methods of obtaining channel model parameters are not applicable to this model. Therefore, we propose a new method, Expectation-Maximization (EM)-based Near-Far Field Channel Modeling, to obtain channel model parameters, which considers whether each path is near-field or far-field as a hidden variable, and optimizes the hidden variables and channel model parameters through an alternating iteration method. Simulation results show that our method is superior to conventional near-field and far-field algorithms in fitting the near-far field channel in terms of outage probability.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07805",
        "abstract url": "https://arxiv.org/abs/2401.07805",
        "title": "A consistent diffuse-interface model for two-phase flow problems with rapid evaporation",
        "rating": "-2",
        "keywords": [
            [
                "thermal"
            ]
        ],
        "abstract": "We present accurate and mathematically consistent formulations of a diffuse-interface model for two-phase flow problems involving rapid evaporation. The model addresses challenges including discontinuities in the density field by several orders of magnitude, leading to high velocity and pressure jumps across the liquid-vapor interface, along with dynamically changing interface topologies. To this end, we integrate an incompressible Navier--Stokes solver combined with a conservative level-set formulation and a regularized, i.e., diffuse, representation of discontinuities into a matrix-free adaptive finite element framework. The achievements are three-fold: First, this work proposes mathematically consistent definitions for the level-set transport velocity in the diffuse interface region by extrapolating the velocity from the liquid or gas phase, which exhibit superior prediction accuracy for the evaporated mass and the resulting interface dynamics compared to a local velocity evaluation, especially for highly curved interfaces. Second, we show that accurate prediction of the evaporation-induced pressure jump requires a consistent, namely a reciprocal, density interpolation across the interface, which satisfies local mass conservation. Third, the combination of diffuse interface models for evaporation with standard Stokes-type constitutive relations for viscous flows leads to significant pressure artifacts in the diffuse interface region. To mitigate these, we propose a modification for such constitutive model types. Through selected analytical and numerical examples, the aforementioned properties are validated. The presented model promises new insights in simulation-based prediction of melt-vapor interactions in thermal multiphase flows such as in laser-based powder bed fusion of metals.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "52 pages, 19 figures"
    },
    {
        "paper id": "2401.07825",
        "abstract url": "https://arxiv.org/abs/2401.07825",
        "title": "Phenotyping calcification in vascular tissues using artificial intelligence",
        "rating": "-2",
        "keywords": [
            [
                "attack"
            ],
            [
                "CT",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vascular calcification is implicated as an important factor in major adverse cardiovascular events (MACE), including heart attack and stroke. A controversy remains over how to integrate the diverse forms of vascular calcification into clinical risk assessment tools. Even the commonly used calcium score for coronary arteries, which assumes risk scales positively with total calcification, has important inconsistencies. Fundamental studies are needed to determine how risk is influenced by the diverse calcification phenotypes. However, studies of these kinds are hindered by the lack of high-throughput, objective, and non-destructive tools for classifying calcification in imaging data sets. Here, we introduce a new classification system for phenotyping calcification along with a semi-automated, non-destructive pipeline that can distinguish these phenotypes in even atherosclerotic tissues. The pipeline includes a deep-learning-based framework for segmenting lipid pools in noisy micro-CT images and an unsupervised clustering framework for categorizing calcification based on size, clustering, and topology. This approach is illustrated for five vascular specimens, providing phenotyping for thousands of calcification particles across as many as 3200 images in less than seven hours. Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for tissue and lipid pool, respectively, with training and validation needed on only 13 images despite the high heterogeneity in these tissues. By introducing an efficient and comprehensive approach to phenotyping calcification, this work enables large-scale studies to identify a more reliable indicator of the risk of cardiovascular events, a leading cause of global mortality and morbidity.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07841",
        "abstract url": "https://arxiv.org/abs/2401.07841",
        "title": "Online Simulation at Machine Level: A Systematic Review",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "The importance of simulation at machine level in industrial environments is steadily increasing especially in the design and commissioning phase. Using models during the operation phase together with the real machine or plant is referred to as online simulation. Online simulation is used for system monitoring, predictive analyses, decision support or online optimization and therefore has various advantages and a wide field of applications. This paper has the aim to characterize online simulation at machine level in industrial automation focusing on key technologies and common applications. Therefore, a set of 65 relevant publications, which are focusing on this subject, is found by database search, expert consultation, and snowballing. As key technological aspects, the used model types, interfaces and platforms, and the aspects of initialization and synchronization are further investigated. The results are interpreted and limitations, knowledge gaps and future prospects are discussed. The potential of online simulation at machine level especially arises due to the increasing availability of component and machine models from the design and commissioning phase, which can be reused for online simulation. Remaining challenges are identified concerning implementation, simulation platforms, model maintenance and especially in the field of synchronization.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "29 pages, 12 figures, submitted to Springer - The International Journal on Advanced Manufacturing Technology"
    },
    {
        "paper id": "2401.07868",
        "abstract url": "https://arxiv.org/abs/2401.07868",
        "title": "Consolidating Trees of Robotic Plans Generated Using Large Language Models to Improve Reliability",
        "rating": "-2",
        "keywords": [
            [
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "The inherent probabilistic nature of Large Language Models (LLMs) introduces an element of unpredictability, raising concerns about potential discrepancies in their output. This paper introduces an innovative approach aims to generate correct and optimal robotic task plans for diverse real-world demands and scenarios. LLMs have been used to generate task plans, but they are unreliable and may contain wrong, questionable, or high-cost steps. The proposed approach uses LLM to generate a number of task plans as trees and amalgamates them into a graph by removing questionable paths. Then an optimal task tree can be retrieved to circumvent questionable and high-cost nodes, thereby improving planning accuracy and execution efficiency. The approach is further improved by incorporating a large knowledge network. Leveraging GPT-4 further, the high-level task plan is converted into a low-level Planning Domain Definition Language (PDDL) plan executable by a robot. Evaluation results highlight the superior accuracy and efficiency of our approach compared to previous methodologies in the field of task planning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07888",
        "abstract url": "https://arxiv.org/abs/2401.07888",
        "title": "Multifidelity domain decomposition-based physics-informed neural networks for time-dependent problems",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Multiscale problems are challenging for neural network-based discretizations of differential equations, such as physics-informed neural networks (PINNs). This can be (partly) attributed to the so-called spectral bias of neural networks. To improve the performance of PINNs for time-dependent problems, a combination of multifidelity stacking PINNs and domain decomposition-based finite basis PINNs are employed. In particular, to learn the high-fidelity part of the multifidelity model, a domain decomposition in time is employed. The performance is investigated for a pendulum and a two-frequency problem as well as the Allen-Cahn equation. It can be observed that the domain decomposition approach clearly improves the PINN and stacking PINN approaches.",
        "subjects": [
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07892",
        "abstract url": "https://arxiv.org/abs/2401.07892",
        "title": "Deep Fuzzy Framework for Emotion Recognition using EEG Signals and Emotion Representation in Type-2 Fuzzy VAD Space",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "EEG"
            ]
        ],
        "abstract": "Recently, the representation of emotions in the Valence, Arousal and Dominance (VAD) space has drawn enough attention. However, the complex nature of emotions and the subjective biases in self-reported values of VAD make the emotion model too specific to a particular experiment. This study aims to develop a generic model representing emotions using a fuzzy VAD space and improve emotion recognition by utilizing this representation. We partitioned the crisp VAD space into a fuzzy VAD space using low, medium and high type-2 fuzzy dimensions to represent emotions. A framework that integrates fuzzy VAD space with EEG data has been developed to recognize emotions. The EEG features were extracted using spatial and temporal feature vectors from time-frequency spectrograms, while the subject-reported values of VAD were also considered. The study was conducted on the DENS dataset, which includes a wide range of twenty-four emotions, along with EEG data and subjective ratings. The study was validated using various deep fuzzy framework models based on type-2 fuzzy representation, cuboid probabilistic lattice representation and unsupervised fuzzy emotion clusters. These models resulted in emotion recognition accuracy of 96.09\\%, 95.75\\% and 95.31\\%, respectively, for the classes of 24 emotions. The study also included an ablation study, one with crisp VAD space and the other without VAD space. The result with crisp VAD space performed better, while the deep fuzzy framework outperformed both models. The model was extended to predict cross-subject cases of emotions, and the results with 78.37\\% accuracy are promising, proving the generality of our model. The generic nature of the developed model, along with its successful cross-subject predictions, gives direction for real-world applications in the areas such as affective computing, human-computer interaction, and mental health monitoring.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07912",
        "abstract url": "https://arxiv.org/abs/2401.07912",
        "title": "Lower Bounds for Unitary Property Testing with Proofs and Advice",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "In unitary property testing a quantum algorithm, also known as a tester, is given query access to a black-box unitary and has to decide whether it satisfies some property. We propose a new technique for proving lower bounds on the quantum query complexity of unitary property testing and related problems, which utilises the connection between unitary property testing and unitary channel discrimination. The main advantage of this technique is that all obtained lower bounds hold for any $\\mathsf{C}$-tester with $\\mathsf{C} \\subseteq \\mathsf{QMA}(\\text{poly(n)} / \\mathsf{qpoly}$, showing that even having access to both (unentangled) quantum proofs and advice does not help for many unitary problems. We apply our technique to prove lower bounds for problems like quantum phase estimation, the entanglement entropy problem, quantum Gibbs sampling and more, removing all logarithmic factors in the lower bounds obtained by the sample-to-query lifting theorem of Wang and Zhang (2023). As a direct corollary, we show that there exists a quantum oracle relative to which $\\mathsf{QMA}(\\text{poly(n)} / \\mathsf{qpoly} \\not\\supset \\mathsf{SBQP}$.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "23 pages, 1 figure"
    },
    {
        "paper id": "2401.07947",
        "abstract url": "https://arxiv.org/abs/2401.07947",
        "title": "Delivery Line Tracking Robot",
        "rating": "-2",
        "keywords": [
            [
                "infrared"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "The project we embarked on is making an electronic robot that can deliver a package along a set route through infrared sensors. It uses the infrared sensors to determine if the path it is following is correct or if it is off course. This is determined by sending off a photon to reflect off the path and determines if it is on a light surface by the amount of light emitted back or if it is a dark surface by the amount of light that is not present. In addition to following a line, the user can stop and start the robot at any interval through the infrared remote control. The project is a combination of the practical parts of machinery with the software part of coding in Arduino which is a coding subsect of C++. This can lead to endless possibilities that could help a wide variety of people from all ranges of life, especially with those that live with disabilities",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07961",
        "abstract url": "https://arxiv.org/abs/2401.07961",
        "title": "Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\u00f6dinger Bridge and Reaction-Diffusion PDEs",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "flight"
            ]
        ],
        "abstract": "Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection of the OMT with the Schr\u00f6dinger bridge problem (SBP). This also shows that the probabilistic Lambert problem with additive dynamic process noise is in fact a generalized SBP, and can be solved numerically using the so-called Schr\u00f6dinger factors, as we do in this work. We explain how the resulting analysis leads to solving a boundary-coupled system of reaction-diffusion PDEs where the nonlinear gravitational potential appears as the reaction rate. We propose novel algorithms for the same, and present illustrative numerical results. Our analysis and the algorithmic framework are nonparametric, i.e., we make neither statistical (e.g., Gaussian, first few moments, mixture or exponential family, finite dimensionality of the sufficient statistic) nor dynamical (e.g., Taylor series) approximations.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07962",
        "abstract url": "https://arxiv.org/abs/2401.07962",
        "title": "Cesium Tiles for High-realism Simulation and Comparing SLAM Results in Corresponding Virtual and Real-world Environments",
        "rating": "-2",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "This article discusses the use of a simulated environment to predict algorithm results in the real world. Simulators are crucial in allowing researchers to test algorithms, sensor integration, and navigation systems without deploying expensive hardware. This article examines how the AirSim simulator, Unreal Engine, and Cesium plugin can be used to generate simulated digital twin models of real-world locations. Several technical challenges in completing the analysis are discussed and the technical solutions are detailed in this article. Work investigates how to assess mapping results for a real-life experiment using Cesium Tiles provided by digital twins of the experimental location. This is accompanied by a description of a process for duplicating real-world flights in simulation. The performance of these methods is evaluated by analyzing real-life and experimental image telemetry with the Direct Sparse Odometry (DSO) mapping algorithm. Results indicate that Cesium Tiles environments can provide highly accurate models of ground truth geometry after careful alignment. Further, results from real-life and simulated telemetry analysis indicate that the virtual simulation results accurately predict real-life results. Findings indicate that the algorithm results in real life and in the simulated duplicate exhibited a high degree of similarity. This indicates that the use of Cesium Tiles environments as a virtual digital twin for real-life experiments will provide representative results for such algorithms. The impact of this can be significant, potentially allowing expansive virtual testing of robotic systems at specific deployment locations to develop solutions that are tailored to the environment and potentially outperforming solutions meant to work in completely generic environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07994",
        "abstract url": "https://arxiv.org/abs/2401.07994",
        "title": "A Novel Approach for Automatic Program Repair using Round-Trip Translation with Large Language Models",
        "rating": "-2",
        "keywords": [
            [
                "grammatical"
            ]
        ],
        "abstract": "Research shows that grammatical mistakes in a sentence can be corrected by translating it to another language and back using neural machine translation with language models. We investigate whether this correction capability of Large Language Models (LLMs) extends to Automatic Program Repair (APR). Current generative models for APR are pre-trained on source code and fine-tuned for repair. This paper proposes bypassing the fine-tuning step and using Round-Trip Translation (RTT): translation of code from one programming language to another programming or natural language, and back. We hypothesize that RTT with LLMs restores the most commonly seen patterns in code during pre-training, i.e., performs a regression toward the mean, which removes bugs as they are a form of noise w.r.t. the more frequent, natural, bug-free code in the training data. To test this hypothesis, we employ eight recent LLMs pre-trained on code, including the latest GPT versions, and four common program repair benchmarks in Java. We find that RTT with English as an intermediate language repaired 101 of 164 bugs with GPT-4 on the HumanEval-Java dataset. Moreover, 46 of these are unique bugs that are not repaired by other LLMs fine-tuned for APR. Our findings highlight the viability of round-trip translation with LLMs as a technique for automated program repair and its potential for research in software engineering. Keywords: automated program repair, large language model, machine translation",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08020",
        "abstract url": "https://arxiv.org/abs/2401.08020",
        "title": "Belief Miner: A Methodology for Discovering Causal Beliefs and Causal Illusions from General Populations",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "Causal belief is a cognitive practice that humans apply everyday to reason about cause and effect relations between factors, phenomena, or events. Like optical illusions, humans are prone to drawing causal relations between events that are only coincidental (i.e., causal illusions). Researchers in domains such as cognitive psychology and healthcare often use logistically expensive experiments to understand causal beliefs and illusions. In this paper, we propose Belief Miner, a crowdsourcing method for evaluating people's causal beliefs and illusions. Our method uses the (dis)similarities between the causal relations collected from the crowds and experts to surface the causal beliefs and illusions. Through an iterative design process, we developed a web-based interface for collecting causal relations from a target population. We then conducted a crowdsourced experiment with 101 workers on Amazon Mechanical Turk and Prolific using this interface and analyzed the collected data with Belief Miner. We discovered a variety of causal beliefs and potential illusions, and we report the design implications for future research.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08037",
        "abstract url": "https://arxiv.org/abs/2401.08037",
        "title": "Understanding factors behind IoT privacy -- A user's perspective on RF sensors",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "While IoT sensors in physical spaces have provided utility and comfort in our lives, their instrumentation in private and personal spaces has led to growing concerns regarding privacy. The existing notion behind IoT privacy is that the sensors whose data can easily be understood and interpreted by humans (such as cameras) are more privacy-invasive than sensors that are not human-understandable, such as RF (radio-frequency) sensors. However, given recent advancements in machine learning, we can not only make sensitive inferences on RF data but also translate between modalities. Thus, the existing notions of privacy for IoT sensors need to be revisited. In this paper, our goal is to understand what factors affect the privacy notions of a non-expert user (someone who is not well-versed in privacy concepts). To this regard, we conduct an online study of 162 participants from the USA to find out what factors affect the privacy perception of a user regarding an RF-based device or a sensor. Our findings show that a user's perception of privacy not only depends upon the data collected by the sensor but also on the inferences that can be made on that data, familiarity with the device and its form factor as well as the control a user has over the device design and its data policies. When the data collected by the sensor is not human-interpretable, it is the inferences that can be made on the data and not the data itself that users care about when making informed decisions regarding device privacy.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08045",
        "abstract url": "https://arxiv.org/abs/2401.08045",
        "title": "Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF"
            ],
            [
                "diffusion"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI. Models such as SAM, DALL-E2, and GPT-4 showcase their adaptability by extracting intricate patterns and performing effectively across diverse tasks, thereby serving as potent building blocks for a wide range of AI applications. Autonomous driving, a vibrant front in AI applications, remains challenged by the lack of dedicated vision foundation models (VFMs). The scarcity of comprehensive training data, the need for multi-sensor integration, and the diverse task-specific architectures pose significant obstacles to the development of VFMs in this field. This paper delves into the critical challenge of forging VFMs tailored specifically for autonomous driving, while also outlining future directions. Through a systematic analysis of over 250 papers, we dissect essential techniques for VFM development, including data preparation, pre-training strategies, and downstream task adaptation. Moreover, we explore key advancements such as NeRF, diffusion models, 3D Gaussian Splatting, and world models, presenting a comprehensive roadmap for future research. To empower researchers, we have built and maintained https://github.com/zhanghm1995/Forge_VFM4AD, an open-access repository constantly updated with the latest advancements in forging VFMs for autonomous driving.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Github Repo: https://github.com/zhanghm1995/Forge_VFM4AD"
    },
    {
        "paper id": "2401.08104",
        "abstract url": "https://arxiv.org/abs/2401.08104",
        "title": "A Reproducibility Study of Goldilocks: Just-Right Tuning of BERT for TAR",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "Screening documents is a tedious and time-consuming aspect of high-recall retrieval tasks, such as compiling a systematic literature review, where the goal is to identify all relevant documents for a topic. To help streamline this process, many Technology-Assisted Review (TAR) methods leverage active learning techniques to reduce the number of documents requiring review. BERT-based models have shown high effectiveness in text classification, leading to interest in their potential use in TAR workflows. In this paper, we investigate recent work that examined the impact of further pre-training epochs on the effectiveness and efficiency of a BERT-based active learning pipeline. We first report that we could replicate the original experiments on two specific TAR datasets, confirming some of the findings: importantly, that further pre-training is critical to high effectiveness, but requires attention in terms of selecting the correct training epoch. We then investigate the generalisability of the pipeline on a different TAR task, that of medical systematic reviews. In this context, we show that there is no need for further pre-training if a domain-specific BERT backbone is used within the active learning pipeline. This finding provides practical implications for using the studied active learning pipeline within domain-specific TAR tasks.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted at ECIR 2024 (reproducibility)"
    },
    {
        "paper id": "2401.08712",
        "abstract url": "https://arxiv.org/abs/2401.08712",
        "title": "Survival Analysis of Young Triple-Negative Breast Cancer Patients",
        "rating": "-2",
        "keywords": [
            [
                "Survival",
                "Cancer",
                "disease",
                "clinical",
                "tumor"
            ]
        ],
        "abstract": "Breast cancer prognosis is crucial for effective treatment, with the disease more common in women over 40 years old but rare under 40 years old, where less than 5 percent of cases occur in the U.S. Studies indicate a worse prognosis in younger women, which varies by ethnicity. Breast cancers are classified based on receptors like estrogen, progesterone, and HER2. Triple-negative breast cancer (TNBC), lacking these receptors, accounts for about 15 percent of cases and is more prevalent in younger patients, often resulting in poorer outcomes. Nevertheless, the impact of age on TNBC prognosis remains unclear. Factors like age, race, tumor grade, size, and lymph node status are studied for their role in TNBC's clinical outcomes, but current research is inconclusive about age-related differences. This study uses SEER data set to examine the influence of younger age on survivability in TNBC patients, aiming to determine if age is a significant prognostic factor. Our experimental results on SEER dataset confirm the existing research reports that TNBC patients have worse prognosis compared to non-TNBC based on age. Our main goal was to investigate whether younger age has any significance on the survivability of TNBC patients. Experimental results do not show that younger age has any significance on the prognosis and survival rate of the TNBC patients",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": "31 Pages, 11 Figures, 7 Tables, Peer-reviewed article"
    },
    {
        "paper id": "2401.08714",
        "abstract url": "https://arxiv.org/abs/2401.08714",
        "title": "Training program on sign language: social inclusion through Virtual Reality in ISENSE project",
        "rating": "-2",
        "keywords": [
            [
                "sign language"
            ]
        ],
        "abstract": "Structured hand gestures that incorporate visual motions and signs are used in sign language. Sign language is a valuable means of daily communication for individuals who are deaf or have speech impairments, but it is still rare among hearing people, and fewer are capable of understand it. Within the academic context, parents and teachers play a crucial role in supporting deaf students from childhood by facilitating their learning of sign language. In the last years, among all the teaching tools useful for learning sign language, the use of Virtual Reality (VR) has increased, as it has been demonstrated to improve retention, memory and attention during the learning process. The ISENSE project has been created to assist students with deafness during their academic life by proposing different technological tools for teaching sign language to the hearing community in the academic context. As part of the ISENSE project, this work aims to develop an application for Spanish and Italian sign language recognition that exploits the VR environment to quickly and easily create a comprehensive database of signs and an Artificial Intelligence (AI)-based software to accurately classify and recognize static and dynamic signs: from letters to sentences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 pages, 4 figures, MetroXRAINE 2023 Conference, ISENSE european project"
    },
    {
        "paper id": "2401.10154",
        "abstract url": "https://arxiv.org/abs/2401.10154",
        "title": "In Memory of Martin Davis",
        "rating": "-2",
        "keywords": [
            [
                "biographical"
            ]
        ],
        "abstract": "The present paper gives an account for the general mathematical reader of the life and work of Martin Davis. Since two rather comprehensive autobiographical accounts and two long biographical interviews already exist, the present work focusses on Davis's scientific achievements, including work on computably enumerable sets, universal Turing machines, the hyperarithmetical hierarchy, neural networks, Hilbert's Tenth Problem, and automated reasoning.",
        "subjects": [
            "math.HO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10285",
        "abstract url": "https://arxiv.org/abs/2401.10285",
        "title": "Analyzing Brain Activity During Learning Tasks with EEG and Machine Learning",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "This study aimed to analyze brain activity during various STEM activities, exploring the feasibility of classifying between different tasks. EEG brain data from twenty subjects engaged in five cognitive tasks were collected and segmented into 4-second clips. Power spectral densities of brain frequency waves were then analyzed. Testing different k-intervals with XGBoost, Random Forest, and Bagging Classifier revealed that Random Forest performed best, achieving a testing accuracy of 91.07% at an interval size of two. When utilizing all four EEG channels, cognitive flexibility was most recognizable. Task-specific classification accuracy showed the right frontal lobe excelled in mathematical processing and planning, the left frontal lobe in cognitive flexibility and mental flexibility, and the left temporoparietal lobe in connections. Notably, numerous connections between frontal and temporoparietal lobes were observed during STEM activities. This study contributes to a deeper understanding of implementing machine learning in analyzing brain activity and sheds light on the brain's mechanisms.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "20 pages, 7 figures"
    },
    {
        "paper id": "2401.16222",
        "abstract url": "https://arxiv.org/abs/2401.16222",
        "title": "Modelling Solar PV Adoption in Irish Dairy Farms using Agent-Based Modelling",
        "rating": "-2",
        "keywords": [
            [
                "forecast",
                "agricultural"
            ]
        ],
        "abstract": "The agricultural sector is facing mounting demands to enhance energy efficiency within farm enterprises, concurrent with a steady escalation in electricity costs. This paper focuses on modelling the adoption rate of photovoltaic (PV) energy within the dairy sector in Ireland. An agent-based modelling approach is introduced to estimate the adoption rate. The model considers grid energy prices, revenue, costs, and maintenance expenses to calculate the probability of PV adoption. The ABM outputs estimate that by year 2022, 2.45% of dairy farmers have installed PV. This is a 0.45% difference to the actual PV adoption rate in year 2022. This validates the proposed ABM. The paper demonstrates the increasing interest in PV systems as evidenced by the rate of adoption, shedding light on the potential advantages of PV energy adoption in agriculture. This study possesses the potential to forecast future rates of PV energy adoption among dairy farmers. It establishes a groundwork for further research on predicting and understanding the factors influencing the adoption of renewable energy.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01664",
        "abstract url": "https://arxiv.org/abs/2402.01664",
        "title": "Edge Offloading in Smart Grid",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The energy transition supports the shift towards more sustainable energy alternatives, paving towards decentralized smart grids, where the energy is generated closer to the point of use. The decentralized smart grids foresee novel data-driven low latency applications for improving resilience and responsiveness, such as peer-to-peer energy trading, microgrid control, fault detection, or demand response. However, the traditional cloud-based smart grid architectures are unable to meet the requirements of the new emerging applications such as low latency and high-reliability thus alternative architectures such as edge, fog, or hybrid need to be adopted. Moreover, edge offloading can play a pivotal role for the next-generation smart grid AI applications because it enables the efficient utilization of computing resources and addresses the challenges of increasing data generated by IoT devices, optimizing the response time, energy consumption, and network performance. However, a comprehensive overview of the current state of research is needed to support sound decisions regarding energy-related applications offloading from cloud to fog or edge, focusing on smart grid open challenges and potential impacts. In this paper, we delve into smart grid and computational distribution architec-tures, including edge-fog-cloud models, orchestration architecture, and serverless computing, and analyze the decision-making variables and optimization algorithms to assess the efficiency of edge offloading. Finally, the work contributes to a comprehensive understanding of the edge offloading in smart grid, providing a SWOT analysis to support decision making.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "to be submitted to journal"
    },
    {
        "paper id": "2402.01665",
        "abstract url": "https://arxiv.org/abs/2402.01665",
        "title": "Knowledge-Driven Deep Learning Paradigms for Wireless Network Optimization in 6G",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "In the sixth-generation (6G) networks, newly emerging diversified services of massive users in dynamic network environments are required to be satisfied by multi-dimensional heterogeneous resources. The resulting large-scale complicated network optimization problems are beyond the capability of model-based theoretical methods due to the overwhelming computational complexity and the long processing time. Although with fast online inference and universal approximation ability, data-driven deep learning (DL) heavily relies on abundant training data and lacks interpretability. To address these issues, a new paradigm called knowledge-driven DL has emerged, aiming to integrate proven domain knowledge into the construction of neural networks, thereby exploiting the strengths of both methods. This article provides a systematic review of knowledge-driven DL in wireless networks. Specifically, a holistic framework of knowledge-driven DL in wireless networks is proposed, where knowledge sources, knowledge representation, knowledge integration and knowledge application are forming as a closed loop. Then, a detailed taxonomy of knowledge integration approaches, including knowledge-assisted, knowledge-fused, and knowledge-embedded DL, is presented. Several open issues for future research are also discussed. The insights offered in this article provide a basic principle for the design of network optimization that incorporates communication-specific domain knowledge and DL, facilitating the realization of intelligent 6G networks.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2401.07958",
        "abstract url": "https://arxiv.org/abs/2401.07958",
        "title": "GD-CAF: Graph Dual-stream Convolutional Attention Fusion for Precipitation Nowcasting",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "agricultural"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurate precipitation nowcasting is essential for various applications, including flood prediction, disaster management, optimizing agricultural activities, managing transportation routes and renewable energy. While several studies have addressed this challenging task from a sequence-to-sequence perspective, most of them have focused on a single area without considering the existing correlation between multiple disjoint regions. In this paper, we formulate precipitation nowcasting as a spatiotemporal graph sequence nowcasting problem. In particular, we introduce Graph Dual-stream Convolutional Attention Fusion (GD-CAF), a novel approach designed to learn from historical spatiotemporal graph of precipitation maps and nowcast future time step ahead precipitation at different spatial locations. GD-CAF consists of spatio-temporal convolutional attention as well as gated fusion modules which are equipped with depthwise-separable convolutional operations. This enhancement enables the model to directly process the high-dimensional spatiotemporal graph of precipitation maps and exploits higher-order correlations between the data dimensions. We evaluate our model on seven years of precipitation maps across Europe and its neighboring areas collected from the ERA5 dataset, provided by Copernicus Climate Change Services. The experimental results reveal the superior performance of the GD-CAF model compared to the other examined models. Additionally, visualizations of averaged seasonal spatial and temporal attention scores across the test set offer valuable insights into the most robust connections between diverse regions or time steps.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "19 pages, 13 figures"
    },
    {
        "paper id": "2401.07533",
        "abstract url": "https://arxiv.org/abs/2401.07533",
        "title": "Understanding the Indirect Effects of Interactive Systems Within Systems of Systems",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "agricultural"
            ]
        ],
        "abstract": "Until recently, research into the sustainable design of interactive systems has primarily focused on the direct material impact of a system, through improving its energy efficiency and optimizing its lifecycle. Yet the way a system is designed and marketed often has wider repercussions, such as rebound effects, and systemic change in practices. These effects are harder to assess (and to anticipate) than the direct physical impact of the construction and use of the system itself. Current tools are unable to account for the complexity of these effects: the underlying causal mechanisms, their multi-level nature, their different temporalities, and the variety of their consequences (environmental and societal). This is why we are seeking to develop a specific methodology and tool, inspired by systemic design and system dynamics. These are intended for decision-makers and designers of interactive systems within systems of systems (for example, in the fields of agricultural robotics or public transportation). In this paper, we present this modeling approach and our prototype tool through the example of a second-hand clothing sales platform.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07541",
        "abstract url": "https://arxiv.org/abs/2401.07541",
        "title": "DynaHull: Density-centric Dynamic Point Filtering in Point Clouds",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "In the field of indoor robotics, accurately navigating and mapping in dynamic environments using point clouds can be a challenging task due to the presence of dynamic points. These dynamic points are often represented by people in indoor environments, but in industrial settings with moving machinery, there can be various types of dynamic points. This study introduces DynaHull, a novel technique designed to enhance indoor mapping accuracy by effectively removing dynamic points from point clouds. DynaHull works by leveraging the observation that, over multiple scans, stationary points have a higher density compared to dynamic ones. Furthermore, DynaHull addresses mapping challenges related to unevenly distributed points by clustering the map into smaller sections. In each section, the density factor of each point is determined by dividing the number of neighbors by the volume these neighboring points occupy using a convex hull method. The algorithm removes the dynamic points using an adaptive threshold based on the point count of each cluster, thus reducing the false positives. The performance of DynaHull was compared to state-of-the-art techniques, such as ERASOR, Removert, OctoMap, and a baseline statistical outlier removal from Open3D, by comparing each method to the ground truth map created during a low activity period in which only a few dynamic points were present. The results indicated that DynaHull outperformed these techniques in various metrics, noticeably in the Earth Mover's Distance. This research contributes to indoor robotics by providing efficient methods for dynamic point removal, essential for accurate mapping and localization in dynamic environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07559",
        "abstract url": "https://arxiv.org/abs/2401.07559",
        "title": "Eco-driving Intelligent Systems and Algorithms: A Patent Review",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Patent"
            ]
        ],
        "abstract": "The transportation industry remains a significant contributor to greenhouse gas emissions, highlighting the requirement for intelligent systems to enhance vehicle energy efficiency. The intellectual property rights of developed systems should be protected by patents. However, there is no patent overview of eco-driving intelligent systems. Unlike a scientific article, a patent documentation indicates both novelty and commercialization potential of an inventor. To address this research gap, this paper provides a patent overview of eco-driving intelligent systems and algorithms. 424 patents in the Google Patent database are analyzed. The patent analysis results show that the top three Cooperative Patent Classifications are: Y02T - climate change mitigation technologies related to transportation (50.7%), B60W - Conjoint control of vehicle subunits of different types or different functions (34.4%) and B60L - Propulsion of electrically-propelled vehicles (20.2%). 219 patents were filed after 2016 when deep learning became popular and can be categorized into five groups: vehicle energy management, smart driving, ecological and sustainable driving, fuel consumption reduction, and driving behavior optimization. Furthermore, all 219 patents involve the physical components of the intelligent system and/or novel machine learning/deep learning algorithms. Moreover, over 70% of them are granted by the China National Intellectual Property Administration.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07591",
        "abstract url": "https://arxiv.org/abs/2401.07591",
        "title": "Multimodal Crowd Counting with Pix2Pix GANs",
        "rating": "-3",
        "keywords": [
            [
                "GAN"
            ],
            [
                "infrared"
            ],
            [
                "thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most state-of-the-art crowd counting methods use color (RGB) images to learn the density map of the crowd. However, these methods often struggle to achieve higher accuracy in densely crowded scenes with poor illumination. Recently, some studies have reported improvement in the accuracy of crowd counting models using a combination of RGB and thermal images. Although multimodal data can lead to better predictions, multimodal data might not be always available beforehand. In this paper, we propose the use of generative adversarial networks (GANs) to automatically generate thermal infrared (TIR) images from color (RGB) images and use both to train crowd counting models to achieve higher accuracy. We use a Pix2Pix GAN network first to translate RGB images to TIR images. Our experiments on several state-of-the-art crowd counting models and benchmark crowd datasets report significant improvement in accuracy.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted version of the paper in 19th International Conference on Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-29 Feb, 2024,"
    },
    {
        "paper id": "2401.07768",
        "abstract url": "https://arxiv.org/abs/2401.07768",
        "title": "On Hilbert-Poincar\u00e9 series of affine semi-regular polynomial sequences and related Gr\u00f6bner bases",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Gr\u00f6bner bases are nowadays central tools for solving various problems in commutative algebra and algebraic geometry. A typical use of Gr\u00f6bner bases is the multivariate polynomial system solving, which enables us to construct algebraic attacks against post-quantum cryptographic protocols. Therefore, the determination of the complexity of computing Gr\u00f6bner bases is very important both in theory and in practice: One of the most important cases is the case where input polynomials compose an (overdetermined) affine semi-regular sequence. The first part of this paper aims to present a survey on Gr\u00f6bner basis computation and its complexity. In the second part, we shall give an explicit formula on the (truncated) Hilbert-Poincar\u00e9 series associated to the homogenization of an affine semi-regular sequence. Based on the formula, we also study (reduced) Gr\u00f6bner bases of the ideals generated by an affine semi-regular sequence and its homogenization. Some of our results are considered to give mathematically rigorous proofs of the correctness of methods for computing Gr\u00f6bner bases of the ideal generated by an affine semi-regular sequence.",
        "subjects": [
            "cs.SC"
        ],
        "comment": "25 pages, Comments are welcome!"
    },
    {
        "paper id": "2401.07774",
        "abstract url": "https://arxiv.org/abs/2401.07774",
        "title": "Predominant Aspects on Security for Quantum Machine Learning: Literature Review",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum Machine Learning (QML) has emerged as a promising intersection of quantum computing and classical machine learning, anticipated to drive breakthroughs in computational tasks. This paper discusses the question which security concerns and strengths are connected to QML by means of a systematic literature review. We categorize and review the security of QML models, their vulnerabilities inherent to quantum architectures, and the mitigation strategies proposed. The survey reveals that while QML possesses unique strengths, it also introduces novel attack vectors not seen in classical systems. We point out specific risks, such as cross-talk in superconducting systems and forced repeated shuttle operations in ion-trap systems, which threaten QML's reliability. However, approaches like adversarial training, quantum noise exploitation, and quantum differential privacy have shown potential in enhancing QML robustness. Our review discuss the need for continued and rigorous research to ensure the secure deployment of QML in real-world applications. This work serves as a foundational reference for researchers and practitioners aiming to navigate the security aspects of QML.",
        "subjects": [
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07783",
        "abstract url": "https://arxiv.org/abs/2401.07783",
        "title": "Cybersecurity and Embodiment Integrity for Modern Robots: A Conceptual Framework",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Modern robots are stepping away from monolithic entities built using ad-hoc sensors and actuators, due to new technologies and communication paradigms, such as the Internet of Things (IoT) and the Robotic Operating System (ROS). Using such paradigms, robots can be built by acquiring heterogeneous standard devices and putting them in communication with each other. This approach brings high degrees of modularity, but it also yields uncertainty of providing cybersecurity assurances, and guarantees on the integrity of the embodiment. In this paper, we first illustrate how cyberattacks on different devices can have radically different consequences on the robot's ability to complete its tasks and preserve its embodiment. We also claim that modern robots should have self-awareness for what it concerns such aspects, and formulate the different characteristics that robots should integrate for doing so. Then, we show that achieving these propositions requires that robots possess at least three properties that conceptually link devices and tasks. Last, we reflect on how these three properties could be achieved in a larger conceptual framework.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 1 figure, 3 tables"
    },
    {
        "paper id": "2401.07914",
        "abstract url": "https://arxiv.org/abs/2401.07914",
        "title": "Graphical Symplectic Algebra",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "We give complete presentations for the dagger-compact props of affine Lagrangian and coisotropic relations over an arbitrary field. This provides a unified family of graphical languages for both affinely constrained classical mechanical systems, as well as odd-prime-dimensional stabiliser quantum circuits. To this end, we present affine Lagrangian relations by a particular class of undirected coloured graphs. In order to reason about composite systems, we introduce a powerful scalable notation where the vertices of these graphs are themselves coloured by graphs. In the setting of stabiliser quantum mechanics, this scalable notation gives an extremely concise description of graph states, which can be composed via ``phased spider fusion.'' Likewise, in the classical mechanical setting of electrical circuits, we show that impedance matrices for reciprocal networks are presented in essentially the same way.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07937",
        "abstract url": "https://arxiv.org/abs/2401.07937",
        "title": "Integrate Any Omics: Towards genome-wide data integration for patient stratification",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "biological",
                "cancer",
                "clinical"
            ]
        ],
        "abstract": "High-throughput omics profiling advancements have greatly enhanced cancer patient stratification. However, incomplete data in multi-omics integration presents a significant challenge, as traditional methods like sample exclusion or imputation often compromise biological diversity and dependencies. Furthermore, the critical task of accurately classifying new patients with partial omics data into existing subtypes is commonly overlooked. To address these issues, we introduce IntegrAO (Integrate Any Omics), an unsupervised framework for integrating incomplete multi-omics data and classifying new samples. IntegrAO first combines partially overlapping patient graphs from diverse omics sources and utilizes graph neural networks to produce unified patient embeddings. Our systematic evaluation across five cancer cohorts involving six omics modalities demonstrates IntegrAO's robustness to missing data and its accuracy in classifying new samples with partial profiles. An acute myeloid leukemia case study further validates its capability to uncover biological and clinical heterogeneity in incomplete datasets. IntegrAO's ability to handle heterogeneous and incomplete data makes it an essential tool for precision oncology, offering a holistic approach to patient characterization.",
        "subjects": [
            "q-bio.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07950",
        "abstract url": "https://arxiv.org/abs/2401.07950",
        "title": "SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning",
        "rating": "-3",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations. To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning. Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain. This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise. Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing physics, chemistry, math, and formal proofs. We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing their scientific and mathematical reasoning capabilities. Remarkably, the SciGLM consistently improves both the base model (ChatGLM3-6B-Base) by 4.87% and larger-scale models (32B) by 2.67%, without sacrificing the language understanding capabilities of the base model. This makes SciGLM a suitable foundational model to facilitate diverse scientific discovery tasks. For the benefit of the wider research community, we release SciInstruct, and SciGLM, alongside a self-reflective framework and fine-tuning code at https://github.com/THUDM/SciGLM.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2401.08054",
        "abstract url": "https://arxiv.org/abs/2401.08054",
        "title": "Mobile robot localization with GNSS multipath detection using pseudorange residuals",
        "rating": "-3",
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "This paper proposes a novel positioning technique suitable for use in mobile robots in urban environments in which large global navigation satellite system (GNSS) positioning errors occur because of multipath signals. During GNSS positioning, the GNSS satellites that are obstructed by buildings emit reflection and diffraction signals, which are called non-line-of-sight (NLOS) multipath signals. These multipath signals cause major positioning errors. The key concept considered in this paper is the estimation of a user's position using the likelihood of the position hypotheses computed from the GNSS pseudoranges, consisting only of LOS signals based on the analysis of the pseudorange residuals. To determine the NLOS GNSS signals from the pseudorange residuals at the user's position, it is necessary to accurately determine the position before the computation of the pseudorange residuals. This problem is solved using a particle filter. We propose a likelihood estimation method using the Mahalanobis distance between the hypotheses of the user's position computed from only the LOS pseudoranges and the particles. To confirm the effectiveness of the proposed technique, a positioning test was performed in a real-world urban environment. The results demonstrated that the proposed method is effective for accurately estimating the user's position in urban canyons.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This is an electronic version of an article published in ADVANCED ROBOTICS, 33(12):602-613, 2019. ADVANCED ROBOTICS is available online at: www.tandfonline.com/Article DOI: 10.1080/01691864.2019.1619622"
    },
    {
        "paper id": "2401.10158",
        "abstract url": "https://arxiv.org/abs/2401.10158",
        "title": "DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks",
        "rating": "-3",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Beyond 5G and 6G networks are expected to support new and challenging use cases and applications that depend on a certain level of Quality of Service (QoS) to operate smoothly. Predicting the QoS in a timely manner is of high importance, especially for safety-critical applications as in the case of vehicular communications. Although until recent years the QoS prediction has been carried out by centralized Artificial Intelligence (AI) solutions, a number of privacy, computational, and operational concerns have emerged. Alternative solutions have been surfaced (e.g. Split Learning, Federated Learning), distributing AI tasks of reduced complexity across nodes, while preserving the privacy of the data. However, new challenges rise when it comes to scalable distributed learning approaches, taking into account the heterogeneous nature of future wireless networks. The current work proposes DISTINQT, a privacy-aware distributed learning framework for QoS prediction. Our framework supports multiple heterogeneous nodes, in terms of data types and model architectures, by sharing computations across them. This, enables the incorporation of diverse knowledge into a sole learning process that will enhance the robustness and generalization capabilities of the final QoS prediction model. DISTINQT also contributes to data privacy preservation by encoding any raw input data into a non-linear latent representation before any transmission. Evaluation results showcase that our framework achieves a statistically identical performance compared to its centralized version and an average performance improvement of up to 65% against six state-of-the-art centralized baseline solutions in the Tele-Operated Driving use case.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "11 Pages Double Column, 9 Figures, Submitted for possible publication in the IEEE Transactions on Vehicular Technology (IEEE TVT)"
    },
    {
        "paper id": "2401.07764",
        "abstract url": "https://arxiv.org/abs/2401.07764",
        "title": "When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "6G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "AI agents based on multimodal large language models (LLMs) are expected to revolutionize human-computer interaction and offer more personalized assistant services across various domains like healthcare, education, manufacturing, and entertainment. Deploying LLM agents in 6G networks enables users to access previously expensive AI assistant services via mobile devices democratically, thereby reducing interaction latency and better preserving user privacy. Nevertheless, the limited capacity of mobile devices constrains the effectiveness of deploying and executing local LLMs, which necessitates offloading complex tasks to global LLMs running on edge servers during long-horizon interactions. In this article, we propose a split learning system for LLM agents in 6G networks leveraging the collaboration between mobile devices and edge servers, where multiple LLMs with different roles are distributed across mobile devices and edge servers to perform user-agent interactive tasks collaboratively. In the proposed system, LLM agents are split into perception, grounding, and alignment modules, facilitating inter-module communications to meet extended user requirements on 6G network functions, including integrated sensing and communication, digital twins, and task-oriented communications. Furthermore, we introduce a novel model caching algorithm for LLMs within the proposed system to improve model utilization in context, thus reducing network costs of the collaborative mobile and edge LLM agents.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07854",
        "abstract url": "https://arxiv.org/abs/2401.07854",
        "title": "$M^{2}$Fusion: Bayesian-based Multimodal Multi-level Fusion on Colorectal Cancer Microsatellite Instability Prediction",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "CT",
                "whole slide",
                "Cancer",
                "radiology"
            ],
            [
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Colorectal cancer (CRC) micro-satellite instability (MSI) prediction on histopathology images is a challenging weakly supervised learning task that involves multi-instance learning on gigapixel images. To date, radiology images have proven to have CRC MSI information and efficient patient imaging techniques. Different data modalities integration offers the opportunity to increase the accuracy and robustness of MSI prediction. Despite the progress in representation learning from the whole slide images (WSI) and exploring the potential of making use of radiology data, CRC MSI prediction remains a challenge to fuse the information from multiple data modalities (e.g., pathology WSI and radiology CT image). In this paper, we propose $M^{2}$Fusion: a Bayesian-based multimodal multi-level fusion pipeline for CRC MSI. The proposed fusion model $M^{2}$Fusion is capable of discovering more novel patterns within and across modalities that are beneficial for predicting MSI than using a single modality alone, as well as other fusion methods. The contribution of the paper is three-fold: (1) $M^{2}$Fusion is the first pipeline of multi-level fusion on pathology WSI and 3D radiology CT image for MSI prediction; (2) CT images are the first time integrated into multimodal fusion for CRC MSI prediction; (3) feature-level fusion strategy is evaluated on both Transformer-based and CNN-based method. Our approach is validated on cross-validation of 352 cases and outperforms either feature-level (0.8177 vs. 0.7908) or decision-level fusion strategy (0.8177 vs. 0.7289) on AUC score.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08022",
        "abstract url": "https://arxiv.org/abs/2401.08022",
        "title": "Preprocessing-based Kinodynamic Motion Planning Framework for Intercepting Projectiles using a Robot Manipulator",
        "rating": "-4",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "We are interested in studying sports with robots and starting with the problem of intercepting a projectile moving toward a robot manipulator equipped with a shield. To successfully perform this task, the robot needs to (i) detect the incoming projectile, (ii) predict the projectile's future motion, (iii) plan a minimum-time rapid trajectory that can evade obstacles and intercept the projectile, and (iv) execute the planned trajectory. These four steps must be performed under the manipulator's dynamic limits and extreme time constraints (<350ms in our setting) to successfully intercept the projectile. In addition, we want these trajectories to be smooth to reduce the robot's joint torques and the impulse on the platform on which it is mounted. To this end, we propose a kinodynamic motion planning framework that preprocesses smooth trajectories offline to allow real-time collision-free executions online. We present an end-to-end pipeline along with our planning framework, including perception, prediction, and execution modules. We evaluate our framework experimentally in simulation and show that it has a higher blocking success rate than the baselines. Further, we deploy our pipeline on a robotic system comprising an industrial arm (ABB IRB-1600) and an onboard stereo camera (ZED 2i), which achieves a 78% success rate in projectile interceptions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Proceedings of the IEEE International Conference on Robotics and Automation (ICRA) 2024"
    },
    {
        "paper id": "2401.08023",
        "abstract url": "https://arxiv.org/abs/2401.08023",
        "title": "Spatial Channel State Information Prediction with Generative AI: Towards Holographic Communication and Digital Radio Twin",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "As 5G technology becomes increasingly established, the anticipation for 6G is growing, which promises to deliver faster and more reliable wireless connections via cutting-edge radio technologies. However, efficient management method of the large-scale antenna arrays deployed by those radio technologies is crucial. Traditional management methods are mainly reactive, usually based on feedback from users to adapt to the dynamic wireless channel. However, a more promising approach lies in the prediction of spatial channel state information (spatial-CSI), which is an all-inclusive channel characterization and consists of all the feasible line-of-sight (LoS) and non-line-of-sight (NLoS) paths between the transmitter (Tx) and receiver (Rx), with the three-dimension (3D) trajectory, attenuation, phase shift, delay, and polarization of each path. Advances in hardware and neural networks make it possible to predict such spatial-CSI using precise environmental information, and further look into the possibility of holographic communication, which implies complete control over every aspect of the radio waves emitted. Based on the integration of holographic communication and digital twin, we proposed a new framework, digital radio twin, which takes advantages from both the digital world and deterministic control over radio waves, supporting a wide range of high-level applications. As a preliminary attempt towards this visionary direction, in this paper, we explore the use of generative artificial intelligence (AI) to pinpoint the valid paths in a given environment, demonstrating promising results, and highlighting the potential of this approach in driving forward the evolution of 6G wireless communication technologies.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "submitted to IEEE for potential publication"
    },
    {
        "paper id": "2401.08067",
        "abstract url": "https://arxiv.org/abs/2401.08067",
        "title": "TrajVis: a visual clinical decision support system to translate artificial intelligence trajectory models in the precision management of chronic kidney disease",
        "rating": "-4",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "graph"
            ],
            [
                "medical",
                "Health",
                "healthcare",
                "disease",
                "clinical"
            ]
        ],
        "abstract": "Objective: Our objective is to develop and validate TrajVis, an interactive tool that assists clinicians in using artificial intelligence (AI) models to leverage patients' longitudinal electronic medical records (EMR) for personalized precision management of chronic disease progression. Methods: We first perform requirement analysis with clinicians and data scientists to determine the visual analytics tasks of the TrajVis system as well as its design and functionalities. A graph AI model for chronic kidney disease (CKD) trajectory inference named DEPOT is used for system development and demonstration. TrajVis is implemented as a full-stack web application with synthetic EMR data derived from the Atrium Health Wake Forest Baptist Translational Data Warehouse and the Indiana Network for Patient Care research database. A case study with a nephrologist and a user experience survey of clinicians and data scientists are conducted to evaluate the TrajVis system. Results: The TrajVis clinical information system is composed of four panels: the Patient View for demographic and clinical information, the Trajectory View to visualize the DEPOT-derived CKD trajectories in latent space, the Clinical Indicator View to elucidate longitudinal patterns of clinical features and interpret DEPOT predictions, and the Analysis View to demonstrate personal CKD progression trajectories. System evaluations suggest that TrajVis supports clinicians in summarizing clinical data, identifying individualized risk predictors, and visualizing patient disease progression trajectories, overcoming the barriers of AI implementation in healthcare. Conclusion: TrajVis bridges the gap between the fast-growing AI/ML modeling and the clinical use of such models for personalized and precision management of chronic diseases.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07842",
        "abstract url": "https://arxiv.org/abs/2401.07842",
        "title": "Closing the Performance and Management Gaps with Satellite Internet: Challenges, Approaches, and Future Directions",
        "rating": "-4.5",
        "keywords": [
            [
                "5G",
                "6G"
            ],
            [
                "Satellite"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Recent advancements in low-Earth orbit (LEO) satellites represented by large constellations and advanced payloads provide great promises for enabling beyond 5G and 6G telecommunications and high-quality and ubiquitous Internet connectivity to everyone anywhere on Earth. LEO satellite networks are envisioned to bridge the urban-rural connectivity gap for the digital divide. However, the digital divide can hardly be closed by only providing connectivity to rural and remote areas. Various unprecedented challenges brought by the emerging satellite Internet still need to be resolved, such as inconsistent end-to-end performance guarantees and a lack of efficient management and operations in these areas, which are referred to as \"performance gap\" and \"management gap\", respectively. This position paper will briefly discuss these gaps, approaches to addressing the gaps, and some research directions based on our recent works.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Published at the IAB Workshop on Barriers to Internet Access of Services (BIAS) 2024. Available at: https://www.ietf.org/slides/slides-biasws-closing-the-performance-and-management-gaps-with-satellite-internet-challenges-approaches-and-future-directions-01.pdf"
    },
    {
        "paper id": "2401.08043",
        "abstract url": "https://arxiv.org/abs/2401.08043",
        "title": "Cross-Modal Semi-Dense 6-DoF Tracking of an Event Camera in Challenging Conditions",
        "rating": "-6",
        "keywords": [
            [
                "3D",
                "6-DoF",
                "depth",
                "Event Camera"
            ],
            [
                "SLAM"
            ],
            [
                "bio-inspired"
            ],
            [
                "HDR"
            ]
        ],
        "abstract": "Vision-based localization is a cost-effective and thus attractive solution for many intelligent mobile platforms. However, its accuracy and especially robustness still suffer from low illumination conditions, illumination changes, and aggressive motion. Event-based cameras are bio-inspired visual sensors that perform well in HDR conditions and have high temporal resolution, and thus provide an interesting alternative in such challenging scenarios. While purely event-based solutions currently do not yet produce satisfying mapping results, the present work demonstrates the feasibility of purely event-based tracking if an alternative sensor is permitted for mapping. The method relies on geometric 3D-2D registration of semi-dense maps and events, and achieves highly reliable and accurate cross-modal tracking results. Practically relevant scenarios are given by depth camera-supported tracking or map-based localization with a semi-dense map prior created by a regular image-based visual SLAM or structure-from-motion system. Conventional edge-based 3D-2D alignment is extended by a novel polarity-aware registration that makes use of signed time-surface maps (STSM) obtained from event streams. We furthermore introduce a novel culling strategy for occluded points. Both modifications increase the speed of the tracker and its robustness against occlusions or large view-point variations. The approach is validated on many real datasets covering the above-mentioned challenging conditions, and compared against similar solutions realised with regular cameras.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "accepted by IEEE Transactions on Robotics (T-RO). arXiv admin note: text overlap with arXiv:2202.02556"
    },
    {
        "paper id": "2401.07472",
        "abstract url": "https://arxiv.org/abs/2401.07472",
        "title": "Fully Decentralized Design of Initialization-free Distributed Network Size Estimation",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose a distributed scheme for estimating the network size, which refers to the total number of agents in a network. By leveraging a synchronization technique for multi-agent systems, we devise an agent dynamics that ensures convergence to an equilibrium point located near the network size regardless of its initial condition. Our approach is based on an assumption that each agent has a unique identifier, and an estimation algorithm for obtaining the largest identifier value. By adopting this approach, we successfully implement the agent dynamics in a fully decentralized manner, ensuring accurate network size estimation even when some agents join or leave the network.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07479",
        "abstract url": "https://arxiv.org/abs/2401.07479",
        "title": "Decentralized Interference-Aware Codebook Learning in Millimeter Wave MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Beam codebooks are integral components of the future millimeter wave (mmWave) multiple input multiple output (MIMO) system to relax the reliance on the instantaneous channel state information (CSI). The design of these codebooks, therefore, becomes one of the fundamental problems for these systems, and the well-designed codebooks play key roles in enabling efficient and reliable communications. Prior work has primarily focused on the codebook learning problem within a single cell/network and under stationary interference. In this work, we generalize the interference-aware codebook learning problem to networks with multiple cells/basestations. One of the key differences compared to the single-cell codebook learning problem is that the underlying environment becomes non-stationary, as the behavior of one base station will influence the learning of the others. Moreover, to encompass some of the challenging scenarios, information exchange between the different learning nodes is not allowed, which leads to a fully decentralized system with significantly increased learning difficulties. To tackle the non-stationarity, the averaging of the measurements is used to estimate the interference nulling performance of a particular beam, based on which a decision rule is provided. Furthermore, we theoretically justify the adoption of such estimator and prove that it is a sufficient statistic for the underlying quantity of interest in an asymptotic sense. Finally, a novel reward function based on averaging is proposed to fully decouple the learning of the multiple agents running at different nodes. Simulation results show that the developed solution is capable of learning well-shaped codebook patterns for different networks that significantly suppress the interference without information exchange, highlighting ...",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Dataset and code files are available on the DeepMIMO website https://www.deepmimo.net/"
    },
    {
        "paper id": "2401.07484",
        "abstract url": "https://arxiv.org/abs/2401.07484",
        "title": "Growing Trees and Amoebas' Replications",
        "rating": "-10",
        "keywords": [],
        "abstract": "An amoeba is a tree with a number assigned to each vertex. We describe a natural process of growing trees from a given amoeba and discuss conditions for such a process to be finite.",
        "subjects": [
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07490",
        "abstract url": "https://arxiv.org/abs/2401.07490",
        "title": "Existence of MMS Allocations with Mixed Manna",
        "rating": "-10",
        "keywords": [],
        "abstract": "Maximin share (MMS) allocations are a popular relaxation of envy-free allocations that have received wide attention in the context of the fair division of indivisible items. Although MMS allocations can fail to exist [1], previous work has found conditions under which they exist. Specifically, MMS allocations exist whenever $m \\leq n+5$ in the context of goods allocation, and this bound is tight in the sense that MMS allocations can fail to exist when $m = n+6$ [2]. Unfortunately, the technique used to establish this result does not generalize readily to the chores and mixed manna settings. This paper generalizes this result to the chores setting and provides a partial solution for the mixed manna setting. Our results depend on the presence of certain types of agents. Specifically, an agent $i$ is a goods agent (resp. chores agent) if every item is a good (resp. chore) to $i$, and a non-negative mixed agent if $i$ is neither a goods nor a chores agent and the MMS guarantee of $i$ is non-negative. In this paper, we prove that an MMS allocation exists if $m \\leq n+5$ and there exists a goods agent, a non-negative mixed agent, or only chores agents. [1] David Kurokawa, Ariel D Procaccia, and Junxing Wang. When can the maximin share guarantee be guaranteed? In Thirtieth AAAI Conference on Artificial Intelligence, 2016. [2] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for mms fair allocations. In International Conference on Web and Internet Economics, pages 355-372. Springer, 2021.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "11 pages. A mistake in the previous version has been fixed, and a new reference has been added"
    },
    {
        "paper id": "2401.07511",
        "abstract url": "https://arxiv.org/abs/2401.07511",
        "title": "Space Networking Kit: A Novel Simulation Platform for Emerging LEO Mega-constellations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents SNK, a novel simulation platform designed to evaluate the network performance of constellation systems for global Internet services. SNK offers realtime communication visualization and supports the simulation of routing between edge node of network. The platform enables the evaluation of routing and network performance metrics such as latency, stretch, network capacity, and throughput under different network structures and density. The effectiveness of SNK is demonstrated through various simulation cases, including the routing between fixed edge stations or mobile edge stations and analysis of space network structures.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2401.07515",
        "abstract url": "https://arxiv.org/abs/2401.07515",
        "title": "On Purely Data-Driven Massive MIMO Detectors",
        "rating": "-10",
        "keywords": [],
        "abstract": "To enhance the performance of massive multi-input multi-output (MIMO) detection using deep learning, prior research primarily adopts a model-driven methodology, integrating deep neural networks (DNNs) with traditional iterative detectors. Despite these efforts, achieving a purely data-driven detector has remained elusive, primarily due to the inherent complexities arising from the problem's high dimensionality. This paper introduces ChannelNet, a simple yet effective purely data-driven massive MIMO detector. ChannelNet embeds the channel matrix into the network as linear layers rather than viewing it as input, enabling scalability to massive MIMO scenarios. ChannelNet is computationally efficient and has a computational complexity of $\\mathcal{O}(N_t N_r)$, where $N_t$ and $N_r$ represent the numbers of transmit and receive antennas, respectively. Despite the low computation complexity, ChannelNet demonstrates robust empirical performance, matching or surpassing state-of-the-art detectors in various scenarios. In addition, theoretical insights establish ChannelNet as a universal approximator in probability for any continuous permutation-equivariant functions. ChannelNet demonstrates that designing deep learning based massive MIMO detectors can be purely data-driven and free from the constraints posed by the conventional iterative frameworks as well as the channel and noise distribution models.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07534",
        "abstract url": "https://arxiv.org/abs/2401.07534",
        "title": "Exploring the Potential of Large Language Models in Self-adaptive Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Models (LLMs), with their abilities in knowledge acquisition and reasoning, can potentially enhance the various aspects of Self-adaptive Systems (SAS). Yet, the potential of LLMs in SAS remains largely unexplored and ambiguous, due to the lack of literature from flagship conferences or journals in the field, such as SEAMS and TAAS. The interdisciplinary nature of SAS suggests that drawing and integrating ideas from related fields, such as software engineering and autonomous agents, could unveil innovative research directions for LLMs within SAS. To this end, this paper reports the results of a literature review of studies in relevant fields, summarizes and classifies the studies relevant to SAS, and outlines their potential to specific aspects of SAS.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "accepted by SEAMS'24"
    },
    {
        "paper id": "2401.07538",
        "abstract url": "https://arxiv.org/abs/2401.07538",
        "title": "Evidence of Scaling Regimes in the Hopfield Dynamics of Whole Brain Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is shown that a Hopfield recurrent neural network, informed by experimentally derived brain topology, recovers the scaling picture recently introduced by Deco et al., according to which the process of information transfer within the human brain shows spatially correlated patterns qualitatively similar to those displayed by turbulent flows. Although both models employ a coupling strength which decays exponentially with the euclidean distance between the nodes, their mathematical nature is widely different, Hopf oscillators versus Hopfield neural network. Hence, their convergence suggests a remarkable robustness of the aforementioned scaling picture. Furthermore, the present analysis shows that the Hopfield model brain remains functional by removing links above about five decay lengths, corresponding to about one sixth of the size of the global brain. This suggests that, in terms of connectivity decay length, the Hopfield brain functions in a sort of intermediate \"turbulent liquid\"-like state, whose essential connections are the intermediate ones between the connectivity decay length and the global brain size. This \"turbulent-like liquid\" appears to be more spiky than actual turbulent fluids, with a scaling exponent around $2/5$ instead of $2/3$.",
        "subjects": [
            "cond-mat.dis-nn"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2401.07539",
        "abstract url": "https://arxiv.org/abs/2401.07539",
        "title": "Experimental Assessment of Containers Running on Top of Virtual Machines",
        "rating": "-10",
        "keywords": [],
        "abstract": "Over the past two decades, the cloud computing paradigm has gradually attracted more popularity due to its efficient resource usage and simple service access model. Virtualization technology is the fundamental element of cloud computing that brings several benefits to cloud users and providers, such as workload isolation, energy efficiency, server consolidation, and cost reduction. This paper examines the combination of operating system-level virtualization (containers) and hardware-level virtualization (virtual machines). To this end, the performance of containers running on top of virtual machines is experimentally compared with standalone virtual machines and containers based on different hardware resources, including the processor, main memory, disk, and network in a real testbed by running the most commonly used benchmarks. Paravirtualization and full virtualization as well as type 1 and type 2 hypervisors are covered in this study. In addition, three prevalent containerization platforms are examined.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07548",
        "abstract url": "https://arxiv.org/abs/2401.07548",
        "title": "Rabin Games and Colourful Universal Trees",
        "rating": "-10",
        "keywords": [],
        "abstract": "We provide an algorithm to solve Rabin and Streett games over graphs with $n$ vertices, $m$ edges, and $k$ colours that runs in $\\tilde{O}\\left(mn(k!)^{1+o(1)} \\right)$ time and $O(nk\\log k \\log n)$ space, where $\\tilde{O}$ hides poly-logarithmic factors. Our algorithm is an improvement by a super quadratic dependence on $k!$ from the currently best known run time of $O\\left(mn^2(k!)^{2+o(1)}\\right)$, obtained by converting a Rabin game into a parity game, while simultaneously improving its exponential space requirement. Our main technical ingredient is a characterisation of progress measures for Rabin games using \\emph{colourful trees} and a combinatorial construction of succinctly-represented, universal colourful trees. Colourful universal trees are generalisations of universal trees used by Jurdzi\u0144ski and Lazi\u0107 (2017) to solve parity games, as well as of Rabin progress measures of Klarlund and Kozen (1991). Our algorithm for Rabin games is a progress measure lifting algorithm where the lifting is performed on succinct, colourful, universal trees.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "31 pages, 4 figures. Accepted at TACAS 2024"
    },
    {
        "paper id": "2401.07549",
        "abstract url": "https://arxiv.org/abs/2401.07549",
        "title": "Computability of extender sets in multidimensional subshifts",
        "rating": "-10",
        "keywords": [],
        "abstract": "Subshifts are colorings of $\\mathbb{Z}^d$ defined by families of forbidden patterns. Given a subshift and a finite pattern, its extender set is the set of admissible completions of this pattern. It has been conjectured that the behavior of extender sets, and in particular their growth called extender entropy (arXiv:1711.07515), could provide a way to separate the classes of sofic and effective subshifts. We prove here that both classes have the same possible extender entropies: exactly the $\u03a0_3$ real numbers of $[0,+\\infty)$. We also consider computational properties of extender entropies for subshifts with some language or dynamical properties: computable language, minimal and some mixing properties.",
        "subjects": [
            "cs.DM"
        ],
        "comment": "15 pages + appendix, 6 figures"
    },
    {
        "paper id": "2401.07576",
        "abstract url": "https://arxiv.org/abs/2401.07576",
        "title": "TDD Without Tears: Towards Test Case Generation from Requirements through Deep Reinforcement Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Test-driven development (TDD) is a widely-employed software development practice that mandates writing test cases based on requirements before writing the actual code. While writing test cases is the centerpiece of TDD, it is time-consuming, expensive, and often shunned by developers. To address these issues associated with TDD, automated test case generation approaches have recently been investigated. Such approaches take source code as input, but not the requirements. Therefore, existing work does not fully support true TDD, as actual code is required to generate test cases. In addition, current deep learning-based test case generation approaches are trained with one learning objective, i.e., to generate test cases that are exactly matched with the ground-truth test cases. However, such approaches may limit the model's ability to generate different yet correct test cases. In this paper, we introduce PyTester, a Text-to-Testcase generation approach that can automatically generate syntactically correct, executable, complete, and effective test cases while being aligned with a given natural language requirement. We evaluate PyTester on the public APPS benchmark dataset, and the results show that our Deep RL approach enables PyTester, a small language model, to outperform much larger language models like GPT3.5, StarCoder, and InCoder. Our findings suggest that future research could consider improving small over large LMs for better resource efficiency by integrating the SE domain knowledge into the design of reinforcement learning architecture.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "21 pages, 5 figures"
    },
    {
        "paper id": "2401.07590",
        "abstract url": "https://arxiv.org/abs/2401.07590",
        "title": "Remaining Useful Life Prediction for Aircraft Engines using LSTM",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study uses a Long Short-Term Memory (LSTM) network to predict the remaining useful life (RUL) of jet engines from time-series data, crucial for aircraft maintenance and safety. The LSTM model's performance is compared with a Multilayer Perceptron (MLP) on the C-MAPSS dataset from NASA, which contains jet engine run-to-failure events. The LSTM learns from temporal sequences of sensor data, while the MLP learns from static data snapshots. The LSTM model consistently outperforms the MLP in prediction accuracy, demonstrating its superior ability to capture temporal dependencies in jet engine degradation patterns. The software for this project is in https://github.com/AneesPeringal/rul-prediction.git.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07616",
        "abstract url": "https://arxiv.org/abs/2401.07616",
        "title": "Model checking strategy-controlled systems in rewriting logic",
        "rating": "-10",
        "keywords": [],
        "abstract": "Rewriting logic and its implementation Maude are an expressive framework for the formal specification and verification of software and other kinds of systems. Concurrency is naturally represented by nondeterministic local transformations produced by the application of rewriting rules over algebraic terms in an equational theory. Some aspects of the global behavior of the systems or additional constraints sometimes require restricting this nondeterminism. Rewriting strategies are used as a higher-level and modular resource to cleanly capture these requirements, which can be easily expressed in Maude with an integrated strategy language. However, strategy-aware specifications cannot be verified with the builtin LTL model checker, making strategies less useful and attractive. In this paper, we discuss model checking for strategy-controlled systems, and present a strategy-aware extension of the Maude LTL model checker. The expressivity of the strategy language is discussed in relation to model checking, the model checker is illustrated with multiple application examples, and its performance is compared.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07627",
        "abstract url": "https://arxiv.org/abs/2401.07627",
        "title": "Cost-sensitive Feature Selection for Support Vector Machines",
        "rating": "-10",
        "keywords": [],
        "abstract": "Feature Selection is a crucial procedure in Data Science tasks such as Classification, since it identifies the relevant variables, making thus the classification procedures more interpretable, cheaper in terms of measurement and more effective by reducing noise and data overfit. The relevance of features in a classification procedure is linked to the fact that misclassifications costs are frequently asymmetric, since false positive and false negative cases may have very different consequences. However, off-the-shelf Feature Selection procedures seldom take into account such cost-sensitivity of errors. In this paper we propose a mathematical-optimization-based Feature Selection procedure embedded in one of the most popular classification procedures, namely, Support Vector Machines, accommodating asymmetric misclassification costs. The key idea is to replace the traditional margin maximization by minimizing the number of features selected, but imposing upper bounds on the false positive and negative rates. The problem is written as an integer linear problem plus a quadratic convex problem for Support Vector Machines with both linear and radial kernels. The reported numerical experience demonstrates the usefulness of the proposed Feature Selection procedure. Indeed, our results on benchmark data sets show that a substantial decrease of the number of features is obtained, whilst the desired trade-off between false positive and false negative rates is achieved.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07631",
        "abstract url": "https://arxiv.org/abs/2401.07631",
        "title": "Fixed-parameter debordering of Waring rank",
        "rating": "-10",
        "keywords": [],
        "abstract": "Border complexity measures are defined via limits (or topological closures), so that any function which can approximated arbitrarily closely by low complexity functions itself has low border complexity. Debordering is the task of proving an upper bound on some non-border complexity measure in terms of a border complexity measure, thus getting rid of limits. Debordering is at the heart of understanding the difference between Valiant's determinant vs permanent conjecture, and Mulmuley and Sohoni's variation which uses border determinantal complexity. The debordering of matrix multiplication tensors by Bini played a pivotal role in the development of efficient matrix multiplication algorithms. Consequently, debordering finds applications in both establishing computational complexity lower bounds and facilitating algorithm design. Currently, very few debordering results are known. In this work, we study the question of debordering the border Waring rank of polynomials. Waring and border Waring rank are very well studied measures in the context of invariant theory, algebraic geometry, and matrix multiplication algorithms. For the first time, we obtain a Waring rank upper bound that is exponential in the border Waring rank and only linear in the degree. All previous known results were exponential in the degree. For polynomials with constant border Waring rank, our results imply an upper bound on the Waring rank linear in degree, which previously was only known for polynomials with border Waring rank at most 5.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "22 pages; accepted at STACS 2024; this is an edited part of the preprint arXiv:2211.07055"
    },
    {
        "paper id": "2401.07640",
        "abstract url": "https://arxiv.org/abs/2401.07640",
        "title": "Directed Ear Anonymity",
        "rating": "-10",
        "keywords": [],
        "abstract": "We define and study a new structural parameter for directed graphs, which we call \\emph{ear anonymity}. Our parameter aims to generalize the useful properties of \\emph{funnels} to larger digraph classes. In particular, funnels are exactly the acyclic digraphs with ear anonymity one. We prove that computing the ear anonymity of a digraph is \\NP/-hard and that it can be solved in $O(m(n + m))$-time on acyclic digraphs (where \\(n\\) is the number of vertices and \\(m\\) is the number of arcs in the input digraph). It remains open where exactly in the polynomial hierarchy the problem of computing ear anonymity lies, however for a related problem we manage to show $\u03a3_2^p$-completeness.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07671",
        "abstract url": "https://arxiv.org/abs/2401.07671",
        "title": "CLSA-CIM: A Cross-Layer Scheduling Approach for Computing-in-Memory Architectures",
        "rating": "-10",
        "keywords": [],
        "abstract": "The demand for efficient machine learning (ML) accelerators is growing rapidly, driving the development of novel computing concepts such as resistive random access memory (RRAM)-based tiled computing-in-memory (CIM) architectures. CIM allows to compute within the memory unit, resulting in faster data processing and reduced power consumption. Efficient compiler algorithms are essential to exploit the potential of tiled CIM architectures. While conventional ML compilers focus on code generation for CPUs, GPUs, and other von Neumann architectures, adaptations are needed to cover CIM architectures. Cross-layer scheduling is a promising approach, as it enhances the utilization of CIM cores, thereby accelerating computations. Although similar concepts are implicitly used in previous work, there is a lack of clear and quantifiable algorithmic definitions for cross-layer scheduling for tiled CIM architectures. To close this gap, we present CLSA-CIM, a cross-layer scheduling algorithm for tiled CIM architectures. We integrate CLSA-CIM with existing weight-mapping strategies and compare performance against state-of-the-art (SOTA) scheduling algorithms. CLSA-CIM improves the utilization by up to 17.9 x , resulting in an overall speedup increase of up to 29.2 x compared to SOTA.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07677",
        "abstract url": "https://arxiv.org/abs/2401.07677",
        "title": "Quantitative Information Flow Control by Construction for Component-Based Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Secure software architecture is increasingly important in a data-driven world. When security is neglected sensitive information might leak through unauthorized access. To mitigate this software architects needs tools and methods to quantify security risks in complex systems. This paper presents doctoral research in its early stages concerned with creating constructive methods for building secure component-based systems from a quantitative information flow specification. This research aim at developing a method that allows software architects to develop secure systems from a repository of secure components. Planned contributions are refinement rules for secure development of components from a specification and well-formedness rules for secure composition of said components.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07680",
        "abstract url": "https://arxiv.org/abs/2401.07680",
        "title": "Strategies, model checking and branching-time properties in Maude",
        "rating": "-10",
        "keywords": [],
        "abstract": "Rewriting logic and its implementation Maude are a natural and expressive framework for the specification of concurrent systems and logics. Its nondeterministic local transformations are described by rewriting rules, which can be controlled at a higher level using a builtin strategy language added to Maude~3. This specification resource would not be of much interest without tools to analyze their models, so in a previous work, we extended the Maude LTL model checker to verify strategy-controlled systems. In this paper, CTL* and $\u03bc$-calculus are added to the repertoire of supported logics, after discussing which adaptations are needed for branching-time properties. The new extension relies on some external model checkers that are exposed the Maude models through general and efficient connections, profitable for future extensions and further applications. The performance of these model checkers is compared.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07694",
        "abstract url": "https://arxiv.org/abs/2401.07694",
        "title": "Stochastic optimization with arbitrary recurrent data sampling",
        "rating": "-10",
        "keywords": [],
        "abstract": "For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expected amount of time to visit a given data point either averaged (`target time') or supremized (`hitting time') over the current location. We demonstrate theoretically and empirically that convergence can be accelerated by selecting sampling algorithms that cover the data set most effectively. We discuss applications of our general framework to decentralized optimization and distributed non-negative matrix factorization.",
        "subjects": [
            "math.OC"
        ],
        "comment": "41 pages, 3 figures, 1 table"
    },
    {
        "paper id": "2401.07696",
        "abstract url": "https://arxiv.org/abs/2401.07696",
        "title": "Towards Automatic Translation of Machine Learning Visual Insights to Analytical Assertions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present our vision for developing an automated tool capable of translating visual properties observed in Machine Learning (ML) visualisations into Python assertions. The tool aims to streamline the process of manually verifying these visualisations in the ML development cycle, which is critical as real-world data and assumptions often change post-deployment. In a prior study, we mined $54,070$ Jupyter notebooks from Github and created a catalogue of $269$ semantically related visualisation-assertion (VA) pairs. Building on this catalogue, we propose to build a taxonomy that organises the VA pairs based on ML verification tasks. The input feature space comprises of a rich source of information mined from the Jupyter notebooks -- visualisations, Python source code, and associated markdown text. The effectiveness of various AI models, including traditional NLP4Code models and modern Large Language Models, will be compared using established machine translation metrics and evaluated through a qualitative study with human participants. The paper also plans to address the challenge of extending the existing VA pair dataset with additional pairs from Kaggle and to compare the tool's effectiveness with commercial generative AI models like ChatGPT. This research not only contributes to the field of ML system validation but also explores novel ways to leverage AI for automating and enhancing software engineering practices in ML.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07698",
        "abstract url": "https://arxiv.org/abs/2401.07698",
        "title": "Online Learning of Continuous Signed Distance Fields Using Piecewise Polynomials",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reasoning about distance is indispensable for establishing or avoiding contact in manipulation tasks. To this end, we present an online approach for learning implicit representations of signed distance using piecewise polynomial basis functions. Starting from an arbitrary prior shape, our method incrementally constructs a continuous and smooth distance representation from incoming surface points, with analytical access to gradient information. The underlying model does not store training data for prediction, and its performance can be balanced through interpretable hyperparameters such as polynomial degree and number of segments. We assess the accuracy of the incrementally learned model on a set of household objects and compare it to neural network and Gaussian process counterparts. The utility of intermediate results and analytical gradients is further demonstrated in a physical experiment. For code and video, see https://sites.google.com/view/pp-sdf/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07704",
        "abstract url": "https://arxiv.org/abs/2401.07704",
        "title": "The Paradox of Function Header Comments",
        "rating": "-10",
        "keywords": [],
        "abstract": "Perhaps the most widely used form of code documentation is function header comments. We performed a large-scale survey of 367 developers to catalog their expectations from such documentation and to chronicle actual practice. Paradoxically, we found that developers appreciate the value of header comments and estimate that they are worth the investment in time, but nevertheless they tend not to write such documentation in their own code. Reasons for not writing header comments vary from the belief that code should be self-documenting to concern that documentation will not be kept up-to-date. A possible outcome of this situation is that developers may evade requirements to write documentation by using templates to generate worthless comments that do not provide any real information. We define a simple metric for information-less documentation based on its similarity to the function signature. Applying this to 21,140 files in GitHub Python projects shows that most functions are undocumented, but when header comments are written they typically do contain additional information beyond the function signature.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "11 pages, 2 figures plus 23 inlined graphs"
    },
    {
        "paper id": "2401.07706",
        "abstract url": "https://arxiv.org/abs/2401.07706",
        "title": "Converse Lyapunov Results for Switched Systems with Lower and Upper Bounds on Switching Intervals",
        "rating": "-10",
        "keywords": [],
        "abstract": "The topic of this manuscript is the stability analysis of continuous-time switched nonlinear systems with constraints on the admissible switching signals. Our particular focus lies in considering signals characterized by upper and lower bounds on the length of the switching intervals. We adapt and extend the existing theory of multiple Lyapunov functions, providing converse results and thus a complete characterization of uniform stability for this class of systems. We specify our results in the context of switched linear systems, providing the equivalence of exponential stability and the existence of multiple Lyapunov norms. By restricting the class of candidate Lyapunov functions to the set of quadratic functions, we are able to provide semidefinite-optimization-based numerical schemes to check the proposed conditions. We provide numerical examples to illustrate our approach and highlight its advantages over existing methods.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07713",
        "abstract url": "https://arxiv.org/abs/2401.07713",
        "title": "Approximations to Study the Impact of the Service Discipline in Systems with Redundancy",
        "rating": "-10",
        "keywords": [],
        "abstract": "As job redundancy has been recognized as an effective means to improve performance of large-scale computer systems, queueing systems with redundancy have been studied by various authors. Existing results include methods to compute the queue length distribution and response time but only when the service discipline is First-Come-First-Served (FCFS). For other service disciplines, such as Processor Sharing (PS), or Last-Come-First-Served (LCFS), only the stability conditions are known. In this paper we develop the first methods to approximate the queue length distribution in a queueing system with redundancy under various service disciplines. We focus on a system with exponential job sizes, i.i.d. copies, and a large number of servers. We first derive a mean field approximation that is independent of the scheduling policy. In order to study the impact of service discipline, we then derive refinements of this approximation to specific scheduling policies. In the case of Processor Sharing, we provide a pair and a triplet approximation. The pair approximation can be regarded as a refinement of the classic mean field approximation and takes the service discipline into account, while the triplet approximation further refines the pair approximation. We also develop a pair approximation for three other service disciplines: First-Come-First-Served, Limited Processor Sharing and Last-Come-First-Served. We present numerical evidence that shows that all the approximations presented in the paper are highly accurate, but that none of them are asymptotically exact (as the number of servers goes to infinity). This makes these approximations suitable to study the impact of the service discipline on the queue length distribution. Our results show that FCFS yields the shortest queue length, and that the differences are more substantial at higher loads.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07732",
        "abstract url": "https://arxiv.org/abs/2401.07732",
        "title": "Popularity in location games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study a variant of the Hotelling-Downs model of spatial competition between firms where consumer choices are influenced by their individual preferences as well as the popularity of the firms. In general, a multiplicity of market equilibria might exist due to the popularity effect. To elucidate firm decision-making, we explore three distinct behavioral attitudes towards this multiplicity of equilibria: optimistic, neutral, and pessimistic. For each behavior, we characterize the set of Nash equilibria and measure the impact of the selfish behavior on the social welfare by means of the price of anarchy and price of stability.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07749",
        "abstract url": "https://arxiv.org/abs/2401.07749",
        "title": "Metalevel transformation of strategies",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the reflective Maude specification language, based on rewriting logic, a strategy language has been introduced to control rule rewriting while avoiding complex and verbose metalevel programs. However, just as multiple levels of reflection are required for some metaprogramming tasks, reflective manipulation and generation of strategies are convenient in multiple situations. Some examples of reflective strategy transformations are presented, which implement special forms of evaluation or extend the strategy language while preserving its advantages.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07754",
        "abstract url": "https://arxiv.org/abs/2401.07754",
        "title": "Passive Beamforming For Practical RIS-Assisted Communication Systems With Non-Ideal Hardware",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reconfigurable intelligent surface (RIS) technology is a promising solution to improve the performance of existing wireless communications. To achieve its cost-effectiveness advantage, there inevitably exist certain hardware impairments in the system. Therefore, it is more reasonable to design passive beamforming in this scenario. Some existing research has considered such problems under transceiver impairments. However, their performance still leaves room for improvement, possibly due to their algorithms not properly handling the fractional structure of the objective function. To address this, the passive beamforming is redesigned in this correspondence paper, taking into account both transceiver impairments and the practical phase-shift model. We tackle the fractional structure of the problem by employing the quadratic transform. The remaining sub-problems are addressed utilizing the penalty-based method and the difference-of-convex programming. Since we provide closed-form solutions for all sub-problems, our algorithm is highly efficient. The simulation results demonstrate the superiority of our proposed algorithm.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07761",
        "abstract url": "https://arxiv.org/abs/2401.07761",
        "title": "Stable Matchings in Practice: A Constraint Programming Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study a practical two-sided matching problem of allocating children to daycare centers, which has significant social implications. We are cooperating with several municipalities in Japan and our goal is to devise a reliable and trustworthy clearing algorithm to deal with the problem. In this paper, we describe the design of our new algorithm that minimizes the number of unmatched children while ensuring stability. We evaluate our algorithm using real-life data sets, and experimental results demonstrate that our algorithm surpasses the commercial software that currently dominates the market in terms of both the number of matched children and the number of blocking coalitions (measuring stability). Our findings have been reported to local governments, and some are considering adopting our proposed algorithm in the near future, instead of the existing solution. Moreover, our model and algorithm have broader applicability to other important matching markets, such as hospital-doctor matching with couples and school choice with siblings.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07762",
        "abstract url": "https://arxiv.org/abs/2401.07762",
        "title": "Auto-Regressive Model with Exogenous Input--ARX--based traffic-flow prediction",
        "rating": "-10",
        "keywords": [],
        "abstract": "Traffic flow prediction is widely used in travel decision making, traffic control, roadway system planning, business sectors, and government agencies. ARX models have proved to be highly effective and versatile. In this research, we investigated the applications of ARX models in prediction for real traffic flow in New York City. The ARX models were constructed by linear/polynomial or neural networks. Comparative studies were carried out based on the results by the efficiency, accuracy, and training computational demand of the algorithms.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07780",
        "abstract url": "https://arxiv.org/abs/2401.07780",
        "title": "Learning Soft Constrained MPC Value Functions: Efficient MPC Design and Implementation providing Stability and Safety Guarantees",
        "rating": "-10",
        "keywords": [],
        "abstract": "Model Predictive Control (MPC) can be applied to safety-critical control problems, providing closed-loop safety and performance guarantees. Implementation of MPC controllers requires solving an optimization problem at every sampling instant, which is challenging to execute on embedded hardware. To address this challenge, we propose a framework that combines a tightened soft constrained MPC formulation with supervised learning to approximate the MPC value function. This combination enables us to obtain a corresponding optimal control law, which can be implemented efficiently on embedded platforms. The framework ensures stability and constraint satisfaction for various nonlinear systems. While the design effort is similar to that of nominal MPC, the proposed formulation provides input-to-state stability (ISS) with respect to the approximation error of the value function. Furthermore, we prove that the value function corresponding to the soft constrained MPC problem is Lipschitz continuous for Lipschitz continuous systems, even if the optimal control law may be discontinuous. This serves two purposes: First, it allows to relate approximation errors to a sufficiently large constraint tightening to obtain constraint satisfaction guarantees. Second, it paves the way for an efficient supervised learning procedure to obtain a continuous value function approximation. We demonstrate the effectiveness of the method using a nonlinear numerical example.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07809",
        "abstract url": "https://arxiv.org/abs/2401.07809",
        "title": "Optimal Data Splitting in Distributed Optimization for Machine Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "The distributed optimization problem has become increasingly relevant recently. It has a lot of advantages such as processing a large amount of data in less time compared to non-distributed methods. However, most distributed approaches suffer from a significant bottleneck - the cost of communications. Therefore, a large amount of research has recently been directed at solving this problem. One such approach uses local data similarity. In particular, there exists an algorithm provably optimally exploiting the similarity property. But this result, as well as results from other works solve the communication bottleneck by focusing only on the fact that communication is significantly more expensive than local computing and does not take into account the various capacities of network devices and the different relationship between communication time and local computing expenses. We consider this setup and the objective of this study is to achieve an optimal ratio of distributed data between the server and local machines for any costs of communications and local computations. The running times of the network are compared between uniform and optimal distributions. The superior theoretical performance of our solutions is experimentally validated.",
        "subjects": [
            "math.OC"
        ],
        "comment": "17 pages, 2 figures"
    },
    {
        "paper id": "2401.07815",
        "abstract url": "https://arxiv.org/abs/2401.07815",
        "title": "Anti-Context-Free languages",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context-free languages can be characterized in several ways. This article studies projective linearisations of languages of simple dependency trees, i.e., dependency trees in which a node can govern at most one node with a given syntactic function. We prove that the projective linearisations of local languages of simple dependency trees coincide with the context-free languages. Simple dependency trees suggest alternative dual notions of locality and projectivity, which permits defining a dual language for each context-free language. We call this new class of languages anti-context-free. These languages are related to some linguistic constructions exhibiting the so-called cross-serial dependencies that were historically important for the development of computational linguistics. We propose that this duality could be a relevant linguistic phenomenon.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "26 pages, 17 figures, to appear at Journal of Automata, languages and combinatorics"
    },
    {
        "paper id": "2401.07835",
        "abstract url": "https://arxiv.org/abs/2401.07835",
        "title": "$q$-ary Sequential Locally Recoverable Codes from the Product Construction",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work focuses on sequential locally recoverable codes (SLRCs), a special family of locally repairable codes, capable of correcting multiple code symbol erasures, which are commonly used for distributed storage systems. First, we construct an extended $q$-ary family of non-binary SLRCs using code products with a novel maximum number of recoverable erasures $t$ and a minimal repair alternativity $A$. Second, we study how MDS and BCH codes can be used to construct $q$-ary SLRCs. Finally, we compare our codes to other LRCs.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07856",
        "abstract url": "https://arxiv.org/abs/2401.07856",
        "title": "Information hiding cameras: optical concealment of object information into ordinary images",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data protection methods like cryptography, despite being effective, inadvertently signal the presence of secret communication, thereby drawing undue attention. Here, we introduce an optical information hiding camera integrated with an electronic decoder, optimized jointly through deep learning. This information hiding-decoding system employs a diffractive optical processor as its front-end, which transforms and hides input images in the form of ordinary-looking patterns that deceive/mislead human observers. This information hiding transformation is valid for infinitely many combinations of secret messages, all of which are transformed into ordinary-looking output patterns, achieved all-optically through passive light-matter interactions within the optical processor. By processing these ordinary-looking output images, a jointly-trained electronic decoder neural network accurately reconstructs the original information hidden within the deceptive output pattern. We numerically demonstrated our approach by designing an information hiding diffractive camera along with a jointly-optimized convolutional decoder neural network. The efficacy of this system was demonstrated under various lighting conditions and noise levels, showing its robustness. We further extended this information hiding camera to multi-spectral operation, allowing the concealment and decoding of multiple images at different wavelengths, all performed simultaneously in a single feed-forward operation. The feasibility of our framework was also demonstrated experimentally using THz radiation. This optical encoder-electronic decoder-based co-design provides a novel information hiding camera interface that is both high-speed and energy-efficient, offering an intriguing solution for visual information security.",
        "subjects": [
            "physics.optics"
        ],
        "comment": "26 Pages, 8 Figures"
    },
    {
        "paper id": "2401.07861",
        "abstract url": "https://arxiv.org/abs/2401.07861",
        "title": "PATSMA: Parameter Auto-tuning for Shared Memory Algorithms",
        "rating": "-10",
        "keywords": [],
        "abstract": "Programs with high levels of complexity often face challenges in adjusting execution parameters, particularly when these parameters vary based on the execution context. These dynamic parameters significantly impact the program's performance, such as loop granularity, which can vary depending on factors like the execution environment, program input, or the choice of compiler. Given the expensive nature of testing each case individually, one viable solution is to automate parameter adjustments using optimization methods. This article introduces PATSMA, a parameter auto-tuning tool that leverages Coupled Simulated Annealing (CSA) and Nelder-Mead (NM) optimization methods to fine-tune existing parameters in an application. We demonstrate how auto-tuning can contribute to the real-time optimization of parallel algorithms designed for shared memory systems. PATSMA is a C++ library readily available under the MIT license.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07862",
        "abstract url": "https://arxiv.org/abs/2401.07862",
        "title": "Adaptive Neural-Operator Backstepping Control of a Benchmark Hyperbolic PDE",
        "rating": "-10",
        "keywords": [],
        "abstract": "To stabilize PDEs, feedback controllers require gain kernel functions, which are themselves governed by PDEs. Furthermore, these gain-kernel PDEs depend on the PDE plants' functional coefficients. The functional coefficients in PDE plants are often unknown. This requires an adaptive approach to PDE control, i.e., an estimation of the plant coefficients conducted concurrently with control, where a separate PDE for the gain kernel must be solved at each timestep upon the update in the plant coefficient function estimate. Solving a PDE at each timestep is computationally expensive and a barrier to the implementation of real-time adaptive control of PDEs. Recently, results in neural operator (NO) approximations of functional mappings have been introduced into PDE control, for replacing the computation of the gain kernel with a neural network that is trained, once offline, and reused in real-time for rapid solution of the PDEs. In this paper, we present the first result on applying NOs in adaptive PDE control, presented for a benchmark 1-D hyperbolic PDE with recirculation. We establish global stabilization via Lyapunov analysis, in the plant and parameter error states, and also present an alternative approach, via passive identifiers, which avoids the strong assumptions on kernel differentiability. We then present numerical simulations demonstrating stability and observe speedups up to three orders of magnitude, highlighting the real-time efficacy of neural operators in adaptive control. Our code (Github) is made publicly available for future researchers.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "16.5 pages, 3 figures"
    },
    {
        "paper id": "2401.07898",
        "abstract url": "https://arxiv.org/abs/2401.07898",
        "title": "Generating Maximal Configurations and Their Variants Using Code Metrics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Testing configurable systems continues to be challenging and costly. Generation of configurations for testing tends to use either techniques based on semantic sampling (e.g., logical formulas over configuration variables, often called presence conditions) or structural code metrics (e.g., code coverage). In this paper we describe our hybrid approaches that combine these two kinds of techniques to good effect. We present new configuration-generation algorithms that leverage constraint solving (SAT and MaxSAT) and configuration fuzzing, and implement our approach in a configuration-generation framework, CONFIZZ. CONFIZZ both enables the generation of maximal configurations (maximal sets of presence conditions that can be satisfied together) and performs code-metric guided configuration fuzzing. Results from evaluation on BusyBox, a highly configurable benchmark, show that our MaxSAT-based configuration generation achieves better coverage for several code metrics. Results also show that, when high coverage of multiple configurations is needed, CONFIZZ's presence-condition fuzzing outperforms alternatives.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07915",
        "abstract url": "https://arxiv.org/abs/2401.07915",
        "title": "Survey of Learning Approaches for Robotic In-Hand Manipulation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Human dexterity is an invaluable capability for precise manipulation of objects in complex tasks. The capability of robots to similarly grasp and perform in-hand manipulation of objects is critical for their use in the ever changing human environment, and for their ability to replace manpower. In recent decades, significant effort has been put in order to enable in-hand manipulation capabilities to robotic systems. Initial robotic manipulators followed carefully programmed paths, while later attempts provided a solution based on analytical modeling of motion and contact. However, these have failed to provide practical solutions due to inability to cope with complex environments and uncertainties. Therefore, the effort has shifted to learning-based approaches where data is collected from the real world or through a simulation, during repeated attempts to complete various tasks. The vast majority of learning approaches focused on learning data-based models that describe the system to some extent or Reinforcement Learning (RL). RL, in particular, has seen growing interest due to the remarkable ability to generate solutions to problems with minimal human guidance. In this survey paper, we track the developments of learning approaches for in-hand manipulations and, explore the challenges and opportunities. This survey is designed both as an introduction for novices in the field with a glossary of terms as well as a guide of novel advances for advanced practitioners.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07930",
        "abstract url": "https://arxiv.org/abs/2401.07930",
        "title": "On Inter-dataset Code Duplication and Data Leakage in Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Motivation. Large language models (LLMs) have exhibited remarkable proficiency in diverse software engineering (SE) tasks. Handling such tasks typically involves acquiring foundational coding knowledge on large, general-purpose datasets during a pre-training phase, and subsequently refining on smaller, task-specific datasets as part of a fine-tuning phase. Problem statement. Data leakage is a well-known issue in training of machine learning models. A manifestation of this issue is the intersection of the training and testing splits. While intra-dataset code duplication examines this intersection within a given dataset and has been addressed in prior research, inter-dataset code duplication, which gauges the overlap between different datasets, remains largely unexplored. If this phenomenon exists, it could compromise the integrity of LLM evaluations because of the inclusion of fine-tuning test samples that were already encountered during pre-training, resulting in inflated performance metrics. Contribution. This paper explores the phenomenon of inter-dataset code duplication and its impact on evaluating LLMs across diverse SE tasks. Study design. We conduct an empirical study using the CSN dataset, a widely adopted pre-training dataset, and five fine-tuning datasets used for various SE tasks. We first identify the intersection between the pre-training and fine-tuning datasets using a deduplication process. Then, we fine-tune four models pre-trained on CSN to evaluate their performance on samples encountered during pre-training and those unseen during that phase. Results. Our findings reveal a potential threat to the evaluation of various LLMs across multiple SE tasks, stemming from the inter-dataset code duplication phenomenon. Moreover, we demonstrate that this threat is accentuated by factors like the LLM's size and the chosen fine-tuning technique.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07969",
        "abstract url": "https://arxiv.org/abs/2401.07969",
        "title": "Simulated Autopoiesis in Liquid Automata",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a novel form of Liquid Automata, using this to simulate autopoiesis, whereby living machines self-organise in the physical realm. This simulation is based on an earlier Cellular Automaton described by Francisco Varela. The basis of Liquid Automata is a particle simulation with additional rules about how particles are transformed on collision with other particles. Unlike cellular automata, there is no fixed grid or time-step, only particles moving about and colliding with each other in a continuous space/time.",
        "subjects": [
            "nlin.CG"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2401.07985",
        "abstract url": "https://arxiv.org/abs/2401.07985",
        "title": "From Digital Twins to Digital Twin Prototypes: Concepts, Formalization, and Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "The transformation to Industry 4.0 also transforms the processes of how we develop intelligent manufacturing production systems. To advance the software development of these new (embedded) software systems, digital twins may be employed. However, there is no consensual definition of what a digital twin is. In this paper, we give an overview of the current state of the digital twin concept and formalize the digital twin concept using the Object-Z notation. This formalization includes the concepts of physical twins, digital models, digital templates, digital threads, digital shadows, digital twins, and digital twin prototypes. The relationships between all these concepts are visualized as UML class diagrams. Our digital twin prototype (DTP) approach supports engineers during the development and automated testing of complex embedded software systems. This approach enable engineers to test embedded software systems in a virtual context, without the need of a connection to a physical object. In continuous integration / continuous deployment pipelines such digital twin prototypes can be used for automated integration testing and, thus, allow for an agile verification and validation process. In this paper, we demonstrate and report on how to apply and implement a digital twin by the example of two real-world field studies (ocean observation systems and smart farming). For independent replication and extension of our approach by other researchers, we provide a lab study published open source on GitHub.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "25 pages, 20 Figures, 50 Object-Z schemes"
    },
    {
        "paper id": "2401.07986",
        "abstract url": "https://arxiv.org/abs/2401.07986",
        "title": "A New Class of Linear Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Let $n$ be a prime power, $r$ be a prime with $r\\mid n-1$, and $\\varepsilon\\in (0,1/2)$. Using the theory of multiplicative character sums and superelliptic curves, we construct new codes over $\\mathbb F_r$ having length $n$, relative distance $(r-1)/r+O(n^{-\\varepsilon})$ and rate $n^{-1/2-\\varepsilon}$. When $r=2$, our binary codes have exponential size when compared to all previously known families of linear and non-linear codes with relative distance asymptotic to $1/2$, such as Delsarte--Goethals codes. Moreover, our codes are linear.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.07992",
        "abstract url": "https://arxiv.org/abs/2401.07992",
        "title": "Playing the MEV Game on a First-Come-First-Served Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "Maximal Extractable Value (MEV) searching has gained prominence on the Ethereum blockchain since the surge in Decentralized Finance activities. In Ethereum, MEV extraction primarily hinges on fee payments to block proposers. However, in First-Come-First-Served (FCFS) blockchain networks, the focus shifts to latency optimizations, akin to High-Frequency Trading in Traditional Finance. This paper illustrates the dynamics of the MEV extraction game in an FCFS network, specifically Algorand. We introduce an arbitrage detection algorithm tailored to the unique time constraints of FCFS networks and assess its effectiveness. Additionally, our experiments investigate potential optimizations in Algorand's network layer to secure optimal execution positions. Our analysis reveals that while the states of relevant trading pools are updated approximately every six blocks on median, pursuing MEV at the block state level is not viable on Algorand, as arbitrage opportunities are typically executed within the blocks they appear. Our algorithm's performance under varying time constraints underscores the importance of timing in arbitrage discovery. Furthermore, our network-level experiments identify critical transaction prioritization strategies for Algorand's FCFS network. Key among these is reducing latency in connections with relays that are well-connected to high-staked proposers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "13 pages, 5 figures"
    },
    {
        "paper id": "2401.07996",
        "abstract url": "https://arxiv.org/abs/2401.07996",
        "title": "Satisfiability of Context-free String Constraints with Subword-ordering and Transducers",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the satisfiability of string constraints where context-free membership constraints may be imposed on variables. Additionally a variable may be constrained to be a subword of a word obtained by shuffling variables and their transductions. The satisfiability problem is known to be undecidable even without rational transductions. It is known to be NExptime-complete without transductions, if the subword relations between variables do not have a cyclic dependency between them. We show that the satisfiability problem stays decidable in this fragment even when rational transductions are added. It is 2NExptime-complete with context-free membership, and NExptime-complete with only regular membership. For the lower bound we prove a technical lemma that is of independent interest: The length of the shortest word in the intersection of a pushdown automaton (of size $O(n)$) and $n$ finite-state automata (each of size $O(n)$) can be double exponential in $n$.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08001",
        "abstract url": "https://arxiv.org/abs/2401.08001",
        "title": "TT-SNN: Tensor Train Decomposition for Efficient Spiking Neural Network Training",
        "rating": "-10",
        "keywords": [],
        "abstract": "Spiking Neural Networks (SNNs) have gained significant attention as a potentially energy-efficient alternative for standard neural networks with their sparse binary activation. However, SNNs suffer from memory and computation overhead due to spatio-temporal dynamics and multiple backpropagation computations across timesteps during training. To address this issue, we introduce Tensor Train Decomposition for Spiking Neural Networks (TT-SNN), a method that reduces model size through trainable weight decomposition, resulting in reduced storage, FLOPs, and latency. In addition, we propose a parallel computation pipeline as an alternative to the typical sequential tensor computation, which can be flexibly integrated into various existing SNN architectures. To the best of our knowledge, this is the first of its kind application of tensor decomposition in SNNs. We validate our method using both static and dynamic datasets, CIFAR10/100 and N-Caltech101, respectively. We also propose a TT-SNN-tailored training accelerator to fully harness the parallelism in TT-SNN. Our results demonstrate substantial reductions in parameter size (7.98X), FLOPs (9.25X), training time (17.7%), and training energy (28.3%) during training for the N-Caltech101 dataset, with negligible accuracy degradation.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08013",
        "abstract url": "https://arxiv.org/abs/2401.08013",
        "title": "A Day-to-Day Dynamical Approach to the Most Likely User Equilibrium Problem",
        "rating": "-10",
        "keywords": [],
        "abstract": "The lack of a unique user equilibrium (UE) route flow in traffic assignment has posed a significant challenge to many transportation applications. The maximum-entropy principle, which advocates for the consistent selection of the most likely solution as a representative, is often used to address the challenge. Built on a recently proposed day-to-day (DTD) discrete-time dynamical model called cumulative logit (CULO), this study provides a new behavioral underpinning for the maximum-entropy UE (MEUE) route flow. It has been proven that CULO can reach a UE state without presuming travelers are perfectly rational. Here, we further establish that CULO always converges to the MEUE route flow if (i) travelers have zero prior information about routes and thus are forced to give all routes an equal choice probability, or (ii) all travelers gather information from the same source such that the so-called general proportionality condition is satisfied. Thus, CULO may be used as a practical solution algorithm for the MEUE problem. To put this idea into practice, we propose to eliminate the route enumeration requirement of the original CULO model through an iterative route discovery scheme. We also examine the discrete-time versions of four popular continuous-time dynamical models and compare them to CULO. The analysis shows that the replicator dynamic is the only one that has the potential to reach the MEUE solution with some regularity. The analytical results are confirmed through numerical experiments.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08015",
        "abstract url": "https://arxiv.org/abs/2401.08015",
        "title": "Parallel $k$-Core Decomposition with Batched Updates and Asynchronous Reads",
        "rating": "-10",
        "keywords": [],
        "abstract": "Maintaining a dynamic $k$-core decomposition is an important problem that identifies dense subgraphs in dynamically changing graphs. Recent work by Liu et al. [SPAA 2022] presents a parallel batch-dynamic algorithm for maintaining an approximate $k$-core decomposition. In their solution, both reads and updates need to be batched, and therefore each type of operation can incur high latency waiting for the other type to finish. To tackle most real-world workloads, which are dominated by reads, this paper presents a novel hybrid concurrent-parallel dynamic $k$-core data structure where asynchronous reads can proceed concurrently with batches of updates, leading to significantly lower read latencies. Our approach is based on tracking causal dependencies between updates, so that causally related groups of updates appear atomic to concurrent readers. Our data structure guarantees linearizability and liveness for both reads and updates, and maintains the same approximation guarantees as prior work. Our experimental evaluation on a 30-core machine shows that our approach reduces read latency by orders of magnitude compared to the batch-dynamic algorithm, up to a $\\left(4.05 \\cdot 10^{5}\\right)$-factor. Compared to an unsynchronized (non-linearizable) baseline, our read latency overhead is only up to a $3.21$-factor greater, while improving accuracy of coreness estimates by up to a factor of $52.7$.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "To appear in PPoPP 2024"
    },
    {
        "paper id": "2401.08018",
        "abstract url": "https://arxiv.org/abs/2401.08018",
        "title": "Effects of Virtual Hand Representation on the Typing Performance, Upper Extremity Angle, and Neck Muscle Activity during Virtual Reality Typing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study evaluated the effect of virtual hand representation on the typing performance, upper extremity angle, neck muscle activity, and usability during virtual reality (VR) typing. A total of 15 participants (7 females and 8 males) performed a typing task with and without virtual hand representations. The optical motion capture data was utilized to capture the upper extremity angles, and electromyography device was used to collect the neck muscle activities (left and right splenius capitis). The results showed that the typing performance, upper extremity angle, neck muscle activity, and usability were significantly different with and without virtual hand representations. With the virtual hand representation, net typing speed (WPM) and usability increased significantly by 171.4% and 25% compared to the without hand representation. Without the virtual hand representation, participants showed increased wrist extension, and decreased right shoulder abduction angles. The variability of the neck rotation was increased while typing without the virtual hand representation. The neck muscle activities were increased with the virtual hand representation. The results suggest that typing with the virtual hand representation could positively affect the typing performance and usability and reduce the risk of the musculoskeletal disorders of the upper extremity. Future study could explore the effect of the virtual hand representation for users with varying levels of typing skills.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "19 pages,2 figures"
    },
    {
        "paper id": "2401.08021",
        "abstract url": "https://arxiv.org/abs/2401.08021",
        "title": "All the Way There and Back: Inertial-Based, Phone-in-Pocket Indoor Wayfinding and Backtracking Apps for Blind Travelers",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce two iOS apps that have been designed to support wayfinding and backtracking for blind travelers navigating in indoor building environments. Wayfinding involves determining and following a route through the building's corridors to reach a destination, and assumes that the app has access to the floor plan of the building. Backtracking one's route, on the other hand, requires no map knowledge. Our apps only use the inertial and magnetic sensors of the smartphone, and thus require no infrastructure modification (e.g., installation and support of BLE beacons). Unlike systems that use the phone's camera, users of our apps can conveniently keep their phone tucked inside a pocket, while interacting with the apps using a smartwatch. Routing directions are given via speech. Both apps were tested in a user study with seven blind participants, who used them while navigating a campus building.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Chia Hsuan Tsai, Fatemeh Elyasi and Peng Ren contributed equally to this research"
    },
    {
        "paper id": "2401.08039",
        "abstract url": "https://arxiv.org/abs/2401.08039",
        "title": "Calibration of an SKA-Low Prototype Station Using Holographic Techniques",
        "rating": "-10",
        "keywords": [],
        "abstract": "Performance of digitally beamformed phased arrays relies on accurate calibration of the array by obtaining gains of each antenna in the array. The stations of the Square Kilometer Array-Low (SKA-Low) are such digital arrays, where the station calibration is currently performed using conventional interferometric techniques. An alternative calibration technique similar to holography of dish based telescopes has been suggested in the past. In this paper, we develop a novel mathematical framework for holography employing tensors, which are multi-way data structures. Self-holography using a reference beam formed with the station under test itself and cross-holography using a different station to obtain the reference beam are unified under the same formalism. Besides, the relation between the two apparently distinct holographic approaches in the literature for phased arrays is shown, and we show that under certain conditions the two methods yield the same results. We test the various holographic techniques on an SKA-Low prototype station Aperture Array Verification System 2 (AAVS2) with the Sun as the calibrator. We perform self-holography of AAVS2 and cross-holography with simultaneous observations carried out with another station Engineering Development Array 2. We find the results from the holographic techniques to be consistent among themselves as well as with a more conventional calibration technique.",
        "subjects": [
            "astro-ph.IM"
        ],
        "comment": "Accepted version"
    },
    {
        "paper id": "2401.08041",
        "abstract url": "https://arxiv.org/abs/2401.08041",
        "title": "Two-Stage Distributionally Robust Edge Node Placement Under Endogenous Demand Uncertainty",
        "rating": "-10",
        "keywords": [],
        "abstract": "Edge computing (EC) promises to deliver low-latency and ubiquitous computation to numerous devices at the network edge. This paper aims to jointly optimize edge node (EN) placement and resource allocation for an EC platform, considering demand uncertainty. Diverging from existing approaches treating uncertainties as exogenous, we propose a novel two-stage decision-dependent distributionally robust optimization (DRO) framework to effectively capture the interdependence between EN placement decisions and uncertain demands. The first stage involves making EN placement decisions, while the second stage optimizes resource allocation after uncertainty revelation. We present an exact mixed-integer linear program reformulation for solving the underlying ``min-max-min\" two-stage model. We further introduce a valid inequality method to enhance computational efficiency, especially for large-scale networks. Extensive numerical experiments demonstrate the benefits of considering endogenous uncertainties and the advantages of the proposed model and approach.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08064",
        "abstract url": "https://arxiv.org/abs/2401.08064",
        "title": "A new model of trust based on neural information processing",
        "rating": "-10",
        "keywords": [],
        "abstract": "More than 30 years of research has firmly established the vital role of trust in human organizations and relationships, but the underlying mechanisms by which people build, lose, and rebuild trust remains incompletely understood. We propose a mechanistic model of trust that is grounded in the modern neuroscience of decision making. Since trust requires anticipating the future actions of others, any mechanistic model must be built upon up-to-date theories on how the brain learns, represents, and processes information about the future within its decision-making systems. Contemporary neuroscience has revealed that decision making arises from multiple parallel systems that perform distinct, complementary information processing. Each system represents information in different forms, and therefore learns via different mechanisms. When an act of trust is reciprocated or violated, this provides new information that can be used to anticipate future actions. The taxonomy of neural information representations that is the basis for the system boundaries between neural decision-making systems provides a taxonomy for categorizing different forms of trust and generating mechanistic predictions about how these forms of trust are learned and manifested in human behavior. Three key predictions arising from our model are (1) strategic risk-taking can reveal how to best proceed in a relationship, (2) human organizations and environments can be intentionally designed to encourage trust among their members, and (3) violations of trust need not always degrade trust, but can also provide opportunities to build trust.",
        "subjects": [
            "econ.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08073",
        "abstract url": "https://arxiv.org/abs/2401.08073",
        "title": "Xaminer: An Internet Cross-Layer Resilience Analysis Tool",
        "rating": "-10",
        "keywords": [],
        "abstract": "A resilient Internet infrastructure is critical in our highly interconnected society. However, the Internet faces several vulnerabilities, ranging from natural disasters to human activities, that can impact the physical layer and, in turn, the higher network layers, such as IP links. In this paper, we introduce Xaminer, the first Internet cross-layer resilience analysis tool, to evaluate the interplay between physical- and network-layer failures. Using a cross-layer Internet map and a failure event model, Xaminer generates a risk profile encompassing a cross-layer impact report, critical infrastructure identification at each layer, and the discovery of trends and patterns under different failure event settings. Xaminer's key strengths lie in its adaptability to diverse disaster scenarios, the ability to assess risks at various granularities, and the capability to generate joint risk profiles for multiple events. We demonstrate Xaminer's capabilities in cross-layer analysis across a spectrum of disaster event models and regions, showcasing its potential role in facilitating well-informed decision-making for resilience planning and deployments.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08080",
        "abstract url": "https://arxiv.org/abs/2401.08080",
        "title": "Approximations of the integral of a class of sinusoidal composite functions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Two approximations of the integral of a class of sinusoidal composite functions, for which an explicit form does not exist, are derived. Numerical experiments show that the proposed approximations yield an error that does not depend on the width of the integration interval. Using such approximations, definite integrals can be computed in almost real-time.",
        "subjects": [
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08091",
        "abstract url": "https://arxiv.org/abs/2401.08091",
        "title": "'One Style Does Not Regulate All': Moderation Practices in Public and Private WhatsApp Groups",
        "rating": "-10",
        "keywords": [],
        "abstract": "WhatsApp is the largest social media platform in the Global South and is a virulent force in global misinformation and political propaganda. Due to end-to-end encryption WhatsApp can barely review any content and this often pushes the responsibility of moderation towards group admins. Yet, little is known about how WhatsApp group admins manage their groups, what factors and values influence moderation decisions, and what challenges they face in moderating their groups. To fill this gap, we interviewed admins of 32 diverse groups and reviewed content from 30 public groups in India and Bangladesh. We observed notable differences in the formation, members' behavior, and moderation of public versus private groups, as well as in how WhatsApp admins operate compared to those on other platforms. We used Baumrind's typology of 'parenting styles' as a lens to explore moderation practices in WhatsApp groups and identified four moderation styles based on how responsive and controlling the admins were and discuss design recommendations to help them better manage problematic content in WhatsApp groups.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08097",
        "abstract url": "https://arxiv.org/abs/2401.08097",
        "title": "A Study of Fairness Concerns in AI-based Mobile App Reviews",
        "rating": "-10",
        "keywords": [],
        "abstract": "Fairness is one of the socio-technical concerns that must be addressed in AI-based systems. Unfair AI-based systems, particularly unfair AI-based mobile apps, can pose difficulties for a significant proportion of the global population. This paper aims to analyze fairness concerns in AI-based app reviews.We first manually constructed a ground-truth dataset, including a statistical sample of fairness and non-fairness reviews. Leveraging the ground-truth dataset, we developed and evaluated a set of machine learning and deep learning classifiers that distinguish fairness reviews from non-fairness reviews. Our experiments show that our best-performing classifier can detect fairness reviews with a precision of 94%. We then applied the best-performing classifier on approximately 9.5M reviews collected from 108 AI-based apps and identified around 92K fairness reviews. Next, applying the K-means clustering technique to the 92K fairness reviews, followed by manual analysis, led to the identification of six distinct types of fairness concerns (e.g., 'receiving different quality of features and services in different platforms and devices' and 'lack of transparency and fairness in dealing with user-generated content'). Finally, the manual analysis of 2,248 app owners' responses to the fairness reviews identified six root causes (e.g., 'copyright issues') that app owners report to justify fairness concerns.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "25 pages, 4 images, 2 tables, Manuscript submitted to a Journal (2024)"
    },
    {
        "paper id": "2401.08710",
        "abstract url": "https://arxiv.org/abs/2401.08710",
        "title": "Dynamic Voltage and Frequency Scaling for Intermittent Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present hardware/software techniques to intelligently regulate supply voltage and clock frequency of intermittently-computing devices. These devices rely on ambient energy harvesting to power their operation and small capacitors as energy buffers. Statically setting their clock frequency fails to capture the unique relations these devices expose between capacitor voltage, energy efficiency at a given operating frequency, and the corresponding operating range. Existing dynamic voltage and frequency scaling techniques are also largely inapplicable due to extreme energy scarcity and peculiar hardware features. We introduce two hardware/software co-designs that accommodate the distinct hardware features and function within a constrained energy envelope, offering varied trade-offs and functionalities. Our experimental evaluation combines tests on custom-manufactured hardware and detailed emulation experiments. The data gathered indicate that our approaches result in up to 3.75x reduced energy consumption and 12x swifter execution times compared to the considered baselines, all while utilizing smaller capacitors to accomplish identical workloads.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08711",
        "abstract url": "https://arxiv.org/abs/2401.08711",
        "title": "Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for Developing Critical AI Literacies",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study explores how discussing metaphors for AI can help build awareness of the frames that shape our understanding of AI systems, particularly large language models (LLMs) like ChatGPT. Given the pressing need to teach \"critical AI literacy\", discussion of metaphor provides an opportunity for inquiry and dialogue with space for nuance, playfulness, and critique. Using a collaborative autoethnographic methodology, we analyzed metaphors from a range of sources, and reflected on them individually according to seven questions, then met and discussed our interpretations. We then analyzed how our reflections contributed to the three kinds of literacies delineated in Selber's multiliteracies framework: functional, critical, and rhetorical. These allowed us to analyze questions of ethics, equity, and accessibility in relation to AI. We explored each metaphor along the dimension of whether or not it was promoting anthropomorphizing, and to what extent such metaphors imply that AI is sentient. Our findings highlight the role of metaphor reflection in fostering a nuanced understanding of AI, suggesting that our collaborative autoethnographic approach as well as the heuristic model of plotting AI metaphors on dimensions of anthropomorphism and multiliteracies, might be useful for educators and researchers in the pursuit of advancing critical AI literacy.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "This is a preprint (accepted version) of an article that has been accepted for publication at the journal Open Praxis: https://openpraxis.org/"
    },
    {
        "paper id": "2401.10921",
        "abstract url": "https://arxiv.org/abs/2401.10921",
        "title": "Push- and Pull-based Effective Communication in Cyber-Physical Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Cyber Physical Systems (CPSs), two groups of actors interact toward the maximization of system performance: the sensors, observing and disseminating the system state, and the actuators, performing physical decisions based on the received information. While it is generally assumed that sensors periodically transmit updates, returning the feedback signal only when necessary, and consequently adapting the physical decisions to the communication policy, can significantly improve the efficiency of the system. In particular, the choice between push-based communication, in which updates are initiated autonomously by the sensors, and pull-based communication, in which they are requested by the actuators, is a key design step. In this work, we propose an analytical model for optimizing push- and pull-based communication in CPSs, observing that the policy optimality coincides with Value of Information (VoI) maximization. Our results also highlight that, despite providing a better optimal solution, implementable push-based communication strategies may underperform even in relatively simple scenarios.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10926",
        "abstract url": "https://arxiv.org/abs/2401.10926",
        "title": "A VR Serious Game to Increase Empathy towards Students with Phonological Dyslexia",
        "rating": "-10",
        "keywords": [],
        "abstract": "Dyslexia is a neurodevelopmental disorder that is estimated to affect about 5-10% of the population. In particular, phonological dyslexia causes problems in connecting the sounds of words with their written forms. This results in difficulties such as slow reading speed, inaccurate reading, and difficulty decoding unfamiliar words. Moreover, dyslexia can also be a challenging and frustrating experience for students as they may feel misunderstood or stigmatized by their peers or educators. For these reasons, the use of compensatory tools and strategies is of crucial importance for dyslexic students to have the same opportunities as non-dyslexic ones. However, generally, people underestimate the problem and are not aware of the importance of support methodologies. In the light of this, the main purpose of this paper is to propose a virtual reality (VR) serious game through which teachers, students and, in general, non-dyslexic people could understand which are some of the issues of student with dyslexia and the fundamental utility of offering support to them. In the game, players must create a potion by following a recipe written in an alphabet that is specifically designed to replicate the reading difficulties experienced by individuals with dyslexia. The task must be solved first without any help and then by receiving supporting tools and strategies with the idea that the player can put himself in the place of the dyslexic person and understand the real need for support methodologies.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "5 pages, 5 figures, MetroXRAINE 2023"
    },
    {
        "paper id": "2401.13693",
        "abstract url": "https://arxiv.org/abs/2401.13693",
        "title": "Challenge design roadmap",
        "rating": "-10",
        "keywords": [],
        "abstract": "Challenges can be seen as a type of game that motivates participants to solve serious tasks. As a result, competition organizers must develop effective game rules. However, these rules have multiple objectives beyond making the game enjoyable for participants. These objectives may include solving real-world problems, advancing scientific or technical areas, making scientific discoveries, and educating the public. In many ways, creating a challenge is similar to launching a product. It requires the same level of excitement and rigorous testing, and the goal is to attract ''customers'' in the form of participants. The process begins with a solid plan, such as a competition proposal that will eventually be submitted to an international conference and subjected to peer review. Although peer review does not guarantee quality, it does force organizers to consider the impact of their challenge, identify potential oversights, and generally improve its quality. This chapter provides guidelines for creating a strong plan for a challenge. The material draws on the preparation guidelines from organizations such as Kaggle 1 , ChaLearn 2 and Tailor 3 , as well as the NeurIPS proposal template, which some of the authors contributed to.",
        "subjects": [
            "cs.OH"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10913",
        "abstract url": "https://arxiv.org/abs/2402.10913",
        "title": "A comparative study of explicit and implicit Large Eddy Simulations using a high-order discontinuous Galerkin solver: application to a Formula 1 front wing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper explores two Large Eddy Simulation (LES) approaches within the framework of the high-order discontinuous Galerkin solver, Horses3D. The investigation focuses on an Inverted Multi-element Wing in Ground Effect (i.e. 2.5D Imperial Front Wing section) representing a Formula 1 front wing, and compares the strengths and limitations of the two LES methods. The explicit LES formulation relies on the Vreman model, that adapts to laminar, transitional and turbulent regimes. The numerical formulation uses nodal basis functions and Gauss points. The implicit LES formulation, does not require explicit turbulence modeling but relies in the discretization scheme. We use the Kennedy-Gruber entropy stable formulation to enhance stability in under resolved simulations, since we recover the continuous properties such as entropy conservation at a discrete level. This formulation employs Gauss-Lobatto points, which downgrades the accuracy of integration but allows for larger time steps in explicit time integration. We compare our results to Nektar++ [1] showing that both LES techniques provide results that agree well with the reference values. The implicit LES shows to better capture transition and allows for larger time steps at a similar cost per iteration. We conclude that this implicit LES formulation is very attractive for complex simulations.",
        "subjects": [
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2402.18584",
        "abstract url": "https://arxiv.org/abs/2402.18584",
        "title": "Adjusting Dynamics of Hopfield Neural Network via Time-variant Stimulus",
        "rating": "-10",
        "keywords": [],
        "abstract": "As a paradigmatic model for nonlinear dynamics studies, the Hopfield Neural Network (HNN) demonstrates a high susceptibility to external disturbances owing to its intricate structure. This paper delves into the challenge of modulating HNN dynamics through time-variant stimuli. The effects of adjustments using two distinct types of time-variant stimuli, namely the Weight Matrix Stimulus (WMS) and the State Variable Stimulus (SVS), along with a Constant Stimulus (CS) are reported. The findings reveal that deploying four WMSs enables the HNN to generate either a four-scroll or a coexisting two-scroll attractor. When combined with one SVS, four WMSs can lead to the formation of an eight-scroll or four-scroll attractor, while the integration of four WMSs and multiple SVSs can induce grid-multi-scroll attractors. Moreover, the introduction of a CS and an SVS can significantly disrupt the dynamic behavior of the HNN. Consequently, suitable adjustment methods are crucial for enhancing the network's dynamics, whereas inappropriate applications can lead to the loss of its chaotic characteristics. To empirically validate these enhancement effects, the study employs an FPGA hardware platform. Subsequently, an image encryption scheme is designed to demonstrate the practical application benefits of the dynamically adjusted HNN in secure multimedia communication. This exploration into the dynamic modulation of HNN via time-variant stimuli offers insightful contributions to the advancement of secure communication technologies.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "14 pages, 21 figures"
    }
]