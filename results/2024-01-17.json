[
    {
        "paper id": "2401.08992",
        "abstract url": "https://arxiv.org/abs/2401.08992",
        "title": "Efficient Adapter Finetuning for Tail Languages in Streaming Multilingual ASR",
        "rating": "2.5",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "The end-to-end ASR model is often desired in the streaming multilingual scenario since it is easier to deploy and can benefit from pre-trained speech models such as powerful foundation models. Meanwhile, the heterogeneous nature and imbalanced data abundance of different languages may cause performance degradation, leading to asynchronous peak performance for different languages during training, especially on tail ones. Sometimes even the data itself may become unavailable as a result of the enhanced privacy protection. Existing work tend to significantly increase the model size or learn language-specific decoders to accommodate each language separately. In this study, we explore simple yet effective Language-Dependent Adapter (LDA) finetuning under a cascaded Conformer transducer framework enhanced by teacher pseudo-labeling for tail languages in the streaming multilingual ASR. The adapter only accounts for 0.4% of the full model per language. It is plugged into the frozen foundation model and is the only trainable module during the finetuning process with noisy student training. The final model merges the adapter parameters from different checkpoints for different languages. The model performance is validated on a challenging multilingual dictation dataset, which includes 39 tail languages across Latin, Greek, Arabic, etc. Our proposed method brings 12.2% word error rate reduction on average and up to 37.5% on a single locale. Furthermore, we show that our parameter-efficient LDA can match the quality of the full model finetuning, thus greatly alleviating the asynchronous peak performance issue.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted to ICASSP 2024"
    },
    {
        "paper id": "2401.09417",
        "abstract url": "https://arxiv.org/abs/2401.09417",
        "title": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model",
        "rating": "2",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recently the state space models (SSMs) with efficient hardware-aware designs, i.e., the Mamba deep learning model, have shown great potential for long sequence modeling. Meanwhile building efficient and generic vision backbones purely upon SSMs is an appealing direction. However, representing visual data is challenging for SSMs due to the position-sensitivity of visual data and the requirement of global context for visual understanding. In this paper, we show that the reliance on self-attention for visual representation learning is not necessary and propose a new generic vision backbone with bidirectional Mamba blocks (Vim), which marks the image sequences with position embeddings and compresses the visual representation with bidirectional state space models. On ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks, Vim achieves higher performance compared to well-established vision transformers like DeiT, while also demonstrating significantly improved computation & memory efficiency. For example, Vim is 2.8$\\times$ faster than DeiT and saves 86.8% GPU memory when performing batch inference to extract features on images with a resolution of 1248$\\times$1248. The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to be the next-generation backbone for vision foundation models. Code is available at https://github.com/hustvl/Vim.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Work in progress. Code is available at https://github.com/hustvl/Vim"
    },
    {
        "paper id": "2401.09067",
        "abstract url": "https://arxiv.org/abs/2401.09067",
        "title": "Towards Continual Learning Desiderata via HSIC-Bottleneck Orthogonalization and Equiangular Embedding",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Deep neural networks are susceptible to catastrophic forgetting when trained on sequential tasks. Various continual learning (CL) methods often rely on exemplar buffers or/and network expansion for balancing model stability and plasticity, which, however, compromises their practical value due to privacy and memory concerns. Instead, this paper considers a strict yet realistic setting, where the training data from previous tasks is unavailable and the model size remains relatively constant during sequential training. To achieve such desiderata, we propose a conceptually simple yet effective method that attributes forgetting to layer-wise parameter overwriting and the resulting decision boundary distortion. This is achieved by the synergy between two key components: HSIC-Bottleneck Orthogonalization (HBO) implements non-overwritten parameter updates mediated by Hilbert-Schmidt independence criterion in an orthogonal space and EquiAngular Embedding (EAE) enhances decision boundary adaptation between old and new tasks with predefined basis vectors. Extensive experiments demonstrate that our method achieves competitive accuracy performance, even with absolute superiority of zero exemplar buffer and 1.02x the base model.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted to AAAI 2024"
    },
    {
        "paper id": "2401.09109",
        "abstract url": "https://arxiv.org/abs/2401.09109",
        "title": "Trapped in texture bias? A large scale comparison of deep instance segmentation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Do deep learning models for instance segmentation generalize to novel objects in a systematic way? For classification, such behavior has been questioned. In this study, we aim to understand if certain design decisions such as framework, architecture or pre-training contribute to the semantic understanding of instance segmentation. To answer this question, we consider a special case of robustness and compare pre-trained models on a challenging benchmark for object-centric, out-of-distribution texture. We do not introduce another method in this work. Instead, we take a step back and evaluate a broad range of existing literature. This includes Cascade and Mask R-CNN, Swin Transformer, BMask, YOLACT(++), DETR, BCNet, SOTR and SOLOv2. We find that YOLACT++, SOTR and SOLOv2 are significantly more robust to out-of-distribution texture than other frameworks. In addition, we show that deeper and dynamic architectures improve robustness whereas training schedules, data augmentation and pre-training have only a minor impact. In summary we evaluate 68 models on 61 versions of MS COCO for a total of 4148 evaluations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ECCV 2022. Code: https://github.com/JohannesTheo/trapped-in-texture-bias"
    },
    {
        "paper id": "2401.09200",
        "abstract url": "https://arxiv.org/abs/2401.09200",
        "title": "A Real-Time Lyrics Alignment System Using Chroma And Phonetic Features For Classical Vocal Performance",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "The goal of real-time lyrics alignment is to take live singing audio as input and to pinpoint the exact position within given lyrics on the fly. The task can benefit real-world applications such as the automatic subtitling of live concerts or operas. However, designing a real-time model poses a great challenge due to the constraints of only using past input and operating within a minimal latency. Furthermore, due to the lack of datasets for real-time models for lyrics alignment, previous studies have mostly evaluated with private in-house datasets, resulting in a lack of standard evaluation methods. This paper presents a real-time lyrics alignment system for classical vocal performances with two contributions. First, we improve the lyrics alignment algorithm by finding an optimal combination of chromagram and phonetic posteriorgram (PPG) that capture melodic and phonetics features of the singing voice, respectively. Second, we recast the Schubert Winterreise Dataset (SWD) which contains multiple performance renditions of the same pieces as an evaluation set for the real-time lyrics alignment.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "To Appear IEEE ICASSP 2024"
    },
    {
        "paper id": "2401.09266",
        "abstract url": "https://arxiv.org/abs/2401.09266",
        "title": "P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Deep clustering, which learns representation and semantic clustering without labels information, poses a great challenge for deep learning-based approaches. Despite significant progress in recent years, most existing methods focus on uniformly distributed datasets, significantly limiting the practical applicability of their methods. In this paper, we first introduce a more practical problem setting named deep imbalanced clustering, where the underlying classes exhibit an imbalance distribution. To tackle this problem, we propose a novel pseudo-labeling-based learning framework. Our framework formulates pseudo-label generation as a progressive partial optimal transport problem, which progressively transports each sample to imbalanced clusters under prior distribution constraints, thus generating imbalance-aware pseudo-labels and learning from high-confident samples. In addition, we transform the initial formulation into an unbalanced optimal transport problem with augmented constraints, which can be solved efficiently by a fast matrix scaling algorithm. Experiments on various datasets, including a human-curated long-tailed CIFAR100, challenging ImageNet-R, and large-scale subsets of fine-grained iNaturalist2018 datasets, demonstrate the superiority of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR2024"
    },
    {
        "paper id": "2401.09334",
        "abstract url": "https://arxiv.org/abs/2401.09334",
        "title": "Large Language Models Are Neurosymbolic Reasoners",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "A wide range of real-world applications is characterized by their symbolic nature, necessitating a strong capability for symbolic reasoning. This paper investigates the potential application of Large Language Models (LLMs) as symbolic reasoners. We focus on text-based games, significant benchmarks for agents with natural language capabilities, particularly in symbolic tasks like math, map reading, sorting, and applying common sense in text-based worlds. To facilitate these agents, we propose an LLM agent designed to tackle symbolic challenges and achieve in-game objectives. We begin by initializing the LLM agent and informing it of its role. The agent then receives observations and a set of valid actions from the text-based games, along with a specific symbolic module. With these inputs, the LLM agent chooses an action and interacts with the game environments. Our experimental results demonstrate that our method significantly enhances the capability of LLMs as automated agents for symbolic reasoning, and our LLM agent is effective in text-based games involving symbolic tasks, achieving an average performance of 88% across all tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.09686",
        "abstract url": "https://arxiv.org/abs/2401.09686",
        "title": "An Empirical Study on the Impact of Positional Encoding in Transformer-based Monaural Speech Enhancement",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Transformer architecture has enabled recent progress in speech enhancement. Since Transformers are position-agostic, positional encoding is the de facto standard component used to enable Transformers to distinguish the order of elements in a sequence. However, it remains unclear how positional encoding exactly impacts speech enhancement based on Transformer architectures. In this paper, we perform a comprehensive empirical study evaluating five positional encoding methods, i.e., Sinusoidal and learned absolute position embedding (APE), T5-RPE, KERPLE, as well as the Transformer without positional encoding (No-Pos), across both causal and noncausal configurations. We conduct extensive speech enhancement experiments, involving spectral mapping and masking methods. Our findings establish that positional encoding is not quite helpful for the models in a causal configuration, which indicates that causal attention may implicitly incorporate position information. In a noncausal configuration, the models significantly benefit from the use of positional encoding. In addition, we find that among the four position embeddings, relative position embeddings outperform APEs.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2401.09709",
        "abstract url": "https://arxiv.org/abs/2401.09709",
        "title": "P2Seg: Pointly-supervised Segmentation via Mutual Distillation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Point-level Supervised Instance Segmentation (PSIS) aims to enhance the applicability and scalability of instance segmentation by utilizing low-cost yet instance-informative annotations. Existing PSIS methods usually rely on positional information to distinguish objects, but predicting precise boundaries remains challenging due to the lack of contour annotations. Nevertheless, weakly supervised semantic segmentation methods are proficient in utilizing intra-class feature consistency to capture the boundary contours of the same semantic regions. In this paper, we design a Mutual Distillation Module (MDM) to leverage the complementary strengths of both instance position and semantic information and achieve accurate instance-level object perception. The MDM consists of Semantic to Instance (S2I) and Instance to Semantic (I2S). S2I is guided by the precise boundaries of semantic regions to learn the association between annotated points and instance contours. I2S leverages discriminative relationships between instances to facilitate the differentiation of various objects within the semantic map. Extensive experiments substantiate the efficacy of MDM in fostering the synergy between instance and semantic information, consequently improving the quality of instance-level object representations. Our method achieves 55.7 mAP$_{50}$ and 17.6 mAP on the PASCAL VOC and MS COCO datasets, significantly outperforming recent PSIS methods and several box-supervised instance segmentation competitors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 12 figures, published to ICLR2024"
    },
    {
        "paper id": "2401.12992",
        "abstract url": "https://arxiv.org/abs/2401.12992",
        "title": "TranSentence: Speech-to-speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Although there has been significant advancement in the field of speech-to-speech translation, conventional models still require language-parallel speech data between the source and target languages for training. In this paper, we introduce TranSentence, a novel speech-to-speech translation without language-parallel speech data. To achieve this, we first adopt a language-agnostic sentence-level speech encoding that captures the semantic information of speech, irrespective of language. We then train our model to generate speech based on the encoded embedding obtained from a language-agnostic sentence-level speech encoder that is pre-trained with various languages. With this method, despite training exclusively on the target language's monolingual data, we can generate target language speech in the inference stage using language-agnostic speech embedding from the source language speech. Furthermore, we extend TranSentence to multilingual speech-to-speech translation. The experimental results demonstrate that TranSentence is superior to other models.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2401.08986",
        "abstract url": "https://arxiv.org/abs/2401.08986",
        "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2401.09003",
        "abstract url": "https://arxiv.org/abs/2401.09003",
        "title": "Augmenting Math Word Problems via Iterative Question Composing",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Despite the advancements in large language models (LLMs) for mathematical reasoning, solving competition-level math problems remains a significant challenge, especially for open-source LLMs without external tools. We introduce the MMIQC dataset, comprising a mixture of processed web data and synthetic question-response pairs, aimed at enhancing the mathematical reasoning capabilities of base language models. Models fine-tuned on MMIQC consistently surpass their counterparts in performance on the MATH benchmark across various model sizes. Notably, Qwen-72B-MMIQC achieves a 45.0% accuracy, exceeding the previous open-source state-of-the-art by 8.2% and outperforming the initial version GPT-4 released in 2023. Extensive evaluation results on Hungarian high school finals suggest that such improvement can generalize to unseen data. Our ablation study on MMIQC reveals that a large part of the improvement can be attributed to our novel augmentation method, Iterative Question Composing (IQC), which involves iteratively composing new questions from seed problems using an LLM and applying rejection sampling through another LLM. The MMIQC dataset is available on the HuggingFace hub at https://huggingface.co/datasets/Vivacem/MMIQC. Our code is available at https://github.com/iiis-ai/IterativeQuestionComposing.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09008",
        "abstract url": "https://arxiv.org/abs/2401.09008",
        "title": "Hybrid of DiffStride and Spectral Pooling in Convolutional Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Stride determines the distance between adjacent filter positions as the filter moves across the input. A fixed stride causes important information contained in the image can not be captured, so that important information is not classified. Therefore, in previous research, the DiffStride Method was applied, namely the Strided Convolution Method with which it can learn its own stride value. Severe Quantization and a constraining lower bound on preserved information are arises with Max Pooling Downsampling Method. Spectral Pooling reduce the constraint lower bound on preserved information by cutting off the representation in the frequency domain. In this research a CNN Model is proposed with the Downsampling Learnable Stride Technique performed by Backpropagation combined with the Spectral Pooling Technique. Diffstride and Spectral Pooling techniques are expected to maintain most of the information contained in the image. In this study, we compare the Hybrid Method, which is a combined implementation of Spectral Pooling and DiffStride against the Baseline Method, which is the DiffStride implementation on ResNet 18. The accuracy result of the DiffStride combination with Spectral Pooling improves over DiffStride which is baseline method by 0.0094. This shows that the Hybrid Method can maintain most of the information by cutting of the representation in the frequency domain and determine the stride of the learning result through Backpropagation.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09023",
        "abstract url": "https://arxiv.org/abs/2401.09023",
        "title": "Explain Thyself Bully: Sentiment Aided Cyberbullying Detection with Explanation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Cyberbullying has become a big issue with the popularity of different social media networks and online communication apps. While plenty of research is going on to develop better models for cyberbullying detection in monolingual language, there is very little research on the code-mixed languages and explainability aspect of cyberbullying. Recent laws like \"right to explanations\" of General Data Protection Regulation, have spurred research in developing interpretable models rather than focusing on performance. Motivated by this we develop the first interpretable multi-task model called {\\em mExCB} for automatic cyberbullying detection from code-mixed languages which can simultaneously solve several tasks, cyberbullying detection, explanation/rationale identification, target group detection and sentiment analysis. We have introduced {\\em BullyExplain}, the first benchmark dataset for explainable cyberbullying detection in code-mixed language. Each post in {\\em BullyExplain} dataset is annotated with four labels, i.e., {\\em bully label, sentiment label, target and rationales (explainability)}, i.e., which phrases are being responsible for annotating the post as a bully. The proposed multitask framework (mExCB) based on CNN and GRU with word and sub-sentence (SS) level attention is able to outperform several baselines and state of the art models when applied on {\\em BullyExplain} dataset.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ICDAR 2023"
    },
    {
        "paper id": "2401.09041",
        "abstract url": "https://arxiv.org/abs/2401.09041",
        "title": "Textual Summarisation of Large Sets: Towards a General Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We are developing techniques to generate summary descriptions of sets of objects. In this paper, we present and evaluate a rule-based NLG technique for summarising sets of bibliographical references in academic papers. This extends our previous work on summarising sets of consumer products and shows how our model generalises across these two very different domains.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09073",
        "abstract url": "https://arxiv.org/abs/2401.09073",
        "title": "Fixed-Budget Differentially Private Best Arm Identification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "We study best arm identification (BAI) in linear bandits in the fixed-budget regime under differential privacy constraints, when the arm rewards are supported on the unit interval. Given a finite budget $T$ and a privacy parameter $\\varepsilon>0$, the goal is to minimise the error probability in finding the arm with the largest mean after $T$ sampling rounds, subject to the constraint that the policy of the decision maker satisfies a certain {\\em $\\varepsilon$-differential privacy} ($\\varepsilon$-DP) constraint. We construct a policy satisfying the $\\varepsilon$-DP constraint (called {\\sc DP-BAI}) by proposing the principle of {\\em maximum absolute determinants}, and derive an upper bound on its error probability. Furthermore, we derive a minimax lower bound on the error probability, and demonstrate that the lower and the upper bounds decay exponentially in $T$, with exponents in the two bounds matching order-wise in (a) the sub-optimality gaps of the arms, (b) $\\varepsilon$, and (c) the problem complexity that is expressible as the sum of two terms, one characterising the complexity of standard fixed-budget BAI (without privacy constraints), and the other accounting for the $\\varepsilon$-DP constraint. Additionally, we present some auxiliary results that contribute to the derivation of the lower bound on the error probability. These results, we posit, may be of independent interest and could prove instrumental in proving lower bounds on error probabilities in several other bandit problems. Whereas prior works provide results for BAI in the fixed-budget regime without privacy constraints or in the fixed-confidence regime with privacy constraints, our work fills the gap in the literature by providing the results for BAI in the fixed-budget regime under the $\\varepsilon$-DP constraint.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IT",
            "math.ST",
            "stat.ML"
        ],
        "comment": "Accepted to ICLR 2024"
    },
    {
        "paper id": "2401.09074",
        "abstract url": "https://arxiv.org/abs/2401.09074",
        "title": "Code Simulation Challenges for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking at straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirically, our new Chain of Simulation (CoSm) method improves on the standard Chain of Thought prompting approach by avoiding the pitfalls of memorisation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.PL"
        ],
        "comment": "main paper (10 pages) + Appendix (11 pages)"
    },
    {
        "paper id": "2401.09082",
        "abstract url": "https://arxiv.org/abs/2401.09082",
        "title": "What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good' social actors and treat people respectfully.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09135",
        "abstract url": "https://arxiv.org/abs/2401.09135",
        "title": "Asynchronous Local-SGD Training for Language Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Local stochastic gradient descent (Local-SGD), also referred to as federated averaging, is an approach to distributed optimization where each device performs more than one SGD update per communication. This work presents an empirical study of {\\it asynchronous} Local-SGD for training language models; that is, each worker updates the global parameters as soon as it has finished its SGD steps. We conduct a comprehensive investigation by examining how worker hardware heterogeneity, model size, number of workers, and optimizer could impact the learning performance. We find that with naive implementations, asynchronous Local-SGD takes more iterations to converge than its synchronous counterpart despite updating the (global) model parameters more frequently. We identify momentum acceleration on the global parameters when worker gradients are stale as a key challenge. We propose a novel method that utilizes a delayed Nesterov momentum update and adjusts the workers' local training steps based on their computation speed. This approach, evaluated with models up to 150M parameters on the C4 dataset, matches the performance of synchronous Local-SGD in terms of perplexity per update step, and significantly surpasses it in terms of wall clock time.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09140",
        "abstract url": "https://arxiv.org/abs/2401.09140",
        "title": "Relative Pose for Nonrigid Multi-Perspective Cameras: The Static Case",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-perspective cameras with potentially non-overlapping fields of view have become an important exteroceptive sensing modality in a number of applications such as intelligent vehicles, drones, and mixed reality headsets. In this work, we challenge one of the basic assumptions made in these scenarios, which is that the multi-camera rig is rigid. More specifically, we are considering the problem of estimating the relative pose between a static non-rigid rig in different spatial orientations while taking into account the effect of gravity onto the system. The deformable physical connections between each camera and the body center are approximated by a simple cantilever model, and inserted into the generalized epipolar constraint. Our results lead us to the important insight that the latent parameters of the deformation model, meaning the gravity vector in both views, become observable. We present a concise analysis of the observability of all variables based on noise, outliers, and rig rigidity for two different algorithms. The first one is a vision-only alternative, while the second one makes use of additional gravity measurements. To conclude, we demonstrate the ability to sense gravity in a real-world example, and discuss practical implications.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09146",
        "abstract url": "https://arxiv.org/abs/2401.09146",
        "title": "Continuous Piecewise-Affine Based Motion Model for Image Animation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image animation aims to bring static images to life according to driving videos and create engaging visual content that can be used for various purposes such as animation, entertainment, and education. Recent unsupervised methods utilize affine and thin-plate spline transformations based on keypoints to transfer the motion in driving frames to the source image. However, limited by the expressive power of the transformations used, these methods always produce poor results when the gap between the motion in the driving frame and the source image is large. To address this issue, we propose to model motion from the source image to the driving frame in highly-expressive diffeomorphism spaces. Firstly, we introduce Continuous Piecewise-Affine based (CPAB) transformation to model the motion and present a well-designed inference algorithm to generate CPAB transformation from control keypoints. Secondly, we propose a SAM-guided keypoint semantic loss to further constrain the keypoint extraction process and improve the semantic consistency between the corresponding keypoints on the source and driving images. Finally, we design a structure alignment loss to align the structure-related features extracted from driving and generated images, thus helping the generator generate results that are more consistent with the driving action. Extensive experiments on four datasets demonstrate the effectiveness of our method against state-of-the-art competitors quantitatively and qualitatively. Code will be publicly available at: https://github.com/DevilPG/AAAI2024-CPABMM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09149",
        "abstract url": "https://arxiv.org/abs/2401.09149",
        "title": "InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding",
        "rating": "1",
        "keywords": [
            [
                "GPU memory"
            ]
        ],
        "abstract": "Large language models (LLMs) with long sequences begin to power more and more fundamentally new applications we use every day. Existing methods for long-sequence LLM training are neither efficient nor compatible with commonly-used training algorithms such as FlashAttention. We design InternEvo to address these issues. InternEvo decouples all of the sharding dimensions into a new hierarchical space, and systematically analyzes the memory and communication cost of LLM training. Then, it generates an effective hybrid parallelism strategy. We design a new selective overlap mechanism to mitigate the communication overhead introduced by the hybrid parallelism. We also implement memory management techniques to reduce GPU memory fragmentation. Evaluation results show that InternEvo generates parallelization strategies that match or outperform existing methods in model FLOPs utilization.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09168",
        "abstract url": "https://arxiv.org/abs/2401.09168",
        "title": "Fine-tuning Strategies for Domain Specific Question Answering under Low Annotation Budget Constraints",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The progress introduced by pre-trained language models and their fine-tuning has resulted in significant improvements in most downstream NLP tasks. The unsupervised training of a language model combined with further target task fine-tuning has become the standard QA fine-tuning procedure. In this work, we demonstrate that this strategy is sub-optimal for fine-tuning QA models, especially under a low QA annotation budget, which is a usual setting in practice due to the extractive QA labeling cost. We draw our conclusions by conducting an exhaustive analysis of the performance of the alternatives of the sequential fine-tuning strategy on different QA datasets. Based on the experiments performed, we observed that the best strategy to fine-tune the QA model in low-budget settings is taking a pre-trained language model (PLM) and then fine-tuning PLM with a dataset composed of the target dataset and SQuAD dataset. With zero extra annotation effort, the best strategy outperforms the standard strategy by 2.28% to 6.48%. Our experiments provide one of the first investigations on how to best fine-tune a QA system under a low budget and are therefore of the utmost practical interest to the QA practitioners.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09175",
        "abstract url": "https://arxiv.org/abs/2401.09175",
        "title": "QAnswer: Towards Question Answering Search over Websites",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Question Answering (QA) is increasingly used by search engines to provide results to their end-users, yet very few websites currently use QA technologies for their search functionality. To illustrate the potential of QA technologies for the website search practitioner, we demonstrate web searches that combine QA over knowledge graphs and QA over free text -- each being usually tackled separately. We also discuss the different benefits and drawbacks of both approaches for web site searches. We use the case studies made of websites hosted by the Wikimedia Foundation (namely Wikipedia and Wikidata). Differently from a search engine (e.g. Google, Bing, etc), the data are indexed integrally, i.e. we do not index only a subset, and they are indexed exclusively, i.e. we index only data available on the corresponding website.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09180",
        "abstract url": "https://arxiv.org/abs/2401.09180",
        "title": "Unsupervised Multiple Domain Translation through Controlled Disentanglement in Variational Autoencoder",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised Multiple Domain Translation is the task of transforming data from one domain to other domains without having paired data to train the systems. Typically, methods based on Generative Adversarial Networks (GANs) are used to address this task. However, our proposal exclusively relies on a modified version of a Variational Autoencoder. This modification consists of the use of two latent variables disentangled in a controlled way by design. One of this latent variables is imposed to depend exclusively on the domain, while the other one must depend on the rest of the variability factors of the data. Additionally, the conditions imposed over the domain latent variable allow for better control and understanding of the latent space. We empirically demonstrate that our approach works on different vision datasets improving the performance of other well known methods. Finally, we prove that, indeed, one of the latent variables stores all the information related to the domain and the other one hardly contains any domain information.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09207",
        "abstract url": "https://arxiv.org/abs/2401.09207",
        "title": "An Energy-efficient Capacitive-Memristive Content Addressable Memory",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Content addressable memory is popular in the field of intelligent computing systems with its searching nature. Emerging CAMs show a promising increase in pixel density and a decrease in power consumption than pure CMOS solutions. This article introduced an energy-efficient 3T1R1C TCAM cooperating with capacitor dividers and RRAM devices. The RRAM as a storage element also acts as a switch to the capacitor divider while searching for content. CAM cells benefit from working parallel in an array structure. We implemented a 64 x 64 array and digital controllers to perform with an internal built-in clock frequency of 875MHz. Both data searches and reads take 3x clock cycles. Its worst average energy for data match is reported to be 1.71 fJ/bit-search and the worst average energy for data miss is found with 4.69 fJ/bit-search. The prototype is simulated and fabricated in 0.18 um technology with in-lab RRAM post-processing. Such memory explores the charge domain searching mechanism and can be applied to data centers that are power-hungry.",
        "subjects": [
            "eess.SY",
            "eess.IV"
        ],
        "comment": "This work has been submitted to the IEEE TCAS-I for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2401.09220",
        "abstract url": "https://arxiv.org/abs/2401.09220",
        "title": "UniVIE: A Unified Label Space Approach to Visual Information Extraction from Form-like Documents",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Existing methods for Visual Information Extraction (VIE) from form-like documents typically fragment the process into separate subtasks, such as key information extraction, key-value pair extraction, and choice group extraction. However, these approaches often overlook the hierarchical structure of form documents, including hierarchical key-value pairs and hierarchical choice groups. To address these limitations, we present a new perspective, reframing VIE as a relation prediction problem and unifying labels of different tasks into a single label space. This unified approach allows for the definition of various relation types and effectively tackles hierarchical relationships in form-like documents. In line with this perspective, we present UniVIE, a unified model that addresses the VIE problem comprehensively. UniVIE functions using a coarse-to-fine strategy. It initially generates tree proposals through a tree proposal network, which are subsequently refined into hierarchical trees by a relation decoder module. To enhance the relation prediction capabilities of UniVIE, we incorporate two novel tree constraints into the relation decoder: a tree attention mask and a tree level embedding. Extensive experimental evaluations on both our in-house dataset HierForms and a publicly available dataset SIBR, substantiate that our method achieves state-of-the-art results, underscoring the effectiveness and potential of our unified approach in advancing the field of VIE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09244",
        "abstract url": "https://arxiv.org/abs/2401.09244",
        "title": "Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The growing prevalence and rapid evolution of offensive language in social media amplify the complexities of detection, particularly highlighting the challenges in identifying such content across diverse languages. This survey presents a systematic and comprehensive exploration of Cross-Lingual Transfer Learning (CLTL) techniques in offensive language detection in social media. Our study stands as the first holistic overview to focus exclusively on the cross-lingual scenario in this domain. We analyse 67 relevant papers and categorise these studies across various dimensions, including the characteristics of multilingual datasets used, the cross-lingual resources employed, and the specific CLTL strategies implemented. According to \"what to transfer\", we also summarise three main CLTL transfer approaches: instance, feature, and parameter transfer. Additionally, we shed light on the current challenges and future research opportunities in this field. Furthermore, we have made our survey resources available online, including two comprehensive tables that provide accessible references to the multilingual datasets and CLTL methods used in the reviewed literature.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "35 pages, 7 figures"
    },
    {
        "paper id": "2401.09245",
        "abstract url": "https://arxiv.org/abs/2401.09245",
        "title": "Uncertainty estimates for semantic segmentation: providing enhanced reliability for automated motor claims handling",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural network models for image segmentation can be a powerful tool for the automation of motor claims handling processes in the insurance industry. A crucial aspect is the reliability of the model outputs when facing adverse conditions, such as low quality photos taken by claimants to document damages. We explore the use of a meta-classification model to assess the precision of segments predicted by a model trained for the semantic segmentation of car body parts. Different sets of features correlated with the quality of a segment are compared, and an AUROC score of 0.915 is achieved for distinguishing between high- and low-quality segments. By removing low-quality segments, the average mIoU of the segmentation output is improved by 16 percentage points and the number of wrongly predicted segments is reduced by 77%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 7 figures, 2 tables, submitted to MVAA"
    },
    {
        "paper id": "2401.09248",
        "abstract url": "https://arxiv.org/abs/2401.09248",
        "title": "Learning from Emotions, Demographic Information and Implicit User Feedback in Task-Oriented Document-Grounded Dialogues",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The success of task-oriented and document-grounded dialogue systems depends on users accepting and enjoying using them. To achieve this, recently published work in the field of Human-Computer Interaction suggests that the combination of considering demographic information, user emotions and learning from the implicit feedback in their utterances, is particularly important. However, these findings have not yet been transferred to the field of Natural Language Processing, where these data are primarily studied separately. Accordingly, no sufficiently annotated dataset is available. To address this gap, we introduce FEDI, the first English dialogue dataset for task-oriented document-grounded dialogues annotated with demographic information, user emotions and implicit feedback. Our experiments with FLAN-T5, GPT-2 and LLaMA-2 show that these data have the potential to improve task completion and the factual consistency of the generated responses and user acceptance.",
        "subjects": [
            "cs.CL",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09278",
        "abstract url": "https://arxiv.org/abs/2401.09278",
        "title": "Adaptive Regret for Bandits Made Possible: Two Queries Suffice",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Fast changing states or volatile environments pose a significant challenge to online optimization, which needs to perform rapid adaptation under limited observation. In this paper, we give query and regret optimal bandit algorithms under the strict notion of strongly adaptive regret, which measures the maximum regret over any contiguous interval $I$. Due to its worst-case nature, there is an almost-linear $\u03a9(|I|^{1-\u03b5})$ regret lower bound, when only one query per round is allowed [Daniely el al, ICML 2015]. Surprisingly, with just two queries per round, we give Strongly Adaptive Bandit Learner (StABL) that achieves $\\tilde{O}(\\sqrt{n|I|})$ adaptive regret for multi-armed bandits with $n$ arms. The bound is tight and cannot be improved in general. Our algorithm leverages a multiplicative update scheme of varying stepsizes and a carefully chosen observation distribution to control the variance. Furthermore, we extend our results and provide optimal algorithms in the bandit convex optimization setting. Finally, we empirically demonstrate the superior performance of our algorithms under volatile environments and for downstream tasks, such as algorithm selection for hyperparameter optimization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR2024"
    },
    {
        "paper id": "2401.09286",
        "abstract url": "https://arxiv.org/abs/2401.09286",
        "title": "Deployable Reinforcement Learning with Variable Control Rate",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Deploying controllers trained with Reinforcement Learning (RL) on real robots can be challenging: RL relies on agents' policies being modeled as Markov Decision Processes (MDPs), which assume an inherently discrete passage of time. The use of MDPs results in that nearly all RL-based control systems employ a fixed-rate control strategy with a period (or time step) typically chosen based on the developer's experience or specific characteristics of the application environment. Unfortunately, the system should be controlled at the highest, worst-case frequency to ensure stability, which can demand significant computational and energy resources and hinder the deployability of the controller on onboard hardware. Adhering to the principles of reactive programming, we surmise that applying control actions only when necessary enables the use of simpler hardware and helps reduce energy consumption. We challenge the fixed frequency assumption by proposing a variant of RL with variable control rate. In this approach, the policy decides the action the agent should take as well as the duration of the time step associated with that action. In our new setting, we expand Soft Actor-Critic (SAC) to compute the optimal policy with a variable control rate, introducing the Soft Elastic Actor-Critic (SEAC) algorithm. We show the efficacy of SEAC through a proof-of-concept simulation driving an agent with Newtonian kinematics. Our experiments show higher average returns, shorter task completion times, and reduced computational resources when compared to fixed rate policies.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "Paper for AAAI-DAI 2024 workshop"
    },
    {
        "paper id": "2401.09290",
        "abstract url": "https://arxiv.org/abs/2401.09290",
        "title": "G-Safe: Safe GPU Sharing in Multi-Tenant Environments",
        "rating": "1",
        "keywords": [
            [
                "GPU memory"
            ]
        ],
        "abstract": "Modern GPU applications, such as machine learning (ML) frameworks, can only partially utilize beefy GPUs, leading to GPU underutilization in cloud environments. Sharing GPUs across multiple applications from different users can improve resource utilization and consequently cost, energy, and power efficiency. However, GPU sharing creates memory safety concerns because kernels must share a single GPU address space (GPU context). Previous GPU memory protection approaches have limited deployability because they require specialized hardware extensions or access to source code. This is often unavailable in GPU-accelerated libraries heavily utilized by ML frameworks. In this paper, we present G-Safe, a PTX-level bounds checking approach for GPUs that limits GPU kernels of each application to stay within the memory partition allocated to them. G-Safe relies on three mechanisms: (1) It divides the common GPU address space into separate partitions for different applications. (2) It intercepts and checks data transfers, fencing erroneous operations. (3) It instruments all GPU kernels at the PTX level (available in closed GPU libraries) fencing all kernel memory accesses outside application memory bounds. We implement G-Safe as an external, dynamically linked library that can be pre-loaded at application startup time. G-Safe's approach is transparent to applications and can support real-life, complex frameworks, such as Caffe and PyTorch, that issue billions of GPU kernels. Our evaluation shows that the overhead of G-Safe compared to native (unprotected) for such frameworks is between 4\\% - 12\\% and on average 9\\%.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09296",
        "abstract url": "https://arxiv.org/abs/2401.09296",
        "title": "Tight Fusion of Events and Inertial Measurements for Direct Velocity Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traditional visual-inertial state estimation targets absolute camera poses and spatial landmark locations while first-order kinematics are typically resolved as an implicitly estimated sub-state. However, this poses a risk in velocity-based control scenarios, as the quality of the estimation of kinematics depends on the stability of absolute camera and landmark coordinates estimation. To address this issue, we propose a novel solution to tight visual-inertial fusion directly at the level of first-order kinematics by employing a dynamic vision sensor instead of a normal camera. More specifically, we leverage trifocal tensor geometry to establish an incidence relation that directly depends on events and camera velocity, and demonstrate how velocity estimates in highly dynamic situations can be obtained over short time intervals. Noise and outliers are dealt with using a nested two-layer RANSAC scheme. Additionally, smooth velocity signals are obtained from a tight fusion with pre-integrated inertial signals using a sliding window optimizer. Experiments on both simulated and real data demonstrate that the proposed tight event-inertial fusion leads to continuous and reliable velocity estimation in highly dynamic scenarios independently of absolute coordinates. Furthermore, in extreme cases, it achieves more stable and more accurate estimation of kinematics than traditional, point-position-based visual-inertial odometry.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted by IEEE Transactions on Robotics (T-RO)"
    },
    {
        "paper id": "2401.09315",
        "abstract url": "https://arxiv.org/abs/2401.09315",
        "title": "On Speech Pre-emphasis as a Simple and Inexpensive Method to Boost Speech Enhancement",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Pre-emphasis filtering, compensating for the natural energy decay of speech at higher frequencies, has been considered as a common pre-processing step in a number of speech processing tasks over the years. In this work, we demonstrate, for the first time, that pre-emphasis filtering may also be used as a simple and computationally-inexpensive way to leverage deep neural network-based speech enhancement performance. Particularly, we look into pre-emphasizing the estimated and actual clean speech prior to loss calculation so that different speech frequency components better mirror their perceptual importance during the training phase. Experimental results on a noisy version of the TIMIT dataset show that integrating the pre-emphasis-based methodology at hand yields relative estimated speech quality improvements of up to 4.6% and 3.4% for noise types seen and unseen, respectively, during the training phase. Similar to the case of pre-emphasis being considered as a default pre-processing step in classical automatic speech recognition and speech coding systems, the pre-emphasis-based methodology analyzed in this article may potentially become a default add-on for modern speech enhancement.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09328",
        "abstract url": "https://arxiv.org/abs/2401.09328",
        "title": "Online Stability Improvement of Groebner Basis Solvers using Deep Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Over the past decade, the Gr\u00f6bner basis theory and automatic solver generation have lead to a large number of solutions to geometric vision problems. In practically all cases, the derived solvers apply a fixed elimination template to calculate the Gr\u00f6bner basis and thereby identify the zero-dimensional variety of the original polynomial constraints. However, it is clear that different variable or monomial orderings lead to different elimination templates, and we show that they may present a large variability in accuracy for a certain instance of a problem. The present paper has two contributions. We first show that for a common class of problems in geometric vision, variable reordering simply translates into a permutation of the columns of the initial coefficient matrix, and that -- as a result -- one and the same elimination template can be reused in different ways, each one leading to potentially different accuracy. We then prove that the original set of coefficients may contain sufficient information to train a classifier for online selection of a good solver, most notably at the cost of only a small computational overhead. We demonstrate wide applicability at the hand of generic dense polynomial problem solvers, as well as a concrete solver from geometric vision.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by 3DV 2019"
    },
    {
        "paper id": "2401.09333",
        "abstract url": "https://arxiv.org/abs/2401.09333",
        "title": "Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Current methods to identify and classify racist language in text rely on small-n qualitative approaches or large-n approaches focusing exclusively on overt forms of racist discourse. This article provides a step-by-step generalizable guideline to identify and classify different forms of racist discourse in large corpora. In our approach, we start by conceptualizing racism and its different manifestations. We then contextualize these racist manifestations to the time and place of interest, which allows researchers to identify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a cross-lingual model for supervised text classification with a cutting-edge contextual understanding of text. We show that XLM-R and XLM-R-Racismo, our pretrained model, outperform other state-of-the-art approaches in classifying racism in large corpora. We illustrate our approach using a corpus of tweets relating to the Ecuadorian ind\u00edgena community between 2018 and 2021.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "37 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2401.09343",
        "abstract url": "https://arxiv.org/abs/2401.09343",
        "title": "Efficient slot labelling",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Slot labelling is an essential component of any dialogue system, aiming to find important arguments in every user turn. Common approaches involve large pre-trained language models (PLMs) like BERT or RoBERTa, but they face challenges such as high computational requirements and dependence on pre-training data. In this work, we propose a lightweight method which performs on par or better than the state-of-the-art PLM-based methods, while having almost 10x less trainable parameters. This makes it especially applicable for real-life industry scenarios.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09407",
        "abstract url": "https://arxiv.org/abs/2401.09407",
        "title": "Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "With the recent proliferation of Large Language Models (LLMs), there has been an increasing demand for tools to detect machine-generated text. The effective detection of machine-generated text face two pertinent problems: First, they are severely limited in generalizing against real-world scenarios, where machine-generated text is produced by a variety of generators, including but not limited to GPT-4 and Dolly, and spans diverse domains, ranging from academic manuscripts to social media posts. Second, existing detection methodologies treat texts produced by LLMs through a restrictive binary classification lens, neglecting the nuanced diversity of artifacts generated by different LLMs. In this work, we undertake a systematic study on the detection of machine-generated text in real-world scenarios. We first study the effectiveness of state-of-the-art approaches and find that they are severely limited against text produced by diverse generators and domains in the real world. Furthermore, t-SNE visualizations of the embeddings from a pretrained LLM's encoder show that they cannot reliably distinguish between human and machine-generated text. Based on our findings, we introduce a novel system, T5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder combined with LLM embedding sub-clustering to address the text produced by diverse generators and domains in the real world. We evaluate our approach across 9 machine-generated text systems and 9 domains and find that our approach provides state-of-the-art generalization ability, with an average increase in F1 score on machine-generated text of 19.6\\% on unseen generators and domains compared to the top performing existing approaches and correctly attributes the generator of text with an accuracy of 93.6\\%.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09518",
        "abstract url": "https://arxiv.org/abs/2401.09518",
        "title": "On-Off Pattern Encoding and Path-Count Encoding as Deep Neural Network Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding the encoded representation of Deep Neural Networks (DNNs) has been a fundamental yet challenging objective. In this work, we focus on two possible directions for analyzing representations of DNNs by studying simple image classification tasks. Specifically, we consider \\textit{On-Off pattern} and \\textit{PathCount} for investigating how information is stored in deep representations. On-off pattern of a neuron is decided as `on' or `off' depending on whether the neuron's activation after ReLU is non-zero or zero. PathCount is the number of paths that transmit non-zero energy from the input to a neuron. We investigate how neurons in the network encodes information by replacing each layer's activation with On-Off pattern or PathCount and evaluating its effect on classification performance. We also examine correlation between representation and PathCount. Finally, we show a possible way to improve an existing DNN interpretation method, Class Activation Map (CAM), by directly utilizing On-Off or PathCount.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2401.09555",
        "abstract url": "https://arxiv.org/abs/2401.09555",
        "title": "Improving Classification Performance With Human Feedback: Label a few, we label the rest",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In the realm of artificial intelligence, where a vast majority of data is unstructured, obtaining substantial amounts of labeled data to train supervised machine learning models poses a significant challenge. To address this, we delve into few-shot and active learning, where are goal is to improve AI models with human feedback on a few labeled examples. This paper focuses on understanding how a continuous feedback loop can refine models, thereby enhancing their accuracy, recall, and precision through incremental human input. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and SetFit, we aim to analyze the efficacy of using a limited number of labeled examples to substantially improve model accuracy. We benchmark this approach on the Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to prove that with just a few labeled examples, we are able to surpass the accuracy of zero shot large language models to provide enhanced text classification performance. We demonstrate that rather than needing to manually label millions of rows of data, we just need to label a few and the model can effectively predict the rest.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09566",
        "abstract url": "https://arxiv.org/abs/2401.09566",
        "title": "Aligning Large Language Models with Counterfactual DPO",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Advancements in large language models (LLMs) have demonstrated remarkable capabilities across a diverse range of applications. These models excel in generating text completions that are contextually coherent and cover an extensive array of subjects. However, the vast datasets required for their training make aligning response styles during the pretraining and instruction tuning phases challenging. Consequently, an additional alignment phase is typically employed, wherein the model is further trained with human preference data to better align its outputs with human expectations. While this process doesn't introduce new capabilities per se, it does accentuate generation styles innate to the model. This paper explores the utilization of counterfactual prompting within the framework of Direct Preference Optimization (DPO) to align the model's style without relying on human intervention. We demonstrate that this method effectively instils desirable behaviour, mitigates undesirable ones, and encourages the model to disregard inappropriate instructions. Our findings suggest that counterfactual prompting with DPO presents a low-resource way to fine-tune LLMs to meet the demands for responsible and ethically aligned AI systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09587",
        "abstract url": "https://arxiv.org/abs/2401.09587",
        "title": "Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Bilevel optimization is an important formulation for many machine learning problems. Current bilevel optimization algorithms assume that the gradient of the upper-level function is Lipschitz. However, recent studies reveal that certain neural networks such as recurrent neural networks (RNNs) and long-short-term memory networks (LSTMs) exhibit potential unbounded smoothness, rendering conventional bilevel optimization algorithms unsuitable. In this paper, we design a new bilevel optimization algorithm, namely BO-REP, to address this challenge. This algorithm updates the upper-level variable using normalized momentum and incorporates two novel techniques for updating the lower-level variable: \\textit{initialization refinement} and \\textit{periodic updates}. Specifically, once the upper-level variable is initialized, a subroutine is invoked to obtain a refined estimate of the corresponding optimal lower-level variable, and the lower-level variable is updated only after every specific period instead of each iteration. When the upper-level problem is nonconvex and unbounded smooth, and the lower-level problem is strongly convex, we prove that our algorithm requires $\\widetilde{\\mathcal{O}}(1/\u03b5^4)$ iterations to find an $\u03b5$-stationary point in the stochastic setting, where each iteration involves calling a stochastic gradient or Hessian-vector product oracle. Notably, this result matches the state-of-the-art complexity results under the bounded smoothness setting and without mean-squared smoothness of the stochastic gradient, up to logarithmic factors. Our proof relies on novel technical lemmas for the periodically updated lower-level variable, which are of independent interest. Our experiments on hyper-representation learning, hyperparameter optimization, and data hyper-cleaning for text classification tasks demonstrate the effectiveness of our proposed algorithm.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "Accepted by ICLR 2024, Spotlight"
    },
    {
        "paper id": "2401.09615",
        "abstract url": "https://arxiv.org/abs/2401.09615",
        "title": "Learning Shortcuts: On the Misleading Promise of NLU in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The advent of large language models (LLMs) has enabled significant performance gains in the field of natural language processing. However, recent studies have found that LLMs often resort to shortcuts when performing tasks, creating an illusion of enhanced performance while lacking generalizability in their decision rules. This phenomenon introduces challenges in accurately assessing natural language understanding in LLMs. Our paper provides a concise survey of relevant research in this area and puts forth a perspective on the implications of shortcut learning in the evaluation of language models, specifically for NLU tasks. This paper urges more research efforts to be put towards deepening our comprehension of shortcut learning, contributing to the development of more robust language models, and raising the standards of NLU evaluation in real-world scenarios.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted at HICSS-SDPS 2024"
    },
    {
        "paper id": "2401.09671",
        "abstract url": "https://arxiv.org/abs/2401.09671",
        "title": "Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised domain translation (UDT) aims to find functions that convert samples from one domain (e.g., sketches) to another domain (e.g., photos) without changing the high-level semantic meaning (also referred to as ``content''). The translation functions are often sought by probability distribution matching of the transformed source domain and target domain. CycleGAN stands as arguably the most representative approach among this line of work. However, it was noticed in the literature that CycleGAN and variants could fail to identify the desired translation functions and produce content-misaligned translations. This limitation arises due to the presence of multiple translation functions -- referred to as ``measure-preserving automorphism\" (MPA) -- in the solution space of the learning criteria. Despite awareness of such identifiability issues, solutions have remained elusive. This study delves into the core identifiability inquiry and introduces an MPA elimination theory. Our analysis shows that MPA is unlikely to exist, if multiple pairs of diverse cross-domain conditional distributions are matched by the learning function. Our theory leads to a UDT learner using distribution matching over auxiliary variable-induced subsets of the domains -- other than over the entire data domains as in the classical approaches. The proposed framework is the first to rigorously establish translation identifiability under reasonable UDT settings, to our best knowledge. Experiments corroborate with our theoretical claims.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09681",
        "abstract url": "https://arxiv.org/abs/2401.09681",
        "title": "Harnessing Density Ratios for Online Reinforcement Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The theories of offline and online reinforcement learning, despite having evolved in parallel, have begun to show signs of the possibility for a unification, with algorithms and analysis techniques for one setting often having natural counterparts in the other. However, the notion of density ratio modeling, an emerging paradigm in offline RL, has been largely absent from online RL, perhaps for good reason: the very existence and boundedness of density ratios relies on access to an exploratory dataset with good coverage, but the core challenge in online RL is to collect such a dataset without having one to start. In this work we show -- perhaps surprisingly -- that density ratio-based algorithms have online counterparts. Assuming only the existence of an exploratory distribution with good coverage, a structural condition known as coverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses density ratio realizability and value function realizability to perform sample-efficient online exploration. GLOW addresses unbounded density ratios via careful use of truncation, and combines this with optimism to guide exploration. GLOW is computationally inefficient; we complement it with a more efficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2022) wherein online RL is augmented with additional offline data. HyGLOW is derived as a special case of a more general meta-algorithm that provides a provable black-box reduction from hybrid RL to offline RL, which may be of independent interest.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2401.09716",
        "abstract url": "https://arxiv.org/abs/2401.09716",
        "title": "HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Domain Generalization (DG) endeavors to create machine learning models that excel in unseen scenarios by learning invariant features. In DG, the prevalent practice of constraining models to a fixed structure or uniform parameterization to encapsulate invariant features can inadvertently blend specific aspects. Such an approach struggles with nuanced differentiation of inter-domain variations and may exhibit bias towards certain domains, hindering the precise learning of domain-invariant features. Recognizing this, we introduce a novel method designed to supplement the model with domain-level and task-specific characteristics. This approach aims to guide the model in more effectively separating invariant features from specific characteristics, thereby boosting the generalization. Building on the emerging trend of visual prompts in the DG paradigm, our work introduces the novel \\textbf{H}ierarchical \\textbf{C}ontrastive \\textbf{V}isual \\textbf{P}rompt (HCVP) methodology. This represents a significant advancement in the field, setting itself apart with a unique generative approach to prompts, alongside an explicit model structure and specialized loss functions. Differing from traditional visual prompts that are often shared across entire datasets, HCVP utilizes a hierarchical prompt generation network enhanced by prompt contrastive learning. These generative prompts are instance-dependent, catering to the unique characteristics inherent to different domains and tasks. Additionally, we devise a prompt modulation network that serves as a bridge, effectively incorporating the generated visual prompts into the vision transformer backbone. Experiments conducted on five DG datasets demonstrate the effectiveness of HCVP, outperforming both established DG algorithms and adaptation protocols.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08993",
        "abstract url": "https://arxiv.org/abs/2401.08993",
        "title": "Estimating Gender Completeness in Wikipedia",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Gender imbalance in Wikipedia content is a known challenge which the editor community is actively addressing. The aim of this paper is to provide the Wikipedia community with instruments to estimate the magnitude of the problem for different entity types (also known as classes) in Wikipedia. To this end, we apply class completeness estimation methods based on the gender attribute. Our results show not only which gender for different sub-classes of Person is more prevalent in Wikipedia, but also an idea of how complete the coverage is for difference genders and sub-classes of Person.",
        "subjects": [
            "cs.CY",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09011",
        "abstract url": "https://arxiv.org/abs/2401.09011",
        "title": "Inductive Models for Artificial Intelligence Systems are Insufficient without Good Explanations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper discusses the limitations of machine learning (ML), particularly deep artificial neural networks (ANNs), which are effective at approximating complex functions but often lack transparency and explanatory power. It highlights the `problem of induction' : the philosophical issue that past observations may not necessarily predict future events, a challenge that ML models face when encountering new, unseen data. The paper argues for the importance of not just making predictions but also providing good explanations, a feature that current models often fail to deliver. It suggests that for AI to progress, we must seek models that offer insights and explanations, not just predictions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09044",
        "abstract url": "https://arxiv.org/abs/2401.09044",
        "title": "Algorithmic amplification of biases on Google Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The evolution of information-seeking processes, driven by search engines like Google, has transformed the access to information people have. This paper investigates how individuals' preexisting attitudes influence the modern information-seeking process, specifically the results presented by Google Search. Through a comprehensive study involving surveys and information-seeking tasks focusing on the topic of abortion, the paper provides four crucial insights: 1) Individuals with opposing attitudes on abortion receive different search results. 2) Individuals express their beliefs in their choice of vocabulary used in formulating the search queries, shaping the outcome of the search. 3) Additionally, the user's search history contributes to divergent results among those with opposing attitudes. 4) Google Search engine reinforces preexisting beliefs in search results. Overall, this study provides insights into the interplay between human biases and algorithmic processes, highlighting the potential for information polarization in modern information-seeking processes.",
        "subjects": [
            "cs.CY",
            "cs.HC",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09052",
        "abstract url": "https://arxiv.org/abs/2401.09052",
        "title": "Flow Divergence: Comparing Maps of Flows with Relative Entropy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Networks represent how the entities of a system are connected and can be partitioned differently, prompting ways to compare partitions. Common approaches for comparing network partitions include information-theoretic measures based on mutual information and set-theoretic measures such as the Jaccard index. These measures are often based on computing the agreement in terms of overlap between different partitions of the same set. However, they ignore link patterns which are essential for the organisation of networks. We propose flow divergence, an information-theoretic divergence measure for comparing network partitions, inspired by the ideas behind the Kullback-Leibler divergence and the map equation for community detection. Similar to the Kullback-Leibler divergence, flow divergence adopts a coding perspective and compares two network partitions $\\mathsf{M}_a$ and $\\mathsf{M}_b$ by considering the expected extra number of bits required to describe a random walk on a network using $\\mathsf{M}_b$ relative to reference partition $\\mathsf{M}_a$. Because flow divergence is based on random walks, it can be used to compare partitions with arbitrary and different depths. We show that flow divergence distinguishes between partitions that traditional measures consider to be equally good when compared to a reference partition. Applied to real networks, we use flow divergence to estimate the cost of overfitting in incomplete networks and to visualise the solution landscape of network partitions.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09075",
        "abstract url": "https://arxiv.org/abs/2401.09075",
        "title": "GPT in Sheep's Clothing: The Risk of Customized GPTs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In November 2023, OpenAI introduced a new service allowing users to create custom versions of ChatGPT (GPTs) by using specific instructions and knowledge to guide the model's behavior. We aim to raise awareness of the fact that GPTs can be used maliciously, posing privacy and security risks to their users.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09102",
        "abstract url": "https://arxiv.org/abs/2401.09102",
        "title": "SendingNetwork: Advancing the Future of Decentralized Messaging Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In the evolving landscape of Internet technologies, where decentralized systems, especially blockchain-based computation and storage like Ethereum Virtual Machine (EVM), Arweave, and IPFS, are gaining prominence, there remains a stark absence of a holistic decentralized communication framework. This gap underlines the pressing necessity for a protocol that not only enables seamless cross-platform messaging but also allows direct messaging to wallet addresses, fostering interoperability and privacy across diverse platforms. SendingNetwork addresses this need by creating a reliable and secure decentralized communication network, targeting essential challenges like privacy protection, scalability, efficiency, and composability. Central to our approach is the incorporation of edge computing to form an adaptive relay network with the modular libp2p library. We introduce a dynamic group chat encryption mechanism based on the Double Ratchet algorithm for secure communication and propose a Delegation scheme for efficient message processing in large group chats, enhancing both resilience and scalability. Our theoretical analyses affirm the Delegation scheme's superior performance. To bolster system stability and encourage node participation, we integrate two innovative consensus mechanisms: \"Proof of Relay\" for validating message relay workload based on the novel KZG commitment, and \"Proof of Availability\" for ensuring network consistency and managing incentives through Verkle trees. Our whitepaper details the network's key components and architecture, concluding with a roadmap and a preview of future enhancements to SendingNetwork.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09181",
        "abstract url": "https://arxiv.org/abs/2401.09181",
        "title": "Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multimodal Continual Instruction Tuning (MCIT) enables Multimodal Large Language Models (MLLMs) to meet continuously emerging requirements without expensive retraining. MCIT faces two major obstacles: catastrophic forgetting (where old knowledge is forgotten) and negative forward transfer (where the performance of future tasks is degraded). Although existing methods have greatly alleviated catastrophic forgetting, they still suffer from negative forward transfer. By performing singular value decomposition (SVD) on input embeddings, we discover a large discrepancy in different input embeddings. The discrepancy results in the model learning irrelevant information for old and pre-trained tasks, which leads to catastrophic forgetting and negative forward transfer. To address these issues, we propose Fwd-Prompt, a prompt-based method projecting prompt gradient to the residual space to minimize the interference between tasks and to the pre-trained subspace for reusing pre-trained knowledge. Our experiments demonstrate that Fwd-Prompt achieves state-of-the-art performance while updating fewer parameters and requiring no old samples. Our research sheds light on the potential of continuously adapting MLLMs to new tasks under the instruction tuning paradigm and encourages future studies to explore MCIT. The code will soon be publicly available.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09184",
        "abstract url": "https://arxiv.org/abs/2401.09184",
        "title": "A Two-Scale Complexity Measure for Deep Learning Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a novel capacity measure 2sED for statistical models based on the effective dimension. The new quantity provably bounds the generalization error under mild assumptions on the model. Furthermore, simulations on standard data sets and popular model architectures show that 2sED correlates well with the training error. For Markovian models, we show how to efficiently approximate 2sED from below through a layerwise iterative approach, which allows us to tackle deep learning models with a large number of parameters. Simulation results suggest that the approximation is good for different prominent models and data sets.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09186",
        "abstract url": "https://arxiv.org/abs/2401.09186",
        "title": "The Mikado Filesystem: An experimental RPC filesystem running over gRPC",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Computer applications seeking to persist files remotely across the Internet are faced with a bewildering choice of mechanisms which tend to boil down to monolithic proprietary closed-source Vendor solutions. We introduce The Mikado Filesystem (mikfs), which provides an open simple lightweight interoperable portable extensible remote filesystem that is open source. mikfs consists of client applications accessing remote servers via RPC running over TCP/IP connections. mikfs is defined as a concrete set of API method calls over gRPC expressed in Google's Protocol Buffers' IDL. gRPC supports a wide variety of programming languages & platforms. For a given language + platform, the gRPC toolset can generate client- & server-side stubs from the IDL callable from client & server code in the selected languages, e.g., a client written in C# or java running on a Windows PC can access a server written in C++ running on Linux. mikfs consists of a virtual hierarchical tree of files & directories. This logical filesystem is not constrained to the limits and file naming conventions of the host's own physical native filesystem. API methods are provided for authentication; for atomic file-level operations on files & directories; for clients to register to receive notifications of file & directory changes on a server. The public API allows developers to write their own new servers and clients; allowing migration of hosted files between different implementations; extension with new methods & features; is Open Source code available for inspection and adaptation. gRPC provides secure authenticated connection & communication over HTTP/2; End-to-End Privacy & Security against eavesdropping of data in transit; support for multiple alternate user login mechanisms. mikfs is provided as source code, 'The Bootstrap Distribution', consisting of an ecosystem of clients, servers, tools and utilities.",
        "subjects": [
            "cs.NI",
            "cs.SI"
        ],
        "comment": "11 pages, 2 figures"
    },
    {
        "paper id": "2401.09191",
        "abstract url": "https://arxiv.org/abs/2401.09191",
        "title": "An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the success of deep learning-based algorithms, it is widely known that neural networks may fail to be robust. A popular paradigm to enforce robustness is adversarial training (AT), however, this introduces many computational and theoretical difficulties. Recent works have developed a connection between AT in the multiclass classification setting and multimarginal optimal transport (MOT), unlocking a new set of tools to study this problem. In this paper, we leverage the MOT connection to propose computationally tractable numerical algorithms for computing universal lower bounds on the optimal adversarial risk and identifying optimal classifiers. We propose two main algorithms based on linear programming (LP) and entropic regularization (Sinkhorn). Our key insight is that one can harmlessly truncate the higher order interactions between classes, preventing the combinatorial run times typically encountered in MOT problems. We validate these results with experiments on MNIST and CIFAR-$10$, which demonstrate the tractability of our approach.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09192",
        "abstract url": "https://arxiv.org/abs/2401.09192",
        "title": "Preparing Lessons for Progressive Training on Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "depth"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rapid progress of Transformers in artificial intelligence has come at the cost of increased resource consumption and greenhouse gas emissions due to growing model sizes. Prior work suggests using pretrained small models to improve training efficiency, but this approach may not be suitable for new model structures. On the other hand, training from scratch can be slow, and progressively stacking layers often fails to achieve significant acceleration. To address these challenges, we propose a novel method called Apollo, which prep\\textbf{a}res lessons for ex\\textbf{p}anding \\textbf{o}perations by \\textbf{l}earning high-\\textbf{l}ayer functi\\textbf{o}nality during training of low layers. Our approach involves low-value-prioritized sampling (LVPS) to train different depths and weight sharing to facilitate efficient expansion. We also introduce an interpolation method for stable model depth extension. Experiments demonstrate that Apollo achieves state-of-the-art acceleration ratios, even rivaling methods using pretrained models, making it a universal and efficient solution for training deep models while reducing time, financial, and environmental costs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09210",
        "abstract url": "https://arxiv.org/abs/2401.09210",
        "title": "Narratives of Collective Action in YouTube's Discourse on Veganism",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Narratives can be powerful tools for inspiring action on pressing societal issues such as climate change. While social science theories offer frameworks for understanding the narratives that arise within collective movements, these are rarely applied to the vast data available from social media platforms, which play a significant role in shaping public opinion and mobilizing collective action. This gap in the empirical evaluation of online narratives limits our understanding of their relationship with public response. In this study, we focus on plant-based diets as a form of pro-environmental action and employ natural language processing to operationalize a theoretical framework of moral narratives specific to the vegan movement. We apply this framework to narratives found in YouTube videos promoting environmental initiatives such as Veganuary, Meatless March, and No Meat May. Our analysis reveals that several narrative types, as defined by the theory, are empirically present in the data. To identify narratives with the potential to elicit positive public engagement, we used text processing to estimate the proportion of comments supporting collective action across narrative types. Video narratives advocating social fight, whether through protest or through efforts to convert others to the cause, are associated with a stronger sense of collective action in the respective comments. These narrative types also demonstrate increased semantic coherence and alignment between the message and public response, markers typically associated with successful collective action. Our work offers new insights into the complex factors that influence the emergence of collective action, thereby informing the development of effective communication strategies within social movements.",
        "subjects": [
            "cs.CY",
            "physics.soc-ph"
        ],
        "comment": "15 pages, 7 figures, 7 tables. Accepted at ICWSM 2024"
    },
    {
        "paper id": "2401.09237",
        "abstract url": "https://arxiv.org/abs/2401.09237",
        "title": "Classification and Reconstruction Processes in Deep Predictive Coding Networks: Antagonists or Allies?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predictive coding-inspired deep networks for visual computing integrate classification and reconstruction processes in shared intermediate layers. Although synergy between these processes is commonly assumed, it has yet to be convincingly demonstrated. In this study, we take a critical look at how classifying and reconstructing interact in deep learning architectures. Our approach utilizes a purposefully designed family of model architectures reminiscent of autoencoders, each equipped with an encoder, a decoder, and a classification head featuring varying modules and complexities. We meticulously analyze the extent to which classification- and reconstruction-driven information can seamlessly coexist within the shared latent layer of the model architectures. Our findings underscore a significant challenge: Classification-driven information diminishes reconstruction-driven information in intermediate layers' shared representations and vice versa. While expanding the shared representation's dimensions or increasing the network's complexity can alleviate this trade-off effect, our results challenge prevailing assumptions in predictive coding and offer guidance for future iterations of predictive coding concepts in deep networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09240",
        "abstract url": "https://arxiv.org/abs/2401.09240",
        "title": "A Blockchain-based Model for Securing Data Pipeline in a Heterogeneous Information System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In our digital world, access to personal and public data has become an item of concern, with challenging security and privacy aspects. Modern information systems are heterogeneous in nature and have an inherent security vulnerability, which is susceptible to data interception and data modification due to unsecured communication data pipelines between connected endpoints. This re-search article presents a blockchain-based model for securing data pipelines in a heterogeneous information system using an integrated multi-hazard early warning system (MHEWS) as a case study. The proposed model utilizes the inherent security features of blockchain technology to address the security and privacy concerns that arise in data pipelines. The model is designed to ensure data integrity, confidentiality, and authenticity in a decentralized manner. The model is evaluated in a hybrid environment using a prototype implementation and simulation experiments with outcomes that demonstrate advantages over traditional approaches for a tamper-proof and immutable data pipeline for data authenticity and integrity using a confidential ledger.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.DC",
            "cs.NI"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2401.09251",
        "abstract url": "https://arxiv.org/abs/2401.09251",
        "title": "Bridging the Gap Between General and Down-Closed Convex Sets in Submodular Maximization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Optimization of DR-submodular functions has experienced a notable surge in significance in recent times, marking a pivotal development within the domain of non-convex optimization. Motivated by real-world scenarios, some recent works have delved into the maximization of non-monotone DR-submodular functions over general (not necessarily down-closed) convex set constraints. Up to this point, these works have all used the minimum $\\ell_\\infty$ norm of any feasible solution as a parameter. Unfortunately, a recent hardness result due to Mualem \\& Feldman~\\cite{mualem2023resolving} shows that this approach cannot yield a smooth interpolation between down-closed and non-down-closed constraints. In this work, we suggest novel offline and online algorithms that provably provide such an interpolation based on a natural decomposition of the convex body constraint into two distinct convex bodies: a down-closed convex body and a general convex body. We also empirically demonstrate the superiority of our proposed algorithms across three offline and two online applications.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09257",
        "abstract url": "https://arxiv.org/abs/2401.09257",
        "title": "A First-Order Multi-Gradient Algorithm for Multi-Objective Bi-Level Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we study the Multi-Objective Bi-Level Optimization (MOBLO) problem, where the upper-level subproblem is a multi-objective optimization problem and the lower-level subproblem is for scalar optimization. Existing gradient-based MOBLO algorithms need to compute the Hessian matrix, causing the computational inefficient problem. To address this, we propose an efficient first-order multi-gradient method for MOBLO, called FORUM. Specifically, we reformulate MOBLO problems as a constrained multi-objective optimization (MOO) problem via the value-function approach. Then we propose a novel multi-gradient aggregation method to solve the challenging constrained MOO problem. Theoretically, we provide the complexity analysis to show the efficiency of the proposed method and a non-asymptotic convergence result. Empirically, extensive experiments demonstrate the effectiveness and efficiency of the proposed FORUM method in different learning problems. In particular, it achieves state-of-the-art performance on three multi-task learning benchmark datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2401.09274",
        "abstract url": "https://arxiv.org/abs/2401.09274",
        "title": "Avoiding strict saddle points of nonconvex regularized problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a strict saddle property for $\\ell_p$ regularized functions, and propose an iterative reweighted $\\ell_1$ algorithm to solve the $\\ell_p$ regularized problems. The algorithm is guaranteed to converge only to local minimizers when randomly initialized. The strict saddle property is shown generic on these sparse optimization problems. Those analyses as well as the proposed algorithm can be easily extended to general nonconvex regularized problems.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2401.09329",
        "abstract url": "https://arxiv.org/abs/2401.09329",
        "title": "Calibrate-Extrapolate: Rethinking Prevalence Estimation with Black Box Classifiers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In computational social science, researchers often use a pre-trained, black box classifier to estimate the frequency of each class in unlabeled datasets. A variety of prevalence estimation techniques have been developed in the literature, each yielding an unbiased estimate if certain stability assumption holds. This work introduces a framework to rethink the prevalence estimation process as calibrating the classifier outputs against ground truth labels to obtain the joint distribution of a base dataset and then extrapolating to the joint distribution of a target dataset. We call this framework \"Calibrate-Extrapolate\". It clarifies what stability assumptions must hold for a prevalence estimation technique to yield accurate estimates. In the calibration phase, the techniques assume only a stable calibration curve between a calibration dataset and the full base dataset. This allows for the classifier outputs to be used for disproportionate random sampling, thus improving the efficiency of calibration. In the extrapolation phase, some techniques assume a stable calibration curve while some assume stable class-conditional densities. We discuss the stability assumptions from a causal perspective. By specifying base and target joint distributions, we can generate simulated datasets, as a way to build intuitions about the impacts of assumption violations. This also leads to a better understanding of how the classifier's predictive power affects the accuracy of prevalence estimates: the greater the predictive power, the lower the sensitivity to violations of stability assumptions in the extrapolation phase. We illustrate the framework with an application that estimates the prevalence of toxic comments on news topics over time on Reddit, Twitter/X, and YouTube, using Jigsaw's Perspective API as a black box classifier. Finally, we summarize several practical advice for prevalence estimation.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "Accepted into ICWSM 2024, the code is publicly available at https://github.com/avalanchesiqi/pyquantifier"
    },
    {
        "paper id": "2401.09339",
        "abstract url": "https://arxiv.org/abs/2401.09339",
        "title": "Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approximation using Markovian samples and show their identical asymptotic performance, a perspective not evident from current finite-time bounds.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "comment": "To appear in AISTATS 2024"
    },
    {
        "paper id": "2401.09346",
        "abstract url": "https://arxiv.org/abs/2401.09346",
        "title": "High Confidence Level Inference is Almost Free using Parallel Stochastic Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Uncertainty quantification for estimation through stochastic optimization solutions in an online setting has gained popularity recently. This paper introduces a novel inference method focused on constructing confidence intervals with efficient computation and fast convergence to the nominal level. Specifically, we propose to use a small number of independent multi-runs to acquire distribution information and construct a t-based confidence interval. Our method requires minimal additional computation and memory beyond the standard updating of estimates, making the inference process almost cost-free. We provide a rigorous theoretical guarantee for the confidence interval, demonstrating that the coverage is approximately exact with an explicit convergence rate and allowing for high confidence level inference. In particular, a new Gaussian approximation result is developed for the online estimators to characterize the coverage properties of our confidence intervals in terms of relative errors. Additionally, our method also allows for leveraging parallel computing to further accelerate calculations using multiple cores. It is easy to implement and can be integrated with existing stochastic algorithms without the need for complicated modifications.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09356",
        "abstract url": "https://arxiv.org/abs/2401.09356",
        "title": "Swing: Short-cutting Rings for Higher Bandwidth Allreduce",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The allreduce collective operation accounts for a significant fraction of the runtime of workloads running on distributed systems. One factor determining its performance is the distance between communicating nodes, especially on networks like torus, where a higher distance implies multiple messages being forwarded on the same link, thus reducing the allreduce bandwidth. Torus networks are widely used on systems optimized for machine learning workloads (e.g., Google TPUs and Amazon Trainium devices), as well as on some of the Top500 supercomputers. To improve allreduce performance on torus networks we introduce Swing, a new algorithm that keeps a low distance between communicating nodes by swinging between torus directions. Our analysis and experimental evaluation show that Swing outperforms by up to 3x existing allreduce algorithms for vectors ranging from 32B to 128MiB, on different types of torus and torus-like topologies, regardless of their shape and size.",
        "subjects": [
            "cs.DC",
            "cs.LG",
            "cs.NI",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09368",
        "abstract url": "https://arxiv.org/abs/2401.09368",
        "title": "Feature-aware ultra-low dimensional reduction of real networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In existing models and embedding methods of networked systems, node features describing their qualities are usually overlooked in favor of focusing solely on node connectivity. This study introduces $FiD$-Mercator, a model-based ultra-low dimensional reduction technique that integrates node features with network structure to create $D$-dimensional maps of complex networks in a hyperbolic space. This embedding method efficiently uses features as an initial condition, guiding the search of nodes' coordinates towards an optimal solution. The research reveals that downstream task performance improves with the correlation between network connectivity and features, emphasizing the importance of such correlation for enhancing the description and predictability of real networks. Simultaneously, hyperbolic embedding's ability to reproduce local network properties remains unaffected by the inclusion of features. The findings highlight the necessity for developing novel network embedding techniques capable of exploiting such correlations to optimize both network structure and feature association jointly in the future.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09376",
        "abstract url": "https://arxiv.org/abs/2401.09376",
        "title": "Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the realm of machine learning and statistical modeling, practitioners often work under the assumption of accessible, static, labeled data for evaluation and training. However, this assumption often deviates from reality where data may be private, encrypted, difficult- to-measure, or unlabeled. In this paper, we bridge this gap by adapting the Hui-Walter paradigm, a method traditionally applied in epidemiology and medicine, to the field of machine learning. This approach enables us to estimate key performance metrics such as false positive rate, false negative rate, and priors in scenarios where no ground truth is available. We further extend this paradigm for handling online data, opening up new possibilities for dynamic data environments. Our methodology involves partitioning data into latent classes to simulate multiple data populations (if natural populations are unavailable) and independently training models to replicate multiple tests. By cross-tabulating binary outcomes across ensemble categorizers and multiple populations, we are able to estimate unknown parameters through Gibbs sampling, eliminating the need for ground-truth or labeled data. This paper showcases the potential of our methodology to transform machine learning practices by allowing for accurate model assessment under dynamic and uncertain data conditions.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09410",
        "abstract url": "https://arxiv.org/abs/2401.09410",
        "title": "Through the Looking-Glass: Transparency Implications and Challenges in Enterprise AI Knowledge Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Knowledge can't be disentangled from people. As AI knowledge systems mine vast volumes of work-related data, the knowledge that's being extracted and surfaced is intrinsically linked to the people who create and use it. When these systems get embedded in organizational settings, the information that is brought to the foreground and the information that's pushed to the periphery can influence how individuals see each other and how they see themselves at work. In this paper, we present the looking-glass metaphor and use it to conceptualize AI knowledge systems as systems that reflect and distort, expanding our view on transparency requirements, implications and challenges. We formulate transparency as a key mediator in shaping different ways of seeing, including seeing into the system, which unveils its capabilities, limitations and behavior, and seeing through the system, which shapes workers' perceptions of their own contributions and others within the organization. Recognizing the sociotechnical nature of these systems, we identify three transparency dimensions necessary to realize the value of AI knowledge systems, namely system transparency, procedural transparency and transparency of outcomes. We discuss key challenges hindering the implementation of these forms of transparency, bringing to light the wider sociotechnical gap and highlighting directions for future Computer-supported Cooperative Work (CSCW) research.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09413",
        "abstract url": "https://arxiv.org/abs/2401.09413",
        "title": "POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images",
        "rating": "0.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D",
                "voxel"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We describe an approach to predict open-vocabulary 3D semantic voxel occupancy map from input 2D images with the objective of enabling 3D grounding, segmentation and retrieval of free-form language queries. This is a challenging problem because of the 2D-3D ambiguity and the open-vocabulary nature of the target tasks, where obtaining annotated training data in 3D is difficult. The contributions of this work are three-fold. First, we design a new model architecture for open-vocabulary 3D semantic occupancy prediction. The architecture consists of a 2D-3D encoder together with occupancy prediction and 3D-language heads. The output is a dense voxel map of 3D grounded language embeddings enabling a range of open-vocabulary tasks. Second, we develop a tri-modal self-supervised learning algorithm that leverages three modalities: (i) images, (ii) language and (iii) LiDAR point clouds, and enables training the proposed architecture using a strong pre-trained vision-language model without the need for any 3D manual language annotations. Finally, we demonstrate quantitatively the strengths of the proposed model on several open-vocabulary tasks: Zero-shot 3D semantic segmentation using existing datasets; 3D grounding and retrieval of free-form language queries, using a small dataset that we propose as an extension of nuScenes. You can find the project page here https://vobecant.github.io/POP3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted to NeurIPS 2023"
    },
    {
        "paper id": "2401.09499",
        "abstract url": "https://arxiv.org/abs/2401.09499",
        "title": "Functional Autoencoder for Smoothing and Representation Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A common pipeline in functional data analysis is to first convert the discretely observed data to smooth functions, and then represent the functions by a finite-dimensional vector of coefficients summarizing the information. Existing methods for data smoothing and dimensional reduction mainly focus on learning the linear mappings from the data space to the representation space, however, learning only the linear representations may not be sufficient. In this study, we propose to learn the nonlinear representations of functional data using neural network autoencoders designed to process data in the form it is usually collected without the need of preprocessing. We design the encoder to employ a projection layer computing the weighted inner product of the functional data and functional weights over the observed timestamp, and the decoder to apply a recovery layer that maps the finite-dimensional vector extracted from the functional data back to functional space using a set of predetermined basis functions. The developed architecture can accommodate both regularly and irregularly spaced data. Our experiments demonstrate that the proposed method outperforms functional principal component analysis in terms of prediction and classification, and maintains superior smoothing ability and better computational efficiency in comparison to the conventional autoencoders under both linear and nonlinear settings.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09500",
        "abstract url": "https://arxiv.org/abs/2401.09500",
        "title": "A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes \\textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.",
        "subjects": [
            "q-bio.NC",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09507",
        "abstract url": "https://arxiv.org/abs/2401.09507",
        "title": "Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the e-commerce advertising scenario, estimating the true probabilities (known as a calibrated estimate) on CTR and CVR is critical and can directly affect the benefits of the buyer, seller and platform. Previous research has introduced numerous solutions for addressing the calibration problem. These methods typically involve the training of calibrators using a validation set and subsequently applying these calibrators to correct the original estimated values during online inference. However, what sets e-commerce advertising scenarios is the challenge of multi-field calibration. Multi-field calibration can be subdivided into two distinct sub-problems: value calibration and shape calibration. Value calibration is defined as no over- or under-estimation for each value under concerned fields. Shape calibration is defined as no over- or under-estimation for each subset of the pCTR within the specified range under condition of concerned fields. In order to achieve shape calibration and value calibration, it is necessary to have a strong data utilization ability.Because the quantity of pCTR specified range for single field-value sample is relative small, which makes the calibrator more difficult to train. However the existing methods cannot simultaneously fulfill both value calibration and shape calibration. To solve these problems, we propose a new method named Deep Ensemble Shape Calibration (DESC). We introduce innovative basis calibration functions, which enhance both function expression capabilities and data utilization by combining these basis calibration functions. A significant advancement lies in the development of an allocator capable of allocating the most suitable shape calibrators to different estimation error distributions within diverse fields and values.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09509",
        "abstract url": "https://arxiv.org/abs/2401.09509",
        "title": "Exploration of Activation Fault Reliability in Quantized Systolic Array-Based DNN Accelerators",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The stringent requirements for the Deep Neural Networks (DNNs) accelerator's reliability stand along with the need for reducing the computational burden on the hardware platforms, i.e. reducing the energy consumption and execution time as well as increasing the efficiency of DNN accelerators. Moreover, the growing demand for specialized DNN accelerators with tailored requirements, particularly for safety-critical applications, necessitates a comprehensive design space exploration to enable the development of efficient and robust accelerators that meet those requirements. Therefore, the trade-off between hardware performance, i.e. area and delay, and the reliability of the DNN accelerator implementation becomes critical and requires tools for analysis. This paper presents a comprehensive methodology for exploring and enabling a holistic assessment of the trilateral impact of quantization on model accuracy, activation fault reliability, and hardware efficiency. A fully automated framework is introduced that is capable of applying various quantization-aware techniques, fault injection, and hardware implementation, thus enabling the measurement of hardware parameters. Moreover, this paper proposes a novel lightweight protection technique integrated within the framework to ensure the dependable deployment of the final systolic-array-based FPGA implementation. The experiments on established benchmarks demonstrate the analysis flow and the profound implications of quantization on reliability, hardware performance, and network accuracy, particularly concerning the transient faults in the network's activations.",
        "subjects": [
            "cs.AR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09515",
        "abstract url": "https://arxiv.org/abs/2401.09515",
        "title": "Enhancing Surveillance Camera FOV Quality via Semantic Line Detection and Classification with Deep Hough Transform",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "The quality of recorded videos and images is significantly influenced by the camera's field of view (FOV). In critical applications like surveillance systems and self-driving cars, an inadequate FOV can give rise to severe safety and security concerns, including car accidents and thefts due to the failure to detect individuals and objects. The conventional methods for establishing the correct FOV heavily rely on human judgment and lack automated mechanisms to assess video and image quality based on FOV. In this paper, we introduce an innovative approach that harnesses semantic line detection and classification alongside deep Hough transform to identify semantic lines, thus ensuring a suitable FOV by understanding 3D view through parallel lines. Our approach yields an effective F1 score of 0.729 on the public EgoCart dataset, coupled with a notably high median score in the line placement metric. We illustrate that our method offers a straightforward means of assessing the quality of the camera's field of view, achieving a classification accuracy of 83.8\\%. This metric can serve as a proxy for evaluating the potential performance of video and image quality applications.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Appeared in the WACV 2024 Workshop on Image/Video/Audio Quality in Computer Vision and Generative AI"
    },
    {
        "paper id": "2401.09516",
        "abstract url": "https://arxiv.org/abs/2401.09516",
        "title": "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Learning neural operators for solving partial differential equations (PDEs) has attracted great attention due to its high inference efficiency. However, training such operators requires generating a substantial amount of labeled data, i.e., PDE problems together with their solutions. The data generation process is exceptionally time-consuming, as it involves solving numerous systems of linear equations to obtain numerical solutions to the PDEs. Many existing methods solve these systems independently without considering their inherent similarities, resulting in extremely redundant computations. To tackle this problem, we propose a novel method, namely Sorting Krylov Recycling (SKR), to boost the efficiency of solving these systems, thus significantly accelerating data generation for neural operators training. To the best of our knowledge, SKR is the first attempt to address the time-consuming nature of data generation for learning neural operators. The working horse of SKR is Krylov subspace recycling, a powerful technique for solving a series of interrelated systems by leveraging their inherent similarities. Specifically, SKR employs a sorting algorithm to arrange these systems in a sequence, where adjacent systems exhibit high similarities. Then it equips a solver with Krylov subspace recycling to solve the systems sequentially instead of independently, thus effectively enhancing the solving efficiency. Both theoretical analysis and extensive experiments demonstrate that SKR can significantly accelerate neural operator data generation, achieving a remarkable speedup of up to 13.9 times.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09556",
        "abstract url": "https://arxiv.org/abs/2401.09556",
        "title": "Deep learning enhanced mixed integer optimization: Learning to reduce model dimensionality",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This work introduces a framework to address the computational complexity inherent in Mixed-Integer Programming (MIP) models by harnessing the potential of deep learning. We compare the effectiveness of (a) feed-forward neural networks (ANN) and (b) convolutional neural networks (CNN) in approximating the active dimensions within MIP problems. We utilize multi-label classification to account for more than one active dimension. To enhance the framework's performance, we employ Bayesian optimization for hyperparameter tuning, aiming to maximize sample-level accuracy. The primary objective is to train the neural networks to predict all active dimensions accurately, thereby maximizing the occurrence of global optimum solutions. We apply this framework to a flow-based facility location allocation Mixed-Integer Linear Programming (MILP) formulation that describes long-term investment planning and medium-term tactical planning in a personalized medicine supply chain for cell therapy manufacturing and distribution.",
        "subjects": [
            "math.OC",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09561",
        "abstract url": "https://arxiv.org/abs/2401.09561",
        "title": "Sharing Knowledge in Multi-Task Deep Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the benefit of sharing representations among tasks to enable the effective use of deep neural networks in Multi-Task Reinforcement Learning. We leverage the assumption that learning from different tasks, sharing common properties, is helpful to generalize the knowledge of them resulting in a more effective feature extraction compared to learning a single task. Intuitively, the resulting set of features offers performance benefits when used by Reinforcement Learning algorithms. We prove this by providing theoretical guarantees that highlight the conditions for which is convenient to share representations among tasks, extending the well-known finite-time bounds of Approximate Value-Iteration to the multi-task setting. In addition, we complement our analysis by proposing multi-task extensions of three Reinforcement Learning algorithms that we empirically evaluate on widely used Reinforcement Learning benchmarks showing significant improvements over the single-task counterparts in terms of sample efficiency and performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09579",
        "abstract url": "https://arxiv.org/abs/2401.09579",
        "title": "Fully-blind Neural Network Based Equalization for Severe Nonlinear Distortions in 112 Gbit/s Passive Optical Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We demonstrate and evaluate a fully-blind digital signal processing (DSP) chain for 100G passive optical networks (PONs), and analyze different equalizer topologies based on neural networks with low hardware complexity.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "Accepted and to be presented at the Optical Fiber Communication Conference (OFC) 2024"
    },
    {
        "paper id": "2401.09582",
        "abstract url": "https://arxiv.org/abs/2401.09582",
        "title": "eipy: An Open-Source Python Package for Multi-modal Data Integration using Heterogeneous Ensembles",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we introduce eipy--an open-source Python package for developing effective, multi-modal heterogeneous ensembles for classification. eipy simultaneously provides both a rigorous, and user-friendly framework for comparing and selecting the best-performing multi-modal data integration and predictive modeling methods by systematically evaluating their performance using nested cross-validation. The package is designed to leverage scikit-learn-like estimators as components to build multi-modal predictive models. An up-to-date user guide, including API reference and tutorials, for eipy is maintained at https://eipy.readthedocs.io . The main repository for this project can be found on GitHub at https://github.com/GauravPandeyLab/eipy .",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09591",
        "abstract url": "https://arxiv.org/abs/2401.09591",
        "title": "Bringing Social Computing to Secondary School Classrooms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Social computing is the study of how technology shapes human social interactions. This topic has become increasingly relevant to secondary school students (ages 11--18) as more of young people's everyday social experiences take place online, particularly with the continuing effects of the COVID-19 pandemic. However, social computing topics are rarely touched upon in existing middle and high school curricula. We seek to introduce concepts from social computing to secondary school students so they can understand how computing has wide-ranging social implications that touch upon their everyday lives, as well as think critically about both the positive and negative sides of different social technology designs. In this report, we present a series of six lessons combining presentations and hands-on activities covering topics within social computing and detail our experience teaching these lessons to approximately 1,405 students across 13 middle and high schools in our local school district. We developed lessons covering how social computing relates to the topics of Data Management, Encrypted Messaging, Human-Computer Interaction Careers, Machine Learning and Bias, Misinformation, and Online Behavior. We found that 81.13% of students expressed greater interest in the content of our lessons compared to their interest in STEM overall. We also found from pre- and post-lesson comprehension questions that 63.65% learned new concepts from the main activity. We release all lesson materials on a website for public use. From our experience, we observed that students were engaged in these topics and found enjoyment in finding connections between computing and their own lives.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09606",
        "abstract url": "https://arxiv.org/abs/2401.09606",
        "title": "Robustness Evaluation of Machine Learning Models for Robot Arm Action Recognition in Noisy Environments",
        "rating": "0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In the realm of robot action recognition, identifying distinct but spatially proximate arm movements using vision systems in noisy environments poses a significant challenge. This paper studies robot arm action recognition in noisy environments using machine learning techniques. Specifically, a vision system is used to track the robot's movements followed by a deep learning model to extract the arm's key points. Through a comparative analysis of machine learning methods, the effectiveness and robustness of this model are assessed in noisy environments. A case study was conducted using the Tic-Tac-Toe game in a 3-by-3 grid environment, where the focus is to accurately identify the actions of the arms in selecting specific locations within this constrained environment. Experimental results show that our approach can achieve precise key point detection and action classification despite the addition of noise and uncertainties to the dataset.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "Accepted at ICASSP"
    },
    {
        "paper id": "2401.09622",
        "abstract url": "https://arxiv.org/abs/2401.09622",
        "title": "SMOOTHIE: A Theory of Hyper-parameter Optimization for Software Analytics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hyper-parameter optimization is the black art of tuning a learner's control parameters. In software analytics, a repeated result is that such tuning can result in dramatic performance improvements. Despite this, hyper-parameter optimization is often applied rarely or poorly in software analytics--perhaps due to the CPU cost of exploring all those parameter options can be prohibitive. We theorize that learners generalize better when the loss landscape is ``smooth''. This theory is useful since the influence on ``smoothness'' of different hyper-parameter choices can be tested very quickly (e.g. for a deep learner, after just one epoch). To test this theory, this paper implements and tests SMOOTHIE, a novel hyper-parameter optimizer that guides its optimizations via considerations of ``smothness''. The experiments of this paper test SMOOTHIE on numerous SE tasks including (a) GitHub issue lifetime prediction; (b) detecting false alarms in static code warnings; (c) defect prediction, and (d) a set of standard ML datasets. In all these experiments, SMOOTHIE out-performed state-of-the-art optimizers. Better yet, SMOOTHIE ran 300% faster than the prior state-of-the art. We hence conclude that this theory (that hyper-parameter optimization is best viewed as a ``smoothing'' function for the decision landscape), is both theoretically interesting and practically very useful. To support open science and other researchers working in this area, all our scripts and datasets are available on-line at https://github.com/yrahul3910/smoothness-hpo/.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "comment": "v1"
    },
    {
        "paper id": "2401.09651",
        "abstract url": "https://arxiv.org/abs/2401.09651",
        "title": "Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We address a key challenge for neuro-symbolic (NeSy) systems by leveraging convex and bilevel optimization techniques to develop a general gradient-based framework for end-to-end neural and symbolic parameter learning. The applicability of our framework is demonstrated with NeuPSL, a state-of-the-art NeSy architecture. To achieve this, we propose a smooth primal and dual formulation of NeuPSL inference and show learning gradients are functions of the optimal dual variables. Additionally, we develop a dual block coordinate descent algorithm for the new formulation that naturally exploits warm-starts. This leads to over 100x learning runtime improvements over the current best NeuPSL inference method. Finally, we provide extensive empirical evaluations across $8$ datasets covering a range of tasks and demonstrate our learning framework achieves up to a 16% point prediction performance improvement over alternative learning methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09691",
        "abstract url": "https://arxiv.org/abs/2401.09691",
        "title": "Imitation Learning Inputting Image Feature to Each Layer of Neural Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Imitation learning enables robots to learn and replicate human behavior from training data. Recent advances in machine learning enable end-to-end learning approaches that directly process high-dimensional observation data, such as images. However, these approaches face a critical challenge when processing data from multiple modalities, inadvertently ignoring data with a lower correlation to the desired output, especially when using short sampling periods. This paper presents a useful method to address this challenge, which amplifies the influence of data with a relatively low correlation to the output by inputting the data into each neural network layer. The proposed approach effectively incorporates diverse data sources into the learning process. Through experiments using a simple pick-and-place operation with raw images and joint information as input, significant improvements in success rates are demonstrated even when dealing with data from short sampling periods.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "6 pages, 4 figures, Accepted at AMC2024"
    },
    {
        "paper id": "2401.09695",
        "abstract url": "https://arxiv.org/abs/2401.09695",
        "title": "Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in Relationship Dissolution",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Relationships are essential to our happiness and wellbeing. The dissolution of a relationship, the final stage of relationship's lifecycle and one of the most stressful events in an individual's life, can have profound and long-lasting impacts on people. With the breakup process increasingly facilitated by computer-mediated communication (CMC), and the likely future influence of AI-mediated communication (AIMC) tools, we conducted a semi-structured interview study with 21 participants. We aim to understand: 1) the current role of technology in the breakup process, 2) the needs and support individuals have during the process, and 3) how AI might address these needs. Our research shows that people have distinct needs at various stages of ending a relationship. Presently, technology is used for information gathering and community support, acting as a catalyst for breakups, enabling ghosting and blocking, and facilitating communication. Participants anticipate that AI could aid in sense-making of their relationship leading up to the breakup, act as a mediator, assist in crafting appropriate wording, tones, and language during breakup conversations, and support companionship, reflection, recovery, and growth after a breakup. Our findings also demonstrate an overlap between the breakup process and the Transtheoretical Model (TTM) of behavior change. Through the lens of TTM, we explore the potential support and affordances AI could offer in breakups, including its benefits and the necessary precautions regarding AI's role in this sensitive process.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10290",
        "abstract url": "https://arxiv.org/abs/2401.10290",
        "title": "Early Prediction of Geomagnetic Storms by Machine Learning Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere. GS can cause severe damages to satellites, power grids, and communication infrastructures. Estimate of direct economic impacts of a large scale GS exceeds $40 billion a day in the US. Early prediction is critical in preventing and minimizing the hazards. However, current methods either predict several hours ahead but fail to identify all types of GS, or make predictions within short time, e.g., one hour ahead of the occurrence. This work aims to predict all types of geomagnetic storms reliably and as early as possible using big data and machine learning algorithms. By fusing big data collected from multiple ground stations in the world on different aspects of solar measurements and using Random Forests regression with feature selection and downsampling on minor geomagnetic storm instances (which carry majority of the data), we are able to achieve an accuracy of 82.55% on data collected in 2021 when making early predictions three hours in advance. Given that important predictive features such as historic Kp indices are measured every 3 hours and their importance decay quickly with the amount of time in advance, an early prediction of 3 hours ahead of time is believed to be close to the practical limit.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "14 pages, 7 figures"
    },
    {
        "paper id": "2401.10294",
        "abstract url": "https://arxiv.org/abs/2401.10294",
        "title": "Tight Group-Level DP Guarantees for DP-SGD with Sampling via Mixture of Gaussians Mechanisms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We give a procedure for computing group-level $(\u03b5, \u03b4)$-DP guarantees for DP-SGD, when using Poisson sampling or fixed batch size sampling. Up to discretization errors in the implementation, the DP guarantees computed by this procedure are tight (assuming we release every intermediate iterate).",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "v2: Added links to open-source implementation of PLD accounting for MoG mechanisms"
    },
    {
        "paper id": "2401.10297",
        "abstract url": "https://arxiv.org/abs/2401.10297",
        "title": "Learning Non-myopic Power Allocation in Constrained Scenarios",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a learning-based framework for efficient power allocation in ad hoc interference networks under episodic constraints. The problem of optimal power allocation -- for maximizing a given network utility metric -- under instantaneous constraints has recently gained significant popularity. Several learnable algorithms have been proposed to obtain fast, effective, and near-optimal performance. However, a more realistic scenario arises when the utility metric has to be optimized for an entire episode under time-coupled constraints. In this case, the instantaneous power needs to be regulated so that the given utility can be optimized over an entire sequence of wireless network realizations while satisfying the constraint at all times. Solving each instance independently will be myopic as the long-term constraint cannot modulate such a solution. Instead, we frame this as a constrained and sequential decision-making problem, and employ an actor-critic algorithm to obtain the constraint-aware power allocation at each step. We present experimental analyses to illustrate the effectiveness of our method in terms of superior episodic network-utility performance and its efficiency in terms of time and computational complexity.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "cs.NI"
        ],
        "comment": "ASILOMAR 2023"
    },
    {
        "paper id": "2401.10935",
        "abstract url": "https://arxiv.org/abs/2401.10935",
        "title": "SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a novel visual GUI agent -- SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key challenge in developing visual GUI agents: GUI grounding -- the capacity to accurately locate screen elements based on instructions. To tackle this challenge, we propose to enhance SeeClick with GUI grounding pre-training and devise a method to automate the curation of GUI grounding data. Along with the efforts above, we have also created ScreenSpot, the first realistic GUI grounding benchmark that encompasses mobile, desktop, and web environments. After pre-training, SeeClick demonstrates significant improvement in ScreenSpot over various baselines. Moreover, comprehensive evaluations on three widely used benchmarks consistently support our finding that advancements in GUI grounding directly correlate with enhanced performance in downstream GUI agent tasks. The model, data and code are available at https://github.com/njucckevin/SeeClick.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10937",
        "abstract url": "https://arxiv.org/abs/2401.10937",
        "title": "Subjective Causality",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We show that it is possible to understand and identify a decision maker's subjective causal judgements by observing her preferences over interventions. Following Pearl [2000], we represent causality using causal models (also called structural equations models), where the world is described by a collection of variables, related by equations. We show that if a preference relation over interventions satisfies certain axioms (related to standard axioms regarding counterfactuals), then we can define (i) a causal model, (ii) a probability capturing the decision-maker's uncertainty regarding the external factors in the world and (iii) a utility on outcomes such that each intervention is associated with an expected utility and such that intervention $A$ is preferred to $B$ iff the expected utility of $A$ is greater than that of $B$. In addition, we characterize when the causal model is unique. Thus, our results allow a modeler to test the hypothesis that a decision maker's preferences are consistent with some causal model and to identify causal judgements from observed behavior.",
        "subjects": [
            "econ.TH",
            "cs.AI",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10938",
        "abstract url": "https://arxiv.org/abs/2401.10938",
        "title": "Even-if Explanations: Formal Foundations, Priorities and Complexity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "EXplainable AI has received significant attention in recent years. Machine learning models often operate as black boxes, lacking explainability and transparency while supporting decision-making processes. Local post-hoc explainability queries attempt to answer why individual inputs are classified in a certain way by a given model. While there has been important work on counterfactual explanations, less attention has been devoted to semifactual ones. In this paper, we focus on local post-hoc explainability queries within the semifactual `even-if' thinking and their computational complexity among different classes of models, and show that both linear and tree-based models are strictly more interpretable than neural networks. After this, we introduce a preference-based framework that enables users to personalize explanations based on their preferences, both in the case of semifactuals and counterfactuals, enhancing interpretability and user-centricity. Finally, we explore the complexity of several interpretability problems in the proposed preference-based framework and provide algorithms for polynomial cases.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2010.12265 by other authors"
    },
    {
        "paper id": "2401.10941",
        "abstract url": "https://arxiv.org/abs/2401.10941",
        "title": "Crowd-PrefRL: Preference-Based Reward Learning from Crowds",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Preference-based reinforcement learning (RL) provides a framework to train agents using human feedback through pairwise preferences over pairs of behaviors, enabling agents to learn desired behaviors when it is difficult to specify a numerical reward function. While this paradigm leverages human feedback, it currently treats the feedback as given by a single human user. Meanwhile, incorporating preference feedback from crowds (i.e. ensembles of users) in a robust manner remains a challenge, and the problem of training RL agents using feedback from multiple human users remains understudied. In this work, we introduce Crowd-PrefRL, a framework for performing preference-based RL leveraging feedback from crowds. This work demonstrates the viability of learning reward functions from preference feedback provided by crowds of unknown expertise and reliability. Crowd-PrefRL not only robustly aggregates the crowd preference feedback, but also estimates the reliability of each user within the crowd using only the (noisy) crowdsourced preference comparisons. Most importantly, we show that agents trained with Crowd-PrefRL outperform agents trained with majority-vote preferences or preferences from any individual user in most cases, especially when the spread of user error rates among the crowd is large. Results further suggest that our method can identify minority viewpoints within the crowd.",
        "subjects": [
            "cs.HC",
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12230",
        "abstract url": "https://arxiv.org/abs/2401.12230",
        "title": "Computing in the Era of Large Generative Models: From Cloud-Native to AI-Native",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we investigate the intersection of large generative AI models and cloud-native computing architectures. Recent large models such as ChatGPT, while revolutionary in their capabilities, face challenges like escalating costs and demand for high-end GPUs. Drawing analogies between large-model-as-a-service (LMaaS) and cloud database-as-a-service (DBaaS), we describe an AI-native computing paradigm that harnesses the power of both cloud-native technologies (e.g., multi-tenancy and serverless computing) and advanced machine learning runtime (e.g., batched LoRA inference). These joint efforts aim to optimize costs-of-goods-sold (COGS) and improve resource accessibility. The journey of merging these two domains is just at the beginning and we hope to stimulate future research and development in this area.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08977",
        "abstract url": "https://arxiv.org/abs/2401.08977",
        "title": "FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data",
        "rating": "0",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected from decentralized local clients manifests a globally prevalent long-tailed distribution, has garnered considerable attention in recent times. In the context of Fed-LT, existing works have predominantly centered on addressing the data imbalance issue to enhance the efficacy of the generic global model while neglecting the performance at the local level. In contrast, conventional Personalized Federated Learning (pFL) techniques are primarily devised to optimize personalized local models under the presumption of a balanced global data distribution. This paper introduces an approach termed Federated Local and Generic Model Training in Fed-LT (FedLoGe), which enhances both local and generic model performance through the integration of representation learning and classifier alignment within a neural collapse framework. Our investigation reveals the feasibility of employing a shared backbone as a foundational framework for capturing overarching global trends, while concurrently employing individualized classifiers to encapsulate distinct refinements stemming from each client's local features. Building upon this discovery, we establish the Static Sparse Equiangular Tight Frame Classifier (SSE-C), inspired by neural collapse principles that naturally prune extraneous noisy features and foster the acquisition of potent data representations. Furthermore, leveraging insights from imbalance neural collapse's classifier norm patterns, we develop Global and Local Adaptive Feature Realignment (GLA-FR) via an auxiliary global classifier and personalized Euclidean norm transfer to align global features with client preferences. Extensive experimental results on CIFAR-10/100-LT, ImageNet, and iNaturalist demonstrate the advantage of our method over state-of-the-art pFL and Fed-LT approaches.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted by ICLR 2024, code: https://github.com/ZackZikaiXiao/FedLoGe"
    },
    {
        "paper id": "2401.09002",
        "abstract url": "https://arxiv.org/abs/2401.09002",
        "title": "AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In our research, we pioneer a novel approach to evaluate the effectiveness of jailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2, diverging from traditional robustness-focused binary evaluations. Our study introduces two distinct evaluation frameworks: a coarse-grained evaluation and a fine-grained evaluation. Each framework, using a scoring range from 0 to 1, offers a unique perspective, enabling a more comprehensive and nuanced evaluation of attack effectiveness and empowering attackers to refine their attack prompts with greater understanding. Furthermore, we have developed a comprehensive ground truth dataset specifically tailored for jailbreak tasks. This dataset not only serves as a crucial benchmark for our current study but also establishes a foundational resource for future research, enabling consistent and comparative analyses in this evolving field. Upon meticulous comparison with traditional evaluation methods, we discovered that our evaluation aligns with the baseline's trend while offering a more profound and detailed assessment. We believe that by accurately evaluating the effectiveness of attack prompts in the Jailbreak task, our work lays a solid foundation for assessing a wider array of similar or even more complex tasks in the realm of prompt injection, potentially revolutionizing this field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09006",
        "abstract url": "https://arxiv.org/abs/2401.09006",
        "title": "Generalized Face Liveness Detection via De-spoofing Face Generator",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous Face Anti-spoofing (FAS) works face the challenge of generalizing in unseen domains. One of the major problems is that most existing FAS datasets are relatively small and lack data diversity. However, we find that there are numerous real faces that can be easily achieved under various conditions, which are neglected by previous FAS works. In this paper, we conduct an Anomalous cue Guided FAS (AG-FAS) method, which leverages real faces for improving model generalization via a De-spoofing Face Generator (DFG). Specifically, the DFG trained only on the real faces gains the knowledge of what a real face should be like and can generate a \"real\" version of the face corresponding to any given input face. The difference between the generated \"real\" face and the input face can provide an anomalous cue for the downstream FAS task. We then propose an Anomalous cue Guided FAS feature extraction Network (AG-Net) to further improve the FAS feature generalization via a cross-attention transformer. Extensive experiments on a total of nine public datasets show our method achieves state-of-the-art results under cross-domain evaluations with unseen scenarios and unknown presentation attacks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "v1"
    },
    {
        "paper id": "2401.09018",
        "abstract url": "https://arxiv.org/abs/2401.09018",
        "title": "Residual Alignment: Uncovering the Mechanisms of Residual Networks",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The ResNet architecture has been widely adopted in deep learning due to its significant boost to performance through the use of simple skip connections, yet the underlying mechanisms leading to its success remain largely unknown. In this paper, we conduct a thorough empirical study of the ResNet architecture in classification tasks by linearizing its constituent residual blocks using Residual Jacobians and measuring their singular value decompositions. Our measurements reveal a process called Residual Alignment (RA) characterized by four properties: (RA1) intermediate representations of a given input are equispaced on a line, embedded in high dimensional space, as observed by Gai and Zhang [2021]; (RA2) top left and right singular vectors of Residual Jacobians align with each other and across different depths; (RA3) Residual Jacobians are at most rank C for fully-connected ResNets, where C is the number of classes; and (RA4) top singular values of Residual Jacobians scale inversely with depth. RA consistently occurs in models that generalize well, in both fully-connected and convolutional architectures, across various depths and widths, for varying numbers of classes, on all tested benchmark datasets, but ceases to occur once the skip connections are removed. It also provably occurs in a novel mathematical model we propose. This phenomenon reveals a strong alignment between residual branches of a ResNet (RA2+4), imparting a highly rigid geometric structure to the intermediate representations as they progress linearly through the network (RA1) up to the final layer, where they undergo Neural Collapse.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at NeurIPS 2023 as a Poster paper"
    },
    {
        "paper id": "2401.09042",
        "abstract url": "https://arxiv.org/abs/2401.09042",
        "title": "LLMs for Relational Reasoning: How Far are We?",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Accepted by The First International Workshop on Large Language Models for Code (ICSE 2024)"
    },
    {
        "paper id": "2401.09047",
        "abstract url": "https://arxiv.org/abs/2401.09047",
        "title": "VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-video generation aims to produce a video based on a given prompt. Recently, several commercial video models have been able to generate plausible videos with minimal noise, excellent details, and high aesthetic scores. However, these models rely on large-scale, well-filtered, high-quality videos that are not accessible to the community. Many existing research works, which train models using the low-quality WebVid-10M dataset, struggle to generate high-quality videos because the models are optimized to fit WebVid-10M. In this work, we explore the training scheme of video models extended from Stable Diffusion and investigate the feasibility of leveraging low-quality videos and synthesized high-quality images to obtain a high-quality video model. We first analyze the connection between the spatial and temporal modules of video models and the distribution shift to low-quality videos. We observe that full training of all modules results in a stronger coupling between spatial and temporal modules than only training temporal modules. Based on this stronger coupling, we shift the distribution to higher quality without motion degradation by finetuning spatial modules with high-quality images, resulting in a generic high-quality video model. Evaluations are conducted to demonstrate the superiority of the proposed method, particularly in picture quality, motion, and concept composition.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Homepage: https://ailab-cvc.github.io/videocrafter; Github: https://github.com/AILab-CVC/VideoCrafter"
    },
    {
        "paper id": "2401.09057",
        "abstract url": "https://arxiv.org/abs/2401.09057",
        "title": "CrossVideo: Self-supervised Cross-modal Contrastive Learning for Point Cloud Video Understanding",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel approach named CrossVideo, which aims to enhance self-supervised cross-modal contrastive learning in the field of point cloud video understanding. Traditional supervised learning methods encounter limitations due to data scarcity and challenges in label acquisition. To address these issues, we propose a self-supervised learning method that leverages the cross-modal relationship between point cloud videos and image videos to acquire meaningful feature representations. Intra-modal and cross-modal contrastive learning techniques are employed to facilitate effective comprehension of point cloud video. We also propose a multi-level contrastive approach for both modalities. Through extensive experiments, we demonstrate that our method significantly surpasses previous state-of-the-art approaches, and we conduct comprehensive ablation studies to validate the effectiveness of our proposed designs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09112",
        "abstract url": "https://arxiv.org/abs/2401.09112",
        "title": "Stream Query Denoising for Vectorized HD Map Construction",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To enhance perception performance in complex and extensive scenarios within the realm of autonomous driving, there has been a noteworthy focus on temporal modeling, with a particular emphasis on streaming methods. The prevailing trend in streaming models involves the utilization of stream queries for the propagation of temporal information. Despite the prevalence of this approach, the direct application of the streaming paradigm to the construction of vectorized high-definition maps (HD-maps) fails to fully harness the inherent potential of temporal information. This paper introduces the Stream Query Denoising (SQD) strategy as a novel approach for temporal modeling in high-definition map (HD-map) construction. SQD is designed to facilitate the learning of temporal consistency among map elements within the streaming model. The methodology involves denoising the queries that have been perturbed by the addition of noise to the ground-truth information from the preceding frame. This denoising process aims to reconstruct the ground-truth information for the current frame, thereby simulating the prediction process inherent in stream queries. The SQD strategy can be applied to those streaming methods (e.g., StreamMapNet) to enhance the temporal modeling. The proposed SQD-MapNet is the StreamMapNet equipped with SQD. Extensive experiments on nuScenes and Argoverse2 show that our method is remarkably superior to other existing methods across all settings of close range and long range. The code will be available soon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09126",
        "abstract url": "https://arxiv.org/abs/2401.09126",
        "title": "Objects With Lighting: A Real-World Dataset for Evaluating Reconstruction and Rendering for Object Relighting",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstructing an object from photos and placing it virtually in a new environment goes beyond the standard novel view synthesis task as the appearance of the object has to not only adapt to the novel viewpoint but also to the new lighting conditions and yet evaluations of inverse rendering methods rely on novel view synthesis data or simplistic synthetic datasets for quantitative analysis. This work presents a real-world dataset for measuring the reconstruction and rendering of objects for relighting. To this end, we capture the environment lighting and ground truth images of the same objects in multiple environments allowing to reconstruct the objects from images taken in one environment and quantify the quality of the rendered views for the unseen lighting environments. Further, we introduce a simple baseline composed of off-the-shelf methods and test several state-of-the-art methods on the relighting task and show that novel view synthesis is not a reliable proxy to measure performance. Code and dataset are available at https://github.com/isl-org/objects-with-lighting .",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Accepted at 3DV 2024, Oral presentation. For the project page see https://github.com/isl-org/objects-with-lighting"
    },
    {
        "paper id": "2401.09160",
        "abstract url": "https://arxiv.org/abs/2401.09160",
        "title": "DK-SLAM: Monocular Visual SLAM with Deep Keypoints Adaptive Learning, Tracking and Loop-Closing",
        "rating": "0",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unreliable feature extraction and matching in handcrafted features undermine the performance of visual SLAM in complex real-world scenarios. While learned local features, leveraging CNNs, demonstrate proficiency in capturing high-level information and excel in matching benchmarks, they encounter challenges in continuous motion scenes, resulting in poor generalization and impacting loop detection accuracy. To address these issues, we present DK-SLAM, a monocular visual SLAM system with adaptive deep local features. MAML optimizes the training of these features, and we introduce a coarse-to-fine feature tracking approach. Initially, a direct method approximates the relative pose between consecutive frames, followed by a feature matching method for refined pose estimation. To counter cumulative positioning errors, a novel online learning binary feature-based online loop closure module identifies loop nodes within a sequence. Experimental results underscore DK-SLAM's efficacy, outperforms representative SLAM solutions, such as ORB-SLAM3 on publicly available datasets.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "In submission"
    },
    {
        "paper id": "2401.09195",
        "abstract url": "https://arxiv.org/abs/2401.09195",
        "title": "Training-Free Semantic Video Composition via Pre-trained Diffusion Model",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The video composition task aims to integrate specified foregrounds and backgrounds from different videos into a harmonious composite. Current approaches, predominantly trained on videos with adjusted foreground color and lighting, struggle to address deep semantic disparities beyond superficial adjustments, such as domain gaps. Therefore, we propose a training-free pipeline employing a pre-trained diffusion model imbued with semantic prior knowledge, which can process composite videos with broader semantic disparities. Specifically, we process the video frames in a cascading manner and handle each frame in two processes with the diffusion model. In the inversion process, we propose Balanced Partial Inversion to obtain generation initial points that balance reversibility and modifiability. Then, in the generation process, we further propose Inter-Frame Augmented attention to augment foreground continuity across frames. Experimental results reveal that our pipeline successfully ensures the visual harmony and inter-frame coherence of the outputs, demonstrating efficacy in managing broader semantic disparities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09232",
        "abstract url": "https://arxiv.org/abs/2401.09232",
        "title": "Dynamic Relation Transformer for Contextual Text Block Detection",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Contextual Text Block Detection (CTBD) is the task of identifying coherent text blocks within the complexity of natural scenes. Previous methodologies have treated CTBD as either a visual relation extraction challenge within computer vision or as a sequence modeling problem from the perspective of natural language processing. We introduce a new framework that frames CTBD as a graph generation problem. This methodology consists of two essential procedures: identifying individual text units as graph nodes and discerning the sequential reading order relationships among these units as graph edges. Leveraging the cutting-edge capabilities of DQ-DETR for node detection, our framework innovates further by integrating a novel mechanism, a Dynamic Relation Transformer (DRFormer), dedicated to edge generation. DRFormer incorporates a dual interactive transformer decoder that deftly manages a dynamic graph structure refinement process. Through this iterative process, the model systematically enhances the graph's fidelity, ultimately resulting in improved precision in detecting contextual text blocks. Comprehensive experimental evaluations conducted on both SCUT-CTW-Context and ReCTS-Context datasets substantiate that our method achieves state-of-the-art results, underscoring the effectiveness and potential of our graph generation framework in advancing the field of CTBD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09235",
        "abstract url": "https://arxiv.org/abs/2401.09235",
        "title": "A Characterization Theorem for Equivariant Networks with Point-wise Activations",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Equivariant neural networks have shown improved performance, expressiveness and sample complexity on symmetrical domains. But for some specific symmetries, representations, and choice of coordinates, the most common point-wise activations, such as ReLU, are not equivariant, hence they cannot be employed in the design of equivariant neural networks. The theorem we present in this paper describes all possible combinations of finite-dimensional representations, choice of coordinates and point-wise activations to obtain an exactly equivariant layer, generalizing and strengthening existing characterizations. Notable cases of practical relevance are discussed as corollaries. Indeed, we prove that rotation-equivariant networks can only be invariant, as it happens for any network which is equivariant with respect to connected compact groups. Then, we discuss implications of our findings when applied to important instances of exactly equivariant networks. First, we completely characterize permutation equivariant networks such as Invariant Graph Networks with point-wise nonlinearities and their geometric counterparts, highlighting a plethora of models whose expressive power and performance are still unknown. Second, we show that feature spaces of disentangled steerable convolutional neural networks are trivial representations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted at the 12th International Conference on Learning Representations (ICLR 2024)"
    },
    {
        "paper id": "2401.09252",
        "abstract url": "https://arxiv.org/abs/2401.09252",
        "title": "3D Scene Geometry Estimation from 360$^\\circ$ Imagery: A Survey",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper provides a comprehensive survey on pioneer and state-of-the-art 3D scene geometry estimation methodologies based on single, two, or multiple images captured under the omnidirectional optics. We first revisit the basic concepts of the spherical camera model, and review the most common acquisition technologies and representation formats suitable for omnidirectional (also called 360$^\\circ$, spherical or panoramic) images and videos. We then survey monocular layout and depth inference approaches, highlighting the recent advances in learning-based solutions suited for spherical data. The classical stereo matching is then revised on the spherical domain, where methodologies for detecting and describing sparse and dense features become crucial. The stereo matching concepts are then extrapolated for multiple view camera setups, categorizing them among light fields, multi-view stereo, and structure from motion (or visual simultaneous localization and mapping). We also compile and discuss commonly adopted datasets and figures of merit indicated for each purpose and list recent results for completeness. We conclude this paper by pointing out current and future trends.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "Published in ACM Computing Surveys"
    },
    {
        "paper id": "2401.09258",
        "abstract url": "https://arxiv.org/abs/2401.09258",
        "title": "An Efficient Generalizable Framework for Visuomotor Policies via Control-aware Augmentation and Privilege-guided Distillation",
        "rating": "0",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visuomotor policies, which learn control mechanisms directly from high-dimensional visual observations, confront challenges in adapting to new environments with intricate visual variations. Data augmentation emerges as a promising method for bridging these generalization gaps by enriching data variety. However, straightforwardly augmenting the entire observation shall impose excessive burdens on policy learning and may even result in performance degradation. In this paper, we propose to improve the generalization ability of visuomotor policies as well as preserve training stability from two aspects: 1) We learn a control-aware mask through a self-supervised reconstruction task with three auxiliary losses and then apply strong augmentation only to those control-irrelevant regions based on the mask to reduce the generalization gaps. 2) To address training instability issues prevalent in visual reinforcement learning (RL), we distill the knowledge from a pretrained RL expert processing low-level environment states, to the student visuomotor policy. The policy is subsequently deployed to unseen environments without any further finetuning. We conducted comparison and ablation studies across various benchmarks: the DMControl Generalization Benchmark (DMC-GB), the enhanced Robot Manipulation Distraction Benchmark (RMDB), and a specialized long-horizontal drawer-opening robotic task. The extensive experimental results well demonstrate the effectiveness of our method, e.g., showing a 17\\% improvement over previous methods in the video-hard setting of DMC-GB.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09294",
        "abstract url": "https://arxiv.org/abs/2401.09294",
        "title": "T-FOLEY: A Controllable Waveform-Domain Diffusion Model for Temporal-Event-Guided Foley Sound Synthesis",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Synthesis"
            ],
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "Foley sound, audio content inserted synchronously with videos, plays a critical role in the user experience of multimedia content. Recently, there has been active research in Foley sound synthesis, leveraging the advancements in deep generative models. However, such works mainly focus on replicating a single sound class or a textual sound description, neglecting temporal information, which is crucial in the practical applications of Foley sound. We present T-Foley, a Temporal-event-guided waveform generation model for Foley sound synthesis. T-Foley generates high-quality audio using two conditions: the sound class and temporal event feature. For temporal conditioning, we devise a temporal event feature and a novel conditioning technique named Block-FiLM. T-Foley achieves superior performance in both objective and subjective evaluation metrics and generates Foley sound well-synchronized with the temporal events. Additionally, we showcase T-Foley's practical applications, particularly in scenarios involving vocal mimicry for temporal event control. We show the demo on our companion website.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09331",
        "abstract url": "https://arxiv.org/abs/2401.09331",
        "title": "Event-Based Visual Odometry on Non-Holonomic Ground Vehicles",
        "rating": "0",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the promise of superior performance under challenging conditions, event-based motion estimation remains a hard problem owing to the difficulty of extracting and tracking stable features from event streams. In order to robustify the estimation, it is generally believed that fusion with other sensors is a requirement. In this work, we demonstrate reliable, purely event-based visual odometry on planar ground vehicles by employing the constrained non-holonomic motion model of Ackermann steering platforms. We extend single feature n-linearities for regular frame-based cameras to the case of quasi time-continuous event-tracks, and achieve a polynomial form via variable degree Taylor expansions. Robust averaging over multiple event tracks is simply achieved via histogram voting. As demonstrated on both simulated and real data, our algorithm achieves accurate and robust estimates of the vehicle's instantaneous rotational velocity, and thus results that are comparable to the delta rotations obtained by frame-based sensors under normal conditions. We furthermore significantly outperform the more traditional alternatives in challenging illumination scenarios. The code is available at \\url{https://github.com/gowanting/NHEVO}.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted by 3DV 2024"
    },
    {
        "paper id": "2401.09340",
        "abstract url": "https://arxiv.org/abs/2401.09340",
        "title": "SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "3D"
            ],
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "3D vision-language grounding, which focuses on aligning language with the 3D physical environment, stands as a cornerstone in the development of embodied agents. In comparison to recent advancements in the 2D domain, grounding language in 3D scenes faces several significant challenges: (i) the inherent complexity of 3D scenes due to the diverse object configurations, their rich attributes, and intricate relationships; (ii) the scarcity of paired 3D vision-language data to support grounded learning; and (iii) the absence of a unified learning framework to distill knowledge from grounded 3D data. In this work, we aim to address these three major challenges in 3D vision-language by examining the potential of systematically upscaling 3D vision-language learning in indoor environments. We introduce the first million-scale 3D vision-language dataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising 2.5M vision-language pairs derived from both human annotations and our scalable scene-graph-based generation approach. We demonstrate that this scaling allows for a unified pre-training framework, Grounded Pre-training for Scenes (GPS), for 3D vision-language learning. Through extensive experiments, we showcase the effectiveness of GPS by achieving state-of-the-art performance on all existing 3D visual grounding benchmarks. The vast potential of SceneVerse and GPS is unveiled through zero-shot transfer experiments in the challenging 3D vision-language tasks. Project website: https://scene-verse.github.io.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2401.09395",
        "abstract url": "https://arxiv.org/abs/2401.09395",
        "title": "Caught in the Quicksand of Reasoning, Far from AGI Summit: Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness in reasoning tasks remains an open question. To this end, in this paper, we focus on two popular reasoning tasks: arithmetic reasoning and code generation. Particularly, we introduce: (i) a general ontology of perturbations for maths and coding questions, (ii) a semi-automatic method to apply these perturbations, and (iii) two datasets, MORE and CORE, respectively, of perturbed maths and coding problems to probe the limits of LLM capabilities in numeric reasoning and coding tasks. Through comprehensive evaluations of both closed-source and open-source LLMs, we show a significant performance drop across all the models against the perturbed questions, suggesting that the current LLMs lack robust problem solving skills and structured reasoning abilities in many areas, as defined by our ontology. We open source the datasets and source codes at: https://github.com/declare-lab/llm_robustness.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09414",
        "abstract url": "https://arxiv.org/abs/2401.09414",
        "title": "Vlogger: Make Your Dream A Vlog",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we present Vlogger, a generic AI system for generating a minute-level video blog (i.e., vlog) of user descriptions. Different from short videos with a few seconds, vlog often contains a complex storyline with diversified scenes, which is challenging for most existing video generation approaches. To break through this bottleneck, our Vlogger smartly leverages Large Language Model (LLM) as Director and decomposes a long video generation task of vlog into four key stages, where we invoke various foundation models to play the critical roles of vlog professionals, including (1) Script, (2) Actor, (3) ShowMaker, and (4) Voicer. With such a design of mimicking human beings, our Vlogger can generate vlogs through explainable cooperation of top-down planning and bottom-up shooting. Moreover, we introduce a novel video diffusion model, ShowMaker, which serves as a videographer in our Vlogger for generating the video snippet of each shooting scene. By incorporating Script and Actor attentively as textual and visual prompts, it can effectively enhance spatial-temporal coherence in the snippet. Besides, we design a concise mixed training paradigm for ShowMaker, boosting its capacity for both T2V generation and prediction. Finally, the extensive experiments show that our method achieves state-of-the-art performance on zero-shot T2V generation and prediction tasks. More importantly, Vlogger can generate over 5-minute vlogs from open-world descriptions, without loss of video coherence on script and actor. The code and model is all available at https://github.com/zhuangshaobin/Vlogger.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "16 pages, 8 figures, 11 tables"
    },
    {
        "paper id": "2401.09419",
        "abstract url": "https://arxiv.org/abs/2401.09419",
        "title": "GARField: Group Anything with Radiance Fields",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Grouping is inherently ambiguous due to the multiple levels of granularity in which one can decompose a scene -- should the wheels of an excavator be considered separate or part of the whole? We present Group Anything with Radiance Fields (GARField), an approach for decomposing 3D scenes into a hierarchy of semantically meaningful groups from posed image inputs. To do this we embrace group ambiguity through physical scale: by optimizing a scale-conditioned 3D affinity feature field, a point in the world can belong to different groups of different sizes. We optimize this field from a set of 2D masks provided by Segment Anything (SAM) in a way that respects coarse-to-fine hierarchy, using scale to consistently fuse conflicting masks from different viewpoints. From this field we can derive a hierarchy of possible groupings via automatic tree construction or user interaction. We evaluate GARField on a variety of in-the-wild scenes and find it effectively extracts groups at many levels: clusters of objects, objects, and various subparts. GARField inherently represents multi-view consistent groupings and produces higher fidelity groups than the input SAM masks. GARField's hierarchical grouping could have exciting downstream applications such as 3D asset extraction or dynamic scene understanding. See the project website at https://www.garfield.studio/",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project site: https://www.garfield.studio/ First three authors contributed equally"
    },
    {
        "paper id": "2401.09553",
        "abstract url": "https://arxiv.org/abs/2401.09553",
        "title": "BERTologyNavigator: Advanced Question Answering with BERT-based Semantics",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The development and integration of knowledge graphs and language models has significance in artificial intelligence and natural language processing. In this study, we introduce the BERTologyNavigator -- a two-phased system that combines relation extraction techniques and BERT embeddings to navigate the relationships within the DBLP Knowledge Graph (KG). Our approach focuses on extracting one-hop relations and labelled candidate pairs in the first phases. This is followed by employing BERT's CLS embeddings and additional heuristics for relation selection in the second phase. Our system reaches an F1 score of 0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score on the subset of the DBLP QuAD test dataset during the QA phase.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted in Scholarly QALD Challenge @ ISWC 2023"
    },
    {
        "paper id": "2401.09596",
        "abstract url": "https://arxiv.org/abs/2401.09596",
        "title": "Efficient generative adversarial networks using linear additive-attention Transformers",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Although the capacity of deep generative models for image generation, such as Diffusion Models (DMs) and Generative Adversarial Networks (GANs), has dramatically improved in recent years, much of their success can be attributed to computationally expensive architectures. This has limited their adoption and use to research laboratories and companies with large resources, while significantly raising the carbon footprint for training, fine-tuning, and inference. In this work, we present LadaGAN, an efficient generative adversarial network that is built upon a novel Transformer block named Ladaformer. The main component of this block is a linear additive-attention mechanism that computes a single attention vector per head instead of the quadratic dot-product attention. We employ Ladaformer in both the generator and discriminator, which reduces the computational complexity and overcomes the training instabilities often associated with Transformer GANs. LadaGAN consistently outperforms existing convolutional and Transformer GANs on benchmark datasets at different resolutions while being significantly more efficient. Moreover, LadaGAN shows competitive performance compared to state-of-the-art multi-step generative models (e.g. DMs) using orders of magnitude less computational resources.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2401.09629",
        "abstract url": "https://arxiv.org/abs/2401.09629",
        "title": "Multiple Locally Linear Kernel Machines",
        "rating": "0",
        "keywords": [
            [
                "Kernel Learning"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In this paper we propose a new non-linear classifier based on a combination of locally linear classifiers. A well known optimization formulation is given as we cast the problem in a $\\ell_1$ Multiple Kernel Learning (MKL) problem using many locally linear kernels. Since the number of such kernels is huge, we provide a scalable generic MKL training algorithm handling streaming kernels. With respect to the inference time, the resulting classifier fits the gap between high accuracy but slow non-linear classifiers (such as classical MKL) and fast but low accuracy linear classifiers.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "This paper was written in 2014 and was originally submitted but rejected at ICML'15"
    },
    {
        "paper id": "2401.09646",
        "abstract url": "https://arxiv.org/abs/2401.09646",
        "title": "ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on Climate Change",
        "rating": "0",
        "keywords": [
            [
                "Synthesizing"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces ClimateGPT, a model family of domain-specific large language models that synthesize interdisciplinary research on climate change. We trained two 7B models from scratch on a science-oriented dataset of 300B tokens. For the first model, the 4.2B domain-specific tokens were included during pre-training and the second was adapted to the climate domain after pre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously pre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each model is instruction fine-tuned on a high-quality and human-generated domain-specific dataset that has been created in close cooperation with climate scientists. To reduce the number of hallucinations, we optimize the model for retrieval augmentation and propose a hierarchical retrieval strategy. To increase the accessibility of our model to non-English speakers, we propose to make use of cascaded machine translation and show that this approach can perform comparably to natively multilingual models while being easier to scale to a large number of languages. Further, to address the intrinsic interdisciplinary aspect of climate change we consider different research perspectives. Therefore, the model can produce in-depth answers focusing on different perspectives in addition to an overall answer. We propose a suite of automatic climate-specific benchmarks to evaluate LLMs. On these benchmarks, ClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model while not degrading results on general domain benchmarks. Our human evaluation confirms the trends we saw in our benchmarks. All models were trained and evaluated using renewable energy and are released publicly.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09665",
        "abstract url": "https://arxiv.org/abs/2401.09665",
        "title": "Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "We study a family of distributed stochastic optimization algorithms where gradients are sampled by a token traversing a network of agents in random-walk fashion. Typically, these random-walks are chosen to be Markov chains that asymptotically sample from a desired target distribution, and play a critical role in the convergence of the optimization iterates. In this paper, we take a novel approach by replacing the standard linear Markovian token by one which follows a nonlinear Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined for any given 'base' Markov chain, the SRRW, parameterized by a positive scalar \u03b1, is less likely to transition to states that were highly visited in the past, thus the name. In the context of MCMC sampling on a graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW achieves O(1/\u03b1) decrease in the asymptotic variance for sampling. We propose the use of a 'generalized' version of the SRRW to drive token algorithms for distributed stochastic optimization in the form of stochastic approximation, termed SA-SRRW. We prove that the optimization iterate errors of the resulting SA-SRRW converge to zero almost surely and prove a central limit theorem, deriving the explicit form of the resulting asymptotic covariance matrix corresponding to iterate errors. This asymptotic covariance is always smaller than that of an algorithm driven by the base Markov chain and decreases at rate O(1/\u03b1^2) - the performance benefit of using SRRW thereby amplified in the stochastic optimization context. Empirical results support our theoretical findings.",
        "subjects": [
            "math.PR",
            "cs.LG",
            "math.OC"
        ],
        "comment": "Accepted for oral presentation at the Twelfth International Conference on Learning Representations (ICLR 2024)"
    },
    {
        "paper id": "2401.09673",
        "abstract url": "https://arxiv.org/abs/2401.09673",
        "title": "Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Neural style transfer (NST) generates new images by combining the style of one image with the content of another. However, unauthorized NST can exploit artwork, raising concerns about artists' rights and motivating the development of proactive protection methods. We propose Locally Adaptive Adversarial Color Attack (LAACA), empowering artists to protect their artwork from unauthorized style transfer by processing before public release. By delving into the intricacies of human visual perception and the role of different frequency components, our method strategically introduces frequency-adaptive perturbations in the image. These perturbations significantly degrade the generation quality of NST while maintaining an acceptable level of visual change in the original image, ensuring that potential infringers are discouraged from using the protected artworks, because of its bad NST generation quality. Additionally, existing metrics often overlook the importance of color fidelity in evaluating color-mattered tasks, such as the quality of NST-generated images, which is crucial in the context of artistic works. To comprehensively assess the color-mattered tasks, we propose the Adversarial Color Distance Metric (ACDM), designed to quantify the color difference of images pre- and post-manipulations. Experimental results confirm that attacking NST using LAACA results in visually inferior style transfer, and the ACDM can efficiently measure color-mattered tasks. By providing artists with a tool to safeguard their intellectual property, our work relieves the socio-technical challenges posed by the misuse of NST in the art community.",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "9 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2401.09712",
        "abstract url": "https://arxiv.org/abs/2401.09712",
        "title": "SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large language models (LLMs) have recently been extended to the vision-language realm, obtaining impressive general multi-modal capabilities. However, the exploration of multi-modal large language models (MLLMs) for remote sensing (RS) data is still in its infancy, and the performance is not satisfactory. In this work, we introduce SkyEyeGPT, a unified multi-modal large language model specifically designed for RS vision-language understanding. To this end, we meticulously curate an RS multi-modal instruction tuning dataset, including single-task and multi-task conversation instructions. After manual verification, we obtain a high-quality RS instruction-following dataset with 968k samples. Our research demonstrates that with a simple yet effective design, SkyEyeGPT works surprisingly well on considerably different tasks without the need for extra encoding modules. Specifically, after projecting RS visual features to the language domain via an alignment layer, they are fed jointly with task-specific instructions into an LLM-based RS decoder to predict answers for RS open-ended tasks. In addition, we design a two-stage tuning method to enhance instruction-following and multi-turn dialogue ability at different granularities. Experiments on 8 datasets for RS vision-language tasks demonstrate SkyEyeGPT's superiority in image-level and region-level tasks, such as captioning and visual grounding. In particular, SkyEyeGPT exhibits encouraging results compared to GPT-4V in some qualitative tests. The online demo, code, and dataset will be released in https://github.com/ZhanYang-nwpu/SkyEyeGPT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09720",
        "abstract url": "https://arxiv.org/abs/2401.09720",
        "title": "GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting",
        "rating": "0",
        "keywords": [
            [
                "3d",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we propose a novel clothed human reconstruction method called GaussianBody, based on 3D Gaussian Splatting. Compared with the costly neural radiance based models, 3D Gaussian Splatting has recently demonstrated great performance in terms of training time and rendering quality. However, applying the static 3D Gaussian Splatting model to the dynamic human reconstruction problem is non-trivial due to complicated non-rigid deformations and rich cloth details. To address these challenges, our method considers explicit pose-guided deformation to associate dynamic Gaussians across the canonical space and the observation space, introducing a physically-based prior with regularized transformations helps mitigate ambiguity between the two spaces. During the training process, we further propose a pose refinement strategy to update the pose regression for compensating the inaccurate initial estimation and a split-with-scale mechanism to enhance the density of regressed point clouds. The experiments validate that our method can achieve state-of-the-art photorealistic novel-view rendering results with high-quality details for dynamic clothed human bodies, along with explicit geometry reconstruction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10940",
        "abstract url": "https://arxiv.org/abs/2401.10940",
        "title": "RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation",
        "rating": "0",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In the era of information proliferation, discerning the credibility of news content poses an ever-growing challenge. This paper introduces RELIANCE, a pioneering ensemble learning system designed for robust information and fake news credibility evaluation. Comprising five diverse base models, including Support Vector Machine (SVM), naive Bayes, logistic regression, random forest, and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs an innovative approach to integrate their strengths, harnessing the collective intelligence of the ensemble for enhanced accuracy. Experiments demonstrate the superiority of RELIANCE over individual models, indicating its efficacy in distinguishing between credible and non-credible information sources. RELIANCE, also surpasses baseline models in information and news credibility assessment, establishing itself as an effective solution for evaluating the reliability of information sources.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG",
            "cs.SI"
        ],
        "comment": "Published in: 2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP) Publisher: IEEE Conference Location: Babol, Iran Date of Conference: 21-22 February 2024 Date Added to IEEE Xplore: 25 March 2024 pages={1-9}, https://ieeexplore.ieee.org/document/10475305"
    },
    {
        "paper id": "2401.08976",
        "abstract url": "https://arxiv.org/abs/2401.08976",
        "title": "ACT-GAN: Radio map construction based on generative adversarial networks with ACT blocks",
        "rating": "-0.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The radio map, serving as a visual representation of electromagnetic spatial characteristics, plays a pivotal role in assessment of wireless communication networks and radio monitoring coverage. Addressing the issue of low accuracy existing in the current radio map construction, this paper presents a novel radio map construction method based on generative adversarial network (GAN) in which the Aggregated Contextual-Transformation (AOT) block, Convolutional Block Attention Module (CBAM), and Transposed Convolution (T-Conv) block are applied to the generator, and we name it as ACT-GAN. It significantly improves the reconstruction accuracy and local texture of the radio maps. The performance of ACT-GAN across three different scenarios is demonstrated. Experiment results reveal that in the scenario without sparse discrete observations, the proposed method reduces the root mean square error (RMSE) by 14.6% in comparison to the state-of-the-art models. In the scenario with sparse discrete observations, the RMSE is diminished by 13.2%. Furthermore, the predictive results of the proposed model show a more lucid representation of electromagnetic spatial field distribution. To verify the universality of this model in radio map construction tasks, the scenario of unknown radio emission source is investigated. The results indicate that the proposed model is robust radio map construction and accurate in predicting the location of the emission source.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": "11 pages, 10 figures"
    },
    {
        "paper id": "2401.08996",
        "abstract url": "https://arxiv.org/abs/2401.08996",
        "title": "MicroNAS: Zero-Shot Neural Architecture Search for MCUs",
        "rating": "-0.5",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Neural Architecture Search (NAS) effectively discovers new Convolutional Neural Network (CNN) architectures, particularly for accuracy optimization. However, prior approaches often require resource-intensive training on super networks or extensive architecture evaluations, limiting practical applications. To address these challenges, we propose MicroNAS, a hardware-aware zero-shot NAS framework designed for microcontroller units (MCUs) in edge computing. MicroNAS considers target hardware optimality during the search, utilizing specialized performance indicators to identify optimal neural architectures without high computational costs. Compared to previous works, MicroNAS achieves up to 1104x improvement in search efficiency and discovers models with over 3.23x faster MCU inference while maintaining similar accuracy",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09031",
        "abstract url": "https://arxiv.org/abs/2401.09031",
        "title": "Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data attribution methods trace model behavior back to its training dataset, offering an effective approach to better understand ''black-box'' neural networks. While prior research has established quantifiable links between model output and training data in diverse settings, interpreting diffusion model outputs in relation to training samples remains underexplored. In particular, diffusion models operate over a sequence of timesteps instead of instantaneous input-output relationships in previous contexts, posing a significant challenge to extend existing frameworks to diffusion models directly. Notably, we present Diffusion-TracIn that incorporates this temporal dynamics and observe that samples' loss gradient norms are highly dependent on timestep. This trend leads to a prominent bias in influence estimation, and is particularly noticeable for samples trained on large-norm-inducing timesteps, causing them to be generally influential. To mitigate this effect, we introduce Diffusion-ReTrac as a re-normalized adaptation that enables the retrieval of training samples more targeted to the test sample of interest, facilitating a localized measurement of influence and considerably more intuitive visualization. We demonstrate the efficacy of our approach through various evaluation metrics and auxiliary tasks, reducing the amount of generally influential samples to $\\frac{1}{3}$ of its original quantity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09048",
        "abstract url": "https://arxiv.org/abs/2401.09048",
        "title": "Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "Diffusion",
                "Synthesis"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Addressing the limitations of text as a source of accurate layout representation in text-conditional diffusion models, many works incorporate additional signals to condition certain attributes within a generated image. Although successful, previous works do not account for the specific localization of said attributes extended into the three dimensional plane. In this context, we present a conditional diffusion model that integrates control over three-dimensional object placement with disentangled representations of global stylistic semantics from multiple exemplar images. Specifically, we first introduce \\textit{depth disentanglement training} to leverage the relative depth of objects as an estimator, allowing the model to identify the absolute positions of unseen objects through the use of synthetic image triplets. We also introduce \\textit{soft guidance}, a method for imposing global semantics onto targeted regions without the use of any additional localization cues. Our integrated framework, \\textsc{Compose and Conquer (CnC)}, unifies these techniques to localize multiple conditions in a disentangled manner. We demonstrate that our approach allows perception of objects at varying depths while offering a versatile framework for composing localized objects with different global semantics. Code: https://github.com/tomtom1103/compose-and-conquer/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2401.09071",
        "abstract url": "https://arxiv.org/abs/2401.09071",
        "title": "Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Whilst spectral Graph Neural Networks (GNNs) are theoretically well-founded in the spectral domain, their practical reliance on polynomial approximation implies a profound linkage to the spatial domain. As previous studies rarely examine spectral GNNs from the spatial perspective, their spatial-domain interpretability remains elusive, e.g., what information is essentially encoded by spectral GNNs in the spatial domain? In this paper, to answer this question, we establish a theoretical connection between spectral filtering and spatial aggregation, unveiling an intrinsic interaction that spectral filtering implicitly leads the original graph to an adapted new graph, explicitly computed for spatial aggregation. Both theoretical and empirical investigations reveal that the adapted new graph not only exhibits non-locality but also accommodates signed edge weights to reflect label consistency among nodes. These findings thus highlight the interpretable role of spectral GNNs in the spatial domain and inspire us to rethink graph spectral filters beyond the fixed-order polynomials, which neglect global information. Built upon the theoretical findings, we revisit the state-of-the-art spectral GNNs and propose a novel Spatially Adaptive Filtering (SAF) framework, which leverages the adapted new graph by spectral filtering for an auxiliary non-local aggregation. Notably, our proposed SAF comprehensively models both node similarity and dissimilarity from a global perspective, therefore alleviating persistent deficiencies of GNNs related to long-range dependencies and graph heterophily. Extensive experiments over 13 node classification benchmarks demonstrate the superiority of our proposed framework to the state-of-the-art models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09125",
        "abstract url": "https://arxiv.org/abs/2401.09125",
        "title": "Understanding Heterophily for Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graphs with heterophily have been regarded as challenging scenarios for Graph Neural Networks (GNNs), where nodes are connected with dissimilar neighbors through various patterns. In this paper, we present theoretical understandings of the impacts of different heterophily patterns for GNNs by incorporating the graph convolution (GC) operations into fully connected networks via the proposed Heterophilous Stochastic Block Models (HSBM), a general random graph model that can accommodate diverse heterophily patterns. Firstly, we show that by applying a GC operation, the separability gains are determined by two factors, i.e., the Euclidean distance of the neighborhood distributions and $\\sqrt{\\mathbb{E}\\left[\\operatorname{deg}\\right]}$, where $\\mathbb{E}\\left[\\operatorname{deg}\\right]$ is the averaged node degree. It reveals that the impact of heterophily on classification needs to be evaluated alongside the averaged node degree. Secondly, we show that the topological noise has a detrimental impact on separability, which is equivalent to degrading $\\mathbb{E}\\left[\\operatorname{deg}\\right]$. Finally, when applying multiple GC operations, we show that the separability gains are determined by the normalized distance of the $l$-powered neighborhood distributions. It indicates that the nodes still possess separability as $l$ goes to infinity in a wide range of regimes. Extensive experiments on both synthetic and real-world data verify the effectiveness of our theory.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09193",
        "abstract url": "https://arxiv.org/abs/2401.09193",
        "title": "GNN-LoFI: a Novel Graph Neural Network through Localized Feature-based Histogram Intersection",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph neural networks are increasingly becoming the framework of choice for graph-based machine learning. In this paper, we propose a new graph neural network architecture that substitutes classical message passing with an analysis of the local distribution of node features. To this end, we extract the distribution of features in the egonet for each local neighbourhood and compare them against a set of learned label distributions by taking the histogram intersection kernel. The similarity information is then propagated to other nodes in the network, effectively creating a message passing-like mechanism where the message is determined by the ensemble of the features. We perform an ablation study to evaluate the network's performance under different choices of its hyper-parameters. Finally, we test our model on standard graph classification and regression benchmarks, and we find that it outperforms widely used alternative approaches, including both graph kernels and graph neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09267",
        "abstract url": "https://arxiv.org/abs/2401.09267",
        "title": "Risk-Aware Accelerated Wireless Federated Learning with Heterogeneous Clients",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Wireless Federated Learning (FL) is an emerging distributed machine learning paradigm, particularly gaining momentum in domains with confidential and private data on mobile clients. However, the location-dependent performance, in terms of transmission rates and susceptibility to transmission errors, poses major challenges for wireless FL's convergence speed and accuracy. The challenge is more acute for hostile environments without a metric that authenticates the data quality and security profile of the clients. In this context, this paper proposes a novel risk-aware accelerated FL framework that accounts for the clients heterogeneity in the amount of possessed data, transmission rates, transmission errors, and trustworthiness. Classifying clients according to their location-dependent performance and trustworthiness profiles, we propose a dynamic risk-aware global model aggregation scheme that allows clients to participate in descending order of their transmission rates and an ascending trustworthiness constraint. In particular, the transmission rate is the dominant participation criterion for initial rounds to accelerate the convergence speed. Our model then progressively relaxes the transmission rate restriction to explore more training data at cell-edge clients. The aggregation rounds incorporate a debiasing factor that accounts for transmission errors. Risk-awareness is enabled by a validation set, where the base station eliminates non-trustworthy clients at the fine-tuning stage. The proposed scheme is benchmarked against a conservative scheme (i.e., only allowing trustworthy devices) and an aggressive scheme (i.e., oblivious to the trust metric). The numerical results highlight the superiority of the proposed scheme in terms of accuracy and convergence speed when compared to both benchmarks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09308",
        "abstract url": "https://arxiv.org/abs/2401.09308",
        "title": "Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?",
        "rating": "-0.5",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "Vehicle"
            ],
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In the design of traffic monitoring solutions for optimizing the urban mobility infrastructure, acoustic vehicle counting models have received attention due to their cost effectiveness and energy efficiency. Although deep learning has proven effective for visual traffic monitoring, its use has not been thoroughly investigated in the audio domain, likely due to real-world data scarcity. In this work, we propose a novel approach to acoustic vehicle counting by developing: i) a traffic noise simulation framework to synthesize realistic vehicle pass-by events; ii) a strategy to mix synthetic and real data to train a deep-learning model for traffic counting. The proposed system is capable of simultaneously counting cars and commercial vehicles driving on a two-lane road, and identifying their direction of travel under moderate traffic density conditions. With only 24 hours of labeled real-world traffic noise, we are able to improve counting accuracy on real-world data from $63\\%$ to $88\\%$ for cars and from $86\\%$ to $94\\%$ for commercial vehicles.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted paper: 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2024)"
    },
    {
        "paper id": "2401.09352",
        "abstract url": "https://arxiv.org/abs/2401.09352",
        "title": "Neural Contractive Dynamical Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Stability guarantees are crucial when ensuring a fully autonomous robot does not take undesirable or potentially harmful actions. Unfortunately, global stability guarantees are hard to provide in dynamical systems learned from data, especially when the learned dynamics are governed by neural networks. We propose a novel methodology to learn neural contractive dynamical systems, where our neural architecture ensures contraction, and hence, global stability. To efficiently scale the method to high-dimensional dynamical systems, we develop a variant of the variational autoencoder that learns dynamics in a low-dimensional latent representation space while retaining contractive stability after decoding. We further extend our approach to learning contractive systems on the Lie group of rotations to account for full-pose end-effector dynamic motions. The result is the first highly flexible learning architecture that provides contractive stability guarantees with capability to perform obstacle avoidance. Empirically, we demonstrate that our approach encodes the desired dynamics more accurately than the current state-of-the-art, which provides less strong stability guarantees.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09510",
        "abstract url": "https://arxiv.org/abs/2401.09510",
        "title": "Community Detection in the Multi-View Stochastic Block Model",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper considers the problem of community detection on multiple potentially correlated graphs from an information-theoretical perspective. We first put forth a random graph model, called the multi-view stochastic block model (MVSBM), designed to generate correlated graphs on the same set of nodes (with cardinality $n$). The $n$ nodes are partitioned into two disjoint communities of equal size. The presence or absence of edges in the graphs for each pair of nodes depends on whether the two nodes belong to the same community or not. The objective for the learner is to recover the hidden communities with observed graphs. Our technical contributions are two-fold: (i) We establish an information-theoretic upper bound (Theorem~1) showing that exact recovery of community is achievable when the model parameters of MVSBM exceed a certain threshold. (ii) Conversely, we derive an information-theoretic lower bound (Theorem~2) showing that when the model parameters of MVSBM fall below the aforementioned threshold, then for any estimator, the expected number of misclassified nodes will always be greater than one. Our results for the MVSBM recover several prior results for community detection in the standard SBM as well as in multiple independent SBMs as special cases.",
        "subjects": [
            "cs.SI",
            "cs.IT",
            "cs.LG",
            "eess.SP"
        ],
        "comment": "Submitted to IEEE for possible publication"
    },
    {
        "paper id": "2401.09574",
        "abstract url": "https://arxiv.org/abs/2401.09574",
        "title": "Towards Scalable and Robust Model Versioning",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As the deployment of deep learning models continues to expand across industries, the threat of malicious incursions aimed at gaining access to these deployed models is on the rise. Should an attacker gain access to a deployed model, whether through server breaches, insider attacks, or model inversion techniques, they can then construct white-box adversarial attacks to manipulate the model's classification outcomes, thereby posing significant risks to organizations that rely on these models for critical tasks. Model owners need mechanisms to protect themselves against such losses without the necessity of acquiring fresh training data - a process that typically demands substantial investments in time and capital. In this paper, we explore the feasibility of generating multiple versions of a model that possess different attack properties, without acquiring new training data or changing model architecture. The model owner can deploy one version at a time and replace a leaked version immediately with a new version. The newly deployed model version can resist adversarial attacks generated leveraging white-box access to one or all previously leaked versions. We show theoretically that this can be accomplished by incorporating parameterized hidden distributions into the model training data, forcing the model to learn task-irrelevant features uniquely defined by the chosen data. Additionally, optimal choices of hidden distributions can produce a sequence of model versions capable of resisting compound transferability attacks over time. Leveraging our analytical insights, we design and implement a practical model versioning method for DNN classifiers, which leads to significant robustness improvements over existing methods. We believe our work presents a promising direction for safeguarding DNN services beyond their initial deployment.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "Published in IEEE SaTML 2024"
    },
    {
        "paper id": "2401.09604",
        "abstract url": "https://arxiv.org/abs/2401.09604",
        "title": "MedBlindTuner: Towards Privacy-preserving Fine-tuning on Biomedical Images with Transformers and Fully Homomorphic Encryption",
        "rating": "-0.5",
        "keywords": [
            [
                "Biomedical",
                "medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Advancements in machine learning (ML) have significantly revolutionized medical image analysis, prompting hospitals to rely on external ML services. However, the exchange of sensitive patient data, such as chest X-rays, poses inherent privacy risks when shared with third parties. Addressing this concern, we propose MedBlindTuner, a privacy-preserving framework leveraging fully homomorphic encryption (FHE) and a data-efficient image transformer (DEiT). MedBlindTuner enables the training of ML models exclusively on FHE-encrypted medical images. Our experimental evaluation demonstrates that MedBlindTuner achieves comparable accuracy to models trained on non-encrypted images, offering a secure solution for outsourcing ML computations while preserving patient data privacy. To the best of our knowledge, this is the first work that uses data-efficient image transformers and fully homomorphic encryption in this domain.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted for the presentation at W3PHIAI, The 38th Annual AAAI Conference on Artificial Intelligence 2024"
    },
    {
        "paper id": "2401.09656",
        "abstract url": "https://arxiv.org/abs/2401.09656",
        "title": "Mobility Accelerates Learning: Convergence Analysis on Hierarchical Federated Learning in Vehicular Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Hierarchical federated learning (HFL) enables distributed training of models across multiple devices with the help of several edge servers and a cloud edge server in a privacy-preserving manner. In this paper, we consider HFL with highly mobile devices, mainly targeting at vehicular networks. Through convergence analysis, we show that mobility influences the convergence speed by both fusing the edge data and shuffling the edge models. While mobility is usually considered as a challenge from the perspective of communication, we prove that it increases the convergence speed of HFL with edge-level heterogeneous data, since more diverse data can be incorporated. Furthermore, we demonstrate that a higher speed leads to faster convergence, since it accelerates the fusion of data. Simulation results show that mobility increases the model accuracy of HFL by up to 15.1% when training a convolutional neural network on the CIFAR-10 dataset.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "Submitted to IEEE for possible publication"
    },
    {
        "paper id": "2401.09666",
        "abstract url": "https://arxiv.org/abs/2401.09666",
        "title": "Traffic Smoothing Controllers for Autonomous Vehicles Using Deep Reinforcement Learning and Real-World Trajectory Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Trajectory",
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Designing traffic-smoothing cruise controllers that can be deployed onto autonomous vehicles is a key step towards improving traffic flow, reducing congestion, and enhancing fuel efficiency in mixed autonomy traffic. We bypass the common issue of having to carefully fine-tune a large traffic microsimulator by leveraging real-world trajectory data from the I-24 highway in Tennessee, replayed in a one-lane simulation. Using standard deep reinforcement learning methods, we train energy-reducing wave-smoothing policies. As an input to the agent, we observe the speed and distance of only the vehicle in front, which are local states readily available on most recent vehicles, as well as non-local observations about the downstream state of the traffic. We show that at a low 4% autonomous vehicle penetration rate, we achieve significant fuel savings of over 15% on trajectories exhibiting many stop-and-go waves. Finally, we analyze the smoothing effect of the controllers and demonstrate robustness to adding lane-changing into the simulation as well as the removal of downstream information.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "Accepted to be published as part of the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC) 2023, Bilbao, Spain, September 24-28, 2023"
    },
    {
        "paper id": "2401.09721",
        "abstract url": "https://arxiv.org/abs/2401.09721",
        "title": "Fast graph-based denoising for point cloud color information",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Point clouds are utilized in various 3D applications such as cross-reality (XR) and realistic 3D displays. In some applications, e.g., for live streaming using a 3D point cloud, real-time point cloud denoising methods are required to enhance the visual quality. However, conventional high-precision denoising methods cannot be executed in real time for large-scale point clouds owing to the complexity of graph constructions with K nearest neighbors and noise level estimation. This paper proposes a fast graph-based denoising (FGBD) for a large-scale point cloud. First, high-speed graph construction is achieved by scanning a point cloud in various directions and searching adjacent neighborhoods on the scanning lines. Second, we propose a fast noise level estimation method using eigenvalues of the covariance matrix on a graph. Finally, we also propose a new low-cost filter selection method to enhance denoising accuracy to compensate for the degradation caused by the acceleration algorithms. In our experiments, we succeeded in reducing the processing time dramatically while maintaining accuracy relative to conventional denoising methods. Denoising was performed at 30fps, with frames containing approximately 1 million points.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "eess.SP"
        ],
        "comment": "Published in the proceeding of 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2024)"
    },
    {
        "paper id": "2401.14411",
        "abstract url": "https://arxiv.org/abs/2401.14411",
        "title": "Precision Mars Entry Navigation with Atmospheric Density Adaptation via Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Discrepancies between the true Martian atmospheric density and the onboard density model can significantly impair the performance of spacecraft entry navigation filters. This work introduces a new approach to online filtering for Martian entry by using a neural network to estimate atmospheric density and employing a consider analysis to account for the uncertainty in the estimate. The network is trained on an exponential atmospheric density model, and its parameters are dynamically adapted in real time to account for any mismatches between the true and estimated densities. The adaptation of the network is formulated as a maximum likelihood problem, leveraging the measurement innovations of the filter to identify optimal network parameters. The incorporation of a neural network enables the use of stochastic optimizers known for their efficiency in the machine learning domain within the context of the maximum likelihood approach. Performance comparisons against previous approaches are conducted in various realistic Mars entry navigation scenarios, resulting in superior estimation accuracy and precise alignment of the estimated density with a broad selection of realistic Martian atmospheres sampled from perturbed Mars-GRAM data.",
        "subjects": [
            "cs.LG",
            "eess.SY",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01671",
        "abstract url": "https://arxiv.org/abs/2402.01671",
        "title": "Learning Analytics Dashboards for Advisors -- A Systematic Literature Review",
        "rating": "-0.5",
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Learning Analytics Dashboard for Advisors is designed to provide data-driven insights and visualizations to support advisors in their decision-making regarding student academic progress, engagement, targeted support, and overall success. This study explores the current state of the art in learning analytics dashboards, focusing on specific requirements for advisors. By examining existing literature and case studies, this research investigates the key features and functionalities essential for an effective learning analytics dashboard tailored to advisor needs. This study also aims to provide a comprehensive understanding of the landscape of learning analytics dashboards for advisors, offering insights into the advancements, opportunities, and challenges in their development by synthesizing the current trends from a total of 21 research papers used for analysis. The findings will contribute to the design and implementation of new features in learning analytics dashboards that empower advisors to provide proactive and individualized support, ultimately fostering student retention and academic success.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09019",
        "abstract url": "https://arxiv.org/abs/2401.09019",
        "title": "Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM)",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised multimodal change detection is pivotal for time-sensitive tasks and comprehensive multi-temporal Earth monitoring. In this study, we explore unsupervised multimodal change detection between two key remote sensing data sources: optical high-resolution imagery and OpenStreetMap (OSM) data. Specifically, we propose to utilize the vision foundation model Segmentation Anything Model (SAM), for addressing our task. Leveraging SAM's exceptional zero-shot transfer capability, high-quality segmentation maps of optical images can be obtained. Thus, we can directly compare these two heterogeneous data forms in the so-called segmentation domain. We then introduce two strategies for guiding SAM's segmentation process: the 'no-prompt' and 'box/mask prompt' methods. The two strategies are designed to detect land-cover changes in general scenarios and to identify new land-cover objects within existing backgrounds, respectively. Experimental results on three datasets indicate that the proposed approach can achieve more competitive results compared to representative unsupervised multimodal change detection methods.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09029",
        "abstract url": "https://arxiv.org/abs/2401.09029",
        "title": "Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "Tumor"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Brain tumor represents one of the most fatal cancers around the world, and is very common in children and the elderly. Accurate identification of the type and grade of tumor in the early stages plays an important role in choosing a precise treatment plan. The Magnetic Resonance Imaging (MRI) protocols of different sequences provide clinicians with important contradictory information to identify tumor regions. However, manual assessment is time-consuming and error-prone due to big amount of data and the diversity of brain tumor types. Hence, there is an unmet need for MRI automated brain tumor diagnosis. We observe that the predictive capability of uni-modality models is limited and their performance varies widely across modalities, and the commonly used modality fusion methods would introduce potential noise, which results in significant performance degradation. To overcome these challenges, we propose a novel cross-modality guidance-aided multi-modal learning with dual attention for addressing the task of MRI brain tumor grading. To balance the tradeoff between model efficiency and efficacy, we employ ResNet Mix Convolution as the backbone network for feature extraction. Besides, dual attention is applied to capture the semantic interdependencies in spatial and slice dimensions respectively. To facilitate information interaction among modalities, we design a cross-modality guidance-aided module where the primary modality guides the other secondary modalities during the process of training, which can effectively leverage the complementary information of different MRI modalities and meanwhile alleviate the impact of the possible noise.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09032",
        "abstract url": "https://arxiv.org/abs/2401.09032",
        "title": "Improved Consensus ADMM for Cooperative Motion Planning of Large-Scale Connected Autonomous Vehicles with Limited Communication",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This paper investigates a cooperative motion planning problem for large-scale connected autonomous vehicles (CAVs) under limited communications, which addresses the challenges of high communication and computing resource requirements. Our proposed methodology incorporates a parallel optimization algorithm with improved consensus ADMM considering a more realistic locally connected topology network, and time complexity of O(N) is achieved by exploiting the sparsity in the dual update process. To further enhance the computational efficiency, we employ a lightweight evolution strategy for the dynamic connectivity graph of CAVs, and each sub-problem split from the consensus ADMM only requires managing a small group of CAVs. The proposed method implemented with the receding horizon scheme is validated thoroughly, and comparisons with existing numerical solvers and approaches demonstrate the efficiency of our proposed algorithm. Also, simulations on large-scale cooperative driving tasks involving 80 vehicles are performed in the high-fidelity CARLA simulator, which highlights the remarkable computational efficiency, scalability, and effectiveness of our proposed development. Demonstration videos are available at https://henryhcliu.github.io/icadmm_cmp_carla.",
        "subjects": [
            "cs.RO",
            "cs.MA",
            "eess.SY"
        ],
        "comment": "15 pages, 10 figures"
    },
    {
        "paper id": "2401.09036",
        "abstract url": "https://arxiv.org/abs/2401.09036",
        "title": "IRS-Enhanced Anti-Jamming Precoding Against DISCO Physical Layer Jamming Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Illegitimate intelligent reflective surfaces (IRSs) can pose significant physical layer security risks on multi-user multiple-input single-output (MU-MISO) systems. Recently, a DISCO approach has been proposed an illegitimate IRS with random and time-varying reflection coefficients, referred to as a \"disco\" IRS (DIRS). Such DIRS can attack MU-MISO systems without relying on either jamming power or channel state information (CSI), and classical anti-jamming techniques are ineffective for the DIRS-based fully-passive jammers (DIRS-based FPJs). In this paper, we propose an IRS-enhanced anti-jamming precoder against DIRS-based FPJs that requires only statistical rather than instantaneous CSI of the DIRS-jammed channels. Specifically, a legitimate IRS is introduced to reduce the strength of the DIRS-based jamming relative to the transmit signals at a legitimate user (LU). In addition, the active beamforming at the legitimate access point (AP) is designed to maximize the signal-to-jamming-plus-noise ratios (SJNRs). Numerical results are presented to evaluate the effectiveness of the proposed IRS-enhanced anti-jamming precoder against DIRS-based FPJs.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "This paper has been accepted by IEEE ICC 2024"
    },
    {
        "paper id": "2401.09049",
        "abstract url": "https://arxiv.org/abs/2401.09049",
        "title": "Enhancing Lidar-based Object Detection in Adverse Weather using Offset Sequences in Time",
        "rating": "-1",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "Lidar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automated vehicles require an accurate perception of their surroundings for safe and efficient driving. Lidar-based object detection is a widely used method for environment perception, but its performance is significantly affected by adverse weather conditions such as rain and fog. In this work, we investigate various strategies for enhancing the robustness of lidar-based object detection by processing sequential data samples generated by lidar sensors. Our approaches leverage temporal information to improve a lidar object detection model, without the need for additional filtering or pre-processing steps. We compare $10$ different neural network architectures that process point cloud sequences including a novel augmentation strategy introducing a temporal offset between frames of a sequence during training and evaluate the effectiveness of all strategies on lidar point clouds under adverse weather conditions through experiments. Our research provides a comprehensive study of effective methods for mitigating the effects of adverse weather on the reliability of lidar-based object detection using sequential data that are evaluated using public datasets such as nuScenes, Dense, and the Canadian Adverse Driving Conditions Dataset. Our findings demonstrate that our novel method, involving temporal offset augmentation through randomized frame skipping in sequences, enhances object detection accuracy compared to both the baseline model (Pillar-based Object Detection) and no augmentation.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Published as part of the III. International Conference on Electrical, Computer and Energy Technologies (ICECET 2023), Cape Town, South Africa, November 16-17, 2023"
    },
    {
        "paper id": "2401.09077",
        "abstract url": "https://arxiv.org/abs/2401.09077",
        "title": "Hands-On Robotics: Enabling Communication Through Direct Gesture Control",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "Robot"
            ]
        ],
        "abstract": "Effective Human-Robot Interaction (HRI) is fundamental to seamlessly integrating robotic systems into our daily lives. However, current communication modes require additional technological interfaces, which can be cumbersome and indirect. This paper presents a novel approach, using direct motion-based communication by moving a robot's end effector. Our strategy enables users to communicate with a robot by using four distinct gestures -- two handshakes ('formal' and 'informal') and two letters ('W' and 'S'). As a proof-of-concept, we conducted a user study with 16 participants, capturing subjective experience ratings and objective data for training machine learning classifiers. Our findings show that the four different gestures performed by moving the robot's end effector can be distinguished with close to 100% accuracy. Our research offers implications for the design of future HRI interfaces, suggesting that motion-based interaction can empower human operators to communicate directly with robots, removing the necessity for additional hardware.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": "Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction"
    },
    {
        "paper id": "2401.09083",
        "abstract url": "https://arxiv.org/abs/2401.09083",
        "title": "Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and Visual Models",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, the flourishing large language models(LLM), especially ChatGPT, have shown exceptional performance in language understanding, reasoning, and interaction, attracting users and researchers from multiple fields and domains. Although LLMs have shown great capacity to perform human-like task accomplishment in natural language and natural image, their potential in handling remote sensing interpretation tasks has not yet been fully explored. Moreover, the lack of automation in remote sensing task planning hinders the accessibility of remote sensing interpretation techniques, especially to non-remote sensing experts from multiple research fields. To this end, we present Remote Sensing ChatGPT, an LLM-powered agent that utilizes ChatGPT to connect various AI-based remote sensing models to solve complicated interpretation tasks. More specifically, given a user request and a remote sensing image, we utilized ChatGPT to understand user requests, perform task planning according to the tasks' functions, execute each subtask iteratively, and generate the final response according to the output of each subtask. Considering that LLM is trained with natural language and is not capable of directly perceiving visual concepts as contained in remote sensing images, we designed visual cues that inject visual information into ChatGPT. With Remote Sensing ChatGPT, users can simply send a remote sensing image with the corresponding request, and get the interpretation results as well as language feedback from Remote Sensing ChatGPT. Experiments and examples show that Remote Sensing ChatGPT can tackle a wide range of remote sensing tasks and can be extended to more tasks with more sophisticated models such as the remote sensing foundation model. The code and demo of Remote Sensing ChatGPT is publicly available at https://github.com/HaonanGuo/Remote-Sensing-ChatGPT .",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The manuscript is submitted to IEEE International Geoscience and Remote Sensing Symposium(IGARSS2024). Looking forward to seeing you in July!"
    },
    {
        "paper id": "2401.09098",
        "abstract url": "https://arxiv.org/abs/2401.09098",
        "title": "Multi-target Detection for Reconfigurable Holographic Surfaces Enabled Radar",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "Multi-target detection is one of the primary tasks in radar-based localization and sensing, typically built on phased array antennas. However, the bulky hardware in the phased array restricts its potential for enhancing detection accuracy, since the cost and power of the phased array can become unaffordable as its physical aperture scales up to pursue higher beam shaping capabilities. To resolve this issue, we propose a radar system enabled by reconfigurable holographic surfaces (RHSs), a novel meta-surface antenna composed of meta-material elements with cost-effective and power-efficient hardware, which performs multi-target detection in an adaptive manner. Different from the phase-control structure in the phased array, the RHS is able to apply beamforming by controlling the radiation amplitudes of its elements. Consequently, traditional beamforming schemes designed for phased arrays cannot be directly applied to RHSs due to this structural difference. To tackle this challenge, a waveform and amplitude optimization algorithm (WAOA) is designed to jointly optimize the radar waveform and RHS amplitudes in order to improve the detection accuracy. Simulation results reveal that the proposed RHS-enabled radar increases the probability of detection by 0.13 compared to phased array radars when six iterations of adaptive detection are performed given the same hardware cost.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09101",
        "abstract url": "https://arxiv.org/abs/2401.09101",
        "title": "PIN-SLAM: LiDAR SLAM Using a Point-Based Implicit Neural Representation for Achieving Global Map Consistency",
        "rating": "-1",
        "keywords": [
            [
                "voxel",
                "RGB-D"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate and robust localization and mapping are essential components for most autonomous robots. In this paper, we propose a SLAM system for building globally consistent maps, called PIN-SLAM, that is based on an elastic and compact point-based implicit neural map representation. Taking range measurements as input, our approach alternates between incremental learning of the local implicit signed distance field and the pose estimation given the current local map using a correspondence-free, point-to-implicit model registration. Our implicit map is based on sparse optimizable neural points, which are inherently elastic and deformable with the global pose adjustment when closing a loop. Loops are also detected using the neural point features. Extensive experiments validate that PIN-SLAM is robust to various environments and versatile to different range sensors such as LiDAR and RGB-D cameras. PIN-SLAM achieves pose estimation accuracy better or on par with the state-of-the-art LiDAR odometry or SLAM systems and outperforms the recent neural implicit SLAM approaches while maintaining a more consistent, and highly compact implicit map that can be reconstructed as accurate and complete meshes. Finally, thanks to the voxel hashing for efficient neural points indexing and the fast implicit map-based registration without closest point association, PIN-SLAM can run at the sensor frame rate on a moderate GPU. Codes will be available at: https://github.com/PRBonn/PIN_SLAM.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2401.09110",
        "abstract url": "https://arxiv.org/abs/2401.09110",
        "title": "Global and Local Error-Tolerant Decentralized State Estimation under Partially Ordered Observations",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "We investigate decentralized state estimation for a discrete event system in a setting where the information received at a coordinator may be corrupted or tampered by a malicious attacker. Specifically, a system is observed by a set of (local) observation sites (OSs) which occasionally send their recorded sequences of observations to the coordinator that is in charge of estimating the system state. The malfunctions and attacks, referred to as errors in this paper, include symbol deletions, insertions and replacements, each of which bears a positive cost. Two types of errors, global errors and local errors, are proposed to describe the impact of errors on decentralized information processing. Global errors occur when all OSs record the same error, while local errors occur when different OSs record different errors. Distinguishing these types of errors is important for a proper design of decentralized information processing (so as to be more resilient and better equipped to handle errors and failures). For each type of error, we propose two methods to efficiently perform state estimation: one based on appropriately modifying the original system and the other based on inferring the matching behavior of the original system. For each method, we adopt an estimation-by-release methodology to design an algorithm for constructing a corresponding synchronizer for state estimation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09115",
        "abstract url": "https://arxiv.org/abs/2401.09115",
        "title": "A Type II Singularity Avoidance Algorithm for Parallel Manipulators using Output Twist Screws",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "Parallel robots (PRs) are closed-chain manipulators with diverse applications due to their accuracy and high payload. However, there are configurations within the workspace named Type II singularities where the PRs lose control of the end-effector movements. Type II singularities are a problem for applications where complete control of the end-effector is essential. Trajectory planning produces accurate movements of a PR by avoiding Type II singularities. Generally, singularity avoidance is achieved by optimising a geometrical path with a velocity profile considering singular configurations as obstacles. This research presents an algorithm that avoids Type II singularities by modifying the trajectory of a subset of the actuators. The subset of actuators represents the limbs responsible for a Type II singularity, and they are identified by the angle between two Output Twist Screws. The proposed avoidance algorithm does not require optimisation procedures, which reduces the computational cost for offline trajectory planning and makes it suitable for online trajectory planning. The avoidance algorithm is implemented in offline trajectory planning for a pick and place planar PR and a spatial knee rehabilitation PR",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09133",
        "abstract url": "https://arxiv.org/abs/2401.09133",
        "title": "SM$^3$: Self-Supervised Multi-task Modeling with Multi-view 2D Images for Articulated Objects",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstructing real-world objects and estimating their movable joint structures are pivotal technologies within the field of robotics. Previous research has predominantly focused on supervised approaches, relying on extensively annotated datasets to model articulated objects within limited categories. However, this approach falls short of effectively addressing the diversity present in the real world. To tackle this issue, we propose a self-supervised interaction perception method, referred to as SM$^3$, which leverages multi-view RGB images captured before and after interaction to model articulated objects, identify the movable parts, and infer the parameters of their rotating joints. By constructing 3D geometries and textures from the captured 2D images, SM$^3$ achieves integrated optimization of movable part and joint parameters during the reconstruction process, obviating the need for annotations. Furthermore, we introduce the MMArt dataset, an extension of PartNet-Mobility, encompassing multi-view and multi-modal data of articulated objects spanning diverse categories. Evaluations demonstrate that SM$^3$ surpasses existing benchmarks across various categories and objects, while its adaptability in real-world scenarios has been thoroughly validated.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09150",
        "abstract url": "https://arxiv.org/abs/2401.09150",
        "title": "Bridging Research and Readers: A Multi-Modal Automated Academic Papers Interpretation System",
        "rating": "-1",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the contemporary information era, significantly accelerated by the advent of Large-scale Language Models, the proliferation of scientific literature is reaching unprecedented levels. Researchers urgently require efficient tools for reading and summarizing academic papers, uncovering significant scientific literature, and employing diverse interpretative methodologies. To address this burgeoning demand, the role of automated scientific literature interpretation systems has become paramount. However, prevailing models, both commercial and open-source, confront notable challenges: they often overlook multimodal data, grapple with summarizing over-length texts, and lack diverse user interfaces. In response, we introduce an open-source multi-modal automated academic paper interpretation system (MMAPIS) with three-step process stages, incorporating LLMs to augment its functionality. Our system first employs the hybrid modality preprocessing and alignment module to extract plain text, and tables or figures from documents separately. It then aligns this information based on the section names they belong to, ensuring that data with identical section names are categorized under the same section. Following this, we introduce a hierarchical discourse-aware summarization method. It utilizes the extracted section names to divide the article into shorter text segments, facilitating specific summarizations both within and between sections via LLMs with specific prompts. Finally, we have designed four types of diversified user interfaces, including paper recommendation, multimodal Q\\&A, audio broadcasting, and interpretation blog, which can be widely applied across various scenarios. Our qualitative and quantitative evaluations underscore the system's superiority, especially in scientific summarization, where it outperforms solutions relying solely on GPT-4.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09190",
        "abstract url": "https://arxiv.org/abs/2401.09190",
        "title": "Exploring the Role of Convolutional Neural Networks (CNN) in Dental Radiography Segmentation: A Comprehensive Systematic Literature Review",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "diagnosis"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In the field of dentistry, there is a growing demand for increased precision in diagnostic tools, with a specific focus on advanced imaging techniques such as computed tomography, cone beam computed tomography, magnetic resonance imaging, ultrasound, and traditional intra-oral periapical X-rays. Deep learning has emerged as a pivotal tool in this context, enabling the implementation of automated segmentation techniques crucial for extracting essential diagnostic data. This integration of cutting-edge technology addresses the urgent need for effective management of dental conditions, which, if left undetected, can have a significant impact on human health. The impressive track record of deep learning across various domains, including dentistry, underscores its potential to revolutionize early detection and treatment of oral health issues. Objective: Having demonstrated significant results in diagnosis and prediction, deep convolutional neural networks (CNNs) represent an emerging field of multidisciplinary research. The goals of this study were to provide a concise overview of the state of the art, standardize the current debate, and establish baselines for future research. Method: In this study, a systematic literature review is employed as a methodology to identify and select relevant studies that specifically investigate the deep learning technique for dental imaging analysis. This study elucidates the methodological approach, including the systematic collection of data, statistical analysis, and subsequent dissemination of outcomes. Conclusion: This work demonstrates how Convolutional Neural Networks (CNNs) can be employed to analyze images, serving as effective tools for detecting dental pathologies. Although this research acknowledged some limitations, CNNs utilized for segmenting and categorizing teeth exhibited their highest level of performance overall.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09204",
        "abstract url": "https://arxiv.org/abs/2401.09204",
        "title": "Cross-Domain AI for Early Attack Detection and Defense Against Malicious Flows in O-RAN",
        "rating": "-1",
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "Only the chairs can edit In the fight against cyber attacks, Network Softwarization (NS) is a flexible and adaptable shield, using advanced software to spot malicious activity in regular network traffic. However, the availability of comprehensive datasets for mobile networks, which are fundamental for the development of Machine Learning (ML) solutions for attack detection near their source, is still limited. Cross-Domain Artificial Intelligence (AI) can be the key to address this, although its application in Open Radio Access Network (O-RAN) is still at its infancy. To address these challenges, we deployed an end-to-end O-RAN network, that was used to collect data from the RAN and the transport network. These datasets allow us to combine the knowledge from an in-network ML traffic classifier for attack detection to bolster the training of an ML-based traffic classifier specifically tailored for the RAN. Our results demonstrate the potential of the proposed approach, achieving an accuracy rate of 93%. This approach not only bridges critical gaps in mobile network security but also showcases the potential of cross-domain AI in enhancing the efficacy of network security measures.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09221",
        "abstract url": "https://arxiv.org/abs/2401.09221",
        "title": "Multiple Subset Problem as an encryption scheme for communication",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Using well-known mathematical problems for encryption is a widely used technique because they are computationally hard and provide security against potential attacks on the encryption method. The subset sum problem (SSP) can be defined as finding a subset of integers from a given set, whose sum is equal to a specified integer. The classic SSP has various variants, one of which is the multiple-subset problem (MSSP). In the MSSP, the goal is to select items from a given set and distribute them among multiple bins, en-suring that the capacity of each bin is not exceeded while maximizing the total weight of the selected items. This approach addresses a related problem with a different perspective. Here a related different kind of problem is approached: given a set of sets A={A1, A2..., An}, find an integer s for which every subset of the given sets is summed up to, if such an integer exists. The problem is NP-complete when considering it as a variant of SSP. However, there exists an algorithm that is relatively efficient for known pri-vate keys. This algorithm is based on dispensing non-relevant values of the potential sums. In this paper we present the encryption scheme based on MSSP and present its novel usage and implementation in communication.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09239",
        "abstract url": "https://arxiv.org/abs/2401.09239",
        "title": "DaFoEs: Mixing Datasets towards the generalization of vision-state deep-learning Force Estimation in Minimally Invasive Robotic Surgery",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "Surgery"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Precisely determining the contact force during safe interaction in Minimally Invasive Robotic Surgery (MIRS) is still an open research challenge. Inspired by post-operative qualitative analysis from surgical videos, the use of cross-modality data driven deep neural network models has been one of the newest approaches to predict sensorless force trends. However, these methods required for large and variable datasets which are not currently available. In this paper, we present a new vision-haptic dataset (DaFoEs) with variable soft environments for the training of deep neural models. In order to reduce the bias from a single dataset, we present a pipeline to generalize different vision and state data inputs for mixed dataset training, using a previously validated dataset with different setup. Finally, we present a variable encoder-decoder architecture to predict the forces done by the laparoscopic tool using single input or sequence of inputs. For input sequence, we use a recurrent decoder, named with the prefix R, and a new temporal sampling to represent the acceleration of the tool. During our training, we demonstrate that single dataset training tends to overfit to the training data domain, but has difficulties on translating the results across new domains. However, dataset mixing presents a good translation with a mean relative estimated force error of 5% and 12% for the recurrent and non-recurrent models respectively. Our method, also marginally increase the effectiveness of transformers for force estimation up to a maximum of ~15%, as the volume of available data is increase by 150%. In conclusion, we demonstrate that mixing experimental set ups for vision-state force estimation in MIRS is a possible approach towards the general solution of the problem.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09241",
        "abstract url": "https://arxiv.org/abs/2401.09241",
        "title": "Biased-MPPI: Informing Sampling-Based Model Predictive Control by Fusing Ancillary Controllers",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Motion planning for autonomous robots in dynamic environments poses numerous challenges due to uncertainties in the robot's dynamics and interaction with other agents. Sampling-based MPC approaches, such as Model Predictive Path Integral (MPPI) control, have shown promise in addressing these complex motion planning problems. However, the performance of MPPI relies heavily on the choice of sampling distribution. Existing literature often uses the previously computed input sequence as the mean of a Gaussian distribution for sampling, leading to potential failures and local minima. In this paper, we propose a novel derivation of MPPI that allows for arbitrary sampling distributions to enhance efficiency, robustness, and convergence while alleviating the problem of local minima. We present an efficient importance sampling scheme that combines classical and learning-based ancillary controllers simultaneously, resulting in more informative sampling and control fusion. Several simulated and real-world demonstrate the validity of our approach.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for Robotics and Automation Letters, April 2024"
    },
    {
        "paper id": "2401.09242",
        "abstract url": "https://arxiv.org/abs/2401.09242",
        "title": "Offloading platooning applications from 5.9 GHz V2X to Radar Communications: effects on safety and efficiency",
        "rating": "-1",
        "keywords": [
            [
                "Radar",
                "vehicle"
            ]
        ],
        "abstract": "V2X communications are nowadays performed at 5.9\\,GHz spectrum, either using WiFi-based or Cellular technology. The channel capacity is limited, and congestion control regulates the number of messages that can enter the medium. With user rate growing, overloading becomes a factor that might affect road safety and traffic efficiency. The present paper evaluates the potential of using Radar-Based Communication (RadCom) for offloading the V2X spectrum. We consider a heavy-duty vehicle (HDV) platooning scenario as a case of maneuver coordination where local messages are transmitted by means of RadCom at different penetration rates. Simulations show significant improvements in channel occupation and network reliability. As a result, RadCom allows for shorter safe and energy efficient inter-vehicle distances.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted to Conference"
    },
    {
        "paper id": "2401.09243",
        "abstract url": "https://arxiv.org/abs/2401.09243",
        "title": "DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Robotics",
                "Robot"
            ],
            [
                "cs.AI"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Robot learning tasks are extremely compute-intensive and hardware-specific. Thus the avenues of tackling these challenges, using a diverse dataset of offline demonstrations that can be used to train robot manipulation agents, is very appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a well-curated open-source dataset for offline training comprised mostly of expert data and also benchmark scores of the common offline-RL and behaviour cloning agents. In this paper, we introduce DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-based policy learning, and measured the efficacy of our method on real online physical robots at test time. This is also our official submission to the Train-Offline-Test-Online (TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both pre-trained visual representation and agent policies. In our experiments, we find that MOCO finetuned ResNet50 performs the best in comparison to other finetuned representations. Goal state conditioning and mapping to transitions resulted in a minute increase in the success rate and mean-reward. As for the agent policy, we developed DiffClone, a behaviour cloning agent improved using conditional diffusion.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "NeurIPS 2023 Train Offline Test Online Workshop and Competition (Best Paper Oral Presentation Winning Competition Submission)"
    },
    {
        "paper id": "2401.09271",
        "abstract url": "https://arxiv.org/abs/2401.09271",
        "title": "PixelDINO: Semi-Supervised Semantic Segmentation for Detecting Permafrost Disturbances",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Arctic Permafrost is facing significant changes due to global climate change. As these regions are largely inaccessible, remote sensing plays a crucial rule in better understanding the underlying processes not just on a local scale, but across the Arctic. In this study, we focus on the remote detection of retrogressive thaw slumps (RTS), a permafrost disturbance comparable to landslides induced by thawing. For such analyses from space, deep learning has become an indispensable tool, but limited labelled training data remains a challenge for training accurate models. To improve model generalization across the Arctic without the need for additional labelled data, we present a semi-supervised learning approach to train semantic segmentation models to detect RTS. Our framework called PixelDINO is trained in parallel on labelled data as well as unlabelled data. For the unlabelled data, the model segments the imagery into self-taught pseudo-classes and the training procedure ensures consistency of these pseudo-classes across strong augmentations of the input data. Our experimental results demonstrate that PixelDINO can improve model performance both over supervised baseline methods as well as existing semi-supervised semantic segmentation approaches, highlighting its potential for training robust models that generalize well to regions that were not included in the training data. The project page containing code and other materials for this study can be found at \\url{https://khdlr.github.io/PixelDINO/}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09292",
        "abstract url": "https://arxiv.org/abs/2401.09292",
        "title": "Hierarchical Analyses Applied to Computer System Performance: Review and Call for Further Studies",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We review studies based on analytic and simulation methods for hierarchical performance analysis of Queueing Network - QN models, which result in an order of magnitude reduction in performance evaluation cost with respect to simulation. The computational cost at the lower level is reduced when the computer system is modeled as a product-form QN. A Continuous Time Markov Chain - CTMC or discrete-event simulation can then be used at the higher level. We first consider a multiprogrammed transaction - txn processing system with Poisson arrivals and predeclared locks requests. Txn throughputs obtained by the analysis of multiprogrammed computer systems serve as the transition rates in a higher level CTMC to determine txn response times. We next analyze a task system where task precedence relationships are specified by a directed acyclic graph to determine its makespan. Task service demands are specified on the devices of a computer system. The composition of tasks in execution determines txn throughputs, which serve as transition rates among the states of the higher level CTMC model. As a third example we consider the hierarchical simulation of a timesharing system with two user classes. Txn throughputs in processing various combinations of requests are obtained by analyzing a closed product-form QN model. A discrete event simulator is provided. More detailed QN modeling parameters, such as the distribution of the number of cycles in central server model - CSM affects the performance of a fork/join queueing system. This detail can be taken into account in Schwetman's hybrid simulation method, which counts remaining cycles in CSM. We propose an extension to hybrid simulation to adjust job service demands according to elapsed time, rather than counting cycles. An example where Equilibrium Point Analysis to reduce computaional cost is privided.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09321",
        "abstract url": "https://arxiv.org/abs/2401.09321",
        "title": "The landscape of Collective Awareness in multi-robot systems",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "The development of collective-aware multi-robot systems is crucial for enhancing the efficiency and robustness of robotic applications in multiple fields. These systems enable collaboration, coordination, and resource sharing among robots, leading to improved scalability, adaptability to dynamic environments, and increased overall system robustness. In this work, we want to provide a brief overview of this research topic and identify open challenges.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to workshop titled \"Designing Aware Robots: The EIC Pathfinder Challenge - Explore Awareness Inside\" at the European Robotics Forum 2024"
    },
    {
        "paper id": "2401.09336",
        "abstract url": "https://arxiv.org/abs/2401.09336",
        "title": "To deform or not: treatment-aware longitudinal registration for breast DCE-MRI during neoadjuvant chemotherapy via unsupervised keypoints detection",
        "rating": "-1",
        "keywords": [
            [
                "biomarker",
                "MRI",
                "Clinical",
                "tumor",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Clinicians compare breast DCE-MRI after neoadjuvant chemotherapy (NAC) with pre-treatment scans to evaluate the response to NAC. Clinical evidence supports that accurate longitudinal deformable registration without deforming treated tumor regions is key to quantifying tumor changes. We propose a conditional pyramid registration network based on unsupervised keypoint detection and selective volume-preserving to quantify changes over time. In this approach, we extract the structural and the abnormal keypoints from DCE-MRI, apply the structural keypoints for the registration algorithm to restrict large deformation, and employ volume-preserving loss based on abnormal keypoints to keep the volume of the tumor unchanged after registration. We use a clinical dataset with 1630 MRI scans from 314 patients treated with NAC. The results demonstrate that our method registers with better performance and better volume preservation of the tumors. Furthermore, a local-global-combining biomarker based on the proposed method achieves high accuracy in pathological complete response (pCR) prediction, indicating that predictive information exists outside tumor regions. The biomarkers could potentially be used to avoid unnecessary surgeries for certain patients. It may be valuable for clinicians and/or computer systems to conduct follow-up tumor segmentation and response prediction on images registered by our method. Our code is available on \\url{https://github.com/fiy2W/Treatment-aware-Longitudinal-Registration}.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09382",
        "abstract url": "https://arxiv.org/abs/2401.09382",
        "title": "POE: Acoustic Soft Robotic Proprioception for Omnidirectional End-effectors",
        "rating": "-1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "3D"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Soft robotic shape estimation and proprioception are challenging because of soft robot's complex deformation behaviors and infinite degrees of freedom. A soft robot's continuously deforming body makes it difficult to integrate rigid sensors and to reliably estimate its shape. In this work, we present Proprioceptive Omnidirectional End-effector (POE), which has six embedded microphones across the tendon-driven soft robot's surface. We first introduce novel applications of previously proposed 3D reconstruction methods to acoustic signals from the microphones for soft robot shape proprioception. To improve the proprioception pipeline's training efficiency and model prediction consistency, we present POE-M. POE-M first predicts key point positions from the acoustic signal observations with the embedded microphone array. Then we utilize an energy-minimization method to reconstruct a physically admissible high-resolution mesh of POE given the estimated key points. We evaluate the mesh reconstruction module with simulated data and the full POE-M pipeline with real-world experiments. We demonstrate that POE-M's explicit guidance of the key points during the mesh reconstruction process provides robustness and stability to the pipeline with ablation studies. POE-M reduced the maximum Chamfer distance error by 23.10 % compared to the state-of-the-art end-to-end soft robot proprioception models and achieved 4.91 mm average Chamfer distance error during evaluation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09512",
        "abstract url": "https://arxiv.org/abs/2401.09512",
        "title": "MLAAD: The Multi-Language Audio Anti-Spoofing Dataset",
        "rating": "-1",
        "keywords": [
            [
                "biometric"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Text-to-Speech (TTS) technology brings significant advantages, such as giving a voice to those with speech impairments, but also enables audio deepfakes and spoofs. The former mislead individuals and may propagate misinformation, while the latter undermine voice biometric security systems. AI-based detection can help to address these challenges by automatically differentiating between genuine and fabricated voice recordings. However, these models are only as good as their training data, which currently is severely limited due to an overwhelming concentration on English and Chinese audio in anti-spoofing databases, thus restricting its worldwide effectiveness. In response, this paper presents the Multi-Language Audio Anti-Spoof Dataset (MLAAD), created using 54 TTS models, comprising 21 different architectures, to generate 163.9 hours of synthetic voice in 23 different languages. We train and evaluate three state-of-the-art deepfake detection models with MLAAD, and observe that MLAAD demonstrates superior performance over comparable datasets like InTheWild or FakeOrReal when used as a training resource. Furthermore, in comparison with the renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary resource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately outperformed each other, both excelling on four datasets. By publishing MLAAD and making trained models accessible via an interactive webserver , we aim to democratize antispoofing technology, making it accessible beyond the realm of specialists, thus contributing to global efforts against audio spoofing and deepfakes.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "IJCNN 2024"
    },
    {
        "paper id": "2401.09517",
        "abstract url": "https://arxiv.org/abs/2401.09517",
        "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "Disease",
                "clinical"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized neuroimaging signatures for disease diagnosis, prognosis, and response to treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it has contributed to a better understanding of disease heterogeneity by identifying disease subtypes that present significant differences in various brain phenotypic measures. In this review, we first present a systematic literature overview of studies using machine learning and multimodal MRI to unravel disease heterogeneity in various neuropsychiatric and neurodegenerative disorders, including Alzheimer disease, schizophrenia, major depressive disorder, autism spectrum disorder, multiple sclerosis, as well as their potential in transdiagnostic settings. Subsequently, we summarize relevant machine learning methodologies and discuss an emerging paradigm which we call dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological heterogeneity of neuropsychiatric and neurodegenerative disorders into a low dimensional yet informative, quantitative brain phenotypic representation, serving as a robust intermediate phenotype (i.e., endophenotype) largely reflecting underlying genetics and etiology. Finally, we discuss the potential clinical implications of the current findings and envision future research avenues.",
        "subjects": [
            "cs.LG",
            "eess.IV",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09543",
        "abstract url": "https://arxiv.org/abs/2401.09543",
        "title": "Token Jumping in Planar Graphs has Linear Sized Kernels",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Let $G$ be a planar graph and $I_s$ and $I_t$ be two independent sets in $G$, each of size $k$. We begin with a ``token'' on each vertex of $I_s$ and seek to move all tokens to $I_t$, by repeated ``token jumping'', removing a single token from one vertex and placing it on another vertex. We require that each intermediate arrangement of tokens again specifies an independent set of size $k$. Given $G$, $I_s$, and $I_t$, we ask whether there exists a sequence of token jumps that transforms $I_s$ to $I_t$. When $k$ is part of the input, this problem is known to be PSPACE-complete. However, it was shown by Ito, Kami\u0144ski, and Ono to be fixed-parameter tractable. That is, when $k$ is fixed, the problem can be solved in time polynomial in the order of $G$. Here we strengthen the upper bound on the running time in terms of $k$ by showing that the problem has a kernel of size linear in $k$. More precisely, we transform an arbitrary input problem on a planar graph into an equivalent problem on a (planar) graph with order $O(k)$.",
        "subjects": [
            "cs.DM",
            "cs.CC"
        ],
        "comment": "6 pages, 1 figure"
    },
    {
        "paper id": "2401.09585",
        "abstract url": "https://arxiv.org/abs/2401.09585",
        "title": "Lower Bounds on $0$-Extension with Steiner Nodes",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In the $0$-Extension problem, we are given an edge-weighted graph $G=(V,E,c)$, a set $T\\subseteq V$ of its vertices called terminals, and a semi-metric $D$ over $T$, and the goal is to find an assignment $f$ of each non-terminal vertex to a terminal, minimizing the sum, over all edges $(u,v)\\in E$, the product of the edge weight $c(u,v)$ and the distance $D(f(u),f(v))$ between the terminals that $u,v$ are mapped to. Current best approximation algorithms on $0$-Extension are based on rounding a linear programming relaxation called the \\emph{semi-metric LP relaxation}. The integrality gap of this LP, with best upper bound $O(\\log |T|/\\log\\log |T|)$ and best lower bound $\u03a9((\\log |T|)^{2/3})$, has been shown to be closely related to the best quality of cut and flow vertex sparsifiers. We study a variant of the $0$-Extension problem where Steiner vertices are allowed. Specifically, we focus on the integrality gap of the same semi-metric LP relaxation to this new problem. Following from previous work, this new integrality gap turns out to be closely related to the quality achievable by cut/flow vertex sparsifiers with Steiner nodes, a major open problem in graph compression. Our main result is that the new integrality gap stays superconstant $\u03a9(\\log\\log |T|)$ even if we allow a super-linear $O(|T|\\log^{1-\\varepsilon}|T|)$ number of Steiner nodes.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09607",
        "abstract url": "https://arxiv.org/abs/2401.09607",
        "title": "Land Cover Image Classification",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Land Cover (LC) image classification has become increasingly significant in understanding environmental changes, urban planning, and disaster management. However, traditional LC methods are often labor-intensive and prone to human error. This paper explores state-of-the-art deep learning models for enhanced accuracy and efficiency in LC analysis. We compare convolutional neural networks (CNN) against transformer-based methods, showcasing their applications and advantages in LC studies. We used EuroSAT, a patch-based LC classification data set based on Sentinel-2 satellite images and achieved state-of-the-art results using current transformer models.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "7 pages, 4 figures, 1 table, published in conference"
    },
    {
        "paper id": "2401.09627",
        "abstract url": "https://arxiv.org/abs/2401.09627",
        "title": "SymTC: A Symbiotic Transformer-CNN Net for Instance Segmentation of Lumbar Spine MRI",
        "rating": "-1",
        "keywords": [
            [
                "diagnosing",
                "MRI",
                "disease"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Intervertebral disc disease, a prevalent ailment, frequently leads to intermittent or persistent low back pain, and diagnosing and assessing of this disease rely on accurate measurement of vertebral bone and intervertebral disc geometries from lumbar MR images. Deep neural network (DNN) models may assist clinicians with more efficient image segmentation of individual instances (disks and vertebrae) of the lumbar spine in an automated way, which is termed as instance image segmentation. In this work, we proposed SymTC, an innovative lumbar spine MR image segmentation model that combines the strengths of Transformer and Convolutional Neural Network (CNN). Specifically, we designed a parallel dual-path architecture to merge CNN layers and Transformer layers, and we integrated a novel position embedding into the self-attention module of Transformer, enhancing the utilization of positional information for more accurate segmentation. To further improves model performance, we introduced a new data augmentation technique to create synthetic yet realistic MR image dataset, named SSMSpine, which is made publicly available. We evaluated our SymTC and the other 15 existing image segmentation models on our private in-house dataset and the public SSMSpine dataset, using two metrics, Dice Similarity Coefficient and 95% Hausdorff Distance. The results show that our SymTC has the best performance for segmenting vertebral bones and intervertebral discs in lumbar spine MR images. The SymTC code and SSMSpine dataset are available at https://github.com/jiasongchen/SymTC.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09630",
        "abstract url": "https://arxiv.org/abs/2401.09630",
        "title": "CT Liver Segmentation via PVT-based Encoding and Refined Decoding",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "CT",
                "disease",
                "Tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate liver segmentation from CT scans is essential for effective diagnosis and treatment planning. Computer-aided diagnosis systems promise to improve the precision of liver disease diagnosis, disease progression, and treatment planning. In response to the need, we propose a novel deep learning approach, \\textit{\\textbf{PVTFormer}}, that is built upon a pretrained pyramid vision transformer (PVT v2) combined with advanced residual upsampling and decoder block. By integrating a refined feature channel approach with a hierarchical decoding strategy, PVTFormer generates high quality segmentation masks by enhancing semantic features. Rigorous evaluation of the proposed method on Liver Tumor Segmentation Benchmark (LiTS) 2017 demonstrates that our proposed architecture not only achieves a high dice coefficient of 86.78\\%, mIoU of 78.46\\%, but also obtains a low HD of 3.50. The results underscore PVTFormer's efficacy in setting a new benchmark for state-of-the-art liver segmentation methods. The source code of the proposed PVTFormer is available at \\url{https://github.com/DebeshJha/PVTFormer}.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09637",
        "abstract url": "https://arxiv.org/abs/2401.09637",
        "title": "Impact of Large Language Model Assistance on Patients Reading Clinical Notes: A Mixed-Methods Study",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "cancer",
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Patients derive numerous benefits from reading their clinical notes, including an increased sense of control over their health and improved understanding of their care plan. However, complex medical concepts and jargon within clinical notes hinder patient comprehension and may lead to anxiety. We developed a patient-facing tool to make clinical notes more readable, leveraging large language models (LLMs) to simplify, extract information from, and add context to notes. We prompt engineered GPT-4 to perform these augmentation tasks on real clinical notes donated by breast cancer survivors and synthetic notes generated by a clinician, a total of 12 notes with 3868 words. In June 2023, 200 female-identifying US-based participants were randomly assigned three clinical notes with varying levels of augmentations using our tool. Participants answered questions about each note, evaluating their understanding of follow-up actions and self-reported confidence. We found that augmentations were associated with a significant increase in action understanding score (0.63 $\\pm$ 0.04 for select augmentations, compared to 0.54 $\\pm$ 0.02 for the control) with p=0.002. In-depth interviews of self-identifying breast cancer patients (N=7) were also conducted via video conferencing. Augmentations, especially definitions, elicited positive responses among the seven participants, with some concerns about relying on LLMs. Augmentations were evaluated for errors by clinicians, and we found misleading errors occur, with errors more common in real donated notes than synthetic notes, illustrating the importance of carefully written clinical notes. Augmentations improve some but not all readability metrics. This work demonstrates the potential of LLMs to improve patients' experience with clinical notes at a lower burden to clinicians. However, having a human in the loop is important to correct potential model errors.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09639",
        "abstract url": "https://arxiv.org/abs/2401.09639",
        "title": "Uncertainty Modeling in Ultrasound Image Segmentation for Precise Fetal Biometric Measurements",
        "rating": "-1",
        "keywords": [
            [
                "Biometric",
                "Medical",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical image segmentation, particularly in the context of ultrasound data, is a crucial aspect of computer vision and medical imaging. This paper delves into the complexities of uncertainty in the segmentation process, focusing on fetal head and femur ultrasound images. The proposed methodology involves extracting target contours and exploring techniques for precise parameter measurement. Uncertainty modeling methods are employed to enhance the training and testing processes of the segmentation network. The study reveals that the average absolute error in fetal head circumference measurement is 8.0833mm, with a relative error of 4.7347%. Similarly, the average absolute error in fetal femur measurement is 2.6163mm, with a relative error of 6.3336%. Uncertainty modeling experiments employing Test-Time Augmentation (TTA) demonstrate effective interpretability of data uncertainty on both datasets. This suggests that incorporating data uncertainty based on the TTA method can support clinical practitioners in making informed decisions and obtaining more reliable measurement results in practical clinical applications. The paper contributes to the advancement of ultrasound image segmentation, addressing critical challenges and improving the reliability of biometric measurements.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09643",
        "abstract url": "https://arxiv.org/abs/2401.09643",
        "title": "OFDM Reference Signal Pattern Design Criteria for Integrated Communication and Sensing",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Ambiguity performance, which indicates the maximum detectable region for target parameter estimation, is critical to radar sensor design. Driven by ambiguity performance requirements of bi-static sensing, we propose design criteria for orthogonal frequency division multiplexing (OFDM) reference signal (RS) patterns. The design not only reduces ambiguities in both time delay and Doppler shift domains under different types of sensing algorithms, but also reduces resource overhead for integrated comunication and sensing. With minimal modifications of post-FFT processing for current RS patterns, guard interval is extended beyond conventional cyclic prefix (CP), while maintaining inter-symbol-interference-(ISI)-free delay estimation. For standard-resolution sensing algorithms, a staggering offset of a linear slope that is relatively prime to the RS comb size is suggested. As for high-resolution sensing algorithms, necessary and sufficient conditions of comb RS staggering offsets, plus new patterns synthesized therefrom, are derived for the corresponding achievable ambiguity performance. Furthermore, we generalize the RS pattern design criterion for high-resolution sensing algorithms to irregular forms, which minimizes number of resource elements (REs) for associated algorithms to eliminate all side peaks. Starting from staggered comb pattern in current positioning RS, our generalized design eventually removes any regular form for ultimate flexibility. Overall, the proposed techniques are promising to extend the ISI- and ambiguity-free range of distance and speed estimates for radar sensing.",
        "subjects": [
            "eess.SP",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09647",
        "abstract url": "https://arxiv.org/abs/2401.09647",
        "title": "Characterizing Online Eating Disorder Communities with Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "The rise in eating disorders, a dangerous mental health condition with high mortality and morbidity, has been linked to the proliferation of idealized body images on social media. However, the link between social media and eating disorders is far more complex. We argue that social media platforms create a feedback loop that amplifies the growth of content and communities that promote eating disorders like anorexia and bulimia. Specifically, social media platforms make it easy for vulnerable individuals to find and connect to like-minded others, while group dynamic processes encourage them to stay engaged within communities that promote and glorify harmful behaviors linked to eating disorders. We characterize this dynamic empirically through a combination of network and language analysis. We describe a novel framework that leverages large language models to analyze the discourse within online communities and probe their attitudes on topics related to eating disorders to identify potentially harmful content. Our work emphasizes the need for better social media moderation to disrupt harmful feedback loops and protect vulnerable individuals.",
        "subjects": [
            "cs.SI",
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09648",
        "abstract url": "https://arxiv.org/abs/2401.09648",
        "title": "Staggered Comb Reference Signal Design for Integrated Communication and Sensing",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Ambiguity performance is a critical criterion in radar sensor design, which indicates the ambiguities arising from multiple target estimation and detection. We considered a requirement-driven selection of OFDM reference signal (RS) patterns based on ambiguity performances for bi-static sensing in integrated communication and sensing with minimal modifications of current RSs. An RS pattern with a staggering offset of a linear slope that is relatively prime to the RS comb size is suggested for standard-resolution sensing algorithms to obtain the best ambiguity performances. Moreover, an extended guard interval design is proposed to increase the maximum time delay, that is inter-symbol interference (ISI) free using post-FFT sensing algorithms. The proposed techniques are promising to extend the distance and speed without ambiguities and ISI for sensing.",
        "subjects": [
            "eess.SP",
            "cs.NI"
        ],
        "comment": "accepted by IEEE International Symposium on Personal, Indoor and Mobile Radio Communications. arXiv admin note: substantial text overlap with arXiv:2401.09643"
    },
    {
        "paper id": "2401.09658",
        "abstract url": "https://arxiv.org/abs/2401.09658",
        "title": "An adaptive optimal control approach to monocular depth observability maximization",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "This paper presents an integral concurrent learning (ICL)-based observer for a monocular camera to accurately estimate the Euclidean distance to features on a stationary object, under the restriction that state information is unavailable. Using distance estimates, an infinite horizon optimal regulation problem is solved, which aims to regulate the camera to a goal location while maximizing feature observability. Lyapunov-based stability analysis is used to guarantee exponential convergence of depth estimates and input-to-state stability of the goal location relative to the camera. The effectiveness of the proposed approach is verified in simulation, and a table illustrating improved observability is provided.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09678",
        "abstract url": "https://arxiv.org/abs/2401.09678",
        "title": "Integrating Graceful Degradation and Recovery through Requirement-driven Adaptation",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Cyber-physical systems (CPS) are subject to environmental uncertainties such as adverse operating conditions, malicious attacks, and hardware degradation. These uncertainties may lead to failures that put the system in a sub-optimal or unsafe state. Systems that are resilient to such uncertainties rely on two types of operations: (1) graceful degradation, to ensure that the system maintains an acceptable level of safety during unexpected environmental conditions and (2) recovery, to facilitate the resumption of normal system functions. Typically, mechanisms for degradation and recovery are developed independently from each other, and later integrated into a system, requiring the designer to develop an additional, ad-hoc logic for activating and coordinating between the two operations. In this paper, we propose a self-adaptation approach for improving system resiliency through automated triggering and coordination of graceful degradation and recovery. The key idea behind our approach is to treat degradation and recovery as requirement-driven adaptation tasks: Degradation can be thought of as temporarily weakening original (i.e., ideal) system requirements to be achieved by the system, and recovery as strengthening the weakened requirements when the environment returns within an expected operating boundary. Furthermore, by treating weakening and strengthening as dual operations, we argue that a single requirement-based adaptation method is sufficient to enable coordination between degradation and recovery. Given system requirements specified in signal temporal logic (STL), we propose a run-time adaptation framework that performs degradation and recovery in response to environmental changes. We describe a prototype implementation of our framework and demonstrate the feasibility of the proposed approach using a case study in unmanned underwater vehicles.",
        "subjects": [
            "cs.SE",
            "cs.FL",
            "cs.LO",
            "eess.SY"
        ],
        "comment": "Pre-print for the SEAMS '24 conference (Software Engineering for Adaptive and Self-Managing Systems Conference)"
    },
    {
        "paper id": "2401.09699",
        "abstract url": "https://arxiv.org/abs/2401.09699",
        "title": "Curriculum Recommendations Using Transformer Base Model with InfoNCE Loss And Language Switching Method",
        "rating": "-1",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The Curriculum Recommendations paradigm is dedicated to fostering learning equality within the ever-evolving realms of educational technology and curriculum development. In acknowledging the inherent obstacles posed by existing methodologies, such as content conflicts and disruptions from language translation, this paradigm aims to confront and overcome these challenges. Notably, it addresses content conflicts and disruptions introduced by language translation, hindrances that can impede the creation of an all-encompassing and personalized learning experience. The paradigm's objective is to cultivate an educational environment that not only embraces diversity but also customizes learning experiences to suit the distinct needs of each learner. To overcome these challenges, our approach builds upon notable contributions in curriculum development and personalized learning, introducing three key innovations. These include the integration of Transformer Base Model to enhance computational efficiency, the implementation of InfoNCE Loss for accurate content-topic matching, and the adoption of a language switching strategy to alleviate translation-related ambiguities. Together, these innovations aim to collectively tackle inherent challenges and contribute to forging a more equitable and effective learning journey for a diverse range of learners. Competitive cross-validation scores underscore the efficacy of sentence-transformers/LaBSE, achieving 0.66314, showcasing our methodology's effectiveness in diverse linguistic nuances for content alignment prediction. Index Terms-Curriculum Recommendation, Transformer model with InfoNCE Loss, Language Switching.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "4pages, 2 figures, ICAICA2023"
    },
    {
        "paper id": "2401.09700",
        "abstract url": "https://arxiv.org/abs/2401.09700",
        "title": "Fully Dynamic Min-Cut of Superconstant Size in Subpolynomial Time",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We present a deterministic fully dynamic algorithm with subpolynomial worst-case time per graph update such that after processing each update of the graph, the algorithm outputs a minimum cut of the graph if the graph has a cut of size at most $c$ for some $c = (\\log n)^{o(1)}$. Previously, the best update time was $\\widetilde O(\\sqrt{n})$ for any $c > 2$ and $c = O(\\log n)$ [Thorup, Combinatorica'07].",
        "subjects": [
            "cs.DS"
        ],
        "comment": "SODA 2024"
    },
    {
        "paper id": "2401.09717",
        "abstract url": "https://arxiv.org/abs/2401.09717",
        "title": "Parameter Selection for Analyzing Conversations with Autism Spectrum Disorder",
        "rating": "-1",
        "keywords": [
            [
                "biochemical",
                "diagnosis"
            ],
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "The diagnosis of autism spectrum disorder (ASD) is a complex, challenging task as it depends on the analysis of interactional behaviors by psychologists rather than the use of biochemical diagnostics. In this paper, we present a modeling approach to ASD diagnosis by analyzing acoustic/prosodic and linguistic features extracted from diagnostic conversations between a psychologist and children who either are typically developing (TD) or have ASD. We compare the contributions of different features across a range of conversation tasks. We focus on finding a minimal set of parameters that characterize conversational behaviors of children with ASD. Because ASD is diagnosed through conversational interaction, in addition to analyzing the behavior of the children, we also investigate whether the psychologist's conversational behaviors vary across diagnostic groups. Our results can facilitate fine-grained analysis of conversation data for children with ASD to support diagnosis and intervention.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "5 pages, 4 tables, Proceedings of INTERSPEECH 2023"
    },
    {
        "paper id": "2401.10291",
        "abstract url": "https://arxiv.org/abs/2401.10291",
        "title": "Detecting Post-Stroke Aphasia Via Brain Responses to Speech in a Deep Learning Framework",
        "rating": "-1",
        "keywords": [
            [
                "time-efficient"
            ],
            [
                "support vector machine"
            ],
            [
                "diagnosis",
                "EEG",
                "clinical"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Aphasia, a language disorder primarily caused by a stroke, is traditionally diagnosed using behavioral language tests. However, these tests are time-consuming, require manual interpretation by trained clinicians, suffer from low ecological validity, and diagnosis can be biased by comorbid motor and cognitive problems present in aphasia. In this study, we introduce an automated screening tool for speech processing impairments in aphasia that relies on time-locked brain responses to speech, known as neural tracking, within a deep learning framework. We modeled electroencephalography (EEG) responses to acoustic, segmentation, and linguistic speech representations of a story using convolutional neural networks trained on a large sample of healthy participants, serving as a model for intact neural tracking of speech. Subsequently, we evaluated our models on an independent sample comprising 26 individuals with aphasia (IWA) and 22 healthy controls. Our results reveal decreased tracking of all speech representations in IWA. Utilizing a support vector machine classifier with neural tracking measures as input, we demonstrate high accuracy in aphasia detection at the individual level (85.42\\%) in a time-efficient manner (requiring 9 minutes of EEG data). Given its high robustness, time efficiency, and generalizability to unseen data, our approach holds significant promise for clinical applications.",
        "subjects": [
            "eess.SP",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Shared first authors: De Clercq & Puffay"
    },
    {
        "paper id": "2401.12993",
        "abstract url": "https://arxiv.org/abs/2401.12993",
        "title": "Estimating the severity of dental and oral problems via sentiment classification over clinical reports",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "clinical",
                "radiology"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Analyzing authors' sentiments in texts as a technique for identifying text polarity can be practical and useful in various fields, including medicine and dentistry. Currently, due to factors such as patients' limited knowledge about their condition, difficulties in accessing specialist doctors, or fear of illness, particularly in pandemic conditions, there might be a delay between receiving a radiology report and consulting a doctor. In some cases, this delay can pose significant risks to the patient, making timely decision-making crucial. Having an automatic system that can inform patients about the deterioration of their condition by analyzing the text of radiology reports could greatly impact timely decision-making. In this study, a dataset comprising 1,134 cone-beam computed tomography (CBCT) photo reports was collected from the Shiraz University of Medical Sciences. Each case was examined, and an expert labeled a severity level for the patient's condition on each document. After preprocessing all the text data, a deep learning model based on Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) network architecture, known as CNN-LSTM, was developed to detect the severity level of the patient's problem based on sentiment analysis in the radiologist's report. The model's performance was evaluated on two datasets, each with two and four classes, in both imbalanced and balanced scenarios. Finally, to demonstrate the effectiveness of our model, we compared its performance with that of other classification models. The results, along with one-way ANOVA and Tukey's test, indicated that our proposed model (CNN-LSTM) performed the best according to precision, recall, and f-measure criteria. This suggests that it can be a reliable model for estimating the severity of oral and dental diseases, thereby assisting patients.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08999",
        "abstract url": "https://arxiv.org/abs/2401.08999",
        "title": "Continuous Time Continuous Space Homeostatic Reinforcement Learning (CTCS-HRRL) : Towards Biological Self-Autonomous Agent",
        "rating": "-1.5",
        "keywords": [
            [
                "Biological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Homeostasis is a biological process by which living beings maintain their internal balance. Previous research suggests that homeostasis is a learned behaviour. Recently introduced Homeostatic Regulated Reinforcement Learning (HRRL) framework attempts to explain this learned homeostatic behavior by linking Drive Reduction Theory and Reinforcement Learning. This linkage has been proven in the discrete time-space, but not in the continuous time-space. In this work, we advance the HRRL framework to a continuous time-space environment and validate the CTCS-HRRL (Continuous Time Continuous Space HRRL) framework. We achieve this by designing a model that mimics the homeostatic mechanisms in a real-world biological agent. This model uses the Hamilton-Jacobian Bellman Equation, and function approximation based on neural networks and Reinforcement Learning. Through a simulation-based experiment we demonstrate the efficacy of this model and uncover the evidence linked to the agent's ability to dynamically choose policies that favor homeostasis in a continuously changing internal-state milieu. Results of our experiments demonstrate that agent learns homeostatic behaviour in a CTCS environment, making CTCS-HRRL a promising framework for modellng animal dynamics and decision-making.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "This work is a result of the ongoing collaboration between Cognitive Neuroscience Lab, BITS Pilani K K Birla Goa Campus and Ecole Normale Superieure, Paris France. This work is jointly supervised by Prof. Boris Gutkin and Prof. Veeky Baths. arXiv admin note: substantial text overlap with arXiv:2109.06580"
    },
    {
        "paper id": "2401.09025",
        "abstract url": "https://arxiv.org/abs/2401.09025",
        "title": "Exploring the Diversity of Music Experiences for Deaf and Hard of Hearing People",
        "rating": "-1.5",
        "keywords": [
            [
                "sign language"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Sensory substitution or enhancement techniques have been proposed to enable deaf or hard of hearing (DHH) people to listen to and even compose music. However, little is known about how such techniques enhance DHH people's music experience. Since deafness is a spectrum -- as are DHH people's preferences and perceptions of music -- a more situated understanding of their interaction with music is needed. To understand the music experience of this population, we conducted social media analyses, both qualitatively and quantitatively, in the deaf and hard of hearing Reddit communities. Our content analysis revealed that DHH people leveraged sign language and visual/haptic cues to feel the music and preferred familiar, non-lyrical, instrument-heavy, and loud music. In addition, hearing aids were not customized for music, and the visual/haptic techniques developed were not widely adopted by DHH people, leading to their suboptimal music experiences. The DHH community embodied mutual support among music lovers, evidenced by active information sharing and Q&A around music and hearing loss. We reflect on design justice for DHH people's music experience and propose practical design implications to create a more accessible music experience for them.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09034",
        "abstract url": "https://arxiv.org/abs/2401.09034",
        "title": "UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Reinforcement learning (RL) has gained traction for enhancing user long-term experiences in recommender systems by effectively exploring users' interests. However, modern recommender systems exhibit distinct user behavioral patterns among tens of millions of items, which increases the difficulty of exploration. For example, user behaviors with different activity levels require varying intensity of exploration, while previous studies often overlook this aspect and apply a uniform exploration strategy to all users, which ultimately hurts user experiences in the long run. To address these challenges, we propose User-Oriented Exploration Policy (UOEP), a novel approach facilitating fine-grained exploration among user groups. We first construct a distributional critic which allows policy optimization under varying quantile levels of cumulative reward feedbacks from users, representing user groups with varying activity levels. Guided by this critic, we devise a population of distinct actors aimed at effective and fine-grained exploration within its respective user group. To simultaneously enhance diversity and stability during the exploration process, we further introduce a population-level diversity regularization term and a supervision module. Experimental results on public recommendation datasets demonstrate that our approach outperforms all other baselines in terms of long-term performance, validating its user-oriented exploration effectiveness. Meanwhile, further analyses reveal our approach's benefits of improved performance for low-activity users as well as increased fairness among users.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09068",
        "abstract url": "https://arxiv.org/abs/2401.09068",
        "title": "DTMM: Deploying TinyML Models on Extremely Weak IoT Devices with Pruning",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "DTMM is a library designed for efficient deployment and execution of machine learning models on weak IoT devices such as microcontroller units (MCUs). The motivation for designing DTMM comes from the emerging field of tiny machine learning (TinyML), which explores extending the reach of machine learning to many low-end IoT devices to achieve ubiquitous intelligence. Due to the weak capability of embedded devices, it is necessary to compress models by pruning enough weights before deploying. Although pruning has been studied extensively on many computing platforms, two key issues with pruning methods are exacerbated on MCUs: models need to be deeply compressed without significantly compromising accuracy, and they should perform efficiently after pruning. Current solutions only achieve one of these objectives, but not both. In this paper, we find that pruned models have great potential for efficient deployment and execution on MCUs. Therefore, we propose DTMM with pruning unit selection, pre-execution pruning optimizations, runtime acceleration, and post-execution low-cost storage to fill the gap for efficient deployment and execution of pruned models. It can be integrated into commercial ML frameworks for practical deployment, and a prototype system has been developed. Extensive experiments on various models show promising gains compared to state-of-the-art methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09090",
        "abstract url": "https://arxiv.org/abs/2401.09090",
        "title": "Understanding the concerns and choices of public when using large language models for healthcare",
        "rating": "-1.5",
        "keywords": [
            [
                "biomedical",
                "medical",
                "health",
                "healthcare",
                "diagnosis"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown their potential in biomedical fields. However, how the public uses them for healthcare purposes such as medical Q\\&A, self-diagnosis, and daily healthcare information seeking is under-investigated. In this paper, we adopt a mixed-methods approach, including surveys (N=167) and interviews (N=17) to investigate how and why the public uses LLMs for healthcare. LLMs as a healthcare tool have gained popularity, and are often used in combination with other information channels such as search engines and online health communities to optimize information quality. LLMs provide more accurate information and a more convenient interaction/service model compared to traditional channels. LLMs also do a better job of reducing misinformation, especially in daily healthcare questions. Doctors using LLMs for diagnosis is less acceptable than for auxiliary work such as writing medical records. Based on the findings, we reflect on the ethical and effective use of LLMs for healthcare and propose future research directions.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2401.09093",
        "abstract url": "https://arxiv.org/abs/2401.09093",
        "title": "RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional Recurrent Neural Network (RNN) architectures, such as LSTM and GRU, have historically held prominence in time series tasks. However, they have recently seen a decline in their dominant position across various time series tasks. As a result, recent advancements in time series forecasting have seen a notable shift away from RNNs towards alternative architectures such as Transformers, MLPs, and CNNs. To go beyond the limitations of traditional RNNs, we design an efficient RNN-based model for time series tasks, named RWKV-TS, with three distinctive features: (i) A novel RNN architecture characterized by $O(L)$ time complexity and memory usage. (ii) An enhanced ability to capture long-term sequence information compared to traditional RNNs. (iii) High computational efficiency coupled with the capacity to scale up effectively. Through extensive experimentation, our proposed RWKV-TS model demonstrates competitive performance when compared to state-of-the-art Transformer-based or CNN-based models. Notably, RWKV-TS exhibits not only comparable performance but also demonstrates reduced latency and memory utilization. The success of RWKV-TS encourages further exploration and innovation in leveraging RNN-based approaches within the domain of Time Series. The combination of competitive performance, low latency, and efficient memory usage positions RWKV-TS as a promising avenue for future research in time series tasks. Code is available at:\\href{https://github.com/howard-hou/RWKV-TS}{ https://github.com/howard-hou/RWKV-TS}",
        "subjects": [
            "cs.LG"
        ],
        "comment": "13 pages. 2 figures, 14 tables"
    },
    {
        "paper id": "2401.09176",
        "abstract url": "https://arxiv.org/abs/2401.09176",
        "title": "ADCNet: a unified framework for predicting the activity of antibody-drug conjugates",
        "rating": "-1.5",
        "keywords": [
            [
                "cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Antibody-drug conjugate (ADC) has revolutionized the field of cancer treatment in the era of precision medicine due to their ability to precisely target cancer cells and release highly effective drug. Nevertheless, the realization of rational design of ADC is very difficult because the relationship between their structures and activities is difficult to understand. In the present study, we introduce a unified deep learning framework called ADCNet to help design potential ADCs. The ADCNet highly integrates the protein representation learning language model ESM-2 and small-molecule representation learning language model FG-BERT models to achieve activity prediction through learning meaningful features from antigen and antibody protein sequences of ADC, SMILES strings of linker and payload, and drug-antibody ratio (DAR) value. Based on a carefully designed and manually tailored ADC data set, extensive evaluation results reveal that ADCNet performs best on the test set compared to baseline machine learning models across all evaluation metrics. For example, it achieves an average prediction accuracy of 87.12%, a balanced accuracy of 0.8689, and an area under receiver operating characteristic curve of 0.9293 on the test set. In addition, cross-validation, ablation experiments, and external independent testing results further prove the stability, advancement, and robustness of the ADCNet architecture. For the convenience of the community, we develop the first online platform (https://ADCNet.idruglab.cn) for the prediction of ADCs activity based on the optimal ADCNet model, and the source code is publicly available at https://github.com/idrugLab/ADCNet.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09322",
        "abstract url": "https://arxiv.org/abs/2401.09322",
        "title": "FIT-SLAM -- Fisher Information and Traversability estimation-based Active SLAM for exploration in 3D environments",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "SLAM"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Active visual SLAM finds a wide array of applications in GNSS-Denied sub-terrain environments and outdoor environments for ground robots. To achieve robust localization and mapping accuracy, it is imperative to incorporate the perception considerations in the goal selection and path planning towards the goal during an exploration mission. Through this work, we propose FIT-SLAM (Fisher Information and Traversability estimation-based Active SLAM), a new exploration method tailored for unmanned ground vehicles (UGVs) to explore 3D environments. This approach is devised with the dual objectives of sustaining an efficient exploration rate while optimizing SLAM accuracy. Initially, an estimation of a global traversability map is conducted, which accounts for the environmental constraints pertaining to traversability. Subsequently, we propose a goal candidate selection approach along with a path planning method towards this goal that takes into account the information provided by the landmarks used by the SLAM backend to achieve robust localization and successful path execution . The entire algorithm is tested and evaluated first in a simulated 3D world, followed by a real-world environment and is compared to pre-existing exploration methods. The results obtained during this evaluation demonstrate a significant increase in the exploration rate while effectively minimizing the localization covariance.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "6 pages, 6 figures, IEEE ICARA 2024"
    },
    {
        "paper id": "2401.09572",
        "abstract url": "https://arxiv.org/abs/2401.09572",
        "title": "Handling Large-scale Cardinality in building recommendation systems",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Effective recommendation systems rely on capturing user preferences, often requiring incorporating numerous features such as universally unique identifiers (UUIDs) of entities. However, the exceptionally high cardinality of UUIDs poses a significant challenge in terms of model degradation and increased model size due to sparsity. This paper presents two innovative techniques to address the challenge of high cardinality in recommendation systems. Specifically, we propose a bag-of-words approach, combined with layer sharing, to substantially decrease the model size while improving performance. Our techniques were evaluated through offline and online experiments on Uber use cases, resulting in promising results demonstrating our approach's effectiveness in optimizing recommendation systems and enhancing their overall performance.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09640",
        "abstract url": "https://arxiv.org/abs/2401.09640",
        "title": "Blackout Mitigation via Physics-guided RL",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper considers the sequential design of remedial control actions in response to system anomalies for the ultimate objective of preventing blackouts. A physics-guided reinforcement learning (RL) framework is designed to identify effective sequences of real-time remedial look-ahead decisions accounting for the long-term impact on the system's stability. The paper considers a space of control actions that involve both discrete-valued transmission line-switching decisions (line reconnections and removals) and continuous-valued generator adjustments. To identify an effective blackout mitigation policy, a physics-guided approach is designed that uses power-flow sensitivity factors associated with the power transmission network to guide the RL exploration during agent training. Comprehensive empirical evaluations using the open-source Grid2Op platform demonstrate the notable advantages of incorporating physical signals into RL decisions, establishing the gains of the proposed physics-guided approach compared to its black box counterparts. One important observation is that strategically~\\emph{removing} transmission lines, in conjunction with multiple real-time generator adjustments, often renders effective long-term decisions that are likely to prevent or delay blackouts.",
        "subjects": [
            "eess.SY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09641",
        "abstract url": "https://arxiv.org/abs/2401.09641",
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "rating": "-1.5",
        "keywords": [
            [
                "fMRI",
                "EEG"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "q-bio.NC",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09680",
        "abstract url": "https://arxiv.org/abs/2401.09680",
        "title": "Tiny Multi-Agent DRL for Twins Migration in UAV Metaverses: A Multi-Leader Multi-Follower Stackelberg Game Approach",
        "rating": "-1.5",
        "keywords": [
            [
                "UAV",
                "drone"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The synergy between Unmanned Aerial Vehicles (UAVs) and metaverses is giving rise to an emerging paradigm named UAV metaverses, which create a unified ecosystem that blends physical and virtual spaces, transforming drone interaction and virtual exploration. UAV Twins (UTs), as the digital twins of UAVs that revolutionize UAV applications by making them more immersive, realistic, and informative, are deployed and updated on ground base stations, e.g., RoadSide Units (RSUs), to offer metaverse services for UAV Metaverse Users (UMUs). Due to the dynamic mobility of UAVs and limited communication coverages of RSUs, it is essential to perform real-time UT migration to ensure seamless immersive experiences for UMUs. However, selecting appropriate RSUs and optimizing the required bandwidth is challenging for achieving reliable and efficient UT migration. To address the challenges, we propose a tiny machine learning-based Stackelberg game framework based on pruning techniques for efficient UT migration in UAV metaverses. Specifically, we formulate a multi-leader multi-follower Stackelberg model considering a new immersion metric of UMUs in the utilities of UAVs. Then, we design a Tiny Multi-Agent Deep Reinforcement Learning (Tiny MADRL) algorithm to obtain the tiny networks representing the optimal game solution. Specifically, the actor-critic network leverages the pruning techniques to reduce the number of network parameters and achieve model size and computation reduction, allowing for efficient implementation of Tiny MADRL. Numerical results demonstrate that our proposed schemes have better performance than traditional schemes.",
        "subjects": [
            "cs.AI",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09682",
        "abstract url": "https://arxiv.org/abs/2401.09682",
        "title": "Comparative Study on the Performance of Categorical Variable Encoders in Classification and Regression Tasks",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosis",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Categorical variables often appear in datasets for classification and regression tasks, and they need to be encoded into numerical values before training. Since many encoders have been developed and can significantly impact performance, choosing the appropriate encoder for a task becomes a time-consuming yet important practical issue. This study broadly classifies machine learning models into three categories: 1) ATI models that implicitly perform affine transformations on inputs, such as multi-layer perceptron neural network; 2) Tree-based models that are based on decision trees, such as random forest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot encoder is the best choice for ATI models in the sense that it can mimic any other encoders by learning suitable weights from the data. We also explain why the target encoder and its variants are the most suitable encoders for tree-based models. This study conducted comprehensive computational experiments to evaluate 14 encoders, including one-hot and target encoders, along with eight common machine-learning models on 28 datasets. The computational results agree with our theoretical analysis. The findings in this study shed light on how to select the suitable encoder for data scientists in fields such as fraud detection, disease diagnosis, etc.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.10293",
        "abstract url": "https://arxiv.org/abs/2401.10293",
        "title": "Symmetry breaking in geometric quantum machine learning in the presence of noise",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Geometric quantum machine learning based on equivariant quantum neural networks (EQNN) recently appeared as a promising direction in quantum machine learning. Despite the encouraging progress, the studies are still limited to theory, and the role of hardware noise in EQNN training has never been explored. This work studies the behavior of EQNN models in the presence of noise. We show that certain EQNN models can preserve equivariance under Pauli channels, while this is not possible under the amplitude damping channel. We claim that the symmetry breaking grows linearly in the number of layers and noise strength. We support our claims with numerical data from simulations as well as hardware up to 64 qubits. Furthermore, we provide strategies to enhance the symmetry protection of EQNN models in the presence of noise.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "12 pages, 10 figures. supplementary material 7 pages, 6 figures"
    },
    {
        "paper id": "2401.08982",
        "abstract url": "https://arxiv.org/abs/2401.08982",
        "title": "Robot Tape Manipulation for 3D Printing",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "3D printing has enabled various applications using different forms of materials, such as filaments, sheets, and inks. Typically, during 3D printing, feedstocks are transformed into discrete building blocks and placed or deposited in a designated location similar to the manipulation and assembly of discrete objects. However, 3D printing of continuous and flexible tape (with the geometry between filaments and sheets) without breaking or transformation remains underexplored and challenging. Here, we report the design and implementation of a customized end-effector, i.e., tape print module (TPM), to realize robot tape manipulation for 3D printing by leveraging the tension formed on the tape between two endpoints. We showcase the feasibility of manufacturing representative 2D and 3D structures while utilizing conductive copper tape for various electronic applications, such as circuits and sensors. We believe this manipulation strategy could unlock the potential of other tape materials for manufacturing, including packaging tape and carbon fiber prepreg tape, and inspire new mechanisms for robot manipulation, 3D printing, and packaging.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08987",
        "abstract url": "https://arxiv.org/abs/2401.08987",
        "title": "The Quantum Cryptography Approach: Unleashing the Potential of Quantum Key Reconciliation Protocol for Secure Communication",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum cryptography is the study of delivering secret communications across a quantum channel. Recently, Quantum Key Distribution (QKD) has been recognized as the most important breakthrough in quantum cryptography. This process facilitates two distant parties to share secure communications based on physical laws. The BB84 protocol was developed in 1984 and remains the most widely used among BB92, Ekert91, COW, and SARG04 protocols. However the practical security of QKD with imperfect devices have been widely discussed, and there are many ways to guarantee that generated key by QKD still provides unconditional security. This paper proposed a novel method that allows users to communicate while generating the secure keys as well as securing the transmission without any leakage of the data. In this approach sender will never reveal her basis, hence neither the receiver nor the intruder will get knowledge of the fundamental basis.Further to detect Eve, polynomial interpolation is also used as a key verification technique. In order to fully utilize the quantum computing capabilities provided by IBM quantum computers, the protocol is executed using the Qiskit backend for 45 qubits. This article discusses a plot of % error against alpha (strength of eavesdropping). As a result, different types of noise have been included, and the success probability of the desired key bits has been determined. Furthermore, the success probability under depolarizing noise is explained for different qubit counts.Last but not least, even when the applied noise is increased to maximum capacity, a 50% probability of successful key generation is still observed in an experiment.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08994",
        "abstract url": "https://arxiv.org/abs/2401.08994",
        "title": "Understanding and Facilitating Mental Health Help-Seeking of Young Adults: A Socio-technical Ecosystem Framework",
        "rating": "-2",
        "keywords": [
            [
                "Health"
            ]
        ],
        "abstract": "Prior research on young adults' mental health help-seeking mostly focuses on one particular resource such as a mobile app or digital platform, paying less attention to their lived experiences interacting with the ecosystem of resources. We conducted in-depth interviews with 18 participants about their help-seeking and non-help-seeking experiences. Guided by Social Ecological Theory, we proposed a Socio-technical Ecosystem Framework for mental health care, consisting of four levels of resources, including technological-, interpersonal-, community-, and societal level resources. Using this framework, we identified two types of support systems for help-seeking, single-resource support system and multi-resource support system. These resources support young adults' help-seeking via three mechanisms, \\textit{care-giving}, \\textit{care-mediating}, and \\textit{care-outreaching}, forming various pathways to care. We then pointed out the barriers to resource use at each level and the general challenges in finding a support system. Our findings contributed to a conceptual framework to categorize mental health care. It also serves as a practical framework to identify challenges in the pathways to care and discover design implications.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09027",
        "abstract url": "https://arxiv.org/abs/2401.09027",
        "title": "Exact Homomorphic Encryption",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Inspired by the concept of fault tolerance quantum computation, this article proposes a framework dubbed Exact Homomorphic Encryption, EHE, enabling exact computations on encrypted data without the need for pre-decryption. The introduction of quantum gates is a critical step for constructing the message encryption and the computation encryption within the framework. Of significance is that both encryptions are respectively accomplished in a multivariate polynomial set generated by quantum gates. Two fundamental traits of quantum gates, the invertibility and the noncommutativity, establish the success of EHE. The encrypted computation is exact because its encryption transformation is conducted with invertible gates. In the same vein, decryptions for both an encrypted message and encrypted computation are exact. The second trait of noncommutativity among applied quantum gates brings forth the security for the two encryptions. Toward the message encryption, a plaintext is encoded into a ciphertext via a polynomial set generated by a product of noncommuting gates randomly chosen. In the computation encryption, a desired operation is encoded into an encrypted polynomial set generated by another product of noncommuting gates. The encrypted computation is then the evaluation of the encrypted polynomial set on the ciphertext and is referred to as the cryptovaluation. EHE is not only attainable on quantum computers, but also straightforwardly realizable on traditional computing environments. Surpassing the standard security 2^128 of quantum resilience, both the encryptions further reach a security greater than the suggested threshold 2^1024 and are characterized as hyper quantum-resilient. Thanks to the two essential traits of quantum gates, this framework can be regarded as the initial tangible manifestation of the concept noncommutative cryptography.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09038",
        "abstract url": "https://arxiv.org/abs/2401.09038",
        "title": "Visual Robotic Manipulation with Depth-Aware Pretraining",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "Robotics"
            ]
        ],
        "abstract": "Recent work on visual representation learning has shown to be efficient for robotic manipulation tasks. However, most existing works pretrained the visual backbone solely on 2D images or egocentric videos, ignoring the fact that robots learn to act in 3D space, which is hard to learn from 2D observation. In this paper, we examine the effectiveness of pretraining for vision backbone with public-available large-scale 3D data to improve manipulation policy learning. Our method, namely Depth-aware Pretraining for Robotics (DPR), enables an RGB-only backbone to learn 3D scene representations from self-supervised contrastive learning, where depth information serves as auxiliary knowledge. No 3D information is necessary during manipulation policy learning and inference, making our model enjoy both efficiency and effectiveness in 3D space manipulation. Furthermore, we introduce a new way to inject robots' proprioception into the policy networks that makes the manipulation model robust and generalizable. We demonstrate in experiments that our proposed framework improves performance on unseen objects and visual environments for various robotics tasks on both simulated and real robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "submitted to ICRA2024"
    },
    {
        "paper id": "2401.09050",
        "abstract url": "https://arxiv.org/abs/2401.09050",
        "title": "Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Score distillation sampling (SDS) and its variants have greatly boosted the development of text-to-3D generation, but are vulnerable to geometry collapse and poor textures yet. To solve this issue, we first deeply analyze the SDS and find that its distillation sampling process indeed corresponds to the trajectory sampling of a stochastic differential equation (SDE): SDS samples along an SDE trajectory to yield a less noisy sample which then serves as a guidance to optimize a 3D model. However, the randomness in SDE sampling often leads to a diverse and unpredictable sample which is not always less noisy, and thus is not a consistently correct guidance, explaining the vulnerability of SDS. Since for any SDE, there always exists an ordinary differential equation (ODE) whose trajectory sampling can deterministically and consistently converge to the desired target point as the SDE, we propose a novel and effective \"Consistent3D\" method that explores the ODE deterministic sampling prior for text-to-3D generation. Specifically, at each training iteration, given a rendered image by a 3D model, we first estimate its desired 3D score function by a pre-trained 2D diffusion model, and build an ODE for trajectory sampling. Next, we design a consistency distillation sampling loss which samples along the ODE trajectory to generate two adjacent samples and uses the less noisy sample to guide another more noisy one for distilling the deterministic prior into the 3D model. Experimental results show the efficacy of our Consistent3D in generating high-fidelity and diverse 3D objects and large-scale scenes, as shown in Fig. 1. The codes are available at https://github.com/sail-sg/Consistent3D.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09076",
        "abstract url": "https://arxiv.org/abs/2401.09076",
        "title": "Benchmarking quantum computer simulation software packages",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Rapid advances in quantum computing technology lead to an increasing need for software simulators that enable both algorithm design and the validation of results obtained from quantum hardware. This includes calculations that aim at probing regimes of quantum advantage, where a quantum computer outperforms a classical computer in the same task. High performance computing (HPC) platforms play a crucial role as today's quantum devices already reach beyond the limits of what powerful workstations can model, but a systematic evaluation of the individual performance of the many offered simulation packages is lacking so far. In this Technical Review, we benchmark several software packages capable of simulating quantum dynamics with a special focus on HPC capabilities. We develop a containerized toolchain for benchmarking a large set of simulation packages on a local HPC cluster using different parallelisation capabilities, and compare the performance and system size-scaling for three paradigmatic quantum computing tasks. Our results can help finding the right package for a given simulation task and lay the foundation for a systematic community effort to benchmark and validate upcoming versions of existing and also newly developed simulation packages.",
        "subjects": [
            "quant-ph",
            "cs.ET",
            "physics.comp-ph"
        ],
        "comment": "18 pages, 10 figures, 3 tables; for online data exploration of the benchmarking results see https://qucos.qchub.ch"
    },
    {
        "paper id": "2401.09084",
        "abstract url": "https://arxiv.org/abs/2401.09084",
        "title": "UniVG: Towards UNIfied-modal Video Generation",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion based video generation has received extensive attention and achieved considerable success within both the academic and industrial communities. However, current efforts are mainly concentrated on single-objective or single-task video generation, such as generation driven by text, by image, or by a combination of text and image. This cannot fully meet the needs of real-world application scenarios, as users are likely to input images and text conditions in a flexible manner, either individually or in combination. To address this, we propose a Unified-modal Video Genearation system that is capable of handling multiple video generation tasks across text and image modalities. To this end, we revisit the various video generation tasks within our system from the perspective of generative freedom, and classify them into high-freedom and low-freedom video generation categories. For high-freedom video generation, we employ Multi-condition Cross Attention to generate videos that align with the semantics of the input images or text. For low-freedom video generation, we introduce Biased Gaussian Noise to replace the pure random Gaussian Noise, which helps to better preserve the content of the input conditions. Our method achieves the lowest Fr\u00e9chet Video Distance (FVD) on the public academic benchmark MSR-VTT, surpasses the current open-source methods in human evaluations, and is on par with the current close-source method Gen2. For more samples, visit https://univg-baidu.github.io.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09177",
        "abstract url": "https://arxiv.org/abs/2401.09177",
        "title": "Performance Analysis and Optimisation of FFR-Aided OFDMA Networks using Channel-Aware Scheduling",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Modern cellular standards typically incorporate interference coordination schemes allowing near universal frequency reuse while preserving reasonably high spectral efficiencies over the whole coverage area. In particular, fractional frequency reuse (FFR) and its variants are deemed to play a fundamental role in the next generation of cellular deployments (B4G/5G systems). This paper presents an analytical framework allowing the downlink performance evaluation of FFR-aided OFDMA networks when using channel-aware scheduling policies. Remarkably, the framework contemplates the use of different rate allocation strategies, thus allowing to assess the network behaviour under ideal (capacity-based) or realistic (throughput-based) conditions. Analytical performance results are used to optimise the FFR parameters as a function of, for instance, the resource block scheduling policy or the density of UEs per cell. Furthermore, different optimisation designs of the FFR component are proposed that allow a tradeoff between throughput performance and fairness by suitably dimensioning the FFR-defined cell-centre and cell-edge areas and the corresponding frequency allocation to each region. Numerical results serve to confirm the accuracy of the proposed analytical model while providing insight on how the different parameters and designs affect network performance.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09178",
        "abstract url": "https://arxiv.org/abs/2401.09178",
        "title": "The Stationary Wavelet Transform as an Efficient Reductor of Powerline Interference for Atrial Bipolar Electrograms in Cardiac Electrophysiology",
        "rating": "-2",
        "keywords": [
            [
                "clinical",
                "Cardiac"
            ]
        ],
        "abstract": "Objective: The most relevant source of signal contamination in the cardiac electrophysiology (EP) laboratory is the ubiquitous powerline interference (PLI). To reduce this perturbation, algorithms including common fixed bandwidth and adaptive notch filters have been proposed. Although such methods have proven to add artificial fractionation to intra atrial electrograms (EGMs), they are still frequently used. However, such morphological alteration can conceal the accurate interpretation of EGMs, specially to evaluate the mechanisms supporting atrial fibrillation (AF), which is the most common cardiac arrhythmia. Given the clinical relevance of AF, a novel algorithm aimed at reducing PLI on highly contaminated bipolar EGMs and, simultaneously, preserving their morphology is proposed. Approach: The method is based on the wavelet shrinkage and has been validated through customized indices on a set of synthesized EGMs to accurately quantify the achieved level of PLI reduction and signal morphology alteration. Visual validation of the algorithms performance has also been included for some real EGM excerpts. Main results: The method has outperformed common filtering-based and wavelet based strategies in the analyzed scenario. Moreover, it possesses advantages such as insensitivity to amplitude and frequency variations in the PLI, and the capability of joint removal of several interferences. Significance: The use of this algorithm in routine cardiac EP studies may enable improved and truthful evaluation of AF mechanisms.",
        "subjects": [
            "physics.med-ph",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09185",
        "abstract url": "https://arxiv.org/abs/2401.09185",
        "title": "Behavior Trees with Dataflow: Coordinating Reactive Tasks in Lingua Franca",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Behavior Trees (BTs) provide a lean set of control flow elements that are easily composable in a modular tree structure. They are well established for modeling the high-level behavior of non-player characters in computer games and recently gained popularity in other areas such as industrial automation. While BTs nicely express control, data handling aspects so far must be provided separately, e. g. in the form of blackboards. This may hamper reusability and can be a source of nondeterminism. We here present a dataflow extension to BTs that explicitly models data relations and communication. We provide a combined textual/graphical approach in line with modern, productivity-enhancing pragmatics-aware modeling techniques. We realized and validated that approach in the recently introduced polyglot coordination language Lingua Franca (LF).",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09216",
        "abstract url": "https://arxiv.org/abs/2401.09216",
        "title": "Algebraic solution of project scheduling problems with temporal constraints",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "New solutions for problems in optimal scheduling of activities in a project under temporal constraints are developed in the framework of tropical algebra, which deals with the theory and application of algebraic systems with idempotent operations. We start with a constrained tropical optimization problem that has an objective function represented as a vector form given by an arbitrary matrix, and that can be solved analytically in a closed but somewhat complicated form. We examine a special case of the problem when the objective function is given by a matrix of unit rank, and show that the solution can be sufficiently refined in this case, which results in an essentially simplified analytical form and reduced computational complexity of the solution. We exploit the obtained result to find complete solutions of project scheduling problems to minimize the project makespan and the maximum absolute deviation of start times of activities under temporal constraints. The constraint under consideration include ``start-start'', ``start-finish'' and ``finish-start'' precedence relations, release times, release deadlines and completion deadlines for activities. As an application, we consider optimal scheduling problems of a vaccination project in a medical centre.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2401.09283",
        "abstract url": "https://arxiv.org/abs/2401.09283",
        "title": "A gradient-based approach to fast and accurate head motion compensation in cone-beam CT",
        "rating": "-2",
        "keywords": [
            [
                "voxel"
            ],
            [
                "medical",
                "CT",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cone-beam computed tomography (CBCT) systems, with their portability, present a promising avenue for direct point-of-care medical imaging, particularly in critical scenarios such as acute stroke assessment. However, the integration of CBCT into clinical workflows faces challenges, primarily linked to long scan duration resulting in patient motion during scanning and leading to image quality degradation in the reconstructed volumes. This paper introduces a novel approach to CBCT motion estimation using a gradient-based optimization algorithm, which leverages generalized derivatives of the backprojection operator for cone-beam CT geometries. Building on that, a fully differentiable target function is formulated which grades the quality of the current motion estimate in reconstruction space. We drastically accelerate motion estimation yielding a 19-fold speed-up compared to existing methods. Additionally, we investigate the architecture of networks used for quality metric regression and propose predicting voxel-wise quality maps, favoring autoencoder-like architectures over contracting ones. This modification improves gradient flow, leading to more accurate motion estimation. The presented method is evaluated through realistic experiments on head anatomy. It achieves a reduction in reprojection error from an initial average of 3mm to 0.61mm after motion compensation and consistently demonstrates superior performance compared to existing approaches. The analytic Jacobian for the backprojection operation, which is at the core of the proposed method, is made publicly available. In summary, this paper contributes to the advancement of CBCT integration into clinical workflows by proposing a robust motion estimation approach that enhances efficiency and accuracy, addressing critical challenges in time-sensitive scenarios.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2401.09284",
        "abstract url": "https://arxiv.org/abs/2401.09284",
        "title": "A Fast Control Plane for a Large-Scale and High-Speed Optical Circuit Switch System",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "We experimentally verify a fast control plane with 100 microseconds of configuration time that can support more than 1000 racks, leveraged by a software-defined network controller and an industrial real-time Ethernet standard EtherCAT.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2401.09297",
        "abstract url": "https://arxiv.org/abs/2401.09297",
        "title": "Spectral Distribution Complexity of the Surface Fibrillatory Waves Predicts Post-Catheter Ablation Relapse in Persistent Atrial Fibrillation",
        "rating": "-2",
        "keywords": [
            [
                "cardiac"
            ]
        ],
        "abstract": "As for most of cardiac arrhythmias, atrial fibrillation (AF) is primarily treated by catheter ablation (CA). However, the mid-term recurrence rate of this procedure in persistent AF patients is still limited and the preoperative prediction of its outcome is clinically interesting to select candidates who could benefit the most from the intervention. This context encouraged the study of C0 complexity as a novel predictor, because it estimates organization of the power spectral distribution (PSD) of the fibrillatory waves (f-waves). For that purpose, the PSD was divided into two divergent components using a threshold, theta, which was considered by multiplying the mean value of the PSD by a factor, alpha, ranging between 1.5 and 2.5. On a database of 74 patients, the values of C0 complexity computed for all alpha factors reported statistically significant differences between the patients who maintained sinus rhythm and those who relapsed to AF after a follow-up of 9 months. They also showed higher values of sensitivity (Se), specificity (Sp), and accuracy (Acc) than the well known predictors of the dominant frequency (DF) and f-wave amplitude. Moreover, the combination of the DF and the C0 complexity computed with alpha = 2, via a decision tree, improved classification until values of Se, Sp and Acc of 75.33, 77.33 and 76.58%, respectively. These results manifests the relevance of the f-wave PSD distribution to anticipate CA outcome in persistent AF patients.",
        "subjects": [
            "eess.SP",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09323",
        "abstract url": "https://arxiv.org/abs/2401.09323",
        "title": "BENO: Boundary-embedded Neural Operators for Elliptic PDEs",
        "rating": "-2",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Elliptic partial differential equations (PDEs) are a major class of time-independent PDEs that play a key role in many scientific and engineering domains such as fluid dynamics, plasma physics, and solid mechanics. Recently, neural operators have emerged as a promising technique to solve elliptic PDEs more efficiently by directly mapping the input to solutions. However, existing networks typically cannot handle complex geometries and inhomogeneous boundary values present in the real world. Here we introduce Boundary-Embedded Neural Operators (BENO), a novel neural operator architecture that embeds the complex geometries and inhomogeneous boundary values into the solving of elliptic PDEs. Inspired by classical Green's function, BENO consists of two branches of Graph Neural Networks (GNNs) for interior source term and boundary values, respectively. Furthermore, a Transformer encoder maps the global boundary geometry into a latent vector which influences each message passing layer of the GNNs. We test our model extensively in elliptic PDEs with various boundary conditions. We show that all existing baseline methods fail to learn the solution operator. In contrast, our model, endowed with boundary-embedded architecture, outperforms state-of-the-art neural operators and strong baselines by an average of 60.96\\%. Our source code can be found https://github.com/AI4Science-WestlakeU/beno.git.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by ICLR 2024"
    },
    {
        "paper id": "2401.09324",
        "abstract url": "https://arxiv.org/abs/2401.09324",
        "title": "Establishing Awareness through Pointing Gestures during Collaborative Decision-Making in a Wall-Display Environment",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "Sharing a physical environment, such as that of a wall-display, facilitates gaining awareness of others' actions and intentions, thereby bringing benefits for collaboration. Previous studies have provided first insights on awareness in the context of tabletops or smaller vertical displays. This paper seeks to advance the current understanding on how users share awareness information in wall-display environments and focusses on mid-air pointing gestures as a foundational part of communication. We present a scenario dealing with the organization of medical supply chains in crisis situations, and report on the results of a user study with 24 users, split into 6 groups of 4, performing several tasks. We investigate pointing gestures and identify three subtypes used as awareness cues during face-to-face collaboration: narrative pointing, loose pointing, and sharp pointing. Our observations show that reliance on gesture subtypes varies across participants and groups, and that sometimes vague pointing is sufficient to support verbal negotiations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "\\c{opyright} Authors | ACM 2023. This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in the CHI'23 proceedings, http://dx.doi.org/10.1145/3544549.3585830"
    },
    {
        "paper id": "2401.09325",
        "abstract url": "https://arxiv.org/abs/2401.09325",
        "title": "Siamese Meets Diffusion Network: SMDNet for Enhanced Change Detection in High-Resolution RS Imagery",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, the application of deep learning to change detection (CD) has significantly progressed in remote sensing images. In recent years, CD tasks have mostly used architectures such as CNN and Transformer to identify these changes. However, these architectures have shortcomings in representing boundary details and are prone to false alarms and missed detections under complex lighting and weather conditions. For that, we propose a new network, Siamese Meets Diffusion Network (SMDNet). This network combines the Siam-U2Net Feature Differential Encoder (SU-FDE) and the denoising diffusion implicit model to improve the accuracy of image edge change detection and enhance the model's robustness under environmental changes. First, we propose an innovative SU-FDE module that utilizes shared weight features to capture differences between time series images and identify similarities between features to enhance edge detail detection. Furthermore, we add an attention mechanism to identify key coarse features to improve the model's sensitivity and accuracy. Finally, the diffusion model of progressive sampling is used to fuse key coarse features, and the noise reduction ability of the diffusion model and the advantages of capturing the probability distribution of image data are used to enhance the adaptability of the model in different environments. Our method's combination of feature extraction and diffusion models demonstrates effectiveness in change detection in remote sensing images. The performance evaluation of SMDNet on LEVIR-CD, DSIFN-CD, and CDD datasets yields validated F1 scores of 90.99%, 88.40%, and 88.47%, respectively. This substantiates the advanced capabilities of our model in accurately identifying variations and intricate details.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 4 figures"
    },
    {
        "paper id": "2401.09375",
        "abstract url": "https://arxiv.org/abs/2401.09375",
        "title": "Self-navigation in crowds: An invariant set-based approach",
        "rating": "-2",
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Self-navigation in non-coordinating crowded environments is formidably challenging within multi-agent systems consisting of non-holonomic robots operating through local sensing. Our primary objective is the development of a novel, rapid, sensor-driven, self-navigation controller that directly computes control commands to enable safe maneuvering while coexisting with other agents. We propose an input-constrained feedback controller meticulously crafted for non-holonomic mobile robots and the characterization of associated invariant sets. The invariant sets are the key to maintaining stability and safety amidst the non-cooperating agents. We then propose a planning strategy that strategically guides the generation of invariant sets toward the agent's intended target. This enables the agents to directly compute theoretically safe control inputs without explicitly requiring pre-planned paths/trajectories to reliably navigate through crowded multi-agent environments. The practicality of our technique is demonstrated through hardware experiments, and the ability to parallelize computations to shorten computational durations for synthesizing safe control commands. The proposed approach finds potential applications in crowded multi-agent scenarios that require rapid control computations based on perceived safety bounds during run-time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09378",
        "abstract url": "https://arxiv.org/abs/2401.09378",
        "title": "A Novel Approach to Fair Power Allocation for NOMA in Visible Light Communication",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "This paper addresses the growing demand for high-bandwidth wireless data transmission by exploring Visible Light Communication (VLC) as an alternative to Radio Frequency (RF) communication. In indoor scenarios, VLC systems utilize existing lighting infrastructure for high-speed data transmission. To meet the data rate demands of 5G and beyond, the paper proposes Non-Orthogonal Multiple Access (NOMA) and introduces Empirical Fair Optical Power Allocation (EFOPA) to simplify resource allocation in NOMA. EFOPA integrates NOMA with VLC, utilizing the Artificial Bee Colony (ABC) optimization algorithm for offline resource allocation planning. The approach then derives a simplified power allocation equation from ABC outcomes, ensuring fair resource distribution among users. EFOPA is compared against existing power allocation methods, demonstrating superior fairness and reduced computational complexity. Numerical evaluations reveal EFOPA consistently outperforms other methods across various channel conditions, making it a robust and efficient solution for fair power allocation in NOMA-VLC systems.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09383",
        "abstract url": "https://arxiv.org/abs/2401.09383",
        "title": "Synthesizing Hardware-Software Leakage Contracts for RISC-V Open-Source Processors",
        "rating": "-2",
        "keywords": [
            [
                "Synthesizing"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Microarchitectural attacks compromise security by exploiting software-visible artifacts of microarchitectural optimizations such as caches and speculative execution. Defending against such attacks at the software level requires an appropriate abstraction at the instruction set architecture (ISA) level that captures microarchitectural leakage. Hardware-software leakage contracts have recently been proposed as such an abstraction. In this paper, we propose a semi-automatic methodology for synthesizing hardware-software leakage contracts for open-source microarchitectures. For a given ISA, our approach relies on human experts to (a) capture the space of possible contracts in the form of contract templates and (b) devise a test-case generation strategy to explore a microarchitecture's potential leakage. For a given implementation of an ISA, these two ingredients are then used to automatically synthesize the most precise leakage contract that is satisfied by the microarchitecture. We have instantiated this methodology for the RISC-V ISA and applied it to the Ibex and CVA6 open-source processors. Our experiments demonstrate the practical applicability of the methodology and uncover subtle and unexpected leaks.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09384",
        "abstract url": "https://arxiv.org/abs/2401.09384",
        "title": "Diverse Part Synthesis for 3D Shape Creation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Synthesis"
            ],
            [
                "graph"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Methods that use neural networks for synthesizing 3D shapes in the form of a part-based representation have been introduced over the last few years. These methods represent shapes as a graph or hierarchy of parts and enable a variety of applications such as shape sampling and reconstruction. However, current methods do not allow easily regenerating individual shape parts according to user preferences. In this paper, we investigate techniques that allow the user to generate multiple, diverse suggestions for individual parts. Specifically, we experiment with multimodal deep generative models that allow sampling diverse suggestions for shape parts and focus on models which have not been considered in previous work on shape synthesis. To provide a comparative study of these techniques, we introduce a method for synthesizing 3D shapes in a part-based representation and evaluate all the part suggestion techniques within this synthesis method. In our method, which is inspired by previous work, shapes are represented as a set of parts in the form of implicit functions which are then positioned in space to form the final shape. Synthesis in this representation is enabled by a neural network architecture based on an implicit decoder and a spatial transformer. We compare the various multimodal generative models by evaluating their performance in generating part suggestions. Our contribution is to show with qualitative and quantitative evaluations which of the new techniques for multimodal part generation perform the best and that a synthesis method based on the top-performing techniques allows the user to more finely control the parts that are generated in the 3D shapes while maintaining high shape fidelity when reconstructing shapes.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09386",
        "abstract url": "https://arxiv.org/abs/2401.09386",
        "title": "Tri$^{2}$-plane: Volumetric Avatar Reconstruction with Feature Pyramid",
        "rating": "-2",
        "keywords": [
            [
                "Avatar"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent years have witnessed considerable achievements in facial avatar reconstruction with neural volume rendering. Despite notable advancements, the reconstruction of complex and dynamic head movements from monocular videos still suffers from capturing and restoring fine-grained details. In this work, we propose a novel approach, named Tri$^2$-plane, for monocular photo-realistic volumetric head avatar reconstructions. Distinct from the existing works that rely on a single tri-plane deformation field for dynamic facial modeling, the proposed Tri$^2$-plane leverages the principle of feature pyramids and three top-to-down lateral connections tri-planes for details improvement. It samples and renders facial details at multiple scales, transitioning from the entire face to specific local regions and then to even more refined sub-regions. Moreover, we incorporate a camera-based geometry-aware sliding window method as an augmentation in training, which improves the robustness beyond the canonical space, with a particular improvement in cross-identity generation capabilities. Experimental outcomes indicate that the Tri$^2$-plane not only surpasses existing methodologies but also achieves superior performance across both quantitative metrics and qualitative assessments through experiments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2401.09387",
        "abstract url": "https://arxiv.org/abs/2401.09387",
        "title": "A Multi-Agent Security Testbed for the Analysis of Attacks and Defenses in Collaborative Sensor Fusion",
        "rating": "-2",
        "keywords": [
            [
                "Robot"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "The performance and safety of autonomous vehicles (AVs) deteriorates under adverse environments and adversarial actors. The investment in multi-sensor, multi-agent (MSMA) AVs is meant to promote improved efficiency of travel and mitigate safety risks. Unfortunately, minimal investment has been made to develop security-aware MSMA sensor fusion pipelines leaving them vulnerable to adversaries. To advance security analysis of AVs, we develop the Multi-Agent Security Testbed, MAST, in the Robot Operating System (ROS2). Our framework is scalable for general AV scenarios and is integrated with recent multi-agent datasets. We construct the first bridge between AVstack and ROS and develop automated AV pipeline builds to enable rapid AV prototyping. We tackle the challenge of deploying variable numbers of agent/adversary nodes at launch-time with dynamic topic remapping. Using this testbed, we motivate the need for security-aware AV architectures by exposing the vulnerability of centralized multi-agent fusion pipelines to (un)coordinated adversary models in case studies and Monte Carlo analysis.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09388",
        "abstract url": "https://arxiv.org/abs/2401.09388",
        "title": "CognitiveDog: Large Multimodal Model Based System to Translate Vision and Language into Action of Quadruped Robot",
        "rating": "-2",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "This paper introduces CognitiveDog, a pioneering development of quadruped robot with Large Multi-modal Model (LMM) that is capable of not only communicating with humans verbally but also physically interacting with the environment through object manipulation. The system was realized on Unitree Go1 robot-dog equipped with a custom gripper and demonstrated autonomous decision-making capabilities, independently determining the most appropriate actions and interactions with various objects to fulfill user-defined tasks. These tasks do not necessarily include direct instructions, challenging the robot to comprehend and execute them based on natural language input and environmental cues. The paper delves into the intricacies of this system, dataset characteristics, and the software architecture. Key to this development is the robot's proficiency in navigating space using Visual-SLAM, effectively manipulating and transporting objects, and providing insightful natural language commentary during task execution. Experimental results highlight the robot's advanced task comprehension and adaptability, underscoring its potential in real-world applications. The dataset used to fine-tune the robot-dog behavior generation model is provided at the following link: huggingface.co/datasets/ArtemLykov/CognitiveDog_dataset",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been accepted for publication at the HRI2024 conference"
    },
    {
        "paper id": "2401.09508",
        "abstract url": "https://arxiv.org/abs/2401.09508",
        "title": "4D-ONIX: A deep learning approach for reconstructing 3D movies from sparse X-ray projections",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "X-ray"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The X-ray flux provided by X-ray free-electron lasers and storage rings offers new spatiotemporal possibilities to study in-situ and operando dynamics, even using single pulses of such facilities. X-ray Multi-Projection Imaging (XMPI) is a novel technique that enables volumetric information using single pulses of such facilities and avoids centrifugal forces induced by state-of-the-art time-resolved 3D methods such as time-resolved tomography. As a result, XMPI can acquire 3D movies (4D) at least three orders of magnitude faster than current methods. However, it is exceptionally challenging to reconstruct 4D from highly sparse projections as acquired by XMPI with current algorithms. Here, we present 4D-ONIX, a Deep Learning (DL)-based approach that learns to reconstruct 3D movies (4D) from an extremely limited number of projections. It combines the computational physical model of X-ray interaction with matter and state-of-the-art DL methods. We demonstrate the potential of 4D-ONIX to generate high-quality 4D by generalizing over multiple experiments with only two projections per timestamp for binary droplet collisions. We envision that 4D-ONIX will become an enabling tool for 4D analysis, offering new spatiotemporal resolutions to study processes not possible before.",
        "subjects": [
            "eess.IV",
            "physics.data-an"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09520",
        "abstract url": "https://arxiv.org/abs/2401.09520",
        "title": "Port-Hamiltonian Neural ODE Networks on Lie Groups For Robot Dynamics Learning and Control",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Accurate models of robot dynamics are critical for safe and stable control and generalization to novel operational conditions. Hand-designed models, however, may be insufficiently accurate, even after careful parameter tuning. This motivates the use of machine learning techniques to approximate the robot dynamics over a training set of state-control trajectories. The dynamics of many robots are described in terms of their generalized coordinates on a matrix Lie group, e.g. on SE(3) for ground, aerial, and underwater vehicles, and generalized velocity, and satisfy conservation of energy principles. This paper proposes a (port-)Hamiltonian formulation over a Lie group of the structure of a neural ordinary differential equation (ODE) network to approximate the robot dynamics. In contrast to a black-box ODE network, our formulation guarantees energy conservation principle and Lie group's constraints by construction and explicitly accounts for energy-dissipation effect such as friction and drag forces in the dynamics model. We develop energy shaping and damping injection control for the learned, potentially under-actuated Hamiltonian dynamics to enable a unified approach for stabilization and trajectory tracking with various robot platforms.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Journal submission with 18 pages, 13 figures. Website: https://thaipduong.github.io/LieGroupHamDL/."
    },
    {
        "paper id": "2401.09521",
        "abstract url": "https://arxiv.org/abs/2401.09521",
        "title": "Experimental Implementation of A Quantum Zero-Knowledge Proof for User Authentication",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "A new interactive quantum zero-knowledge protocol for identity authentication implementable in currently available quantum cryptographic devices is proposed and demonstrated. The protocol design involves a verifier and a prover knowing a pre-shared secret, and the acceptance or rejection of the proof is determined by the quantum bit error rate. It has been implemented in modified Quantum Key Distribution devices executing two fundamental cases. In the first case, all players are honest, while in the second case, one of the users is a malicious player. We demonstrate an increase of the quantum bit error rate around 25% in the latter case compared to the case of honesty. The protocol has also been validated for distances from a back-to-back setup to more than 60 km between verifier and prover. The security and robustness of the protocol has been analysed, demonstrating its completeness, soundness and zero-knowledge properties.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09552",
        "abstract url": "https://arxiv.org/abs/2401.09552",
        "title": "Centralized active reconfigurable intelligent surface: Architecture, path loss analysis and experimental verification",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Reconfigurable intelligent surfaces (RISs) are promising candidate for the 6G communication. Recently, active RIS has been proposed to compensate the multiplicative fading effect inherent in passive RISs. However, conventional distributed active RISs, with at least one amplifier per element, are costly, complex, and power-intensive. To address these challenges, this paper proposes a novel architecture of active RIS: the centralized active RIS (CA-RIS), which amplifies the energy using a centralized amplifying reflector to reduce the number of amplifiers. Under this architecture, only as low as one amplifier is needed for power amplification of the entire array, which can eliminate the mutual-coupling effect among amplifiers, and significantly reduce the cost, noise level, and power consumption. We evaluate the performance of CA-RIS, specifically its path loss, and compare it with conventional passive RISs, revealing a moderate amplification gain. Furthermore, the proposed CA-RIS and the path loss model are experimentally verified, achieving a 9.6 dB net gain over passive RIS at 4 GHz. The CA-RIS offers a substantial simplification of active RIS architecture while preserving performance, striking an optimal balance between system complexity and the performance, which is competitive in various scenarios.",
        "subjects": [
            "physics.app-ph",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09575",
        "abstract url": "https://arxiv.org/abs/2401.09575",
        "title": "Zero Trust Implementation in the Emerging Technologies Era: Survey",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "This paper presents a comprehensive analysis of the shift from the traditional perimeter model of security to the Zero Trust (ZT) framework, emphasizing the key points in the transition and the practical application of ZT. It outlines the differences between ZT policies and legacy security policies, along with the significant events that have impacted the evolution of ZT. Additionally, the paper explores the potential impacts of emerging technologies, such as Artificial Intelligence (AI) and quantum computing, on the policy and implementation of ZT. The study thoroughly examines how AI can enhance ZT by utilizing Machine Learning (ML) algorithms to analyze patterns, detect anomalies, and predict threats, thereby improving real-time decision-making processes. Furthermore, the paper demonstrates how a chaos theory-based approach, in conjunction with other technologies like eXtended Detection and Response (XDR), can effectively mitigate cyberattacks. As quantum computing presents new challenges to ZT and cybersecurity as a whole, the paper delves into the intricacies of ZT migration, automation, and orchestration, addressing the complexities associated with these aspects. Finally, the paper provides a best practice approach for the seamless implementation of ZT in organizations, laying out the proposed guidelines to facilitate organizations in their transition towards a more secure ZT model. The study aims to support organizations in successfully implementing ZT and enhancing their cybersecurity measures.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "15 pages, 3 figures"
    },
    {
        "paper id": "2401.09595",
        "abstract url": "https://arxiv.org/abs/2401.09595",
        "title": "Modulating Retroreflector-based Satellite-to-Ground Optical Communications: Sensing and Positioning",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "This paper focuses on the optimal design of a modulated retroreflector (MRR) laser link to establish a high-speed downlink for cube satellites (CubeSats), taking into account the weight and power limitations commonly encountered by these tiny satellites. To this end, first, a comprehensive channel modeling is conducted considering key real channel parameters including mechanical gimbal error, fast steering mirror angle error, laser beamwidth, MRR area, atmospheric turbulence, and channel coherence time. Accordingly, a closed-form expression for the distribution of the received signal is derived and utilized to propose a maximum likelihood based method to sense and estimate the initial position of the satellite. Subsequently, the distribution of the distance estimation error during the sensing phase is formulated as a function of the laser beamwidth and the gimbal error, which enables us to fine-tune the optimal laser beamwidth to minimize sensing time. Moreover, using the sensing and initial satellite distance estimation, two positioning algorithms are proposed. To compare the performance of the proposed positioning method, we obtain the lower bound of the positioning error as a benchmark. Finally, by providing comprehensive simulations, we evaluate the effect of different parameters on the performance of the considered MRR-based system in both the sensing and positioning phases.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09600",
        "abstract url": "https://arxiv.org/abs/2401.09600",
        "title": "Statistical Analysis and Optimization of a Fifth-Percentile User Rate Constrained Design for FFR/SFR-Aided OFDMA-Based Cellular Networks",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Interference mitigation strategies are deemed to play a key role in the context of the next generation (B4G/5G) of multicellular networks based on orthogonal frequency division multiple access. Fractional and soft frequency reuse (FFR, SFR) constitute two powerful mechanisms for intercell interference coordination that have been already adopted by emerging cellular deployments as an efficient way to improve the throughput performance perceived by cell-edge users. This paper presents a novel optimal fifth-percentile user rate constrained design for FFR/SFR-based networks that, by appropriately dimensioning the center and edge regions of the cell, rightly splitting the available bandwidth among these two areas while assigning the corresponding transmit power, allows a tradeoff between cell throughput performance and fairness to be established. To this end, both the cumulative distribution function of the user throughput and the average spectral efficiency of the system are derived assuming the use of the ubiquitous proportional fair scheduling policy. The mathematical framework is then used to obtain numerical results showing that the novel proposed design clearly outperforms previous schemes in terms of throughput fairness control due to a more rational compromise between average cell throughput and cell-edge ICIC.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09638",
        "abstract url": "https://arxiv.org/abs/2401.09638",
        "title": "Automatic 3D Multi-modal Ultrasound Segmentation of Human Placenta using Fusion Strategies and Deep Learning",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "diagnosis",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Purpose: Ultrasound is the most commonly used medical imaging modality for diagnosis and screening in clinical practice. Due to its safety profile, noninvasive nature and portability, ultrasound is the primary imaging modality for fetal assessment in pregnancy. Current ultrasound processing methods are either manual or semi-automatic and are therefore laborious, time-consuming and prone to errors, and automation would go a long way in addressing these challenges. Automated identification of placental changes at earlier gestation could facilitate potential therapies for conditions such as fetal growth restriction and pre-eclampsia that are currently detected only at late gestational age, potentially preventing perinatal morbidity and mortality. Methods: We propose an automatic three-dimensional multi-modal (B-mode and power Doppler) ultrasound segmentation of the human placenta using deep learning combined with different fusion strategies.We collected data containing Bmode and power Doppler ultrasound scans for 400 studies. Results: We evaluated different fusion strategies and state-of-the-art image segmentation networks for placenta segmentation based on standard overlap- and boundary-based metrics. We found that multimodal information in the form of B-mode and power Doppler scans outperform any single modality. Furthermore, we found that B-mode and power Doppler input scans fused at the data level provide the best results with a mean Dice Similarity Coefficient (DSC) of 0.849. Conclusion: We conclude that the multi-modal approach of combining B-mode and power Doppler scans is effective in segmenting the placenta from 3D ultrasound scans in a fully automated manner and is robust to quality variation of the datasets.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09650",
        "abstract url": "https://arxiv.org/abs/2401.09650",
        "title": "The role of shared randomness in quantum state certification with unentangled measurements",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Given $n$ copies of an unknown quantum state $\u03c1\\in\\mathbb{C}^{d\\times d}$, quantum state certification is the task of determining whether $\u03c1=\u03c1_0$ or $\\|\u03c1-\u03c1_0\\|_1>\\varepsilon$, where $\u03c1_0$ is a known reference state. We study quantum state certification using unentangled quantum measurements, namely measurements which operate only on one copy of $\u03c1$ at a time. When there is a common source of shared randomness available and the unentangled measurements are chosen based on this randomness, prior work has shown that $\u0398(d^{3/2}/\\varepsilon^2)$ copies are necessary and sufficient. This holds even when the measurements are allowed to be chosen adaptively. We consider deterministic measurement schemes (as opposed to randomized) and demonstrate that $\u0398(d^2/\\varepsilon^2)$ copies are necessary and sufficient for state certification. This shows a separation between algorithms with and without shared randomness. We develop a unified lower bound framework for both fixed and randomized measurements, under the same theoretical framework that relates the hardness of testing to the well-established L\u00fcders rule. More precisely, we obtain lower bounds for randomized and fixed schemes as a function of the eigenvalues of the L\u00fcders channel which characterizes one possible post-measurement state transformation.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.IT"
        ],
        "comment": "29 pages, 2 tables. Comments welcome"
    },
    {
        "paper id": "2401.09677",
        "abstract url": "https://arxiv.org/abs/2401.09677",
        "title": "Eye Motion Matters for 3D Face Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in single-image 3D face reconstruction have shown remarkable progress in various applications. Nevertheless, prevailing techniques tend to prioritize the global facial contour and expression, often neglecting the nuanced dynamics of the eye region. In response, we introduce an Eye Landmark Adjustment Module, complemented by a Local Dynamic Loss, designed to capture the dynamic features of the eyes area. Our module allows for flexible adjustment of landmarks, resulting in accurate recreation of various eye states. In this paper, we present a comprehensive evaluation of our approach, conducting extensive experiments on two datasets. The results underscore the superior performance of our approach, highlighting its significant contributions in addressing this particular challenge.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2401.09209",
        "abstract url": "https://arxiv.org/abs/2401.09209",
        "title": "Username Squatting on Online Social Networks: A Study on X",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "recommendation"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Adversaries have been targeting unique identifiers to launch typo-squatting, mobile app squatting and even voice squatting attacks. Anecdotal evidence suggest that online social networks (OSNs) are also plagued with accounts that use similar usernames. This can be confusing to users but can also be exploited by adversaries. However, to date no study characterizes this problem on OSNs. In this work, we define the username squatting problem and design the first multi-faceted measurement study to characterize it on X. We develop a username generation tool (UsernameCrazy) to help us analyze hundreds of thousands of username variants derived from celebrity accounts. Our study reveals that thousands of squatted usernames have been suspended by X, while tens of thousands that still exist on the network are likely bots. Out of these, a large number share similar profile pictures and profile names to the original account signalling impersonation attempts. We found that squatted accounts are being mentioned by mistake in tweets hundreds of thousands of times and are even being prioritized in searches by the network's search recommendation algorithm exacerbating the negative impact squatted accounts can have in OSNs. We use our insights and take the first step to address this issue by designing a framework (SQUAD) that combines UsernameCrazy with a new classifier to efficiently detect suspicious squatted accounts. Our evaluation of SQUAD's prototype implementation shows that it can achieve 94% F1-score when trained on a small dataset.",
        "subjects": [
            "cs.CR",
            "cs.SI"
        ],
        "comment": "Accepted at the 19th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2024)"
    },
    {
        "paper id": "2401.09261",
        "abstract url": "https://arxiv.org/abs/2401.09261",
        "title": "MSHyper: Multi-Scale Hypergraph Transformer for Long-Range Time Series Forecasting",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Demystifying interactions between temporal patterns of different scales is fundamental to precise long-range time series forecasting. However, previous works lack the ability to model high-order interactions. To promote more comprehensive pattern interaction modeling for long-range time series forecasting, we propose a Multi-Scale Hypergraph Transformer (MSHyper) framework. Specifically, a multi-scale hypergraph is introduced to provide foundations for modeling high-order pattern interactions. Then by treating hyperedges as nodes, we also build a hyperedge graph to enhance hypergraph modeling. In addition, a tri-stage message passing mechanism is introduced to aggregate pattern information and learn the interaction strength between temporal patterns of different scales. Extensive experiments on five real-world datasets demonstrate that MSHyper achieves state-of-the-art performance, reducing prediction errors by an average of 8.73% and 7.15% over the best baseline in MSE and MAE, respectively.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2401.09393",
        "abstract url": "https://arxiv.org/abs/2401.09393",
        "title": "\u00c9liv\u00e1gar: Efficient Quantum Circuit Search for Classification",
        "rating": "-2.5",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Designing performant and noise-robust circuits for Quantum Machine Learning (QML) is challenging -- the design space scales exponentially with circuit size, and there are few well-supported guiding principles for QML circuit design. Although recent Quantum Circuit Search (QCS) methods attempt to search for performant QML circuits that are also robust to hardware noise, they directly adopt designs from classical Neural Architecture Search (NAS) that are misaligned with the unique constraints of quantum hardware, resulting in high search overheads and severe performance bottlenecks. We present \u00c9liv\u00e1gar, a novel resource-efficient, noise-guided QCS framework. \u00c9liv\u00e1gar innovates in all three major aspects of QCS -- search space, search algorithm and candidate evaluation strategy -- to address the design flaws in current classically-inspired QCS methods. \u00c9liv\u00e1gar achieves hardware-efficiency and avoids an expensive circuit-mapping co-search via noise- and device topology-aware candidate generation. By introducing two cheap-to-compute predictors, Clifford noise resilience and Representational capacity, \u00c9liv\u00e1gar decouples the evaluation of noise robustness and performance, enabling early rejection of low-fidelity circuits and reducing circuit evaluation costs. Due to its resource-efficiency, \u00c9liv\u00e1gar can further search for data embeddings, significantly improving performance. Based on a comprehensive evaluation of \u00c9liv\u00e1gar on 12 real quantum devices and 9 QML applications, \u00c9liv\u00e1gar achieves 5.3% higher accuracy and a 271$\\times$ speedup compared to state-of-the-art QCS methods.",
        "subjects": [
            "quant-ph",
            "cs.AR",
            "cs.LG"
        ],
        "comment": "13 pages, 11 figures. To appear in ASPLOS 2024"
    },
    {
        "paper id": "2401.09498",
        "abstract url": "https://arxiv.org/abs/2401.09498",
        "title": "Technical Report: On the Convergence of Gossip Learning in the Presence of Node Inaccessibility",
        "rating": "-2.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Gossip learning (GL), as a decentralized alternative to federated learning (FL), is more suitable for resource-constrained wireless networks, such as Flying Ad-Hoc Networks (FANETs) that are formed by unmanned aerial vehicles (UAVs). GL can significantly enhance the efficiency and extend the battery life of UAV networks. Despite the advantages, the performance of GL is strongly affected by data distribution, communication speed, and network connectivity. However, how these factors influence the GL convergence is still unclear. Existing work studied the convergence of GL based on a virtual quantity for the sake of convenience, which failed to reflect the real state of the network when some nodes are inaccessible. In this paper, we formulate and investigate the impact of inaccessible nodes to GL under a dynamic network topology. We first decompose the weight divergence by whether the node is accessible or not. Then, we investigate the GL convergence under the dynamic of node accessibility and theoretically provide how the number of inaccessible nodes, data non-i.i.d.-ness, and duration of inaccessibility affect the convergence. Extensive experiments are carried out in practical settings to comprehensively verify the correctness of our theoretical findings.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09693",
        "abstract url": "https://arxiv.org/abs/2401.09693",
        "title": "EfficientRec an unlimited user-item scale recommendation system based on clustering and users interaction embedding profile",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial",
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recommendation systems are highly interested in technology companies nowadays. The businesses are constantly growing users and products, causing the number of users and items to continuously increase over time, to very large numbers. Traditional recommendation algorithms with complexity dependent on the number of users and items make them difficult to adapt to the industrial environment. In this paper, we introduce a new method applying graph neural networks with a contrastive learning framework in extracting user preferences. We incorporate a soft clustering architecture that significantly reduces the computational cost of the inference process. Experiments show that the model is able to learn user preferences with low computational cost in both training and prediction phases. At the same time, the model gives a very good accuracy. We call this architecture EfficientRec with the implication of model compactness and the ability to scale to unlimited users and products.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Published in 14th Asian Conference on Intelligent Information and Database Systems (ACIIDS), 2022"
    },
    {
        "paper id": "2401.10155",
        "abstract url": "https://arxiv.org/abs/2401.10155",
        "title": "A novel hybrid time-varying graph neural network for traffic flow forecasting",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Real-time and accurate traffic flow prediction is the foundation for ensuring the efficient operation of intelligent transportation systems.In existing traffic flow prediction methods based on graph neural networks (GNNs), pre-defined graphs were usually used to describe the spatial correlations of different traffic nodes in urban road networks. However, the ability of pre-defined graphs used to describe spatial correlation was limited by prior knowledge and graph generation methods. Although time-varying graphs based on data-driven learning can partially overcome the drawbacks of pre-defined graphs, the learning ability of existing adaptive graphs was limited. For example, time-varying graphs cannot adequately capture the inherent spatial correlations in traffic flow data.In order to solve these problems, we have proposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow prediction.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages 1figures"
    },
    {
        "paper id": "2401.10942",
        "abstract url": "https://arxiv.org/abs/2401.10942",
        "title": "Machine Unlearning for Recommendation Systems: An Insight",
        "rating": "-2.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This review explores machine unlearning (MUL) in recommendation systems, addressing adaptability, personalization, privacy, and bias challenges. Unlike traditional models, MUL dynamically adjusts system knowledge based on shifts in user preferences and ethical considerations. The paper critically examines MUL's basics, real-world applications, and challenges like algorithmic transparency. It sifts through literature, offering insights into how MUL could transform recommendations, discussing user trust, and suggesting paths for future research in responsible and user-focused artificial intelligence (AI). The document guides researchers through challenges involving the trade-off between personalization and privacy, encouraging contributions to meet practical demands for targeted data removal. Emphasizing MUL's role in secure and adaptive machine learning, the paper proposes ways to push its boundaries. The novelty of this paper lies in its exploration of the limitations of the methods, which highlights exciting prospects for advancing the field.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "In Proceedings of 7th INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION 2024 (https://icicc-conf.com/)"
    },
    {
        "paper id": "2401.13695",
        "abstract url": "https://arxiv.org/abs/2401.13695",
        "title": "Inverse analysis of granular flows using differentiable graph neural network simulator",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Inverse problems in granular flows, such as landslides and debris flows, involve estimating material parameters or boundary conditions based on target runout profile. Traditional high-fidelity simulators for these inverse problems are computationally demanding, restricting the number of simulations possible. Additionally, their non-differentiable nature makes gradient-based optimization methods, known for their efficiency in high-dimensional problems, inapplicable. While machine learning-based surrogate models offer computational efficiency and differentiability, they often struggle to generalize beyond their training data due to their reliance on low-dimensional input-output mappings that fail to capture the complete physics of granular flows. We propose a novel differentiable graph neural network simulator (GNS) by combining reverse mode automatic differentiation of graph neural networks with gradient-based optimization for solving inverse problems. GNS learns the dynamics of granular flow by representing the system as a graph and predicts the evolution of the graph at the next time step, given the current state. The differentiable GNS shows optimization capabilities beyond the training data. We demonstrate the effectiveness of our method for inverse estimation across single and multi-parameter optimization problems, including evaluating material properties and boundary conditions for a target runout distance and designing baffle locations to limit a landslide runout. Our proposed differentiable GNS framework offers an orders of magnitude faster solution to these inverse problems than the conventional finite difference approach to gradient-based optimization.",
        "subjects": [
            "physics.geo-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08998",
        "abstract url": "https://arxiv.org/abs/2401.08998",
        "title": "Attack and Reset for Unlearning: Exploiting Adversarial Noise toward Machine Unlearning through Parameter Re-initialization",
        "rating": "-3",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "Attack"
            ],
            [
                "facial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With growing concerns surrounding privacy and regulatory compliance, the concept of machine unlearning has gained prominence, aiming to selectively forget or erase specific learned information from a trained model. In response to this critical need, we introduce a novel approach called Attack-and-Reset for Unlearning (ARU). This algorithm leverages meticulously crafted adversarial noise to generate a parameter mask, effectively resetting certain parameters and rendering them unlearnable. ARU outperforms current state-of-the-art results on two facial machine-unlearning benchmark datasets, MUFAC and MUCAC. In particular, we present the steps involved in attacking and masking that strategically filter and re-initialize network parameters biased towards the forget set. Our work represents a significant advancement in rendering data unexploitable to deep learning models through parameter re-initialization, achieved by harnessing adversarial noise to craft a mask.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09013",
        "abstract url": "https://arxiv.org/abs/2401.09013",
        "title": "An Improved Virtual Force Approach for UAV Deployment and Resource Allocation in Emergency Communications",
        "rating": "-3",
        "keywords": [
            [
                "vehicle",
                "flight"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this paper, we consider an unmanned aerial vehicle (UAV)-enabled emergency communication system, which establishes temporary communication link with users equipment (UEs) in a typical disaster environment with mountainous forest and obstacles. Towards this end, a joint deployment, power allocation, and user association optimization problem is formulated to maximize the total transmission rate, while considering the demand of each UE and the disaster environment characteristics. Then, an alternating optimization algorithm is proposed by integrating coalition game and virtual force approach which captures the impact of the demand priority of UEs and the obstacles to the flight path and consumed power. Simulation results demonstrate that the computation time consumed by our proposed algorithm is only $5.6\\%$ of the traditional heuristic algorithms, which validates its effectiveness in disaster scenarios.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09059",
        "abstract url": "https://arxiv.org/abs/2401.09059",
        "title": "Autonomous Catheterization with Open-source Simulator and Expert Trajectory",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Endovascular robots have been actively developed in both academia and industry. However, progress toward autonomous catheterization is often hampered by the widespread use of closed-source simulators and physical phantoms. Additionally, the acquisition of large-scale datasets for training machine learning algorithms with endovascular robots is usually infeasible due to expensive medical procedures. In this chapter, we introduce CathSim, the first open-source simulator for endovascular intervention to address these limitations. CathSim emphasizes real-time performance to enable rapid development and testing of learning algorithms. We validate CathSim against the real robot and show that our simulator can successfully mimic the behavior of the real robot. Based on CathSim, we develop a multimodal expert navigation network and demonstrate its effectiveness in downstream endovascular navigation tasks. The intensive experimental results suggest that CathSim has the potential to significantly accelerate research in the autonomous catheterization field. Our project is publicly available at https://github.com/airvlab/cathsim.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Code: https://github.com/airvlab/cathsim"
    },
    {
        "paper id": "2401.09127",
        "abstract url": "https://arxiv.org/abs/2401.09127",
        "title": "AI Empowered Channel Semantic Acquisition for 6G Integrated Sensing and Communication Networks",
        "rating": "-3",
        "keywords": [
            [
                "radar"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "Motivated by the need for increased spectral efficiency and the proliferation of intelligent applications, the sixth-generation (6G) mobile network is anticipated to integrate the dual-functions of communication and sensing (C&S). Although the millimeter wave (mmWave) communication and mmWave radar share similar multiple-input multiple-output (MIMO) architecture for integration, the full potential of dual-function synergy remains to be exploited. In this paper, we commence by overviewing state-of-the-art schemes from the aspects of waveform design and signal processing. Nevertheless, these approaches face the dilemma of mutual compromise between C&S performance. To this end, we reveal and exploit the synergy between C&S. In the proposed framework, we introduce a two-stage frame structure and resort artificial intelligence (AI) to achieve the synergistic gain by designing a joint C&S channel semantic extraction and reconstruction network (JCASCasterNet). With just a cost-effective and energy-efficient single sensing antenna, the proposed scheme achieves enhanced overall performance while requiring only limited pilot and feedback signaling overhead. In the end, we outline the challenges that lie ahead in the future development of integrated sensing and communication networks, along with promising directions for further research.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "9 pages, 5 figures, accepted by the IEEE journal"
    },
    {
        "paper id": "2401.09132",
        "abstract url": "https://arxiv.org/abs/2401.09132",
        "title": "Admittance Controller Complemented with Real-time Singularity Avoidance for Rehabilitation Parallel Robots",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Rehabilitation tasks demand robust and accurate trajectory-tracking performance, mainly achieved with parallel robots. In this field, limiting the value of the force exerted on the patient is crucial, especially when an injured limb is involved. In human-robot interaction studies, the admittance controller modifies the location of the robot according to the user efforts driving the end-effector to an arbitrary location within the workspace. However, a parallel robot has singularities within the workspace, making implementing a conventional admittance controller unsafe. Thus, this study proposes an admittance controller that overcomes the limitations of singular configurations by using a real-time singularity avoidance algorithm. The singularity avoidance algorithm modifies the original trajectory based on the actual location of the parallel robot. The complemented admittance controller is applied to a 4 degrees of freedom parallel robot for knee rehabilitation. In this case, the actual location is measured by a 3D tracking system because the location calculated by the forward kinematics is inaccurate in the vicinity of a singularity. The experimental results verify the effectiveness of the proposed admittance controller for safe knee rehabilitation exercises",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09285",
        "abstract url": "https://arxiv.org/abs/2401.09285",
        "title": "Enhancing Rural Agricultural Value Chains through Electric Mobility Services in Ethiopia",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Agricultural"
            ]
        ],
        "abstract": "Transportation is a constitutional part of most supply and value chains in modern economies. Smallholder farmers in rural Ethiopia face severe challenges along their supply and value chains. In particular, suitable, affordable, and available transport services are in high demand. To develop context-specific technical solutions, a problem-to-solution methodology based on the interaction with technology is developed. With this approach, we fill the gap between proven transportation assessment frameworks and general user-centered techniques. Central to our approach is an electric test vehicle that is implemented in rural supply and value chains for research, development, and testing. Based on our objective and the derived methodological requirements, a set of existing methods is selected. Local partners are integrated in an organizational framework that executes major parts of this research endeavour in Arsi Zone, Oromia Region, Ethiopia.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09358",
        "abstract url": "https://arxiv.org/abs/2401.09358",
        "title": "Detection of Distributed Denial of Service Attacks Carried Out by Botnets in Software-Defined Networks",
        "rating": "-3",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Recent years witnessed a surge in network traffic due to the emergence of new online services, causing periodic saturation and complexity problems. Additionally, the growing number of IoT devices further compounds the problem. Software Defined Network (SDN) is a new architecture which offers innovative advantages that help to reduce saturation problems. Despite its benefits, SDNs not only can be affected by traditional attacks but also introduce new security challenges. In this context, Distributed Denial of Service (DDoS) is one of the most important attacks that can damage an SDN network's normal operation. Furthermore, if these attacks are executed using botnets, they can use thousands of compromised devices to disrupt critical online services. This paper proposes a framework for detecting DDoS attacks generated by a group of botnets in an SDN network. The framework is implemented using open-source tools such as Mininet and OpenDaylight and tested in a centralized network topology using BYOB and SNORT. The results demonstrate real-time attack identification by implementing an intrusion detection mechanism in the victim client. Our proposed solution offers quick and effective detection of DDoS attacks in SDN networks. The framework can successfully differentiate the type of attack with high accuracy in a short time",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09416",
        "abstract url": "https://arxiv.org/abs/2401.09416",
        "title": "TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "Synthesis"
            ],
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present TextureDreamer, a novel image-guided texture synthesis method to transfer relightable textures from a small number of input images (3 to 5) to target 3D shapes across arbitrary categories. Texture creation is a pivotal challenge in vision and graphics. Industrial companies hire experienced artists to manually craft textures for 3D assets. Classical methods require densely sampled views and accurately aligned geometry, while learning-based methods are confined to category-specific shapes within the dataset. In contrast, TextureDreamer can transfer highly detailed, intricate textures from real-world environments to arbitrary objects with only a few casually captured images, potentially significantly democratizing texture creation. Our core idea, personalized geometry-aware score distillation (PGSD), draws inspiration from recent advancements in diffuse models, including personalized modeling for texture information extraction, variational score distillation for detailed appearance synthesis, and explicit geometry guidance with ControlNet. Our integration and several essential modifications substantially improve the texture quality. Experiments on real images spanning different categories show that TextureDreamer can successfully transfer highly realistic, semantic meaningful texture to arbitrary objects, surpassing the visual quality of previous state-of-the-art.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project page: https://texturedreamer.github.io"
    },
    {
        "paper id": "2401.09624",
        "abstract url": "https://arxiv.org/abs/2401.09624",
        "title": "MITS-GAN: Safeguarding Medical Imaging from Tampering with Generative Adversarial Networks",
        "rating": "-3",
        "keywords": [
            [
                "GAN"
            ],
            [
                "attacks"
            ],
            [
                "Medical",
                "CT"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The progress in generative models, particularly Generative Adversarial Networks (GANs), opened new possibilities for image generation but raised concerns about potential malicious uses, especially in sensitive areas like medical imaging. This study introduces MITS-GAN, a novel approach to prevent tampering in medical images, with a specific focus on CT scans. The approach disrupts the output of the attacker's CT-GAN architecture by introducing imperceptible but yet precise perturbations. Specifically, the proposed approach involves the introduction of appropriate Gaussian noise to the input as a protective measure against various attacks. Our method aims to enhance tamper resistance, comparing favorably to existing techniques. Experimental results on a CT scan dataset demonstrate MITS-GAN's superior performance, emphasizing its ability to generate tamper-resistant images with negligible artifacts. As image tampering in medical domains poses life-threatening risks, our proactive approach contributes to the responsible and ethical use of generative models. This work provides a foundation for future research in countering cyber threats in medical imaging. Models and codes are publicly available at the following link \\url{https://iplab.dmi.unict.it/MITS-GAN-2024/}.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09705",
        "abstract url": "https://arxiv.org/abs/2401.09705",
        "title": "Learning Hybrid Policies for MPC with Application to Drone Flight in Unknown Dynamic Environments",
        "rating": "-3",
        "keywords": [
            [
                "Flight"
            ],
            [
                "Drone"
            ]
        ],
        "abstract": "In recent years, drones have found increased applications in a wide array of real-world tasks. Model predictive control (MPC) has emerged as a practical method for drone flight control, owing to its robustness against modeling errors/uncertainties and external disturbances. However, MPC's sensitivity to manually tuned parameters can lead to rapid performance degradation when faced with unknown environmental dynamics. This paper addresses the challenge of controlling a drone as it traverses a swinging gate characterized by unknown dynamics. This paper introduces a parameterized MPC approach named hyMPC that leverages high-level decision variables to adapt to uncertain environmental conditions. To derive these decision variables, a novel policy search framework aimed at training a high-level Gaussian policy is presented. Subsequently, we harness the power of neural network policies, trained on data gathered through the repeated execution of the Gaussian policy, to provide real-time decision variables. The effectiveness of hyMPC is validated through numerical simulations, achieving a 100\\% success rate in 20 drone flight tests traversing a swinging gate, demonstrating its capability to achieve safe and precise flight with limited prior knowledge of environmental dynamics.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "To be published in Unmanned Systems"
    },
    {
        "paper id": "2403.12970",
        "abstract url": "https://arxiv.org/abs/2403.12970",
        "title": "Hybrid deep learning and physics-based neural network for programmable illumination computational microscopy",
        "rating": "-3",
        "keywords": [
            [
                "biological"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Relying on either deep models or physical models are two mainstream approaches for solving inverse sample reconstruction problems in programmable illumination computational microscopy. Solutions based on physical models possess strong generalization capabilities while struggling with global optimization of inverse problems due to a lack of insufficient physical constraints. In contrast, deep learning methods have strong problem-solving abilities, but their generalization ability is often questioned because of the unclear physical principles. Besides, conventional deep models are difficult to apply to some specific scenes because of the difficulty in acquiring high-quality training data and their limited capacity to generalize across different scenarios. In this paper, to combine the advantages of deep models and physical models together, we propose a hybrid framework consisting of three sub-neural networks (two deep learning networks and one physics-based network). We first obtain a result with rich semantic information through a light deep learning neural network and then use it as the initial value of the physical network to make its output comply with physical process constraints. These two results are then used as the input of a fusion deep learning neural work which utilizes the paired features between the reconstruction results of two different models to further enhance imaging quality. The final result integrates the advantages of both deep models and physical models and can quickly solve the computational reconstruction inverse problem in programmable illumination computational microscopy and achieve better results. We verified the feasibility and effectiveness of the proposed hybrid framework with theoretical analysis and actual experiments on resolution targets and biological samples.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.bio-ph",
            "physics.optics"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08984",
        "abstract url": "https://arxiv.org/abs/2401.08984",
        "title": "A GAN-based data poisoning framework against anomaly detection in vertical federated learning",
        "rating": "-3.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "federated learning"
            ],
            [
                "anomaly detection"
            ],
            [
                "attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In vertical federated learning (VFL), commercial entities collaboratively train a model while preserving data privacy. However, a malicious participant's poisoning attack may degrade the performance of this collaborative model. The main challenge in achieving the poisoning attack is the absence of access to the server-side top model, leaving the malicious participant without a clear target model. To address this challenge, we introduce an innovative end-to-end poisoning framework P-GAN. Specifically, the malicious participant initially employs semi-supervised learning to train a surrogate target model. Subsequently, this participant employs a GAN-based method to produce adversarial perturbations to degrade the surrogate target model's performance. Finally, the generator is obtained and tailored for VFL poisoning. Besides, we develop an anomaly detection algorithm based on a deep auto-encoder (DAE), offering a robust defense mechanism to VFL scenarios. Through extensive experiments, we evaluate the efficacy of P-GAN and DAE, and further analyze the factors that influence their performance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "6 pages, 7 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2401.10144",
        "abstract url": "https://arxiv.org/abs/2401.10144",
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "rating": "-3.5",
        "keywords": [
            [
                "bioinformatics"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": "Accepted to J-BHI"
    },
    {
        "paper id": "2404.03659",
        "abstract url": "https://arxiv.org/abs/2404.03659",
        "title": "Federated Unlearning for Human Activity Recognition",
        "rating": "-3.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Unlearning"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The rapid evolution of Internet of Things (IoT) technology has spurred the widespread adoption of Human Activity Recognition (HAR) in various daily life domains. Federated Learning (FL) is frequently utilized to build a global HAR model by aggregating user contributions without transmitting raw individual data. Despite substantial progress in user privacy protection with FL, challenges persist. Regulations like the General Data Protection Regulation (GDPR) empower users to request data removal, raising a new query in FL: How can a HAR client request data removal without compromising other clients' privacy? In response, we propose a lightweight machine unlearning method for refining the FL HAR model by selectively removing a portion of a client's training data. Our method employs a third-party dataset unrelated to model training. Using KL divergence as a loss function for fine-tuning, we aim to align the predicted probability distribution on forgotten data with the third-party dataset. Additionally, we introduce a membership inference evaluation method to assess unlearning effectiveness. Experimental results across diverse datasets show our method achieves unlearning accuracy comparable to \\textit{retraining} methods, resulting in speedups ranging from hundreds to thousands.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09167",
        "abstract url": "https://arxiv.org/abs/2401.09167",
        "title": "Novel Entropy-Based Metrics for Long-Term Atrial Fibrillation Recurrence Prediction Following Surgical Ablation: Insights from Preoperative Electrocardiographic Analysis",
        "rating": "-4",
        "keywords": [
            [
                "Surgical",
                "surgery",
                "clinical",
                "cardiac"
            ],
            [
                "forecasting"
            ]
        ],
        "abstract": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated concomitantly with other cardiac interventions through the Cox Maze procedure. This highly invasive intervention is still linked to a long-term recurrence rate of approximately 35% in permanent AF patients. The aim of this study is to preoperatively predict long-term AF recurrence post-surgery through the analysis of atrial activity (AA) organization from non-invasive electrocardiographic (ECG) recordings. A dataset comprising ECGs from 53 patients with permanent AF who had undergone Cox Maze concomitant surgery was analyzed. The AA was extracted from the lead V1 of these recordings and then characterized using novel predictors, such as the mean and standard deviation of the relative wavelet energy (RWEm and RWEs) across different scales, and an entropy-based metric that computes the stationary wavelet entropy variability (SWEnV). The individual predictors exhibited limited predictive capabilities to anticipate the outcome of the procedure, with the SWEnV yielding a classification accuracy (Acc) of 68.07%. However, the assessment of the RWEs for the seventh scale (RWEs7), which encompassed frequencies associated with the AA, stood out as the most promising individual predictor, with sensitivity (Se) and specificity (Sp) values of 80.83% and 67.09%, respectively, and an Acc of almost 75%. Diverse multivariate decision tree-based models were constructed for prediction, giving priority to simplicity in the interpretation of the forecasting methodology. In fact, the combination of the SWEnV and RWEs7 consistently outperformed the individual predictors and excelled in predicting post-surgery outcomes one year after the Cox Maze procedure, with Se, Sp, and Acc values of approximately 80%, thus surpassing the results of previous studies based on anatomical predictors associated with atrial function or clinical data.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09268",
        "abstract url": "https://arxiv.org/abs/2401.09268",
        "title": "Chemically Motivated Simulation Problems are Efficiently Solvable by a Quantum Computer",
        "rating": "-4",
        "keywords": [
            [
                "chemical"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Simulating chemical systems is highly sought after and computationally challenging, as the simulation cost exponentially increases with the system size. Quantum computers have been proposed as a computational means to overcome this bottleneck. Most efforts recently have been spent on determining the ground states of chemical systems. Hardness results and the lack of efficient heuristics for initial-state generation sheds doubt on the feasibility. Here we propose an inherently efficient approach for solving chemical simulation problems, meaning it requires quantum circuits of size scaling polynomially in relevant system parameters. If a set of assumptions can be satisfied, our approach finds good initial states by assembling initial states for dynamical simulation in a scattering tree. We discuss a variety of quantities of chemical interest that can be measured based on quantum simulation, e.g. of a reaction, succeeding the initial state preparation.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "physics.chem-ph"
        ],
        "comment": "12 pages, 4 figures"
    },
    {
        "paper id": "2401.09332",
        "abstract url": "https://arxiv.org/abs/2401.09332",
        "title": "Synergistic Reinforcement and Imitation Learning for Vision-driven Autonomous Flight of UAV Along River",
        "rating": "-4",
        "keywords": [
            [
                "Flight"
            ],
            [
                "navigation"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Vision-driven autonomous flight and obstacle avoidance of Unmanned Aerial Vehicles (UAVs) along complex riverine environments for tasks like rescue and surveillance requires a robust control policy, which is yet difficult to obtain due to the shortage of trainable riverine environment simulators. To easily verify the vision-based navigation controller performance for the river following task before real-world deployment, we developed a trainable photo-realistic dynamics-free riverine simulation environment using Unity. In this paper, we address the shortcomings that vanilla Reinforcement Learning (RL) algorithm encounters in learning a navigation policy within this partially observable, non-Markovian environment. We propose a synergistic approach that integrates RL and Imitation Learning (IL). Initially, an IL expert is trained on manually collected demonstrations, which then guides the RL policy training process. Concurrently, experiences generated by the RL agent are utilized to re-train the IL expert, enhancing its ability to generalize to unseen data. By leveraging the strengths of both RL and IL, this framework achieves a faster convergence rate and higher performance compared to pure RL, pure IL, and RL combined with static IL algorithms. The results validate the efficacy of the proposed method in terms of both task completion and efficiency. The code and trainable environments are available.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to IROS2024"
    },
    {
        "paper id": "2401.09590",
        "abstract url": "https://arxiv.org/abs/2401.09590",
        "title": "LoS Coverage Analysis for UAV-based THz Communication Networks: Towards 3D Visualization of Wireless Networks",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Terahertz (THz) links require a line-of-sight (LoS) connection, which is hard to be obtained in most scenarios. For THz communications, analyses based on LoS probability are not accurate, and a new real LoS model should be considered to determine the LoS status of the link in a real 3D environment. Considering unmanned aerial vehicle (UAV)-based THz networks, LoS coverage is analyzed in this work, where nodes are accurately determined to be in LoS or not. Specifically, by modeling an environment with 3D blocks, our target is to locate a set of UAVs equipped with directional THz links to provide LoS connectivity for the distributed users among the 3D obstacles. To this end, we first characterize and model the environment with 3D blocks. Then, we propose a user-friendly algorithm based on 3D spatial vectors, which determines the LoS status of nodes in the target area. In addition, using 3D modeling, several meta-heuristic algorithms are proposed for UAVs' positioning under 3D blocks in order to maximize the LoS coverage percentage. In the second part of the paper, for a UAV-based THz communication network, a geometrical analysis-based algorithm is proposed, which jointly clusters the distributed nodes and locates the set of UAVs to maximize average network capacity while ensuring the LoS state of distributed nodes among 3D obstacles. Moreover, we also propose a sub-optimal hybrid k-means-geometrical-based algorithm with a low computational complexity that can be used for networks where the topology continuously changes, and thus, users' clustering and UAVs' positioning need to be regularly updated. Finally, by providing various 3D simulations, we evaluate the effect of various system parameters such as the number and heights of UAVs, as well as the density and height of 3D obstacles on the LoS coverage.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09631",
        "abstract url": "https://arxiv.org/abs/2401.09631",
        "title": "Physics-Informed Calibration of Aeromagnetic Compensation in Magnetic Navigation Systems using Liquid Time-Constant Networks",
        "rating": "-4",
        "keywords": [
            [
                "flight"
            ],
            [
                "Navigation"
            ],
            [
                "attacks"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Magnetic navigation (MagNav) is a rising alternative to the Global Positioning System (GPS) and has proven useful for aircraft navigation. Traditional aircraft navigation systems, while effective, face limitations in precision and reliability in certain environments and against attacks. Airborne MagNav leverages the Earth's magnetic field to provide accurate positional information. However, external magnetic fields induced by aircraft electronics and Earth's large-scale magnetic fields disrupt the weaker signal of interest. We introduce a physics-informed approach using Tolles-Lawson coefficients for compensation and Liquid Time-Constant Networks (LTCs) to remove complex, noisy signals derived from the aircraft's magnetic sources. Using real flight data with magnetometer measurements and aircraft measurements, we observe up to a 64% reduction in aeromagnetic compensation error (RMSE nT), outperforming conventional models. This significant improvement underscores the potential of a physics-informed, machine learning approach for extracting clean, reliable, and accurate magnetic signals for MagNav positional estimation.",
        "subjects": [
            "cs.LG",
            "eess.SY",
            "physics.comp-ph",
            "physics.geo-ph"
        ],
        "comment": "Accepted at the NeurIPS 2023 Machine Learning and the Physical Sciences workshop, 7 pages, 4 figures, see code here: https://github.com/fnerrise/LNNs_MagNav/"
    },
    {
        "paper id": "2401.09674",
        "abstract url": "https://arxiv.org/abs/2401.09674",
        "title": "QoS-Aware 3D Coverage Deployment of UAVs for Internet of Vehicles in Intelligent Transportation",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "It is a challenging problem to characterize the air-to-ground (A2G) channel and identify the best deployment location for 3D UAVs with the QoS awareness. To address this problem, we propose a QoS-aware UAV 3D coverage deployment algorithm, which simulates the three-dimensional urban road scenario, considers the UAV communication resource capacity and vehicle communication QoS requirements comprehensively, and then obtains the optimal UAV deployment position by improving the genetic algorithm. Specifically, the K-means clustering algorithm is used to cluster the vehicles, and the center locations of these clusters serve as the initial UAV positions to generate the initial population. Subsequently, we employ the K-means initialized grey wolf optimization (KIGWO) algorithm to achieve the UAV location with an optimal fitness value by performing an optimal search within the grey wolf population. To enhance the algorithm's diversity and global search capability, we randomly substitute this optimal location with one of the individual locations from the initial population. The fitness value is determined by the total number of vehicles covered by UAVs in the system, while the allocation scheme's feasibility is evaluated based on the corresponding QoS requirements. Competitive selection operations are conducted to retain individuals with higher fitness values, while crossover and mutation operations are employed to maintain the diversity of solutions. Finally, the individual with the highest fitness, which represents the UAV deployment position that covers the maximum number of vehicles in the entire system, is selected as the optimal solution. Extensive experimental results demonstrate that the proposed algorithm can effectively enhance the reliability and vehicle communication QoS.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09711",
        "abstract url": "https://arxiv.org/abs/2401.09711",
        "title": "Joint Beam Direction Control and Radio Resource Allocation in Dynamic Multi-beam LEO Satellite Networks",
        "rating": "-4",
        "keywords": [
            [
                "5G",
                "6G"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Multi-beam low earth orbit (LEO) satellites are emerging as key components in beyond 5G and 6G to provide global coverage and high data rate. To fully unleash the potential of LEO satellite communication, resource management plays a key role. However, the uneven distribution of users, the coupling of multi-dimensional resources, complex inter-beam interference, and time-varying network topologies all impose significant challenges on effective communication resource management. In this paper, we study the joint optimization of beam direction and the allocation of spectrum, time, and power resource in a dynamic multi-beam LEO satellite network. The objective is to improve long-term user sum data rate while taking user fairness into account. Since the concerned resource management problem is mixed-integer non-convex programming, the problem is decomposed into three subproblems, namely beam direction control and time slot allocation, user subchannel assignment, and beam power allocation. Then, these subproblems are solved iteratively by leveraging matching with externalities and successive convex approximation, and the proposed algorithms are analyzed in terms of stability, convergence, and complexity. Extensive simulations are conducted, and the results demonstrate that our proposal can improve the number of served users by up to two times and the sum user data rate by up to 68%, compared to baseline schemes.",
        "subjects": [
            "cs.IT",
            "eess.SY"
        ],
        "comment": "Accepted by IEEE Transactions on Vehicular Technology"
    },
    {
        "paper id": "2401.09070",
        "abstract url": "https://arxiv.org/abs/2401.09070",
        "title": "Knowledge Pyramid: A Novel Hierarchical Reasoning Structure for Generalized Knowledge Augmentation and Inference",
        "rating": "-4.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "medical"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Knowledge graph (KG) based reasoning has been regarded as an effective means for the analysis of semantic networks and is of great usefulness in areas of information retrieval, recommendation, decision-making, and man-machine interaction. It is widely used in recommendation, decision-making, question-answering, search, and other fields. However, previous studies mainly used low-level knowledge in the KG for reasoning, which may result in insufficient generalization and poor robustness of reasoning. To this end, this paper proposes a new inference approach using a novel knowledge augmentation strategy to improve the generalization capability of KG. This framework extracts high-level pyramidal knowledge from low-level knowledge and applies it to reasoning in a multi-level hierarchical KG, called knowledge pyramid in this paper. We tested some medical data sets using the proposed approach, and the experimental results show that the proposed knowledge pyramid has improved the knowledge inference performance with better generalization. Especially, when there are fewer training samples, the inference accuracy can be significantly improved.",
        "subjects": [
            "cs.AI",
            "cs.IR"
        ],
        "comment": "10 pages,8 figures"
    },
    {
        "paper id": "2401.09145",
        "abstract url": "https://arxiv.org/abs/2401.09145",
        "title": "Your blush gives you away: detecting hidden mental states with remote photoplethysmography and thermal imaging",
        "rating": "-4.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "facial",
                "cardiac"
            ],
            [
                "thermal"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Multimodal emotion recognition techniques are increasingly essential for assessing mental states. Image-based methods, however, tend to focus predominantly on overt visual cues and often overlook subtler mental state changes. Psychophysiological research has demonstrated that HR and skin temperature are effective in detecting ANS activities, thereby revealing these subtle changes. However, traditional HR tools are generally more costly and less portable, while skin temperature analysis usually necessitates extensive manual processing. Advances in remote-PPG and automatic thermal ROI detection algorithms have been developed to address these issues, yet their accuracy in practical applications remains limited. This study aims to bridge this gap by integrating r-PPG with thermal imaging to enhance prediction performance. Ninety participants completed a 20-minute questionnaire to induce cognitive stress, followed by watching a film aimed at eliciting moral elevation. The results demonstrate that the combination of r-PPG and thermal imaging effectively detects emotional shifts. Using r-PPG alone, the prediction accuracy was 77% for cognitive stress and 61% for moral elevation, as determined by SVM. Thermal imaging alone achieved 79% accuracy for cognitive stress and 78% for moral elevation, utilizing a RF algorithm. An early fusion strategy of these modalities significantly improved accuracies, achieving 87% for cognitive stress and 83% for moral elevation using RF. Further analysis, which utilized statistical metrics and explainable machine learning methods including SHAP, highlighted key features and clarified the relationship between cardiac responses and facial temperature variations. Notably, it was observed that cardiovascular features derived from r-PPG models had a more pronounced influence in data fusion, despite thermal imaging's higher predictive accuracy in unimodal analysis.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "28 pages, 6 figures"
    },
    {
        "paper id": "2401.09198",
        "abstract url": "https://arxiv.org/abs/2401.09198",
        "title": "Space and Time Continuous Physics Simulation From Partial Observations",
        "rating": "-4.5",
        "keywords": [
            [
                "GNNs"
            ],
            [
                "forecast"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern techniques for physical simulations rely on numerical schemes and mesh-refinement methods to address trade-offs between precision and complexity, but these handcrafted solutions are tedious and require high computational power. Data-driven methods based on large-scale machine learning promise high adaptivity by integrating long-range dependencies more directly and efficiently. In this work, we focus on fluid dynamics and address the shortcomings of a large part of the literature, which are based on fixed support for computations and predictions in the form of regular or irregular grids. We propose a novel setup to perform predictions in a continuous spatial and temporal domain while being trained on sparse observations. We formulate the task as a double observation problem and propose a solution with two interlinked dynamical systems defined on, respectively, the sparse positions and the continuous domain, which allows to forecast and interpolate a solution from the initial condition. Our practical implementation involves recurrent GNNs and a spatio-temporal attention observer capable of interpolating the solution at arbitrary locations. Our model not only generalizes to new initial conditions (as standard auto-regressive models do) but also performs evaluation at arbitrary space and time locations. We evaluate on three standard datasets in fluid dynamics and compare to strong baselines, which are outperformed both in classical settings and in the extended new task requiring continuous predictions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Project Page: https://continuous-pde.github.io/"
    },
    {
        "paper id": "2401.09124",
        "abstract url": "https://arxiv.org/abs/2401.09124",
        "title": "Machine Learning for Healthcare-IoT Security: A Review and Risk Mitigation",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Healthcare",
                "diagnosis"
            ],
            [
                "5G",
                "IoT"
            ]
        ],
        "abstract": "The Healthcare Internet-of-Things (H-IoT), commonly known as Digital Healthcare, is a data-driven infrastructure that highly relies on smart sensing devices (i.e., blood pressure monitors, temperature sensors, etc.) for faster response time, treatments, and diagnosis. However, with the evolving cyber threat landscape, IoT devices have become more vulnerable to the broader risk surface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if exploited, may lead to data breaches, unauthorized access, and lack of command and control and potential harm. This paper reviews the fundamentals of healthcare IoT, its privacy, and data security challenges associated with machine learning and H-IoT devices. The paper further emphasizes the importance of monitoring healthcare IoT layers such as perception, network, cloud, and application. Detecting and responding to anomalies involves various cyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things (NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust authentication mechanism based on machine learning and deep learning techniques is required to protect and mitigate H-IoT devices from increasing cybersecurity vulnerabilities. Hence, in this review paper, security and privacy challenges and risk mitigation strategies for building resilience in H-IoT are explored and reported.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "28 pages, 17 figures, 2 tables"
    },
    {
        "paper id": "2401.09157",
        "abstract url": "https://arxiv.org/abs/2401.09157",
        "title": "Interference analysis of Positioning Reference Signals in 5G NTN",
        "rating": "-6",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "attacks"
            ],
            [
                "5G"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Accurate asset localization holds paramount importance across various industries, ranging from transportation management to search and rescue operations. In scenarios where traditional positioning equations cannot be adequately solved due to limited measurements obtained by the receiver, the utilization of Non-Terrestrial Networks (NTN) based on Low Earth Orbit (LEO) satellites can prove pivotal for precise positioning. The decision to employ NTN in lieu of conventional Global Navigation Satellite Systems (GNSS) is rooted in two key factors. Firstly, GNSS systems are susceptible to jamming and spoofing attacks, thereby compromising their reliability, where LEO satellites link budgets can benefit from a closer distances and the new mega constellations could offer more satellites in view than GNSS. Secondly, 5G service providers seek to reduce dependence on third-party services. Presently, the NTN operation necessitates a GNSS receiver within the User Equipment (UE), placing the service provider at the mercy of GNSS reliability. Consequently, when GNSS signals are unavailable in certain regions, NTN services are also rendered inaccessible.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Our ongoing research, closely related to our manuscript, promises crucial insights enhancing our findings. Committed to scientific quality and integrity, we refrain from submitting incomplete work to avoid misleading the scientific community"
    },
    {
        "paper id": "2401.08981",
        "abstract url": "https://arxiv.org/abs/2401.08981",
        "title": "Real-time generative design of diverse, \"truly\" optimized structures with controllable structural complexities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Compared with traditional design methods, generative design significantly attracts engineers in various disciplines. In thiswork, howto achieve the real-time generative design of optimized structures with various diversities and controllable structural complexities is investigated. To this end, a modified Moving Morphable Component (MMC) method together with novel strategies are adopted to generate high-quality dataset. The complexity level of optimized structures is categorized by the topological invariant. By improving the cost function, the WGAN is trained to produce optimized designs with the input of loading position and complexity level in real time. It is found that, diverse designs with a clear load transmission path and crisp boundary, even not requiring further optimization and different from any reference in the dataset, can be generated by the proposed model. This method holds great potential for future applications of machine learning enhanced intelligent design.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08988",
        "abstract url": "https://arxiv.org/abs/2401.08988",
        "title": "DECENT-BRM: Decentralization through Block Reward Mechanisms",
        "rating": "-10",
        "keywords": [],
        "abstract": "Proof-of-Work is a consensus algorithm where miners solve cryptographic puzzles to mine blocks and obtain a reward through some Block Reward Mechanism (BRM). PoW blockchain faces the problem of centralization due to the formation of mining pools, where miners mine blocks as a group and distribute rewards. The rationale is to reduce the risk (variance) in reward while obtaining the same expected block reward. In this work, we address the problem of centralization due to mining pools in PoW blockchain. We propose a two-player game between the new miner joining the system and the PoW blockchain system. We model the utility for the incoming miner as a combination of (i) expected block reward, (ii) risk, and (iii) cost of switching between different mining pools. With this utility structure, we analyze the equilibrium strategy of the incoming miner for different BRMs: (a) memoryless -- block reward is history independent (e.g., Bitcoin) (b) retentive: block reward is history-dependent (e.g., Fruitchains). For memoryless BRMs, we show that depending on the coefficient of switching cost $c$, the protocol is decentralized when $c = 0$ and centralized when $c > \\underline{c}$. In addition, we show the impossibility of constructing a memoryless BRM where solo mining gives a higher payoff than forming/joining mining pools. While retentive BRM in Fruitchains reduces risk in solo mining, the equilibrium strategy for incoming miners is still to join mining pools, leading to centralization. We then propose our novel retentive BRM -- \\textsf{Decent-BRM}. We show that under \\textsf{Decent-BRM}, incoming miners obtain higher utility in solo mining than joining mining pools. Therefore, no mining pools are formed, and the Pow blockchain using \\textsf{Decent-BRM} is decentralized.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.08991",
        "abstract url": "https://arxiv.org/abs/2401.08991",
        "title": "Knight Watch: Ubiquitous Computing Enhancements To Sleep Quality With Acoustic Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "This project introduces a wearable, non-intrusive device for snoring detection and remediation, designed to be placed under or alongside a pillow. The device uses sensors and machine learning algorithms to detect snoring and employs gentle vibrations to prompt positional changes, thereby reducing snoring episodes. The device is capable of connecting via an API to a cloud-based platform for the analysis of snoring sleep patterns and environmental context. The paper details the development from concept to prototype, emphasizing the technical challenges, solutions, and alignment with ubiquitous computing in sleep quality improvement.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 Pages, 3 Figures"
    },
    {
        "paper id": "2401.09001",
        "abstract url": "https://arxiv.org/abs/2401.09001",
        "title": "Enablers and Barriers of Empathy in Software Developer and User Interaction: A Mixed Methods Case Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software engineering (SE) requires developers to collaborate with stakeholders, and understanding their emotions and perspectives is often vital. Empathy is a concept characterising a person's ability to understand and share the feelings of another. However, empathy continues to be an under-researched human aspect in SE. We studied how empathy is practised between developers and end users using a mixed methods case study. We used an empathy test, observations and interviews to collect data, and socio technical grounded theory and descriptive statistics to analyse data. We identified the nature of awareness required to trigger empathy and enablers of empathy. We discovered barriers to empathy and a set of potential strategies to overcome these barriers. We report insights on emerging relationships and present a set of recommendations and potential future works on empathy and SE for software practitioners and SE researchers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09014",
        "abstract url": "https://arxiv.org/abs/2401.09014",
        "title": "Data assimilation approach for addressing imperfections in people flow measurement techniques using particle filter",
        "rating": "-10",
        "keywords": [],
        "abstract": "Understanding and predicting people flow in urban areas is useful for decision-making in urban planning and marketing strategies. Traditional methods for understanding people flow can be divided into measurement-based approaches and simulation-based approaches. Measurement-based approaches have the advantage of directly capturing actual people flow, but they face the challenge of data imperfection. On the other hand, simulations can obtain complete data on a computer, but they only consider some of the factors determining human behavior, leading to a divergence from actual people flow. Both measurement and simulation methods have unresolved issues, and combining the two can complementarily overcome them. This paper proposes a method that applies data assimilation, a fusion technique of measurement and simulation, to agent-based simulation. Data assimilation combines the advantages of both measurement and simulation, contributing to the creation of an environment that can reflect real people flow while acquiring richer data. The paper verifies the effectiveness of the proposed method in a virtual environment and demonstrates the potential of data assimilation to compensate for the three types of imperfection in people flow measurement techniques. These findings can serve as guidelines for supplementing sparse measurement data in physical environments.",
        "subjects": [
            "cs.HC",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09016",
        "abstract url": "https://arxiv.org/abs/2401.09016",
        "title": "Fast parallel sampling under isoperimetry",
        "rating": "-10",
        "keywords": [],
        "abstract": "We show how to sample in parallel from a distribution $\u03c0$ over $\\mathbb R^d$ that satisfies a log-Sobolev inequality and has a smooth log-density, by parallelizing the Langevin (resp. underdamped Langevin) algorithms. We show that our algorithm outputs samples from a distribution $\\hat\u03c0$ that is close to $\u03c0$ in Kullback--Leibler (KL) divergence (resp. total variation (TV) distance), while using only $\\log(d)^{O(1)}$ parallel rounds and $\\widetilde{O}(d)$ (resp. $\\widetilde O(\\sqrt d)$) gradient evaluations in total. This constitutes the first parallel sampling algorithms with TV distance guarantees. For our main application, we show how to combine the TV distance guarantees of our algorithms with prior works and obtain RNC sampling-to-counting reductions for families of discrete distribution on the hypercube $\\{\\pm 1\\}^n$ that are closed under exponential tilts and have bounded covariance. Consequently, we obtain an RNC sampler for directed Eulerian tours and asymmetric determinantal point processes, resolving open questions raised in prior works.",
        "subjects": [
            "cs.DS",
            "math.ST",
            "stat.ML"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2401.09051",
        "abstract url": "https://arxiv.org/abs/2401.09051",
        "title": "Canvil: Designerly Adaptation for LLM-Powered User Experiences",
        "rating": "-10",
        "keywords": [],
        "abstract": "Advancements in large language models (LLMs) are poised to spark a proliferation of LLM-powered user experiences. In product teams, designers are often tasked with crafting user experiences that align with user needs. To involve designers and leverage their user-centered perspectives to create effective and responsible LLM-powered products, we introduce the practice of designerly adaptation for engaging with LLMs as an adaptable design material. We first identify key characteristics of designerly adaptation through a formative study with designers experienced in designing for LLM-powered products (N=12). These characteristics are 1) have a low technical barrier to entry, 2) leverage designers' unique perspectives bridging users and technology, and 3) encourage model tinkering. Based on this characterization, we build Canvil, a Figma widget that operationalizes designerly adaptation. Canvil supports structured authoring of system prompts to adapt LLM behavior, testing of adapted models on diverse user inputs, and integration of model outputs into interface designs. We use Canvil as a technology probe in a group-based design study (6 groups, N=17) to investigate the implications of integrating designerly adaptation into design workflows. We find that designers are able to iteratively tinker with different adaptation approaches and reason about interface affordances to enhance end-user interaction with LLMs. Furthermore, designers identified promising collaborative workflows for designerly adaptation. Our work opens new avenues for collaborative processes and tools that foreground designers' user-centered expertise in the crafting and deployment of LLM-powered user experiences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09053",
        "abstract url": "https://arxiv.org/abs/2401.09053",
        "title": "On some computational properties of open sets",
        "rating": "-10",
        "keywords": [],
        "abstract": "Open sets are central to mathematics, especially analysis and topology, in ways few notions are. In most, if not all, computational approaches to mathematics, open sets are only studied indirectly via their 'codes' or 'representations'. In this paper, we study how hard it is to compute, given an arbitrary open set of reals, the most common representation, i.e. a countable set of open intervals. We work in Kleene's higher-order computability theory, which was historically based on the S1-S9 schemes and which now has an intuitive lambda calculus formulation due to the authors. We establish many computational equivalences between on one hand the 'structure' functional that converts open sets to the aforementioned representation, and on the other hand functionals arising from mainstream mathematics, like basic properties of semi-continuous functions, the Urysohn lemma, and the Tietze extension theorem. We also compare these functionals to known operations on regulated and bounded variation functions, and the Lebesgue measure restricted to closed sets. We obtain a number of natural computational equivalences for the latter involving theorems from mainstream mathematics.",
        "subjects": [
            "math.LO",
            "cs.LO"
        ],
        "comment": "28 pages, 1 figure"
    },
    {
        "paper id": "2401.09060",
        "abstract url": "https://arxiv.org/abs/2401.09060",
        "title": "Joint Route Selection and Power Allocation in Multi-hop Cache-enabled Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The caching paradigm has been introduced to alleviate backhaul traffic load and to reduce latencies due to massive never ending increase in data traffic. To fully exploit the benefits offered by caching, unmanned aerial vehicles (UAVs) and device-to-device (D2D) communication can be further utilized. In contrast to prior works, that strictly limits the content delivery routes up to two hops, we explore a multi-hop communications scenario, where the UAVs, the UEs, or both can relay the content to individual users. In this context, we formulate the problem for joint route selection and power allocation to minimize the overall system content delivery duration. First, motivated by the limitations of existing works, we consider the case where the nodes may transmit content simultaneously rather than sequentially and propose simple yet effective approach to allocate the transmission power. Second, we design a low-complexity greedy algorithm jointly handling route selection and power allocation. The simulation results demonstrate that the proposed greedy algorithm outperforms the benchmark algorithm by up to 56.98% in terms of content delivery duration while it achieves close-to-optimal performance.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 4 figures, accepted at IEEE WCNC 2024 - Track 2"
    },
    {
        "paper id": "2401.09062",
        "abstract url": "https://arxiv.org/abs/2401.09062",
        "title": "On Optimization of Next-Generation Microservice-Based Core Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Next-generation mobile core networks are required to be scalable and capable of efficiently utilizing heterogeneous bare metal resources that may include edge servers. To this end, microservice-based solutions where control plane procedures are deconstructed in their fundamental building blocks are gaining momentum. This letter proposes an optimization framework delivering the partitioning and mapping of large-scale microservice graphs onto heterogeneous bare metal deployments while minimizing the total network traffic among servers. An efficient heuristic strategy for solving the optimization problem is also provided. Simulation results show that, with the proposed framework, a microservice-based core can consistently support the requested load in heterogeneous bare metal deployments even when alternative architecture fails. Besides, our framework ensures an overall reduction in the control plane-related network traffic if compared to current core architectures.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted to IEEE Transactions on Vehicular Technology"
    },
    {
        "paper id": "2401.09064",
        "abstract url": "https://arxiv.org/abs/2401.09064",
        "title": "Performance Bounds and Optimization for CSI-Ratio based Bi-static Doppler Sensing in ISAC Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bi-static sensing is crucial for exploring the potential of networked sensing capabilities in integrated sensing and communications (ISAC). However, it suffers from the challenging clock asynchronism issue. CSI ratio-based sensing is an effective means to address the issue. Its performance bounds, particular for Doppler sensing, have not been fully understood yet. This work endeavors to fill the research gap. Focusing on a single dynamic path in high-SNR scenarios, we derive the closed-form CRB. Then, through analyzing the mutual interference between dynamic and static paths, we simplify the CRB results by deriving close approximations, further unveiling new insights of the impact of numerous physical parameters on Doppler sensing. Moreover, utilizing the new CRB and analyses, we propose novel waveform optimization strategies for noise- and interference-limited sensing scenarios, which are also empowered by closed-form and efficient solutions. Extensive simulation results are provided to validate the preciseness of the derived CRB results and analyses, with the aid of the maximum-likelihood estimator. The results also demonstrate the substantial enhanced Doppler sensing accuracy and the sensing capabilities for low-speed target achieved by the proposed waveform design.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "14 pages, 15 figures, journal paper"
    },
    {
        "paper id": "2401.09089",
        "abstract url": "https://arxiv.org/abs/2401.09089",
        "title": "Is Synchronization a Bottleneck for Pilot-Assisted URLLC Links?",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a framework to evaluate the random-coding union bound with parameter $s$ on the achievable error probability in the finite-blocklength regime for a pilot-assisted transmission scheme operating over an imperfectly synchronized and memoryless block-fading waveform channel. Unlike previous results, which disregard the effects of imperfect synchronization, our framework utilizes pilots for both synchronization and channel estimation. Specifically, we provide an algorithm to perform joint synchronization and channel estimation and verify its accuracy by observing its tightness in comparison with the Cramer-Rao bound. Then, we develop an RCUs bound on the error probability, which applies for a receiver that treats the estimates provided by the algorithm as accurate. Additionally, we utilize the saddlepoint approximation to provide a numerically efficient method for evaluating the RCUs bound in this scenario. Our numerical experiments verify the accuracy of the proposed approximation. Moreover, when transmission blocks are received synchronously, numerical results indicate that the number of pilot symbols needed to estimate the fading channel gains to the level of accuracy required in ultra-reliable low-latency communication is also sufficient to acquire sufficiently good synchronization. However, when the blocks are received asynchronously, synchronization becomes the bottleneck for the system performance.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09092",
        "abstract url": "https://arxiv.org/abs/2401.09092",
        "title": "BibSonomy Meets ChatLLMs for Publication Management: From Chat to Publication Management: Organizing your related work using BibSonomy & LLMs",
        "rating": "-10",
        "keywords": [],
        "abstract": "The ever-growing corpus of scientific literature presents significant challenges for researchers with respect to discovery, management, and annotation of relevant publications. Traditional platforms like Semantic Scholar, BibSonomy, and Zotero offer tools for literature management, but largely require manual laborious and error-prone input of tags and metadata. Here, we introduce a novel retrieval augmented generation system that leverages chat-based large language models (LLMs) to streamline and enhance the process of publication management. It provides a unified chat-based interface, enabling intuitive interactions with various backends, including Semantic Scholar, BibSonomy, and the Zotero Webscraper. It supports two main use-cases: (1) Explorative Search & Retrieval - leveraging LLMs to search for and retrieve both specific and general scientific publications, while addressing the challenges of content hallucination and data obsolescence; and (2) Cataloguing & Management - aiding in the organization of personal publication libraries, in this case BibSonomy, by automating the addition of metadata and tags, while facilitating manual edits and updates. We compare our system to different LLM models in three different settings, including a user study, and we can show its advantages in different metrics.",
        "subjects": [
            "cs.IR",
            "cs.HC"
        ],
        "comment": "Accepted at 2024 ACM SIGIR CHIIR, For a demo see here http://professor-x.de/demos/bibsonomy-chatgpt/demo.mp4"
    },
    {
        "paper id": "2401.09119",
        "abstract url": "https://arxiv.org/abs/2401.09119",
        "title": "Anchor-points Assisted Uplink Sensing in Perceptive Mobile Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Uplink sensing in integrated sensing and communications (ISAC) systems, such as Perceptive Mobile Networks, is challenging due to the clock asynchronism between transmitter and receiver. Existing solutions typically require the presence of a dominating line-of-sight path and the knowledge of transmitter location at the receiver. In this paper, relaxing these requirements, we propose a novel and effective uplink sensing scheme with the assistance of static anchor points. Two major algorithms are proposed in the scheme. The first algorithm estimates the relative timing and carrier frequency offsets due to clock asynchronism, with respect to those at a randomly selected reference snapshot. Theoretical performance analysis is provided for the algorithm. The estimates from the first algorithm are then used to compensate for the offsets and generate the angle-Doppler maps. Using the maps, the second algorithm identifies the anchor points, and then locates the UE and dynamic targets. Feasibility of UE localization is also analyzed. Simulation results are provided and demonstrate the effectiveness of the proposed algorithms.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages, 12 figures, journal paper"
    },
    {
        "paper id": "2401.09162",
        "abstract url": "https://arxiv.org/abs/2401.09162",
        "title": "Named Service Networking as a primer for the Metaverse",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ubiquitous extended reality environments such as the Metaverse will have a significant impact on the Internet, which will evolve to interconnect a large number of mixed reality spaces. Currently, Metaverse development is related to the creation of mixed reality environments, not tackling the required networking functionalities. This article analyzes suitable networking design choices to support the Metaverse, proposing a new service-centric networking approach capable of incorporating low-latency data fetching, distributed computing, and fusion of heterogeneous data types over the Cloud-to-Thing continuum.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2401.09179",
        "abstract url": "https://arxiv.org/abs/2401.09179",
        "title": "Super-Directive Antenna Arrays: How Many Elements Do We Need?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Super-directive antenna arrays have faced challenges in achieving high realized gains ever since their introduction in the academic literature. The primary challenges are high impedance mismatches and resistive losses, which become increasingly more dominant as the number of elements increases. Consequently, a critical limitation arises in determining the maximum number of elements that should be utilized to achieve super-directivity, particularly within dense array configurations. This paper addresses precisely this issue through an optimization study to design a super-directive antenna array with a maximum number of elements. An iterative approach is employed to increase the array of elements while sustaining a satisfactory realized gain using the differential evolution (DE) algorithm. Thus, it is observed that super-directivity can be obtained in an array with a maximum of five elements. Our results indicate that the obtained unit array has a $67.20\\%$ higher realized gain than a uniform linear array with conventional excitation. For these reasons, these results make the proposed architecture a strong candidate for applications that require densely packed arrays, particularly in the context of massive multiple-input multiple-output (MIMO).",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09199",
        "abstract url": "https://arxiv.org/abs/2401.09199",
        "title": "Data Trading and Monetization: Challenges and Open Research Directions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Traditional data monetization approaches face challenges related to data protection and logistics. In response, digital data marketplaces have emerged as intermediaries simplifying data transactions. Despite the growing establishment and acceptance of digital data marketplaces, significant challenges hinder efficient data trading. As a result, few companies can derive tangible value from their data, leading to missed opportunities in understanding customers, pricing decisions, and fraud prevention. In this paper, we explore both technical and organizational challenges affecting data monetization. Moreover, we identify areas in need of further research, aiming to expand the boundaries of current knowledge by emphasizing where research is currently limited or lacking.",
        "subjects": [
            "cs.DC",
            "cs.DB"
        ],
        "comment": "Paper accepted by the International Conference on Future Networks and Distributed Systems (ICFNDS 2023)"
    },
    {
        "paper id": "2401.09201",
        "abstract url": "https://arxiv.org/abs/2401.09201",
        "title": "Tropical modeling of battery swapping and charging station",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose and investigate a queueing model of a battery swapping and charging station (BSCS) for electric vehicles (EVs). A new approach to the analysis of the queueing model is developed, which combines the representation of the model as a stochastic dynamic system with the use of the methods and results of tropical algebra, which deals with the theory and applications of algebraic systems with idempotent operations. We describe the dynamics of the queueing model by a system of recurrence equations that involve random variables (RVs) to represent the interarrival time of incoming EVs. A performance measure for the model is defined as the mean operation cycle time of the station. Furthermore, the system of equations is represented in terms of the tropical algebra in vector form as an implicit linear state dynamic equation. The performance measure takes on the meaning of the mean growth rate of the state vector (the Lyapunov exponent) of the dynamic system. By applying a solution technique of vector equations in tropical algebra, the implicit equation is transformed into an explicit one with a state transition matrix with random entries. The evaluation of the Lyapunov exponent reduces to finding the limit of the expected value of norms of tropical matrix products. This limit is then obtained using results from the tropical spectral theory of deterministic and random matrices. With this approach, we derive a new exact formula for the mean cycle time of the BSCS, which is given in terms of the expected value of the RVs involved. We present the results of the Monte Carlo simulation of the BSCS's operation, which show a good agreement with the exact solution. The application of the obtained solution to evaluate the performance of one BSCS and to find the optimal distribution of battery packs between stations in a network of BSCSs is discussed.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "21 pages, 5 figures"
    },
    {
        "paper id": "2401.09202",
        "abstract url": "https://arxiv.org/abs/2401.09202",
        "title": "Complexity results on the decomposition of a digraph into directed linear forests and out-stars",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider two decomposition problems in directed graphs. We say that a digraph is $k$-bounded for some $k \\in \\mathbb{Z}_{\\geq 1}$ if each of its connected components contains at most $k$ arcs. For the first problem, a directed linear forest is a collection of vertex-disjoint directed paths and we consider the problem of decomposing a given digraph into a $k$-bounded and an $\\ell$-bounded directed linear forest for some fixed $k,\\ell \\in \\mathbb{Z}_{\\geq 1}\\cup \\{\\infty\\}$. We give a full dichotomy for this problem by showing that it can be solved in polynomial time if $k+\\ell \\leq 3$ and is NP-complete otherwise. This answers a question of Campbell, H\u00f6rsch, and Moore. For the second problem, we say that an out-galaxy is a vertex-disjoint collection of out-stars. Again, we give a full dichotomy of when a given digraph can be edge-decomposed into a $k$-bounded and an $\\ell$-bounded out-galaxy for fixed $k,\\ell \\in \\mathbb{Z}_{\\geq 1}\\cup \\{\\infty\\}$. More precisely, we show that the problem can be solved in polynomial time if $\\min\\{k,\\ell\\}\\in \\{1,\\infty\\}$ and is NP-complete otherwise.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09217",
        "abstract url": "https://arxiv.org/abs/2401.09217",
        "title": "Neural Network Equalizers and Successive Interference Cancellation for Bandlimited Channels with a Nonlinearity",
        "rating": "-10",
        "keywords": [],
        "abstract": "Neural networks (NNs) inspired by the forward-backward algorithm (FBA) are used as equalizers for bandlimited channels with a memoryless nonlinearity. The NN-equalizers are combined with successive interference cancellation (SIC) to approach the information rates of joint detection and decoding (JDD) with considerably less complexity than JDD and other existing equalizers. Simulations for short-haul optical fiber links with square-law detection illustrate the gains of NNs as compared to the complexity-limited FBA and Gibbs sampling.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Submitted to IEEE Trans. Commun. on January 11, 2024;"
    },
    {
        "paper id": "2401.09218",
        "abstract url": "https://arxiv.org/abs/2401.09218",
        "title": "Complexity of some algorithmic problems in groups: a survey",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this survey, we address the worst-case, average-case, and generic-case time complexity of the word problem and some other algorithmic problems in several classes of groups and show that it is often the case that the average-case complexity of the word problem is linear with respect to the length of an input word, which is as good as it gets if one considers groups given by generators and defining relations. At the same time, there are other natural algorithmic problems, for instance, the geodesic (decision) problem or Whitehead's automorphism problem, where the average-case time complexity can be sublinear, even constant.",
        "subjects": [
            "math.GR",
            "cs.CC"
        ],
        "comment": "12 pages. arXiv admin note: text overlap with arXiv:2205.05232"
    },
    {
        "paper id": "2401.09229",
        "abstract url": "https://arxiv.org/abs/2401.09229",
        "title": "Information flow and Laplacian dynamics on local optima networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a new way of looking at local optima networks (LONs). LONs represent fitness landscapes; the nodes are local optima, and the edges are search transitions between them. Many metrics computed on LONs have been proposed and shown to be linked to metaheuristic search difficulty. These have typically considered LONs as describing static structures. In contrast to this, Laplacian dynamics (LD) is an approach to consider the information flow across a network as a dynamical process. We adapt and apply LD to the context of LONs. As a testbed, we consider instances from the quadratic assignment problem (QAP) library. Metrics related to LD are proposed and these are compared with existing LON metrics. The results show that certain LD metrics are strong predictors of metaheuristic performance for iterated local search and tabu search.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09231",
        "abstract url": "https://arxiv.org/abs/2401.09231",
        "title": "Scalable Resource Provisioning for Multi-user Communications in Next Generation Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The great demand for real-time multimedia sessions encompassing groups of users (multi-user), associated with the limitations of the current Internet in providing quality assurance, has raised challenges for defining the best mechanisms to deploy the Next Generation of Networks (NGN). There is a consensus that an efficient and scalable provisioning of network resources is crucial for the success of the NGN, mainly in what concerns access networks. Previous solutions for the control of multi-user sessions rely mostly on uncoordinated actions to allocate per-flow bandwidth and multicast trees. This paper introduces a Multiuser Aggregated Resource Allocation mechanism (MARA) that coordinates the control of class-based bandwidth and multicast resources in a scalable manner. In comparison with previous work, MARA significantly reduces signaling, state and processing overhead. The performance benefits of MARA are analyzed though simulations, which successfully demonstrated the significant optimization in the network performance.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09234",
        "abstract url": "https://arxiv.org/abs/2401.09234",
        "title": "SARRIGUREN: a polynomial-time complete algorithm for random $k$-SAT with relatively dense clauses",
        "rating": "-10",
        "keywords": [],
        "abstract": "SARRIGUREN, a new complete algorithm for SAT based on counting clauses (which is valid also for Unique-SAT and #SAT) is described, analyzed and tested. Although existing complete algorithms for SAT perform slower with clauses with many literals, that is an advantage for SARRIGUREN, because the more literals are in the clauses the bigger is the probability of overlapping among clauses, a property that makes the clause counting process more efficient. Actually, it provides a $O(m^2 \\times n/k)$ time complexity for random $k$-SAT instances of $n$ variables and $m$ relatively dense clauses, where that density level is relative to the number of variables $n$, that is, clauses are relatively dense when $k\\geq7\\sqrt{n}$. Although theoretically there could be worst-cases with exponential complexity, the probability of those cases to happen in random $k$-SAT with relatively dense clauses is practically zero. The algorithm has been empirically tested and that polynomial time complexity maintains also for $k$-SAT instances with less dense clauses ($k\\geq5\\sqrt{n}$). That density could, for example, be of only 0.049 working with $n=20000$ variables and $k=989$ literals. In addition, they are presented two more complementary algorithms that provide the solutions to $k$-SAT instances and valuable information about number of solutions for each literal. Although this algorithm does not solve the NP=P problem (it is not a polynomial algorithm for 3-SAT), it broads the knowledge about that subject, because $k$-SAT with $k>3$ and dense clauses is not harder than 3-SAT. Moreover, the Python implementation of the algorithms, and all the input datasets and obtained results in the experiments are made available.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": "23 pages, 2 figures, 8 tables, algorithms, results and data in http://bdi.si.ehu.es/bdi/sarriguren"
    },
    {
        "paper id": "2401.09256",
        "abstract url": "https://arxiv.org/abs/2401.09256",
        "title": "Relay Channels with Unreliable Helpers",
        "rating": "-10",
        "keywords": [],
        "abstract": "The relay channel with unreliable helper is introduced and studied. The model is that of a classical relay channel where the input from the relay to the channel has an extra primitive link whose presence is not assured a priori. The extra link represents a helper who may decide not to cooperate in transmission. The goal is to devise robust coding schemes that exploit all the relay links when they are present, but can also operate, possibly at reduced rates, when the extra primitive link (helper) is absent. The capacity region of this class of problems is defined, and fully characterized for degraded relay channels. The degraded Gaussian relay channel with unreliable relay link is solved.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "9 pages, 4 figures. Part of the results were presented at the 2023 International Symposium on Information Theory, June 25-30 2023, Taipei, Taiwan"
    },
    {
        "paper id": "2401.09270",
        "abstract url": "https://arxiv.org/abs/2401.09270",
        "title": "Exact Real Search: Formalised Optimisation and Regression in Constructive Univalent Mathematics",
        "rating": "-10",
        "keywords": [],
        "abstract": "The real numbers are important in both mathematics and computation theory. Computationally, real numbers can be represented in several ways; most commonly using inexact floating-point data-types, but also using exact arbitrary-precision data-types which satisfy the expected mathematical properties of the reals. This thesis is concerned with formalising properties of certain types for exact real arithmetic, as well as utilising them computationally for the purposes of search, optimisation and regression. We develop, in a constructive and univalent type-theoretic foundation of mathematics, a formalised framework for performing search, optimisation and regression on a wide class of types. This framework utilises Mart\u00edn Escard\u00f3's prior work on searchable types, along with a convenient version of ultrametric spaces -- which we call closeness spaces -- in order to consistently search certain infinite types using the functional programming language and proof assistant Agda. We formally define and prove the convergence properties of type-theoretic variants of global optimisation and parametric regression, problems related to search from the literature of analysis. As we work in a constructive setting, these convergence theorems yield computational algorithms for correct optimisation and regression on the types of our framework. Importantly, we can instantiate our framework on data-types from the literature of exact real arithmetic, allowing us to perform our variants of search, optimisation and regression on ternary signed-digit encodings of the real numbers, as well as a simplified version of Hans-J. Boehm's functional encodings of real numbers. Furthermore, we contribute to the extensive work on ternary signed-digits by formally verifying the definition of certain exact real arithmetic operations using the Escard\u00f3-Simpson interval object specification of compact intervals.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "A thesis submitted to the University of Birmingham for the degree of Doctor of Philosophy. 198 pages. Supervised by Dan Ghica and Mart\u00edn Escard\u00f3"
    },
    {
        "paper id": "2401.09273",
        "abstract url": "https://arxiv.org/abs/2401.09273",
        "title": "A classification of bisimilarities for general Markov decision processes",
        "rating": "-10",
        "keywords": [],
        "abstract": "We provide a fine classification of bisimilarities between states of possibly different labelled Markov processes (LMP). We show that a bisimilarity relation proposed by Panangaden that uses direct sums coincides with \"event bisimilarity\" from his joint work with Danos, Desharnais, and Laviolette. We also extend Giorgio Bacci's notions of bisimilarity between two different processes to the case of nondeterministic LMP and generalize the game characterization of state bisimilarity by Clerc et al. for the latter.",
        "subjects": [
            "cs.LO",
            "math.LO"
        ],
        "comment": "38 pages. v2: Reference to prior example due to D. Gburek and added acknowledgment"
    },
    {
        "paper id": "2401.09275",
        "abstract url": "https://arxiv.org/abs/2401.09275",
        "title": "Hot Fixing Software: A Comprehensive Review of Terminology, Techniques, and Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "A hot fix is an improvement to a specific time-critical issue deployed to a software system in production. While hot fixing is an essential and common activity in software maintenance, it has never been surveyed as a research activity. Thus, such a review is long overdue. In this paper, we conduct a comprehensive literature review of work on hot fixing. We highlight the fields where this topic has been addressed, inconsistencies we identified in the terminology, gaps in the literature, and directions for future work. Our search concluded with 91 papers on the topic between the year 2000 and 2022. The papers found encompass many different research areas such as log analysis, runtime patching (also known as hot patching), and automated repair, as well as various application domains such as security, mobile, and video games. We find that there are many directions that can take hot fix research forward such as unifying existing terminology, establishing a benchmark set of hot fixes, researching costs and frequency of hot fixes, and researching the possibility of end-to-end automation of detection, mitigation, and propagation. We discuss these avenues in detail to inspire the community to systematize hot fixing as a software engineering activity. We hope that this paper streamlines the existing body of work and drives research in the area forward.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09281",
        "abstract url": "https://arxiv.org/abs/2401.09281",
        "title": "PIM-STM: Software Transactional Memory for Processing-In-Memory Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Processing-In-Memory (PIM) is a novel approach that augments existing DRAM memory chips with lightweight logic. By allowing to offload computations to the PIM system, this architecture allows for circumventing the data-bottleneck problem that affects many modern workloads. This work tackles the problem of how to build efficient software implementations of the Transactional Memory (TM) abstraction by introducing PIM-STM, a library that provides a range of diverse TM implementations for UPMEM, the first commercial PIM system. Via an extensive study we assess the efficiency of alternative choices in the design space of TM algorithms on this emerging architecture. We further quantify the impact of using different memory tiers of the UPMEM system (having different trade-offs for what concerns latency vs capacity) to store the metadata used by different TM implementations. Finally, we assess the gains achievable in terms of performance and memory efficiency when using PIM-STM to accelerate TM applications originally conceived for conventional CPU-based systems.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "To be published in 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24), April 27-May 1, 2024, La Jolla, CA, USA"
    },
    {
        "paper id": "2401.09289",
        "abstract url": "https://arxiv.org/abs/2401.09289",
        "title": "Same Data, Diverging Perspectives: The Power of Visualizations to Elicit Competing Interpretations",
        "rating": "-10",
        "keywords": [],
        "abstract": "People routinely rely on data to make decisions, but the process can be riddled with biases. We show that patterns in data might be noticed first or more strongly, depending on how the data is visually represented or what the viewer finds salient. We also demonstrate that viewer interpretation of data is similar to that of 'ambiguous figures' such that two people looking at the same data can come to different decisions. In our studies, participants read visualizations depicting competitions between two entities, where one has a historical lead (A) but the other has been gaining momentum (B) and predicted a winner, across two chart types and three annotation approaches. They either saw the historical lead as salient and predicted that A would win, or saw the increasing momentum as salient and predicted B to win. These results suggest that decisions can be influenced by both how data are presented and what patterns people find visually salient.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09317",
        "abstract url": "https://arxiv.org/abs/2401.09317",
        "title": "From Zero-Freeness to Strong Spatial Mixing via a Christoffel-Darboux Type Identity",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a unifying approach to derive the strong spatial mixing (SSM) property for the general 2-spin system from zero-free regions of its partition function. Our approach works for the multivariate partition function over all three complex parameters $(\u03b2, \u03b3, \u03bb)$, and we allow the zero-free regions of $\u03b2, \u03b3$ or $\u03bb$ to be of arbitrary shapes. As long as the zero-free region contains a positive point and it is a complex neighborhood of $\u03bb=0$ when fixing $\u03b2, \u03b3\\in \\mathbb{C}$, or a complex neighborhood of $\u03b2\u03b3=1$ when fixing $\u03b2, \u03bb\\in \\mathbb{C}$ or $\u03b3, \u03bb\\in \\mathbb{C}$ respectively, we are able to show that the corresponding 2-spin system exhibits SSM on such a region. The underlying graphs of the 2-spin system are not necessarily of bounded degree, while are required to include graphs with pinned vertices. We prove this result by establishing a Christoffel-Darboux type identity for the 2-spin system on trees. This identity plays an important role in our approach and is of its own interests. We also use certain tools from complex analysis such as Riemann mapping theorem. Our approach comprehensively turns all existing zero-free regions (to our best knowledge) of the partition function of the 2-spin system where pinned vertices are allowed into the SSM property. As a consequence, we obtain new SSM results for the 2-spin system beyond the direct argument for SSM based on tree recurrence. Moreover, we extend our approach to handle the 2-spin system with non-uniform external fields. As an application, we obtain a new SSM result for the non-uniform ferromagnetic Ising model from the celebrated Lee-Yang circle theorem.",
        "subjects": [
            "math-ph",
            "cs.DS",
            "math.CO",
            "math.PR"
        ],
        "comment": "Main results are slightly improved: A new condition under which Theorem 1 also holds was added. The condition of Theorem 2 was updated to a more general one"
    },
    {
        "paper id": "2401.09350",
        "abstract url": "https://arxiv.org/abs/2401.09350",
        "title": "Foundations of Vector Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "Vectors are universal mathematical objects that can represent text, images, speech, or a mix of these data modalities. That happens regardless of whether data is represented by hand-crafted features or learnt embeddings. Collect a large enough quantity of such vectors and the question of retrieval becomes urgently relevant: Finding vectors that are more similar to a query vector. This monograph is concerned with the question above and covers fundamental concepts along with advanced data structures and algorithms for vector retrieval. In doing so, it recaps this fascinating topic and lowers barriers of entry into this rich area of research.",
        "subjects": [
            "cs.DS",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09359",
        "abstract url": "https://arxiv.org/abs/2401.09359",
        "title": "LRSCwait: Enabling Scalable and Efficient Synchronization in Manycore Systems through Polling-Free and Retry-Free Operation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Extensive polling in shared-memory manycore systems can lead to contention, decreased throughput, and poor energy efficiency. Both lock implementations and the general-purpose atomic operation, load-reserved/store-conditional (LRSC), cause polling due to serialization and retries. To alleviate this overhead, we propose LRwait and SCwait, a synchronization pair that eliminates polling by allowing contending cores to sleep while waiting for previous cores to finish their atomic access. As a scalable implementation of LRwait, we present Colibri, a distributed and scalable approach to managing LRwait reservations. Through extensive benchmarking on an open-source RISC-V platform with 256 cores, we demonstrate that Colibri outperforms current synchronization approaches for various concurrent algorithms with high and low contention regarding throughput, fairness, and energy efficiency. With an area overhead of only 6%, Colibri outperforms LRSC-based implementations by a factor of 6.5x in terms of throughput and 7.1x in terms of energy efficiency.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "6 pages, 6 figures, 2 tables, accepted as a regular paper at DATE24"
    },
    {
        "paper id": "2401.09366",
        "abstract url": "https://arxiv.org/abs/2401.09366",
        "title": "An Introduction to Different Approaches to Initial Semantics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Characterizing programming languages with variable binding as initial objects, was first achieved by Fiore, Plotkin, and Turi in their seminal paper published at LICS'99. To do so, in particular to prove initiality theorems, they developed a framework based on monoidal categories, functors with strengths, and $\u03a3$-monoids. An alternative approach using modules over monads was later introduced by Hirschowitz and Maggesi, for endofunctor categories, that is, for particular monoidal categories. This approach has the advantage of providing a more general and abstract definition of signatures and models; however, no general initiality result is known for this notion of signature. Furthermore, Matthes and Uustalu provided a categorical formalism for constructing (initial) monads via Mendler-style recursion, that can also be used for initial semantics. The different approaches have been developed further in several articles. However, in practice, the literature is difficult to access, and links between the different strands of work remain underexplored. In the present work, we give an introduction to initial semantics that encompasses the three different strands. We develop a suitable \"pushout\" of Hirschowitz and Maggesi's framework with Fiore's, and rely on Matthes and Uustalu's formalism to provide modular proofs. For this purpose, we generalize both Hirschowitz and Maggesi's framework, and Matthes and Uustalu's formalism to the general setting of monoidal categories studied by Fiore and collaborators. Moreover, we provide fully worked out presentation of some basic instances of the literature, and an extensive discussion of related work explaining the links between the different approaches.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09371",
        "abstract url": "https://arxiv.org/abs/2401.09371",
        "title": "Maximally Concentrated Sequences after Half-sample Shifts",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is well known that index (discrete-time)-limited sampled sequences leak outside the support set when a band-limiting operation is applied. Similarly, a fractional shift causes an index-limited sequence to be infinite in extent due to the inherent band-limiting. Index-limited versions of discrete prolate spheroidal sequences (DPSS) are known to experience minimum leakage after band-limiting. In this work, we consider the effect of a half-sample shift and provide upper bounds on the resulting leakage energy for arbitrary sequences. Furthermore, we find an orthonormal basis derived from DPSS with members ordered according to energy concentration after half sample shifts; the primary (first) member being the global optimum.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09412",
        "abstract url": "https://arxiv.org/abs/2401.09412",
        "title": "Weakly-Private Information Retrieval From MDS-Coded Distributed Storage",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider the problem of weakly-private information retrieval (WPIR) when data is encoded by a maximum distance separable code and stored across multiple servers. In WPIR, a user wishes to retrieve a piece of data from a set of servers without leaking too much information about which piece of data she is interested in. We study and provide the first WPIR protocols for this scenario and present results on their optimal trade-off between download rate and information leakage using the maximal leakage privacy metric.",
        "subjects": [
            "cs.IT",
            "cs.CR"
        ],
        "comment": "To be presented at the 2024 International Zurich Seminar on Information and Communication (IZS'24), Zurich, Switzerland"
    },
    {
        "paper id": "2401.09420",
        "abstract url": "https://arxiv.org/abs/2401.09420",
        "title": "LionHeart: A Layer-based Mapping Framework for Heterogeneous Systems with Analog In-Memory Computing Tiles",
        "rating": "-10",
        "keywords": [],
        "abstract": "When arranged in a crossbar configuration, resistive memory devices can be used to execute MVM, the most dominant operation of many ML algorithms, in constant time complexity. Nonetheless, when performing computations in the analog domain, novel challenges are introduced in terms of arithmetic precision and stochasticity, due to non-ideal circuit and device behaviour. Moreover, these non-idealities have a temporal dimension, resulting in a degrading application accuracy over time. Facing these challenges, we propose a novel framework, named LionHeart, to obtain hybrid analog-digital mappings to execute DL inference workloads using heterogeneous accelerators. The accuracy-constrained mappings derived by LionHeart showcase, across different DNNs and datasets, high accuracy and potential for speedup. The results of the full system simulations highlight run-time reductions and energy efficiency gains that exceed 6X, with a user-defined accuracy threshold with respect to a fully digital floating point implementation.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09501",
        "abstract url": "https://arxiv.org/abs/2401.09501",
        "title": "Reservoir computing with logistic map",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent studies on reservoir computing essentially involve a high dimensional dynamical system as the reservoir, which transforms and stores the input as a higher dimensional state, for temporal and nontemporal data processing. We demonstrate here a method to predict temporal and nontemporal tasks by constructing virtual nodes as constituting a reservoir in reservoir computing using a nonlinear map, namely logistic map, and a simple finite trigonometric series. We predict three nonlinear systems, namely Lorenz, R\u00f6ssler, and Hindmarsh-Rose, for temporal tasks and a seventh order polynomial for nontemporal tasks with great accuracy. Also, the prediction is made in the presence of noise and found to closely agree with the target. Remarkably, the logistic map performs well and predicts close to the actual or target values. The low values of the root mean square error confirm the accuracy of this method in terms of efficiency. Our approach removes the necessity of continuous dynamical systems for constructing the reservoir in reservoir computing. Moreover, the accurate prediction for the three different nonlinear systems suggests that this method can be considered a general one and can be applied to predict many systems. Finally, we show that the method also accurately anticipates the time series for the future (self prediction).",
        "subjects": [
            "cond-mat.dis-nn",
            "cs.NE",
            "nlin.CD"
        ],
        "comment": "Submitted for publication in Physical Review E"
    },
    {
        "paper id": "2401.09519",
        "abstract url": "https://arxiv.org/abs/2401.09519",
        "title": "Privacy Engineering in Smart Home (SH) Systems: A Comprehensive Privacy Threat Analysis and Risk Management Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Addressing trust concerns in Smart Home (SH) systems is imperative due to the limited study on preservation approaches that focus on analyzing and evaluating privacy threats for effective risk management. While most research focuses primarily on user privacy, device data privacy, especially identity privacy, is almost neglected, which can significantly impact overall user privacy within the SH system. To this end, our study incorporates privacy engineering (PE) principles in the SH system that consider user and device data privacy. We start with a comprehensive reference model for a typical SH system. Based on the initial stage of LINDDUN PRO for the PE framework, we present a data flow diagram (DFD) based on a typical SH reference model to better understand SH system operations. To identify potential areas of privacy threat and perform a privacy threat analysis (PTA), we employ the LINDDUN PRO threat model. Then, a privacy impact assessment (PIA) was carried out to implement privacy risk management by prioritizing privacy threats based on their likelihood of occurrence and potential consequences. Finally, we suggest possible privacy enhancement techniques (PETs) that can mitigate some of these threats. The study aims to elucidate the main threats to privacy, associated risks, and effective prioritization of privacy control in SH systems. The outcomes of this study are expected to benefit SH stakeholders, including vendors, cloud providers, users, researchers, and regulatory bodies in the SH systems domain.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "The paper has 3 figures, 8 tables"
    },
    {
        "paper id": "2401.09593",
        "abstract url": "https://arxiv.org/abs/2401.09593",
        "title": "Idempotent cellular automata and their natural order",
        "rating": "-10",
        "keywords": [],
        "abstract": "Motivated by the search for idempotent cellular automata (CA), we study CA that act almost as the identity unless they read a fixed pattern $p$. We show that constant and symmetrical patterns always produce idempotent CA, and we characterize the quasi-constant patterns that produce idempotent CA. Our results are valid for CA over an arbitrary group $G$. Moreover, we study the semigroup theoretic natural partial order defined on idempotent CA. If $G$ is infinite, we prove that there is an infinite independent set of idempotent CA, and if $G$ has an element of infinite order, we prove that there is an infinite increasing chain of idempotent CA.",
        "subjects": [
            "math.GR",
            "cs.FL",
            "nlin.CG"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2401.09605",
        "abstract url": "https://arxiv.org/abs/2401.09605",
        "title": "Charting a Path to Efficient Onboarding: The Role of Software Visualization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Background. Within the software industry, it is commonly estimated that software professionals invest a substantial portion of their work hours in the process of understanding existing systems. In this context, an ineffective technical onboarding process, which introduces newcomers to software under development, can result in a prolonged period for them to absorb the necessary knowledge required to become productive in their roles. Goal. The present study aims to explore the familiarity of managers, leaders, and developers with software visualization tools and how these tools are employed to facilitate the technical onboarding of new team members. Method. To address the research problem, we built upon the insights gained through the literature and embraced a sequential exploratory approach. This approach incorporated quantitative and qualitative analyses of data collected from practitioners using questionnaires and semi-structured interviews. Findings. Our findings demonstrate a gap between the concept of software visualization and the practical use of onboarding tools and techniques. Overall, practitioners do not systematically incorporate software visualization tools into their technical onboarding processes due to a lack of conceptual understanding and awareness of their potential benefits. Conclusion. The software industry could benefit from standardized and evolving onboarding models, improved by incorporating software visualization techniques and tools to support program comprehension of newcomers in the software projects.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09608",
        "abstract url": "https://arxiv.org/abs/2401.09608",
        "title": "Hidden Populations in Software Engineering: Challenges, Lessons Learned, and Opportunities",
        "rating": "-10",
        "keywords": [],
        "abstract": "The growing emphasis on studying equity, diversity, and inclusion within software engineering has amplified the need to explore hidden populations within this field. Exploring hidden populations becomes important to obtain invaluable insights into the experiences, challenges, and perspectives of underrepresented groups in software engineering and, therefore, devise strategies to make the software industry more diverse. However, studying these hidden populations presents multifaceted challenges, including the complexities associated with identifying and engaging participants due to their marginalized status. In this paper, we discuss our experiences and lessons learned while conducting multiple studies involving hidden populations in software engineering. We emphasize the importance of recognizing and addressing these challenges within the software engineering research community to foster a more inclusive and comprehensive understanding of diverse populations of software professionals.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09620",
        "abstract url": "https://arxiv.org/abs/2401.09620",
        "title": "Cost-effective and performant virtual WANs with CORNIFER",
        "rating": "-10",
        "keywords": [],
        "abstract": "Virtual wide-area networks (WANs) are WAN-as-a-service cloud offerings that aim to bring the performance benefits of dedicated wide-area interconnects to enterprise customers. In this work, we show that the topology of a virtual WAN can render it both performance and cost inefficient. We develop Cornifer, a tool that designs virtual WAN topologies by deciding the number of virtual WAN nodes and their location in the cloud to minimize connection latency at low cost to enterprises. By leveraging millions of latency measurements from vantage points across the world to cloud points of presence, Cornifer designs virtual WAN topologies that improve weighted client latency by 26% and lower cost by 28% compared to the state-of-the-art. Cornifer identifies virtual WAN topologies at the Pareto frontier of the deployment cost vs. connection latency trade-off and proposes a heuristic for automatic selection of Pareto-optimal virtual WAN topologies for enterprises.",
        "subjects": [
            "cs.NI",
            "cs.PF"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2401.09621",
        "abstract url": "https://arxiv.org/abs/2401.09621",
        "title": "XTable in Action: Seamless Interoperability in Data Lakes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Contemporary approaches to data management are increasingly relying on unified analytics and AI platforms to foster collaboration, interoperability, seamless access to reliable data, and high performance. Data Lakes featuring open standard table formats such as Delta Lake, Apache Hudi, and Apache Iceberg are central components of these data architectures. Choosing the right format for managing a table is crucial for achieving the objectives mentioned above. The challenge lies in selecting the best format, a task that is onerous and can yield temporary results, as the ideal choice may shift over time with data growth, evolving workloads, and the competitive development of table formats and processing engines. Moreover, restricting data access to a single format can hinder data sharing resulting in diminished business value over the long term. The ability to seamlessly interoperate between formats and with negligible overhead can effectively address these challenges. Our solution in this direction is an innovative omni-directional translator, XTable, that facilitates writing data in one format and reading it in any format, thus achieving the desired format interoperability. In this work, we demonstrate the effectiveness of XTable through application scenarios inspired by real-world use cases.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09628",
        "abstract url": "https://arxiv.org/abs/2401.09628",
        "title": "Polynomial Convergence of Bandit No-Regret Dynamics in Congestion Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce an online learning algorithm in the bandit feedback model that, once adopted by all agents of a congestion game, results in game-dynamics that converge to an $\u03b5$-approximate Nash Equilibrium in a polynomial number of rounds with respect to $1/\u03b5$, the number of players and the number of available resources. The proposed algorithm also guarantees sublinear regret to any agent adopting it. As a result, our work answers an open question from arXiv:2206.01880 and extends the recent results of arXiv:2306.15543 to the bandit feedback model. We additionally establish that our online learning algorithm can be implemented in polynomial time for the important special case of Network Congestion Games on Directed Acyclic Graphs (DAG) by constructing an exact $1$-barycentric spanner for DAGs.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09654",
        "abstract url": "https://arxiv.org/abs/2401.09654",
        "title": "User Study: Comparison of Picture Passwords and Current Login Approaches",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this research, we conduct a user study that compares different computer/system authentication methods. More specifically, we look into comparing regular password authentication with picture authentication. Picture authentication means selecting a sequence of pictures from a set of pictures (30). We present users with both interfaces; various metrics are tracked while the participants conduct a variety of user authentication-related tasks. Other metrics include user perception of security with such technologies.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09670",
        "abstract url": "https://arxiv.org/abs/2401.09670",
        "title": "DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving",
        "rating": "-10",
        "keywords": [],
        "abstract": "DistServe improves the performance of large language models (LLMs) serving by disaggregating the prefill and decoding computation. Existing LLM serving systems colocate the two phases and batch the computation of prefill and decoding across all users and requests. We find that this strategy not only leads to strong prefill-decoding interferences but also couples the resource allocation and parallelism plans for both phases. LLM applications often emphasize individual latency for each phase: time to first token (TTFT) for the prefill phase and time per output token (TPOT) of each request for the decoding phase. In the presence of stringent latency requirements, existing systems have to prioritize one latency over the other, or over-provision compute resources to meet both. DistServe assigns prefill and decoding computation to different GPUs, hence eliminating prefill-decoding interferences. Given the application's TTFT and TPOT requirements, DistServe co-optimizes the resource allocation and parallelism strategy tailored for each phase. DistServe also places the two phases according to the serving cluster's bandwidth to minimize the communication caused by disaggregation. As a result, DistServe significantly improves LLM serving performance in terms of the maximum rate that can be served within both TTFT and TPOT constraints on each GPU. Our evaluations show that on various popular LLMs, applications, and latency requirements, DistServe can serve 4.48x more requests or 10.2x tighter SLO, compared to state-of-the-art systems, while staying within latency constraints for > 90% of requests.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.09685",
        "abstract url": "https://arxiv.org/abs/2401.09685",
        "title": "Decades of Transformation: Evolution of the NASA Astrophysics Data System's Infrastructure",
        "rating": "-10",
        "keywords": [],
        "abstract": "The NASA Astrophysics Data System (ADS) is the primary Digital Library portal for researchers in astronomy and astrophysics. Over the past 30 years, the ADS has gone from being an astronomy-focused bibliographic database to an open digital library system supporting research in space and (soon) earth sciences. This paper describes the evolution of the ADS system, its capabilities, and the technological infrastructure underpinning it. We give an overview of the ADS's original architecture, constructed primarily around simple database models. This bespoke system allowed for the efficient indexing of metadata and citations, the digitization and archival of full-text articles, and the rapid development of discipline-specific capabilities running on commodity hardware. The move towards a cloud-based microservices architecture and an open-source search engine in the late 2010s marked a significant shift, bringing full-text search capabilities, a modern API, higher uptime, more reliable data retrieval, and integration of advanced visualizations and analytics. Another crucial evolution came with the gradual and ongoing incorporation of Machine Learning and Natural Language Processing algorithms in our data pipelines. Originally used for information extraction and classification tasks, NLP and ML techniques are now being developed to improve metadata enrichment, search, notifications, and recommendations. we describe how these computational techniques are being embedded into our software infrastructure, the challenges faced, and the benefits reaped. Finally, we conclude by describing the future prospects of ADS and its ongoing expansion, discussing the challenges of managing an interdisciplinary information system in the era of AI and Open Science, where information is abundant, technology is transformative, but their trustworthiness can be elusive.",
        "subjects": [
            "astro-ph.IM",
            "cs.DL"
        ],
        "comment": "10 pages, 3 figures, submitted to the ADASS 2023 proceedings"
    },
    {
        "paper id": "2401.09694",
        "abstract url": "https://arxiv.org/abs/2401.09694",
        "title": "A Multi-Area Architecture for Real-Time Feedback-Based Optimization of Distribution Grids",
        "rating": "-10",
        "keywords": [],
        "abstract": "A challenge in transmission-distribution coordination is how to quickly and reliably coordinate Distributed Energy Resources (DERs) across large multi-stakeholder Distribution Networks (DNs) to support the Transmission Network (TN), while ensuring operational constraints continue to be met within the DN. Here we propose a hierarchical feedback-based control architecture for coordination of DERs in DNs, enabling the DN to quickly respond to power set-point requests from the Transmission System Operator (TSO) while maintaining local DN constraints. Our scheme allows for multiple independently-managed areas within the DN to optimize their local resources while coordinating to support the TN, and while maintaining data privacy; the only required inter-area communication is between physically adjacent areas within the DN control hierarchy. We conduct a rigorous stability analysis, establishing intuitive conditions for closed-loop stability, and provide detailed tuning recommendations. The proposal is validated via case studies on multiple feeders, including IEEE-123 and IEEE-8500, using a custom MATLAB-based application which integrates with OpenDSS. The simulation results show that the proposed structure is highly scalable and can quickly coordinate DERs in response to TSO commands, while responding to local disturbances within the DN and maintaining DN operational limits.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "13 pages, 11 figures, for the supplement document (pdf), see https://1drv.ms/b/s!AmH_VfOdVVKazYUpDEVplHjtvj-7ZA?e=oyfXD4"
    },
    {
        "paper id": "2401.09706",
        "abstract url": "https://arxiv.org/abs/2401.09706",
        "title": "A HPC Co-Scheduler with Reinforcement Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although High Performance Computing (HPC) users understand basic resource requirements such as the number of CPUs and memory limits, internal infrastructural utilization data is exclusively leveraged by cluster operators, who use it to configure batch schedulers. This task is challenging and increasingly complex due to ever larger cluster scales and heterogeneity of modern scientific workflows. As a result, HPC systems achieve low utilization with long job completion times (makespans). To tackle these challenges, we propose a co-scheduling algorithm based on an adaptive reinforcement learning algorithm, where application profiling is combined with cluster monitoring. The resulting cluster scheduler matches resource utilization to application performance in a fine-grained manner (i.e., operating system level). As opposed to nominal allocations, we apply decision trees to model applications' actual resource usage, which are used to estimate how much resource capacity from one allocation can be co-allocated to additional applications. Our algorithm learns from incorrect co-scheduling decisions and adapts from changing environment conditions, and evaluates when such changes cause resource contention that impacts quality of service metrics such as jobs slowdowns. We integrate our algorithm in an HPC resource manager that combines Slurm and Mesos for job scheduling and co-allocation, respectively. Our experimental evaluation performed in a dedicated cluster executing a mix of four real different scientific workflows demonstrates improvements on cluster utilization of up to 51% even in high load scenarios, with 55% average queue makespan reductions under low loads.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    }
]