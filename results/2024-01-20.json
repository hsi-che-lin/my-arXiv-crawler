[
    {
        "paper id": "2401.11124",
        "abstract url": "https://arxiv.org/abs/2401.11124",
        "title": "EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Multitask learning (MTL) has gained prominence for its ability to jointly predict multiple tasks, achieving better per-task performance while using fewer per-task model parameters than single-task learning. More recently, decoder-focused architectures have considerably improved multitask performance by refining task predictions using the features of other related tasks. However, most of these refinement methods fail to simultaneously capture local and global task-specific representations, as well as cross-task patterns in a parameter-efficient manner. In this paper, we introduce the Efficient Multitask Affinity Learning Network (EMA-Net), which is a lightweight framework that enhances the task refinement capabilities of multitask networks. EMA-Net adeptly captures local, global, and cross-task interactions using our novel Cross-Task Affinity Learning (CTAL) module. The key innovation of CTAL lies in its ability to manipulate task affinity matrices in a manner that is optimally suited to apply parameter-efficient grouped convolutions without worrying about information loss. Our results show that we achieve state-of-the-art MTL performance for CNN-based decoder-focused models while using substantially fewer model parameters. Our code is publicly available at https://github.com/Armanfard-Lab/EMA-Net.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11228",
        "abstract url": "https://arxiv.org/abs/2401.11228",
        "title": "Unifying Visual and Vision-Language Tracking via Contrastive Learning",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Single object tracking aims to locate the target object in a video sequence according to the state specified by different modal references, including the initial bounding box (BBOX), natural language (NL), or both (NL+BBOX). Due to the gap between different modalities, most existing trackers are designed for single or partial of these reference settings and overspecialize on the specific modality. Differently, we present a unified tracker called UVLTrack, which can simultaneously handle all three reference settings (BBOX, NL, NL+BBOX) with the same parameters. The proposed UVLTrack enjoys several merits. First, we design a modality-unified feature extractor for joint visual and language feature learning and propose a multi-modal contrastive loss to align the visual and language features into a unified semantic space. Second, a modality-adaptive box head is proposed, which makes full use of the target reference to mine ever-changing scenario features dynamically from video contexts and distinguish the target in a contrastive way, enabling robust performance in different reference settings. Extensive experimental results demonstrate that UVLTrack achieves promising performance on seven visual tracking datasets, three vision-language tracking datasets, and three visual grounding datasets. Codes and models will be open-sourced at https://github.com/OpenSpaceAI/UVLTrack.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11316",
        "abstract url": "https://arxiv.org/abs/2401.11316",
        "title": "PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the proliferation of large pre-trained language models (PLMs), fine-tuning all model parameters becomes increasingly inefficient, particularly when dealing with numerous downstream tasks that entail substantial training and storage costs. Several approaches aimed at achieving parameter-efficient fine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA) stands out as an archetypal method, incorporating trainable rank decomposition matrices into each target module. Nevertheless, LoRA does not consider the varying importance of each layer. To address these challenges, we introduce PRILoRA, which linearly allocates a different rank for each layer, in an increasing manner, and performs pruning throughout the training process, considering both the temporary magnitude of weights and the accumulated statistics of the input to any given layer. We validate the effectiveness of PRILoRA through extensive experiments on eight GLUE benchmarks, setting a new state of the art.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "EACL 2024"
    },
    {
        "paper id": "2401.11337",
        "abstract url": "https://arxiv.org/abs/2401.11337",
        "title": "Prompting Large Vision-Language Models for Compositional Reasoning",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Vision-language models such as CLIP have shown impressive capabilities in encoding texts and images into aligned embeddings, enabling the retrieval of multimodal data in a shared embedding space. However, these embedding-based models still face challenges in effectively matching images and texts with similar visio-linguistic compositionality, as evidenced by their performance on the recent Winoground dataset. In this paper, we argue that this limitation stems from two factors: the use of single vector representations for complex multimodal data, and the absence of step-by-step reasoning in these embedding-based methods. To address this issue, we make an exploratory step using a novel generative method that prompts large vision-language models (e.g., GPT-4) to depict images and perform compositional reasoning. Our method outperforms other embedding-based methods on the Winoground dataset, and obtains further improvement of up to 10% accuracy when enhanced with the optimal description.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11170",
        "abstract url": "https://arxiv.org/abs/2401.11170",
        "title": "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images",
        "rating": "1.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "attack"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Large vision-language models (VLMs) such as GPT-4 have achieved exceptional performance across various multi-modal tasks. However, the deployment of VLMs necessitates substantial energy consumption and computational resources. Once attackers maliciously induce high energy consumption and latency time (energy-latency cost) during inference of VLMs, it will exhaust computational resources. In this paper, we explore this attack surface about availability of VLMs and aim to induce high energy-latency cost during inference of VLMs. We find that high energy-latency cost during inference of VLMs can be manipulated by maximizing the length of generated sequences. To this end, we propose verbose images, with the goal of crafting an imperceptible perturbation to induce VLMs to generate long sentences during inference. Concretely, we design three loss objectives. First, a loss is proposed to delay the occurrence of end-of-sequence (EOS) token, where EOS token is a signal for VLMs to stop generating further tokens. Moreover, an uncertainty loss and a token diversity loss are proposed to increase the uncertainty over each generated token and the diversity among all tokens of the whole generated sequence, respectively, which can break output dependency at token-level and sequence-level. Furthermore, a temporal weight adjustment algorithm is proposed, which can effectively balance these losses. Extensive experiments demonstrate that our verbose images can increase the length of generated sequences by 7.87 times and 8.56 times compared to original images on MS-COCO and ImageNet datasets, which presents potential challenges for various applications. Our code is available at https://github.com/KuofengGao/Verbose_Images.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": "Accepted by ICLR 2024"
    },
    {
        "paper id": "2401.11349",
        "abstract url": "https://arxiv.org/abs/2401.11349",
        "title": "Asynchronous Parallel Reinforcement Learning for Optimizing Propulsive Performance in Fin Ray Control",
        "rating": "1.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fish fin rays constitute a sophisticated control system for ray-finned fish, facilitating versatile locomotion within complex fluid environments. Despite extensive research on the kinematics and hydrodynamics of fish locomotion, the intricate control strategies in fin-ray actuation remain largely unexplored. While deep reinforcement learning (DRL) has demonstrated potential in managing complex nonlinear dynamics; its trial-and-error nature limits its application to problems involving computationally demanding environmental interactions. This study introduces a cutting-edge off-policy DRL algorithm, interacting with a fluid-structure interaction (FSI) environment to acquire intricate fin-ray control strategies tailored for various propulsive performance objectives. To enhance training efficiency and enable scalable parallelism, an innovative asynchronous parallel training (APT) strategy is proposed, which fully decouples FSI environment interactions and policy/value network optimization. The results demonstrated the success of the proposed method in discovering optimal complex policies for fin-ray actuation control, resulting in a superior propulsive performance compared to the optimal sinusoidal actuation function identified through a parametric grid search. The merit and effectiveness of the APT approach are also showcased through comprehensive comparison with conventional DRL training strategies in numerical experiments of controlling nonlinear dynamics.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "37 pages, 12 figures"
    },
    {
        "paper id": "2401.10967",
        "abstract url": "https://arxiv.org/abs/2401.10967",
        "title": "HOSC: A Periodic Activation Function for Preserving Sharp Features in Implicit Neural Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recently proposed methods for implicitly representing signals such as images, scenes, or geometries using coordinate-based neural network architectures often do not leverage the choice of activation functions, or do so only to a limited extent. In this paper, we introduce the Hyperbolic Oscillation function (HOSC), a novel activation function with a controllable sharpness parameter. Unlike any previous activations, HOSC has been specifically designed to better capture sudden changes in the input signal, and hence sharp or acute features of the underlying data, as well as smooth low-frequency transitions. Due to its simplicity and modularity, HOSC offers a plug-and-play functionality that can be easily incorporated into any existing method employing a neural network as a way of implicitly representing a signal. We benchmark HOSC against other popular activations in an array of general tasks, empirically showing an improvement in the quality of obtained representations, provide the mathematical motivation behind the efficacy of HOSC, and discuss its limitations.",
        "subjects": [
            "cs.NE",
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2401.11140",
        "abstract url": "https://arxiv.org/abs/2401.11140",
        "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt object detectors efficiently with only few annotated samples. Fine-tuning has been shown to be an effective and practical approach. However, previous works often take the classical base-novel two stage fine-tuning procedure but ignore the implicit stability-plasticity contradiction among different modules. Specifically, the random re-initialized classifiers need more plasticity to adapt to novel samples. The other modules inheriting pre-trained weights demand more stability to reserve their class-agnostic knowledge. Regular fine-tuning which couples the optimization of these two parts hurts the model generalization in FSOD scenarios. In this paper, we find that this problem is prominent in the end-to-end object detector Sparse R-CNN for its multi-classifier cascaded architecture. We propose to mitigate this contradiction by a new three-stage fine-tuning procedure by introducing an addtional plasticity classifier fine-tuning(PCF) stage. We further design the multi-source ensemble(ME) technique to enhance the generalization of the model in the final fine-tuning stage. Extensive experiments verify that our method is effective in regularizing Sparse R-CNN, outperforming previous methods in the FSOD benchmark.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11143",
        "abstract url": "https://arxiv.org/abs/2401.11143",
        "title": "Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy across a diverse range of tasks, including emotion recognition in speech, image classification, and text classification, thereby establishing its robustness and versatility in handling multi-modal data. Furthermore, we introduce the Importance Factor (IF), a new learning-based metric that enhances the explainability of models trained with GAAM-based methods. Overall, GAAM represents an advancement towards development of better performing and more explainable attention models across multiple modalities.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.SD",
            "eess.AS",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11144",
        "abstract url": "https://arxiv.org/abs/2401.11144",
        "title": "Towards Open-World Gesture Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Static machine learning methods in gesture recognition assume that training and test data come from the same underlying distribution. However, in real-world applications involving gesture recognition on wrist-worn devices, data distribution may change over time. We formulate this problem of adapting recognition models to new tasks, where new data patterns emerge, as open-world gesture recognition (OWGR). We propose leveraging continual learning to make machine learning models adaptive to new tasks without degrading performance on previously learned tasks. However, the exploration of parameters for questions around when and how to train and deploy recognition models requires time-consuming user studies and is sometimes impractical. To address this challenge, we propose a design engineering approach that enables offline analysis on a collected large-scale dataset with various parameters and compares different continual learning methods. Finally, design guidelines are provided to enhance the development of an open-world wrist-worn gesture recognition process.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11150",
        "abstract url": "https://arxiv.org/abs/2401.11150",
        "title": "Simultaneous Gesture Classification and Localization with an Automatic Gesture Annotation Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Training a real-time gesture recognition model heavily relies on annotated data. However, manual data annotation is costly and demands substantial human effort. In order to address this challenge, we propose a novel annotation model that can automatically annotate gesture classes and identify their temporal ranges. Our ablation study demonstrates that our annotation model design surpasses the baseline in terms of both gesture classification accuracy (3-4\\% improvement) and localization accuracy (71-75\\% improvement). We believe that this annotation model has immense potential to improve the training of downstream gesture recognition models using unlabeled datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11185",
        "abstract url": "https://arxiv.org/abs/2401.11185",
        "title": "How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Dynamic adversarial question generation, where humans write examples to stump a model, aims to create examples that are realistic and informative. However, the advent of large language models (LLMs) has been a double-edged sword for human authors: more people are interested in seeing and pushing the limits of these models, but because the models are so much stronger an opponent, they are harder to defeat. To understand how these models impact adversarial question writing process, we enrich the writing guidance with LLMs and retrieval models for the authors to reason why their questions are not adversarial. While authors could create interesting, challenging adversarial questions, they sometimes resort to tricks that result in poor questions that are ambiguous, subjective, or confusing not just to a computer but also to humans. To address these issues, we propose new metrics and incentives for eliciting good, challenging questions and present a new dataset of adversarially authored questions.",
        "subjects": [
            "cs.CL",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11199",
        "abstract url": "https://arxiv.org/abs/2401.11199",
        "title": "Projected Belief Networks With Discriminative Alignment for Acoustic Event Classification: Rivaling State of the Art CNNs",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The projected belief network (PBN) is a generative stochastic network with tractable likelihood function based on a feed-forward neural network (FFNN). The generative function operates by \"backing up\" through the FFNN. The PBN is two networks in one, a FFNN that operates in the forward direction, and a generative network that operates in the backward direction. Both networks co-exist based on the same parameter set, have their own cost functions, and can be separately or jointly trained. The PBN therefore has the potential to possess the best qualities of both discriminative and generative classifiers. To realize this potential, a separate PBN is trained on each class, maximizing the generative likelihood function for the given class, while minimizing the discriminative cost for the FFNN against \"all other classes\". This technique, called discriminative alignment (PBN-DA), aligns the contours of the likelihood function to the decision boundaries and attains vastly improved classification performance, rivaling that of state of the art discriminative networks. The method may be further improved using a hidden Markov model (HMM) as a component of the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment of PBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classification experiments are provided. The first experiment uses air-acoustic events, and the second uses underwater acoustic data consisting of marine mammal calls. In both experiments, PBN-DA-HMM attains comparable or better performance as a state of the art CNN, and attain a factor of two error reduction when combined with the CNN.",
        "subjects": [
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "15 Pages. Submitted to IEEE-TNNLS"
    },
    {
        "paper id": "2401.11207",
        "abstract url": "https://arxiv.org/abs/2401.11207",
        "title": "Unfair TOS: An Automated Approach using Customized BERT",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Terms of Service (ToS) form an integral part of any agreement as it defines the legal relationship between a service provider and an end-user. Not only do they establish and delineate reciprocal rights and responsibilities, but they also provide users with information on essential aspects of contracts that pertain to the use of digital spaces. These aspects include a wide range of topics, including limitation of liability, data protection, etc. Users tend to accept the ToS without going through it before using any application or service. Such ignorance puts them in a potentially weaker situation in case any action is required. Existing methodologies for the detection or classification of unfair clauses are however obsolete and show modest performance. In this research paper, we present SOTA(State of The Art) results on unfair clause detection from ToS documents based on unprecedented custom BERT Fine-tuning in conjunction with SVC(Support Vector Classifier). The study shows proficient performance with a macro F1-score of 0.922 at unfair clause detection, and superior performance is also shown in the classification of unfair clauses by each tag. Further, a comparative analysis is performed by answering research questions on the Transformer models utilized. In order to further research and experimentation the code and results are made available on https://github.com/batking24/Unfair-TOS-An-Automated-Approach-based-on-Fine-tuning-BERT-in-conjunction-with-ML.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11218",
        "abstract url": "https://arxiv.org/abs/2401.11218",
        "title": "End-to-End Argument Mining over Varying Rhetorical Structures",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Rhetorical Structure Theory implies no single discourse interpretation of a text, and the limitations of RST parsers further exacerbate inconsistent parsing of similar structures. Therefore, it is important to take into account that the same argumentative structure can be found in semantically similar texts with varying rhetorical structures. In this work, the differences between paraphrases within the same argument scheme are evaluated from a rhetorical perspective. The study proposes a deep dependency parsing model to assess the connection between rhetorical and argument structures. The model utilizes rhetorical relations; RST structures of paraphrases serve as training data augmentations. The method allows for end-to-end argumentation analysis using a rhetorical tree instead of a word sequence. It is evaluated on the bilingual Microtexts corpus, and the first results on fully-fledged argument parsing for the Russian version of the corpus are reported. The results suggest that argument mining can benefit from multiple variants of discourse structure.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11237",
        "abstract url": "https://arxiv.org/abs/2401.11237",
        "title": "Closing the Gap between TD Learning and Supervised Learning -- A Generalisation Point of View",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Some reinforcement learning (RL) algorithms can stitch pieces of experience to solve a task never seen before during training. This oft-sought property is one of the few ways in which RL methods based on dynamic-programming differ from RL methods based on supervised-learning (SL). Yet, certain RL methods based on off-the-shelf SL algorithms achieve excellent results without an explicit mechanism for stitching; it remains unclear whether those methods forgo this important stitching property. This paper studies this question for the problems of achieving a target goal state and achieving a target return value. Our main result is to show that the stitching property corresponds to a form of combinatorial generalization: after training on a distribution of (state, goal) pairs, one would like to evaluate on (state, goal) pairs not seen together in the training data. Our analysis shows that this sort of generalization is different from i.i.d. generalization. This connection between stitching and generalisation reveals why we should not expect SL-based RL methods to perform stitching, even in the limit of large datasets and models. Based on this analysis, we construct new datasets to explicitly test for this property, revealing that SL-based methods lack this stitching property and hence fail to perform combinatorial generalization. Nonetheless, the connection between stitching and combinatorial generalisation also suggests a simple remedy for improving generalisation in SL: data augmentation. We propose a temporal data augmentation and demonstrate that adding it to SL-based methods enables them to successfully complete tasks not seen together during training. On a high level, this connection illustrates the importance of combinatorial generalization for data efficiency in time-series data beyond tasks beyond RL, like audio, video, or text.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR 2024, Project code: https://github.com/RajGhugare19/stitching-is-combinatorial-generalisation"
    },
    {
        "paper id": "2401.11243",
        "abstract url": "https://arxiv.org/abs/2401.11243",
        "title": "LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise Relevance Propagation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision transformers (ViTs) have demonstrated remarkable performance across various visual tasks. However, ViT models suffer from substantial computational and memory requirements, making it challenging to deploy them on resource-constrained platforms. Quantization is a popular approach for reducing model size, but most studies mainly focus on equal bit-width quantization for the entire network, resulting in sub-optimal solutions. While there are few works on mixed precision quantization (MPQ) for ViTs, they typically rely on search space-based methods or employ mixed precision arbitrarily. In this paper, we introduce LRP-QViT, an explainability-based method for assigning mixed-precision bit allocations to different layers based on their importance during classification. Specifically, to measure the contribution score of each layer in predicting the target class, we employ the Layer-wise Relevance Propagation (LRP) method. LRP assigns local relevance at the output layer and propagates it through all layers, distributing the relevance until it reaches the input layers. These relevance scores serve as indicators for computing the layer contribution score. Additionally, we have introduced a clipped channel-wise quantization aimed at eliminating outliers from post-LayerNorm activations to alleviate severe inter-channel variations. To validate and assess our approach, we employ LRP-QViT across ViT, DeiT, and Swin transformer models on various datasets. Our experimental findings demonstrate that both our fixed-bit and mixed-bit post-training quantization methods surpass existing models in the context of 4-bit and 6-bit quantization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11246",
        "abstract url": "https://arxiv.org/abs/2401.11246",
        "title": "Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose a natural language prompt-based retrieval augmented generation (Prompt-RAG), a novel approach to enhance the performance of generative large language models (LLMs) in niche domains. Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain. To explore and exemplify this point, we compared vector embeddings from Korean Medicine (KM) and Conventional Medicine (CM) documents, finding that KM document embeddings correlated more with token overlaps and less with human-assessed document relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from conventional RAG models, operates without the need for embedding vectors. Its performance was assessed through a Question-Answering (QA) chatbot application, where responses were evaluated for relevance, readability, and informativeness. The results showed that Prompt-RAG outperformed existing models, including ChatGPT and conventional vector embedding-based RAGs, in terms of relevance and informativeness. Despite challenges like content structuring and response latency, the advancements in LLMs are expected to encourage the use of Prompt-RAG, making it a promising tool for other domains in need of RAG methods.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "26 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2401.11248",
        "abstract url": "https://arxiv.org/abs/2401.11248",
        "title": "Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Masked auto-encoder pre-training has emerged as a prevalent technique for initializing and enhancing dense retrieval systems. It generally utilizes additional Transformer decoder blocks to provide sustainable supervision signals and compress contextual information into dense representations. However, the underlying reasons for the effectiveness of such a pre-training technique remain unclear. The usage of additional Transformer-based decoders also incurs significant computational costs. In this study, we aim to shed light on this issue by revealing that masked auto-encoder (MAE) pre-training with enhanced decoding significantly improves the term coverage of input tokens in dense representations, compared to vanilla BERT checkpoints. Building upon this observation, we propose a modification to the traditional MAE by replacing the decoder of a masked auto-encoder with a completely simplified Bag-of-Word prediction task. This modification enables the efficient compression of lexical signals into dense representations through unsupervised pre-training. Remarkably, our proposed method achieves state-of-the-art retrieval performance on several large-scale retrieval benchmarks without requiring any additional parameters, which provides a 67% training speed-up compared to standard masked auto-encoder pre-training with enhanced decoding.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": "Accepted by SIGIR24. Our code is available at https://github.com/ma787639046/bowdpr"
    },
    {
        "paper id": "2401.11268",
        "abstract url": "https://arxiv.org/abs/2401.11268",
        "title": "Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In the realm of automatic speech recognition (ASR), the quest for models that not only perform with high accuracy but also offer transparency in their decision-making processes is crucial. The potential of quality estimation (QE) metrics is introduced and evaluated as a novel tool to enhance explainable artificial intelligence (XAI) in ASR systems. Through experiments and analyses, the capabilities of the NoRefER (No Reference Error Rate) metric are explored in identifying word-level errors to aid post-editors in refining ASR hypotheses. The investigation also extends to the utility of NoRefER in the corpus-building process, demonstrating its effectiveness in augmenting datasets with insightful annotations. The diagnostic aspects of NoRefER are examined, revealing its ability to provide valuable insights into model behaviors and decision patterns. This has proven beneficial for prioritizing hypotheses in post-editing workflows and fine-tuning ASR models. The findings suggest that NoRefER is not merely a tool for error detection but also a comprehensive framework for enhancing ASR systems' transparency, efficiency, and effectiveness. To ensure the reproducibility of the results, all source codes of this study are made publicly available.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11270",
        "abstract url": "https://arxiv.org/abs/2401.11270",
        "title": "RoTIR: Rotation-Equivariant Network and Transformers for Fish Scale Image Registration",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Image registration is an essential process for aligning features of interest from multiple images. With the recent development of deep learning techniques, image registration approaches have advanced to a new level. In this work, we present 'Rotation-Equivariant network and Transformers for Image Registration' (RoTIR), a deep-learning-based method for the alignment of fish scale images captured by light microscopy. This approach overcomes the challenge of arbitrary rotation and translation detection, as well as the absence of ground truth data. We employ feature-matching approaches based on Transformers and general E(2)-equivariant steerable CNNs for model creation. Besides, an artificial training dataset is employed for semi-supervised learning. Results show RoTIR successfully achieves the goal of fish scale image registration.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "7 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2401.11305",
        "abstract url": "https://arxiv.org/abs/2401.11305",
        "title": "Progress in Privacy Protection: A Review of Privacy Preserving Techniques in Recommender Systems, Edge Computing, and Cloud Computing",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As digital technology evolves, the increasing use of connected devices brings both challenges and opportunities in the areas of mobile crowdsourcing, edge computing, and recommender systems. This survey focuses on these dynamic fields, emphasizing the critical need for privacy protection in our increasingly data-oriented world. It explores the latest trends in these interconnected areas, with a special emphasis on privacy and data security. Our method involves an in-depth analysis of various academic works, which helps us to gain a comprehensive understanding of these sectors and their shifting focus towards privacy concerns. We present new insights and marks a significant advancement in addressing privacy issues within these technologies. The survey is a valuable resource for researchers, industry practitioners, and policy makers, offering an extensive overview of these fields and their related privacy challenges, catering to a wide audience in the modern digital era.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11311",
        "abstract url": "https://arxiv.org/abs/2401.11311",
        "title": "A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the rapid evolution of computer vision has seen the emergence of various foundation models, each tailored to specific data types and tasks. In this study, we explore the adaptation of these models for few-shot semantic segmentation. Specifically, we conduct a comprehensive comparative analysis of four prominent foundation models: DINO V2, Segment Anything, CLIP, Masked AutoEncoders, and of a straightforward ResNet50 pre-trained on the COCO dataset. We also include 5 adaptation methods, ranging from linear probing to fine tuning. Our findings show that DINO V2 outperforms other models by a large margin, across various datasets and adaptation methods. On the other hand, adaptation methods provide little discrepancy in the obtained results, suggesting that a simple linear probing can compete with advanced, more computationally intensive, alternatives",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11323",
        "abstract url": "https://arxiv.org/abs/2401.11323",
        "title": "Identifying and Analyzing Task-Encoding Tokens in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In-context learning (ICL) has become an effective solution for few-shot learning in natural language processing. However, our understanding of ICL's working mechanisms is limited, specifically regarding how models learn to perform tasks from ICL demonstrations. For example, unexpectedly large changes in performance can arise from small changes in the prompt, leaving prompt design a largely empirical endeavour. In this paper, we investigate this problem by identifying and analyzing task-encoding tokens on whose representations the task performance depends. Using experiments that ablate the representations of different token types, we find that template and stopword tokens are the most prone to be task-encoding. In addition, we demonstrate experimentally that lexical meaning, repetition, and text formatting are the main distinguishing characteristics of these tokens. Our work sheds light on how large language models (LLMs) learn to perform a task from demonstrations, deepens our understanding of the varied roles different types of tokens play in LLMs, and provides insights for avoiding instability from improperly utilizing task-encoding tokens.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2401.11356",
        "abstract url": "https://arxiv.org/abs/2401.11356",
        "title": "ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing. To bridge this gap, we propose a new task, language proficiency-oriented lexical substitution. We also introduce ProLex, a novel benchmark designed to assess systems' ability to generate not only appropriate substitutes but also substitutes that demonstrate better language proficiency. Besides the benchmark, we propose models that can automatically perform the new task. We show that our best model, a Llama2-13B model fine-tuned with task-specific synthetic data, outperforms ChatGPT by an average of 3.2% in F-score and achieves comparable results with GPT-4 on ProLex.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "19 pages, 4 figures"
    },
    {
        "paper id": "2401.11358",
        "abstract url": "https://arxiv.org/abs/2401.11358",
        "title": "ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for Autonomous Vehicles",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent breakthroughs in artificial intelligence offer tremendous promise for the development of self-driving applications. Deep Neural Networks, in particular, are being utilized to support the operation of semi-autonomous cars through object identification and semantic segmentation. To assess the inadequacy of the current dataset in the context of autonomous and semi-autonomous cars, we created a new dataset named ANNA. This study discusses a custom-built dataset that includes some unidentified vehicles in the perspective of Bangladesh, which are not included in the existing dataset. A dataset validity check was performed by evaluating models using the Intersection Over Union (IOU) metric. The results demonstrated that the model trained on our custom dataset was more precise and efficient than the models trained on the KITTI or COCO dataset concerning Bangladeshi traffic. The research presented in this paper also emphasizes the importance of developing accurate and efficient object detection algorithms for the advancement of autonomous vehicles.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11361",
        "abstract url": "https://arxiv.org/abs/2401.11361",
        "title": "Revolutionizing API Documentation through Summarization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study tackles the challenges associated with interpreting Application Programming Interface (API) documentation, an integral aspect of software development. Official API documentation, while essential, can be lengthy and challenging to navigate, prompting developers to seek unofficial sources such as Stack Overflow. Leveraging the vast user-generated content on Stack Overflow, including code snippets and discussions, we employ BERTopic and extractive summarization to automatically generate concise and informative API summaries. These summaries encompass key insights like general usage, common developer issues, and potential solutions, sourced from the wealth of knowledge on Stack Overflow. Software developers evaluate these summaries for performance, coherence, and interoperability, providing valuable feedback on the practicality of our approach.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2308.09070"
    },
    {
        "paper id": "2401.11365",
        "abstract url": "https://arxiv.org/abs/2401.11365",
        "title": "Confidence Preservation Property in Knowledge Distillation Abstractions",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Social media platforms prevent malicious activities by detecting harmful content of posts and comments. To that end, they employ large-scale deep neural network language models for sentiment analysis and content understanding. Some models, like BERT, are complex, and have numerous parameters, which makes them expensive to operate and maintain. To overcome these deficiencies, industry experts employ a knowledge distillation compression technique, where a distilled model is trained to reproduce the classification behavior of the original model. The distillation processes terminates when the distillation loss function reaches the stopping criteria. This function is mainly designed to ensure that the original and the distilled models exhibit alike classification behaviors. However, besides classification accuracy, there are additional properties of the original model that the distilled model should preserve to be considered as an appropriate abstraction. In this work, we explore whether distilled TinyBERT models preserve confidence values of the original BERT models, and investigate how this confidence preservation property could guide tuning hyperparameters of the distillation process.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11374",
        "abstract url": "https://arxiv.org/abs/2401.11374",
        "title": "Language Models as Hierarchy Encoders",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Interpreting hierarchical structures latent in language is a key limitation of current language models (LMs). While previous research has implicitly leveraged these hierarchies to enhance LMs, approaches for their explicit encoding are yet to be explored. To address this, we introduce a novel approach to re-train transformer encoder-based LMs as Hierarchy Transformer encoders (HiTs), harnessing the expansive nature of hyperbolic space. Our method situates the output embedding space of pre-trained LMs within a Poincar\u00e9 ball with a curvature that adapts to the embedding dimension, followed by re-training on hyperbolic cluster and centripetal losses. These losses are designed to effectively cluster related entities (input as texts) and organise them hierarchically. We evaluate HiTs against pre-trained and fine-tuned LMs, focusing on their capabilities in simulating transitive inference, predicting subsumptions, and transferring knowledge across hierarchies. The results demonstrate that HiTs consistently outperform both pre-trained and fine-tuned LMs in these tasks, underscoring the effectiveness and transferability of our re-trained hierarchy encoders.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11382",
        "abstract url": "https://arxiv.org/abs/2401.11382",
        "title": "Using Large Language Model for End-to-End Chinese ASR and NER",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Mapping speech tokens to the same feature space as text tokens has become the paradigm for the integration of speech modality into decoder-only large language models (LLMs). An alternative approach is to use an encoder-decoder architecture that incorporates speech features through cross-attention. This approach, however, has received less attention in the literature. In this work, we connect the Whisper encoder with ChatGLM3 and provide in-depth comparisons of these two approaches using Chinese automatic speech recognition (ASR) and name entity recognition (NER) tasks. We evaluate them not only by conventional metrics like the F1 score but also by a novel fine-grained taxonomy of ASR-NER errors. Our experiments reveal that encoder-decoder architecture outperforms decoder-only architecture with a short context, while decoder-only architecture benefits from a long context as it fully exploits all layers of the LLM. By using LLM, we significantly reduced the entity omission errors and improved the entity ASR accuracy compared to the Conformer baseline. Additionally, we obtained a state-of-the-art (SOTA) F1 score of 0.805 on the AISHELL-NER test set by using chain-of-thought (CoT) NER which first infers long-form ASR transcriptions and then predicts NER labels.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "5 pages, 2 figures"
    },
    {
        "paper id": "2401.11396",
        "abstract url": "https://arxiv.org/abs/2401.11396",
        "title": "Visual Imitation Learning with Calibrated Contrastive Representation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Adversarial Imitation Learning (AIL) allows the agent to reproduce expert behavior with low-dimensional states and actions. However, challenges arise in handling visual states due to their less distinguishable representation compared to low-dimensional proprioceptive features. While existing methods resort to adopt complex network architectures or separate the process of learning representation and decision-making, they overlook valuable intra-agent information within demonstrations. To address this problem, this paper proposes a simple and effective solution by incorporating calibrated contrastive representative learning into visual AIL framework. Specifically, we present an image encoder in visual AIL, utilizing a combination of unsupervised and supervised contrastive learning to extract valuable features from visual states. Based on the fact that the improved agent often produces demonstrations of varying quality, we propose to calibrate the contrastive loss by treating each agent demonstrations as a mixed sample. The incorporation of contrastive learning can be jointly optimized with the AIL framework, without modifying the architecture or incurring significant computational costs. Experimental results on DMControl Suite demonstrate our proposed method is sample efficient and can outperform other compared methods from different aspects.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12246",
        "abstract url": "https://arxiv.org/abs/2401.12246",
        "title": "Orion-14B: Open-source Multilingual Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we introduce Orion-14B, a collection of multilingual large language models with 14 billion parameters. We utilize a data scheduling approach to train a foundational model on a diverse corpus of 2.5 trillion tokens, sourced from texts in English, Chinese, Japanese, Korean, and other languages. Additionally, we fine-tuned a series of models tailored for conversational applications and other specific use cases. Our evaluation results demonstrate that Orion-14B achieves state-of-the-art performance across a broad spectrum of tasks. We make the Orion-14B model family and its associated code publicly accessible https://github.com/OrionStarAI/Orion, aiming to inspire future research and practical applications in the field.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Authors are alphabetically listed by last names, except the corresponding author who is listed last"
    },
    {
        "paper id": "2401.12253",
        "abstract url": "https://arxiv.org/abs/2401.12253",
        "title": "Accelerating Sinkhorn Algorithm with Sparse Newton Iterations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Computing the optimal transport distance between statistical distributions is a fundamental task in machine learning. One remarkable recent advancement is entropic regularization and the Sinkhorn algorithm, which utilizes only matrix scaling and guarantees an approximated solution with near-linear runtime. Despite the success of the Sinkhorn algorithm, its runtime may still be slow due to the potentially large number of iterations needed for convergence. To achieve possibly super-exponential convergence, we present Sinkhorn-Newton-Sparse (SNS), an extension to the Sinkhorn algorithm, by introducing early stopping for the matrix scaling steps and a second stage featuring a Newton-type subroutine. Adopting the variational viewpoint that the Sinkhorn algorithm maximizes a concave Lyapunov potential, we offer the insight that the Hessian matrix of the potential function is approximately sparse. Sparsification of the Hessian results in a fast $O(n^2)$ per-iteration complexity, the same as the Sinkhorn algorithm. In terms of total iteration count, we observe that the SNS algorithm converges orders of magnitude faster across a wide range of practical cases, including optimal transportation between empirical distributions and calculating the Wasserstein $W_1, W_2$ distance of discretized densities. The empirical performance is corroborated by a rigorous bound on the approximate sparsity of the Hessian matrix.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "In ICLR 2024"
    },
    {
        "paper id": "2402.01677",
        "abstract url": "https://arxiv.org/abs/2402.01677",
        "title": "Embedding Ontologies via Incorporating Extensional and Intensional Knowledge",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can capture both structure information and textual information. Experimental results show that EIKE significantly outperforms state-of-the-art methods in three datasets for both triple classification and link prediction, indicating that EIKE provides a more comprehensive and representative perspective of the domain.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Submitting to IJCAI2024; 9 pages and 3 figures"
    },
    {
        "paper id": "2402.01679",
        "abstract url": "https://arxiv.org/abs/2402.01679",
        "title": "STICKERCONV: Generating Multimodal Empathetic Responses from Scratch",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Stickers, while widely recognized for enhancing empathetic communication in online interactions, remain underexplored in current empathetic dialogue research, notably due to the challenge of a lack of comprehensive datasets. In this paper, we introduce the Agent for STICKERCONV (Agent4SC), which uses collaborative agent interactions to realistically simulate human behavior with sticker usage, thereby enhancing multimodal empathetic communication. Building on this foundation, we develop a multimodal empathetic dialogue dataset, STICKERCONV, comprising 12.9K dialogue sessions, 5.8K unique stickers, and 2K diverse conversational scenarios. This dataset serves as a benchmark for multimodal empathetic generation. To advance further, we propose PErceive and Generate Stickers (PEGS), a multimodal empathetic response generation framework, complemented by a comprehensive set of empathy evaluation metrics based on LLM. Our experiments demonstrate PEGS's effectiveness in generating contextually relevant and emotionally resonant multimodal empathetic responses, contributing to the advancement of more nuanced and engaging empathetic dialogue systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11116",
        "abstract url": "https://arxiv.org/abs/2401.11116",
        "title": "Promotion of Scientific Publications on ArXiv and X Is on the Rise and Impacts Citations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "In the evolving landscape of scientific publishing, it is important to understand the drivers of high-impact research, to equip scientists with actionable strategies to enhance the reach of their work, and to understand trends in the use modern scientific publishing tools to inform their further development. Here, based on a large dataset of computer science publications, we study trends in the use of early preprint publications and revisions on ArXiv and the use of X (formerly Twitter) for promotion of such papers in the last 10 years. We find that early submission to ArXiv and promotion on X have soared in recent years. Estimating the effect that the use of each of these modern affordances has on the number of citations of scientific publications, we find that in the first 5 years from an initial publication peer-reviewed conference papers submitted early to ArXiv gain on average $21.1 \\pm 17.4$ more citations, revised on ArXiv gain $18.4 \\pm 17.6$ more citations, and promoted on X gain $44.4 \\pm 8$ more citations. Our results show that promoting one's work on ArXiv or X has a large impact on the number of citations, as well as the number of influential citations computed by Semantic Scholar, and thereby on the career of researchers. We discuss the far-reaching implications of these findings for future scientific publishing systems and measures of scientific impact.",
        "subjects": [
            "cs.DL",
            "cs.CY",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11130",
        "abstract url": "https://arxiv.org/abs/2401.11130",
        "title": "Identification and Estimation of Conditional Average Partial Causal Effects via Instrumental Variable",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has been considerable recent interest in estimating heterogeneous causal effects. In this paper, we introduce conditional average partial causal effects (CAPCE) to reveal the heterogeneity of causal effects with continuous treatment. We provide conditions for identifying CAPCE in an instrumental variable setting. We develop three families of CAPCE estimators: sieve, parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze their statistical properties. We illustrate the proposed CAPCE estimators on synthetic and real-world data.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11145",
        "abstract url": "https://arxiv.org/abs/2401.11145",
        "title": "Document Set Expansion with Positive-Unlabeled Learning: A Density Estimation-based Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Document set expansion aims to identify relevant documents from a large collection based on a small set of documents that are on a fine-grained topic. Previous work shows that PU learning is a promising method for this task. However, some serious issues remain unresolved, i.e. typical challenges that PU methods suffer such as unknown class prior and imbalanced data, and the need for transductive experimental settings. In this paper, we propose a novel PU learning framework based on density estimation, called puDE, that can handle the above issues. The advantage of puDE is that it neither constrained to the SCAR assumption and nor require any class prior knowledge. We demonstrate the effectiveness of the proposed method using a series of real-world datasets and conclude that our method is a better alternative for the DSE task.",
        "subjects": [
            "cs.LG",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11188",
        "abstract url": "https://arxiv.org/abs/2401.11188",
        "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoretical study and providing practical guidelines to practitioners relies on Piecewise Affine Splines. In that realm, a DN's input-mapping is expressed as per-region affine mapping where those regions are implicitly determined by the model's architecture and form a partition of their input space. That partition -- which is involved in all the results spanned from this line of research -- has so far only been computed on $2/3$-dimensional slices of the DN's input space or estimated by random sampling. In this paper, we provide the first parallel algorithm that does exact enumeration of the DN's partition regions. The proposed algorithm enables one to finally assess the closeness of the commonly employed approximations methods, e.g. based on random sampling of the DN input space. One of our key finding is that if one is only interested in regions with ``large'' volume, then uniform sampling of the space is highly efficient, but that if one is also interested in discovering the ``small'' regions of the partition, then uniform sampling is exponentially costly with the DN's input space dimension. On the other hand, our proposed method has complexity scaling linearly with input dimension and the number of regions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11196",
        "abstract url": "https://arxiv.org/abs/2401.11196",
        "title": "Machine learning based state observer for discrete time systems evolving on Lie groups",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, a machine learning based observer for systems evolving on manifolds is designed such that the state of the observer is restricted to the Lie group on which the system evolves. Conventional techniques involving machine learning based observers on systems evolving on Lie groups involve designing charts for the Lie group, training a machine learning based observer for each chart, and switching between the trained models based on the state of the system. We propose a novel deep learning based technique whose predictions are restricted to a measure 0 subset of Euclidean space without using charts. Using this network, we design an observer ensuring that the state of the observer is restricted to the Lie group, and predicting the state using only one trained algorithm. The deep learning network predicts an ``error term'' on the Lie algebra of the Lie group, uses the map from the Lie algebra to the group, and uses the group action and the present state to estimate the state at the next epoch. This model being purely data driven does not require the model of the system. The proposed algorithm provides a novel framework for constraining the output of machine learning networks to a measure 0 subset of a Euclidean space without chart specific training and without requiring switching. We show the validity of this method using Monte Carlo simulations performed of the rigid body rotation and translation system.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11201",
        "abstract url": "https://arxiv.org/abs/2401.11201",
        "title": "Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Opinionated users often seek information that aligns with their preexisting beliefs while dismissing contradictory evidence due to confirmation bias. This conduct hinders their ability to consider alternative stances when searching the web. Despite this, few studies have analyzed how the diversification of search results on disputed topics influences the search behavior of highly opinionated users. To this end, we present a preregistered user study (n = 257) investigating whether different levels (low and high) of bias metrics and search results presentation (with or without AI-predicted stances labels) can affect the stance diversity consumption and search behavior of opinionated users on three debated topics (i.e., atheism, intellectual property rights, and school uniforms). Our results show that exposing participants to (counter-attitudinally) biased search results increases their consumption of attitude-opposing content, but we also found that bias was associated with a trend toward overall fewer interactions within the search page. We also found that 19% of users interacted with queries and search pages but did not select any search results. When we removed these participants in a post-hoc analysis, we found that stance labels increased the diversity of stances consumed by users, particularly when the search results were biased. Our findings highlight the need for future research to explore distinct search scenario settings to gain insight into opinionated users' behavior.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "17 pages, 3 figures, ECIR2024 (46th European Conference on Information Retrieval - IR4Good track)"
    },
    {
        "paper id": "2401.11202",
        "abstract url": "https://arxiv.org/abs/2401.11202",
        "title": "PartIR: Composing SPMD Partitioning Strategies for Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training of modern large neural networks (NN) requires a combination of parallelization strategies encompassing data, model, or optimizer sharding. When strategies increase in complexity, it becomes necessary for partitioning tools to be 1) expressive, allowing the composition of simpler strategies, and 2) predictable to estimate performance analytically. We present PartIR, our design for a NN partitioning system. PartIR is focused on an incremental approach to rewriting and is hardware-and-runtime agnostic. We present a simple but powerful API for composing sharding strategies and a simulator to validate them. The process is driven by high-level programmer-issued partitioning tactics, which can be both manual and automatic. Importantly, the tactics are specified separately from the model code, making them easy to change. We evaluate PartIR on several different models to demonstrate its predictability, expressibility, and ability to reach peak performance..",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11204",
        "abstract url": "https://arxiv.org/abs/2401.11204",
        "title": "Towards Category Unification of 3D Single Object Tracking on Point Clouds",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Category-specific models are provenly valuable methods in 3D single object tracking (SOT) regardless of Siamese or motion-centric paradigms. However, such over-specialized model designs incur redundant parameters, thus limiting the broader applicability of 3D SOT task. This paper first introduces unified models that can simultaneously track objects across all categories using a single network with shared model parameters. Specifically, we propose to explicitly encode distinct attributes associated to different object categories, enabling the model to adapt to cross-category data. We find that the attribute variances of point cloud objects primarily occur from the varying size and shape (e.g., large and square vehicles v.s. small and slender humans). Based on this observation, we design a novel point set representation learning network inheriting transformer architecture, termed AdaFormer, which adaptively encodes the dynamically varying shape and size information from cross-category data in a unified manner. We further incorporate the size and shape prior derived from the known template targets into the model's inputs and learning objective, facilitating the learning of unified representation. Equipped with such designs, we construct two category-unified models SiamCUT and MoCUT.Extensive experiments demonstrate that SiamCUT and MoCUT exhibit strong generalization and training stability. Furthermore, our category-unified models outperform the category-specific counterparts by a significant margin (e.g., on KITTI dataset, 12% and 3% performance gains on the Siamese and motion paradigms). Our code will be available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR2024 (poster)"
    },
    {
        "paper id": "2401.11215",
        "abstract url": "https://arxiv.org/abs/2401.11215",
        "title": "Selecting Walk Schemes for Database Embedding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machinery for data analysis often requires a numeric representation of the input. Towards that, a common practice is to embed components of structured data into a high-dimensional vector space. We study the embedding of the tuples of a relational database, where existing techniques are often based on optimization tasks over a collection of random walks from the database. The focus of this paper is on the recent FoRWaRD algorithm that is designed for dynamic databases, where walks are sampled by following foreign keys between tuples. Importantly, different walks have different schemas, or \"walk schemes\", that are derived by listing the relations and attributes along the walk. Also importantly, different walk schemes describe relationships of different natures in the database. We show that by focusing on a few informative walk schemes, we can obtain tuple embedding significantly faster, while retaining the quality. We define the problem of scheme selection for tuple embedding, devise several approaches and strategies for scheme selection, and conduct a thorough empirical study of the performance over a collection of downstream tasks. Our results confirm that with effective strategies for scheme selection, we can obtain high-quality embeddings considerably (e.g., three times) faster, preserve the extensibility to newly inserted tuples, and even achieve an increase in the precision of some tasks.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "comment": "Accepted by CIKM 2023, 10 pages"
    },
    {
        "paper id": "2401.11232",
        "abstract url": "https://arxiv.org/abs/2401.11232",
        "title": "Collaborative consumption for low and high trust requiring business models: from fare sharing to supporting the elderly and people with disability",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper offers an overview of collaborative consumption (CC), the related business models (BM), the value added (VA) from the consumer's perspective and the role of trust. CC is expanding but it is unclear what opportunities it offers and what the challenges will be. This research evaluates the current CC BMs and identifies 13 ways they add value from the consumer's perspective. This research further explores whether CC BMs fall into two categories in terms of what the consumer values. In the first category, the CC BMs require a low level of trust while in the second category of CC BMs a higher level of trust is necessary. It was found that 13 VA by CC BMs could be grouped into personal interest, communal interest and trust building. It is important for organisations to acknowledge how their CC BM relates to these dimensions.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11250",
        "abstract url": "https://arxiv.org/abs/2401.11250",
        "title": "AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of feature selection in general machine learning (ML) context, which is one of the most critical subjects in the field. Although, there exist many feature selection methods, however, these methods face challenges such as scalability, managing high-dimensional data, dealing with correlated features, adapting to variable feature importance, and integrating domain knowledge. To this end, we introduce the ``Adaptive Feature Selection with Binary Masking\" (AFS-BM) which remedies these problems. AFS-BM achieves this by joint optimization for simultaneous feature selection and model training. In particular, we do the joint optimization and binary masking to continuously adapt the set of features and model parameters during the training process. This approach leads to significant improvements in model accuracy and a reduction in computational requirements. We provide an extensive set of experiments where we compare AFS-BM with the established feature selection methods using well-known datasets from real-life competitions. Our results show that AFS-BM makes significant improvement in terms of accuracy and requires significantly less computational complexity. This is due to AFS-BM's ability to dynamically adjust to the changing importance of features during the training process, which an important contribution to the field. We openly share our code for the replicability of our results and to facilitate further research.",
        "subjects": [
            "cs.LG",
            "eess.SP",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11254",
        "abstract url": "https://arxiv.org/abs/2401.11254",
        "title": "The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "In the current landscape of online abuses and harms, effective content moderation is necessary to cultivate safe and inclusive online spaces. Yet, the effectiveness of many moderation interventions is still unclear. Here, we assess the effectiveness of The Great Ban, a massive deplatforming operation that affected nearly 2,000 communities on Reddit. By analyzing 16M comments posted by 17K users during 14 months, we provide nuanced results on the effects, both desired and otherwise, of the ban. Among our main findings is that 15.6% of the affected users left Reddit and that those who remained reduced their toxicity by 6.6% on average. The ban also caused 5% users to increase their toxicity by more than 70% of their pre-ban level. Overall, our multifaceted results provide new insights into the efficacy of deplatforming. As such, our findings can inform the development of future moderation interventions and the policing of online platforms.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11257",
        "abstract url": "https://arxiv.org/abs/2401.11257",
        "title": "Measuring Policy Distance for Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Diversity plays a crucial role in improving the performance of multi-agent reinforcement learning (MARL). Currently, many diversity-based methods have been developed to overcome the drawbacks of excessive parameter sharing in traditional MARL. However, there remains a lack of a general metric to quantify policy differences among agents. Such a metric would not only facilitate the evaluation of the diversity evolution in multi-agent systems, but also provide guidance for the design of diversity-based MARL algorithms. In this paper, we propose the multi-agent policy distance (MAPD), a general tool for measuring policy differences in MARL. By learning the conditional representations of agents' decisions, MAPD can computes the policy distance between any pair of agents. Furthermore, we extend MAPD to a customizable version, which can quantify differences among agent policies on specified aspects. Based on the online deployment of MAPD, we design a multi-agent dynamic parameter sharing (MADPS) algorithm as an example of the MAPD's applications. Extensive experiments demonstrate that our method is effective in measuring differences in agent policies and specific behavioral tendencies. Moreover, in comparison to other methods of parameter sharing, MADPS exhibits superior performance.",
        "subjects": [
            "cs.MA",
            "cs.AI"
        ],
        "comment": "9 pages, 6 figures"
    },
    {
        "paper id": "2401.11281",
        "abstract url": "https://arxiv.org/abs/2401.11281",
        "title": "Sources of Underproduction in Open Source Software",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Because open source software relies on individuals who select their own tasks, it is often underproduced -- a term used by software engineering researchers to describe when a piece of software's relative quality is lower than its relative importance. We examine the social and technical factors associated with underproduction through a comparison of software packaged by the Debian GNU/Linux community. We test a series of hypotheses developed from a reading of prior research in software engineering. Although we find that software age and programming language age offer a partial explanation for variation in underproduction, we were surprised to find that the association between underproduction and package age is weaker at high levels of programming language age. With respect to maintenance efforts, we find that additional resources are not always tied to better outcomes. In particular, having higher numbers of contributors is associated with higher underproduction risk. Also, contrary to our expectations, maintainer turnover and maintenance by a declared team are not associated with lower rates of underproduction. Finally, we find that the people working on bugs in underproduced packages tend to be those who are more central to the community's collaboration network structure, although contributors' betweenness centrality (often associated with brokerage in social networks) is not associated with underproduction.",
        "subjects": [
            "cs.SE",
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11314",
        "abstract url": "https://arxiv.org/abs/2401.11314",
        "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "CHI 2024 Paper - The paper includes 17 pages, 8 figures, 2 tables, along with a 2-page appendix"
    },
    {
        "paper id": "2401.11317",
        "abstract url": "https://arxiv.org/abs/2401.11317",
        "title": "Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Community management is critical for stakeholders to collaboratively build and sustain communities with socio-technical support. However, most of the existing research has mainly focused on the community members and the platform, with little attention given to the developers who act as intermediaries between the platform and community members and develop tools to support community management. This study focuses on third-party developers (TPDs) for the live streaming platform Twitch and explores their tool development practices. Using a mixed method with in-depth qualitative analysis, we found that TPDs maintain complex relationships with different stakeholders (streamers, viewers, platform, professional developers), and the multi-layered policy restricts their agency regarding idea innovation and tool development. We argue that HCI research should shift its focus from tool users to tool developers with regard to community management. We propose designs to support closer collaboration between TPDS and the platform and professional developers and streamline TPDs' development process with unified toolkits and policy documentation.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "Accepted by ACM CHI 2024"
    },
    {
        "paper id": "2401.11325",
        "abstract url": "https://arxiv.org/abs/2401.11325",
        "title": "Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Many Reinforcement Learning algorithms assume a Markov reward function to guarantee optimality. However, not all reward functions are known to be Markov. In this paper, we propose a framework for mapping non-Markov reward functions into equivalent Markov ones by learning a Reward Machine - a specialized reward automaton. Unlike the general practice of learning Reward Machines, we do not require a set of high-level propositional symbols from which to learn. Rather, we learn \\emph{hidden triggers} directly from data that encode them. We demonstrate the importance of learning Reward Machines versus their Deterministic Finite-State Automata counterparts, for this task, given their ability to model reward dependencies in a single automaton. We formalize this distinction in our learning objective. Our mapping process is constructed as an Integer Linear Programming problem. We prove that our mappings provide consistent expectations for the underlying process. We empirically validate our approach by learning black-box non-Markov Reward functions in the Officeworld Domain. Additionally, we demonstrate the effectiveness of learning dependencies between rewards in a new domain, Breakfastworld.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11335",
        "abstract url": "https://arxiv.org/abs/2401.11335",
        "title": "Deception and Manipulation in Generative AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Large language models now possess human-level linguistic abilities in many contexts. This raises the concern that they can be used to deceive and manipulate on unprecedented scales, for instance spreading political misinformation on social media. In future, agentic AI systems might also deceive and manipulate humans for their own ends. In this paper, first, I argue that AI-generated content should be subject to stricter standards against deception and manipulation than we ordinarily apply to humans. Second, I offer new characterizations of AI deception and manipulation meant to support such standards, according to which a statement is deceptive (manipulative) if it leads human addressees away from the beliefs (choices) they would endorse under ``semi-ideal'' conditions. Third, I propose two measures to guard against AI deception and manipulation, inspired by this characterization: \"extreme transparency\" requirements for AI-generated content and defensive systems that, among other things, annotate AI-generated statements with contextualizing information. Finally, I consider to what extent these measures can protect against deceptive behavior in future, agentic AIs, and argue that non-agentic defensive systems can provide an important layer of defense even against more powerful agentic systems.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11353",
        "abstract url": "https://arxiv.org/abs/2401.11353",
        "title": "Distributionally Robust Policy Evaluation under General Covariate Shift in Contextual Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a distributionally robust approach that enhances the reliability of offline policy evaluation in contextual bandits under general covariate shifts. Our method aims to deliver robust policy evaluation results in the presence of discrepancies in both context and policy distribution between logging and target data. Central to our methodology is the application of robust regression, a distributionally robust technique tailored here to improve the estimation of conditional reward distribution from logging data. Utilizing the reward model obtained from robust regression, we develop a comprehensive suite of policy value estimators, by integrating our reward model into established evaluation frameworks, namely direct methods and doubly robust methods. Through theoretical analysis, we further establish that the proposed policy value estimators offer a finite sample upper bound for the bias, providing a clear advantage over traditional methods, especially when the shift is large. Finally, we designed an extensive range of policy evaluation scenarios, covering diverse magnitudes of shifts and a spectrum of logging and target policies. Our empirical results indicate that our approach significantly outperforms baseline methods, most notably in 90% of the cases under the policy shift-only settings and 72% of the scenarios under the general covariate shift settings.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11354",
        "abstract url": "https://arxiv.org/abs/2401.11354",
        "title": "Squared Wasserstein-2 Distance for Efficient Reconstruction of Stochastic Differential Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We provide an analysis of the squared Wasserstein-2 ($W_2$) distance between two probability distributions associated with two stochastic differential equations (SDEs). Based on this analysis, we propose the use of a squared $W_2$ distance-based loss functions in the \\textit{reconstruction} of SDEs from noisy data. To demonstrate the practicality of our Wasserstein distance-based loss functions, we performed numerical experiments that demonstrate the efficiency of our method in reconstructing SDEs that arise across a number of applications.",
        "subjects": [
            "math.PR",
            "cs.LG",
            "stat.ME"
        ],
        "comment": "37 pages, 5 figures"
    },
    {
        "paper id": "2401.11360",
        "abstract url": "https://arxiv.org/abs/2401.11360",
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "q-bio.BM"
        ],
        "comment": "25 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2401.11370",
        "abstract url": "https://arxiv.org/abs/2401.11370",
        "title": "Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Software systems impact society at different levels as they pervasively solve real-world problems. Modern software systems are often so sophisticated that their complexity exceeds the limits of human comprehension. These systems must respond to changing goals, dynamic data, unexpected failures, and security threats, among other variable factors in real-world environments. Systems' complexity challenges their interpretability and requires autonomous responses to dynamic changes. Two main research areas explore autonomous systems' responses: evolutionary computing and autonomic computing. Evolutionary computing focuses on software improvement based on iterative modifications to the source code. Autonomic computing focuses on optimising systems' performance by changing their structure, behaviour, or environment variables. Approaches from both areas rely on feedback loops that accumulate knowledge from the system interactions to inform autonomous decision-making. However, this knowledge is often limited, constraining the systems' interpretability and adaptability. This paper proposes a new concept for interpretable and adaptable software systems: self-sustaining software systems (S4). S4 builds knowledge loops between all available knowledge sources that define modern software systems to improve their interpretability and adaptability. This paper introduces and discusses the S4 concept.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "eess.SY"
        ],
        "comment": "Accepted at The 1st International Workshop New Trends in Software Architecture (SATrends) 2024"
    },
    {
        "paper id": "2401.11378",
        "abstract url": "https://arxiv.org/abs/2401.11378",
        "title": "Multi-Agent Generative Adversarial Interactive Self-Imitation Learning for AUV Formation Control and Obstacle Avoidance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multiple autonomous underwater vehicles (multi-AUV) can cooperatively accomplish tasks that a single AUV cannot complete. Recently, multi-agent reinforcement learning has been introduced to control of multi-AUV. However, designing efficient reward functions for various tasks of multi-AUV control is difficult or even impractical. Multi-agent generative adversarial imitation learning (MAGAIL) allows multi-AUV to learn from expert demonstration instead of pre-defined reward functions, but suffers from the deficiency of requiring optimal demonstrations and not surpassing provided expert demonstrations. This paper builds upon the MAGAIL algorithm by proposing multi-agent generative adversarial interactive self-imitation learning (MAGAISIL), which can facilitate AUVs to learn policies by gradually replacing the provided sub-optimal demonstrations with self-generated good trajectories selected by a human trainer. Our experimental results in a multi-AUV formation control and obstacle avoidance task on the Gazebo platform with AUV simulator of our lab show that AUVs trained via MAGAISIL can surpass the provided sub-optimal expert demonstrations and reach a performance close to or even better than MAGAIL with optimal demonstrations. Further results indicate that AUVs' policies trained via MAGAISIL can adapt to complex and different tasks as well as MAGAIL learning from optimal demonstrations.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "8pages,10figures,Published to RA-L"
    },
    {
        "paper id": "2401.11380",
        "abstract url": "https://arxiv.org/abs/2401.11380",
        "title": "MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Model-based offline reinforcement learning methods (RL) have achieved state-of-the-art performance in many decision-making problems thanks to their sample efficiency and generalizability. Despite these advancements, existing model-based offline RL approaches either focus on theoretical studies without developing practical algorithms or rely on a restricted parametric policy space, thus not fully leveraging the advantages of an unrestricted policy space inherent to model-based methods. To address this limitation, we develop MoMA, a model-based mirror ascent algorithm with general function approximations under partial coverage of offline data. MoMA distinguishes itself from existing literature by employing an unrestricted policy class. In each iteration, MoMA conservatively estimates the value function by a minimization procedure within a confidence set of transition models in the policy evaluation step, then updates the policy with general function approximations instead of commonly-used parametric policy classes in the policy improvement step. Under some mild assumptions, we establish theoretical guarantees of MoMA by proving an upper bound on the suboptimality of the returned policy. We also provide a practically implementable, approximate version of the algorithm. The effectiveness of MoMA is demonstrated via numerical studies.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11394",
        "abstract url": "https://arxiv.org/abs/2401.11394",
        "title": "Causal Generative Explainers using Counterfactual Inference: A Case Study on the Morpho-MNIST Dataset",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose leveraging causal generative learning as an interpretable tool for explaining image classifiers. Specifically, we present a generative counterfactual inference approach to study the influence of visual features (i.e., pixels) as well as causal factors through generative learning. To this end, we first uncover the most influential pixels on a classifier's decision by varying the value of a causal attribute via counterfactual inference and computing both Shapely and contrastive explanations for counterfactual images with these different attribute values. We then establish a Monte-Carlo mechanism using the generator of a causal generative model in order to adapt Shapley explainers to produce feature importances for the human-interpretable attributes of a causal dataset in the case where a classifier has been trained exclusively on the images of the dataset. Finally, we present optimization methods for creating counterfactual explanations of classifiers by means of counterfactual inference, proposing straightforward approaches for both differentiable and arbitrary classifiers. We exploit the Morpho-MNIST causal dataset as a case study for exploring our proposed methods for generating counterfacutl explantions. We employ visual explanation methods from OmnixAI open source toolkit to compare them with our proposed methods. By employing quantitative metrics to measure the interpretability of counterfactual explanations, we find that our proposed methods of counterfactual explanation offer more interpretable explanations compared to those generated from OmnixAI. This finding suggests that our methods are well-suited for generating highly interpretable counterfactual explanations on causal datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11402",
        "abstract url": "https://arxiv.org/abs/2401.11402",
        "title": "Enabling clustering algorithms to detect clusters of varying densities through scale-invariant data preprocessing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we show that preprocessing data using a variant of rank transformation called 'Average Rank over an Ensemble of Sub-samples (ARES)' makes clustering algorithms robust to data representation and enable them to detect varying density clusters. Our empirical results, obtained using three most widely used clustering algorithms-namely KMeans, DBSCAN, and DP (Density Peak)-across a wide range of real-world datasets, show that clustering after ARES transformation produces better and more consistent results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11403",
        "abstract url": "https://arxiv.org/abs/2401.11403",
        "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
        "rating": "0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Chemical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Deep learning is now widely used in drug discovery, providing significant acceleration and cost reduction. As the most fundamental building block, molecular representation is essential for predicting molecular properties to enable various downstream applications. Most existing methods attempt to incorporate more information to learn better representations. However, not all features are equally important for a specific task. Ignoring this would potentially compromise the training efficiency and predictive accuracy. To address this issue, we propose a novel approach, which treats language models as an agent and molecular pretraining models as a knowledge base. The agent accentuates task-relevant features in the molecular representation by understanding the natural language description of the task, just as a tailor customizes clothes for clients. Thus, we call this approach MolTailor. Evaluations demonstrate MolTailor's superior performance over baselines, validating the efficacy of enhancing relevance for molecular representation learning. This illustrates the potential of language model guided optimization to better exploit and unleash the capabilities of existing powerful molecular representation methods. Our code is available at https://github.com/SCIR-HI/MolTailor.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "q-bio.BM"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.12247",
        "abstract url": "https://arxiv.org/abs/2401.12247",
        "title": "Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial intelligence based chatbots have brought unprecedented business potential. This study aims to explore consumers trust and response to a text-based chatbot in ecommerce, involving the moderating effects of task complexity and chatbot identity disclosure. A survey method with 299 useable responses was conducted in this research. This study adopted the ordinary least squares regression to test the hypotheses. First, the consumers perception of both the empathy and friendliness of the chatbot positively impacts their trust in it. Second, task complexity negatively moderates the relationship between friendliness and consumers trust. Third, disclosure of the text based chatbot negatively moderates the relationship between empathy and consumers trust, while it positively moderates the relationship between friendliness and consumers trust. Fourth, consumers trust in the chatbot increases their reliance on the chatbot and decreases their resistance to the chatbot in future interactions. Adopting the stimulus organism response framework, this study provides important insights on consumers perception and response to the text-based chatbot. The findings of this research also make suggestions that can increase consumers positive responses to text based chatbots. Extant studies have investigated the effects of automated bots attributes on consumers perceptions. However, the boundary conditions of these effects are largely ignored. This research is one of the first attempts to provide a deep understanding of consumers responses to a chatbot.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Internet Research (2021)"
    },
    {
        "paper id": "2402.04880",
        "abstract url": "https://arxiv.org/abs/2402.04880",
        "title": "Combining Cloud and Mobile Computing for Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Although the computing power of mobile devices is increasing, machine learning models are also growing in size. This trend creates problems for mobile devices due to limitations like their memory capacity and battery life. While many services, like ChatGPT and Midjourney, run all the inferences in the cloud, we believe a flexible and fine-grained task distribution is more desirable. In this work, we consider model segmentation as a solution to improving the user experience, dividing the computation between mobile devices and the cloud in a way that offloads the compute-heavy portion of the model while minimizing the data transfer required. We show that the division not only reduces the wait time for users but can also be fine-tuned to optimize the workloads of the cloud. To achieve that, we design a scheduler that collects information about network quality, client device capability, and job requirements, making decisions to achieve consistent performance across a range of devices while reducing the work the cloud needs to perform.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Ruiqi Xu and Tianchi Zhang contributed equally to this work"
    },
    {
        "paper id": "2401.11122",
        "abstract url": "https://arxiv.org/abs/2401.11122",
        "title": "Spatial Structure Constraints for Weakly Supervised Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The image-level label has prevailed in weakly supervised semantic segmentation tasks due to its easy availability. Since image-level labels can only indicate the existence or absence of specific categories of objects, visualization-based techniques have been widely adopted to provide object location clues. Considering class activation maps (CAMs) can only locate the most discriminative part of objects, recent approaches usually adopt an expansion strategy to enlarge the activation area for more integral object localization. However, without proper constraints, the expanded activation will easily intrude into the background region. In this paper, we propose spatial structure constraints (SSC) for weakly supervised semantic segmentation to alleviate the unwanted object over-activation of attention expansion. Specifically, we propose a CAM-driven reconstruction module to directly reconstruct the input image from deep CAM features, which constrains the diffusion of last-layer object attention by preserving the coarse spatial structure of the image content. Moreover, we propose an activation self-modulation module to refine CAMs with finer spatial structure details by enhancing regional consistency. Without external saliency models to provide background clues, our approach achieves 72.7\\% and 47.0\\% mIoU on the PASCAL VOC 2012 and COCO datasets, respectively, demonstrating the superiority of our proposed approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by IEEE Transactions on Image Processing"
    },
    {
        "paper id": "2401.11123",
        "abstract url": "https://arxiv.org/abs/2401.11123",
        "title": "Uncertainty-aware Bridge based Mobile-Former Network for Event-based Pattern Recognition",
        "rating": "0",
        "keywords": [
            [
                "event cameras"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The mainstream human activity recognition (HAR) algorithms are developed based on RGB cameras, which are easily influenced by low-quality images (e.g., low illumination, motion blur). Meanwhile, the privacy protection issue caused by ultra-high definition (HD) RGB cameras aroused more and more people's attention. Inspired by the success of event cameras which perform better on high dynamic range, no motion blur, and low energy consumption, we propose to recognize human actions based on the event stream. We propose a lightweight uncertainty-aware information propagation based Mobile-Former network for efficient pattern recognition, which aggregates the MobileNet and Transformer network effectively. Specifically, we first embed the event images using a stem network into feature representations, then, feed them into uncertainty-aware Mobile-Former blocks for local and global feature learning and fusion. Finally, the features from MobileNet and Transformer branches are concatenated for pattern recognition. Extensive experiments on multiple event-based recognition datasets fully validated the effectiveness of our model. The source code of this work will be released at https://github.com/Event-AHU/Uncertainty_aware_MobileFormer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Short Paper. arXiv admin note: text overlap with arXiv:2306.05239"
    },
    {
        "paper id": "2401.11156",
        "abstract url": "https://arxiv.org/abs/2401.11156",
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Published in IEEE/ACM Transactions on Audio, Speech, and Language Processing (doi updated)"
    },
    {
        "paper id": "2401.11206",
        "abstract url": "https://arxiv.org/abs/2401.11206",
        "title": "InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the rapid development of large language models (LLMs), they are not only used as general-purpose AI assistants but are also customized through further fine-tuning to meet the requirements of different applications. A pivotal factor in the success of current LLMs is the alignment process. Current alignment methods, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), focus on training-time alignment and are often complex and cumbersome to implement. Therefore, we develop \\textbf{InferAligner}, a novel inference-time alignment method that utilizes cross-model guidance for harmlessness alignment. InferAligner utilizes safety steering vectors extracted from safety-aligned model to modify the activations of the target model when responding to harmful inputs, thereby guiding the target model to provide harmless responses. Experimental results show that our method can be very effectively applied to domain-specific models in finance, medicine, and mathematics, as well as to multimodal large language models (MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate (ASR) of both harmful instructions and jailbreak attacks, while maintaining almost unchanged performance in downstream tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11239",
        "abstract url": "https://arxiv.org/abs/2401.11239",
        "title": "Product-Level Try-on: Characteristics-preserving Try-on with Realistic Clothes Shading and Wrinkles",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "synthesize"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image-based virtual try-on systems,which fit new garments onto human portraits,are gaining research attention.An ideal pipeline should preserve the static features of clothes(like textures and logos)while also generating dynamic elements(e.g.shadows,folds)that adapt to the model's pose and environment.Previous works fail specifically in generating dynamic features,as they preserve the warped in-shop clothes trivially with predicted an alpha mask by composition.To break the dilemma of over-preserving and textures losses,we propose a novel diffusion-based Product-level virtual try-on pipeline,\\ie PLTON, which can preserve the fine details of logos and embroideries while producing realistic clothes shading and wrinkles.The main insights are in three folds:1)Adaptive Dynamic Rendering:We take a pre-trained diffusion model as a generative prior and tame it with image features,training a dynamic extractor from scratch to generate dynamic tokens that preserve high-fidelity semantic information. Due to the strong generative power of the diffusion prior,we can generate realistic clothes shadows and wrinkles.2)Static Characteristics Transformation: High-frequency Map(HF-Map)is our fundamental insight for static representation.PLTON first warps in-shop clothes to the target model pose by a traditional warping network,and uses a high-pass filter to extract an HF-Map for preserving static cloth features.The HF-Map is used to generate modulation maps through our static extractor,which are injected into a fixed U-net to synthesize the final result.To enhance retention,a Two-stage Blended Denoising method is proposed to guide the diffusion process for correct spatial layout and color.PLTON is finetuned only with our collected small-size try-on dataset.Extensive quantitative and qualitative experiments on 1024 768 datasets demonstrate the superiority of our framework in mimicking real clothes dynamics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11256",
        "abstract url": "https://arxiv.org/abs/2401.11256",
        "title": "Equivariant Multiscale Learned Invertible Reconstruction for Cone Beam CT",
        "rating": "0",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "CT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cone Beam CT (CBCT) is an essential imaging modality nowadays, but the image quality of CBCT still lags behind the high quality standards established by the conventional Computed Tomography. We propose LIRE+, a learned iterative scheme for fast and memory-efficient CBCT reconstruction, which is a substantially faster and more parameter-efficient alternative to the recently proposed LIRE method. LIRE+ is a rotationally-equivariant multiscale learned invertible primal-dual iterative scheme for CBCT reconstruction. Memory usage is optimized by relying on simple reversible residual networks in primal/dual cells and patch-wise computations inside the cells during forward and backward passes, while increased inference speed is achieved by making the primal-dual scheme multiscale so that the reconstruction process starts at low resolution and with low resolution primal/dual latent vectors. A LIRE+ model was trained and validated on a set of 260 + 22 thorax CT scans and tested using a set of 142 thorax CT scans with additional evaluation with and without finetuning on an out-of-distribution set of 79 Head and Neck (HN) CT scans. Our method surpasses classical and deep learning baselines, including LIRE, on the thorax test set. For a similar inference time and with only 37 % of the parameter budget, LIRE+ achieves a +0.2 dB PSNR improvement over LIRE, while being able to match the performance of LIRE in 45 % less inference time and with 28 % of the parameter budget. Rotational equivariance ensures robustness of LIRE+ to patient orientation, while LIRE and other deep learning baselines suffer from substantial performance degradation when patient orientation is unusual. On the HN dataset in the absence of finetuning, LIRE+ is generally comparable to LIRE in performance apart from a few outlier cases, whereas after identical finetuning LIRE+ demonstates a +1.02 dB PSNR improvement over LIRE.",
        "subjects": [
            "physics.med-ph",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11261",
        "abstract url": "https://arxiv.org/abs/2401.11261",
        "title": "Diffusion Model Conditioning on Gaussian Mixture Model and Negative Gaussian Mixture Gradient",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "synthesis"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models (DMs) are a type of generative model that has a huge impact on image synthesis and beyond. They achieve state-of-the-art generation results in various generative tasks. A great diversity of conditioning inputs, such as text or bounding boxes, are accessible to control the generation. In this work, we propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) as feature conditioning to guide the denoising process. Based on set theory, we provide a comprehensive theoretical analysis that shows that conditional latent distribution based on features and classes is significantly different, so that conditional latent distribution on features produces fewer defect generations than conditioning on classes. Two diffusion models conditioned on the Gaussian mixture model are trained separately for comparison. Experiments support our findings. A novel gradient function called the negative Gaussian mixture gradient (NGMG) is proposed and applied in diffusion model training with an additional classifier. Training stability has improved. We also theoretically prove that NGMG shares the same benefit as the Earth Mover distance (Wasserstein) as a more sensible cost function when learning distributions supported by low-dimensional manifolds.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11271",
        "abstract url": "https://arxiv.org/abs/2401.11271",
        "title": "DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series Anomaly Detection",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Anomaly detection in time-series data is crucial for identifying faults, failures, threats, and outliers across a range of applications. Recently, deep learning techniques have been applied to this topic, but they often struggle in real-world scenarios that are complex and highly dynamic, e.g., the normal data may consist of multiple distributions, and various types of anomalies may differ from the normal data to different degrees. In this work, to tackle these challenges, we propose Distribution-Augmented Contrastive Reconstruction (DACR). DACR generates extra data disjoint from the normal data distribution to compress the normal data's representation space, and enhances the feature extractor through contrastive learning to better capture the intrinsic semantics from time-series data. Furthermore, DACR employs an attention mechanism to model the semantic dependencies among multivariate time-series features, thereby achieving more robust reconstruction for anomaly detection. Extensive experiments conducted on nine benchmark datasets in various anomaly detection scenarios demonstrate the effectiveness of DACR in achieving new state-of-the-art time-series anomaly detection.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 3 figures, accepted at ICASSP 2024"
    },
    {
        "paper id": "2401.11284",
        "abstract url": "https://arxiv.org/abs/2401.11284",
        "title": "Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose",
        "rating": "0",
        "keywords": [
            [
                "automated driving",
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "As automated driving technology advances, the role of the driver to resume control of the vehicle in conditionally automated vehicles becomes increasingly critical. In the SAE Level 3 or partly automated vehicles, the driver needs to be available and ready to intervene when necessary. This makes it essential to evaluate their readiness accurately. This article presents a comprehensive analysis of driver readiness assessment by combining head pose features and eye-tracking data. The study explores the effectiveness of predictive models in evaluating driver readiness, addressing the challenges of dataset limitations and limited ground truth labels. Machine learning techniques, including LSTM architectures, are utilised to model driver readiness based on the Spatio-temporal status of the driver's head pose and eye gaze. The experiments in this article revealed that a Bidirectional LSTM architecture, combining both feature sets, achieves a mean absolute error of 0.363 on the DMD dataset, demonstrating superior performance in assessing driver readiness. The modular architecture of the proposed model also allows the integration of additional driver-specific features, such as steering wheel activity, enhancing its adaptability and real-world applicability.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11324",
        "abstract url": "https://arxiv.org/abs/2401.11324",
        "title": "BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single GPU",
        "rating": "0",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithms routinely employed in information retrieval, pattern recognition, data mining, image processing, and beyond. Recent works have established that graph-based ANNS algorithms are practically more efficient than the other methods proposed in the literature, on large datasets. The growing volume and dimensionality of data necessitates designing scalable techniques for ANNS. To this end, the prior art has explored parallelizing graph-based ANNS on GPU leveraging its high computational power and energy efficiency. The current state-of-the-art GPU-based ANNS algorithms either (i) require both the index-graph and the data to reside entirely in the GPU memory, or (ii) they partition the data into small independent shards, each of which can fit in GPU memory, and perform the search on these shards on the GPU. While the first approach fails to handle large datasets due to the limited memory available on the GPU, the latter delivers poor performance on large datasets due to high data traffic over the low-bandwidth PCIe bus. In this paper, we introduce BANG, a first-of-its-kind GPU-based ANNS method which works efficiently on billion-scale datasets that cannot entirely fit in the GPU memory. BANG stands out by harnessing compressed data on the GPU to perform distance computations while maintaining the graph on the CPU. BANG incorporates high-optimized GPU kernels and proceeds in stages that run concurrently on the GPU and CPU, taking advantage of their architectural specificities. We evaluate BANG using a single NVIDIA Ampere A100 GPU on ten popular ANN benchmark datasets. BANG outperforms the state-of-the-art in the majority of the cases. Notably, on the billion-size datasets, we are significantly faster than our competitors, achieving throughputs 40x-200x more than the competing methods for a high recall of 0.9.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11373",
        "abstract url": "https://arxiv.org/abs/2401.11373",
        "title": "Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Adversarial attacks against language models(LMs) are a significant concern. In particular, adversarial samples exploit the model's sensitivity to small input changes. While these changes appear insignificant on the semantics of the input sample, they result in significant decay in model performance. In this paper, we propose Targeted Paraphrasing via RL (TPRL), an approach to automatically learn a policy to generate challenging samples that most likely improve the model's performance. TPRL leverages FLAN T5, a language model, as a generator and employs a self learned policy using a proximal policy gradient to generate the adversarial examples automatically. TPRL's reward is based on the confusion induced in the classifier, preserving the original text meaning through a Mutual Implication score. We demonstrate and evaluate TPRL's effectiveness in discovering natural adversarial attacks and improving model performance through extensive experiments on four diverse NLP classification tasks via Automatic and Human evaluation. TPRL outperforms strong baselines, exhibits generalizability across classifiers and datasets, and combines the strengths of language modeling and reinforcement learning to generate diverse and influential adversarial examples.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL 2024 - Main conference - Camera ready version"
    },
    {
        "paper id": "2401.11395",
        "abstract url": "https://arxiv.org/abs/2401.11395",
        "title": "UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with Fine-Grained Feature Representation",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D open-vocabulary scene understanding aims to recognize arbitrary novel categories beyond the base label space. However, existing works not only fail to fully utilize all the available modal information in the 3D domain but also lack sufficient granularity in representing the features of each modality. In this paper, we propose a unified multimodal 3D open-vocabulary scene understanding network, namely UniM-OV3D, which aligns point clouds with image, language and depth. To better integrate global and local features of the point clouds, we design a hierarchical point cloud feature extraction module that learns comprehensive fine-grained feature representations. Further, to facilitate the learning of coarse-to-fine point-semantic representations from captions, we propose the utilization of hierarchical 3D caption pairs, capitalizing on geometric constraints across various viewpoints of 3D scenes. Extensive experimental results demonstrate the effectiveness and superiority of our method in open-vocabulary semantic and instance segmentation, which achieves state-of-the-art performance on both indoor and outdoor benchmarks such as ScanNet, ScanNet200, S3IDS and nuScenes. Code is available at https://github.com/hithqd/UniM-OV3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IJCAI 2024"
    },
    {
        "paper id": "2401.11401",
        "abstract url": "https://arxiv.org/abs/2401.11401",
        "title": "LLMRA: Multi-modal Large Language Model based Restoration Assistant",
        "rating": "0",
        "keywords": [
            [
                "vision language"
            ],
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal Large Language Models (MLLMs) have a significant impact on various tasks, due to their extensive knowledge and powerful perception and generation capabilities. However, it still remains an open research problem on applying MLLMs to low-level vision tasks. In this paper, we present a simple MLLM-based Image Restoration framework to address this gap, namely Multi-modal Large Language Model based Restoration Assistant (LLMRA). We exploit the impressive capabilities of MLLMs to obtain the degradation information for universal image restoration. By employing a pretrained multi-modal large language model and a vision language model, we generate text descriptions and encode them as context embedding with degradation information for the degraded image. Through the proposed Context Enhance Module (CEM) and Degradation Context based Transformer Network (DC-former), we integrate these context embedding into the restoration network, contributing to more accurate and adjustable image restoration. Based on the dialogue with the users, our method leverages image degradation priors from MLLMs, providing low-level attributes descriptions of the input low-quality images and the restored high-quality images simultaneously. Extensive experiments demonstrate the superior performance of our LLMRA in universal image restoration tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12244",
        "abstract url": "https://arxiv.org/abs/2401.12244",
        "title": "Large-scale Reinforcement Learning for Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image diffusion models are a class of deep generative models that have demonstrated an impressive capacity for high-quality image generation. However, these models are susceptible to implicit biases that arise from web-scale text-image training pairs and may inaccurately model aspects of images we care about. This can result in suboptimal samples, model bias, and images that do not align with human ethics and preferences. In this paper, we present an effective scalable algorithm to improve diffusion models using Reinforcement Learning (RL) across a diverse set of reward functions, such as human preference, compositionality, and fairness over millions of images. We illustrate how our approach substantially outperforms existing methods for aligning diffusion models with human preferences. We further illustrate how this substantially improves pretrained Stable Diffusion (SD) models, generating samples that are preferred by humans 80.3% of the time over those from the base SD model while simultaneously improving both the composition and diversity of generated samples.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12251",
        "abstract url": "https://arxiv.org/abs/2401.12251",
        "title": "Diffusion Representation for Asymmetric Kernels",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "We extend the diffusion-map formalism to data sets that are induced by asymmetric kernels. Analytical convergence results of the resulting expansion are proved, and an algorithm is proposed to perform the dimensional reduction. In this work we study data sets in which its geometry structure is induced by an asymmetric kernel. We use a priori coordinate system to represent this geometry and, thus, be able to improve the computational complexity of reducing the dimensionality of data sets. A coordinate system connected to the tensor product of Fourier basis is used to represent the underlying geometric structure obtained by the diffusion-map, thus reducing the dimensionality of the data set and making use of the speedup provided by the two-dimensional Fast Fourier Transform algorithm (2-D FFT). We compare our results with those obtained by other eigenvalue expansions, and verify the efficiency of the algorithms with synthetic data, as well as with real data from applications including climate change studies.",
        "subjects": [
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11115",
        "abstract url": "https://arxiv.org/abs/2401.11115",
        "title": "MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Controllable generation of 3D human motions becomes an important topic as the world embraces digital transformation. Existing works, though making promising progress with the advent of diffusion models, heavily rely on meticulously captured and annotated (e.g., text) high-quality motion corpus, a resource-intensive endeavor in the real world. This motivates our proposed MotionMix, a simple yet effective weakly-supervised diffusion model that leverages both noisy and unannotated motion sequences. Specifically, we separate the denoising objectives of a diffusion model into two stages: obtaining conditional rough motion approximations in the initial $T-T^*$ steps by learning the noisy annotated motions, followed by the unconditional refinement of these preliminary motions during the last $T^*$ steps using unannotated motions. Notably, though learning from two sources of imperfect data, our model does not compromise motion generation quality compared to fully supervised approaches that access gold data. Extensive experiments on several benchmarks demonstrate that our MotionMix, as a versatile framework, consistently achieves state-of-the-art performances on text-to-motion, action-to-motion, and music-to-dance tasks. Project page: https://nhathoang2002.github.io/MotionMix-page/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at the 38th Association for the Advancement of Artificial Intelligence (AAAI) Conference on Artificial Intelligence, Main Conference"
    },
    {
        "paper id": "2401.11126",
        "abstract url": "https://arxiv.org/abs/2401.11126",
        "title": "CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive Attackers for Security Applications",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Ensemble defenses, are widely employed in various security-related applications to enhance model performance and robustness. The widespread adoption of these techniques also raises many questions: Are general ensembles defenses guaranteed to be more robust than individuals? Will stronger adaptive attacks defeat existing ensemble defense strategies as the cybersecurity arms race progresses? Can ensemble defenses achieve adversarial robustness to different types of attacks simultaneously and resist the continually adjusted adaptive attacks? Unfortunately, these critical questions remain unresolved as there are no platforms for comprehensive evaluation of ensemble adversarial attacks and defenses in the cybersecurity domain. In this paper, we propose a general Cybersecurity Adversarial Robustness Evaluation (CARE) platform aiming to bridge this gap.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11176",
        "abstract url": "https://arxiv.org/abs/2401.11176",
        "title": "Data-Driven Target Localization: Benchmarking Gradient Descent Using the Cramer-Rao Bound",
        "rating": "-0.5",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In modern radar systems, precise target localization using azimuth and velocity estimation is paramount. Traditional unbiased estimation methods have utilized gradient descent algorithms to reach the theoretical limits of the Cramer Rao Bound (CRB) for the error of the parameter estimates. As an extension, we demonstrate on a realistic simulated example scenario that our earlier presented data-driven neural network model outperforms these traditional methods, yielding improved accuracies in target azimuth and velocity estimation. We emphasize, however, that this improvement does not imply that the neural network outperforms the CRB itself. Rather, the enhanced performance is attributed to the biased nature of the neural network approach. Our findings underscore the potential of employing deep learning methods in radar systems to achieve more accurate localization in cluttered and dynamic environments.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11238",
        "abstract url": "https://arxiv.org/abs/2401.11238",
        "title": "Can global, extended and repeated ransomware attacks overcome the users status quo bias and cause a switch of system",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Ransomware attack effectiveness has increased causing far reaching consequences that are not fully understood. The ability to disrupt core services, the global reach, extended duration, and the repetition has increased their ability to harm organizations. One aspect that needs to be understood better is the effect on the user. The user in the current environment is exposed to new technologies that might be adopted, but there are also habits of using existing systems. The habits have developed over time with trust increasing in the organization in contact directly and the institutions supporting it. This research explores whether the global, extended, and repeated RW attacks reduce the trust and inertia sufficiently to change long-held habits in using information systems. The model tested measures the effect of the RW attack on the e-commerce status quo to evaluate if it is significant enough to overcome the users resistance to change.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "International Journal of Information Systems in the Service Sector (2022)"
    },
    {
        "paper id": "2401.11288",
        "abstract url": "https://arxiv.org/abs/2401.11288",
        "title": "Long-Term Fair Decision Making through Deep Generative Models",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "This paper studies long-term fair machine learning which aims to mitigate group disparity over the long term in sequential decision-making systems. To define long-term fairness, we leverage the temporal causal graph and use the 1-Wasserstein distance between the interventional distributions of different demographic groups at a sufficiently large time step as the quantitative metric. Then, we propose a three-phase learning framework where the decision model is trained on high-fidelity data generated by a deep generative model. We formulate the optimization problem as a performative risk minimization and adopt the repeated gradient descent algorithm for learning. The empirical evaluation shows the efficacy of the proposed method using both synthetic and semi-synthetic datasets.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11330",
        "abstract url": "https://arxiv.org/abs/2401.11330",
        "title": "Source Detection in Networks using the Stationary Distribution of a Markov Chain",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Nowadays, the diffusion of information through social networks is a powerful phenomenon. One common way to model diffusions in social networks is the Independent Cascade (IC) model. Given a set of infected nodes according to the IC model, a natural problem is the source detection problem, in which the goal is to identify the unique node that has started the diffusion. Maximum Likelihood Estimation (MLE) is a common approach for tackling the source detection problem, but it is computationally hard. In this work, we propose an efficient method for the source detection problem under the MLE approach, which is based on computing the stationary distribution of a Markov chain. Using simulations, we demonstrate the effectiveness of our method compared to other state-of-the-art methods from the literature, both on random and real-world networks.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11372",
        "abstract url": "https://arxiv.org/abs/2401.11372",
        "title": "Back-stepping Experience Replay with Application to Model-free Reinforcement Learning for a Soft Snake Robot",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot",
                "navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a novel technique, Back-stepping Experience Replay (BER), that is compatible with arbitrary off-policy reinforcement learning (RL) algorithms. BER aims to enhance learning efficiency in systems with approximate reversibility, reducing the need for complex reward shaping. The method constructs reversed trajectories using back-stepping transitions to reach random or fixed targets. Interpretable as a bi-directional approach, BER addresses inaccuracies in back-stepping transitions through a distillation of the replay experience during learning. Given the intricate nature of soft robots and their complex interactions with environments, we present an application of BER in a model-free RL approach for the locomotion and navigation of a soft snake robot, which is capable of serpentine motion enabled by anisotropic friction between the body and ground. In addition, a dynamic simulator is developed to assess the effectiveness and efficiency of the BER algorithm, in which the robot demonstrates successful learning (reaching a 100% success rate) and adeptly reaches random targets, achieving an average speed 48% faster than that of the best baseline approach.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2402.00041",
        "abstract url": "https://arxiv.org/abs/2402.00041",
        "title": "Spatial-temporal-demand clustering for solving large-scale vehicle routing problems with time windows",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Several metaheuristics use decomposition and pruning strategies to solve large-scale instances of the vehicle routing problem (VRP). Those complexity reduction techniques often rely on simple, problem-specific rules. However, the growth in available data and advances in computer hardware enable data-based approaches that use machine learning (ML) to improve scalability of solution algorithms. We propose a decompose-route-improve (DRI) framework that groups customers using clustering. Its similarity metric incorporates customers' spatial, temporal, and demand data and is formulated to reflect the problem's objective function and constraints. The resulting sub-routing problems can independently be solved using any suitable algorithm. We apply pruned local search (LS) between solved subproblems to improve the overall solution. Pruning is based on customers' similarity information obtained in the decomposition phase. In a computational study, we parameterize and compare existing clustering algorithms and benchmark the DRI against the Hybrid Genetic Search (HGS) of Vidal et al. (2013). Results show that our data-based approach outperforms classic cluster-first, route-second approaches solely based on customers' spatial information. The newly introduced similarity metric forms separate sub-VRPs and improves the selection of LS moves in the improvement phase. Thus, the DRI scales existing metaheuristics to achieve high-quality solutions faster for large-scale VRPs by efficiently reducing complexity. Further, the DRI can be easily adapted to various solution methods and VRP characteristics, such as distribution of customer locations and demands, depot location, and different time window scenarios, making it a generalizable approach to solving routing problems.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.NE",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06635",
        "abstract url": "https://arxiv.org/abs/2402.06635",
        "title": "Large (and Deep) Factor Models",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We open up the black box behind Deep Learning for portfolio optimization and prove that a sufficiently wide and arbitrarily deep neural network (DNN) trained to maximize the Sharpe ratio of the Stochastic Discount Factor (SDF) is equivalent to a large factor model (LFM): A linear factor pricing model that uses many non-linear characteristics. The nature of these characteristics depends on the architecture of the DNN in an explicit, tractable fashion. This makes it possible to derive end-to-end trained DNN-based SDFs in closed form for the first time. We evaluate LFMs empirically and show how various architectural choices impact SDF performance. We document the virtue of depth complexity: With enough data, the out-of-sample performance of DNN-SDF is increasing in the NN depth, saturating at huge depths of around 100 hidden layers.",
        "subjects": [
            "q-fin.ST",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11137",
        "abstract url": "https://arxiv.org/abs/2401.11137",
        "title": "Reconfigurable Intelligent Surface-Enabled Array Radar for Interference Mitigation",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "Conventional active array radars often jointly design the transmit and receive beamforming for effectively suppressing interferences. To further promote the interference suppression performance, this paper introduces a reconfigurable intelligent surface (RIS) to assist the radar receiver because the RIS has the ability to bring plentiful additional degrees-of-freedom. To maximize the output signal-to-interference-plus-noise ratio (SINR) of receive array, we formulate the codesign of transmit beamforming and RIS-assisted receive beamforming into a nonconvex constrained fractional programming problem, and then propose an alternating minimization-based algorithm to jointly optimize the transmitor beamfmer, receive beamformer and RIS reflection coefficients. Concretely, we translate the RIS reflection coefficients design into a series of unimodular quadratic programming (UQP) subproblems by employing the Dinkelbach transform, and offer the closed-form optimal solutions of transmit and receive beamformers according to the minimum variance distortionless response principle. To tackle the UQP subproblems efficiently, we propose a second-order Riemannian Newton method (RNM) with improved Riemannian Newton direction, which avoids the line search and has better convergence speed than typical first-order Riemannian manifold optimization methods. Moreover, we derive the convergence of the proposed codesign algorithm by deducing the explicit convergence condition of RNM. We also analyze the computational complexity. Numerical results demonstrate that the proposed RIS-assisted array radar has superior performance of interference suppression to the RIS-free one, and the SINR improvement is proportional to the number of RIS elements.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "29 pages, 9 figures"
    },
    {
        "paper id": "2401.11148",
        "abstract url": "https://arxiv.org/abs/2401.11148",
        "title": "Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe Reinforcement Learning",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving"
            ]
        ],
        "abstract": "Connected and automated vehicles (CAVs) have recently gained prominence in traffic research due to advances in communication technology and autonomous driving. Various longitudinal control strategies for CAVs have been developed to enhance traffic efficiency, stability, and safety in mixed-autonomy scenarios. Deep reinforcement learning (DRL) is one promising strategy for mixed-autonomy platoon control, thanks to its capability of managing complex scenarios in real time after sufficient offline training. However, there are three research gaps for DRL-based mixed-autonomy platoon control: (i) the lack of theoretical collision-free guarantees, (ii) the widely adopted but impractical assumption of skilled and rational drivers who will not collide with preceding vehicles, and (iii) the strong assumption of a known human driver model. To address these research gaps, we propose a safe DRL-based controller that can provide a system-level safety guarantee for mixed-autonomy platoon control. First, we combine control barrier function (CBF)-based safety constraints and DRL via a quadratic programming (QP)-based differentiable neural network layer to provide theoretical safety guarantees. Second, we incorporate system-level safety constraints into our proposed method to account for the safety of both CAVs and the following HDVs to address the potential collisions due to irrational human driving behavior. Third, we devise a learning-based system identification approach to estimate the unknown human car-following behavior in the real system. Simulation results demonstrate that our proposed method effectively ensures CAV safety and improves HDV safety in mixed platoon environments while simultaneously enhancing traffic capacity and string stability.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11174",
        "abstract url": "https://arxiv.org/abs/2401.11174",
        "title": "Pixel-Wise Recognition for Holistic Surgical Scene Understanding",
        "rating": "-1",
        "keywords": [
            [
                "Surgical",
                "Endoscopic"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents the Holistic and Multi-Granular Surgical Scene Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that models surgical scene understanding as a hierarchy of complementary tasks with varying levels of granularity. Our approach enables a multi-level comprehension of surgical activities, encompassing long-term tasks such as surgical phases and steps recognition and short-term tasks including surgical instrument segmentation and atomic visual actions detection. To exploit our proposed benchmark, we introduce the Transformers for Actions, Phases, Steps, and Instrument Segmentation (TAPIS) model, a general architecture that combines a global video feature extractor with localized region proposals from an instrument segmentation model to tackle the multi-granularity of our benchmark. Through extensive experimentation, we demonstrate the impact of including segmentation annotations in short-term recognition tasks, highlight the varying granularity requirements of each task, and establish TAPIS's superiority over previously proposed baselines and conventional CNN-based models. Additionally, we validate the robustness of our method across multiple public benchmarks, confirming the reliability and applicability of our dataset. This work represents a significant step forward in Endoscopic Vision, offering a novel and comprehensive framework for future research towards a holistic understanding of surgical procedures.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Preprint submitted to Medical Image Analysis. Official extension of previous MICCAI 2022 (https://link.springer.com/chapter/10.1007/978-3-031-16449-1_42) and ISBI 2023 (https://ieeexplore.ieee.org/document/10230819) orals. Data and codes are available at https://github.com/BCV-Uniandes/GraSP"
    },
    {
        "paper id": "2401.11183",
        "abstract url": "https://arxiv.org/abs/2401.11183",
        "title": "Predictive stability filters for nonlinear dynamical systems affected by disturbances",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Predictive safety filters provide a way of projecting potentially unsafe inputs, proposed, e.g. by a human or learning-based controller, onto the set of inputs that guarantee recursive state and input constraint satisfaction by leveraging model predictive control techniques. In this paper, we extend this framework such that in addition, robust asymptotic stability of the closed-loop system can be guaranteed by enforcing a decrease of an implicit Lyapunov function which is constructed using a predicted system trajectory. Differently from previous results, we show robust asymptotic stability with respect to a predefined disturbance set on an extended state consisting of the system state and a warmstart input sequence. The proposed strategy is applied to an automotive lane keeping example in simulation.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "Accepted at NMPC'24"
    },
    {
        "paper id": "2401.11187",
        "abstract url": "https://arxiv.org/abs/2401.11187",
        "title": "The degree-diameter problem for plane graphs with pentagonal faces",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The degree-diameter problem consists of finding the maximum number of vertices $n$ of a graph with diameter $d$ and maximum degree $\u0394$. This problem is well studied, and has been solved for plane graphs of low diameter in which every face is bounded by a 3-cycle (triangulations), and plane graphs in which every face is bounded by a 4-cycle (quadrangulations). In this paper, we solve the degree diameter problem for plane graphs of diameter 3 in which every face is bounded by a 5-cycle (pentagulations). We prove that if $\u0394\\geq 8$, then $n \\leq 3\u0394- 1$ for such graphs. This bound is sharp for $\u0394$ odd.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "34 pages, 33 figures, 1 table. This paper is based on a chapter in the Author's PhD thesis: Distances in Planar graphs, at the University of Cape Town, faculty of science, department of mathematics and applied mathematics (2001)"
    },
    {
        "paper id": "2401.11191",
        "abstract url": "https://arxiv.org/abs/2401.11191",
        "title": "Angular velocity and linear acceleration measurement bias estimators for the rigid body system with global exponential convergence",
        "rating": "-1",
        "keywords": [
            [
                "LiDAR"
            ]
        ],
        "abstract": "Rigid body systems usually consider measurements of the pose of the body using onboard cameras/LiDAR systems, that of linear acceleration using an accelerometer and of angular velocity using an IMU. However, the measurements of the linear acceleration and angular velocity are usually biased with an unknown constant or slowly varying bias. We propose a measurement bias estimator for such systems under assumption of boundedness of angular velocity. We also provide continuous estimates to the state of the system, i.e. the pose, linear velocity, and position of the body. These estimates are globally exponentially convergent to the state of the rigid body system. We propose two bias estimators designed with the estimate of the pose in the ambient Euclidean space of the Special Euclidean group and show global exponential convergence of the proposed observers to the state of the system. The first observer assumes knowledge of bounds of the angular velocity, while the second observer uses a Riccati observer to overcome this limitation. We show the convergence with an example of a rigid body rotation and translation system on the special Euclidean group. We show that the observer is able to estimate the bias using data collected from an Intel Realsense camera.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11203",
        "abstract url": "https://arxiv.org/abs/2401.11203",
        "title": "Obstacle-Aware Navigation of Soft Growing Robots via Deep Reinforcement Learning",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "Soft growing robots, are a type of robots that are designed to move and adapt to their environment in a similar way to how plants grow and move with potential applications where they could be used to navigate through tight spaces, dangerous terrain, and hard-to-reach areas. This research explores the application of deep reinforcement Q-learning algorithm for facilitating the navigation of the soft growing robots in cluttered environments. The proposed algorithm utilizes the flexibility of the soft robot to adapt and incorporate the interaction between the robot and the environment into the decision-making process. Results from simulations show that the proposed algorithm improves the soft robot's ability to navigate effectively and efficiently in confined spaces. This study presents a promising approach to addressing the challenges faced by growing robots in particular and soft robots general in planning obstacle-aware paths in real-world scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11225",
        "abstract url": "https://arxiv.org/abs/2401.11225",
        "title": "Protecting Personalized Trajectory with Differential Privacy under Temporal Correlations",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "Location-based services (LBSs) in vehicular ad hoc networks (VANETs) offer users numerous conveniences. However, the extensive use of LBSs raises concerns about the privacy of users' trajectories, as adversaries can exploit temporal correlations between different locations to extract personal information. Additionally, users have varying privacy requirements depending on the time and location. To address these issues, this paper proposes a personalized trajectory privacy protection mechanism (PTPPM). This mechanism first uses the temporal correlation between trajectory locations to determine the possible location set for each time instant. We identify a protection location set (PLS) for each location by employing the Hilbert curve-based minimum distance search algorithm. This approach incorporates the complementary features of geo-indistinguishability and distortion privacy. We put forth a novel Permute-and-Flip mechanism for location perturbation, which maps its initial application in data publishing privacy protection to a location perturbation mechanism. This mechanism generates fake locations with smaller perturbation distances while improving the balance between privacy and quality of service (QoS). Simulation results show that our mechanism outperforms the benchmark by providing enhanced privacy protection while meeting user's QoS requirements.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11287",
        "abstract url": "https://arxiv.org/abs/2401.11287",
        "title": "On-The-Fly Algorithm for Reachability in Parametric Timed Games (Extended Version)",
        "rating": "-1",
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "Parametric Timed Games (PTG) are an extension of the model of Timed Automata. They allow for the verification and synthesis of real-time systems, reactive to their environmeand depending on adjustable parameters. Given a PTG and a reachability objective, we synthesize the values of the parameters such that the game is winning for the controller. We adapt and implement the On-The-Fly algorithm for parameter synthesis for PTG. Several pruning heuristics are introduced, to improve termination and speed of the algorithm. We evaluate the feasibility of parameter synthesis for PTG on two large case studies. Finally, we investigate the correctness guarantee of the algorithm: though the problem is undecidable, our semi-algorithm produces all correct parameter valuations ``in the limit''.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "26 pages, 4 figures"
    },
    {
        "paper id": "2401.11290",
        "abstract url": "https://arxiv.org/abs/2401.11290",
        "title": "On Dependent Variables in Reactive Synthesis",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "Given a Linear Temporal Logic (LTL) formula over input and output variables, reactive synthesis requires us to design a deterministic Mealy machine that gives the values of outputs at every time step for every sequence of inputs, such that the LTL formula is satisfied. In this paper, we investigate the notion of dependent variables in the context of reactive synthesis. Inspired by successful pre-processing steps in Boolean functional synthesis, we define dependent variables as output variables that are uniquely assigned, given an assignment, to all other variables and the history so far. We describe an automata-based approach for finding a set of dependent variables. Using this, we show that dependent variables are surprisingly common in reactive synthesis benchmarks. Next, we develop a novel synthesis framework that exploits dependent variables to construct an overall synthesis solution. By implementing this framework using the widely used library Spot, we show that reactive synthesis using dependent variables can solve some problems beyond the reach of several existing techniques. Further, among benchmarks with dependent variables, if the number of non-dependent variables is low (at most 3 in our experiments), our method is able outperform all state-of-the-art tools for synthesis.",
        "subjects": [
            "cs.LO",
            "cs.FL"
        ],
        "comment": "Full version of conference paper published in TACAS'24"
    },
    {
        "paper id": "2401.11313",
        "abstract url": "https://arxiv.org/abs/2401.11313",
        "title": "Weakly-Supervised Semantic Segmentation of Circular-Scan, Synthetic-Aperture-Sonar Imagery",
        "rating": "-1",
        "keywords": [
            [
                "seafloor"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We propose a weakly-supervised framework for the semantic segmentation of circular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of our framework is trained in a supervised manner, on image-level labels, to uncover a set of semi-sparse, spatially-discriminative regions in each image. The classification uncertainty of each region is then evaluated. Those areas with the lowest uncertainties are then chosen to be weakly labeled segmentation seeds, at the pixel level, for the second part of the framework. Each of the seed extents are progressively resized according to an unsupervised, information-theoretic loss with structured-prediction regularizers. This reshaping process uses multi-scale, adaptively-weighted features to delineate class-specific transitions in local image content. Content-addressable memories are inserted at various parts of our framework so that it can leverage features from previously seen images to improve segmentation performance for related images. We evaluate our weakly-supervised framework using real-world CSAS imagery that contains over ten seafloor classes and ten target classes. We show that our framework performs comparably to nine fully-supervised deep networks. Our framework also outperforms eleven of the best weakly-supervised deep networks. We achieve state-of-the-art performance when pre-training on natural imagery. The average absolute performance gap to the next-best weakly-supervised network is well over ten percent for both natural imagery and sonar imagery. This gap is found to be statistically significant.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "Submitted to the IEEE Journal of Oceanic Engineering"
    },
    {
        "paper id": "2401.11333",
        "abstract url": "https://arxiv.org/abs/2401.11333",
        "title": "Error bounds of constant gain least-mean-squares algorithms",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Constant gain least-mean-squares (LMS) algorithms have a wide range of applications in trajectory tracking problems, but the formal convergence of LMS in mean square is not yet fully established. This work provides an upper bound on the constant gain that guarantees a bounded mean-squared error of LMS for a general design vector. These results highlight the role of the fourth-order moment of the design vector. Numerical examples demonstrate the applicability of this upper bound in setting a constant gain in LMS, while existing criteria may fail. We also provide the associated error bound, which can be applied to design vectors with linearly dependent elements.",
        "subjects": [
            "eess.SP",
            "eess.SY"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2401.11344",
        "abstract url": "https://arxiv.org/abs/2401.11344",
        "title": "Decentralized Optimization in Networks with Arbitrary Delays",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We consider the problem of decentralized optimization in networks with communication delays. To accommodate delays, we need decentralized optimization algorithms that work on directed graphs. Existing approaches require nodes to know their out-degree to achieve convergence. We propose a novel gossip-based algorithm that circumvents this requirement, allowing decentralized optimization in networks with communication delays. We prove that our algorithm converges on non-convex objectives, with the same main complexity order term as centralized Stochastic Gradient Descent (SGD), and show that the graph topology and the delays only affect the higher order terms. We provide numerical simulations that illustrate our theoretical results.",
        "subjects": [
            "math.OC",
            "cs.MA",
            "eess.SP",
            "eess.SY"
        ],
        "comment": "Accepted to IEEE ICC 2024"
    },
    {
        "paper id": "2401.11389",
        "abstract url": "https://arxiv.org/abs/2401.11389",
        "title": "MedLM: Exploring Language Models for Medical Question Answering Systems",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of medical Q&A. The findings will provide valuable insights into the suitability of different LMs for specific applications in the medical domain.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12249",
        "abstract url": "https://arxiv.org/abs/2401.12249",
        "title": "Understanding users negative emotions and continuous usage intention in short video platforms",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "While short videos bring a lot of information and happiness to users, they also occupy users time and short videos gradually change peoples living habits. This paper studies the negative effects and negative emotions of users caused by using short video platforms, as well as the users intention to continue using the short video platform when they have negative emotions. Therefore, this study uses flow theory and illusion of control theory to construct a research hypothesis model and preliminarily confirms six influencing factors, and uses sequential mixed research method to conduct quantitative and qualitative research. The results show that users use of short video platforms will have negative emotions and negative emotions will affect users intention to continue to use short video platforms. This study expands the breadth and depth of research on short videos and enriches the research of negative emotions on the intention to continue using human computer interaction software. Additionally, illusion of control theory is introduced into the field of human computer interaction for the first time, which enriches the application scenarios of control illusion theory.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Electronic Commerce Research and Applications (2023)"
    },
    {
        "paper id": "2401.14414",
        "abstract url": "https://arxiv.org/abs/2401.14414",
        "title": "Fuzzy Logic-Based System for Brain Tumour Detection and Classification",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Brain Tumours (BT) are extremely dangerous and difficult to treat. Currently, doctors must manually examine images and manually mark out tumour regions to diagnose BT; this process is time-consuming and error-prone. In recent times, experts have proposed automating approaches for detecting BT at an early stage. The poor accuracy and highly incorrect prediction results of these methods caused them to start the research. In this study, we suggest a fuzzy logic-based system for categorising BT. This study used a dataset of 253 Magnetic Resonance Imaging (MRI) brain images that included tumour and healthy images. The images were first pre-processed. After that, we pull out features like tumour size and the image's global threshold value. The watershed and region-growing approach is used to calculate the tumour size. After that, the fuzzy system receives the two features as input. Accuracy, F1-score, precision, and recall are used to assess the results of the fuzzy by employing both size determination approaches. With the size input variable discovered by the region growth method and global threshold values, the fuzzy system outperforms the watershed method. The significance of this research lies in its potential to revolutionize brain tumour diagnosis by offering a more accurate and efficient automated classification system. By reducing human intervention and providing reliable results, this approach could assist medical professionals in making timely and precise decisions, leading to improved patient outcomes and potentially saving lives. The advancement of such automated techniques has the potential to pave the way for enhanced medical imaging analysis and, ultimately, better management of brain tumour cases.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "math.OC"
        ],
        "comment": "14 pages, 9 figures"
    },
    {
        "paper id": "2402.09422",
        "abstract url": "https://arxiv.org/abs/2402.09422",
        "title": "Traffic Flow and Speed Monitoring Based On Optical Fiber Distributed Acoustic Sensor",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "In the realm of intelligent transportation systems, accurate and reliable traffic monitoring is crucial. Traditional devices, such as cameras and lidars, face limitations in adverse weather conditions and complex traffic scenarios, prompting the need for more resilient technologies. This paper presents traffic flow monitoring method using optical fiber-based Distributed Acoustic Sensors (DAS). An innovative vehicle trajectory extraction algorithm is proposed to derive traffic flow statistics. In the processing of optical fiber waterfall diagrams, Butterworth low-pass filter and peaks location search method are employed to determine the entry position of vehicles. Subsequently, line-by-line matching algorithm is proposed to effectively track the trajectories. Experiments were conducted under both real highway and tunnel scenarios, showing that our approach not only extracts vehicle trajectories more accurately than the classical Hough and Radon transform-based methods, but also facilitates the calculation of traffic flow information using the low-cost acoustic sensors. It provides a new reliable means for traffic flow monitoring which can be integrated with existing methods.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "10 pages,23 figures, references added"
    },
    {
        "paper id": "2402.09423",
        "abstract url": "https://arxiv.org/abs/2402.09423",
        "title": "Online Mean Estimation for Multi-frame Optical Fiber Signals On Highways",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "In the era of Big Data, prompt analysis and processing of data sets is critical. Meanwhile, statistical methods provide key tools and techniques to extract valuable insights and knowledge from complex data sets. This paper creatively applies statistical methods to the field of traffic, particularly focusing on the preprocessing of multi-frame signals obtained by optical fiber-based Distributed Acoustic Sensing (DAS) system. An online non-parametric regression model based on Local Polynomial Regression (LPR) and variable bandwidth selection is employed to dynamically update the estimation of mean function as signals flow in. This mean estimation method can derive average information of multi-frame fiber signals, thus providing the basis for the subsequent vehicle trajectory extraction algorithms. To further evaluate the effectiveness of the proposed method, comparison experiments were conducted under real highway scenarios, showing that our approach not only deals with multi-frame signals more accurately than the classical filter-based Kalman and Wavelet methods, but also meets the needs better under the condition of saving memory and rapid responses. It provides a new reliable means for signal processing which can be integrated with other existing methods.",
        "subjects": [
            "eess.SP",
            "physics.data-an"
        ],
        "comment": "8 pages, 8figures"
    },
    {
        "paper id": "2402.16865",
        "abstract url": "https://arxiv.org/abs/2402.16865",
        "title": "Improve Robustness of Eye Disease Detection by including Learnable Probabilistic Discrete Latent Variables into Machine Learning Models",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "diagnosis",
                "Disease",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Ocular diseases, ranging from diabetic retinopathy to glaucoma, present a significant public health challenge due to their prevalence and potential for causing vision impairment. Early and accurate diagnosis is crucial for effective treatment and management.In recent years, deep learning models have emerged as powerful tools for analysing medical images, including ocular imaging . However, challenges persist in model interpretability and uncertainty estimation, which are critical for clinical decision-making. This study introduces a novel application of GFlowOut, leveraging the probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks, for the classification and analysis of ocular diseases using eye fundus images. We develop a robust and generalizable method that utilizes GFlowOut integrated with ResNet18 and ViT models as backbone in identifying various ocular conditions. This study employs a unique set of dropout masks - none, random, bottomup, and topdown - to enhance model performance in analyzing ocular images. Our results demonstrate that the bottomup GFlowOut mask significantly improves accuracy, outperforming the traditional dropout approach.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "This is a work in progress"
    },
    {
        "paper id": "2401.11117",
        "abstract url": "https://arxiv.org/abs/2401.11117",
        "title": "A Finger on the Pulse of Cardiovascular Health: Smartphone Photoplethysmography-Based Pulse Waveform Analysis for Blood Pressure Measurement",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "Health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Routine blood pressure (BP) monitoring, crucial for health assessment, faces challenges such as limited access to medical-grade equipment and expertise. Portable cuff BP devices, on the other hand, are cumbersome to carry all day and often cost-prohibitive in less developed countries. Besides, these sphygmomanometer-based devices can cause discomfort and disrupt blood flow during measurement. This study explores the use of smartphones for continuous BP monitoring, focusing on overcoming the trust barriers associated with the opacity of machine learning models in predicting BP from low-quality PPG signals. Our approach included developing models based on cardiovascular literature, using simple statistical methods to estimate BP from smartphone PPG signals with comprehensive data pre-processing, applying SHAP for enhanced interpretability and feature identification, and comparing our methods against standard references using Bland-Altman analysis. Validated with data from 125 participants, the study demonstrated significant correlations in waveform features between smartphone and reference BP monitoring devices. The cross-validation of linear regression [MAE=9.86 and 8.01 mmHg for systolic blood pressure (SBP) and diastolic blood pressure (DBP), respectively] and random forest model (MAE=8.91 and 6.68 mmHg for SBP and DBP) using waveform-only variables demonstrated the feasibility of using a smartphone to estimate BP. Although SHAP analysis identified key feature sets, Bland-Altman results did not fully meet established thresholds (84.64% and 94.69% of MAE<15 mmHg for SBP and DBP, respectively). The study suggests the potential of smartphone cameras to enhance the accuracy and interpretability of machine learning models for daily BP estimation, but also indicates that smartphone PPG-based BP prediction is not yet a replacement for traditional medical devices.",
        "subjects": [
            "eess.SP",
            "cs.CY"
        ],
        "comment": "33 pages, 9 figures"
    },
    {
        "paper id": "2401.11212",
        "abstract url": "https://arxiv.org/abs/2401.11212",
        "title": "Programming Distributed Collective Processes in the eXchange Calculus",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calculus (XC), a core functional language based on neighbouring values (maps from neighbours to values) where state and interaction is handled through a single primitive, exchange, and provide a corresponding implementation in the FCPP language. Then, we exercise distributed collective processes using two case studies: multi-hop message propagation and distributed monitoring of spatial properties. Finally, we discuss the features of the abstraction and its suitability for different kinds of distributed computing applications.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.MA",
            "cs.PL"
        ],
        "comment": "32 pages, 13 figures"
    },
    {
        "paper id": "2401.11249",
        "abstract url": "https://arxiv.org/abs/2401.11249",
        "title": "Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Trust and privacy have emerged as significant concerns in online transactions. Sharing information on health is especially sensitive but it is necessary for purchasing and utilizing health insurance. Evidence shows that consumers are increasingly comfortable with technology in place of humans, but the expanding use of AI potentially changes this. This research explores whether trust and privacy concern are barriers to the adoption of AI in health insurance. Two scenarios are compared: The first scenario has limited AI that is not in the interface and its presence is not explicitly revealed to the consumer. In the second scenario there is an AI interface and AI evaluation, and this is explicitly revealed to the consumer. The two scenarios were modeled and compared using SEM PLS-MGA. The findings show that trust is significantly lower in the second scenario where AI is visible. Privacy concerns are higher with AI but the difference is not statistically significant within the model.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": "Journal of Internet Commerce (2021)"
    },
    {
        "paper id": "2401.11351",
        "abstract url": "https://arxiv.org/abs/2401.11351",
        "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "28 pages. Invited review"
    },
    {
        "paper id": "2401.12243",
        "abstract url": "https://arxiv.org/abs/2401.12243",
        "title": "Constraint-Generation Policy Optimization (CGPO): Nonlinear Programming for Policy Optimization in Mixed Discrete-Continuous MDPs",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose Constraint-Generation Policy Optimization (CGPO) for optimizing policy parameters within compact and interpretable policy classes for mixed discrete-continuous Markov Decision Processes (DC-MDPs). CGPO is not only able to provide bounded policy error guarantees over an infinite range of initial states for many DC-MDPs with expressive nonlinear dynamics, but it can also provably derive optimal policies in cases where it terminates with zero error. Furthermore, CGPO can generate worst-case state trajectories to diagnose policy deficiencies and provide counterfactual explanations of optimal actions. To achieve such results, CGPO proposes a bi-level mixed-integer nonlinear optimization framework for optimizing policies within defined expressivity classes (i.e. piecewise (non)-linear) and reduces it to an optimal constraint generation methodology that adversarially generates worst-case state trajectories. Furthermore, leveraging modern nonlinear optimizers, CGPO can obtain solutions with bounded optimality gap guarantees. We handle stochastic transitions through explicit marginalization (where applicable) or chance-constraints, providing high-probability policy performance guarantees. We also present a road-map for understanding the computational complexities associated with different expressivity classes of policy, reward, and transition dynamics. We experimentally demonstrate the applicability of CGPO in diverse domains, including inventory control, management of a system of water reservoirs, and physics control. In summary, we provide a solution for deriving structured, compact, and explainable policies with bounded performance guarantees, enabling worst-case scenario generation and counterfactual policy diagnostics.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "cs.RO",
            "cs.SC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00043",
        "abstract url": "https://arxiv.org/abs/2402.00043",
        "title": "Interactive and Intelligent Root Cause Analysis in Manufacturing with Causal Bayesian Networks and Knowledge Graphs",
        "rating": "-1.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Root Cause Analysis (RCA) in the manufacturing of electric vehicles is the process of identifying fault causes. Traditionally, the RCA is conducted manually, relying on process expert knowledge. Meanwhile, sensor networks collect significant amounts of data in the manufacturing process. Using this data for RCA makes it more efficient. However, purely data-driven methods like Causal Bayesian Networks have problems scaling to large-scale, real-world manufacturing processes due to the vast amount of potential cause-effect relationships (CERs). Furthermore, purely data-driven methods have the potential to leave out already known CERs or to learn spurious CERs. The paper contributes by proposing an interactive and intelligent RCA tool that combines expert knowledge of an electric vehicle manufacturing process and a data-driven machine learning method. It uses reasoning over a large-scale Knowledge Graph of the manufacturing process while learning a Causal Bayesian Network. In addition, an Interactive User Interface enables a process expert to give feedback to the root cause graph by adding and removing information to the Knowledge Graph. The interactive and intelligent RCA tool reduces the learning time of the Causal Bayesian Network while decreasing the number of spurious CERs. Thus, the interactive and intelligent RCA tool closes the feedback loop between expert and machine learning method.",
        "subjects": [
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00881",
        "abstract url": "https://arxiv.org/abs/2402.00881",
        "title": "On the Interplay of Artificial Intelligence and Space-Air-Ground Integrated Networks: A Survey",
        "rating": "-1.5",
        "keywords": [
            [
                "6G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Space-Air-Ground Integrated Networks (SAGINs), which incorporate space and aerial networks with terrestrial wireless systems, are vital enablers of the emerging sixth-generation (6G) wireless networks. Besides bringing significant benefits to various applications and services, SAGINs are envisioned to extend high-speed broadband coverage to remote areas, such as small towns or mining sites, or areas where terrestrial infrastructure cannot reach, such as airplanes or maritime use cases. However, due to the limited power and storage resources, as well as other constraints introduced by the design of terrestrial networks, SAGINs must be intelligently configured and controlled to satisfy the envisioned requirements. Meanwhile, Artificial Intelligence (AI) is another critical enabler of 6G. Due to massive amounts of available data, AI has been leveraged to address pressing challenges of current and future wireless networks. By adding AI and facilitating the decision-making and prediction procedures, SAGINs can effectively adapt to their surrounding environment, thus enhancing the performance of various metrics. In this work, we aim to investigate the interplay of AI and SAGINs by providing a holistic overview of state-of-the-art research in AI-enabled SAGINs. Specifically, we present a comprehensive overview of some potential applications of AI in SAGINs. We also cover open issues in employing AI and detail the contributions of SAGINs in the development of AI. Finally, we highlight some limitations of the existing research works and outline potential future research directions.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.16863",
        "abstract url": "https://arxiv.org/abs/2402.16863",
        "title": "Quantum Inspired Chaotic Salp Swarm Optimization for Dynamic Optimization",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Many real-world problems are dynamic optimization problems that are unknown beforehand. In practice, unpredictable events such as the arrival of new jobs, due date changes, and reservation cancellations, changes in parameters or constraints make the search environment dynamic. Many algorithms are designed to deal with stationary optimization problems, but these algorithms do not face dynamic optimization problems or manage them correctly. Although some optimization algorithms are proposed to deal with the changes in dynamic environments differently, there are still areas of improvement in existing algorithms due to limitations or drawbacks, especially in terms of locating and following the previously identified optima. With this in mind, we studied a variant of SSA known as QSSO, which integrates the principles of quantum computing. An attempt is made to improve the overall performance of standard SSA to deal with the dynamic environment effectively by locating and tracking the global optima for DOPs. This work is an extension of the proposed new algorithm QSSO, known as the Quantum-inspired Chaotic Salp Swarm Optimization (QCSSO) Algorithm, which details the various approaches considered while solving DOPs. A chaotic operator is employed with quantum computing to respond to change and guarantee to increase individual searchability by improving population diversity and the speed at which the algorithm converges. We experimented by evaluating QCSSO on a well-known generalized dynamic benchmark problem (GDBG) provided for CEC 2009, followed by a comparative numerical study with well-regarded algorithms. As promised, the introduced QCSSO is discovered as the rival algorithm for DOPs.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": "14 pages, 2 figures, 1 algorithm"
    },
    {
        "paper id": "2401.11120",
        "abstract url": "https://arxiv.org/abs/2401.11120",
        "title": "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Background Large Language Models (LLMs), enhanced with Clinical Practice Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS). However, methods for incorporating CPGs into LLMs are not well studied. Methods We develop three distinct methods for incorporating CPGs into LLMs: Binary Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of the proposed methods, we create a set of synthetic patient descriptions and conduct both automatic and human evaluation of the responses generated by four LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was used as the baseline method. We focus on CDS for COVID-19 outpatient treatment as the case study. Results All four LLMs exhibit improved performance when enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP and PAGC in automatic evaluation. All of the proposed methods demonstrated high performance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate superior performance, as compared to plain LLMs with ZSP, in providing accurate recommendations for COVID-19 outpatient treatment, which also highlights the potential for broader applications beyond the case study.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11131",
        "abstract url": "https://arxiv.org/abs/2401.11131",
        "title": "Towards a Non-Ideal Methodological Framework for Responsible ML",
        "rating": "-2",
        "keywords": [
            [
                "diagnosing"
            ]
        ],
        "abstract": "Though ML practitioners increasingly employ various Responsible ML (RML) strategies, their methodological approach in practice is still unclear. In particular, the constraints, assumptions, and choices of practitioners with technical duties -- such as developers, engineers, and data scientists -- are often implicit, subtle, and under-scrutinized in HCI and related fields. We interviewed 22 technically oriented ML practitioners across seven domains to understand the characteristics of their methodological approaches to RML through the lens of ideal and non-ideal theorizing of fairness. We find that practitioners' methodological approaches fall along a spectrum of idealization. While they structured their approaches through ideal theorizing, such as by abstracting RML workflow from the inquiry of applicability of ML, they did not pay deliberate attention and systematically documented their non-ideal approaches, such as diagnosing imperfect conditions. We end our paper with a discussion of a new methodological approach, inspired by elements of non-ideal theory, to structure technical practitioners' RML process and facilitate collaboration with other stakeholders.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "20 pages, single-column, preprint for conference"
    },
    {
        "paper id": "2401.11224",
        "abstract url": "https://arxiv.org/abs/2401.11224",
        "title": "Susceptibility of Adversarial Attack on Medical Image Segmentation Models",
        "rating": "-2",
        "keywords": [
            [
                "Attack"
            ],
            [
                "Medical",
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The nature of deep neural networks has given rise to a variety of attacks, but little work has been done to address the effect of adversarial attacks on segmentation models trained on MRI datasets. In light of the grave consequences that such attacks could cause, we explore four models from the U-Net family and examine their responses to the Fast Gradient Sign Method (FGSM) attack. We conduct FGSM attacks on each of them and experiment with various schemes to conduct the attacks. In this paper, we find that medical imaging segmentation models are indeed vulnerable to adversarial attacks and that there is a negligible correlation between parameter size and adversarial attack success. Furthermore, we show that using a different loss function than the one used for training yields higher adversarial attack success, contrary to what the FGSM authors suggested. In future efforts, we will conduct the experiments detailed in this paper with more segmentation models and different attacks. We will also attempt to find ways to counteract the attacks by using model ensembles or special data augmentations. Our code is available at https://github.com/ZhongxuanWang/adv_attk",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "6 pages, 8 figures, presented at 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI) conference"
    },
    {
        "paper id": "2401.11231",
        "abstract url": "https://arxiv.org/abs/2401.11231",
        "title": "Two-Insertion/Deletion/Substitution Correcting Codes",
        "rating": "-2",
        "keywords": [
            [
                "DNA"
            ]
        ],
        "abstract": "In recent years, the emergence of DNA storage systems has led to a widespread focus on the research of codes correcting insertions, deletions, and classic substitutions. During the initial investigation, Levenshtein discovered the VT codes are precisely capable of correcting single insertion/deletion and then extended the VT construction to single-insertion/deletion/substitution ($1$-ins/del/sub) correcting codes. Inspired by this, we generalize the recent findings of $1$-del $1$-sub correcting codes with redundancy $6\\log_{2}n+O(1)$ to more general $2$-ins/del/sub correcting codes without increasing the redundancy. Our key technique is to apply higher-order VT syndromes to distinct objects and accomplish a systematic classification of all error patterns.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11235",
        "abstract url": "https://arxiv.org/abs/2401.11235",
        "title": "TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision",
        "rating": "-2",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Time series anomaly detection (TSAD) plays a vital role in various domains such as healthcare, networks, and industry. Considering labels are crucial for detection but difficult to obtain, we turn to TSAD with inexact supervision: only series-level labels are provided during the training phase, while point-level anomalies are predicted during the testing phase. Previous works follow a traditional multi-instance learning (MIL) approach, which focuses on encouraging high anomaly scores at individual time steps. However, time series anomalies are not only limited to individual point anomalies, they can also be collective anomalies, typically exhibiting abnormal patterns over subsequences. To address the challenge of collective anomalies, in this paper, we propose a tree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to divide the entire series into multiple nodes, where nodes at different levels represent subsequences with different lengths. Then, the subsequence features are extracted to determine the presence of collective anomalies. Finally, we calculate point-level anomaly scores by aggregating features from nodes at different levels. Experiments conducted on seven public datasets and eight baselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1- score compared to previous state-of-the-art methods. The code is available at https://github.com/fly-orange/TreeMIL.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "This paper has been accepted by IEEE ICASSP 2024"
    },
    {
        "paper id": "2401.11236",
        "abstract url": "https://arxiv.org/abs/2401.11236",
        "title": "Hierarchical Cell-Free Massive MIMO for High Capacity with Simple Implementation",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Cell-free massive multi-input multi-output (MIMO) has recently gained much attention for its potential in shaping the landscape of sixth-generation (6G) wireless systems. This paper proposes a hierarchical network architecture tailored for cell-free massive MIMO, seamlessly integrating co-located and distributed antennas. A central base station (CBS), equipped with an antenna array, positions itself near the center of the coverage area, complemented by distributed access points spanning the periphery. The proposed architecture remarkably outperforms conventional cell-free networks, demonstrating superior sum throughput while maintaining a comparable worst-case per-user spectral efficiency. Meanwhile, the implementation cost associated with the fronthaul network is substantially diminished.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "2024 IEEE International Conference on Communications (ICC-2024)"
    },
    {
        "paper id": "2401.11255",
        "abstract url": "https://arxiv.org/abs/2401.11255",
        "title": "Visualization Generation with Large Language Models: An Evaluation",
        "rating": "-2",
        "keywords": [
            [
                "grammar"
            ]
        ],
        "abstract": "Analysts frequently need to create visualizations in the data analysis process to obtain and communicate insights. To reduce the burden of creating visualizations, previous research has developed various approaches for analysts to create visualizations from natural language queries. Recent studies have demonstrated the capabilities of large language models in natural language understanding and code generation tasks. The capabilities imply the potential of using large language models to generate visualization specifications from natural language queries. In this paper, we evaluate the capability of a large language model to generate visualization specifications on the task of natural language to visualization (NL2VIS). More specifically, we have opted for GPT-3.5 and Vega-Lite to represent large language models and visualization specifications, respectively. The evaluation is conducted on the nvBench dataset. In the evaluation, we utilize both zero-shot and few-shot prompt strategies. The results demonstrate that GPT-3.5 surpasses previous NL2VIS approaches. Additionally, the performance of few-shot prompts is higher than that of zero-shot prompts. We discuss the limitations of GPT-3.5 on NL2VIS, such as misunderstanding the data attributes and grammar errors in generated specifications. We also summarized several directions, such as correcting the ground truth and reducing the ambiguities in natural language queries, to improve the NL2VIS benchmark.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11258",
        "abstract url": "https://arxiv.org/abs/2401.11258",
        "title": "Adaptive Quantum Optimized Centroid Initialization",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "One of the major benefits of quantum computing is the potential to resolve complex computational problems faster than can be done by classical methods. There are many prototype-based clustering methods in use today, and selection of the starting nodes for the center points is often done randomly. For prototype-based clustering algorithms, this could lead to much slower convergence times. One of the causes of this may be prototype-based clustering accepting a local minima as a valid solution when there are possibly better solutions. Quantum computing, specifically quantum annealing, offers a solution to these problems by mapping the initial centroid problem to an Ising Hamiltonian where over time the lowest energy in the spectrum correlates to a valid, but better solution. A first approach to this problem utilizing quantum annealing was known as Quantum Optimized Centroid Initialization (QOCI), but this approach has some limitations both in results and performance. We will present a modification of QOCI known as Adaptive Quantum Optimized Centroid Initialization (AQOCI) which addresses many of the limitations in QOCI. The results presented are comparable to those obtained using classical techniques as well as being superior to those results found using QOCI.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "QPL 2024 Submission. arXiv admin note: text overlap with arXiv:2305.08626"
    },
    {
        "paper id": "2401.11286",
        "abstract url": "https://arxiv.org/abs/2401.11286",
        "title": "Data repairing and resolution enhancement using data-driven modal decomposition and deep learning",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "This paper introduces a new series of methods which combine modal decomposition algorithms, such as singular value decomposition and high-order singular value decomposition, and deep learning architectures to repair, enhance, and increase the quality and precision of numerical and experimental data. A combination of two- and three-dimensional, numerical and experimental dasasets are used to demonstrate the reconstruction capacity of the presented methods, showing that these methods can be used to reconstruct any type of dataset, showing outstanding results when applied to highly complex data, which is noisy. The combination of benefits of these techniques results in a series of data-driven methods which are capable of repairing and/or enhancing the resolution of a dataset by identifying the underlying physics that define the data, which is incomplete or under-resolved, filtering any existing noise. These methods and the Python codes are included in the first release of ModelFLOWs-app.",
        "subjects": [
            "cs.CE",
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11362",
        "abstract url": "https://arxiv.org/abs/2401.11362",
        "title": "Quantum Circuit Simulation with Fast Tensor Decision Diagram",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum circuit simulation is a challenging computational problem crucial for quantum computing research and development. The predominant approaches in this area center on tensor networks, prized for their better concurrency and less computation than methods using full quantum vectors and matrices. However, even with the advantages, array-based tensors can have significant redundancy. We present a novel open-source framework that harnesses tensor decision diagrams to eliminate overheads and achieve significant speedups over prior approaches. On average, it delivers a speedup of 37$\\times$ over Google's TensorNetwork library on redundancy-rich circuits, and 25$\\times$ and 144$\\times$ over quantum multi-valued decision diagram and prior tensor decision diagram implementation, respectively, on Google random quantum circuits. To achieve this, we introduce a new linear-complexity rank simplification algorithm, Tetris, and edge-centric data structures for recursive tensor decision diagram operations. Additionally, we explore the efficacy of tensor network contraction ordering and optimizations from binary decision diagrams.",
        "subjects": [
            "quant-ph",
            "cs.DS",
            "cs.ET"
        ],
        "comment": "Camera-Ready version. Accepted to ISQED 2024"
    },
    {
        "paper id": "2401.11371",
        "abstract url": "https://arxiv.org/abs/2401.11371",
        "title": "Modeling Considerations for Developing Deep Space Autonomous Spacecraft and Simulators",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "To extend the limited scope of autonomy used in prior missions for operation in distant and complex environments, there is a need to further develop and mature autonomy that jointly reasons over multiple subsystems, which we term system-level autonomy. System-level autonomy establishes situational awareness that resolves conflicting information across subsystems, which may necessitate the refinement and interconnection of the underlying spacecraft and environment onboard models. However, with a limited understanding of the assumptions and tradeoffs of modeling to arbitrary extents, designing onboard models to support system-level capabilities presents a significant challenge. In this paper, we provide a detailed analysis of the increasing levels of model fidelity for several key spacecraft subsystems, with the goal of informing future spacecraft functional- and system-level autonomy algorithms and the physics-based simulators on which they are validated. We do not argue for the adoption of a particular fidelity class of models but, instead, highlight the potential tradeoffs and opportunities associated with the use of models for onboard autonomy and in physics-based simulators at various fidelity levels. We ground our analysis in the context of deep space exploration of small bodies, an emerging frontier for autonomous spacecraft operation in space, where the choice of models employed onboard the spacecraft may determine mission success. We conduct our experiments in the Multi-Spacecraft Concept and Autonomy Tool (MuSCAT), a software suite for developing spacecraft autonomy algorithms.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Project page: https://sites.google.com/stanford.edu/spacecraft-models. 20 pages, 8 figures. Accepted to the IEEE Conference on Aerospace (AeroConf) 2024"
    },
    {
        "paper id": "2401.11376",
        "abstract url": "https://arxiv.org/abs/2401.11376",
        "title": "Self-supervised Contrastive Learning for 6G UM-MIMO THz Communications: Improving Robustness Under Imperfect CSI",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "This paper investigates the potential of contrastive learning in 6G ultra-massive multiple-input multiple-output (UM-MIMO) communication systems, specifically focusing on hybrid beamforming under imperfect channel state information (CSI) conditions at THz. UM-MIMO systems are promising for future 6G wireless communication networks due to their high spectral efficiency and capacity. The accuracy of CSI significantly influences the performance of UM-MIMO systems. However, acquiring perfect CSI is challenging due to various practical constraints such as channel estimation errors, feedback delays, and hardware imperfections. To address this issue, we propose a novel self-supervised contrastive learning-based approach for hybrid beamforming, which is robust against imperfect CSI. We demonstrate the power of contrastive learning to tackle the challenges posed by imperfect CSI and show that our proposed method results in improved system performance in terms of achievable rate compared to traditional methods.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 7 figures, Submitted to IEEE International Conference on Communications, 2024"
    },
    {
        "paper id": "2404.15279",
        "abstract url": "https://arxiv.org/abs/2404.15279",
        "title": "Jointly Modeling Spatio-Temporal Features of Tactile Signals for Action Classification",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Tactile signals collected by wearable electronics are essential in modeling and understanding human behavior. One of the main applications of tactile signals is action classification, especially in healthcare and robotics. However, existing tactile classification methods fail to capture the spatial and temporal features of tactile signals simultaneously, which results in sub-optimal performances. In this paper, we design Spatio-Temporal Aware tactility Transformer (STAT) to utilize continuous tactile signals for action classification. We propose spatial and temporal embeddings along with a new temporal pretraining task in our model, which aims to enhance the transformer in modeling the spatio-temporal features of tactile signals. Specially, the designed temporal pretraining task is to differentiate the time order of tubelet inputs to model the temporal properties explicitly. Experimental results on a public action classification dataset demonstrate that our model outperforms state-of-the-art methods in all metrics.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.11252",
        "abstract url": "https://arxiv.org/abs/2401.11252",
        "title": "Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions",
        "rating": "-2.5",
        "keywords": [
            [
                "architecture search",
                "NAS"
            ],
            [
                "Medical",
                "Health",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The widespread adoption of Electronic Health Record (EHR) systems in healthcare institutes has generated vast amounts of medical data, offering significant opportunities for improving healthcare services through deep learning techniques. However, the complex and diverse modalities and feature structures in real-world EHR data pose great challenges for deep learning model design. To address the multi-modality challenge in EHR data, current approaches primarily rely on hand-crafted model architectures based on intuition and empirical experiences, leading to sub-optimal model architectures and limited performance. Therefore, to automate the process of model design for mining EHR data, we propose a novel neural architecture search (NAS) framework named AutoFM, which can automatically search for the optimal model architectures for encoding diverse input modalities and fusion strategies. We conduct thorough experiments on real-world multi-modal EHR data and prediction tasks, and the results demonstrate that our framework not only achieves significant performance improvement over existing state-of-the-art methods but also discovers meaningful network architectures effectively.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted by SDM 2024"
    },
    {
        "paper id": "2401.11214",
        "abstract url": "https://arxiv.org/abs/2401.11214",
        "title": "3D Receiver for Molecular Communications in Internet of Organoids",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "bio-inspired",
                "organ"
            ]
        ],
        "abstract": "Organoids have garnered attention due to their effectiveness in modeling the 3D structure of organ interactions. However, the communication engineering perspective has received relatively little attention. One way to achieve organoids communication is molecular communication (MC). Molecular communication is a bio-inspired communication paradigm that uses molecules as information carriers. It is considered one of the most promising methods for enabling the Internet of Nano-Things (IoNT) and nanonetworks. BioFETs are commonly used to implement practical MC receivers. However, most previous analyses have focused on a planar device, neglecting considerations like the threshold voltage and its potential 3D structure. This paper introduces the first FinFET-based MC receiver that covers both the top and side gates with receptors. Both binding noise and flicker noise are considered in the analysis. The performance, in terms of signal-to-noise ratio (SNR) and symbol error probability (SEP), is compared with that of the 2D receiver.",
        "subjects": [
            "cs.ET",
            "eess.SY"
        ],
        "comment": "10 pages, 11 figures"
    },
    {
        "paper id": "2401.12248",
        "abstract url": "https://arxiv.org/abs/2401.12248",
        "title": "A two-circuit approach to reducing quantum resources for the quantum lattice Boltzmann method",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Computational fluid dynamics (CFD) simulations often entail a large computational burden on classical computers. At present, these simulations can require up to trillions of grid points and millions of time steps. To reduce costs, novel architectures like quantum computers may be intrinsically more efficient at the appropriate computation. Current quantum algorithms for solving CFD problems use a single quantum circuit and, in some cases, lattice-based methods. We introduce the a novel multiple circuits algorithm that makes use of a quantum lattice Boltzmann method (QLBM). The two-circuit algorithm we form solves the Navier-Stokes equations with a marked reduction in CNOT gates compared to existing QLBM circuits. The problem is cast as a stream function--vorticity formulation of the 2D Navier-Stokes equations and verified and tested on a 2D lid-driven cavity flow. We show that using separate circuits for the stream function and vorticity lead to a marked CNOT reduction: 35% in total CNOT count and 16% in combined gate depth. This strategy has the additional benefit of the circuits being able to run concurrently, further halving the seen gate depth. This work is intended as a step towards practical quantum circuits for solving differential equation-based problems of scientific interest.",
        "subjects": [
            "quant-ph",
            "cs.ET",
            "physics.comp-ph",
            "physics.flu-dyn"
        ],
        "comment": "17 pages, 10 figures, 2 tables"
    },
    {
        "paper id": "2402.16864",
        "abstract url": "https://arxiv.org/abs/2402.16864",
        "title": "Joint Resource Allocation and Trajectory Design for Resilient Multi-UAV Communication Networks",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory",
                "Vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In contrast to terrestrial wireless networks, dynamic Unmanned Aerial Vehicle (UAV) networks are susceptible to unexpected link failures arising from UAV breakdowns or the depletion of its batteries. Drastic user rate fluctuations and sum rate drops can occur due to the unexpected UAV link failures. Previous research has focused primarily on re-establishing these links to maintain service continuity, while neglecting overall system performance, including sum rate and user rate fluctuations. This letter proposes a resilient UAV network design utilizing the modern portfolio theory (MPT), which jointly optimizes the bandwidth allocation, UAV-user association, and UAV trajectories to enhance the overall service stability. Specifically, the design incorporates a novel utility function based on MPT to achieve a better balance between the sum rate and user rate fluctuations. To solve the joint optimization problem, we propose an iterative algorithm based on alternating optimization (AO) and successive convex approximation (SCA). Simulation results show that our scheme outperforms the other two baselines in terms of sum rate and user rate fluctuations. Furthermore, the resilience requirement in terms of sum rate, user rate fluctuations and user fairness can be achieved by flexibly tuning weight factor in our proposed algorithm.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11118",
        "abstract url": "https://arxiv.org/abs/2401.11118",
        "title": "Meta Reinforcement Learning for Strategic IoT Deployments Coverage in Disaster-Response UAV Swarms",
        "rating": "-3.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "UAV"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the past decade, Unmanned Aerial Vehicles (UAVs) have grabbed the attention of researchers in academia and industry for their potential use in critical emergency applications, such as providing wireless services to ground users and collecting data from areas affected by disasters, due to their advantages in terms of maneuverability and movement flexibility. The UAVs' limited resources, energy budget, and strict mission completion time have posed challenges in adopting UAVs for these applications. Our system model considers a UAV swarm that navigates an area collecting data from ground IoT devices focusing on providing better service for strategic locations and allowing UAVs to join and leave the swarm (e.g., for recharging) in a dynamic way. In this work, we introduce an optimization model with the aim of minimizing the total energy consumption and provide the optimal path planning of UAVs under the constraints of minimum completion time and transmit power. The formulated optimization is NP-hard making it not applicable for real-time decision making. Therefore, we introduce a light-weight meta-reinforcement learning solution that can also cope with sudden changes in the environment through fast convergence. We conduct extensive simulations and compare our approach to three state-of-the-art learning models. Our simulation results prove that our introduced approach is better than the three state-of-the-art algorithms in providing coverage to strategic locations with fast convergence.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": "accepted paper at GlobeCom Conference, 2023- Kuala Lumpor - Malayisa"
    },
    {
        "paper id": "2401.11217",
        "abstract url": "https://arxiv.org/abs/2401.11217",
        "title": "A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant",
        "rating": "-3.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Constructing first principles models is a challenging task for nonlinear and complex systems such as a wastewater treatment unit. In recent years, data-driven models are widely used to overcome the complexity. However, they often suffer from issues such as missing, low quality or noisy data. Transfer learning is a solution for this issue where knowledge from another task is transferred to target one to increase the prediction performance. In this work, the objective is increasing the prediction performance of an industrial wastewater treatment plant by transferring the knowledge of (i) an open-source simulation model that captures the underlying physics of the process, albeit with dissimilarities to the target plant, (ii) another industrial plant characterized by noisy and limited data but located in the same refinery, and (iii) the model in (ii) and making the objective function of the training problem physics informed where the physics information derived from the open-source model in (ii). The results have shown that test and validation performance are improved up to 27% and 59%, respectively.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.14413",
        "abstract url": "https://arxiv.org/abs/2401.14413",
        "title": "Aprendizado de m\u00e1quina aplicado na eletroqu\u00edmica",
        "rating": "-3.5",
        "keywords": [
            [
                "biosensors",
                "medical"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This systematic review focuses on analyzing the use of machine learning techniques for identifying and quantifying analytes in various electrochemical applications, presenting the available applications in the literature. Machine learning is a tool that can facilitate the analysis and enhance the understanding of processes involving various analytes. In electrochemical biosensors, it increases the precision of medical diagnostics, improving the identification of biomarkers and pathogens with high reliability. It can be effectively used for the classification of complex chemical products; in environmental monitoring, using low-cost sensors; in portable devices and wearable systems; among others. Currently, the analysis of some analytes is still performed manually, requiring the expertise of a specialist in the field and thus hindering the generalization of results. In light of the advancements in artificial intelligence today, this work proposes to carry out a systematic review of the literature on the applications of artificial intelligence techniques. A set of articles has been identified that address electrochemical problems using machine learning techniques, more specifically, supervised learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "in Portuguese language"
    },
    {
        "paper id": "2402.00042",
        "abstract url": "https://arxiv.org/abs/2402.00042",
        "title": "Optimized Task Assignment and Predictive Maintenance for Industrial Machines using Markov Decision Process",
        "rating": "-3.5",
        "keywords": [
            [
                "health"
            ],
            [
                "Industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper considers a distributed decision-making approach for manufacturing task assignment and condition-based machine health maintenance. Our approach considers information sharing between the task assignment and health management decision-making agents. We propose the design of the decision-making agents based on Markov decision processes. The key advantage of using a Markov decision process-based approach is the incorporation of uncertainty involved in the decision-making process. The paper provides detailed mathematical models along with the associated practical execution strategy. In order to demonstrate the effectiveness and practical applicability of our proposed approach, we have included a detailed numerical case study that is based on open source milling machine tool degradation data. Our case study indicates that the proposed approach offers flexibility in terms of the selection of cost parameters and it allows for offline computation and analysis of the decision-making policy. These features create and opportunity for the future work on learning of the cost parameters associated with our proposed model using artificial intelligence.",
        "subjects": [
            "cs.AI",
            "eess.SY"
        ],
        "comment": "19 pages, 11 figures, 3 tables"
    },
    {
        "paper id": "2404.15278",
        "abstract url": "https://arxiv.org/abs/2404.15278",
        "title": "Security-Sensitive Task Offloading in Integrated Satellite-Terrestrial Networks",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "6G"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "With the rapid development of sixth-generation (6G) communication technology, global communication networks are moving towards the goal of comprehensive and seamless coverage. In particular, low earth orbit (LEO) satellites have become a critical component of satellite communication networks. The emergence of LEO satellites has brought about new computational resources known as the \\textit{LEO satellite edge}, enabling ground users (GU) to offload computing tasks to the resource-rich LEO satellite edge. However, existing LEO satellite computational offloading solutions primarily focus on optimizing system performance, neglecting the potential issue of malicious satellite attacks during task offloading. In this paper, we propose the deployment of LEO satellite edge in an integrated satellite-terrestrial networks (ISTN) structure to support \\textit{security-sensitive computing task offloading}. We model the task allocation and offloading order problem as a joint optimization problem to minimize task offloading delay, energy consumption, and the number of attacks while satisfying reliability constraints. To achieve this objective, we model the task offloading process as a Markov decision process (MDP) and propose a security-sensitive task offloading strategy optimization algorithm based on proximal policy optimization (PPO). Experimental results demonstrate that our algorithm significantly outperforms other benchmark methods in terms of performance.",
        "subjects": [
            "eess.SP",
            "cs.CR",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11127",
        "abstract url": "https://arxiv.org/abs/2401.11127",
        "title": "The Bit Complexity of Dynamic Algebraic Formulas and their Determinants",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many iterative algorithms in optimization, computational geometry, computer algebra, and other areas of computer science require repeated computation of some algebraic expression whose input changes slightly from one iteration to the next. Although efficient data structures have been proposed for maintaining the solution of such algebraic expressions under low-rank updates, most of these results are only analyzed under exact arithmetic (real-RAM model and finite fields) which may not accurately reflect the complexity guarantees of real computers. In this paper, we analyze the stability and bit complexity of such data structures for expressions that involve the inversion, multiplication, addition, and subtraction of matrices under the word-RAM model. We show that the bit complexity only increases linearly in the number of matrix operations in the expression. In addition, we consider the bit complexity of maintaining the determinant of a matrix expression. We show that the required bit complexity depends on the logarithm of the condition number of matrices instead of the logarithm of their determinant. We also discuss rank maintenance and its connections to determinant maintenance. Our results have wide applications ranging from computational geometry (e.g., computing the volume of a polytope) to optimization (e.g., solving linear programs using the simplex algorithm).",
        "subjects": [
            "cs.CC"
        ],
        "comment": "37 pages, 1 Figure"
    },
    {
        "paper id": "2401.11132",
        "abstract url": "https://arxiv.org/abs/2401.11132",
        "title": "ConceptThread: Visualizing Threaded Concepts in MOOC Videos",
        "rating": "-10",
        "keywords": [],
        "abstract": "Massive Open Online Courses (MOOCs) platforms are becoming increasingly popular in recent years. Online learners need to watch the whole course video on MOOC platforms to learn the underlying new knowledge, which is often tedious and time-consuming due to the lack of a quick overview of the covered knowledge and their structures. In this paper, we propose ConceptThread, a visual analytics approach to effectively show the concepts and the relations among them to facilitate effective online learning. Specifically, given that the majority of MOOC videos contain slides, we first leverage video processing and speech analysis techniques, including shot recognition, speech recognition and topic modeling, to extract core knowledge concepts and construct the hierarchical and temporal relations among them. Then, by using a metaphor of thread, we present a novel visualization to intuitively display the concepts based on video sequential flow, and enable learners to perform interactive visual exploration of concepts. We conducted a quantitative study, two case studies, and a user study to extensively evaluate ConceptThread. The results demonstrate the effectiveness and usability of ConceptThread in providing online learners with a quick understanding of the knowledge content of MOOC videos.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "17 pages, 10 figures, 2 tables"
    },
    {
        "paper id": "2401.11135",
        "abstract url": "https://arxiv.org/abs/2401.11135",
        "title": "COVID-19 as Reflected in University President Bulk Email",
        "rating": "-10",
        "keywords": [],
        "abstract": "E-mail ``Messages From the President'' to university students, staff, and faculty have long been used to keep campus communities aware of the latest policies, events, and news. But during the COVID-19 pandemic, as universities quickly closed facilities, sent students home, and canceled travel, these messages took on even greater importance. We report on a content analysis of bulk emails from different universities' presidents to their students and employees before and in three stages of the pandemic. We find that these messages change as universities move towards and through closure. During the pandemic, 1) presidential bulk emails tend to be more informative, positive, clearer than before; 2) they tend to use more personal and collective language; 3) university presidents tend to mention more local political leaders and fewer other university leaders. Our results can inform research on digital crisis communication and may be useful for researchers interested in automatically identifying crisis situations from communication streams.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11141",
        "abstract url": "https://arxiv.org/abs/2401.11141",
        "title": "Wideband Beamforming for RIS Assisted Near-Field Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "A near-field wideband beamforming scheme is investigated for reconfigurable intelligent surface (RIS) assisted multiple-input multiple-output (MIMO) systems, in which a deep learning-based end-to-end (E2E) optimization framework is proposed to maximize the system spectral efficiency. To deal with the near-field double beam split effect, the base station is equipped with frequency-dependent hybrid precoding architecture by introducing sub-connected true time delay (TTD) units, while two specific RIS architectures, namely true time delay-based RIS (TTD-RIS) and virtual subarray-based RIS (SA-RIS), are exploited to realize the frequency-dependent passive beamforming at the RIS. Furthermore, the efficient E2E beamforming models without explicit channel state information are proposed, which jointly exploits the uplink channel training module and the downlink wideband beamforming module. In the proposed network architecture of the E2E models, the classical communication signal processing methods, i.e., polarized filtering and sparsity transform, are leveraged to develop a signal-guided beamforming network. Numerical results show that the proposed E2E models have superior beamforming performance and robustness to conventional beamforming benchmarks. Furthermore, the tradeoff between the beamforming gain and the hardware complexity is investigated for different frequency-dependent RIS architectures, in which the TTD-RIS can achieve better spectral efficiency than the SA-RIS while requiring additional energy consumption and hardware cost.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11155",
        "abstract url": "https://arxiv.org/abs/2401.11155",
        "title": "Deep Learning-Based Adaptive Joint Source-Channel Coding using Hypernetworks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Deep learning-based joint source-channel coding (DJSCC) is expected to be a key technique for {the} next-generation wireless networks. However, the existing DJSCC schemes still face the challenge of channel adaptability as they are typically trained under specific channel conditions. In this paper, we propose a generic framework for channel-adaptive DJSCC by utilizing hypernetworks. To tailor the hypernetwork-based framework for communication systems, we propose a memory-efficient hypernetwork parameterization and then develop a channel-adaptive DJSCC network, named Hyper-AJSCC. Compared with existing adaptive DJSCC based on the attention mechanism, Hyper-AJSCC introduces much fewer parameters and can be seamlessly combined with various existing DJSCC networks without any substantial modifications to their neural network architecture. Extensive experiments demonstrate the better adaptability to channel conditions and higher memory efficiency of Hyper-AJSCC compared with state-of-the-art baselines.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11160",
        "abstract url": "https://arxiv.org/abs/2401.11160",
        "title": "Quasi-Perfect and Distance-Optimal Codes Sum-Rank Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Constructions of distance-optimal codes and quasi-perfect codes are challenging problems and have attracted many attentions. In this paper, we give the following three results. 1) If $\u03bb|q^{sm}-1$ and $\u03bb<\\sqrt{\\frac{(q^s-1)}{2(q-1)^2(1+\u03b5)}}$, an infinite family of distance-optimal $q$-ary cyclic sum-rank codes with the block length $t=\\frac{q^{sm}-1}\u03bb$, the matrix size $s \\times s$, the cardinality $q^{s^2t-s(2m+3)}$ and the minimum sum-rank distance four is constructed. 2) Block length $q^4-1$ and the matrix size $2 \\times 2$ distance-optimal sum-rank codes with the minimum sum-rank distance four and the Singleton defect four are constructed. These sum-rank codes are close to the sphere packing bound , the Singleton-like bound and have much larger block length $q^4-1>>q-1$. 3) For given positive integers $m$ satisfying $2 \\leq m$, an infinite family of quasi-perfect sum-rank codes with the matrix size $2 \\times m$, and the minimum sum-rank distance three is also constructed. Quasi-perfect binary sum-rank codes with the minimum sum-rank distance four are also given. Almost MSRD $q$-ary codes with the block lengths up to $q^2$ are given. We show that more distance-optimal binary sum-rank codes can be obtained from the Plotkin sum.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "19 pages, only quasi-perfect sum-rank codes were constructed. Almost MSRD codes with the block lengths up to $q^2$ were included"
    },
    {
        "paper id": "2401.11161",
        "abstract url": "https://arxiv.org/abs/2401.11161",
        "title": "BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching",
        "rating": "-10",
        "keywords": [],
        "abstract": "While third-party libraries are extensively reused to enhance productivity during software development, they can also introduce potential security risks such as vulnerability propagation. Software composition analysis, proposed to identify reused TPLs for reducing such risks, has become an essential procedure within modern DevSecOps. As one of the mainstream SCA techniques, binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching, which is a major challenge in reverse engineering since binary and source code exhibit substantial disparities after compilation. The existing binary-to-source SCA techniques leverage basic syntactic features that suffer from redundancy and lack robustness in the large-scale TPL dataset, leading to inevitable false positives and compromised recall. To mitigate these limitations, we introduce BinaryAI, a novel binary-to-source SCA technique with two-phase binary source code matching to capture both syntactic and semantic code features. First, BinaryAI trains a transformer-based model to produce function-level embeddings and obtain similar source functions for each binary function accordingly. Then by applying the link-time locality to facilitate function matching, BinaryAI detects the reused TPLs based on the ratio of matched source functions. Our experimental results demonstrate the superior performance of BinaryAI in terms of binary source code matching and the downstream SCA task. Specifically, our embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving 22.54% recall@1 and 0.34 MRR compared with 10.75% and 0.17 respectively. Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in TPL detection, increasing the precision from 73.36% to 85.84% and recall from 59.81% to 64.98% compared with the well-recognized commercial SCA product Black Duck.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "In Proceedings of the 46th International Conference on Software Engineering (ICSE'24)"
    },
    {
        "paper id": "2401.11162",
        "abstract url": "https://arxiv.org/abs/2401.11162",
        "title": "Extending Polaris to Support Transactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Polaris, we introduced a cloud-native distributed query processor to perform analytics at scale. In this paper, we extend the underlying Polaris distributed computation framework, which can be thought of as a read-only transaction engine, to execute general transactions (including updates, deletes, inserts and bulk loads, in addition to queries) for Tier 1 warehousing workloads in a highly performant and predictable manner. We take advantage of the immutability of data files in log-structured data stores and build on SQL Server transaction management to deliver full transactional support with Snapshot Isolation semantics, including multi-table and multi-statement transactions. With the enhancements described in this paper, Polaris supports both query processing and transactions for T-SQL in Microsoft Fabric.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "12 pages, 12 Figures"
    },
    {
        "paper id": "2401.11166",
        "abstract url": "https://arxiv.org/abs/2401.11166",
        "title": "ChatGPT in the classroom. Exploring its potential and limitations in a Functional Programming course",
        "rating": "-10",
        "keywords": [],
        "abstract": "In November 2022, OpenAI has introduced ChatGPT, a chatbot based on supervised and reinforcement learning. Not only can it answer questions emulating human-like responses, but it can also generate code from scratch or complete coding templates provided by the user. ChatGPT can generate unique responses which render any traditional anti-plagiarism tool useless. Its release has ignited a heated debate about its usage in academia, especially by students. We have found, to our surprise, that our students at POLITEHNICA University of Bucharest (UPB) have been using generative AI tools (ChatGPT and its predecessors) for solving homework, for at least 6 months. We therefore set out to explore the capabilities of ChatGPT and assess its value for educational purposes. We solved all our coding assignments for the semester from our UPB Functional Programming course. We discovered that, although ChatGPT provides correct answers in 68% of the cases, only around half of those are legible solutions which can benefit students in some form. On the other hand, ChatGPT has a very good ability to perform code review on student programming homework. Based on these findings, we discuss the pros and cons of ChatGPT in education.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11167",
        "abstract url": "https://arxiv.org/abs/2401.11167",
        "title": "Coevolving Artistic Images Using OMNIREP",
        "rating": "-10",
        "keywords": [],
        "abstract": "We have recently developed OMNIREP, a coevolutionary algorithm to discover both a representation and an interpreter that solve a particular problem of interest. Herein, we demonstrate that the OMNIREP framework can be successfully applied within the field of evolutionary art. Specifically, we coevolve representations that encode image position, alongside interpreters that transform these positions into one of three pre-defined shapes (chunks, polygons, or circles) of varying size, shape, and color. We showcase a sampling of the unique image variations produced by this approach.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11181",
        "abstract url": "https://arxiv.org/abs/2401.11181",
        "title": "Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads",
        "rating": "-10",
        "keywords": [],
        "abstract": "Transformer-based large language model (LLM) inference serving is now the backbone of many cloud services. LLM inference consists of a prefill phase and a decode phase. However, existing LLM deployment practices often overlook the distinct characteristics of these phases, leading to significant interference. To mitigate interference, our insight is to carefully schedule and group inference requests based on their characteristics. We realize this idea in TetriInfer through three pillars. First, it partitions prompts into fixed-size chunks so that the accelerator always runs close to its computationsaturated limit. Second, it disaggregates prefill and decode instances so each can run independently. Finally, it uses a smart two-level scheduling algorithm augmented with predicted resource usage to avoid decode scheduling hotspots. Results show that TetriInfer improves time-to-first-token (TTFT), job completion time (JCT), and inference efficiency in turns of performance per dollar by a large margin, e.g., it uses 38% less resources all the while lowering average TTFT and average JCT by 97% and 47%, respectively.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11189",
        "abstract url": "https://arxiv.org/abs/2401.11189",
        "title": "Globally exponentially convergent observer for systems evolving on matrix Lie groups",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a globally exponentially convergent observer for the dynamical system evolving on matrix Lie groups with bounded velocity with unknown bound. We design the observer in the ambient Euclidean space and show exponential convergence of the observer to the state of the system. We show the convergence with an example of a rigid body rotation and translation system on the special Euclidean group. We compare the proposed observer with an observer present in the literature.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11194",
        "abstract url": "https://arxiv.org/abs/2401.11194",
        "title": "Mapping the Field of Algorithm Auditing: A Systematic Literature Review Identifying Research Trends, Linguistic and Geographical Disparities",
        "rating": "-10",
        "keywords": [],
        "abstract": "The increasing reliance on complex algorithmic systems by online platforms has sparked a growing need for algorithm auditing, a research methodology evaluating these systems' functionality and societal impact. In this paper, we systematically review algorithm auditing studies and identify trends in their methodological approaches, the geographic distribution of authors, and the selection of platforms, languages, geographies, and group-based attributes in the focus of auditing research. We present evidence of a significant skew of research focus toward Western contexts, particularly the US, and a disproportionate reliance on English language data. Additionally, our analysis indicates a tendency in algorithm auditing studies to focus on a narrow set of group-based attributes, often operationalized in simplified ways, which might obscure more nuanced aspects of algorithmic bias and discrimination. By conducting this review, we aim to provide a clearer understanding of the current state of the algorithm auditing field and identify gaps that need to be addressed for a more inclusive and representative research landscape.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11195",
        "abstract url": "https://arxiv.org/abs/2401.11195",
        "title": "Triple-Refined Hybrid-Field Beam Training for mmWave Extremely Large-Scale MIMO",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates beam training for extremely large-scale multiple-input multiple-output systems. By considering both the near field and far field, a triple-refined hybrid-field beam training scheme is proposed, where high-accuracy estimates of channel parameters are obtained through three steps of progressive beam refinement. First, the hybrid-field beam gain (HFBG)-based first refinement method is developed. Based on the analysis of the HFBG, the first-refinement codebook is designed and the beam training is performed accordingly to narrow down the potential region of the channel path. Then, the maximum likelihood (ML)-based and principle of stationary phase (PSP)-based second refinement methods are developed. By exploiting the measurements of the beam training, the ML is used to estimate the channel parameters. To avoid the high computational complexity of ML, closed-form estimates of the channel parameters are derived according to the PSP. Moreover, the Gaussian approximation (GA)-based third refinement method is developed. The hybrid-field neighboring search is first performed to identify the potential region of the main lobe of the channel steering vector. Afterwards, by applying the GA, a least-squares estimator is developed to obtain the high-accuracy channel parameter estimation. Simulation results verify the effectiveness of the proposed scheme.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11197",
        "abstract url": "https://arxiv.org/abs/2401.11197",
        "title": "Introducing TOAST: Safe Asynchronous Mixed-Choice For Timed Interactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mixed-choice has long been barred from models of asynchronous communication since it compromises the decidability of key properties of communicating finite-state machines. Session types inherit this restriction, which precludes them from fully modelling timeouts -- a core property of web and cloud services. To address this deficiency, we present (binary) Timeout Asynchronous Session Types ({TOAST}) as an extension to (binary) asynchronous timed session types, that permits mixed-choice. {TOAST} deploys timing constraints to regulate the use of mixed-choice so as to preserve communication safety. We provide a new behavioural semantics for {TOAST} which guarantees progress in the presence of mixed-choice. Building upon {TOAST}, we provide a calculus featuring process timers which is capable of modelling timeouts using a $\\mathtt{receive\\text{-}after}$ pattern, much like Erlang, and capture the correspondence with TOAST specifications via a type system for which we prove subject reduction.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11198",
        "abstract url": "https://arxiv.org/abs/2401.11198",
        "title": "A Deep Learning Approach for Selective Relevance Feedback",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pseudo-relevance feedback (PRF) can enhance average retrieval effectiveness over a sufficiently large number of queries. However, PRF often introduces a drift into the original information need, thus hurting the retrieval effectiveness of several queries. While a selective application of PRF can potentially alleviate this issue, previous approaches have largely relied on unsupervised or feature-based learning to determine whether a query should be expanded. In contrast, we revisit the problem of selective PRF from a deep learning perspective, presenting a model that is entirely data-driven and trained in an end-to-end manner. The proposed model leverages a transformer-based bi-encoder architecture. Additionally, to further improve retrieval effectiveness with this selective PRF approach, we make use of the model's confidence estimates to combine the information from the original and expanded queries. In our experiments, we apply this selective feedback on a number of different combinations of ranking and feedback models, and show that our proposed approach consistently improves retrieval effectiveness for both sparse and dense ranking models, with the feedback models being either sparse, dense or generative.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11200",
        "abstract url": "https://arxiv.org/abs/2401.11200",
        "title": "Transversally exponentially stable Euclidean space extension technique for discrete time systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a modification technique for discrete time systems for exponentially fast convergence to compact sets. The extension technique allows us to use tools defined on Euclidean spaces to systems evolving on manifolds by modifying the dynamics of the system such that the manifold is an attractor set. We show the stability properties of this technique using the simulation of the rigid body rotation system on the unit sphere $S^3$. We also show the improvement afforded due to this technique on a Luenberger like observer designed for the rigid body rotation system on $S^3$.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11205",
        "abstract url": "https://arxiv.org/abs/2401.11205",
        "title": "Joint Beamforming Optimization and Mode Selection for RDARS-aided MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Considering the appealing distribution gains of distributed antenna systems (DAS) and passive gains of reconfigurable intelligent surface (RIS), a flexible reconfigurable architecture called reconfigurable distributed antenna and reflecting surface (RDARS) is proposed. RDARS encompasses DAS and RIS as two special cases and maintains the advantages of distributed antennas while reducing the hardware cost by replacing some active antennas with low-cost passive reflecting surfaces. In this paper, we present a RDARS-aided uplink multi-user communication system and investigate the system transmission reliability with the newly proposed architecture. Specifically, in addition to the distribution gain and the reflection gain provided by the connection and reflection modes, respectively, we also consider the dynamic mode switching of each element which introduces an additional degree of freedom (DoF) and thus results in a selection gain. As such, we aim to minimize the total sum mean-square-error (MSE) of all data streams by jointly optimizing the receive beamforming matrix, the reflection phase shifts and the channel-aware placement of elements in the connection mode. To tackle this nonconvex problem with intractable binary and cardinality constraints, we propose an inexact block coordinate descent (BCD) based penalty dual decomposition (PDD) algorithm with the guaranteed convergence. Since the PDD algorithm usually suffers from high computational complexity, a low-complexity greedy-search-based alternating optimization (AO) algorithm is developed to yield a semi-closed-form solution with acceptable performance. Numerical results demonstrate the superiority of the proposed architecture compared to the conventional fully passive RIS or DAS. Furthermore, some insights about the practical implementation of RDARS are provided.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "13 pages, 9 figures. This paper has been submitted to IEEE journal for possible publication"
    },
    {
        "paper id": "2401.11219",
        "abstract url": "https://arxiv.org/abs/2401.11219",
        "title": "On the Information Leakage Performance of Secure Finite Blocklength Transmissions over Rayleigh Fading Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a secrecy performance study of a wiretap communication system with finite blocklength (FBL) transmissions over Rayleigh fading channels, based on the definition of an average information leakage (AIL) metric. We evaluate the exact and closed-form approximate AIL performance, assuming that only statistical channel state information (CSI) of the eavesdropping link is available. Then, we reveal an inherent statistical relationship between the AIL metric in the FBL regime and the commonly-used secrecy outage probability in conventional infinite blocklength communications. Aiming to improve the secure communication performance of the considered system, we formulate a blocklength optimization problem and solve it via a low-complexity approach. Next, we present numerical results to verify our analytical findings and provide various important insights into the impacts of system parameters on the AIL. Specifically, our results indicate that i) compromising a small amount of AIL can lead to significant reliability improvements, and ii) the AIL experiences a secrecy floor in the high signal-to-noise ratio regime.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 5 figures. Accepted for presentation at the 2024 IEEE International Conference on Communications (CT Symposium), 9 - 13 June 2024, Denver, CO United States. Note: An extended version of this work is available as arXiv:2308.13184"
    },
    {
        "paper id": "2401.11240",
        "abstract url": "https://arxiv.org/abs/2401.11240",
        "title": "CaraServe: CPU-Assisted and Rank-Aware LoRA Serving for Generative LLM Inference",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pre-trained large language models (LLMs) often need specialization for domain-specific tasks. Low-Rank Adaptation (LoRA) is a popular approach that adapts a base model to multiple tasks by adding lightweight trainable adapters. In this paper, we present CaraServe, a system that efficiently serves many LoRA adapters derived from a common base model. CaraServe maintains the base model on GPUs and dynamically loads activated LoRA adapters from main memory. As GPU loading results in a cold-start that substantially delays token generation, CaraServe employs a CPU-assisted approach. It early starts the activated adapters on CPUs for prefilling as they are being loaded onto GPUs; after loading completes, it then switches to the GPUs for generative LoRA inference. CaraServe develops a highly optimized synchronization mechanism to efficiently coordinate LoRA computation on the CPU and GPU. Moreover, CaraServe employs a rank-aware scheduling algorithm to optimally schedule heterogeneous LoRA requests for maximum service-level objective (SLO) attainment. We have implemented CaraServe and evaluated it against state-of-the-art LoRA serving systems. Our results demonstrate that CaraServe can speed up the average request serving latency by up to 1.4$\\times$ and achieve an SLO attainment of up to 99%.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11266",
        "abstract url": "https://arxiv.org/abs/2401.11266",
        "title": "Lower bounds for set-blocked clauses proofs",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study propositional proof systems with inference rules that formalize restricted versions of the ability to make assumptions that hold without loss of generality, commonly used informally to shorten proofs. Each system we study is built on resolution. They are called BC${}^-$, RAT${}^-$, SBC${}^-$, and GER${}^-$, denoting respectively blocked clauses, resolution asymmetric tautologies, set-blocked clauses, and generalized extended resolution - all \"without new variables.\" They may be viewed as weak versions of extended resolution (ER) since they are defined by first generalizing the extension rule and then taking away the ability to introduce new variables. Except for SBC${}^-$, they are known to be strictly between resolution and extended resolution. Several separations between these systems were proved earlier by exploiting the fact that they effectively simulate ER. We answer the questions left open: We prove exponential lower bounds for SBC${}^-$ proofs of a binary encoding of the pigeonhole principle, which separates ER from SBC${}^-$. Using this new separation, we prove that both RAT${}^-$ and GER${}^-$ are exponentially separated from SBC${}^-$. This completes the picture of their relative strengths.",
        "subjects": [
            "cs.LO",
            "cs.CC"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2211.12456"
    },
    {
        "paper id": "2401.11274",
        "abstract url": "https://arxiv.org/abs/2401.11274",
        "title": "Unambiguous parity-query complexity",
        "rating": "-10",
        "keywords": [],
        "abstract": "We give a lower bound of $\u03a9(\\sqrt n)$ on the unambiguous randomised parity-query complexity of the approximate majority problem -- that is, on the lowest randomised parity-query complexity of any function over $\\{0,1\\}^n$ whose value is \"0\" if the Hamming weight of the input is at most n/3, is \"1\" if the weight is at least 2n/3, and may be arbitrary otherwise.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11282",
        "abstract url": "https://arxiv.org/abs/2401.11282",
        "title": "What Juris Hartmanis taught me about Reductions",
        "rating": "-10",
        "keywords": [],
        "abstract": "I was a student of Juris Hartmanis at Cornell in the late 1970's. He believed that there was great potential in studying restricted reductions. I describe here some of his influences on me and, in particular, how his insights concerning reductions helped me to prove that nondeterministic space is closed under complementation.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11326",
        "abstract url": "https://arxiv.org/abs/2401.11326",
        "title": "Navigating Cybersecurity Training: A Comprehensive Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the dynamic realm of cybersecurity, awareness training is crucial for strengthening defenses against cyber threats. This survey examines a spectrum of cybersecurity awareness training methods, analyzing traditional, technology-based, and innovative strategies. It evaluates the principles, efficacy, and constraints of each method, presenting a comparative analysis that highlights their pros and cons. The study also investigates emerging trends like artificial intelligence and extended reality, discussing their prospective influence on the future of cybersecurity training. Additionally, it addresses implementation challenges and proposes solutions, drawing on insights from real-world case studies. The goal is to bolster the understanding of cybersecurity awareness training's current landscape, offering valuable perspectives for both practitioners and scholars.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11328",
        "abstract url": "https://arxiv.org/abs/2401.11328",
        "title": "A Hierarchical Decision-Based Maintenance for a Complex Modular System Driven by the { MoMA} Algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a maintenance policy for a modular system formed by K independent modules (n-subsystems) subjected to environmental conditions (shocks). For the modeling of this complex system, the use of the Matrix-Analytical Method (MAM) is proposed under a layered approach according to its hierarchical structure. Thus, the operational state of the system (top layer) depends on the states of the modules (middle layer), which in turn depend on the states of their components (bottom layer). This allows a detailed description of the system operation to plan maintenance actions appropriately and optimally. We propose a hierarchical decision-based maintenance strategy with periodic inspections as follows: at the time of the inspection, the condition of the system is first evaluated. If intervention is necessary, the modules are then checked to make individual decisions based on their states, and so on. Replacement or repair will be carried out as appropriate. An optimization problem is formulated as a function of the length of the inspection period and the intervention cost incurred over the useful life of the system. Our method shows the advantages, providing compact and implementable expressions. The model is illustrated on a submarine Electrical Control Unit (ECU).",
        "subjects": [
            "eess.SY",
            "stat.ME"
        ],
        "comment": "43 pages, 6 figures"
    },
    {
        "paper id": "2401.11347",
        "abstract url": "https://arxiv.org/abs/2401.11347",
        "title": "Are Your Epochs Too Epic? Batch Free Can Be Harmful",
        "rating": "-10",
        "keywords": [],
        "abstract": "Epoch based memory reclamation (EBR) is one of the most popular techniques for reclaiming memory in lock-free and optimistic locking data structures, due to its ease of use and good performance in practice. However, EBR is known to be sensitive to thread delays, which can result in performance degradation. Moreover, the exact mechanism for this performance degradation is not well understood. This paper illustrates this performance degradation in a popular data structure benchmark, and does a deep dive to uncover its root cause-a subtle interaction between EBR and state of the art memory allocators. In essence, modern allocators attempt to reduce the overhead of freeing by maintaining bounded thread caches of objects for local reuse, actually freeing them (a very high latency operation) only when thread caches become too large. EBR immediately bypasses these mechanisms whenever a particularly large batch of objects is freed, substantially increasing overheads and latencies. Beyond EBR, many memory reclamation algorithms, and data structures, that reclaim objects in large batches suffer similar deleterious interactions with popular allocators. We propose a simple algorithmic fix for such algorithms to amortize the freeing of large object batches over time, and apply this technique to ten existing memory reclamation algorithms, observing performance improvements for nine out of ten, and over 50% improvement for six out of ten in experiments on a high performance lock-free ABtree. We also present an extremely simple token passing variant of EBR and show that, with our fix, it performs 1.5-2.6x faster than the fastest known memory reclamation algorithm, and 1.2-1.5x faster than not reclaiming at all, on a 192 thread four socket Intel system.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Full version of the paper accepted in PPoPP 2024"
    },
    {
        "paper id": "2401.11364",
        "abstract url": "https://arxiv.org/abs/2401.11364",
        "title": "Folding Custom Gates with Verifier Input",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the context of interactive proofs, a \"folding scheme\" (popularized by Nova) is a way to combine multiple instances of a constraint system into a single instance, so the validity of the multiple instances can statistically be reduced to the validity of a single one. We show how Nova folding can be generalized to ``custom'' gates and extra rounds of verifier randomness. As an application of this extension, we present Origami, the first (to our knowledge) known example of a folding scheme for lookups.",
        "subjects": [
            "cs.CR",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11366",
        "abstract url": "https://arxiv.org/abs/2401.11366",
        "title": "A Multivocal Literature Review on the Benefits and Limitations of Automated Machine Learning Tools",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context. Advancements in Machine Learning (ML) are revolutionizing every application domain, driving unprecedented transformations and fostering innovation. However, despite these advances, several organizations are experiencing friction in the adoption of ML-based technologies, mainly due to the shortage of ML professionals. In this context, Automated Machine Learning (AutoML) techniques have been presented as a promising solution to democratize ML adoption. Objective. We aim to provide an overview of the evidence on the benefits and limitations of using AutoML tools. Method. We conducted a multivocal literature review, which allowed us to identify 54 sources from the academic literature and 108 sources from the grey literature reporting on AutoML benefits and limitations. We extracted reported benefits and limitations from the papers and applied thematic analysis. Results. We identified 18 benefits and 25 limitations. Concerning the benefits, we highlight that AutoML tools can help streamline the core steps of ML workflows, namely data preparation, feature engineering, model construction, and hyperparameter tuning, with concrete benefits on model performance, efficiency, and scalability. In addition, AutoML empowers both novice and experienced data scientists, promoting ML accessibility. On the other hand, we highlight several limitations that may represent obstacles to the widespread adoption of AutoML. For instance, AutoML tools may introduce barriers to transparency and interoperability, exhibit limited flexibility for complex scenarios, and offer inconsistent coverage of the ML workflow. Conclusions. The effectiveness of AutoML in facilitating the adoption of machine learning by users may vary depending on the tool and the context in which it is used. As of today, AutoML tools are used to increase human expertise rather than replace it, and, as such, they require skilled users.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11369",
        "abstract url": "https://arxiv.org/abs/2401.11369",
        "title": "A Fast Effective Greedy Approach for MU-MIMO Beam Selection in mm-Wave and THz Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper addresses the beam-selection challenges in Multi-User Multiple Input Multiple Output (MU-MIMO) beamforming for mm-wave and THz channels, focusing on the pivotal aspect of spectral efficiency (SE) and computational efficiency. We introduce a novel approach, the Greedy Interference-Optimized Singular Vector Beam-selection (G-IOSVB) algorithm, which offers a strategic balance between high SE and low computational complexity. Our study embarks on a comparative analysis of G-IOSVB against the traditional IOSVB and the exhaustive Singular-Vector Beamspace Search (SVBS) algorithms. The findings reveal that while SVBS achieves the highest SE, it incurs significant computational costs, approximately 162 seconds per channel realization. In contrast, G-IOSVB aligns closely with IOSVB in SE performance yet is markedly more computationally efficient. Heatmaps vividly demonstrate this efficiency, highlighting G-IOSVB's reduced computation time without sacrificing SE. We also delve into the mathematical intricacies of G-IOSVB, demonstrating its theoretical and practical superiority through rigorous expressions and detailed algorithmic analysis. The numerical results illustrate that G-IOSVB stands out as an efficient, practical solution for MU-MIMO systems, making it a promising candidate for high-speed, high-efficiency wireless communication networks.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Accepted for Lecture presentation at the 58th Annual Conference on Information Sciences and Systems, to be held at Princeton University from March 13-15, 2024"
    },
    {
        "paper id": "2401.11377",
        "abstract url": "https://arxiv.org/abs/2401.11377",
        "title": "Joint User Scheduling and Computing Resource Allocation Optimization in Asynchronous Mobile Edge Computing Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, the problem of joint user scheduling and computing resource allocation in asynchronous mobile edge computing (MEC) networks is studied. In such networks, edge devices will offload their computational tasks to an MEC server, using the energy they harvest from this server. To get their tasks processed on time using the harvested energy, edge devices will strategically schedule their task offloading, and compete for the computational resource at the MEC server. Then, the MEC server will execute these tasks asynchronously based on the arrival of the tasks. This joint user scheduling, time and computation resource allocation problem is posed as an optimization framework whose goal is to find the optimal scheduling and allocation strategy that minimizes the energy consumption of these mobile computing tasks. To solve this mixed-integer non-linear programming problem, the general benders decomposition method is adopted which decomposes the original problem into a primal problem and a master problem. Specifically, the primal problem is related to computation resource and time slot allocation, of which the optimal closed-form solution is obtained. The master problem regarding discrete user scheduling variables is constructed by adding optimality cuts or feasibility cuts according to whether the primal problem is feasible, which is a standard mixed-integer linear programming problem and can be efficiently solved. By iteratively solving the primal problem and master problem, the optimal scheduling and resource allocation scheme is obtained. Simulation results demonstrate that the proposed asynchronous computing framework reduces 87.17% energy consumption compared with conventional synchronous computing counterpart.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11383",
        "abstract url": "https://arxiv.org/abs/2401.11383",
        "title": "Entropic Conditional Central Limit Theorem and Hadamard Compression",
        "rating": "-10",
        "keywords": [],
        "abstract": "We make use of an entropic property to establish a convergence theorem (Main Theorem), which reveals that the conditional entropy measures the asymptotic Gaussianity. As an application, we establish the {\\it entropic conditional central limit theorem} (CCLT), which is stronger than the classical CCLT. As another application, we show that continuous input under iterated Hadamard transform, almost every distribution of the output conditional on the values of the previous signals will tend to Gaussian, and the conditional distribution is in fact insensitive to the condition. The results enable us to make a theoretic study concerning Hadamard compression, which provides a solid theoretical analysis supporting the simulation results in previous literature. We show also that the conditional Fisher information can be used to measure the asymptotic Gaussianity.",
        "subjects": [
            "math.PR",
            "cs.IT"
        ],
        "comment": "40 pages"
    },
    {
        "paper id": "2401.11390",
        "abstract url": "https://arxiv.org/abs/2401.11390",
        "title": "A Transformation of Repairing Reed-Solomon Codes from Rack-Aware Storage Model to Homogeneous Storage Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we address the node repair problem of Reed-Solomon (RS) coded distributed storage systems. Specifically, to overcome the challenges of multiple-node failures of RS codes under the rack-aware storage model, we employ good polynomials to guide the placement of the conventional RS codes into racks and then propose a novel repair framework for the resultant rack-aware RS codes, which can transform its repair to that under the homogeneous storage model. As applications of our repair framework, firstly we present the repair scheme of multiple-node failures for some existing constructions, which can only repair a single-node failure before. Secondly, we deduce several new constructions of rack-aware RS codes supporting the repair of multiple-node failures.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "9 pages, 2 figures, 2 tables"
    },
    {
        "paper id": "2401.11391",
        "abstract url": "https://arxiv.org/abs/2401.11391",
        "title": "Interactive AI with Retrieval-Augmented Generation for Next Generation Networking",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the advance of artificial intelligence (AI), the emergence of Google Gemini and OpenAI Q* marks the direction towards artificial general intelligence (AGI). To implement AGI, the concept of interactive AI (IAI) has been introduced, which can interactively understand and respond not only to human user input but also to dynamic system and network conditions. In this article, we explore an integration and enhancement of IAI in networking. We first comprehensively review recent developments and future perspectives of AI and then introduce the technology and components of IAI. We then explore the integration of IAI into the next-generation networks, focusing on how implicit and explicit interactions can enhance network functionality, improve user experience, and promote efficient network management. Subsequently, we propose an IAI-enabled network management and optimization framework, which consists of environment, perception, action, and brain units. We also design the pluggable large language model (LLM) module and retrieval augmented generation (RAG) module to build the knowledge base and contextual memory for decision-making in the brain unit. We demonstrate the effectiveness of the framework through case studies. Finally, we discuss potential research directions for IAI-based networks.",
        "subjects": [
            "cs.NI",
            "cs.IT"
        ],
        "comment": "10 pages, 4 figures"
    },
    {
        "paper id": "2401.11398",
        "abstract url": "https://arxiv.org/abs/2401.11398",
        "title": "Application of a Novel Model Reduction Technique to the Assessment of Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper develops a new approach to the assessment of the boundedness/stability of some vector nonlinear systems with delays and variable coefficients. The approach rests on the development of scalar counterparts to the original vector systems. We show that the solutions to these scalar auxiliary nonlinear equations with delay and variable coefficients bound from the above the norms of solutions to the original equations with the matched history functions. This prompts the assessment of the boundedness/stability traits of the vector systems through the abridged evaluation of the dynamics of their scalar counterparts. The latter task is achieved in effortless simulations or through the application of simplified analytical inferences. Consequently, we convey some novel boundedness/ stability criteria and estimate the radiuses of the balls imbedded in the boundedness/stability regions. Lastly, we authenticate our inferences in representative simulations that also measure their accuracy.",
        "subjects": [
            "eess.SY",
            "math.DG"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2402.06636",
        "abstract url": "https://arxiv.org/abs/2402.06636",
        "title": "A Multichain based marketplace Architecture",
        "rating": "-10",
        "keywords": [],
        "abstract": "]A multichain non-fungible tokens (NFTs) marketplace is a decentralized platform where users can buy, sell, and trade NFTs across multiple blockchain networks by using cross communication bridge. In past most of NFT marketplace was based on singlechain in which NFTs have been bought, sold, and traded on a same blockchain network without the need for any external platform. The singlechain based marketplace have faced number of issues such as performance, scalability, flexibility and limited transaction throughput consequently long confirmation times and high transaction fees during high network usage. Firstly, this paper provides the comprehensive overview about NFT Multichain architecture and explore the challenges and opportunities of designing and implementation phase of multichain NFT marketplace to overcome the issue of single chain-based architecture. NFT multichain marketplace architecture includes different blockchain networks that communicate with each other. Secondly, this paper discusses the concept of mainchain interacting with sidechains which refers to multi blockchain architecture where multiple blockchain networks are connected to each other in a hierarchical structure and identifies key challenges related to interoperability, security, scalability, and user adoption. Finally, we proposed a novel architecture for a multichain NFT marketplace, which leverages the benefits of multiple blockchain networks and marketplaces to overcome these key challenges. Moreover, proposed architecture is evaluated through a case study, demonstrating its ability to support efficient and secure transactions across multiple blockchain networks and highlighting the future trends NFTs and marketplaces and comprehensive discussion about the technology.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "15"
    },
    {
        "paper id": "2402.10917",
        "abstract url": "https://arxiv.org/abs/2402.10917",
        "title": "SRAM Alpha-SER Estimation From Word-Line Voltage Margin Measurements: Design Architecture and Experimental Results",
        "rating": "-10",
        "keywords": [],
        "abstract": "Experimental results from a 65 nm CMOS commercial technology SRAM test chip reveal a linear correlation between a new electrical parameter -- the word-line voltage margin (VWLVM) -- and the measured circuit alpha-SER. Additional experiments show that no other memory cell electrical robustness-related parameters exhibit such correlation. The technique proposed is based on correlating the VWLVM to the SER measured on a small number of circuit samples to determine the correlation parameters. Then, the remaining non-irradiated circuits SER is determined from electrical measurements (VWLVM) without the need of additional radiation experiments. This method represents a significant improvement in time and cost, while simplifying the SER-determination methods since most of the circuits do not require irradiation. The technique involves a minor memory design modification that does not degrade circuit performance, while circuit area increase is negligible.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "6 pages, 10 figures"
    },
    {
        "paper id": "2402.16862",
        "abstract url": "https://arxiv.org/abs/2402.16862",
        "title": "Revisiting Common Randomness, No-signaling and Information Structure in Decentralized Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work revisits the no-signaling condition for decentralized information structures. We produce examples to show that within the no-signaling polytope exist strategies that cannot be achieved by passive common randomness but instead require agents to either share their observations with a mediator or communicate directly with each other. This poses a question mark on whether the no-signaling condition truly captures the decentralized information structure in the strictest sense.",
        "subjects": [
            "cs.IT",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.16836",
        "abstract url": "https://arxiv.org/abs/2404.16836",
        "title": "The Division Problem of Chances",
        "rating": "-10",
        "keywords": [],
        "abstract": "In frequently repeated matching scenarios, individuals may require diversification in their choices. Therefore, when faced with a set of potential outcomes, each individual may have an ideal lottery over outcomes that represents their preferred option. This suggests that, as people seek variety, their favorite choice is not a particular outcome, but rather a lottery over them as their peak for their preferences. We explore matching problems in situations where agents' preferences are represented by ideal lotteries. Our focus lies in addressing the challenge of dividing chances in matching, where agents express their preferences over a set of objects through ideal lotteries that reflect their single-peaked preferences. We discuss properties such as strategy proofness, replacement monotonicity, (Pareto) efficiency, in-betweenness, non-bossiness, envy-freeness, and anonymity in the context of dividing chances, and propose a class of mechanisms called URC mechanisms that satisfy these properties. Subsequently, we prove that if a mechanism for dividing chances is strategy proof, (Pareto) efficient, replacement monotonic, in-between, non-bossy, and anonymous (or envy free), then it is equivalent in terms of welfare to a URC mechanism.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "52 pages, 5 figures"
    },
    {
        "paper id": "2405.00005",
        "abstract url": "https://arxiv.org/abs/2405.00005",
        "title": "Scheduling of Distributed Applications on the Computing Continuum: A Survey",
        "rating": "-10",
        "keywords": [],
        "abstract": "The demand for distributed applications has significantly increased over the past decade, with improvements in machine learning techniques fueling this growth. These applications predominantly utilize Cloud data centers for high-performance computing and Fog and Edge devices for low-latency communication for small-size machine learning model training and inference. The challenge of executing applications with different requirements on heterogeneous devices requires effective methods for solving NP-hard resource allocation and application scheduling problems. The state-of-the-art techniques primarily investigate conflicting objectives, such as the completion time, energy consumption, and economic cost of application execution on the Cloud, Fog, and Edge computing infrastructure. Therefore, in this work, we review these research works considering their objectives, methods, and evaluation tools. Based on the review, we provide a discussion on the scheduling methods in the Computing Continuum.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "7 pages, 3 figures, 3 tables"
    }
]