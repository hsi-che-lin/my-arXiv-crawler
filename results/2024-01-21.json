[
    {
        "paper id": "2401.11649",
        "abstract url": "https://arxiv.org/abs/2401.11649",
        "title": "M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action Recognition",
        "rating": 3,
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient FineTuning"
            ],
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, the rise of large-scale vision-language pretrained models like CLIP, coupled with the technology of Parameter-Efficient FineTuning (PEFT), has captured substantial attraction in video action recognition. Nevertheless, prevailing approaches tend to prioritize strong supervised performance at the expense of compromising the models' generalization capabilities during transfer. In this paper, we introduce a novel Multimodal, Multi-task CLIP adapting framework named \\name to address these challenges, preserving both high supervised performance and robust transferability. Firstly, to enhance the individual modality architectures, we introduce multimodal adapters to both the visual and text branches. Specifically, we design a novel visual TED-Adapter, that performs global Temporal Enhancement and local temporal Difference modeling to improve the temporal representation capabilities of the visual encoder. Moreover, we adopt text encoder adapters to strengthen the learning of semantic label information. Secondly, we design a multi-task decoder with a rich set of supervisory signals to adeptly satisfy the need for strong supervised performance and generalization within a multimodal framework. Experimental results validate the efficacy of our approach, demonstrating exceptional performance in supervised learning while maintaining strong generalization in zero-shot scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11601",
        "abstract url": "https://arxiv.org/abs/2401.11601",
        "title": "Robust Evaluation Measures for Evaluating Social Biases in Masked Language Models",
        "rating": 2,
        "keywords": [
            [
                "Social Biases"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Many evaluation measures are used to evaluate social biases in masked language models (MLMs). However, we find that these previously proposed evaluation measures are lacking robustness in scenarios with limited datasets. This is because these measures are obtained by comparing the pseudo-log-likelihood (PLL) scores of the stereotypical and anti-stereotypical samples using an indicator function. The disadvantage is the limited mining of the PLL score sets without capturing its distributional information. In this paper, we represent a PLL score set as a Gaussian distribution and use Kullback Leibler (KL) divergence and Jensen Shannon (JS) divergence to construct evaluation measures for the distributions of stereotypical and anti-stereotypical PLL scores. Experimental results on the publicly available datasets StereoSet (SS) and CrowS-Pairs (CP) show that our proposed measures are significantly more robust and interpretable than those proposed previously.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2401.11633",
        "abstract url": "https://arxiv.org/abs/2401.11633",
        "title": "Zoom-shot: Fast and Efficient Unsupervised Zero-Shot Transfer of CLIP to Vision Encoders with Multimodal Loss",
        "rating": 2,
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The fusion of vision and language has brought about a transformative shift in computer vision through the emergence of Vision-Language Models (VLMs). However, the resource-intensive nature of existing VLMs poses a significant challenge. We need an accessible method for developing the next generation of VLMs. To address this issue, we propose Zoom-shot, a novel method for transferring the zero-shot capabilities of CLIP to any pre-trained vision encoder. We do this by exploiting the multimodal information (i.e. text and image) present in the CLIP latent space through the use of specifically designed multimodal loss functions. These loss functions are (1) cycle-consistency loss and (2) our novel prompt-guided knowledge distillation loss (PG-KD). PG-KD combines the concept of knowledge distillation with CLIP's zero-shot classification, to capture the interactions between text and image features. With our multimodal losses, we train a $\\textbf{linear mapping}$ between the CLIP latent space and the latent space of a pre-trained vision encoder, for only a $\\textbf{single epoch}$. Furthermore, Zoom-shot is entirely unsupervised and is trained using $\\textbf{unpaired}$ data. We test the zero-shot capabilities of a range of vision encoders augmented as new VLMs, on coarse and fine-grained classification datasets, outperforming the previous state-of-the-art in this problem domain. In our ablations, we find Zoom-shot allows for a trade-off between data and compute during training; and our state-of-the-art results can be obtained by reducing training from 20% to 1% of the ImageNet training data with 20 epochs. All code and models are available on GitHub.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2401.11431",
        "abstract url": "https://arxiv.org/abs/2401.11431",
        "title": "Majority or Minority: Data Imbalance Learning Method for Named Entity Recognition",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Data imbalance presents a significant challenge in various machine learning (ML) tasks, particularly named entity recognition (NER) within natural language processing (NLP). NER exhibits a data imbalance with a long-tail distribution, featuring numerous minority classes (i.e., entity classes) and a single majority class (i.e., O-class). This imbalance leads to misclassifications of the entity classes as the O-class. To tackle this issue, we propose a simple and effective learning method named majority or minority (MoM) learning. MoM learning incorporates the loss computed only for samples whose ground truth is the majority class into the loss of the conventional ML model. Evaluation experiments on four NER datasets (Japanese and English) showed that MoM learning improves prediction performance of the minority classes without sacrificing the performance of the majority class and is more effective than widely known and state-of-the-art methods. We also evaluated MoM learning using frameworks as sequential labeling and machine reading comprehension, which are commonly used in NER. Furthermore, MoM learning has achieved consistent performance improvements regardless of language or framework.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "5 pages, 1 figures, 3 tables. Accepted at Practical ML for Low Resource Settings (PML4LRS) Workshop @ ICLR 2024"
    },
    {
        "paper id": "2401.11615",
        "abstract url": "https://arxiv.org/abs/2401.11615",
        "title": "Another Way to the Top: Exploit Contextual Clustering in Learned Image Coding",
        "rating": 1.5,
        "keywords": [
            [
                "eess.IV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "While convolution and self-attention are extensively used in learned image compression (LIC) for transform coding, this paper proposes an alternative called Contextual Clustering based LIC (CLIC) which primarily relies on clustering operations and local attention for correlation characterization and compact representation of an image. As seen, CLIC expands the receptive field into the entire image for intra-cluster feature aggregation. Afterward, features are reordered to their original spatial positions to pass through the local attention units for inter-cluster embedding. Additionally, we introduce the Guided Post-Quantization Filtering (GuidedPQF) into CLIC, effectively mitigating the propagation and accumulation of quantization errors at the initial decoding stage. Extensive experiments demonstrate the superior performance of CLIC over state-of-the-art works: when optimized using MSE, it outperforms VVC by about 10% BD-Rate in three widely-used benchmark datasets; when optimized using MS-SSIM, it saves more than 50% BD-Rate over VVC. Our CLIC offers a new way to generate compact representations for image compression, which also provides a novel direction along the line of LIC development.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)"
    },
    {
        "paper id": "2401.11406",
        "abstract url": "https://arxiv.org/abs/2401.11406",
        "title": "Adversarial Augmentation Training Makes Action Recognition Models More Robust to Realistic Video Distribution Shifts",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite recent advances in video action recognition achieving strong performance on existing benchmarks, these models often lack robustness when faced with natural distribution shifts between training and test data. We propose two novel evaluation methods to assess model resilience to such distribution disparity. One method uses two different datasets collected from different sources and uses one for training and validation, and the other for testing. More precisely, we created dataset splits of HMDB-51 or UCF-101 for training, and Kinetics-400 for testing, using the subset of the classes that are overlapping in both train and test datasets. The other proposed method extracts the feature mean of each class from the target evaluation dataset's training data (i.e. class prototype) and estimates test video prediction as a cosine similarity score between each sample to the class prototypes of each target class. This procedure does not alter model weights using the target dataset and it does not require aligning overlapping classes of two different datasets, thus is a very efficient method to test the model robustness to distribution shifts without prior knowledge of the target distribution. We address the robustness problem by adversarial augmentation training - generating augmented views of videos that are \"hard\" for the classification model by applying gradient ascent on the augmentation parameters - as well as \"curriculum\" scheduling the strength of the video augmentations. We experimentally demonstrate the superior performance of the proposed adversarial augmentation approach over baselines across three state-of-the-art action recognition models - TSM, Video Swin Transformer, and Uniformer. The presented work provides critical insight into model robustness to distribution shifts and presents effective techniques to enhance video action recognition performance in a real-world deployment.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11413",
        "abstract url": "https://arxiv.org/abs/2401.11413",
        "title": "Optimal detection of non-overlapping images via combinatorial auction",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "This paper studies the classical problem of detecting the location of multiple image occurrences in a two-dimensional, noisy measurement. Assuming the image occurrences do not overlap, we formulate this task as a constrained maximum likelihood optimization problem. We show that the maximum likelihood estimator is equivalent to an instance of the winner determination problem from the field of combinatorial auction, and that the solution can be obtained by searching over a binary tree. We then design a pruning mechanism that significantly accelerates the runtime of the search. We demonstrate on simulations and electron microscopy data sets that the proposed algorithm provides accurate detection in challenging regimes of high noise levels and densely packed image occurrences.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11436",
        "abstract url": "https://arxiv.org/abs/2401.11436",
        "title": "Geometric Prior Guided Feature Representation Learning for Long-Tailed Classification",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Real-world data are long-tailed, the lack of tail samples leads to a significant limitation in the generalization ability of the model. Although numerous approaches of class re-balancing perform well for moderate class imbalance problems, additional knowledge needs to be introduced to help the tail class recover the underlying true distribution when the observed distribution from a few tail samples does not represent its true distribution properly, thus allowing the model to learn valuable information outside the observed domain. In this work, we propose to leverage the geometric information of the feature distribution of the well-represented head class to guide the model to learn the underlying distribution of the tail class. Specifically, we first systematically define the geometry of the feature distribution and the similarity measures between the geometries, and discover four phenomena regarding the relationship between the geometries of different feature distributions. Then, based on four phenomena, feature uncertainty representation is proposed to perturb the tail features by utilizing the geometry of the head class feature distribution. It aims to make the perturbed features cover the underlying distribution of the tail class as much as possible, thus improving the model's generalization performance in the test domain. Finally, we design a three-stage training scheme enabling feature uncertainty modeling to be successfully applied. Experiments on CIFAR-10/100-LT, ImageNet-LT, and iNaturalist2018 show that our proposed approach outperforms other similar methods on most metrics. In addition, the experimental phenomena we discovered are able to provide new perspectives and theoretical foundations for subsequent studies.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This work was accepted by the IJCV"
    },
    {
        "paper id": "2401.11453",
        "abstract url": "https://arxiv.org/abs/2401.11453",
        "title": "Inter-Domain Mixup for Semi-Supervised Domain Adaptation",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semi-supervised domain adaptation (SSDA) aims to bridge source and target domain distributions, with a small number of target labels available, achieving better classification performance than unsupervised domain adaptation (UDA). However, existing SSDA work fails to make full use of label information from both source and target domains for feature alignment across domains, resulting in label mismatch in the label space during model testing. This paper presents a novel SSDA approach, Inter-domain Mixup with Neighborhood Expansion (IDMNE), to tackle this issue. Firstly, we introduce a cross-domain feature alignment strategy, Inter-domain Mixup, that incorporates label information into model adaptation. Specifically, we employ sample-level and manifold-level data mixing to generate compatible training samples. These newly established samples, combined with reliable and actual label information, display diversity and compatibility across domains, while such extra supervision thus facilitates cross-domain feature alignment and mitigates label mismatch. Additionally, we utilize Neighborhood Expansion to leverage high-confidence pseudo-labeled samples in the target domain, diversifying the label information of the target domain and thereby further increasing the performance of the adaptation model. Accordingly, the proposed approach outperforms existing state-of-the-art methods, achieving significant accuracy improvements on popular SSDA benchmarks, including DomainNet, Office-Home, and Office-31.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Publisted to Elsevier PR2024, available at https://www.sciencedirect.com/science/article/pii/S0031320323007203?via%3Dihub"
    },
    {
        "paper id": "2401.11458",
        "abstract url": "https://arxiv.org/abs/2401.11458",
        "title": "Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The success of AI assistants based on Language Models (LLMs) hinges on Reinforcement Learning from Human Feedback (RLHF) to comprehend and align with user intentions. However, traditional alignment algorithms, such as PPO, are hampered by complex annotation and training requirements. This reliance limits the applicability of RLHF and hinders the development of professional assistants tailored to diverse human preferences. In this work, we introduce \\textit{Linear Alignment}, a novel algorithm that aligns language models with human preferences in one single inference step, eliminating the reliance on data annotation and model training. Linear alignment incorporates a new parameterization for policy optimization under divergence constraints, which enables the extraction of optimal policy in a closed-form manner and facilitates the direct estimation of the aligned response. Extensive experiments on both general and personalized preference datasets demonstrate that linear alignment significantly enhances the performance and efficiency of LLM alignment across diverse scenarios. Our code and dataset will be published on \\url{https://github.com/Wizardcoast/Linear_Alignment.git}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11467",
        "abstract url": "https://arxiv.org/abs/2401.11467",
        "title": "Over-Reasoning and Redundant Calculation of Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) can solve problems step-by-step. While this chain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if LLMs \\textit{know} when to use CoT and whether those CoT are always necessary to answer the question. This paper shows that LLMs tend to generate redundant calculations and reasoning on a manually constructed math QA dataset, GSM8K-Zero. GSM8K-Zero is constructed such that the questions can be answered without any calculations, but LLMs, including Llama-2 models and Claude-2, tend to generate lengthy and unnecessary calculations to answer the questions. We also conduct experiments to explain why LLMs generate redundant calculations and reasonings. GSM8K-Zero is publicly available at https://github.com/d223302/Over-Reasoning-of-LLMs and https://huggingface.co/datasets/dcml0714/GSM8K-Zero.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL 2024 main conference paper. Camera-ready version"
    },
    {
        "paper id": "2401.11469",
        "abstract url": "https://arxiv.org/abs/2401.11469",
        "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control",
        "rating": 1,
        "keywords": [
            [
                "training efficiency"
            ]
        ],
        "abstract": "Transformer-based models are becoming deeper and larger recently. For better scalability, an underlying training solution in industry is to split billions of parameters (tensors) into many tasks and then run them across homogeneous accelerators (e.g., GPUs). However, such dedicated compute cluster is prohibitively expensive in academia and moderate companies. An economic replacement is to aggregate existing heterogeneous devices and share resources among multi-tenants. Nevertheless, static hardware configurations and dynamic resource contention definitely cause straggling tasks, which heavily slows down the overall training efficiency. Existing works feature contributions mainly tailored for traditional data parallelism. They cannot work well for the new tensor parallelism due to strict communication and correctness constraints. In this paper we first present ZERO-resizing, a novel dynamic workload balancing technique without any data migration. We tune workloads in real-time by temporarily resizing matrices involved in core tensor-related computations. We particularly design data imputation and priority selection policies to respectively satisfy consistency constraint required by normal training and reduce the accuracy loss. We also give a lightweight data migration technique without loss of accuracy, to cope with heavy heterogeneity. Our final SEMI-migration solution is built on top of these two techniques and can adaptively distinguish their respective balancing missions, to achieve an overall success in efficiency and accuracy. Extensive experiments on the representative Colossal-AI platform validate the effectiveness of our proposals.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2401.11470",
        "abstract url": "https://arxiv.org/abs/2401.11470",
        "title": "Exploring Missing Modality in Multimodal Egocentric Datasets",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal video understanding is crucial for analyzing egocentric videos, where integrating multiple sensory signals significantly enhances action recognition and moment localization. However, practical applications often grapple with incomplete modalities due to factors like privacy concerns, efficiency demands, or hardware malfunctions. Addressing this, our study delves into the impact of missing modalities on egocentric action recognition, particularly within transformer-based models. We introduce a novel concept -Missing Modality Token (MMT)-to maintain performance even when modalities are absent, a strategy that proves effective in the Ego4D, Epic-Kitchens, and Epic-Sounds datasets. Our method mitigates the performance loss, reducing it from its original $\\sim 30\\%$ drop to only $\\sim 10\\%$ when half of the test set is modal-incomplete. Through extensive experimentation, we demonstrate the adaptability of MMT to different training scenarios and its superiority in handling missing modalities compared to current methods. Our research contributes a comprehensive analysis and an innovative approach, opening avenues for more resilient multimodal systems in real-world settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11485",
        "abstract url": "https://arxiv.org/abs/2401.11485",
        "title": "ColorVideoVDP: A visual difference predictor for image, video and display distortions",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "ColorVideoVDP is a video and image quality metric that models spatial and temporal aspects of vision, for both luminance and color. The metric is built on novel psychophysical models of chromatic spatiotemporal contrast sensitivity and cross-channel contrast masking. It accounts for the viewing conditions, geometric, and photometric characteristics of the display. It was trained to predict common video streaming distortions (e.g. video compression, rescaling, and transmission errors), and also 8 new distortion types related to AR/VR displays (e.g. light source and waveguide non-uniformities). To address the latter application, we collected our novel XR-Display-Artifact-Video quality dataset (XR-DAVID), comprised of 336 distorted videos. Extensive testing on XR-DAVID, as well as several datasets from the literature, indicate a significant gain in prediction performance compared to existing metrics. ColorVideoVDP opens the doors to many novel applications which require the joint automated spatiotemporal assessment of luminance and color distortions, including video streaming, display specification and design, visual comparison of results, and perceptually-guided quality optimization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "28 pages"
    },
    {
        "paper id": "2401.11487",
        "abstract url": "https://arxiv.org/abs/2401.11487",
        "title": "Towards Better Inclusivity: A Diverse Tweet Corpus of English Varieties",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The prevalence of social media presents a growing opportunity to collect and analyse examples of English varieties. Whilst usage of these varieties was - and, in many cases, still is - used only in spoken contexts or hard-to-access private messages, social media sites like Twitter provide a platform for users to communicate informally in a scrapeable format. Notably, Indian English (Hinglish), Singaporean English (Singlish), and African-American English (AAE) can be commonly found online. These varieties pose a challenge to existing natural language processing (NLP) tools as they often differ orthographically and syntactically from standard English for which the majority of these tools are built. NLP models trained on standard English texts produced biased outcomes for users of underrepresented varieties. Some research has aimed to overcome the inherent biases caused by unrepresentative data through techniques like data augmentation or adjusting training models. We aim to address the issue of bias at its root - the data itself. We curate a dataset of tweets from countries with high proportions of underserved English variety speakers, and propose an annotation framework of six categorical classifications along a pseudo-spectrum that measures the degree of standard English and that thereby indirectly aims to surface the manifestations of English varieties in these tweets. Following best annotation practices, our growing corpus features 170,800 tweets taken from 7 countries, labeled by annotators who are from those countries and can communicate in regionally-dominant varieties of English. Our corpus highlights the accuracy discrepancies in pre-trained language identifiers between western English and non-western (i.e., less standard) English varieties. We hope to contribute to the growing literature identifying and reducing the implicit demographic discrepancies in NLP.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages (including limitations, references and appendices), 2 figures"
    },
    {
        "paper id": "2401.11489",
        "abstract url": "https://arxiv.org/abs/2401.11489",
        "title": "MapChange: Enhancing Semantic Change Detection with Temporal-Invariant Historical Maps Based on Deep Triplet Network",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semantic Change Detection (SCD) is recognized as both a crucial and challenging task in the field of image analysis. Traditional methods for SCD have predominantly relied on the comparison of image pairs. However, this approach is significantly hindered by substantial imaging differences, which arise due to variations in shooting times, atmospheric conditions, and angles. Such discrepancies lead to two primary issues: the under-detection of minor yet significant changes, and the generation of false alarms due to temporal variances. These factors often result in unchanged objects appearing markedly different in multi-temporal images. In response to these challenges, the MapChange framework has been developed. This framework introduces a novel paradigm that synergizes temporal-invariant historical map data with contemporary high-resolution images. By employing this combination, the temporal variance inherent in conventional image pair comparisons is effectively mitigated. The efficacy of the MapChange framework has been empirically validated through comprehensive testing on two public datasets. These tests have demonstrated the framework's marked superiority over existing state-of-the-art SCD methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11492",
        "abstract url": "https://arxiv.org/abs/2401.11492",
        "title": "Edge-Enabled Real-time Railway Track Segmentation",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate and rapid railway track segmentation can assist automatic train driving and is a key step in early warning to fixed or moving obstacles on the railway track. However, certain existing algorithms tailored for track segmentation often struggle to meet the requirements of real-time and efficiency on resource-constrained edge devices. Considering this challenge, we propose an edge-enabled real-time railway track segmentation algorithm, which is optimized to be suitable for edge applications by optimizing the network structure and quantizing the model after training. Initially, Ghost convolution is introduced to reduce the complexity of the backbone, thereby achieving the extraction of key information of the interested region at a lower cost. To further reduce the model complexity and calculation, a new lightweight detection head is proposed to achieve the best balance between accuracy and efficiency. Subsequently, we introduce quantization techniques to map the model's floating-point weights and activation values into lower bit-width fixed-point representations, reducing computational demands and memory footprint, ultimately accelerating the model's inference. Finally, we draw inspiration from GPU parallel programming principles to expedite the pre-processing and post-processing stages of the algorithm by doing parallel processing. The approach is evaluated with public and challenging dataset RailSem19 and tested on Jetson Nano. Experimental results demonstrate that our enhanced algorithm achieves an accuracy level of 83.3% while achieving a real-time inference rate of 25 frames per second when the input size is 480x480, thereby effectively meeting the requirements for real-time and high-efficiency operation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11504",
        "abstract url": "https://arxiv.org/abs/2401.11504",
        "title": "With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Long text generation, such as novel writing and discourse-level translation with extremely long contexts, presents significant challenges to current language models. Existing methods mainly focus on extending the model's context window through strategies like length extrapolation. However, these approaches demand substantial hardware resources during the training and/or inference phases. Our proposed method, Temp-Lora, introduces an alternative concept. Instead of relying on the KV cache to store all context information, we embeds this information directly into a temporary Lora module. In the process of long text generation, this module is progressively trained with text generated previously. This approach not only efficiently preserves contextual knowledge but also prevents any permanent alteration to the model's parameters given that the module is discarded post-generation. Extensive experiments on the PG19 language modeling benchmark and the GuoFeng discourse-level translation benchmark validate the effectiveness of Temp-Lora. Our results show that: 1) Temp-Lora substantially enhances generation quality for long text, as indicated by a 13.2% decrease in perplexity (PPL) on a subset of PG19, and a 29.3% decrease in PPL along with a 113.2% increase in BLEU score on a subset of GuoFeng, 2) Temp-Lora is compatible with and enhances most existing long text generation methods, and 3) Temp-Lora can greatly reduce computational costs by shortening the context window. For example, we can ensure a moderate improvement in generation quality (a decrease of 3.8% in PPL) while enabling a 51.5% memory usage reduction and a 60.0% decrease in latency for inference.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11544",
        "abstract url": "https://arxiv.org/abs/2401.11544",
        "title": "Hierarchical Prompts for Rehearsal-free Continual Learning",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Continual learning endeavors to equip the model with the capability to integrate current task knowledge while mitigating the forgetting of past task knowledge. Inspired by prompt tuning, prompt-based methods maintain a frozen backbone and train with slight learnable prompts to minimize the catastrophic forgetting that arises due to updating a large number of backbone parameters. Nonetheless, these learnable prompts tend to concentrate on the discriminatory knowledge of the current task while ignoring past task knowledge, leading to that learnable prompts still suffering from catastrophic forgetting. This paper introduces a novel rehearsal-free paradigm for continual learning termed Hierarchical Prompts (H-Prompts), comprising three categories of prompts -- class prompt, task prompt, and general prompt. To effectively depict the knowledge of past classes, class prompt leverages Bayesian Distribution Alignment to model the distribution of classes in each task. To reduce the forgetting of past task knowledge, task prompt employs Cross-task Knowledge Excavation to amalgamate the knowledge encapsulated in the learned class prompts of past tasks and current task knowledge. Furthermore, general prompt utilizes Generalized Knowledge Exploration to deduce highly generalized knowledge in a self-supervised manner. Evaluations on two benchmarks substantiate the efficacy of the proposed H-Prompts, exemplified by an average accuracy of 87.8% in Split CIFAR-100 and 70.6% in Split ImageNet-R.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to TPAMI"
    },
    {
        "paper id": "2401.11618",
        "abstract url": "https://arxiv.org/abs/2401.11618",
        "title": "Efficient local linearity regularization to overcome catastrophic overfitting",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Catastrophic overfitting (CO) in single-step adversarial training (AT) results in abrupt drops in the adversarial test accuracy (even down to 0%). For models trained with multi-step AT, it has been observed that the loss function behaves locally linearly with respect to the input, this is however lost in single-step AT. To address CO in single-step AT, several methods have been proposed to enforce local linearity of the loss via regularization. However, these regularization terms considerably slow down training due to Double Backpropagation. Instead, in this work, we introduce a regularization term, called ELLE, to mitigate CO effectively and efficiently in classical AT evaluations, as well as some more difficult regimes, e.g., large adversarial perturbations and long training schedules. Our regularization term can be theoretically linked to curvature of the loss function and is computationally cheaper than previous methods by avoiding Double Backpropagation. Our thorough experimental validation demonstrates that our work does not suffer from CO, even in challenging settings where previous works suffer from it. We also notice that adapting our regularization parameter during training (ELLE-A) greatly improves the performance, specially in large $\u03b5$ setups. Our implementation is available in https://github.com/LIONS-EPFL/ELLE .",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted in ICLR 2024"
    },
    {
        "paper id": "2401.11624",
        "abstract url": "https://arxiv.org/abs/2401.11624",
        "title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training procedures, and inference algorithms.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11645",
        "abstract url": "https://arxiv.org/abs/2401.11645",
        "title": "Streaming Bilingual End-to-End ASR model using Attention over Multiple Softmax",
        "rating": 1,
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Even with several advancements in multilingual modeling, it is challenging to recognize multiple languages using a single neural model, without knowing the input language and most multilingual models assume the availability of the input language. In this work, we propose a novel bilingual end-to-end (E2E) modeling approach, where a single neural model can recognize both languages and also support switching between the languages, without any language input from the user. The proposed model has shared encoder and prediction networks, with language-specific joint networks that are combined via a self-attention mechanism. As the language-specific posteriors are combined, it produces a single posterior probability over all the output symbols, enabling a single beam search decoding and also allowing dynamic switching between the languages. The proposed approach outperforms the conventional bilingual baseline with 13.3%, 8.23% and 1.3% word error rate relative reduction on Hindi, English and code-mixed test sets, respectively.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Published in IEEE's Spoken Language Technology (SLT) 2022, 8 pages (6 + 2 for references), 5 figures"
    },
    {
        "paper id": "2401.11654",
        "abstract url": "https://arxiv.org/abs/2401.11654",
        "title": "ActionHub: A Large-scale Action Video Description Dataset for Zero-shot Action Recognition",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-shot action recognition (ZSAR) aims to learn an alignment model between videos and class descriptions of seen actions that is transferable to unseen actions. The text queries (class descriptions) used in existing ZSAR works, however, are often short action names that fail to capture the rich semantics in the videos, leading to misalignment. With the intuition that video content descriptions (e.g., video captions) can provide rich contextual information of visual concepts in videos, we propose to utilize human annotated video descriptions to enrich the semantics of the class descriptions of each action. However, all existing action video description datasets are limited in terms of the number of actions, the semantics of video descriptions, etc. To this end, we collect a large-scale action video descriptions dataset named ActionHub, which covers a total of 1,211 common actions and provides 3.6 million action video descriptions. With the proposed ActionHub dataset, we further propose a novel Cross-modality and Cross-action Modeling (CoCo) framework for ZSAR, which consists of a Dual Cross-modality Alignment module and a Cross-action Invariance Mining module. Specifically, the Dual Cross-modality Alignment module utilizes both action labels and video descriptions from ActionHub to obtain rich class semantic features for feature alignment. The Cross-action Invariance Mining module exploits a cycle-reconstruction process between the class semantic feature spaces of seen actions and unseen actions, aiming to guide the model to learn cross-action invariant representations. Extensive experimental results demonstrate that our CoCo framework significantly outperforms the state-of-the-art on three popular ZSAR benchmarks (i.e., Kinetics-ZSAR, UCF101 and HMDB51) under two different learning protocols in ZSAR. We will release our code, models, and the proposed ActionHub dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11667",
        "abstract url": "https://arxiv.org/abs/2401.11667",
        "title": "INCPrompt: Task-Aware incremental Prompting for Rehearsal-Free Class-incremental Learning",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "This paper introduces INCPrompt, an innovative continual learning solution that effectively addresses catastrophic forgetting. INCPrompt's key innovation lies in its use of adaptive key-learner and task-aware prompts that capture task-relevant information. This unique combination encapsulates general knowledge across tasks and encodes task-specific knowledge. Our comprehensive evaluation across multiple continual learning benchmarks demonstrates INCPrompt's superiority over existing algorithms, showing its effectiveness in mitigating catastrophic forgetting while maintaining high performance. These results highlight the significant impact of task-aware incremental prompting on continual learning performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by the 49th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)"
    },
    {
        "paper id": "2401.12255",
        "abstract url": "https://arxiv.org/abs/2401.12255",
        "title": "Instructional Fingerprinting of Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "parameter-efficient"
            ]
        ],
        "abstract": "The exorbitant cost of training Large language models (LLMs) from scratch makes it essential to fingerprint the models to protect intellectual property via ownership authentication and to ensure downstream users and developers comply with their license terms (e.g. restricting commercial use). In this study, we present a pilot study on LLM fingerprinting as a form of very lightweight instruction tuning. Model publisher specifies a confidential private key and implants it as an instruction backdoor that causes the LLM to generate specific text when the key is present. Results on 11 popularly-used LLMs showed that this approach is lightweight and does not affect the normal behavior of the model. It also prevents publisher overclaim, maintains robustness against fingerprint guessing and parameter-efficient training, and supports multi-stage fingerprinting akin to MIT License. Code is available in https://cnut1648.github.io/Model-Fingerprint/.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted at NAACL 2024; 30 pages"
    },
    {
        "paper id": "2401.11409",
        "abstract url": "https://arxiv.org/abs/2401.11409",
        "title": "Robust Beamforming for Downlink Multi-Cell Systems: A Bilevel Optimization Perspective",
        "rating": 0.5,
        "keywords": [
            [
                "AAAI"
            ]
        ],
        "abstract": "Utilization of inter-base station cooperation for information processing has shown great potential in enhancing the overall quality of communication services (QoS) in wireless communication networks. Nevertheless, such cooperations require the knowledge of channel state information (CSI) at base stations (BSs), which is assumed to be perfectly known. However, CSI errors are inevitable in practice which necessitates beamforming techniques that can achieve robust performance in the presence of channel estimation errors. Existing approaches relax the robust beamforming design problems into semidefinite programming (SDP), which can only achieve a solution that is far from being optimal. To this end, this paper views robust beamforming design problems from a bilevel optimization perspective. In particular, we focus on maximizing the worst-case weighted sum-rate (WSR) in the downlink multi-cell multi-user multiple-input single-output (MISO) system considering bounded CSI errors. We first reformulate this problem into a bilevel optimization problem and then develop an efficient algorithm based on the cutting plane method. A distributed optimization algorithm has also been developed to facilitate the parallel processing in practical settings. Numerical results are provided to confirm the effectiveness of the proposed algorithm in terms of performance and complexity, particularly in the presence of CSI uncertainties.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "accepted at AAAI2024"
    },
    {
        "paper id": "2401.11418",
        "abstract url": "https://arxiv.org/abs/2401.11418",
        "title": "Double-Bounded Optimal Transport for Advanced Clustering and Classification",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Optimal transport (OT) is attracting increasing attention in machine learning. It aims to transport a source distribution to a target one at minimal cost. In its vanilla form, the source and target distributions are predetermined, which contracts to the real-world case involving undetermined targets. In this paper, we propose Doubly Bounded Optimal Transport (DB-OT), which assumes that the target distribution is restricted within two boundaries instead of a fixed one, thus giving more freedom for the transport to find solutions. Based on the entropic regularization of DB-OT, three scaling-based algorithms are devised for calculating the optimal solution. We also show that our DB-OT is helpful for barycenter-based clustering, which can avoid the excessive concentration of samples in a single cluster. Then we further develop DB-OT techniques for long-tailed classification which is an emerging and open problem. We first propose a connection between OT and classification, that is, in the classification task, training involves optimizing the Inverse OT to learn the representations, while testing involves optimizing the OT for predictions. With this OT perspective, we first apply DB-OT to improve the loss, and the Balanced Softmax is shown as a special case. Then we apply DB-OT for inference in the testing process. Even with vanilla Softmax trained features, our extensive experimental results show that our method can achieve good results with our improved inference scheme in the testing stage.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11430",
        "abstract url": "https://arxiv.org/abs/2401.11430",
        "title": "Exploring Diffusion Time-steps for Unsupervised Representation Learning",
        "rating": 0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Representation learning is all about discovering the hidden modular attributes that generate the data faithfully. We explore the potential of Denoising Diffusion Probabilistic Model (DM) in unsupervised learning of the modular attributes. We build a theoretical framework that connects the diffusion time-steps and the hidden attributes, which serves as an effective inductive bias for unsupervised learning. Specifically, the forward diffusion process incrementally adds Gaussian noise to samples at each time-step, which essentially collapses different samples into similar ones by losing attributes, e.g., fine-grained attributes such as texture are lost with less noise added (i.e., early time-steps), while coarse-grained ones such as shape are lost by adding more noise (i.e., late time-steps). To disentangle the modular attributes, at each time-step t, we learn a t-specific feature to compensate for the newly lost attribute, and the set of all 1,...,t-specific features, corresponding to the cumulative set of lost attributes, are trained to make up for the reconstruction error of a pre-trained DM at time-step t. On CelebA, FFHQ, and Bedroom datasets, the learned feature significantly improves attribute classification and enables faithful counterfactual generation, e.g., interpolating only one specified attribute between two images, validating the disentanglement quality. Codes are in https://github.com/yue-zhongqi/diti.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2024"
    },
    {
        "paper id": "2401.11437",
        "abstract url": "https://arxiv.org/abs/2401.11437",
        "title": "Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Current advancements in reinforcement learning (RL) have predominantly focused on learning step-based policies that generate actions for each perceived state. While these methods efficiently leverage step information from environmental interaction, they often ignore the temporal correlation between actions, resulting in inefficient exploration and unsmooth trajectories that are challenging to implement on real hardware. Episodic RL (ERL) seeks to overcome these challenges by exploring in parameters space that capture the correlation of actions. However, these approaches typically compromise data efficiency, as they treat trajectories as opaque \\emph{black boxes}. In this work, we introduce a novel ERL algorithm, Temporally-Correlated Episodic RL (TCE), which effectively utilizes step information in episodic policy updates, opening the 'black box' in existing ERL methods while retaining the smooth and consistent exploration in parameter space. TCE synergistically combines the advantages of step-based and episodic RL, achieving comparable performance to recent ERL methods while maintaining data efficiency akin to state-of-the-art (SoTA) step-based RL.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Codebase, see: https://github.com/BruceGeLi/TCE_RL"
    },
    {
        "paper id": "2401.11447",
        "abstract url": "https://arxiv.org/abs/2401.11447",
        "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT. Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities. Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\\,\\%$ to $72\\%$, and for LSTM models, it is $66\\,\\%$ to $84\\,\\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for LSTM models it is between $1.09$ and $1.77$. Notably, these RMSEs are significantly lower than the random prediction error of $4.55$. Conclusion: We creatively apply sequential models in the long-term management of SCIT with promising accuracy in the prediction of SCIT nonadherence in Allergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in score prediction for patients undergoing SCIT for AR. The state-action-based SLAC adds flexibility, presenting a novel and effective approach for managing long-term AIT.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11462",
        "abstract url": "https://arxiv.org/abs/2401.11462",
        "title": "Frost Prediction Using Machine Learning Methods in Fars Province",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "One of the common hazards and issues in meteorology and agriculture is the problem of frost, chilling or freezing. This event occurs when the minimum ambient temperature falls below a certain value. This phenomenon causes a lot of damage to the country, especially Fars province. Solving this problem requires that, in addition to predicting the minimum temperature, we can provide enough time to implement the necessary measures. Empirical methods have been provided by the Food and Agriculture Organization (FAO), which can predict the minimum temperature, but not in time. In addition to this, we can use machine learning methods to model the minimum temperature. In this study, we have used three methods Gated Recurrent Unit (GRU), Temporal Convolutional Network (TCN) as deep learning methods, and Gradient Boosting (XGBoost). A customized loss function designed for methods based on deep learning, which can be effective in reducing prediction errors. With methods based on deep learning models, not only do we observe a reduction in RMSE error compared to empirical methods but also have more time to predict minimum temperature. Thus, we can model the minimum temperature for the next 24 hours by having the current 24 hours. With the gradient boosting model (XGBoost) we can keep the prediction time as deep learning and RMSE error reduced. Finally, we experimentally concluded that machine learning methods work better than empirical methods and XGBoost model can have better performance in this problem among other implemented.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accpeted by 28th International Computer Conference, Computer Society of Iran (CSICC)"
    },
    {
        "paper id": "2401.11472",
        "abstract url": "https://arxiv.org/abs/2401.11472",
        "title": "Abstract Weighted Based Gradual Semantics in Argumentation Theory",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Weighted gradual semantics provide an acceptability degree to each argument representing the strength of the argument, computed based on factors including background evidence for the argument, and taking into account interactions between this argument and others. We introduce four important problems linking gradual semantics and acceptability degrees. First, we reexamine the inverse problem, seeking to identify the argument weights of the argumentation framework which lead to a specific final acceptability degree. Second, we ask whether the function mapping between argument weights and acceptability degrees is injective or a homeomorphism onto its image. Third, we ask whether argument weights can be found when preferences, rather than acceptability degrees for arguments are considered. Fourth, we consider the topology of the space of valid acceptability degrees, asking whether gaps exist in this space. While different gradual semantics have been proposed in the literature, in this paper, we identify a large family of weighted gradual semantics, called abstract weighted based gradual semantics. These generalise many of the existing semantics while maintaining desirable properties such as convergence to a unique fixed point. We also show that a sub-family of the weighted gradual semantics, called abstract weighted (Lp,lambda,mu,A)-based gradual semantics and which include well-known semantics, solve all four of the aforementioned problems.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11511",
        "abstract url": "https://arxiv.org/abs/2401.11511",
        "title": "MobileARLoc: On-device Robust Absolute Localisation for Pervasive Markerless Mobile AR",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "workshop"
            ]
        ],
        "abstract": "Recent years have seen significant improvement in absolute camera pose estimation, paving the way for pervasive markerless Augmented Reality (AR). However, accurate absolute pose estimation techniques are computation- and storage-heavy, requiring computation offloading. As such, AR systems rely on visual-inertial odometry (VIO) to track the device's relative pose between requests to the server. However, VIO suffers from drift, requiring frequent absolute repositioning. This paper introduces MobileARLoc, a new framework for on-device large-scale markerless mobile AR that combines an absolute pose regressor (APR) with a local VIO tracking system. Absolute pose regressors (APRs) provide fast on-device pose estimation at the cost of reduced accuracy. To address APR accuracy and reduce VIO drift, MobileARLoc creates a feedback loop where VIO pose estimations refine the APR predictions. The VIO system identifies reliable predictions of APR, which are then used to compensate for the VIO drift. We comprehensively evaluate MobileARLoc through dataset simulations. MobileARLoc halves the error compared to the underlying APR and achieve fast (80\\,ms) on-device inference speed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for publication at the 3rd edition of the Pervasive and Resource-Constrained AI (PerConAI) workshop (co-located with PerCom 2024). This article supersedes arXiv:2308.05394"
    },
    {
        "paper id": "2401.11512",
        "abstract url": "https://arxiv.org/abs/2401.11512",
        "title": "Information-Theoretic State Variable Selection for Reinforcement Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Identifying the most suitable variables to represent the state is a fundamental challenge in Reinforcement Learning (RL). These variables must efficiently capture the information necessary for making optimal decisions. In order to address this problem, in this paper, we introduce the Transfer Entropy Redundancy Criterion (TERC), an information-theoretic criterion, which determines if there is \\textit{entropy transferred} from state variables to actions during training. We define an algorithm based on TERC that provably excludes variables from the state that have no effect on the final performance of the agent, resulting in more sample efficient learning. Experimental results show that this speed-up is present across three different algorithm classes (represented by tabular Q-learning, Actor-Critic, and Proximal Policy Optimization (PPO)) in a variety of environments. Furthermore, to highlight the differences between the proposed methodology and the current state-of-the-art feature selection approaches, we present a series of controlled experiments on synthetic data, before generalizing to real-world decision-making tasks. We also introduce a representation of the problem that compactly captures the transfer of information from state variables to actions as Bayesian networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "47 pages, 12 figures"
    },
    {
        "paper id": "2401.11553",
        "abstract url": "https://arxiv.org/abs/2401.11553",
        "title": "Taxi dispatching strategies with compensations",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi vehicles are key elements in daily traffic activity. The advance of ICT and geo-positioning systems has given rise to new opportunities for improving the efficiency of taxi fleets in terms of waiting times of passengers, cost and time for drivers, traffic density, CO2 emissions, etc., by using more informed, intelligent dispatching. Still, the explicit spatial and temporal components, as well as the scale and, in particular, the dynamicity of the problem of pairing passengers and taxis in big towns, render traditional approaches for solving standard assignment problem useless for this purpose, and call for intelligent approximation strategies based on domain-specific heuristics. Furthermore, taxi drivers are often autonomous actors and may not agree to participate in assignments that, though globally efficient, may not be sufficently beneficial for them individually. This paper presents a new heuristic algorithm for taxi assignment to customers that considers taxi reassignments if this may lead to globally better solutions. In addition, as such new assignments may reduce the expected revenues of individual drivers, we propose an economic compensation scheme to make individually rational drivers agree to proposed modifications in their assigned clients. We carried out a set of experiments, where several commonly used assignment strategies are compared to three different instantiations of our heuristic algorithm. The results indicate that our proposal has the potential to reduce customer waiting times in fleets of autonomous taxis, while being also beneficial from an economic point of view.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11565",
        "abstract url": "https://arxiv.org/abs/2401.11565",
        "title": "Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We explore a stochastic contextual linear bandit problem where the agent observes a noisy, corrupted version of the true context through a noise channel with an unknown noise parameter. Our objective is to design an action policy that can approximate\" that of an oracle, which has access to the reward model, the channel parameter, and the predictive distribution of the true context from the observed noisy context. In a Bayesian framework, we introduce a Thompson sampling algorithm for Gaussian bandits with Gaussian context noise. Adopting an information-theoretic analysis, we demonstrate the Bayesian regret of our algorithm concerning the oracle's action policy. We also extend this problem to a scenario where the agent observes the true context with some delay after receiving the reward and show that delayed true contexts lead to lower Bayesian regret. Finally, we empirically demonstrate the performance of the proposed algorithms against baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11609",
        "abstract url": "https://arxiv.org/abs/2401.11609",
        "title": "Graph Edits for Counterfactual Explanations: A comparative study",
        "rating": 0.5,
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals on images, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on graph edits as counterfactual explanations by conducting a comparative study which encompasses both supervised and unsupervised Graph Neural Network (GNN) approaches. To this end, we pose the following significant research question: should we represent input data as graphs, which is the optimal GNN approach in terms of performance and time efficiency to generate minimal and meaningful counterfactual explanations for black-box image classifiers?",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11627",
        "abstract url": "https://arxiv.org/abs/2401.11627",
        "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at AISTATS 2024"
    },
    {
        "paper id": "2401.11629",
        "abstract url": "https://arxiv.org/abs/2401.11629",
        "title": "Jump off the Bandwagon? Characterizing Bandwagon Fans' Future Loyalty in Online NBA Fan Communities",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Online user dynamics has been actively studied in recent years and bandwagon behavior is one of the most representative topics which can provide valuable insights for user identity change. Many previous studies have characterized bandwagon users and leveraged such characteristics to tackle practical problems such as community loyalty prediction. However, very few of them have investigated bandwagon dynamics from a long-term perspective. In this work, we focus on characterizing and predicting long-term bandwagon user behaviors in the context of online fan loyalty. Using a dataset collected from NBA-related discussion forums on Reddit, we trace the long-term loyalty status of bandwagon fans to capture their latent behavioral characteristics and then propose a computational model to predict their next sport season loyalty status with their home teams. Our analyses reveal that bandwagoning for most fans is a temporary switch and most of them will be back in the long term. In addition, online fans with different loyalty levels to their home teams have demonstrated different behaviors in various aspects, such as activity level, language usage and reply network properties. We then propose a model based on such behavioral characteristics to predict their next-season loyalty status. Its promising performance demonstrates the effectiveness of our behavior characterization.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Accepted to IEEE SocialCom 2023"
    },
    {
        "paper id": "2401.11630",
        "abstract url": "https://arxiv.org/abs/2401.11630",
        "title": "Reframing Offline Reinforcement Learning as a Regression Problem",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The study proposes the reformulation of offline reinforcement learning as a regression problem that can be solved with decision trees. Aiming to predict actions based on input states, return-to-go (RTG), and timestep information, we observe that with gradient-boosted trees, the agent training and inference are very fast, the former taking less than a minute. Despite the simplification inherent in this reformulated problem, our agent demonstrates performance that is at least on par with established methods. This assertion is validated by testing it across standard datasets associated with D4RL Gym-MuJoCo tasks. We further discuss the agent's ability to generalize by testing it on two extreme cases, how it learns to model the return distributions effectively even with highly skewed expert datasets, and how it exhibits robust performance in scenarios with sparse/delayed rewards.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11664",
        "abstract url": "https://arxiv.org/abs/2401.11664",
        "title": "Zero-Space Cost Fault Tolerance for Transformer-based Language Models on ReRAM",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Resistive Random Access Memory (ReRAM) has emerged as a promising platform for deep neural networks (DNNs) due to its support for parallel in-situ matrix-vector multiplication. However, hardware failures, such as stuck-at-fault defects, can result in significant prediction errors during model inference. While additional crossbars can be used to address these failures, they come with storage overhead and are not efficient in terms of space, energy, and cost. In this paper, we propose a fault protection mechanism that incurs zero space cost. Our approach includes: 1) differentiable structure pruning of rows and columns to reduce model redundancy, 2) weight duplication and voting for robust output, and 3) embedding duplicated most significant bits (MSBs) into the model weight. We evaluate our method on nine tasks of the GLUE benchmark with the BERT model, and experimental results prove its effectiveness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11673",
        "abstract url": "https://arxiv.org/abs/2401.11673",
        "title": "MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo",
        "rating": 0.5,
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Recent advancements in learning-based Multi-View Stereo (MVS) methods have prominently featured transformer-based models with attention mechanisms. However, existing approaches have not thoroughly investigated the profound influence of transformers on different MVS modules, resulting in limited depth estimation capabilities. In this paper, we introduce MVSFormer++, a method that prudently maximizes the inherent characteristics of attention to enhance various components of the MVS pipeline. Formally, our approach involves infusing cross-view information into the pre-trained DINOv2 model to facilitate MVS learning. Furthermore, we employ different attention mechanisms for the feature encoder and cost volume regularization, focusing on feature and spatial aggregations respectively. Additionally, we uncover that some design details would substantially impact the performance of transformer modules in MVS, including normalized 3D positional encoding, adaptive attention scaling, and the position of layer normalization. Comprehensive experiments on DTU, Tanks-and-Temples, BlendedMVS, and ETH3D validate the effectiveness of the proposed method. Notably, MVSFormer++ achieves state-of-the-art performance on the challenging DTU and Tanks-and-Temples benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ICLR2024"
    },
    {
        "paper id": "2401.12254",
        "abstract url": "https://arxiv.org/abs/2401.12254",
        "title": "Transfer learning-assisted inverse modeling in nanophotonics based on mixture density networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The simulation of nanophotonic structures relies on electromagnetic solvers, which play a crucial role in understanding their behavior. However, these solvers often come with a significant computational cost, making their application in design tasks, such as optimization, impractical. To address this challenge, machine learning techniques have been explored for accurate and efficient modeling and design of photonic devices. Deep neural networks, in particular, have gained considerable attention in this field. They can be used to create both forward and inverse models. An inverse modeling approach avoids the need for coupling a forward model with an optimizer and directly performs the prediction of the optimal design parameters values. In this paper, we propose an inverse modeling method for nanophotonic structures, based on a mixture density network model enhanced by transfer learning. Mixture density networks can predict multiple possible solutions at a time including their respective importance as Gaussian distributions. However, multiple challenges exist for mixture density network models. An important challenge is that an upper bound on the number of possible simultaneous solutions needs to be specified in advance. Also, another challenge is that the model parameters must be jointly optimized, which can result computationally expensive. Moreover, optimizing all parameters simultaneously can be numerically unstable and can lead to degenerate predictions. The proposed approach allows overcoming these limitations using transfer learning-based techniques, while preserving a high accuracy in the prediction capability of the design solutions given an optical response as an input. A dimensionality reduction step is also explored. Numerical results validate the proposed method.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11421",
        "abstract url": "https://arxiv.org/abs/2401.11421",
        "title": "Enhancing the vision-language foundation model with key semantic knowledge-emphasized report refinement",
        "rating": 0,
        "keywords": [
            [
                "vision-language"
            ],
            [
                "medical",
                "disease",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, vision-language representation learning has made remarkable advancements in building up medical foundation models, holding immense potential for transforming the landscape of clinical research and medical care. The underlying hypothesis is that the rich knowledge embedded in radiology reports can effectively assist and guide the learning process, reducing the need for additional labels. However, these reports tend to be complex and sometimes even consist of redundant descriptions that make the representation learning too challenging to capture the key semantic information. This paper develops a novel iterative vision-language representation learning framework by proposing a key semantic knowledge-emphasized report refinement method. Particularly, raw radiology reports are refined to highlight the key information according to a constructed clinical dictionary and two model-optimized knowledge-enhancement metrics. The iterative framework is designed to progressively learn, starting from gaining a general understanding of the patient's condition based on raw reports and gradually refines and extracts critical information essential to the fine-grained analysis tasks. The effectiveness of the proposed framework is validated on various downstream medical image analysis tasks, including disease classification, region-of-interest segmentation, and phrase grounding. Our framework surpasses seven state-of-the-art methods in both fine-tuning and zero-shot settings, demonstrating its encouraging potential for different clinical applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11448",
        "abstract url": "https://arxiv.org/abs/2401.11448",
        "title": "Adaptive Betweenness Clustering for Semi-Supervised Domain Adaptation",
        "rating": 0,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Compared to unsupervised domain adaptation, semi-supervised domain adaptation (SSDA) aims to significantly improve the classification performance and generalization capability of the model by leveraging the presence of a small amount of labeled data from the target domain. Several SSDA approaches have been developed to enable semantic-aligned feature confusion between labeled (or pseudo labeled) samples across domains; nevertheless, owing to the scarcity of semantic label information of the target domain, they were arduous to fully realize their potential. In this study, we propose a novel SSDA approach named Graph-based Adaptive Betweenness Clustering (G-ABC) for achieving categorical domain alignment, which enables cross-domain semantic alignment by mandating semantic transfer from labeled data of both the source and target domains to unlabeled target samples. In particular, a heterogeneous graph is initially constructed to reflect the pairwise relationships between labeled samples from both domains and unlabeled ones of the target domain. Then, to degrade the noisy connectivity in the graph, connectivity refinement is conducted by introducing two strategies, namely Confidence Uncertainty based Node Removal and Prediction Dissimilarity based Edge Pruning. Once the graph has been refined, Adaptive Betweenness Clustering is introduced to facilitate semantic transfer by using across-domain betweenness clustering and within-domain betweenness clustering, thereby propagating semantic label information from labeled samples across domains to unlabeled target data. Extensive experiments on three standard benchmark datasets, namely DomainNet, Office-Home, and Office-31, indicated that our method outperforms previous state-of-the-art SSDA approaches, demonstrating the superiority of the proposed G-ABC algorithm.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 9 figures, published to IEEE TIP"
    },
    {
        "paper id": "2401.11541",
        "abstract url": "https://arxiv.org/abs/2401.11541",
        "title": "Multi-View Neural 3D Reconstruction of Micro-/Nanostructures with Atomic Force Microscopy",
        "rating": 0,
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Atomic Force Microscopy (AFM) is a widely employed tool for micro-/nanoscale topographic imaging. However, conventional AFM scanning struggles to reconstruct complex 3D micro-/nanostructures precisely due to limitations such as incomplete sample topography capturing and tip-sample convolution artifacts. Here, we propose a multi-view neural-network-based framework with AFM (MVN-AFM), which accurately reconstructs surface models of intricate micro-/nanostructures. Unlike previous works, MVN-AFM does not depend on any specially shaped probes or costly modifications to the AFM system. To achieve this, MVN-AFM uniquely employs an iterative method to align multi-view data and eliminate AFM artifacts simultaneously. Furthermore, we pioneer the application of neural implicit surface reconstruction in nanotechnology and achieve markedly improved results. Extensive experiments show that MVN-AFM effectively eliminates artifacts present in raw AFM images and reconstructs various micro-/nanostructures including complex geometrical microstructures printed via Two-photon Lithography and nanoparticles such as PMMA nanospheres and ZIF-67 nanocrystals. This work presents a cost-effective tool for micro-/nanoscale 3D analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11605",
        "abstract url": "https://arxiv.org/abs/2401.11605",
        "title": "Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "Synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present the Hourglass Diffusion Transformer (HDiT), an image generative model that exhibits linear scaling with pixel count, supporting training at high-resolution (e.g. $1024 \\times 1024$) directly in pixel-space. Building on the Transformer architecture, which is known to scale to billions of parameters, it bridges the gap between the efficiency of convolutional U-Nets and the scalability of Transformers. HDiT trains successfully without typical high-resolution training techniques such as multiscale architectures, latent autoencoders or self-conditioning. We demonstrate that HDiT performs competitively with existing models on ImageNet $256^2$, and sets a new state-of-the-art for diffusion models on FFHQ-$1024^2$.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "20 pages, 13 figures, project page and code available at https://crowsonkb.github.io/hourglass-diffusion-transformers/"
    },
    {
        "paper id": "2401.11617",
        "abstract url": "https://arxiv.org/abs/2401.11617",
        "title": "A Survey on African Computer Vision Datasets, Topics and Researchers",
        "rating": 0,
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Computer vision encompasses a range of tasks such as object detection, semantic segmentation, and 3D reconstruction. Despite its relevance to African communities, research in this field within Africa represents only 0.06% of top-tier publications over the past decade. This study undertakes a thorough analysis of 63,000 Scopus-indexed computer vision publications from Africa, spanning from 2012 to 2022. The aim is to provide a survey of African computer vision topics, datasets and researchers. A key aspect of our study is the identification and categorization of African Computer Vision datasets using large language models that automatically parse abstracts of these publications. We also provide a compilation of unofficial African Computer Vision datasets distributed through challenges or data hosting platforms, and provide a full taxonomy of dataset categories. Our survey also pinpoints computer vision topics trends specific to different African regions, indicating their unique focus areas. Additionally, we carried out an extensive survey to capture the views of African researchers on the current state of computer vision research in the continent and the structural barriers they believe need urgent attention. In conclusion, this study catalogs and categorizes Computer Vision datasets and topics contributed or initiated by African institutions and identifies barriers to publishing in top-tier Computer Vision venues. This survey underscores the importance of encouraging African researchers and institutions in advancing computer vision research in the continent. It also stresses on the need for research topics to be more aligned with the needs of African communities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under Review, Community Work of Ro'ya Grassroots, https://ro-ya-cv4africa.github.io/homepage/.Journal extension of our conference paper, arXiv admin note: text overlap with arXiv:2305.06773"
    },
    {
        "paper id": "2401.11652",
        "abstract url": "https://arxiv.org/abs/2401.11652",
        "title": "OnDev-LCT: On-Device Lightweight Convolutional Transformers towards federated learning",
        "rating": 0,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Federated learning (FL) has emerged as a promising approach to collaboratively train machine learning models across multiple edge devices while preserving privacy. The success of FL hinges on the efficiency of participating models and their ability to handle the unique challenges of distributed learning. While several variants of Vision Transformer (ViT) have shown great potential as alternatives to modern convolutional neural networks (CNNs) for centralized training, the unprecedented size and higher computational demands hinder their deployment on resource-constrained edge devices, challenging their widespread application in FL. Since client devices in FL typically have limited computing resources and communication bandwidth, models intended for such devices must strike a balance between model size, computational efficiency, and the ability to adapt to the diverse and non-IID data distributions encountered in FL. To address these challenges, we propose OnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks with limited training data and resources. Our models incorporate image-specific inductive biases through the LCT tokenizer by leveraging efficient depthwise separable convolutions in residual linear bottleneck blocks to extract local features, while the multi-head self-attention (MHSA) mechanism in the LCT encoder implicitly facilitates capturing global representations of images. Extensive experiments on benchmark image datasets indicate that our models outperform existing lightweight vision models while having fewer parameters and lower computational demands, making them suitable for FL scenarios with data heterogeneity and communication bottlenecks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published in Neural Networks"
    },
    {
        "paper id": "2401.11675",
        "abstract url": "https://arxiv.org/abs/2401.11675",
        "title": "Rethinking Cross-Attention for Infrared and Visible Image Fusion",
        "rating": 0,
        "keywords": [
            [
                "Infrared"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The salient information of an infrared image and the abundant texture of a visible image can be fused to obtain a comprehensive image. As can be known, the current fusion methods based on Transformer techniques for infrared and visible (IV) images have exhibited promising performance. However, the attention mechanism of the previous Transformer-based methods was prone to extract common information from source images without considering the discrepancy information, which limited fusion performance. In this paper, by reevaluating the cross-attention mechanism, we propose an alternate Transformer fusion network (ATFuse) to fuse IV images. Our ATFuse consists of one discrepancy information injection module (DIIM) and two alternate common information injection modules (ACIIM). The DIIM is designed by modifying the vanilla cross-attention mechanism, which can promote the extraction of the discrepancy information of the source images. Meanwhile, the ACIIM is devised by alternately using the vanilla cross-attention mechanism, which can fully mine common information and integrate long dependencies. Moreover, the successful training of ATFuse is facilitated by a proposed segmented pixel loss function, which provides a good trade-off for texture detail and salient structure preservation. The qualitative and quantitative results on public datasets indicate our ATFFuse is effective and superior compared to other state-of-the-art methods.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01680",
        "abstract url": "https://arxiv.org/abs/2402.01680",
        "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges",
        "rating": 0,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents' capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This work is ongoing and we welcome your contribution!"
    },
    {
        "paper id": "2401.11415",
        "abstract url": "https://arxiv.org/abs/2401.11415",
        "title": "A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Link prediction can help rectify inaccuracies in various graph algorithms, stemming from unaccounted-for or overlooked links within networks. However, many existing works use a baseline approach, which incurs unnecessary computational costs due to its high time complexity. Further, many studies focus on smaller graphs, which can lead to misleading conclusions. This technical report introduces two parallel approaches, called IHub and LHub, which predict links using neighborhood-based similarity measures on large graphs. LHub is a heuristic approach that additionally disregards large hubs, based on the idea that high-degree nodes contribute little similarity among their neighbors. On a server equipped with dual 16-core Intel Xeon Gold 6226R processors, LHub is on average 1019x faster than IHub, especially on web graphs and social networks, while maintaining similar prediction accuracy. Notably, LHub achieves a link prediction rate of 38.1M edges/s and improves performance at a rate of 1.6x for every doubling of threads.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "16 pages, 11 figures, 1 table"
    },
    {
        "paper id": "2401.11543",
        "abstract url": "https://arxiv.org/abs/2401.11543",
        "title": "How Robust Are Energy-Based Models Trained With Equilibrium Propagation?",
        "rating": -0.5,
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) are easily fooled by adversarial perturbations that are imperceptible to humans. Adversarial training, a process where adversarial examples are added to the training set, is the current state-of-the-art defense against adversarial attacks, but it lowers the model's accuracy on clean inputs, is computationally expensive, and offers less robustness to natural noise. In contrast, energy-based models (EBMs), which were designed for efficient implementation in neuromorphic hardware and physical systems, incorporate feedback connections from each layer to the previous layer, yielding a recurrent, deep-attractor architecture which we hypothesize should make them naturally robust. Our work is the first to explore the robustness of EBMs to both natural corruptions and adversarial attacks, which we do using the CIFAR-10 and CIFAR-100 datasets. We demonstrate that EBMs are more robust than transformers and display comparable robustness to adversarially-trained DNNs on gradient-based (white-box) attacks, query-based (black-box) attacks, and natural perturbations without sacrificing clean accuracy, and without the need for adversarial training or additional training techniques.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11592",
        "abstract url": "https://arxiv.org/abs/2401.11592",
        "title": "Differentially-Private Hierarchical Federated Learning",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "While federated learning (FL) eliminates the transmission of raw data over a network, it is still vulnerable to privacy breaches from the communicated model parameters. In this work, we propose \\underline{H}ierarchical \\underline{F}ederated Learning with \\underline{H}ierarchical \\underline{D}ifferential \\underline{P}rivacy ({\\tt H$^2$FDP}), a DP-enhanced FL methodology for jointly optimizing privacy and performance in hierarchical networks. Building upon recent proposals for Hierarchical Differential Privacy (HDP), one of the key concepts of {\\tt H$^2$FDP} is adapting DP noise injection at different layers of an established FL hierarchy -- edge devices, edge servers, and cloud servers -- according to the trust models within particular subnetworks. We conduct a comprehensive analysis of the convergence behavior of {\\tt H$^2$FDP}, revealing conditions on parameter tuning under which the training process converges sublinearly to a finite stationarity gap that depends on the network hierarchy, trust model, and target privacy level. Leveraging these relationships, we develop an adaptive control algorithm for {\\tt H$^2$FDP} that tunes properties of local model training to minimize communication energy, latency, and the stationarity gap while striving to maintain a sub-linear convergence rate and meet desired privacy criteria. Subsequent numerical evaluations demonstrate that {\\tt H$^2$FDP} obtains substantial improvements in these metrics over baselines for different privacy budgets, and validate the impact of different system configurations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11600",
        "abstract url": "https://arxiv.org/abs/2401.11600",
        "title": "Understanding the Generalization Benefits of Late Learning Rate Decay",
        "rating": -0.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Why do neural networks trained with large learning rates for a longer time often lead to better generalization? In this paper, we delve into this question by examining the relation between training and testing loss in neural networks. Through visualization of these losses, we note that the training trajectory with a large learning rate navigates through the minima manifold of the training loss, finally nearing the neighborhood of the testing loss minimum. Motivated by these findings, we introduce a nonlinear model whose loss landscapes mirror those observed for real neural networks. Upon investigating the training process using SGD on our model, we demonstrate that an extended phase with a large learning rate steers our model towards the minimum norm solution of the training loss, which may achieve near-optimal generalization, thereby affirming the empirically observed benefits of late learning rate decay.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by AISTATS 2024"
    },
    {
        "paper id": "2401.11626",
        "abstract url": "https://arxiv.org/abs/2401.11626",
        "title": "Freely Long-Thinking Transformer (FraiLT)",
        "rating": -0.5,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Freely Long-Thinking Transformer (FraiLT) is an improved transformer model designed to enhance processing capabilities without scaling up size. It utilizes a recursive approach, iterating over a subset of layers multiple times, and introduces iteration encodings to maintain awareness across these cycles. Iteration encoding allows FraiLT to achieve the interpretive depth of larger models in a compact form. When evaluated on a synthetic story dataset, FraiLT outperformed larger models, showcasing its ability to deliver high-quality performance while reducing memory demands. This model represents a step forward towards more efficient and accessible language models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11647",
        "abstract url": "https://arxiv.org/abs/2401.11647",
        "title": "LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised Learning",
        "rating": -0.5,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many recent studies integrate federated learning (FL) with self-supervised learning (SSL) to take advantage of raw training data distributed across edge devices. However, edge devices often struggle with high computation and communication costs imposed by SSL and FL algorithms. To tackle this hindrance, we propose LW-FedSSL, a layer-wise federated self-supervised learning approach that allows edge devices to incrementally train one layer of the model at a time. LW-FedSSL comprises server-side calibration and representation alignment mechanisms to maintain comparable performance with end-to-end FedSSL while significantly lowering clients' resource requirements. The server-side calibration mechanism takes advantage of the resource-rich server in an FL environment to assist in global model training. Meanwhile, the representation alignment mechanism encourages closeness between representations of FL local models and those of the global model. Our experiments show that LW-FedSSL has a $3.3 \\times$ lower memory requirement and a $3.2 \\times$ cheaper communication cost than its end-to-end counterpart. We also explore a progressive training strategy called Prog-FedSSL that outperforms end-to-end training with a similar memory requirement and a $1.8 \\times$ cheaper communication cost.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11660",
        "abstract url": "https://arxiv.org/abs/2401.11660",
        "title": "Differentiable Tree Search in Latent State Space",
        "rating": -0.5,
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In decision-making problems with limited training data, policy functions approximated using deep neural networks often exhibit suboptimal performance. An alternative approach involves learning a world model from the limited data and determining actions through online search. However, the performance is adversely affected by compounding errors arising from inaccuracies in the learnt world model. While methods like TreeQN have attempted to address these inaccuracies by incorporating algorithmic structural biases into their architectures, the biases they introduce are often weak and insufficient for complex decision-making tasks. In this work, we introduce Differentiable Tree Search (DTS), a novel neural network architecture that significantly strengthens the inductive bias by embedding the algorithmic structure of a best-first online search algorithm. DTS employs a learnt world model to conduct a fully differentiable online search in latent state space. The world model is jointly optimised with the search algorithm, enabling the learning of a robust world model and mitigating the effect of model inaccuracies. We address potential Q-function discontinuities arising from naive incorporation of best-first search by adopting a stochastic tree expansion policy, formulating search tree expansion as a decision-making task, and introducing an effective variance reduction technique for the gradient computation. We evaluate DTS in an offline-RL setting with a limited training data scenario on Procgen games and grid navigation task, and demonstrate that DTS outperforms popular model-free and model-based baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11414",
        "abstract url": "https://arxiv.org/abs/2401.11414",
        "title": "S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching for Autonomous Driving",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semantic segmentation and stereo matching are two essential components of 3D environmental perception systems for autonomous driving. Nevertheless, conventional approaches often address these two problems independently, employing separate models for each task. This approach poses practical limitations in real-world scenarios, particularly when computational resources are scarce or real-time performance is imperative. Hence, in this article, we introduce S$^3$M-Net, a novel joint learning framework developed to perform semantic segmentation and stereo matching simultaneously. Specifically, S$^3$M-Net shares the features extracted from RGB images between both tasks, resulting in an improved overall scene understanding capability. This feature sharing process is realized using a feature fusion adaption (FFA) module, which effectively transforms the shared features into semantic space and subsequently fuses them with the encoded disparity features. The entire joint learning framework is trained by minimizing a novel semantic consistency-guided (SCG) loss, which places emphasis on the structural consistency in both tasks. Extensive experimental results conducted on the vKITTI2 and KITTI datasets demonstrate the effectiveness of our proposed joint learning framework and its superior performance compared to other state-of-the-art single-task networks. Our project webpage is accessible at mias.group/S3M-Net.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted to IEEE Trans. on Intelligent Vehicles (T-IV)"
    },
    {
        "paper id": "2401.11420",
        "abstract url": "https://arxiv.org/abs/2401.11420",
        "title": "Embedded Hyperspectral Band Selection with Adaptive Optimization for Image Semantic Segmentation",
        "rating": -1,
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Hyperspectral band selection plays a pivotal role in remote sensing and image analysis, aiming to identify the most informative spectral bands while minimizing computational overhead. In this paper, we introduce a pioneering approach for hyperspectral band selection that offers an embedded solution, making it well-suited for resource-constrained or real-time applications. Our proposed method, embedded Hyperspectral Band Selection (EHBS), excels in selecting the best bands without the need for prior processing, seamlessly integrating with the downstream task model. This is achieved through the adaptation of the Stochastic Gates (STG) algorithm, originally designed for feature selection, for hyperspectral band selection in the context of image semantic segmentation and the integration of a dynamic optimizer, DoG, which removes the need for the required tuning the learning rate. To assess the performance of our method, we introduce a novel metric for evaluating band selection methods across different target numbers of selected bands quantified by the Area Under the Curve (AUC). We conduct experiments on two distinct semantic-segmentation hyperspectral benchmark datasets, demonstrating its superiority in terms of its resulting accuracy and its ease of use compared to many common and state-of-the-art methods. Furthermore, our contributions extend beyond the realm of hyperspectral band selection. The adaptability of our approach to other tasks, especially those involving grouped features, opens up promising avenues for broader applications within the realm of deep learning, such as feature selection for feature groups. The demonstrated success on the tested datasets and the potential for application to a variety of tasks underscore the value of our method as a substantial addition to the field of computer vision.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11464",
        "abstract url": "https://arxiv.org/abs/2401.11464",
        "title": "Task-specific regularization loss towards model calibration for reliable lung cancer detection",
        "rating": -1,
        "keywords": [
            [
                "survival",
                "CT",
                "cancer"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Lung cancer is one of the significant causes of cancer-related deaths globally. Early detection and treatment improve the chances of survival. Traditionally CT scans have been used to extract the most significant lung infection information and diagnose cancer. This process is carried out manually by an expert radiologist. The imbalance in the radiologists-to-population ratio in a country like India implies significant work pressure on them and thus raises the need to automate a few of their responsibilities. The tendency of modern-day Deep Neural networks to make overconfident mistakes limit their usage to detect cancer. In this paper, we propose a new task-specific loss function to calibrate the neural network to reduce the risk of overconfident mistakes. We use the state-of-the-art Multi-class Difference in Confidence and Accuracy (MDCA) loss in conjunction with the proposed task-specific loss function to achieve the same. We also integrate post-hoc calibration by performing temperature scaling on top of the train-time calibrated model. We demonstrate 5.98% improvement in the Expected Calibration Error (ECE) and a 17.9% improvement in Maximum Calibration Error (MCE) as compared to the best-performing SOTA algorithm.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11479",
        "abstract url": "https://arxiv.org/abs/2401.11479",
        "title": "Battery-Free Sensor Array for Wireless Multi-Depth In-Situ Sensing",
        "rating": -1,
        "keywords": [
            [
                "Depth"
            ]
        ],
        "abstract": "Underground in-situ sensing plays a vital role in precision agriculture and infrastructure monitoring. While existing sensing systems utilize wires to connect an array of sensors at various depths for spatial-temporal data collection, wireless underground sensor networks offer a cable-free alternative. However, these wireless sensors are typically battery-powered, necessitating periodic recharging or replacement. This paper proposes a battery-free sensor array which can be used for wireless multi-depth in-situ sensing. Utilizing Near Field Communication (NFC)-which can penetrate soil with negligible signal power loss-this sensor array can form a virtual magnetic waveguide, achieving long communication ranges. An analytical model has been developed to offer insights and determine optimal design parameters. Moreover, a prototype, constructed using off-the-shelf NFC sensors, was tested to validate the proposed concept. While this system is primarily designed for underground applications, it holds potential for other multi-depth in-situ sensing scenarios, including underwater environments.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11483",
        "abstract url": "https://arxiv.org/abs/2401.11483",
        "title": "Distributed Traffic Signal Control of Interconnected Intersections: A Two-Lane Traffic Network Model",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Practical and accurate traffic models play an important role in capturing real traffic dynamics and then in achieving effective control performance. This paper studies traffic signal control in a traffic network with multiple interconnected intersections, where the target is to balance the vehicle density on each lane by controlling the green times of each phase at every intersection. Different from traditional road-based modeling schemes, a two-lane intersection model is first proposed to model the flow propagation in a more accurate way. A distributed model predictive control (MPC) method is then presented to assign the green times. To enable the real-time feasibility of the proposed approach, the alternating direction method of multipliers (ADMM) is incorporated with the distributed MPC scheme for solving the problem. Finally, the simulation studies performed in VISSIM for a six-intersection traffic network in Dalian, China, show the effectiveness and characteristics of the proposed method.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "journal paper"
    },
    {
        "paper id": "2401.11505",
        "abstract url": "https://arxiv.org/abs/2401.11505",
        "title": "CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray Report Labeling",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "X-ray"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Free-text radiology reports present a rich data source for various medical tasks, but effectively labeling these texts remains challenging. Traditional rule-based labeling methods fall short of capturing the nuances of diverse free-text patterns. Moreover, models using expert-annotated data are limited by data scarcity and pre-defined classes, impacting their performance, flexibility and scalability. To address these issues, our study offers three main contributions: 1) We demonstrate the potential of GPT as an adept labeler using carefully designed prompts. 2) Utilizing only the data labeled by GPT, we trained a BERT-based labeler, CheX-GPT, which operates faster and more efficiently than its GPT counterpart. 3) To benchmark labeler performance, we introduced a publicly available expert-annotated test set, MIMIC-500, comprising 500 cases from the MIMIC validation set. Our findings demonstrate that CheX-GPT not only excels in labeling accuracy over existing models, but also showcases superior efficiency, flexibility, and scalability, supported by our introduction of the MIMIC-500 dataset for robust benchmarking. Code and models are available at https://github.com/kakaobrain/CheXGPT.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "16 pages, 3 figures"
    },
    {
        "paper id": "2401.11519",
        "abstract url": "https://arxiv.org/abs/2401.11519",
        "title": "CaBuAr: California Burned Areas dataset for delineation",
        "rating": -1,
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Forest wildfires represent one of the catastrophic events that, over the last decades, caused huge environmental and humanitarian damages. In addition to a significant amount of carbon dioxide emission, they are a source of risk to society in both short-term (e.g., temporary city evacuation due to fire) and long-term (e.g., higher risks of landslides) cases. Consequently, the availability of tools to support local authorities in automatically identifying burned areas plays an important role in the continuous monitoring requirement to alleviate the aftereffects of such catastrophic events. The great availability of satellite acquisitions coupled with computer vision techniques represents an important step in developing such tools. This paper introduces a novel open dataset that tackles the burned area delineation problem, a binary segmentation problem applied to satellite imagery. The presented resource consists of pre- and post-fire Sentinel-2 L2A acquisitions of California forest fires that took place starting in 2015. Raster annotations were generated from the data released by California's Department of Forestry and Fire Protection. Moreover, in conjunction with the dataset, we release three different baselines based on spectral indexes analyses, SegFormer, and U-Net models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at the IEEE Geoscience and Remote Sensing Magazine"
    },
    {
        "paper id": "2401.11524",
        "abstract url": "https://arxiv.org/abs/2401.11524",
        "title": "Controlling the Misinformation Diffusion in Social Media by the Effect of Different Classes of Agents",
        "rating": -1,
        "keywords": [
            [
                "Diffusion"
            ]
        ],
        "abstract": "The rapid and widespread dissemination of misinformation through social networks is a growing concern in today's digital age. This study focused on modeling fake news diffusion, discovering the spreading dynamics, and designing control strategies. A common approach for modeling the misinformation dynamics is SIR-based models. Our approach is an extension of a model called 'SBFC' which is a SIR-based model. This model has three states, Susceptible, Believer, and Fact-Checker. The dynamics and transition between states are based on neighbors' beliefs, hoax credibility, spreading rate, probability of verifying the news, and probability of forgetting the current state. Our contribution is to push this model to real social networks by considering different classes of agents with their characteristics. We proposed two main strategies for confronting misinformation diffusion. First, we can educate a minor class, like scholars or influencers, to improve their ability to verify the news or remember their state longer. The second strategy is adding fact-checker bots to the network to spread the facts and influence their neighbors' states. Our result shows that both of these approaches can effectively control the misinformation spread.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "Accepted at The Computational Social Science Society of the Americas (CSS) - 2023, Annual Conference"
    },
    {
        "paper id": "2401.11529",
        "abstract url": "https://arxiv.org/abs/2401.11529",
        "title": "Computational predictions of weld structural integrity in hydrogen transport pipelines",
        "rating": -1,
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "We combine welding process modelling with deformation-diffusion-fracture (embrittlement) simulations to predict failures in hydrogen transport pipelines. The focus is on the structural integrity of seam welds, as these are often the locations most susceptible to damage in gas transport infrastructure. Finite element analyses are conducted to showcase the ability of the model to predict cracking in pipeline steels exposed to hydrogen-containing environments. The validated model is then employed to quantify critical H$_2$ fracture pressures. The coupled, phase field-based simulations conducted provide insight into the role of existing defects, microstructural heterogeneity, and residual stresses. We find that under a combination of deleterious yet realistic conditions, the critical pressure at which fracture takes place can be as low as 15 MPa. These results bring new mechanistic insight into the viability of using the existing natural gas pipeline network to transport hydrogen, and the computational framework presented enables mapping the conditions under which this can be achieved safely.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11580",
        "abstract url": "https://arxiv.org/abs/2401.11580",
        "title": "Age of Gossip in Random and Bipartite Networks",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper we study gossip networks where a source observing a process sends updates to an underlying graph. Nodes in the graph communicate to their neighbors by randomly sending updates. Our interest is studying the version age of information (vAoI) metric over various classes of networks. It is known that the version age of $K_n$ is logarithmic, and the version age of $\\overline{K_n}$ is linear. We study the question `how does the vAoI evolve as we interpolate between $K_n$ and $\\overline{K_n}$' by studying Erd\u0151s-Reyni random graphs, random $d$-regular graphs, and bipartite networks. Our main results are proving the existence of a threshold in $G(n,p)$ from rational to logarithmic average version age, and showing $G(n,d)$ almost surely has logarithmic version age for constant $d$. We also characterize the version age of complete bipartite graphs $K_{L,R}$, when we let $L$ vary from $O(1)$ to $O(n)$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11582",
        "abstract url": "https://arxiv.org/abs/2401.11582",
        "title": "Thermal Image Calibration and Correction using Unpaired Cycle-Consistent Adversarial Networks",
        "rating": -1,
        "keywords": [
            [
                "Thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) offer a flexible and cost-effective solution for wildfire monitoring. However, their widespread deployment during wildfires has been hindered by a lack of operational guidelines and concerns about potential interference with aircraft systems. Consequently, the progress in developing deep-learning models for wildfire detection and characterization using aerial images is constrained by the limited availability, size, and quality of existing datasets. This paper introduces a solution aimed at enhancing the quality of current aerial wildfire datasets to align with advancements in camera technology. The proposed approach offers a solution to create a comprehensive, standardized large-scale image dataset. This paper presents a pipeline based on CycleGAN to enhance wildfire datasets and a novel fusion method that integrates paired RGB images as attribute conditioning in the generators of both directions, improving the accuracy of the generated images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper has been accepted at the Asilomar 2023 Conference and will be published"
    },
    {
        "paper id": "2401.11590",
        "abstract url": "https://arxiv.org/abs/2401.11590",
        "title": "Small Even Covers, Locally Decodable Codes and Restricted Subgraphs of Edge-Colored Kikuchi Graphs",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Given a $k$-uniform hypergraph $H$ on $n$ vertices, an even cover in $H$ is a collection of hyperedges that touch each vertex an even number of times. Even covers are a generalization of cycles in graphs and are equivalent to linearly dependent subsets of a system of linear equations modulo $2$. As a result, they arise naturally in the context of well-studied questions in coding theory and refuting unsatisfiable $k$-SAT formulas. Analogous to the irregular Moore bound of Alon, Hoory, and Linial (2002), in 2008, Feige conjectured an extremal trade-off between the number of hyperedges and the length of the smallest even cover in a $k$-uniform hypergraph. This conjecture was recently settled up to a multiplicative logarithmic factor in the number of hyperedges (Guruswami, Kothari, and 1Manohar 2022 and Hsieh, Kothari, and Mohanty 2023). These works introduce the new technique that relates hypergraph even covers to cycles in the associated \\emph{Kikuchi} graphs. Their analysis of these Kikuchi graphs, especially for odd $k$, is rather involved and relies on matrix concentration inequalities. In this work, we give a simple and purely combinatorial argument that recovers the best-known bound for Feige's conjecture for even $k$. We also introduce a novel variant of a Kikuchi graph which together with this argument improves the logarithmic factor in the best-known bounds for odd $k$. As an application of our ideas, we also give a purely combinatorial proof of the improved lower bounds (Alrabiah, Guruswami, Kothari and Manohar, 2023) on 3-query binary linear locally decodable codes.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "19 pages"
    },
    {
        "paper id": "2401.11599",
        "abstract url": "https://arxiv.org/abs/2401.11599",
        "title": "Reducing Usefulness of Stolen Credentials in SSO Contexts",
        "rating": -1,
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Approximately 61% of cyber attacks involve adversaries in possession of valid credentials. Attackers acquire credentials through various means, including phishing, dark web data drops, password reuse, etc. Multi-factor authentication (MFA) helps to thwart attacks that use valid credentials, but attackers still commonly breach systems by tricking users into accepting MFA step up requests through techniques, such as ``MFA Bombing'', where multiple requests are sent to a user until they accept one. Currently, there are several solutions to this problem, each with varying levels of security and increasing invasiveness on user devices. This paper proposes a token-based enrollment architecture that is less invasive to user devices than mobile device management, but still offers strong protection against use of stolen credentials and MFA attacks.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2401.11608",
        "abstract url": "https://arxiv.org/abs/2401.11608",
        "title": "$\\texttt{immrax}$: A Parallelizable and Differentiable Toolbox for Interval Analysis and Mixed Monotone Reachability in JAX",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "We present an implementation of interval analysis and mixed monotone interval reachability analysis as function transforms in Python, fully composable with the computational framework JAX. The resulting toolbox inherits several key features from JAX, including computational efficiency through Just-In-Time Compilation, GPU acceleration for quick parallelized computations, and Automatic Differentiability. We demonstrate the toolbox's performance on several case studies, including a reachability problem on a vehicle model controlled by a neural network, and a robust closed-loop optimal control problem for a swinging pendulum.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11610",
        "abstract url": "https://arxiv.org/abs/2401.11610",
        "title": "Note on k-Planar and Min-k-Planar Drawings of Graphs",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The k-planar graphs, which are (usually with small values of k such as 1, 2, 3) subject to recent intense research, admit a drawing in which edges are allowed to cross, but each one edge is allowed to carry at most k crossings. In recently introduced [Binucci et al., GD 2023] min-k-planar drawings of graphs, edges may possibly carry more than k crossings, but in any two crossing edges, at least one of the two must have at most k crossings. In both concepts, one may consider general drawings or a popular restricted concept of drawings called simple (sometimes also `good'). In a simple drawing, every two edges are allowed to cross at most once, and any two edges which share a vertex are forbidden to cross. While, regarding the former concept, it is for k<=3 known (but not widely known) that every general k-planar graph admits a simple k-planar drawing and this ceases to be true for any k>=4, the difference between general and simple drawings in the latter concept is more striking. We prove that graphs with a min-k-planar drawing but no simple min-k-planar drawing exist for every k>=2, and for every k>=3 there even is a graph with a min-3-planar drawing but no simple min-k-planar drawing.",
        "subjects": [
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11631",
        "abstract url": "https://arxiv.org/abs/2401.11631",
        "title": "Text-to-Image Cross-Modal Generation: A Systematic Review",
        "rating": -1,
        "keywords": [
            [
                "image editing",
                "Text-to-Image"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We review research on generating visual data from text from the angle of \"cross-modal generation.\" This point of view allows us to draw parallels between various methods geared towards working on input text and producing visual output, without limiting the analysis to narrow sub-areas. It also results in the identification of common templates in the field, which are then compared and contrasted both within pools of similar methods and across lines of research. We provide a breakdown of text-to-image generation into various flavors of image-from-text methods, video-from-text methods, image editing, self-supervised and graph-based approaches. In this discussion, we focus on research papers published at 8 leading machine learning conferences in the years 2016-2022, also incorporating a number of relevant papers not matching the outlined search criteria. The conducted review suggests a significant increase in the number of papers published in the area and highlights research gaps and potential lines of investigation. To our knowledge, this is the first review to systematically look at text-to-image generation from the perspective of \"cross-modal generation.\"",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11641",
        "abstract url": "https://arxiv.org/abs/2401.11641",
        "title": "Revolutionizing Finance with LLMs: An Overview of Applications and Insights",
        "rating": -1,
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, Large Language Models (LLMs) like ChatGPT have seen considerable advancements and have been applied in diverse fields. Built on the Transformer architecture, these models are trained on extensive datasets, enabling them to understand and generate human language effectively. In the financial domain, the deployment of LLMs is gaining momentum. These models are being utilized for automating financial report generation, forecasting market trends, analyzing investor sentiment, and offering personalized financial advice. Leveraging their natural language processing capabilities, LLMs can distill key insights from vast financial data, aiding institutions in making informed investment choices and enhancing both operational efficiency and customer satisfaction. In this study, we provide a comprehensive overview of the emerging integration of LLMs into various financial tasks. Additionally, we conducted holistic tests on multiple financial tasks through the combination of natural language instructions. Our findings show that GPT-4 effectively follow prompt instructions across various financial tasks. This survey and evaluation of LLMs in the financial domain aim to deepen the understanding of LLMs' current role in finance for both financial practitioners and LLM researchers, identify new research and application prospects, and highlight how these technologies can be leveraged to solve practical challenges in the finance industry.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11644",
        "abstract url": "https://arxiv.org/abs/2401.11644",
        "title": "Friends Across Time: Multi-Scale Action Segmentation Transformer for Surgical Phase Recognition",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "Surgical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic surgical phase recognition is a core technology for modern operating rooms and online surgical video assessment platforms. Current state-of-the-art methods use both spatial and temporal information to tackle the surgical phase recognition task. Building on this idea, we propose the Multi-Scale Action Segmentation Transformer (MS-AST) for offline surgical phase recognition and the Multi-Scale Action Segmentation Causal Transformer (MS-ASCT) for online surgical phase recognition. We use ResNet50 or EfficientNetV2-M for spatial feature extraction. Our MS-AST and MS-ASCT can model temporal information at different scales with multi-scale temporal self-attention and multi-scale temporal cross-attention, which enhances the capture of temporal relationships between frames and segments. We demonstrate that our method can achieve 95.26% and 96.15% accuracy on the Cholec80 dataset for online and offline surgical phase recognition, respectively, which achieves new state-of-the-art results. Our method can also achieve state-of-the-art results on non-medical datasets in the video action segmentation domain.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11650",
        "abstract url": "https://arxiv.org/abs/2401.11650",
        "title": "PointGL: A Simple Global-Local Framework for Efficient Point Cloud Analysis",
        "rating": -1,
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Efficient analysis of point clouds holds paramount significance in real-world 3D applications. Currently, prevailing point-based models adhere to the PointNet++ methodology, which involves embedding and abstracting point features within a sequence of spatially overlapping local point sets, resulting in noticeable computational redundancy. Drawing inspiration from the streamlined paradigm of pixel embedding followed by regional pooling in Convolutional Neural Networks (CNNs), we introduce a novel, uncomplicated yet potent architecture known as PointGL, crafted to facilitate efficient point cloud analysis. PointGL employs a hierarchical process of feature acquisition through two recursive steps. First, the Global Point Embedding leverages straightforward residual Multilayer Perceptrons (MLPs) to effectuate feature embedding for each individual point. Second, the novel Local Graph Pooling technique characterizes point-to-point relationships and abstracts regional representations through succinct local graphs. The harmonious fusion of one-time point embedding and parameter-free graph pooling contributes to PointGL's defining attributes of minimized model complexity and heightened efficiency. Our PointGL attains state-of-the-art accuracy on the ScanObjectNN dataset while exhibiting a runtime that is more than 5 times faster and utilizing only approximately 4% of the FLOPs and 30% of the parameters compared to the recent PointMLP model. The code for PointGL is available at https://github.com/Roywangj/PointGL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11666",
        "abstract url": "https://arxiv.org/abs/2401.11666",
        "title": "P2DT: Mitigating Forgetting in task-incremental Learning with progressive prompt Decision Transformer",
        "rating": -1.0,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Catastrophic forgetting poses a substantial challenge for managing intelligent agents controlled by a large model, causing performance degradation when these agents face new tasks. In our work, we propose a novel solution - the Progressive Prompt Decision Transformer (P2DT). This method enhances a transformer-based model by dynamically appending decision tokens during new task training, thus fostering task-specific policies. Our approach mitigates forgetting in continual and offline reinforcement learning scenarios. Moreover, P2DT leverages trajectories collected via traditional reinforcement learning from all tasks and generates new task-specific tokens during training, thereby retaining knowledge from previous studies. Preliminary results demonstrate that our model effectively alleviates catastrophic forgetting and scales well with increasing task environments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by the 49th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)"
    },
    {
        "paper id": "2401.11671",
        "abstract url": "https://arxiv.org/abs/2401.11671",
        "title": "RTA-Former: Reverse Transformer Attention for Polyp Segmentation",
        "rating": -1,
        "keywords": [
            [
                "cancer",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Polyp segmentation is a key aspect of colorectal cancer prevention, enabling early detection and guiding subsequent treatments. Intelligent diagnostic tools, including deep learning solutions, are widely explored to streamline and potentially automate this process. However, even with many powerful network architectures, there still comes the problem of producing accurate edge segmentation. In this paper, we introduce a novel network, namely RTA-Former, that employs a transformer model as the encoder backbone and innovatively adapts Reverse Attention (RA) with a transformer stage in the decoder for enhanced edge segmentation. The results of the experiments illustrate that RTA-Former achieves state-of-the-art (SOTA) performance in five polyp segmentation datasets. The strong capability of RTA-Former holds promise in improving the accuracy of Transformer-based polyp segmentation, potentially leading to better clinical decisions and patient outcomes. Our code will be publicly available on GitHub.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11681",
        "abstract url": "https://arxiv.org/abs/2401.11681",
        "title": "Functional Eigen-Grasping Using Approach Heatmaps",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This work presents a framework for a robot with a multi-fingered hand to freely utilize daily tools, including functional parts like buttons and triggers. An approach heatmap is generated by selecting a functional finger, indicating optimal palm positions on the object's surface that enable the functional finger to contact the tool's functional part. Once the palm position is identified through the heatmap, achieving the functional grasp becomes a straightforward process where the fingers stably grasp the object with low-dimensional inputs using the eigengrasp. As our approach does not need human demonstrations, it can easily adapt to various sizes and designs, extending its applicability to different objects. In our approach, we use directional manipulability to obtain the approach heatmap. In addition, we add two kinds of energy functions, i.e., palm energy and functional energy functions, to realize the eigengrasp. Using this method, each robotic gripper can autonomously identify its optimal workspace for functional grasping, extending its applicability to non-anthropomorphic robotic hands. We show that several daily tools like spray, drill, and remotes can be efficiently used by not only an anthropomorphic Shadow hand but also a non-anthropomorphic Barrett hand.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2401.12261",
        "abstract url": "https://arxiv.org/abs/2401.12261",
        "title": "Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks",
        "rating": -1,
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "As AI models rapidly evolve, they are frequently released to open repositories, such as HuggingFace. It is essential to perform quality assurance validation on these models before integrating them into the production development lifecycle. In addition to evaluating efficiency in terms of balanced accuracy and computing costs, adversarial attacks are potential threats to the robustness and explainability of AI models. Meanwhile, XAI applies algorithms that approximate inputs to outputs post-hoc to identify the contributing features. Adversarial perturbations may also degrade the utility of XAI explanations that require further investigation. In this paper, we present an integrated process designed for downstream evaluation tasks, including validating AI model accuracy, evaluating robustness with benchmark perturbations, comparing explanation utility, and assessing overhead. We demonstrate an evaluation scenario involving six computer vision models, which include CNN-based, Transformer-based, and hybrid architectures, three types of perturbations, and five XAI methods, resulting in ninety unique combinations. The process reveals the explanation utility among the XAI methods in terms of the identified key areas responding to the adversarial perturbation. The process produces aggregated results that illustrate multiple attributes of each AI model.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11563",
        "abstract url": "https://arxiv.org/abs/2401.11563",
        "title": "Distributed Multi-Task Learning for Stochastic Bandits with Context Distribution and Stage-wise Constraints",
        "rating": -1.5,
        "keywords": [
            [
                "forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present the problem of conservative distributed multi-task learning in stochastic linear contextual bandits with heterogeneous agents. This extends conservative linear bandits to a distributed setting where M agents tackle different but related tasks while adhering to stage-wise performance constraints. The exact context is unknown, and only a context distribution is available to the agents as in many practical applications that involve a prediction mechanism to infer context, such as stock market prediction and weather forecast. We propose a distributed upper confidence bound (UCB) algorithm, DiSC-UCB. Our algorithm constructs a pruned action set during each round to ensure the constraints are met. Additionally, it includes synchronized sharing of estimates among agents via a central server using well-structured synchronization steps. We prove the regret and communication bounds on the algorithm. We extend the problem to a setting where the agents are unaware of the baseline reward. For this setting, we provide a modified algorithm, DiSC-UCB2, and we show that the modified algorithm achieves the same regret and communication bounds. We empirically validated the performance of our algorithm on synthetic data and real-world Movielens-100K data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11611",
        "abstract url": "https://arxiv.org/abs/2401.11611",
        "title": "Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks",
        "rating": -1.5,
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reliably reconstructing physical fields from sparse sensor data is a challenge that frequently arises in many scientific domains. In practice, the process generating the data often is not understood to sufficient accuracy. Therefore, there is a growing interest in using the deep neural network route to address the problem. This work presents a novel approach that learns a continuous representation of the physical field using implicit neural representations (INRs). Specifically, after factorizing spatiotemporal variability into spatial and temporal components using the separation of variables technique, the method learns relevant basis functions from sparsely sampled irregular data points to develop a continuous representation of the data. In experimental evaluations, the proposed model outperforms recent INR methods, offering superior reconstruction quality on simulation data from a state-of-the-art climate model and a second dataset that comprises ultra-high resolution satellite-based sea surface temperature fields.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "25 pages,21 figures"
    },
    {
        "paper id": "2401.11648",
        "abstract url": "https://arxiv.org/abs/2401.11648",
        "title": "Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation",
        "rating": -1.5,
        "keywords": [
            [
                "Medical",
                "Health",
                "healthcare",
                "Diagnosis",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical codes representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to EACL 2024 (The 18th Conference of the European Chapter of the Association for Computational Linguistics)"
    },
    {
        "paper id": "2401.11669",
        "abstract url": "https://arxiv.org/abs/2401.11669",
        "title": "An Improved Grey Wolf Optimization Algorithm for Heart Disease Prediction",
        "rating": -1.5,
        "keywords": [
            [
                "medical",
                "Disease",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a unique solution to challenges in medical image processing by incorporating an adaptive curve grey wolf optimization (ACGWO) algorithm into neural network backpropagation. Neural networks show potential in medical data but suffer from issues like overfitting and lack of interpretability due to imbalanced and scarce data. Traditional Gray Wolf Optimization (GWO) also has its drawbacks, such as a lack of population diversity and premature convergence. This paper addresses these problems by introducing an adaptive algorithm, enhancing the standard GWO with a sigmoid function. This algorithm was extensively compared to four leading algorithms using six well-known test functions, outperforming them effectively. Moreover, by utilizing the ACGWO, we increase the robustness and generalization of the neural network, resulting in more interpretable predictions. Applied to the publicly accessible Cleveland Heart Disease dataset, our technique surpasses ten other methods, achieving 86.8% accuracy, indicating its potential for efficient heart disease prediction in the clinical setting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11674",
        "abstract url": "https://arxiv.org/abs/2401.11674",
        "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
        "rating": -1.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cancer"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Recent studies have made remarkable progress in histopathology classification. Based on current successes, contemporary works proposed to further upgrade the model towards a more generalizable and robust direction through incrementally learning from the sequentially delivered domains. Unlike previous parameter isolation based approaches that usually demand massive computation resources during model updating, we present a memory-efficient prompt tuning framework to cultivate model generalization potential in economical memory cost. For each incoming domain, we reuse the existing parameters of the initial classification model and attach lightweight trainable prompts into it for customized tuning. Considering the domain heterogeneity, we perform decoupled prompt tuning, where we adopt a domain-specific prompt for each domain to independently investigate its distinctive characteristics, and one domain-invariant prompt shared across all domains to continually explore the common content embedding throughout time. All domain-specific prompts will be appended to the prompt bank and isolated from further changes to prevent forgetting the distinctive features of early-seen domains. While the domain-invariant prompt will be passed on and iteratively evolve by style-augmented prompt refining to improve model generalization capability over time. In specific, we construct a graph with existing prompts and build a style-augmented graph attention network to guide the domain-invariant prompt exploring the overlapped latent embedding among all delivered domains for more domain generic representations. We have extensively evaluated our framework with two histopathology tasks, i.e., breast cancer metastasis classification and epithelium-stroma tissue classification, where our approach yielded superior performance and memory efficiency over the competing methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.11408",
        "abstract url": "https://arxiv.org/abs/2401.11408",
        "title": "SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction Tasks Oriented to the Finance Field",
        "rating": -2,
        "keywords": [
            [
                "graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Event extraction lies at the cores of investment analysis and asset management in the financial field, and thus has received much attention. The 2019 China conference on knowledge graph and semantic computing (CCKS) challenge sets up a evaluation competition for event entity extraction task oriented to the finance field. In this task, we mainly focus on how to extract the event entity accurately, and recall all the corresponding event entity effectively. In this paper, we propose a novel model, Sequence Enhanced BERT Networks (SEBERTNets for short), which can inherit the advantages of the BERT,and while capturing sequence semantic information. In addition, motivated by recommendation system, we propose Hybrid Sequence Enhanced BERT Networks (HSEBERTNets for short), which uses a multi-channel recall method to recall all the corresponding event entity. The experimental results show that, the F1 score of SEBERTNets is 0.905 in the first stage, and the F1 score of HSEBERTNets is 0.934 in the first stage, which demonstarate the effectiveness of our methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "CCKS 2019"
    },
    {
        "paper id": "2401.11419",
        "abstract url": "https://arxiv.org/abs/2401.11419",
        "title": "Joint UAV Deployment and Resource Allocation in THz-Assisted MEC-Enabled Integrated Space-Air-Ground Networks",
        "rating": -2,
        "keywords": [
            [
                "UAV"
            ]
        ],
        "abstract": "Multi-access edge computing (MEC)-enabled integrated space-air-ground (SAG) networks have drawn much attention recently, as they can provide communication and computing services to wireless devices in areas that lack terrestrial base stations (TBSs). Leveraging the ample bandwidth in the terahertz (THz) spectrum, in this paper, we propose MEC-enabled integrated SAG networks with collaboration among unmanned aerial vehicles (UAVs). We then formulate the problem of minimizing the energy consumption of devices and UAVs in the proposed MEC-enabled integrated SAG networks by optimizing tasks offloading decisions, THz sub-bands assignment, transmit power control, and UAVs deployment. The formulated problem is a mixed-integer nonlinear programming (MILP) problem with a non-convex structure, which is challenging to solve. We thus propose a block coordinate descent (BCD) approach to decompose the problem into four sub-problems: 1) device task offloading decision problem, 2) THz sub-band assignment and power control problem, 3) UAV deployment problem, and 4) UAV task offloading decision problem. We then propose to use a matching game, concave-convex procedure (CCP) method, successive convex approximation (SCA), and block successive upper-bound minimization (BSUM) approaches for solving the individual subproblems. Finally, extensive simulations are performed to demonstrate the effectiveness of our proposed algorithm.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "36 pages, 8 figures"
    },
    {
        "paper id": "2401.11425",
        "abstract url": "https://arxiv.org/abs/2401.11425",
        "title": "Grayscale Image Colorization with GAN and CycleGAN in Different Image Domain",
        "rating": -2,
        "keywords": [
            [
                "GAN"
            ],
            [
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic colorization of grayscale image has been a challenging task. Previous research have applied supervised methods in conquering this problem [ 1]. In this paper, we reproduces a GAN-based coloring model, and experiments one of its variant. We also proposed a CycleGAN based model and experiments those methods on various datasets. The result shows that the proposed CycleGAN model does well in human-face coloring and comic coloring, but lack the ability to diverse colorization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11432",
        "abstract url": "https://arxiv.org/abs/2401.11432",
        "title": "Bimanual Deformable Bag Manipulation Using a Structure-of-Interest Based Latent Dynamics Model",
        "rating": -2,
        "keywords": [
            [
                "point cloud"
            ],
            [
                "GNN",
                "Graph"
            ]
        ],
        "abstract": "The manipulation of deformable objects by robotic systems presents a significant challenge due to their complex and infinite-dimensional configuration spaces. This paper introduces a novel approach to Deformable Object Manipulation (DOM) by emphasizing the identification and manipulation of Structures of Interest (SOIs) in deformable fabric bags. We propose a bimanual manipulation framework that leverages a Graph Neural Network (GNN)-based latent dynamics model to succinctly represent and predict the behavior of these SOIs. Our approach involves constructing a graph representation from partial point cloud data of the object and learning the latent dynamics model that effectively captures the essential deformations of the fabric bag within a reduced computational space. By integrating this latent dynamics model with Model Predictive Control (MPC), we empower robotic manipulators to perform precise and stable manipulation tasks focused on the SOIs. We have validated our framework through various empirical experiments demonstrating its efficacy in bimanual manipulation of fabric bags. Our contributions not only address the complexities inherent in DOM but also provide new perspectives and methodologies for enhancing robotic interactions with deformable objects by concentrating on their critical structural elements. Experimental videos can be obtained from https://sites.google.com/view/bagbot.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11435",
        "abstract url": "https://arxiv.org/abs/2401.11435",
        "title": "IoT Cloud RAN Testbed for Ultra-Precise TDoA-based Localization in LPWANs",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "There have been many research efforts in the area of localization in recent years. Especially within the Internet of Things (IoT), the knowledge of position information for individual components is of great interest, for example, in asset tracking, to name just one. However, many of these use cases require a high energy efficiency, making a GNSS-based approach infeasible. One promising candidate can be found in Low Power Wide Area Networks (LPWAN), which enable battery lifetimes of up to 20 years. However, no gold standard for localization exists for these types of networks. Our work proposes a testbed architecture that allows the investigation and development of localization algorithms within LPWA Networks. The concept is built on a Cloud Radio Access Network (CRAN) architecture that allows the streaming of IQ from remote base stations to a central processing unit. Furthermore, the architecture is expanded by a synchronization concept based on Signals of Opportunity (SoO) to enable the testbed for runtime-based positioning. Therefore, we propose a hardware concept consisting of antennas and a low-cost off-the-shelf software-defined radio (SDR)-based frontend architecture and a software framework using a hypertext transfer protocol (HTTP)-based server and client architecture. The proposed system is installed in an urban environment. Initial measurements are conducted, where it can be shown that the proposed architecture can be used for highly precise Time Difference of Arrival (TDoA) measurements, offering the possibility of time synchronization down to approximately 200 ps and frequency synchronization of 3 mHz.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11441",
        "abstract url": "https://arxiv.org/abs/2401.11441",
        "title": "On-Device Recommender Systems: A Comprehensive Survey",
        "rating": -2,
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Recommender systems have been widely deployed in various real-world applications to help users identify content of interest from massive amounts of information. Traditional recommender systems work by collecting user-item interaction data in a cloud-based data center and training a centralized model to perform the recommendation service. However, such cloud-based recommender systems (CloudRSs) inevitably suffer from excessive resource consumption, response latency, as well as privacy and security risks concerning both data and models. Recently, driven by the advances in storage, communication, and computation capabilities of edge devices, there has been a shift of focus from CloudRSs to on-device recommender systems (DeviceRSs), which leverage the capabilities of edge devices to minimize centralized data storage requirements, reduce the response latency caused by communication overheads, and enhance user privacy and security by localizing data processing and model training. Despite the rapid rise of DeviceRSs, there is a clear absence of timely literature reviews that systematically introduce, categorize and contrast these methods. To bridge this gap, we aim to provide a comprehensive survey of DeviceRSs, covering three main aspects: (1) the deployment and inference of DeviceRSs (2) the training and update of DeviceRSs (3) the security and privacy of DeviceRSs. Furthermore, we provide a fine-grained and systematic taxonomy of the methods involved in each aspect, followed by a discussion regarding challenges and future research directions. This is the first comprehensive survey on DeviceRSs that covers a spectrum of tasks to fit various needs. We believe this survey will help readers effectively grasp the current research status in this field, equip them with relevant technical foundations, and stimulate new research ideas for developing DeviceRSs.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11449",
        "abstract url": "https://arxiv.org/abs/2401.11449",
        "title": "Energy Consumption Analysis for Continuous Phase Modulation in Smart-Grid Internet of Things of beyond 5G",
        "rating": -2,
        "keywords": [
            [
                "5G",
                "6G",
                "IoT"
            ]
        ],
        "abstract": "Wireless sensor network (WSN) underpinning the smart-grid Internet of Things (SG-IoT) has been a popular research topic in recent years due to its great potential for enabling a wide range of important applications. However, the energy consumption (EC) characteristic of sensor nodes is a key factor that affects the operational performance (e.g., lifetime of sensors) and the total cost of ownership of WSNs. In this paper, to find the modulation techniques suitable for WSNs, we investigate the EC characteristic of continuous phase modulation (CPM), which is an attractive modulation scheme candidate for WSNs because of its constant envelope property. We first develop an EC model for the sensor nodes of WSNs by considering the circuits and a typical communication protocol that relies on automatic repeat request (ARQ)-based retransmissions to ensure successful data delivery. Then, we use this model to analyze the EC characteristic of CPM under various configurations of modulation parameters. Furthermore, we compare the EC characteristic of CPM with that of other representative modulation schemes, such as offset quadrature phase-shift keying (OQPSK) and quadrature amplitude modulation (QAM), which are commonly used in communication protocols of WSNs. Our analysis and simulation results provide insights into the EC characteristics of multiple modulation schemes in the context of WSNs; thus, they are beneficial for designing energy-efficient SG-IoT in the beyond-5G (B5G) and the 6G era.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "7 figures, 2 tables"
    },
    {
        "paper id": "2401.11452",
        "abstract url": "https://arxiv.org/abs/2401.11452",
        "title": "Towards Reliable and Factual Response Generation: Detecting Unanswerable Questions in Information-Seeking Conversations",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "Generative AI models face the challenge of hallucinations that can undermine users' trust in such systems. We approach the problem of conversational information seeking as a two-step process, where relevant passages in a corpus are identified first and then summarized into a final system response. This way we can automatically assess if the answer to the user's question is present in the corpus. Specifically, our proposed method employs a sentence-level classifier to detect if the answer is present, then aggregates these predictions on the passage level, and eventually across the top-ranked passages to arrive at a final answerability estimate. For training and evaluation, we develop a dataset based on the TREC CAsT benchmark that includes answerability labels on the sentence, passage, and ranking levels. We demonstrate that our proposed method represents a strong baseline and outperforms a state-of-the-art LLM on the answerability prediction task.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "This is the author's version of the work. The definitive version is published in: Proceedings of the 46th European Conference on Information Retrieval} (ECIR '24), March 24--28, 2024, Glasgow, Scotland"
    },
    {
        "paper id": "2401.11455",
        "abstract url": "https://arxiv.org/abs/2401.11455",
        "title": "Study on the Particle Sorting Performance for Reactor Monte Carlo Neutron Transport on Apple Unified Memory GPUs",
        "rating": -2,
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "In simulation of nuclear reactor physics using the Monte Carlo neutron transport method on GPUs, the sorting of particles plays a significant role in performance of calculation. Traditionally, CPUs and GPUs are separated devices connected at low data transfer rate and high data transfer latency. Emerging computing chips tend to integrate CPUs and GPUs. One example is the Apple silicon chips with unified memory. Such unified memory chips have opened doors for new strategies of collaboration between CPUs and GPUs for Monte Carlo neutron transport. Sorting particle on CPU and transport on GPU is an example of such new strategy, which has been suffering the high CPU-GPU data transfer latency on the traditional devices with separated CPU and GPU. The finding is that for the Apple M2 max chip, sorting on CPU leads to better performance per power than sorting on GPU for the ExaSMR whole core benchmark problems and the HTR-10 high temperature gas reactor fuel pebble problem. The partially sorted particle order has been identified to contribute to the higher performance with CPU sort than GPU. The in-house code using both CPU and GPU achieves 7.5 times power efficiency that of OpenMC on CPU for ExaSMR whole core benchmark with depleted fuel, and 150 times for HTR-10 fuel pebble benchmark with depleted fuel.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11478",
        "abstract url": "https://arxiv.org/abs/2401.11478",
        "title": "D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems",
        "rating": -2,
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "A vast amount of user behavior data is constantly accumulating on today's large recommendation platforms, recording users' various interests and tastes. Preserving knowledge from the old data while new data continually arrives is a vital problem for recommender systems. Existing approaches generally seek to save the knowledge implicitly in the model parameters. However, such a parameter-centric approach lacks scalability and flexibility -- the capacity is hard to scale, and the knowledge is inflexible to utilize. Hence, in this work, we propose a framework that turns massive user behavior data to retrievable knowledge (D2K). It is a data-centric approach that is model-agnostic and easy to scale up. Different from only storing unary knowledge such as the user-side or item-side information, D2K propose to store ternary knowledge for recommendation, which is determined by the complete recommendation factors -- user, item, and context. The knowledge retrieved by target samples can be directly used to enhance the performance of any recommendation algorithms. Specifically, we introduce a Transformer-based knowledge encoder to transform the old data into knowledge with the user-item-context cross features. A personalized knowledge adaptation unit is devised to effectively exploit the information from the knowledge base by adapting the retrieved knowledge to the target samples. Extensive experiments on two public datasets show that D2K significantly outperforms existing baselines and is compatible with a major collection of recommendation algorithms.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2401.11488",
        "abstract url": "https://arxiv.org/abs/2401.11488",
        "title": "HARDCORE: H-field and power loss estimation for arbitrary waveforms with residual, dilated convolutional neural networks in ferrite cores",
        "rating": -2,
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "The MagNet Challenge 2023 calls upon competitors to develop data-driven models for the material-specific, waveform-agnostic estimation of steady-state power losses in toroidal ferrite cores. The following HARDCORE (H-field and power loss estimation for Arbitrary waveforms with Residual, Dilated convolutional neural networks in ferrite COREs) approach shows that a residual convolutional neural network with physics-informed extensions can serve this task efficiently when trained on observational data beforehand. One key solution element is an intermediate model layer which first reconstructs the bh curve and then estimates the power losses based on the curve's area rendering the proposed topology physically interpretable. In addition, emphasis was placed on expert-based feature engineering and information-rich inputs in order to enable a lean model architecture. A model is trained from scratch for each material, while the topology remains the same. A Pareto-style trade-off between model size and estimation accuracy is demonstrated, which yields an optimum at as low as 1755 parameters and down to below 8\\,\\% for the 95-th percentile of the relative error for the worst-case material with sufficient samples.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Competition submission version, slightly change author order"
    },
    {
        "paper id": "2401.11490",
        "abstract url": "https://arxiv.org/abs/2401.11490",
        "title": "Reliable Low-Delay Routing In Space with Routing-Oblivious LEO Satellites",
        "rating": -2,
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "Large networks of Low Earth Orbit (LEO) satellites are being built using inter-satellite lasers. These networks promise to offer low-latency wide-area connectivity, but reliably routing such traffic is difficult, as satellites are very resource-constrained and paths change constantly. We present STARGLIDER, a new routing system where path computation is delegated to ground stations, while satellites are routing-oblivious and exchange no information at runtime. Yet, STARGLIDER satellites effectively support reliability primitives: they fast reroute packets over near-optimal paths when links fail, and validate that packets sent by potentially malicious ground stations follow reasonable paths.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11506",
        "abstract url": "https://arxiv.org/abs/2401.11506",
        "title": "Enhancing Recommendation Diversity by Re-ranking with Large Language Models",
        "rating": -2,
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "It has long been recognized that it is not enough for a Recommender System (RS) to provide recommendations based only on their relevance to users. Among many other criteria, the set of recommendations may need to be diverse in order to handle uncertainty and offer a meaningful choice. The literature reports many ways of measuring diversity and ways of improving the diversity of a set of recommendations, most notably by re-ranking and selecting from a larger set of candidate recommendations. Driven by promising insights from the literature on how to incorporate versatile Large Language Models (LLMs) into the RS pipeline, in this paper, we show how LLMs can be used for diversity re-ranking. We begin with an informal study that verifies that LLMs can be used for re-ranking tasks and do have some understanding of the concept of diversity. Then, we design a more rigorous methodology where LLMs are prompted to generate a diverse ranking from a candidate ranking using various prompt templates with different re-ranking instructions in a zero-shot fashion. We conduct comprehensive experiments testing state-of-the-art conversational LLMs from the GPT and Llama families. We compare their re-ranking capabilities with random re-ranking and various traditional re-ranking methods from the literature (MMR, xQuAD and RxQuAD). We find that LLM-based re-ranking outperforms random re-ranking across all the metrics that we use but does not perform as well as the traditional re-ranking methods. We gain insight into prompt design for this task (e.g.\\ on the whole, it is better to prompt for diversity rather than a balance of diversity and relevance). Given that no special knowledge engineering is needed, we conclude that LLM-based re-ranking is a promising approach, and we highlight directions for future research. We open-source the code of our experiments for reproducibility.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "32 pages, 2 figures"
    },
    {
        "paper id": "2401.11533",
        "abstract url": "https://arxiv.org/abs/2401.11533",
        "title": "Pulse Width Modulation Method Applied to Nonlinear Model Predictive Control on an Under-actuated Small Satellite",
        "rating": -2,
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "Among various satellite actuators, magnetic torquers have been widely equipped for stabilization and attitude control of small satellites. Although magnetorquers are generally used with other actuators, such as momentum wheels, this paper explores a control method where only a magnetic actuation is available. We applied a nonlinear optimal control method, Nonlinear Model Predictive Control (NMPC), to small satellites, employing the generalized minimal residual (GMRES) method, which generates continuous control inputs. Onboard magnetic actuation systems often find it challenging to produce smooth magnetic moments as a control input; hence, we employ the Pulse Width Modulation (PWM) method, which discretizes a control input and reduces the burden on actuators. In our case, the PWM approach discretizes control torques generated by the NMPC scheme. This study's main contributions are investigating the NMPC and the GMRES method applied to small spacecraft and presenting the PWM control system's feasibility.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "19 pages, 10 figures. In AIAA Scitech 2021 Forum"
    },
    {
        "paper id": "2401.11535",
        "abstract url": "https://arxiv.org/abs/2401.11535",
        "title": "EndoGS: Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting",
        "rating": -2,
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth",
                "radiance fields"
            ],
            [
                "Surgical",
                "surgery",
                "Endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Surgical 3D reconstruction is a critical area of research in robotic surgery, with recent works adopting variants of dynamic radiance fields to achieve success in 3D reconstruction of deformable tissues from single-viewpoint videos. However, these methods often suffer from time-consuming optimization or inferior quality, limiting their adoption in downstream tasks. Inspired by 3D Gaussian Splatting, a recent trending 3D representation, we present EndoGS, applying Gaussian Splatting for deformable endoscopic tissue reconstruction. Specifically, our approach incorporates deformation fields to handle dynamic scenes, depth-guided supervision with spatial-temporal weight masks to optimize 3D targets with tool occlusion from a single viewpoint, and surface-aligned regularization terms to capture the much better geometry. As a result, EndoGS reconstructs and renders high-quality deformable endoscopic tissues from a single-viewpoint video, estimated depth maps, and labeled tool masks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGS achieves superior rendering quality. Code is available at https://github.com/HKU-MedAI/EndoGS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2401.11536",
        "abstract url": "https://arxiv.org/abs/2401.11536",
        "title": "Nonlinear Model Predictive Detumbling of Small Satellites with a Single-axis Magnetorquer",
        "rating": -2,
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "Various actuators are used in spacecraft to achieve attitude stabilization, including thrusters, momentum wheels, and control moment gyros. Small satellites, however, have stringent size, weight, and cost constraints, which makes many actuator choices prohibitive. Consequently, magnetic torquers have commonly been applied to spacecraft to attenuate angular rates. Approaches for dealing with under-actuation due to magnetic control torque's dependency on the magnetic field and required high magnetic flux densities have been previously considered. Generally speaking, control of a satellite that becomes under-actuated as a result of on-board failures has been a recurrent theme in the literature. Methods for controlling spacecraft with fewer actuators than degrees of freedom are increasingly in demand due to the increased number of small satellite launches. Magnetic torquers have been extensively investigated for momentum management of spacecraft with momentum wheels and for nutation damping of spin satellites, momentum-biased, and dual-spin satellites. Nonetheless, severely under-actuated small spacecraft that carry only a single-axis magnetic torquer have not been previously treated. This note considers the detumbling of a small spacecraft using only a single-axis magnetic torquer. Even with a three-axis magnetic torquer, the spacecraft is under-actuated, while, in the case of only a single axis magnetic torquer, the problem is considerably more demanding. Our note examines the feasibility of spacecraft attitude control with a single-axis magnetic torquer and possible control methods that can be used.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "20 pages, 6 figures. Journal of Guidance, Control, and Dynamics (2021)"
    },
    {
        "paper id": "2401.11538",
        "abstract url": "https://arxiv.org/abs/2401.11538",
        "title": "Maintenance cost assessment for heterogeneous multi-component systems incorporating perfect inspections and waiting time to maintenance",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Most existing research about complex systems maintenance assumes they consist of the same type of components. However, systems can be assembled with heterogeneous components (for example degrading and non-degrading components) that require different maintenance actions. Since industrial systems become more and more complex, more research about the maintenance of systems with heterogeneous components is needed. For this reason, in this paper, a system consisting of two groups of components: degrading and non-degrading components is analyzed. The main novelty of this paper is the evaluation of a maintenance policy at system-level coordinating condition-based maintenance for the degrading components, delay time to the maintenance and an inspection strategy for this heterogeneous system. To that end, an analytic cost model is built using the semi-regenerative processes theory. Furthermore, a safety constraint related to the reliability of the degrading components is imposed. To find the optimal maintenance strategy, meta-heuristic algorithms are used.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "27 pages, 4 figures"
    },
    {
        "paper id": "2401.11539",
        "abstract url": "https://arxiv.org/abs/2401.11539",
        "title": "Model Predictive Approach for Detumbling an Underactuated Satellite",
        "rating": -2,
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "This research proposes an innovative approach to detumble satellites' triple-axis angular velocities with only one single-axis magnetic torquer. Since magnetic torque is generated perpendicularly to magnetorquers, no intended control torque along the magnetorquer can be produced, which makes systems underactuated. Our paper introduces a control method using Model Predictive Control (MPC) and compares it with B-dot control algorithm. By applying these control laws to Kyushu University Light Curve Inversion (Q-Li) Demonstration Satellite in numerical simulations, we describe the applicability of these control laws to underactuated systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "15 pages, 4 figures"
    },
    {
        "paper id": "2401.11542",
        "abstract url": "https://arxiv.org/abs/2401.11542",
        "title": "Nigel -- Mechatronic Design and Robust Sim2Real Control of an Over-Actuated Autonomous Vehicle",
        "rating": -2,
        "keywords": [
            [
                "synthesis"
            ],
            [
                "Vehicle"
            ]
        ],
        "abstract": "Simulation to reality (sim2real) transfer from a dynamics and controls perspective usually involves re-tuning or adapting the designed algorithms to suit real-world operating conditions, which often violates the performance guarantees established originally. This work presents a generalizable framework for achieving reliable sim2real transfer of autonomy-oriented control systems using multi-model multi-objective robust optimal control synthesis, which lends well to uncertainty handling and disturbance rejection with theoretical guarantees. Particularly, this work is centered around a novel actuation-redundant scaled autonomous vehicle called Nigel, with independent all-wheel drive and independent all-wheel steering architecture, whose enhanced configuration space bodes well for robust control applications. To this end, we present the mechatronic design, dynamics modeling, parameter identification, and robust stabilizing as well as tracking control of Nigel using the proposed framework, with exhaustive experimentation and benchmarking in simulation as well as real-world settings.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11555",
        "abstract url": "https://arxiv.org/abs/2401.11555",
        "title": "VQC-Based Reinforcement Learning with Data Re-uploading: Performance and Trainability",
        "rating": -2,
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) consists of designing agents that make intelligent decisions without human supervision. When used alongside function approximators such as Neural Networks (NNs), RL is capable of solving extremely complex problems. Deep Q-Learning, a RL algorithm that uses Deep NNs, achieved super-human performance in some specific tasks. Nonetheless, it is also possible to use Variational Quantum Circuits (VQCs) as function approximators in RL algorithms. This work empirically studies the performance and trainability of such VQC-based Deep Q-Learning models in classic control benchmark environments. More specifically, we research how data re-uploading affects both these metrics. We show that the magnitude and the variance of the gradients of these models remain substantial throughout training due to the moving targets of Deep Q-Learning. Moreover, we empirically show that increasing the number of qubits does not lead to an exponential vanishing behavior of the magnitude and variance of the gradients for a PQC approximating a 2-design, unlike what was expected due to the Barren Plateau Phenomenon. This hints at the possibility of VQCs being specially adequate for being used as function approximators in such a context.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "21 pages, 8 figures"
    },
    {
        "paper id": "2401.11567",
        "abstract url": "https://arxiv.org/abs/2401.11567",
        "title": "Deterministic Multi-stage Constellation Reconfiguration Using Integer Linear Programing and Sequential Decision-Making Methods",
        "rating": -2,
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "In this paper, we address the problem of reconfiguring Earth observation satellite constellation systems through multiple stages. The Multi-stage Constellation Reconfiguration Problem (MCRP) aims to maximize the total observation rewards obtained by covering a set of targets of interest through the active manipulation of the orbits and relative phasing of constituent satellites. In this paper, we consider deterministic problem settings in which the targets of interest are known a priori. We propose a novel integer linear programming formulation for MCRP, capable of obtaining provably optimal solutions. To overcome computational intractability due to the combinatorial explosion in solving large-scale instances, we introduce two computationally efficient sequential decision-making methods based on the principles of a myopic policy and a rolling horizon procedure. The computational experiments demonstrate that the devised sequential decision-making approaches yield high-quality solutions with improved computational efficiency over the baseline MCRP. Finally, a case study using Hurricane Harvey data showcases the advantages of multi-stage constellation reconfiguration over single-stage and no-reconfiguration scenarios.",
        "subjects": [
            "math.OC"
        ],
        "comment": "37 pages, 13 figures, submitted to the Journal of Spacecraft and Rockets"
    },
    {
        "paper id": "2401.11598",
        "abstract url": "https://arxiv.org/abs/2401.11598",
        "title": "TetraLoss: Improving the Robustness of Face Recognition against Morphing Attacks",
        "rating": -2,
        "keywords": [
            [
                "Attacks"
            ],
            [
                "biometric",
                "Face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Face recognition systems are widely deployed in high-security applications such as for biometric verification at border controls. Despite their high accuracy on pristine data, it is well-known that digital manipulations, such as face morphing, pose a security threat to face recognition systems. Malicious actors can exploit the facilities offered by the identity document issuance process to obtain identity documents containing morphed images. Thus, subjects who contributed to the creation of the morphed image can with high probability use the identity document to bypass automated face recognition systems. In recent years, no-reference (i.e., single image) and differential morphing attack detectors have been proposed to tackle this risk. These systems are typically evaluated in isolation from the face recognition system that they have to operate jointly with and do not consider the face recognition process. Contrary to most existing works, we present a novel method for adapting deep learning-based face recognition systems to be more robust against face morphing attacks. To this end, we introduce TetraLoss, a novel loss function that learns to separate morphed face images from its contributing subjects in the embedding space while still preserving high biometric verification performance. In a comprehensive evaluation, we show that the proposed method can significantly enhance the original system while also significantly outperforming other tested baseline methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to the IEEE International Conference on Automatic Face & Gesture Recognition 2024 (FG'24)"
    },
    {
        "paper id": "2401.11620",
        "abstract url": "https://arxiv.org/abs/2401.11620",
        "title": "Real-Time Systems Optimization with Black-box Constraints and Hybrid Variables",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "When optimizing real-time systems, designers often face a challenging problem where the schedulability constraints are non-convex, non-continuous, or lack an analytical form to understand their properties. Although the optimization framework NORTH proposed in previous work is general (it works with arbitrary schedulability analysis) and scalable, it can only handle problems with continuous variables, which limits its application. In this paper, we extend the applications of the framework NORTH to problems with a hybrid of continuous and discrete variables. This is achieved in a coordinate-descent method, where the continuous and discrete variables are optimized separately during iterations. The new framework, NORTH+, improves around 20% solution quality than NORTH in experiments.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Workshop on OPtimization for Embedded and ReAl-time systems (OPERA 2023) co-located with the 44th IEEE Real-Time Systems Symposium (RTSS)"
    },
    {
        "paper id": "2401.11632",
        "abstract url": "https://arxiv.org/abs/2401.11632",
        "title": "What Are We Optimizing For? A Human-centric Evaluation Of Deep Learning-based Recommender Systems",
        "rating": -2,
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Deep learning-based (DL) models in recommender systems (RecSys) have gained significant recognition for their remarkable accuracy in predicting user preferences. However, their performance often lacks a comprehensive evaluation from a human-centric perspective, which encompasses various dimensions beyond simple interest matching. In this work, we have developed a robust human-centric evaluation framework that incorporates seven diverse metrics to assess the quality of recommendations generated by five recent open-sourced DL models. Our evaluation datasets consist of both offline benchmark data and personalized online recommendation feedback collected from 445 real users. We find that (1) different DL models have different pros and cons in the multi-dimensional metrics that we test with; (2) users generally want a combination of accuracy with at least one another human values in the recommendation; (3) the degree of combination of different values needs to be carefully experimented to user preferred level.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11634",
        "abstract url": "https://arxiv.org/abs/2401.11634",
        "title": "MR.CAP: Multi-Robot Joint Control and Planning for Object Transport",
        "rating": -2,
        "keywords": [
            [
                "Robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "With the recent influx in demand for multi-robot systems throughout industry and academia, there is an increasing need for faster, robust, and generalizable path planning algorithms. Similarly, given the inherent connection between control algorithms and multi-robot path planners, there is in turn an increased demand for fast, efficient, and robust controllers. We propose a scalable joint path planning and control algorithm for multi-robot systems with constrained behaviours based on factor graph optimization. We demonstrate our algorithm on a series of hardware and simulated experiments. Our algorithm is consistently able to recover from disturbances and avoid obstacles while outperforming state-of-the-art methods in optimization time, path deviation, and inter-robot errors. See the code and supplementary video for experiments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "H. A. Jaafar, C. -H. Kao and S. Saeedi, \"MR.CAP: Multi-Robot Joint Control and Planning for Object Transport,\" in IEEE Control Systems Letters, doi: 10.1109/LCSYS.2024.3349989"
    },
    {
        "paper id": "2401.11656",
        "abstract url": "https://arxiv.org/abs/2401.11656",
        "title": "Agent-Based Modeling of C. Difficile Spread in Hospitals: Assessing Contribution of High-Touch vs. Low-Touch Surfaces and Inoculations' Containment Impact",
        "rating": -2,
        "keywords": [
            [
                "Health",
                "healthcare"
            ]
        ],
        "abstract": "Health issues and pandemics remain paramount concerns in the contemporary era. Clostridioides Difficile Infection (CDI) stands out as a critical healthcare-associated infection with global implications. Effectively understanding the mechanisms of infection dissemination within healthcare units and hospitals is imperative to implement targeted containment measures. In this study, we address the limitations of prior research by Sulyok et al., where they delineated two distinct categories of surfaces as high-touch and low-touch fomites, and subsequently evaluated the viral spread contribution of each surface utilizing mathematical modeling and Ordinary Differential Equations (ODE). Acknowledging the indispensable role of spatial features and heterogeneity in the modeling of hospital and healthcare settings, we employ agent-based modeling to capture new insights. By incorporating spatial considerations and heterogeneous patients, we explore the impact of high-touch and low-touch surfaces on contamination transmission between patients. Furthermore, the study encompasses a comprehensive assessment of various cleaning protocols, with differing intervals and detergent cleaning efficacies, in order to identify the most optimal cleaning strategy and the most important factor amidst the array of alternatives. Our results indicate that, among various factors, the frequency of cleaning intervals is the most critical element for controlling the spread of CDI in a hospital environment.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "Accepted and presented at the Computational Social Science Society of the Americas Conference (CSS 2023)"
    },
    {
        "paper id": "2401.11685",
        "abstract url": "https://arxiv.org/abs/2401.11685",
        "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture",
        "rating": -2,
        "keywords": [
            [
                "DNA"
            ]
        ],
        "abstract": "DNA sequence alignment is an important workload in computational genomics. Reference-guided DNA assembly involves aligning many read sequences against candidate locations in a long reference genome. To reduce the computational load of this alignment, candidate locations can be pre-filtered using simpler alignment algorithms like edit distance. Prior work has explored accelerating filtering on simulated compute-in-DRAM, due to the massive parallelism of compute-in-memory architectures. In this paper, we present work-in-progress on accelerating filtering using a commercial compute-in-SRAM accelerator. We leverage the recently released Gemini accelerator platform from GSI Technology, which is the first, to our knowledge, commercial-scale compute-in-SRAM system. We accelerate the Myers' bit-parallel edit distance algorithm, producing average speedups of 14.1x over single-core CPU performance. Individual query/candidate alignments produce speedups of up to 24.1x. These early results suggest this novel architecture is well-suited to accelerating the filtering step of sequence-to-sequence DNA alignment.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11687",
        "abstract url": "https://arxiv.org/abs/2401.11687",
        "title": "TIM: An Efficient Temporal Interaction Module for Spiking Transformer",
        "rating": -2,
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs), as the third generation of neural networks, have gained prominence for their biological plausibility and computational efficiency, especially in processing diverse datasets. The integration of attention mechanisms, inspired by advancements in neural network architectures, has led to the development of Spiking Transformers. These have shown promise in enhancing SNNs' capabilities, particularly in the realms of both static and neuromorphic datasets. Despite their progress, a discernible gap exists in these systems, specifically in the Spiking Self Attention (SSA) mechanism's effectiveness in leveraging the temporal processing potential of SNNs. To address this, we introduce the Temporal Interaction Module (TIM), a novel, convolution-based enhancement designed to augment the temporal data processing abilities within SNN architectures. TIM's integration into existing SNN frameworks is seamless and efficient, requiring minimal additional parameters while significantly boosting their temporal information handling capabilities. Through rigorous experimentation, TIM has demonstrated its effectiveness in exploiting temporal information, leading to state-of-the-art performance across various neuromorphic datasets.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "9pages,6figures"
    },
    {
        "paper id": "2401.17317",
        "abstract url": "https://arxiv.org/abs/2401.17317",
        "title": "Detection of Auditory Brainstem Response Peaks Using Image Processing Techniques in Infants with Normal Hearing Sensitivity",
        "rating": -2,
        "keywords": [
            [
                "diagnosing",
                "disease"
            ]
        ],
        "abstract": "Introduction: The auditory brainstem response (ABR) is measured to find the brainstem-level peripheral auditory nerve system integrity in children having normal hearing. The Auditory Evoked Potential (AEP) is generated using acoustic stimuli. Interpreting these waves requires competence to avoid misdiagnosing hearing problems. Automating ABR test labeling with computer vision may reduce human error. Method: The ABR test results of 26 children aged 1 to 20 months with normal hearing in both ears were used. A new approach is suggested for automatically calculating the peaks of waves of different intensities (in decibels). The procedure entails acquiring wave images from an Audera device using the Color Thresholder method, segmenting each wave as a single wave image using the Image Region Analyzer application, converting all wave images into waves using Image Processing (IP) techniques, and finally calculating the latency of the peaks for each wave to be used by an audiologist for diagnosing the disease. Findings: Image processing techniques were able to detect 1, 3, and 5 waves in the diagnosis field with accuracy (0.82), (0.98), and (0.98), respectively, and its precision for waves 1, 3, and 5, were respectively (0.32), (0.97) and (0.87). This evaluation also worked well in the thresholding part and 82.7 % correctly detected the ABR waves. Conclusion: Our findings indicate that the audiology test battery suite can be made more accurate, quick, and error-free by using technology to automatically detect and label ABR waves.",
        "subjects": [
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00044",
        "abstract url": "https://arxiv.org/abs/2402.00044",
        "title": "Training microrobots to swim by a large language model",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Machine learning and artificial intelligence have recently represented a popular paradigm for designing and optimizing robotic systems across various scales. Recent studies have showcased the innovative application of large language models (LLMs) in industrial control [1] and in directing legged walking robots [2]. In this study, we utilize an LLM, GPT-4, to train two prototypical microrobots for swimming in viscous fluids. Adopting a few-shot learning approach, we develop a minimal, unified prompt composed of only five sentences. The same concise prompt successfully guides two distinct articulated microrobots -- the three-link swimmer and the three-sphere swimmer -- in mastering their signature strokes. These strokes, initially conceptualized by physicists, are now effectively interpreted and applied by the LLM, enabling the microrobots to circumvent the physical constraints inherent to micro-locomotion. Remarkably, our LLM-based decision-making strategy substantially surpasses a traditional reinforcement learning method in terms of training speed. We discuss the nuanced aspects of prompt design, particularly emphasizing the reduction of monetary expenses of using GPT-4.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.09424",
        "abstract url": "https://arxiv.org/abs/2402.09424",
        "title": "Epilepsy Seizure Detection and Prediction using an Approximate Spiking Convolutional Transformer",
        "rating": -2,
        "keywords": [
            [
                "health",
                "disease"
            ]
        ],
        "abstract": "Epilepsy is a common disease of the nervous system. Timely prediction of seizures and intervention treatment can significantly reduce the accidental injury of patients and protect the life and health of patients. This paper presents a neuromorphic Spiking Convolutional Transformer, named Spiking Conformer, to detect and predict epileptic seizure segments from scalped long-term electroencephalogram (EEG) recordings. We report evaluation results from the Spiking Conformer model using the Boston Children's Hospital-MIT (CHB-MIT) EEG dataset. By leveraging spike-based addition operations, the Spiking Conformer significantly reduces the classification computational cost compared to the non-spiking model. Additionally, we introduce an approximate spiking neuron layer to further reduce spike-triggered neuron updates by nearly 38% without sacrificing accuracy. Using raw EEG data as input, the proposed Spiking Conformer achieved an average sensitivity rate of 94.9% and a specificity rate of 99.3% for the seizure detection task, and 96.8%, 89.5% for the seizure prediction task, and needs >10x fewer operations compared to the non-spiking equivalent model.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "To be published at the 2024 IEEE International Symposium on Circuits and Systems (ISCAS), Singapore"
    },
    {
        "paper id": "2403.08774",
        "abstract url": "https://arxiv.org/abs/2403.08774",
        "title": "Discussion of Loop Expansion and Introduction of Series Cutting Functions to Local Potential Approximation: Complexity Analysis Using Green's Functions, Cutting Of Nth-Order Social Interactions For Progressive Safety",
        "rating": -2,
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "In this study, we focus on the aforementioned paper, \"Examination Kubo-Matsubara Green's Function Of The Edwards-Anderson Model: Extreme Value Information Flow Of Nth-Order Interpolated Extrapolation Of Zero Phenomena Using The Replica Method (2024)\". This paper also applies theoretical physics methods to better understand the filter bubble phenomenon, focusing in particular on loop expansions and truncation functions. Using the loop expansion method, the complexity of social interactions during the occurrence of filter bubbles will be discussed in order to introduce series, express mathematically, and evaluate the impact of these interactions. We analyze the interactions between agents and their time evolution using a variety of Green's functions, including delayed Green's functions, advanced Green's functions, and causal Green's functions, to capture the dynamic response of the system through local potential approximations. In addition, we apply truncation functions and truncation techniques to ensure incremental safety and evaluate the long-term stability of the system. This approach will enable a better understanding of the mechanisms of filter bubble generation and dissolution, and discuss insights into their prevention and management. This research explores the possibilities of applying theoretical physics frameworks to social science problems and examines methods for analyzing the complex dynamics of information flow and opinion formation in digital society.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "In this study, we focus on the aforementioned paper, \"Examination Kubo-Matsubara Green's Function Of The Edwards-Anderson Model: Extreme Value Information Flow Of Nth-Order Interpolated Extrapolation Of Zero Phenomena Using The Replica Method (2024)\""
    },
    {
        "paper id": "2402.03342",
        "abstract url": "https://arxiv.org/abs/2402.03342",
        "title": "MADRL-based UAVs Trajectory Design with Anti-Collision Mechanism in Vehicular Networks",
        "rating": -2.5,
        "keywords": [
            [
                "Trajectory",
                "vehicle"
            ],
            [
                "6G"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In upcoming 6G networks, unmanned aerial vehicles (UAVs) are expected to play a fundamental role by acting as mobile base stations, particularly for demanding vehicle-to-everything (V2X) applications. In this scenario, one of the most challenging problems is the design of trajectories for multiple UAVs, cooperatively serving the same area. Such joint trajectory design can be performed using multi-agent deep reinforcement learning (MADRL) algorithms, but ensuring collision-free paths among UAVs becomes a critical challenge. Traditional methods involve imposing high penalties during training to discourage unsafe conditions, but these can be proven to be ineffective, whereas binary masks can be used to restrict unsafe actions, but naively applying them to all agents can lead to suboptimal solutions and inefficiencies. To address these issues, we propose a rank-based binary masking approach. Higher-ranked UAVs move optimally, while lower-ranked UAVs use this information to define improved binary masks, reducing the number of unsafe actions. This approach allows to obtain a good trade-off between exploration and exploitation, resulting in enhanced training performance, while maintaining safety constraints.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)"
    },
    {
        "paper id": "2401.11404",
        "abstract url": "https://arxiv.org/abs/2401.11404",
        "title": "PlasmoData.jl -- A Julia Framework for Modeling and Analyzing Complex Data as Graphs",
        "rating": -3,
        "keywords": [
            [
                "Graph"
            ],
            [
                "disease"
            ]
        ],
        "abstract": "Datasets encountered in scientific and engineering applications appear in complex formats (e.g., images, multivariate time series, molecules, video, text strings, networks). Graph theory provides a unifying framework to model such datasets and enables the use of powerful tools that can help analyze, visualize, and extract value from data. In this work, we present PlasmoData.jl, an open-source, Julia framework that uses concepts of graph theory to facilitate the modeling and analysis of complex datasets. The core of our framework is a general data modeling abstraction, which we call a DataGraph. We show how the abstraction and software implementation can be used to represent diverse data objects as graphs and to enable the use of tools from topology, graph theory, and machine learning (e.g., graph neural networks) to conduct a variety of tasks. We illustrate the versatility of the framework by using real datasets: i) an image classification problem using topological data analysis to extract features from the graph model to train machine learning models; ii) a disease outbreak problem where we model multivariate time series as graphs to detect abnormal events; and iii) a technology pathway analysis problem where we highlight how we can use graphs to navigate connectivity. Our discussion also highlights how PlasmoData.jl leverages native Julia capabilities to enable compact syntax, scalable computations, and interfaces with diverse packages.",
        "subjects": [
            "cs.MS"
        ],
        "comment": "62 pages, 18 figures, 8 tables"
    },
    {
        "paper id": "2401.11491",
        "abstract url": "https://arxiv.org/abs/2401.11491",
        "title": "BA-LINS: A Frame-to-Frame Bundle Adjustment for LiDAR-Inertial Navigation",
        "rating": -3,
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "Navigation"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Bundle Adjustment (BA) has been proven to improve the accuracy of the LiDAR mapping. However, the BA method has not yet been properly employed in a dead-reckoning navigation system. In this paper, we present a frame-to-frame (F2F) BA for LiDAR-inertial navigation, named BA-LINS. Based on the direct F2F point-cloud association, the same-plane points are associated among the LiDAR keyframes. Hence, the F2F plane-point BA measurement can be constructed using the same-plane points. The LiDAR BA and the inertial measurement unit (IMU)-preintegration measurements are tightly integrated under the framework of factor graph optimization. An effective adaptive covariance estimation algorithm for LiDAR BA measurements is proposed to further improve the accuracy. We conduct exhaustive real-world experiments on public and private datasets to examine the proposed BA-LINS. The results demonstrate that BA-LINS yields superior accuracy to state-of-the-art methods. Compared to the baseline system FF-LINS, the absolute translation accuracy and state-estimation efficiency of BA-LINS are improved by 29.5% and 28.7% on the private dataset, respectively. Besides, the ablation experiment results exhibit that the proposed adaptive covariance estimation algorithm can notably improve the accuracy and robustness of BA-LINS.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "14 pages, 14 figures"
    },
    {
        "paper id": "2401.11499",
        "abstract url": "https://arxiv.org/abs/2401.11499",
        "title": "Self-Supervised Bird's Eye View Motion Prediction with Cross-Modality Signals",
        "rating": -3,
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "robotics"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Learning the dense bird's eye view (BEV) motion flow in a self-supervised manner is an emerging research for robotics and autonomous driving. Current self-supervised methods mainly rely on point correspondences between point clouds, which may introduce the problems of fake flow and inconsistency, hindering the model's ability to learn accurate and realistic motion. In this paper, we introduce a novel cross-modality self-supervised training framework that effectively addresses these issues by leveraging multi-modality data to obtain supervision signals. We design three innovative supervision signals to preserve the inherent properties of scene motion, including the masked Chamfer distance loss, the piecewise rigidity loss, and the temporal consistency loss. Through extensive experiments, we demonstrate that our proposed self-supervised framework outperforms all previous self-supervision methods for the motion prediction task.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11500",
        "abstract url": "https://arxiv.org/abs/2401.11500",
        "title": "Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis",
        "rating": -3,
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "This paper presents an innovative approach to integrating Large Language Models (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps for precise color synthesis in automation systems. We propose a novel framework that employs fine-tuned LLMs to interpret natural language commands and convert them into specific operational instructions for EHD pump control. This approach aims to enhance user interaction with complex hardware systems, making it more intuitive and efficient. The methodology involves four key steps: fine-tuning the language model with a dataset of color specifications and corresponding Arduino code, developing a natural language processing interface, translating user inputs into executable Arduino code, and controlling EHD pumps for accurate color mixing. Conceptual experiment results, based on theoretical assumptions, indicate a high potential for accurate color synthesis, efficient language model interpretation, and reliable EHD pump operation. This research extends the application of LLMs beyond text-based tasks, demonstrating their potential in industrial automation and control systems. While highlighting the limitations and the need for real-world testing, this study opens new avenues for AI applications in physical system control and sets a foundation for future advancements in AI-driven automation technologies.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11576",
        "abstract url": "https://arxiv.org/abs/2401.11576",
        "title": "Quantum Architecture Search with Unsupervised Representation Learning",
        "rating": -3,
        "keywords": [
            [
                "Architecture Search"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Utilizing unsupervised representation learning for quantum architecture search (QAS) represents a cutting-edge approach poised to realize potential quantum advantage on Noisy Intermediate-Scale Quantum (NISQ) devices. Most QAS algorithms combine their search space and search algorithms together and thus generally require evaluating a large number of quantum circuits during the search process. Predictor-based QAS algorithms can alleviate this problem by directly estimating the performance of circuits according to their structures. However, a high-performance predictor generally requires very time-consuming labeling to obtain a large number of labeled quantum circuits. Recently, a classical neural architecture search algorithm Arch2vec inspires us by showing that architecture search can benefit from decoupling unsupervised representation learning from the search process. Whether unsupervised representation learning can help QAS without any predictor is still an open topic. In this work, we propose a framework QAS with unsupervised representation learning and visualize how unsupervised architecture representation learning encourages quantum circuit architectures with similar connections and operators to cluster together. Specifically, our framework enables the process of QAS to be decoupled from unsupervised architecture representation learning so that the learned representation can be directly applied to different downstream applications. Furthermore, our framework is predictor-free eliminating the need for a large number of labeled quantum circuits. During the search process, we use two algorithms REINFORCE and Bayesian Optimization to directly search on the latent representation, and compare them with the method Random Search. The results show our framework can more efficiently get well-performing candidate circuits within a limited number of searches.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "9 Pages, quantum architecture search, unsupervised representation learning"
    },
    {
        "paper id": "2401.11679",
        "abstract url": "https://arxiv.org/abs/2401.11679",
        "title": "Simulating Nighttime Visible Satellite Imagery of Tropical Cyclones Using Conditional Generative Adversarial Networks",
        "rating": -3,
        "keywords": [
            [
                "infrared"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Visible (VIS) imagery of satellites has various important applications in meteorology, including monitoring Tropical Cyclones (TCs). However, it is unavailable at night because of the lack of sunlight. This study presents a Conditional Generative Adversarial Networks (CGAN) model that generates highly accurate nighttime visible reflectance using infrared (IR) bands and sunlight direction parameters as input. The model was trained and validated using target area observations of the Advanced Himawari Imager (AHI) in the daytime. This study also presents the first nighttime model validation using the Day/Night Band (DNB) of the Visible/Infrared Imager Radiometer Suite (VIIRS). The daytime statistical results of the Structural Similarity Index Measure (SSIM), Peak Signal-to-Noise Ratio (PSNR), Root Mean Square Error (RMSE), Correlation Coefficient (CC), and Bias are 0.885, 28.3, 0.0428, 0.984, and -0.0016 respectively, completely surpassing the model performance of previous studies. The nighttime statistical results of SSIM, PSNR, RMSE, and CC are 0.821, 24.4, 0.0643, and 0.969 respectively, which are slightly negatively impacted by the parallax between satellites. We performed full-disk model validation which proves our model could also be readily applied in the tropical ocean without TCs in the northern hemisphere. This model contributes to the nighttime monitoring of meteorological phenomena by providing accurate AI-generated visible imagery with adjustable virtual sunlight directions.",
        "subjects": [
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11410",
        "abstract url": "https://arxiv.org/abs/2401.11410",
        "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
        "rating": -3.5,
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "Forecasting",
                "Agricultural"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. With extensive evaluation, the multivariate Stacked Bi-LSTM (three Bi-LSTM layers with a time Distributed layer) Network is employed as the weather forecasting model. The proposed weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for any given location in Bangladesh with an average R-squared value of 0.9824, and the model outperforms other state-of-the-art LSTM models. These predictions guide our system in generating viable farming decisions. Additionally, our full-fledged system is capable of alerting the farmers about extreme weather conditions so that preventive measures can be undertaken to protect the crops. Finally, the system is also adept at making knowledge-based crop suggestions for the flood and drought-prone regions of Bangladesh.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "18 pages, 16 figures and 13 tables. Two figures and one table have been added to this version"
    },
    {
        "paper id": "2401.11439",
        "abstract url": "https://arxiv.org/abs/2401.11439",
        "title": "General Flow as Foundation Affordance for Scalable Robot Learning",
        "rating": -4,
        "keywords": [
            [
                "3D",
                "RGBD"
            ],
            [
                "Robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "We address the challenge of acquiring real-world manipulation skills with a scalable framework.Inspired by the success of large-scale auto-regressive prediction in Large Language Models (LLMs), we hold the belief that identifying an appropriate prediction target capable of leveraging large-scale datasets is crucial for achieving efficient and universal learning. Therefore, we propose to utilize flow, which represents the future trajectories of 3D points on objects of interest, as an ideal prediction target in robot learning. To exploit scalable data resources, we turn our attention to cross-embodiment datasets. We develop, for the first time, a language-conditioned prediction model directly from large-scale RGBD human video datasets. Our predicted flow offers actionable geometric and physics guidance, thus facilitating stable zero-shot skill transfer in real-world scenarios.We deploy our method with a policy based on closed-loop flow prediction. Remarkably, without any additional training, our method achieves an impressive 81% success rate in human-to-robot skill transfer, covering 18 tasks in 6 scenes. Our framework features the following benefits: (1) scalability: leveraging cross-embodiment data resources; (2) universality: multiple object categories, including rigid, articulated, and soft bodies; (3) stable skill transfer: providing actionable guidance with a small inference domain-gap. These lead to a new pathway towards scalable general robot learning. Data, code, and model weights will be made publicly available.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11445",
        "abstract url": "https://arxiv.org/abs/2401.11445",
        "title": "Towards Non-Robocentric Dynamic Landing of Quadrotor UAVs",
        "rating": -4,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this work, we propose a dynamic landing solution without the need for onboard exteroceptive sensors and an expensive computation unit, where all localization and control modules are carried out on the ground in a non-inertial frame. Our system starts with a relative state estimator of the aerial robot from the perspective of the landing platform, where the state tracking of the UAV is done through a set of onboard LED markers and an on-ground camera; the state is expressed geometrically on manifold, and is returned by Iterated Extended Kalman filter (IEKF) algorithm. Subsequently, a motion planning module is developed to guide the landing process, formulating it as a minimum jerk trajectory by applying the differential flatness property. Considering visibility and dynamic constraints, the problem is solved using quadratic programming, and the final motion primitive is expressed through piecewise polynomials. Through a series of experiments, the applicability of this approach is validated by successfully landing 18 cm x 18 cm quadrotor on a 43 cm x 43 cm platform, exhibiting performance comparable to conventional methods. Finally, we provide comprehensive hardware and software details to the research community for future reference.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11614",
        "abstract url": "https://arxiv.org/abs/2401.11614",
        "title": "Lightweight Self-Driven Deformable Organ Animations",
        "rating": -4,
        "keywords": [
            [
                "biological",
                "medical",
                "Organ"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "The subject of simulating internal organs is a valuable and important topic of research to multiple fields from medical analysis to education and training. This paper presents a solution that utilizes a graphical technique in combination with a Stochastic method for tuning an active physics-based model. We generate responsive interactive organ animations with regional properties (i.e., areas of the model oscillating with different harmonic frequencies) to reproduce and capture real-world characteristics. Our method builds upon biological and physical discoveries to procedurally generate internally controlled rhythmic motions but also enable the solution to be interactive and adaptive. We briefly review deformation models for medical simulations and investigate the impediments to combining 'computergraphics' representations with biomechanical models. Finally, we present a lightweight solution that is scalable and able to procedurally generate large organ animations. In particular, simplified geometric representations of deformable structures that use periodic coupled forces to drive themselves.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13699",
        "abstract url": "https://arxiv.org/abs/2401.13699",
        "title": "Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey",
        "rating": -4,
        "keywords": [
            [
                "health",
                "Healthcare",
                "diagnosis"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "The Internet of things (IoT) can significantly enhance the quality of human life, specifically in healthcare, attracting extensive attentions to IoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as an innovative paradigm that can comprehensively characterize the replication of the individual human body in the digital world and reflect its physical status in real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the application of healthcare monitoring by acting as a versatile and vivid human digital testbed, simulating the outcomes and guiding the practical treatments. However, successfully establishing HDT requires high-fidelity virtual modeling and strong information interactions but possibly with scarce, biased and noisy data. Fortunately, a recent popular technology called generative artificial intelligence (GAI) may be a promising solution because it can leverage advanced AI algorithms to automatically create, manipulate, and modify valuable while diverse data. This survey particularly focuses on the implementation of GAI-driven HDT in IoT-healthcare. We start by introducing the background of IoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the fundamental techniques and present the overall framework of GAI-driven HDT. After that, we explore the realization of GAI-driven HDT in detail, including GAI-enabled data acquisition, communication, data management, digital modeling, and data analysis. Besides, we discuss typical IoT-healthcare applications that can be revolutionized by GAI-driven HDT, namely personalized health monitoring and diagnosis, personalized prescription, and personalized rehabilitation. Finally, we conclude this survey by highlighting some future research directions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11429",
        "abstract url": "https://arxiv.org/abs/2401.11429",
        "title": "Joint Downlink and Uplink Optimization for RIS-Aided FDD MIMO Communication Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper investigates reconfigurable intelligent surface (RIS)-aided frequency division duplexing (FDD) communication systems. Since the downlink and uplink signals are simultaneously transmitted in FDD, the phase shifts at the RIS should be designed to support both transmissions. Considering a single-user multiple-input multiple-output system, we formulate a weighted sum-rate maximization problem to jointly maximize the downlink and uplink system performance. To tackle the non-convex optimization problem, we adopt an alternating optimization (AO) algorithm, in which two phase shift optimization techniques are developed to handle the unit-modulus constraints induced by the reflection coefficients at the RIS. The first technique exploits the manifold optimization-based algorithm, while the second uses a lower-complexity AO approach. Numerical results verify that the proposed techniques rapidly converge to local optima and significantly improve the overall system performance compared to existing benchmark schemes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Accepted to IEEE Transactions on Wireless Communications"
    },
    {
        "paper id": "2401.11433",
        "abstract url": "https://arxiv.org/abs/2401.11433",
        "title": "Error-Correcting Codes on Projective Bundles over Deligne-Lusztig varieties",
        "rating": -10,
        "keywords": [],
        "abstract": "The aim of this article is to give lower bounds on the parameters of algebraic geometric error-correcting codes constructed from projective bundles over Deligne--Lusztig surfaces. The methods based on an intensive use of the intersection theory allow us to extend the codes previously constructed from higher-dimensional varieties, as well as those coming from curves. General bounds are obtained for the case of projective bundles of rank $2$ over standard Deligne-Lusztig surfaces, and some explicit examples coming from surfaces of type $A_{2}$ and ${}^{2}A_{4}$ are given.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2401.11459",
        "abstract url": "https://arxiv.org/abs/2401.11459",
        "title": "AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology",
        "rating": -10,
        "keywords": [],
        "abstract": "Large language models (LLMs) with Transformer architectures have become phenomenal in natural language processing, multimodal generative artificial intelligence, and agent-oriented artificial intelligence. The self-attention module is the most dominating sub-structure inside Transformer-based LLMs. Computation using general-purpose graphics processing units (GPUs) inflicts reckless demand for I/O bandwidth for transferring intermediate calculation results between memories and processing units. To tackle this challenge, this work develops a fully customized vanilla self-attention accelerator, AttentionLego, as the basic building block for constructing spatially expandable LLM processors. AttentionLego provides basic implementation with fully-customized digital logic incorporating Processing-In-Memory (PIM) technology. It is based on PIM-based matrix-vector multiplication and look-up table-based Softmax design. The open-source code is available online: https://bonany.cc/attentionleg.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "for associated source codes, see https://bonany.cc/attentionleg"
    },
    {
        "paper id": "2401.11463",
        "abstract url": "https://arxiv.org/abs/2401.11463",
        "title": "Estimating the Usefulness of Clarifying Questions and Answers for Conversational Search",
        "rating": -10,
        "keywords": [],
        "abstract": "While the body of research directed towards constructing and generating clarifying questions in mixed-initiative conversational search systems is vast, research aimed at processing and comprehending users' answers to such questions is scarce. To this end, we present a simple yet effective method for processing answers to clarifying questions, moving away from previous work that simply appends answers to the original query and thus potentially degrades retrieval performance. Specifically, we propose a classifier for assessing usefulness of the prompted clarifying question and an answer given by the user. Useful questions or answers are further appended to the conversation history and passed to a transformer-based query rewriting module. Results demonstrate significant improvements over strong non-mixed-initiative baselines. Furthermore, the proposed approach mitigates the performance drops when non useful questions and answers are utilized.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "This is the author's version of the work. The definitive version is published in: Proceedings of the 46th European Conference on Information Retrieval (ECIR '24), March 24-28, 2024, Glasgow, Scotland"
    },
    {
        "paper id": "2401.11471",
        "abstract url": "https://arxiv.org/abs/2401.11471",
        "title": "LR-CNN: Lightweight Row-centric Convolutional Neural Network Training for Memory Reduction",
        "rating": -10,
        "keywords": [],
        "abstract": "In the last decade, Convolutional Neural Network with a multi-layer architecture has advanced rapidly. However, training its complex network is very space-consuming, since a lot of intermediate data are preserved across layers, especially when processing high-dimension inputs with a big batch size. That poses great challenges to the limited memory capacity of current accelerators (e.g., GPUs). Existing efforts mitigate such bottleneck by external auxiliary solutions with additional hardware costs, and internal modifications with potential accuracy penalty. Differently, our analysis reveals that computations intra- and inter-layers exhibit the spatial-temporal weak dependency and even complete independency features. That inspires us to break the traditional layer-by-layer (column) dataflow rule. Now operations are novelly re-organized into rows throughout all convolution layers. This lightweight design allows a majority of intermediate data to be removed without any loss of accuracy. We particularly study the weak dependency between two consecutive rows. For the resulting skewed memory consumption, we give two solutions with different favorite scenarios. Evaluations on two representative networks confirm the effectiveness. We also validate that our middle dataflow optimization can be smoothly embraced by existing works for better memory reduction.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11496",
        "abstract url": "https://arxiv.org/abs/2401.11496",
        "title": "On a Group Under Which Symmetric Reed-Muller Codes are Invariant",
        "rating": -10,
        "keywords": [],
        "abstract": "The Reed-Muller codes are a family of error-correcting codes that have been widely studied in coding theory. In 2020, Wei Yan and Sian-Jheng Lin introduced a variant of Reed-Muller codes so called symmetric Reed-Muller codes. We investigate linear maps of the automorphism group of symmetric Reed-Muller codes and show that the set of these linear maps forms a subgroup of the general linear group, which is the automorphism group of punctured Reed-Muller codes. We provide a method to determine all the automorphisms in this subgroup explicitly for some special cases.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2401.11509",
        "abstract url": "https://arxiv.org/abs/2401.11509",
        "title": "Simple Domain Adaptation for Sparse Retrievers",
        "rating": -10,
        "keywords": [],
        "abstract": "In Information Retrieval, and more generally in Natural Language Processing, adapting models to specific domains is conducted through fine-tuning. Despite the successes achieved by this method and its versatility, the need for human-curated and labeled data makes it impractical to transfer to new tasks, domains, and/or languages when training data doesn't exist. Using the model without training (zero-shot) is another option that however suffers an effectiveness cost, especially in the case of first-stage retrievers. Numerous research directions have emerged to tackle these issues, most of them in the context of adapting to a task or a language. However, the literature is scarcer for domain (or topic) adaptation. In this paper, we address this issue of cross-topic discrepancy for a sparse first-stage retriever by transposing a method initially designed for language adaptation. By leveraging pre-training on the target data to learn domain-specific knowledge, this technique alleviates the need for annotated data and expands the scope of domain adaptation. Despite their relatively good generalization ability, we show that even sparse retrievers can benefit from our simple domain adaptation method.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted at ECIR 2024"
    },
    {
        "paper id": "2401.11513",
        "abstract url": "https://arxiv.org/abs/2401.11513",
        "title": "Exploring the Truth and Beauty of Theory Landscapes with Machine Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "Theoretical physicists describe nature by i) building a theory model and ii) determining the model parameters. The latter step involves the dual aspect of both fitting to the existing experimental data and satisfying abstract criteria like beauty, naturalness, etc. We use the Yukawa quark sector as a toy example to demonstrate how both of those tasks can be accomplished with machine learning techniques. We propose loss functions whose minimization results in true models that are also beautiful as measured by three different criteria - uniformity, sparsity, or symmetry.",
        "subjects": [
            "hep-ph"
        ],
        "comment": "13 pages, 9 figures. arXiv admin note: text overlap with arXiv:2311.00087"
    },
    {
        "paper id": "2401.11520",
        "abstract url": "https://arxiv.org/abs/2401.11520",
        "title": "Is it a Real CD Mismatch in Interdomain Routing?",
        "rating": -10,
        "keywords": [],
        "abstract": "In inter-domain routing, a packet is not always forwarded along the Autonomous System (AS) level path determined by the BGP routing protocol. This is often called control-plane and data-plane (CD) mismatch, which allows for flexible traffic control, but also leads to operation and security issues. We systematically analyze this phenomenon with path pairs collected from 128 pairs of vantage points over more than 5 years, and use multiple IP-to-AS mapping methods to compare CD paths. What is interesting is that, working at such a large scale in turn helps us design a novel method to fairly evaluate the accuracy of various existing mapping methods, and further develop a new mapping method, i.e., LearnToCorrect, that can correct more than 70\\% mapping errors of the state-of-the-art one. Then we devise to identify real mismatches with LearnToCorrect, and estimate that the real-mismatch ratio in the wild is typically less than 6\\%. At last, we use our proposed methods to detect routing security issues, which are previously difficult to accurately find out.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11531",
        "abstract url": "https://arxiv.org/abs/2401.11531",
        "title": "Tempo: Confidentiality Preservation in Cloud-Based Neural Network Training",
        "rating": -10,
        "keywords": [],
        "abstract": "Cloud deep learning platforms provide cost-effective deep neural network (DNN) training for customers who lack computation resources. However, cloud systems are often untrustworthy and vulnerable to attackers, leading to growing concerns about model privacy. Recently, researchers have sought to protect data privacy in deep learning by leveraging CPU trusted execution environments (TEEs), which minimize the use of cryptography, but existing works failed to simultaneously utilize the computational resources of GPUs to assist in training and prevent model leakage. This paper presents Tempo, the first cloud-based deep learning system that cooperates with TEE and distributed GPUs for efficient DNN training with model confidentiality preserved. To tackle the challenge of preserving privacy while offloading linear algebraic operations from TEE to GPUs for efficient batch computation, we introduce a customized permutation-based obfuscation algorithm to blind both inputs and model parameters. An optimization mechanism that reduces encryption operations is proposed for faster weight updates during backpropagation to speed up training. We implement Tempo and evaluate it with both training and inference for two prevalent DNNs. Empirical results indicate that Tempo outperforms baselines and offers sufficient privacy protection.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11547",
        "abstract url": "https://arxiv.org/abs/2401.11547",
        "title": "Understanding the Security Risks of Decentralized Exchanges by Uncovering Unfair Trades in the Wild",
        "rating": -10,
        "keywords": [],
        "abstract": "DEX, or decentralized exchange, is a prominent class of decentralized finance (DeFi) applications on blockchains, attracting a total locked value worth tens of billions of USD today. This paper presents the first large-scale empirical study that uncovers unfair trades on popular DEX services on Ethereum and Binance Smart Chain (BSC). By joining and analyzing 60 million transactions, we find 671,400 unfair trades on all six measured DEXes, including Uniswap, Balancer, and Curve. Out of these unfair trades, we attribute 55,000 instances, with high confidence, to token thefts that cause a value loss of more than 3.88 million USD. Furthermore, the measurement study uncovers previously unknown causes of extractable value and real-world adaptive strategies to these causes. Finally, we propose countermeasures to redesign secure DEX protocols and to harden deployed services against the discovered security risks.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11562",
        "abstract url": "https://arxiv.org/abs/2401.11562",
        "title": "Enhancing selectivity using Wasserstein distance based reweighing",
        "rating": -10,
        "keywords": [],
        "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$. On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well. Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). We tune the algorithm's parameter so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\% to 95\\%, as a result of our reweighing. Of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\% but not MNK1, at 10$\u03bc$M -- a 5\\% success rate.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11596",
        "abstract url": "https://arxiv.org/abs/2401.11596",
        "title": "Learning to Maximize Gains From Trade in Small Markets",
        "rating": -10,
        "keywords": [],
        "abstract": "We study the problem of designing a two-sided market (double auction) to maximize the gains from trade (social welfare) under the constraints of (dominant-strategy) incentive compatibility and budget-balance. Our goal is to do so for an unknown distribution from which we are given a polynomial number of samples. Our first result is a general impossibility for the case of correlated distributions of values even between just one seller and two buyers, in contrast to the case of one seller and one buyer (bilateral trade) where this is possible. Our second result is an efficient learning algorithm for one seller and two buyers in the case of independent distributions which is based on a novel algorithm for computing optimal mechanisms for finitely supported and explicitly given independent distributions. Both results rely heavily on characterizations of (dominant-strategy) incentive compatible mechanisms that are strongly budget-balanced.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11622",
        "abstract url": "https://arxiv.org/abs/2401.11622",
        "title": "The Markov-Chain Polytope with Applications",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper addresses the problem of finding a minimum-cost $m$-state Markov chain $(S_0,\\ldots,S_{m-1})$ in a large set of chains. The chains studied have a reward associated with each state. The cost of a chain is its \"gain\", i.e., its average reward under its stationary distribution. Specifically, for each $k=0,\\ldots,m-1$ there is a known set ${\\mathbb S}_k$ of type-$k$ states. A permissible Markov chain contains exactly one state of each type; the problem is to find a minimum-cost permissible chain. The original motivation was to find a cheapest binary AIFV-$m$ lossless code on a source alphabet of size $n$. Such a code is an $m$-tuple of trees, in which each tree can be viewed as a Markov Chain state. This formulation was then used to address other problems in lossless compression. The known solution techniques for finding minimum-cost Markov chains were iterative and ran in exponential time. This paper shows how to map every possible type-$k$ state into a type-$k$ hyperplane and then define a \"Markov Chain Polytope\" as the lower envelope of all such hyperplanes. Finding a minimum-cost Markov chain can then be shown to be equivalent to finding a \"highest\" point on this polytope. The local optimization procedures used in the previous iterative algorithms are shown to be separation oracles for this polytope. Since these were often polynomial time, an application of the Ellipsoid method immediately leads to polynomial time algorithms for these problems.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11628",
        "abstract url": "https://arxiv.org/abs/2401.11628",
        "title": "Older Adults Imagining Future Technologies in Participatory Design Workshops: Supporting Continuity in the Pursuit of Meaningful Activities",
        "rating": -10,
        "keywords": [],
        "abstract": "Recent innovations in digital technology offer significant opportunities for older adults to engage in meaningful activities. To investigate older adults' perceptions of using existing and emerging technologies for meaningful activities, we conducted three participatory design workshops and follow-up interviews with adults aged over 65. The workshops encompassed discussions on existing technologies for meaningful activities, demonstrations of emerging technologies such as VR, AR, and AI, and design activities including prototyping and storyboarding. Our findings show that while participants had diverse interpretations of meaningful activities, they sought to use technologies to support continuity in the pursuit of these activities. Specifically, participants highlighted the importance of safe aging at home, which provides a pathway for meaningful activities in later life. We further discuss participants' discerning attitudes when assessing the use of different technologies for meaningful activities and several values and attributes they desire when envisioning future technologies, including simplicity, positivity, proactivity, and integration.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11640",
        "abstract url": "https://arxiv.org/abs/2401.11640",
        "title": "Optimizing performance in elastic optical networks using advanced reconfigurable optical add-drop multiplexers: A novel design approach and comprehensive analysis",
        "rating": -10,
        "keywords": [],
        "abstract": "Network operators diversify service offerings and enhance network efficiency by leveraging bandwidth-variable transceivers and colorless flexible-grid reconfigurable optical add-drop multiplexers (ROADMs). Nonetheless, the paradigm shift from rigid to elastic optical networks (EONs) has affected several key parameters, including bit rate, center frequency spacing, modulation format, and optical reach. This study investigated the transformative impact of emerging technologies on the design and structure of optical network architectures, including spectrally efficient multicarrier systems and bandwidth-variable wavelength-selective switches. A cost-effective ROADM architecture applying an order-based connecting approach was introduced, which presented a high connectivity level and a blockage probability of less than 10-4. When this architecture was implemented in the EON, the data transportation rate was 1 Tb/s. This outcome successfully accommodated a 20 % surge in traffic demand, while the optimized network architecture significantly improved fiber utilization by 3.4 %. Consequently, this study contributed a practical and efficient solution for implementing flexible optical networks, effectively addressing current concerns and propelling the optical communication system sector forward.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11642",
        "abstract url": "https://arxiv.org/abs/2401.11642",
        "title": "SyzRetrospector: A Large-Scale Retrospective Study of Syzbot",
        "rating": -10,
        "keywords": [],
        "abstract": "Over the past 6 years, Syzbot has fuzzed the Linux kernel day and night to report over 5570 bugs, of which 4604 have been patched [11]. While this is impressive, we have found the average time to find a bug is over 405 days. Moreover, we have found that current metrics commonly used, such as time-to-find and number of bugs found, are inaccurate in evaluating Syzbot since bugs often spend the majority of their lives hidden from the fuzzer. In this paper, we set out to better understand and quantify Syzbot's performance and improvement in finding bugs. Our tool, SyzRetrospector, takes a different approach to evaluating Syzbot by finding the earliest that Syzbot was capable of finding a bug, and why that bug was revealed. We use SyzRetrospector on a large scale to analyze 559 bugs and find that bugs are hidden for an average of 331.17 days before Syzbot is even able to find them. We further present findings on the behaviors of revealing factors, how some bugs are harder to reveal than others, the trends in delays over the past 6 years, and how bug location relates to delays. We also provide key takeaways for improving Syzbot's delays.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.11646",
        "abstract url": "https://arxiv.org/abs/2401.11646",
        "title": "Nonparametric Estimation via Variance-Reduced Sketching",
        "rating": -10,
        "keywords": [],
        "abstract": "Nonparametric models are of great interest in various scientific and engineering disciplines. Classical kernel methods, while numerically robust and statistically sound in low-dimensional settings, become inadequate in higher-dimensional settings due to the curse of dimensionality. In this paper, we introduce a new framework called Variance-Reduced Sketching (VRS), specifically designed to estimate density functions and nonparametric regression functions in higher dimensions with a reduced curse of dimensionality. Our framework conceptualizes multivariable functions as infinite-size matrices, and facilitates a new sketching technique motivated by numerical linear algebra literature to reduce the variance in estimation problems. We demonstrate the robust numerical performance of VRS through a series of simulated experiments and real-world data applications. Notably, VRS shows remarkable improvement over existing neural network estimators and classical kernel methods in numerous density estimation and nonparametric regression models. Additionally, we offer theoretical justifications for VRS to support its ability to deliver nonparametric estimation with a reduced curse of dimensionality.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "64 pages, 8 figures"
    },
    {
        "paper id": "2401.11663",
        "abstract url": "https://arxiv.org/abs/2401.11663",
        "title": "\"I Got Flagged for Supposed Bullying, Even Though It Was in Response to Someone Harassing Me About My Disability.\": A Study of Blind TikTokers' Content Moderation Experiences",
        "rating": -10,
        "keywords": [],
        "abstract": "The Human-Computer Interaction (HCI) community has consistently focused on the experiences of users moderated by social media platforms. Recently, scholars have noticed that moderation practices could perpetuate biases, resulting in the marginalization of user groups undergoing moderation. However, most studies have primarily addressed marginalization related to issues such as racism or sexism, with little attention given to the experiences of people with disabilities. In this paper, we present a study on the moderation experiences of blind users on TikTok, also known as \"BlindToker,\" to address this gap. We conducted semi-structured interviews with 20 BlindTokers and used thematic analysis to analyze the data. Two main themes emerged: BlindTokers' situated content moderation experiences and their reactions to content moderation. We reported on the lack of accessibility on TikTok's platform, contributing to the moderation and marginalization of BlindTokers. Additionally, we discovered instances of harassment from trolls that prompted BlindTokers to respond with harsh language, triggering further moderation. We discussed these findings in the context of the literature on moderation, marginalization, and transformative justice, seeking solutions to address such issues.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "24 paged, 1 Figure, accepted by CHI'24"
    },
    {
        "paper id": "2401.11665",
        "abstract url": "https://arxiv.org/abs/2401.11665",
        "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
        "rating": -10,
        "keywords": [],
        "abstract": "Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde O}(\\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "52 pages, 2 figures, to appear in AISTATS 2024"
    },
    {
        "paper id": "2401.11677",
        "abstract url": "https://arxiv.org/abs/2401.11677",
        "title": "Emulation-based Stabilization for Networked Control Systems with Stochastic Channels",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper studies the stabilization problem of networked control systems (NCSs) with random packet dropouts caused by stochastic channels. To describe the effects of stochastic channels on the information transmission, the transmission times are assumed to be deterministic, whereas the packet transmission is assumed to be random. We first propose a stochastic scheduling protocol to model random packet dropouts, and address the properties of the proposed stochastic scheduling protocol. The proposed scheduling protocol provides a unified modelling framework for a general class of random packet dropouts due to different stochastic channels. Next, the proposed scheduling protocol is embedded into the closed-loop system, which leads to a stochastic hybrid model for NCSs with random packet dropouts. Based on this stochastic hybrid model, we follow the emulation approach to establish sufficient conditions to guarantee uniform global asymptotical stability in probability. In particular, an upper bound on the maximally allowable transmission interval is derived explicitly for all stochastic protocols satisfying Lyapunov conditions that guarantee uniform global asymptotic stability in probability. Finally, two numerical examples are presented to demonstrate the derived results.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "12 pages, 4 figures, accepted"
    },
    {
        "paper id": "2401.11686",
        "abstract url": "https://arxiv.org/abs/2401.11686",
        "title": "Evolutionary dynamics of any multiplayer game on regular graphs",
        "rating": -10,
        "keywords": [],
        "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions of key evolutionary processes that govern vital social and natural systems. However, a comprehensive theoretical framework for solving multiplayer games with an arbitrary number of strategies on graphs is still missing. Here, we solve this by drawing an analogy with the Ball-and-Box problem, based on which we show that the local configuration of multiplayer games on graphs is equivalent to distributing $k$ identical co-players among $n$ distinct strategies. We use this to derive the replicator equation for any $n$-strategy multiplayer game under weak selection, which can be solved in polynomial time. As an example, we revisit the second-order free-riding problem, where costly punishment cannot truly resolve social dilemmas in a well-mixed population. Yet, in structured populations, we derive an accurate threshold for the punishment strength, beyond which punishment can either lead to the extinction of defection or transform the system into a rock-paper-scissors-like cycle. The analytical solution also qualitatively agrees with the phase diagrams that were previously obtained for non-marginal selection strengths. Our framework thus allows an exploration of any multi-strategy multiplayer game on regular graphs.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12258",
        "abstract url": "https://arxiv.org/abs/2401.12258",
        "title": "Emergent Dominance Hierarchies in Reinforcement Learning Agents",
        "rating": -10,
        "keywords": [],
        "abstract": "Modern Reinforcement Learning (RL) algorithms are able to outperform humans in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings present additional challenges, and successful cooperation in mixed-motive groups of agents depends on a delicate balancing act between individual and group objectives. Social conventions and norms, often inspired by human institutions, are used as tools for striking this balance. In this paper, we examine a fundamental, well-studied social convention that underlies cooperation in both animal and human societies: dominance hierarchies. We adapt the ethological theory of dominance hierarchies to artificial agents, borrowing the established terminology and definitions with as few amendments as possible. We demonstrate that populations of RL agents, operating without explicit programming or intrinsic rewards, can invent, learn, enforce, and transmit a dominance hierarchy to new populations. The dominance hierarchies that emerge have a similar structure to those studied in chickens, mice, fish, and other species.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12259",
        "abstract url": "https://arxiv.org/abs/2401.12259",
        "title": "Agreement Technologies for Coordination in Smart Cities",
        "rating": -10,
        "keywords": [],
        "abstract": "Many challenges in today's society can be tackled by distributed open systems. This is particularly true for domains that are commonly perceived under the umbrella of smart cities, such as intelligent transportation, smart energy grids, or participative governance. When designing computer applications for these domains, it is necessary to account for the fact that the elements of such systems, often called software agents, are usually made by different designers and act on behalf of particular stakeholders. Furthermore, it is unknown at design time when such agents will enter or leave the system, and what interests new agents will represent. To instil coordination in such systems is particularly demanding, as usually only part of them can be directly controlled at runtime. Agreement technologies refer to a sandbox of tools and mechanisms for the development of such open multiagent systems, which are based on the notion of agreement. In this paper, we argue that agreement technologies are a suitable means for achieving coordination in smart city domains, and back our claim through examples of several real-world applications.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08775",
        "abstract url": "https://arxiv.org/abs/2403.08775",
        "title": "Constrained Reinforcement Learning for Adaptive Controller Synchronization in Distributed SDN",
        "rating": -10,
        "keywords": [],
        "abstract": "In software-defined networking (SDN), the implementation of distributed SDN controllers, with each controller responsible for managing a specific sub-network or domain, plays a critical role in achieving a balance between centralized control, scalability, reliability, and network efficiency. These controllers must be synchronized to maintain a logically centralized view of the entire network. While there are various approaches for synchronizing distributed SDN controllers, most tend to prioritize goals such as optimization of communication latency or load balancing, often neglecting to address both the aspects simultaneously. This limitation becomes particularly significant when considering applications like Augmented and Virtual Reality (AR/VR), which demand constrained network latencies and substantial computational resources. Additionally, many existing studies in this field predominantly rely on value-based reinforcement learning (RL) methods, overlooking the potential advantages offered by state-of-the-art policy-based RL algorithms. To bridge this gap, our work focuses on examining deep reinforcement learning (DRL) techniques, encompassing both value-based and policy-based methods, to guarantee an upper latency threshold for AR/VR task offloading within SDN environments, while selecting the most cost-effective servers for AR/VR task offloading. Our evaluation results indicate that while value-based methods excel in optimizing individual network metrics such as latency or load balancing, policy-based approaches exhibit greater robustness in adapting to sudden network changes or reconfiguration.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    }
]