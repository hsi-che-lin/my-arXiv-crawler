[
    {
        "paper id": "2401.12535",
        "abstract url": "https://arxiv.org/abs/2401.12535",
        "title": "Self-Supervised Vision Transformers Are Efficient Segmentation Learners for Imperfect Labels",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "This study demonstrates a cost-effective approach to semantic segmentation using self-supervised vision transformers (SSVT). By freezing the SSVT backbone and training a lightweight segmentation head, our approach effectively utilizes imperfect labels, thereby improving robustness to label imperfections. Empirical experiments show significant performance improvements over existing methods for various annotation types, including scribble, point-level, and image-level labels. The research highlights the effectiveness of self-supervised vision transformers in dealing with imperfect labels, providing a practical and efficient solution for semantic segmentation while reducing annotation costs. Through extensive experiments, we confirm that our method outperforms baseline models for all types of imperfect labels. Especially under the zero-shot vision-language-model-based label, our model exhibits 11.5\\%p performance gain compared to the baseline.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "AAAI2024 Edge Intelligence Workshop (EIW) accepted"
    },
    {
        "paper id": "2401.12503",
        "abstract url": "https://arxiv.org/abs/2401.12503",
        "title": "Small Language Model Meets with Reinforced Vision Vocabulary",
        "rating": "2",
        "keywords": [
            [
                "Vision Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI community. However, the relatively large number of parameters (more than 7B) of popular LVLMs makes it difficult to train and deploy on consumer GPUs, discouraging many researchers with limited resources. Imagine how cool it would be to experience all the features of current LVLMs on an old GTX1080ti (our only game card). Accordingly, we present Vary-toy in this report, a small-size Vary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we introduce an improved vision vocabulary, allowing the model to not only possess all features of Vary but also gather more generality. Specifically, we replace negative samples of natural images with positive sample data driven by object detection in the procedure of generating vision vocabulary, more sufficiently utilizing the capacity of the vocabulary network and enabling it to efficiently encode visual information corresponding to natural objects. For experiments, Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1% accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on the homepage.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12522",
        "abstract url": "https://arxiv.org/abs/2401.12522",
        "title": "BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) commonly employ autoregressive generation during inference, leading to high memory bandwidth demand and consequently extended latency. To mitigate this inefficiency, we present Bi-directional Tuning for lossless Acceleration (BiTA), an innovative method expediting LLMs via streamlined semi-autoregressive generation and draft verification. Inspired by the concept of prompt tuning, we enhance LLMs with a parameter-efficient design called bi-directional tuning for the capability in semi-autoregressive generation. Employing efficient tree-based decoding, the models perform draft candidate generation and verification in parallel, ensuring outputs identical to their autoregressive counterparts under greedy sampling. BiTA serves as a lightweight plug-in module, seamlessly boosting the inference efficiency of existing LLMs without requiring additional assistance models or incurring significant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat achieves a 2.7$\\times$ speedup on the MT-Bench benchmark. Extensive experiments confirm our method surpasses state-of-the-art acceleration techniques.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "An appendix has been included. Source code at https://github.com/linfeng93/BiTA"
    },
    {
        "paper id": "2401.12540",
        "abstract url": "https://arxiv.org/abs/2401.12540",
        "title": "DREditor: An Time-efficient Approach for Building a Domain-specific Dense Retrieval Model",
        "rating": "2",
        "keywords": [
            [
                "Time-efficient"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Deploying dense retrieval models efficiently is becoming increasingly important across various industries. This is especially true for enterprise search services, where customizing search engines to meet the time demands of different enterprises in different domains is crucial. Motivated by this, we develop a time-efficient approach called DREditor to edit the matching rule of an off-the-shelf dense retrieval model to suit a specific domain. This is achieved by directly calibrating the output embeddings of the model using an efficient and effective linear mapping. This mapping is powered by an edit operator that is obtained by solving a specially constructed least squares problem. Compared to implicit rule modification via long-time finetuning, our experimental results show that DREditor provides significant advantages on different domain-specific datasets, dataset sources, retrieval models, and computing devices. It consistently enhances time efficiency by 100-300 times while maintaining comparable or even superior retrieval performance. In a broader context, we take the first step to introduce a novel embedding calibration approach for the retrieval task, filling the technical blank in the current field of embedding calibration. This approach also paves the way for building domain-specific dense retrieval models efficiently and inexpensively.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": "15 pages, 6 figures, Codes are available at https://github.com/huangzichun/DREditor"
    },
    {
        "paper id": "2401.12902",
        "abstract url": "https://arxiv.org/abs/2401.12902",
        "title": "Facing the Elephant in the Room: Visual Prompt Tuning or Full Finetuning?",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As the scale of vision models continues to grow, the emergence of Visual Prompt Tuning (VPT) as a parameter-efficient transfer learning technique has gained attention due to its superior performance compared to traditional full-finetuning. However, the conditions favoring VPT (the ``when\") and the underlying rationale (the ``why\") remain unclear. In this paper, we conduct a comprehensive analysis across 19 distinct datasets and tasks. To understand the ``when\" aspect, we identify the scenarios where VPT proves favorable by two dimensions: task objectives and data distributions. We find that VPT is preferrable when there is 1) a substantial disparity between the original and the downstream task objectives (e.g., transitioning from classification to counting), or 2) a similarity in data distributions between the two tasks (e.g., both involve natural images). In exploring the ``why\" dimension, our results indicate VPT's success cannot be attributed solely to overfitting and optimization considerations. The unique way VPT preserves original features and adds parameters appears to be a pivotal factor. Our study provides insights into VPT's mechanisms, and offers guidance for its optimal utilization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "29 pages, 19 figures"
    },
    {
        "paper id": "2401.12915",
        "abstract url": "https://arxiv.org/abs/2401.12915",
        "title": "Red Teaming Visual Language Models",
        "rating": "2",
        "keywords": [
            [
                "Visual Language",
                "VLMs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language Models) to accept multimodal inputs. Since it has been verified that LLMs can be induced to generate harmful or inaccurate content through specific test cases (termed as Red Teaming), how VLMs perform in similar scenarios, especially with their combination of textual and visual inputs, remains a question. To explore this problem, we present a novel red teaming dataset RTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal jail-breaking, face fairness, etc) under 4 primary aspects (faithfulness, privacy, safety, fairness). Our RTVLM is the first red-teaming dataset to benchmark current VLMs in terms of these 4 different aspects. Detailed analysis shows that 10 prominent open-sourced VLMs struggle with the red teaming in different degrees and have up to 31% performance gap with GPT-4V. Additionally, we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning (SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLM test set, 13% in MM-Hal, and without noticeable decline in MM-Bench, overpassing other LLaVA-based models with regular alignment data. This reveals that current open-sourced VLMs still lack red teaming alignment. Our code and datasets will be open-source.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "Working in progress"
    },
    {
        "paper id": "2401.12520",
        "abstract url": "https://arxiv.org/abs/2401.12520",
        "title": "Key Information Retrieval to Classify the Unstructured Data Content of Preferential Trade Agreements",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "With the rapid proliferation of textual data, predicting long texts has emerged as a significant challenge in the domain of natural language processing. Traditional text prediction methods encounter substantial difficulties when grappling with long texts, primarily due to the presence of redundant and irrelevant information, which impedes the model's capacity to capture pivotal insights from the text. To address this issue, we introduce a novel approach to long-text classification and prediction. Initially, we employ embedding techniques to condense the long texts, aiming to diminish the redundancy therein. Subsequently,the Bidirectional Encoder Representations from Transformers (BERT) embedding method is utilized for text classification training. Experimental outcomes indicate that our method realizes considerable performance enhancements in classifying long texts of Preferential Trade Agreements. Furthermore, the condensation of text through embedding methods not only augments prediction accuracy but also substantially reduces computational complexity. Overall, this paper presents a strategy for long-text prediction, offering a valuable reference for researchers and engineers in the natural language processing sphere.",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "AI4TS Workshop@AAAI 2024 accepted publication"
    },
    {
        "paper id": "2401.12689",
        "abstract url": "https://arxiv.org/abs/2401.12689",
        "title": "Energy-based Automated Model Evaluation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real world applications. The Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels. Despite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost. In that regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that allows the AutoEval framework to be both more efficient and effective. The core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning. We further provide our theoretical insights by connecting the MDE with the classification loss. We provide extensive experiments across modalities, datasets and different architectural backbones to validate MDE's validity, together with its superiority compared with prior approaches. We also prove MDE's versatility by showing its seamless integration with large-scale models, and easy adaption to learning scenarios with noisy- or imbalanced- labels. Code and data are available: https://github.com/pengr/Energy_AutoEval",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "ICLR2024 poster paper"
    },
    {
        "paper id": "2401.12789",
        "abstract url": "https://arxiv.org/abs/2401.12789",
        "title": "Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In the era of large models, the autoregressive nature of decoding often results in latency serving as a significant bottleneck. We propose a non-autoregressive LM-fused ASR system that effectively leverages the parallelization capabilities of accelerator hardware. Our approach combines the Universal Speech Model (USM) and the PaLM 2 language model in per-segment scoring mode, achieving an average relative WER improvement across all languages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, our comprehensive ablation study analyzes key parameters such as LLM size, context length, vocabulary size, fusion methodology. For instance, we explore the impact of LLM size ranging from 128M to 340B parameters on ASR performance. This study provides valuable insights into the factors influencing the effectiveness of practical large-scale LM-fused speech recognition systems.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "ICASSP 2024"
    },
    {
        "paper id": "2401.12819",
        "abstract url": "https://arxiv.org/abs/2401.12819",
        "title": "Dynamic Layer Tying for Parameter-Efficient Transformers",
        "rating": "1.5",
        "keywords": [
            [
                "Parameter-Efficient"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the pursuit of reducing the number of trainable parameters in deep transformer networks, we employ Reinforcement Learning to dynamically select layers during training and tie them together. Every few iterations, the RL agent is asked whether to train each layer $i$ independently or to copy the weights of a previous layer $j<i$. This facilitates weight sharing, reduces the number of trainable parameters, and also serves as an effective regularization technique. Experimental evaluations validate that our model modestly outperforms the baseline transformer model with regard to perplexity and drastically reduces the number of trainable parameters. In particular, the memory consumption during training is up to one order of magnitude less than the conventional training method.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12863",
        "abstract url": "https://arxiv.org/abs/2401.12863",
        "title": "KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in natural language processing tasks by leveraging chain of thought (CoT) that enables step-by-step thinking. Extending LLMs with multimodal capabilities is the recent interest, but incurs computational cost and requires substantial hardware resources. To address these challenges, we propose KAM-CoT a framework that integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities for a comprehensive understanding of multimodal tasks. KAM-CoT adopts a two-stage training process with KG grounding to generate effective rationales and answers. By incorporating external knowledge from KGs during reasoning, the model gains a deeper contextual understanding reducing hallucinations and enhancing the quality of answers. This knowledge-augmented CoT reasoning empowers the model to handle questions requiring external context, providing more informed answers. Experimental findings show KAM-CoT outperforms the state-of-the-art methods. On the ScienceQA dataset, we achieve an average accuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by 10%. Remarkably, KAM-CoT achieves these results with only 280M trainable parameters at a time, demonstrating its cost-efficiency and effectiveness.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "AAAI 2024"
    },
    {
        "paper id": "2401.12925",
        "abstract url": "https://arxiv.org/abs/2401.12925",
        "title": "Emotion-Aware Contrastive Adaptation Network for Source-Free Cross-Corpus Speech Emotion Recognition",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Cross-corpus speech emotion recognition (SER) aims to transfer emotional knowledge from a labeled source corpus to an unlabeled corpus. However, prior methods require access to source data during adaptation, which is unattainable in real-life scenarios due to data privacy protection concerns. This paper tackles a more practical task, namely source-free cross-corpus SER, where a pre-trained source model is adapted to the target domain without access to source data. To address the problem, we propose a novel method called emotion-aware contrastive adaptation network (ECAN). The core idea is to capture local neighborhood information between samples while considering the global class-level adaptation. Specifically, we propose a nearest neighbor contrastive learning to promote local emotion consistency among features of highly similar samples. Furthermore, relying solely on nearest neighborhoods may lead to ambiguous boundaries between clusters. Thus, we incorporate supervised contrastive learning to encourage greater separation between clusters representing different emotions, thereby facilitating improved class-level adaptation. Extensive experiments indicate that our proposed ECAN significantly outperforms state-of-the-art methods under the source-free cross-corpus SER setting on several speech emotion corpora.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2401.12970",
        "abstract url": "https://arxiv.org/abs/2401.12970",
        "title": "Raidar: geneRative AI Detection viA Rewriting",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "We find that large language models (LLMs) are more likely to modify human-written text than AI-generated text when tasked with rewriting. This tendency arises because LLMs often perceive AI-generated text as high-quality, leading to fewer modifications. We introduce a method to detect AI-generated content by prompting LLMs to rewrite text and calculating the editing distance of the output. We dubbed our geneRative AI Detection viA Rewriting method Raidar. Raidar significantly improves the F1 detection scores of existing AI content detection models -- both academic and commercial -- across various domains, including News, creative writing, student essays, code, Yelp reviews, and arXiv papers, with gains of up to 29 points. Operating solely on word symbols without high-dimensional features, our method is compatible with black box LLMs, and is inherently robust on new content. Our results illustrate the unique imprint of machine-generated text through the lens of the machines themselves.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ICLR 2024, Large Language Models, Detection"
    },
    {
        "paper id": "2401.12975",
        "abstract url": "https://arxiv.org/abs/2401.12975",
        "title": "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Recent advances in high-fidelity virtual environments serve as one of the major driving forces for building intelligent embodied agents to perceive, reason and interact with the physical world. Typically, these environments remain unchanged unless agents interact with them. However, in real-world scenarios, agents might also face dynamically changing environments characterized by unexpected events and need to rapidly take action accordingly. To remedy this gap, we propose a new simulated embodied benchmark, called HAZARD, specifically designed to assess the decision-making abilities of embodied agents in dynamic situations. HAZARD consists of three unexpected disaster scenarios, including fire, flood, and wind, and specifically supports the utilization of large language models (LLMs) to assist common sense reasoning and decision-making. This benchmark enables us to evaluate autonomous agents' decision-making capabilities across various pipelines, including reinforcement learning (RL), rule-based, and search-based methods in dynamically changing environments. As a first step toward addressing this challenge using large language models, we further develop an LLM-based agent and perform an in-depth analysis of its promise and challenge of solving these challenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "ICLR 2024. The first two authors contributed equally to this work"
    },
    {
        "paper id": "2401.13129",
        "abstract url": "https://arxiv.org/abs/2401.13129",
        "title": "Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Accurately typing entity mentions from text segments is a fundamental task for various natural language processing applications. Many previous approaches rely on massive human-annotated data to perform entity typing. Nevertheless, collecting such data in highly specialized science and engineering domains (e.g., software engineering and security) can be time-consuming and costly, without mentioning the domain gaps between training and inference data if the model needs to be applied to confidential datasets. In this paper, we study the task of seed-guided fine-grained entity typing in science and engineering domains, which takes the name and a few seed entities for each entity type as the only supervision and aims to classify new entity mentions into both seen and unseen types (i.e., those without seed entities). To solve this problem, we propose SEType which first enriches the weak supervision by finding more entities for each seen type from an unlabeled corpus using the contextualized representations of pre-trained language models. It then matches the enriched entities to unlabeled text to get pseudo-labeled samples and trains a textual entailment model that can make inferences for both seen and unseen types. Extensive experiments on two datasets covering four domains demonstrate the effectiveness of SEType in comparison with various baselines.",
        "subjects": [
            "cs.CL",
            "cs.SE"
        ],
        "comment": "9 pages; Accepted to AAAI 2024 (Code: https://github.com/yuzhimanhua/SEType)"
    },
    {
        "paper id": "2401.13193",
        "abstract url": "https://arxiv.org/abs/2401.13193",
        "title": "Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Deep learning has made significant advances in computer vision, particularly in image classification tasks. Despite their high accuracy on training data, deep learning models often face challenges related to complexity and overfitting. One notable concern is that the model often relies heavily on a limited subset of filters for making predictions. This dependency can result in compromised generalization and an increased vulnerability to minor variations. While regularization techniques like weight decay, dropout, and data augmentation are commonly used to address this issue, they may not directly tackle the reliance on specific filters. Our observations reveal that the heavy reliance problem gets severe when slow-learning filters are deprived of learning opportunities due to fast-learning filters. Drawing inspiration from image augmentation research that combats over-reliance on specific image regions by removing and replacing parts of images, our idea is to mitigate the problem of over-reliance on strong filters by substituting highly activated features. To this end, we present a novel method called Catch-up Mix, which provides learning opportunities to a wide range of filters during training, focusing on filters that may lag behind. By mixing activation maps with relatively lower norms, Catch-up Mix promotes the development of more diverse representations and reduces reliance on a small subset of filters. Experimental results demonstrate the superiority of our method in various vision classification datasets, providing enhanced robustness.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Published at AAAI2024, Equal contribution of first two authors"
    },
    {
        "paper id": "2402.01694",
        "abstract url": "https://arxiv.org/abs/2402.01694",
        "title": "ARGS: Alignment as Reward-Guided Search",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Aligning large language models with human objectives is paramount, yet common approaches including RLHF suffer from unstable and resource-intensive training. In response to this challenge, we introduce ARGS, Alignment as Reward-Guided Search, a novel framework that integrates alignment into the decoding process, eliminating the need for expensive RL training. By adjusting the model's probabilistic predictions using a reward signal, ARGS generates texts with semantic diversity while being aligned with human preferences, offering a promising and flexible solution for aligning language models. Notably, ARGS demonstrates consistent enhancements in average reward compared to baselines across diverse alignment tasks and various model dimensions. For example, under the same greedy-based decoding strategy, our method improves the average reward by 19.56% relative to the baseline and secures a preference or tie score of 64.33% in GPT-4 evaluation. We believe that our framework, emphasizing decoding-time alignment, paves the way for more responsive language models in the future. Code is publicly available at: \\url{https://github.com/deeplearning-wisc/args}.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2401.12491",
        "abstract url": "https://arxiv.org/abs/2401.12491",
        "title": "Assessing and Understanding Creativity in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In the field of natural language processing, the rapid development of large language model (LLM) has attracted more and more attention. LLMs have shown a high level of creativity in various tasks, but the methods for assessing such creativity are inadequate. The assessment of LLM creativity needs to consider differences from humans, requiring multi-dimensional measurement while balancing accuracy and efficiency. This paper aims to establish an efficient framework for assessing the level of creativity in LLMs. By adapting the modified Torrance Tests of Creative Thinking, the research evaluates the creative performance of various LLMs across 7 tasks, emphasizing 4 criteria including Fluency, Flexibility, Originality, and Elaboration. In this context, we develop a comprehensive dataset of 700 questions for testing and an LLM-based evaluation method. In addition, this study presents a novel analysis of LLMs' responses to diverse prompts and role-play situations. We found that the creativity of LLMs primarily falls short in originality, while excelling in elaboration. Besides, the use of prompts and the role-play settings of the model significantly influence creativity. Additionally, the experimental results also indicate that collaboration among multiple LLMs can enhance originality. Notably, our findings reveal a consensus between human evaluations and LLMs regarding the personality traits that influence creativity. The findings underscore the significant impact of LLM design on creativity and bridges artificial intelligence and human creativity, offering insights into LLMs' creativity and potential applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12492",
        "abstract url": "https://arxiv.org/abs/2401.12492",
        "title": "Comparing Pre-trained Human Language Models: Is it Better with Human Context as Groups, Individual Traits, or Both?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Incorporating human context into language models is the next frontier for human-centered natural language processing. Currently, two pre-training methods exist: group-wise attributes (e.g., over-45-year-olds) or individual traits. Group attributes are coarse -- not all 45-year-olds write the same way -- while modeling individual traits allows for a more personalized representation, but requires more complex modeling and data. So far, it is unclear which pre-training approach benefits what tasks. We compare pre-training models with human context via 1) group attributes, 2) individual users, and 3) a combined approach on 5 user- and document-level tasks. We find that pre-training with both group and individual features significantly improves the two user-level regression tasks like age estimation and personality assessment. Pre-training on individual users significantly improves the three document-level classification tasks like stance and topic detection. It even does well for downstream tasks without historical user data. Our results suggest both approaches have specific use cases, opening new avenues for human-centered language modeling.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12497",
        "abstract url": "https://arxiv.org/abs/2401.12497",
        "title": "Building Minimal and Reusable Causal State Abstractions for Reinforcement Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Two desiderata of reinforcement learning (RL) algorithms are the ability to learn from relatively little experience and the ability to learn policies that generalize to a range of problem specifications. In factored state spaces, one approach towards achieving both goals is to learn state abstractions, which only keep the necessary variables for learning the tasks at hand. This paper introduces Causal Bisimulation Modeling (CBM), a method that learns the causal relationships in the dynamics and reward functions for each task to derive a minimal, task-specific abstraction. CBM leverages and improves implicit modeling to train a high-fidelity causal dynamics model that can be reused for all tasks in the same environment. Empirical validation on manipulation environments and Deepmind Control Suite reveals that CBM's learned implicit dynamics models identify the underlying causal relationships and state abstractions more accurately than explicit ones. Furthermore, the derived state abstractions allow a task learner to achieve near-oracle levels of sample efficiency and outperform baselines on all tasks.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "Accepted at AAAI24"
    },
    {
        "paper id": "2401.12511",
        "abstract url": "https://arxiv.org/abs/2401.12511",
        "title": "Convolutional Initialization for Data-Efficient Vision Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Training vision transformer networks on small datasets poses challenges. In contrast, convolutional neural networks (CNNs) can achieve state-of-the-art performance by leveraging their architectural inductive bias. In this paper, we investigate whether this inductive bias can be reinterpreted as an initialization bias within a vision transformer network. Our approach is motivated by the finding that random impulse filters can achieve almost comparable performance to learned filters in CNNs. We introduce a novel initialization strategy for transformer networks that can achieve comparable performance to CNNs on small datasets while preserving its architectural flexibility.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 9 figures, 8 tables"
    },
    {
        "paper id": "2401.12513",
        "abstract url": "https://arxiv.org/abs/2401.12513",
        "title": "Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Purpose: The capacity to isolate and recognize individual characters from facsimile images of papyrus manuscripts yields rich opportunities for digital analysis. For this reason the `ICDAR 2023 Competition on Detection and Recognition of Greek Letters on Papyri' was held as part of the 17th International Conference on Document Analysis and Recognition. This paper discusses our submission to the competition. Methods: We used an ensemble of YOLOv8 models to detect and classify individual characters and employed two different approaches for refining the character predictions, including a transformer based DeiT approach and a ResNet-50 model trained on a large corpus of unlabelled data using SimCLR, a self-supervised learning method. Results: Our submission won the recognition challenge with a mAP of 42.2%, and was runner-up in the detection challenge with a mean average precision (mAP) of 51.4%. At the more relaxed intersection over union threshold of 0.5, we achieved the highest mean average precision and mean average recall results for both detection and classification. Conclusion: The results demonstrate the potential for these techniques for automated character recognition on historical manuscripts. We ran the prediction pipeline on more than 4,500 images from the Oxyrhynchus Papyri to illustrate the utility of our approach, and we release the results publicly in multiple formats.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12576",
        "abstract url": "https://arxiv.org/abs/2401.12576",
        "title": "LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools and Self-Explanations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Interpretability tools that offer explanations in the form of a dialogue have demonstrated their efficacy in enhancing users' understanding (Slack et al., 2023; Shen et al., 2023), as one-off explanations may fall short in providing sufficient information to the user. Current solutions for dialogue-based explanations, however, often require external tools and modules and are not easily transferable to tasks they were not designed for. With LLMCheckup, we present an easily accessible tool that allows users to chat with any state-of-the-art large language model (LLM) about its behavior. We enable LLMs to generate explanations and perform user intent recognition without fine-tuning, by connecting them with a broad spectrum of Explainable AI (XAI) methods, including white-box explainability tools such as feature attributions, and self-explanations (e.g., for rationale generation). LLM-based (self-)explanations are presented as an interactive dialogue that supports follow-up questions and generates suggestions. LLMCheckupprovides tutorials for operations available in the system, catering to individuals with varying levels of expertise in XAI and supporting multiple input modalities. We introduce a new parsing strategy that substantially enhances the user intent recognition accuracy of the LLM. Finally, we showcase LLMCheckup for the tasks of fact checking and commonsense question answering.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to NAACL 2024 HCI+NLP workshop; camera-ready version"
    },
    {
        "paper id": "2401.12585",
        "abstract url": "https://arxiv.org/abs/2401.12585",
        "title": "SLANG: New Concept Comprehension of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The dynamic nature of language, particularly evident in the realm of slang and memes on the Internet, poses serious challenges to the adaptability of large language models (LLMs). Traditionally anchored to static datasets, these models often struggle to keep up with the rapid linguistic evolution characteristic of online communities. This research aims to bridge this gap by enhancing LLMs' comprehension of the evolving new concepts on the Internet, without the high cost of continual retraining. In pursuit of this goal, we introduce $\\textbf{SLANG}$, a benchmark designed to autonomously integrate novel data and assess LLMs' ability to comprehend emerging concepts, alongside $\\textbf{FOCUS}$, an approach uses causal inference to enhance LLMs to understand new phrases and their colloquial context. Our benchmark and approach involves understanding real-world instances of linguistic shifts, serving as contextual beacons, to form more precise and contextually relevant connections between newly emerging expressions and their meanings. The empirical analysis shows that our causal inference-based approach outperforms the baseline methods in terms of precision and relevance in the comprehension of Internet slang and memes.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12600",
        "abstract url": "https://arxiv.org/abs/2401.12600",
        "title": "EEND-M2F: Masked-attention mask transformers for speaker diarization",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "In this paper, we make the explicit connection between image segmentation methods and end-to-end diarization methods. From these insights, we propose a novel, fully end-to-end diarization model, EEND-M2F, based on the Mask2Former architecture. Speaker representations are computed in parallel using a stack of transformer decoders, in which irrelevant frames are explicitly masked from the cross attention using predictions from previous layers. EEND-M2F is lightweight, efficient, and truly end-to-end, as it does not require any additional diarization, speaker verification, or segmentation models to run, nor does it require running any clustering algorithms. Our model achieves state-of-the-art performance on several public datasets, such as AMI, AliMeeting and RAMC. Most notably our DER of 16.07% on DIHARD-III is the first major improvement upon the challenge winning system.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "14 pages, 2 figures"
    },
    {
        "paper id": "2401.12609",
        "abstract url": "https://arxiv.org/abs/2401.12609",
        "title": "Fast Semi-supervised Unmixing using Non-convex Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce a novel linear model tailored for semisupervised/library-based unmixing. Our model incorporates considerations for library mismatch while enabling the enforcement of the abundance sum-to-one constraint (ASC). Unlike conventional sparse unmixing methods, this model involves nonconvex optimization, presenting significant computational challenges. We demonstrate the efficacy of Alternating Methods of Multipliers (ADMM) in cyclically solving these intricate problems. We propose two semisupervised unmixing approaches, each relying on distinct priors applied to the new model in addition to the ASC: sparsity prior and convexity constraint. Our experimental results validate that enforcing the convexity constraint outperforms the sparsity prior for the endmember library. These results are corroborated across three simulated datasets (accounting for spectral variability and varying pixel purity levels) and the Cuprite dataset. Additionally, our comparison with conventional sparse unmixing methods showcases considerable advantages of our proposed model, which entails nonconvex optimization. Notably, our implementations of the proposed algorithms-fast semisupervised unmixing (FaSUn) and sparse unmixing using soft-shrinkage (SUnS)-prove considerably more efficient than traditional sparse unmixing methods. SUnS and FaSUn were implemented using PyTorch and provided in a dedicated Python package called Fast Semisupervised Unmixing (FUnmix), which is open-source and available at https://github.com/BehnoodRasti/FUnmix",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12617",
        "abstract url": "https://arxiv.org/abs/2401.12617",
        "title": "The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "In continual learning, catastrophic forgetting is affected by multiple aspects of the tasks. Previous works have analyzed separately how forgetting is affected by either task similarity or overparameterization. In contrast, our paper examines how task similarity and overparameterization jointly affect forgetting in an analyzable model. Specifically, we focus on two-task continual linear regression, where the second task is a random orthogonal transformation of an arbitrary first task (an abstraction of random permutation tasks). We derive an exact analytical expression for the expected forgetting - and uncover a nuanced pattern. In highly overparameterized models, intermediate task similarity causes the most forgetting. However, near the interpolation threshold, forgetting decreases monotonically with the expected task similarity. We validate our findings with linear regression on synthetic data, and with neural networks on established permutation task benchmarks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to the Twelfth International Conference on Learning Representations (ICLR 2024)"
    },
    {
        "paper id": "2401.12631",
        "abstract url": "https://arxiv.org/abs/2401.12631",
        "title": "A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We respond to the recent paper by Makelov et al. (2023), which reviews subspace interchange intervention methods like distributed alignment search (DAS; Geiger et al. 2023) and claims that these methods potentially cause \"interpretability illusions\". We first review Makelov et al. (2023)'s technical notion of what an \"interpretability illusion\" is, and then we show that even intuitive and desirable explanations can qualify as illusions in this sense. As a result, their method of discovering \"illusions\" can reject explanations they consider \"non-illusory\". We then argue that the illusions Makelov et al. (2023) see in practice are artifacts of their training and evaluation paradigms. We close by emphasizing that, though we disagree with their core characterization, Makelov et al. (2023)'s examples and discussion have undoubtedly pushed the field of interpretability forward.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "20 pages, 14 figures"
    },
    {
        "paper id": "2401.12656",
        "abstract url": "https://arxiv.org/abs/2401.12656",
        "title": "MoodLoopGP: Generating Emotion-Conditioned Loop Tablature Music with Multi-Granular Features",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Loopable music generation systems enable diverse applications, but they often lack controllability and customization capabilities. We argue that enhancing controllability can enrich these models, with emotional expression being a crucial aspect for both creators and listeners. Hence, building upon LooperGP, a loopable tablature generation model, this paper explores endowing systems with control over conveyed emotions. To enable such conditional generation, we propose integrating musical knowledge by utilizing multi-granular semantic and musical features during model training and inference. Specifically, we incorporate song-level features (Emotion Labels, Tempo, and Mode) and bar-level features (Tonal Tension) together to guide emotional expression. Through algorithmic and human evaluations, we demonstrate the approach's effectiveness in producing music conveying two contrasting target emotions, happiness and sadness. An ablation study is also conducted to clarify the contributing factors behind our approach's results.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "This preprint is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). The Version of Record of this contribution is published in Proceedings of EvoMUSART: International Conference on Computational Intelligence in Music, Sound, Art and Design (Part of EvoStar) 2024"
    },
    {
        "paper id": "2401.12665",
        "abstract url": "https://arxiv.org/abs/2401.12665",
        "title": "ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, foundational models such as CLIP and SAM have shown promising performance for the task of Zero-Shot Anomaly Segmentation (ZSAS). However, either CLIP-based or SAM-based ZSAS methods still suffer from non-negligible key drawbacks: 1) CLIP primarily focuses on global feature alignment across different inputs, leading to imprecise segmentation of local anomalous parts; 2) SAM tends to generate numerous redundant masks without proper prompt constraints, resulting in complex post-processing requirements. In this work, we innovatively propose a CLIP and SAM collaboration framework called ClipSAM for ZSAS. The insight behind ClipSAM is to employ CLIP's semantic understanding capability for anomaly localization and rough segmentation, which is further used as the prompt constraints for SAM to refine the anomaly segmentation results. In details, we introduce a crucial Unified Multi-scale Cross-modal Interaction (UMCI) module for interacting language with visual features at multiple scales of CLIP to reason anomaly positions. Then, we design a novel Multi-level Mask Refinement (MMR) module, which utilizes the positional information as multi-level prompts for SAM to acquire hierarchical levels of masks and merges them. Extensive experiments validate the effectiveness of our approach, achieving the optimal segmentation performance on the MVTec-AD and VisA datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "17 pages,17 figures"
    },
    {
        "paper id": "2401.12736",
        "abstract url": "https://arxiv.org/abs/2401.12736",
        "title": "Shift-ConvNets: Small Convolutional Kernel with Large Kernel Effects",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent studies reveal that the remarkable performance of Vision transformers (ViTs) benefits from large receptive fields. For this reason, the large convolutional kernel design becomes an ideal solution to make Convolutional Neural Networks (CNNs) great again. However, the typical large convolutional kernels turn out to be hardware-unfriendly operators, resulting in discount compatibility of various hardware platforms. Thus, it is unwise to simply enlarge the convolutional kernel size. In this paper, we reveal that small convolutional kernels and convolution operations can achieve the closing effects of large kernel sizes. Then, we propose a shift-wise operator that ensures the CNNs capture long-range dependencies with the help of the sparse mechanism, while remaining hardware-friendly. Experimental results show that our shift-wise operator significantly improves the accuracy of a regular CNN while markedly reducing computational requirements. On the ImageNet-1k, our shift-wise enhanced CNN model outperforms the state-of-the-art models. Code & models at https://github.com/lidc54/shift-wiseConv.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12743",
        "abstract url": "https://arxiv.org/abs/2401.12743",
        "title": "Correlation-Embedded Transformer Tracking: A Single-Branch Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Developing robust and discriminative appearance models has been a long-standing research challenge in visual object tracking. In the prevalent Siamese-based paradigm, the features extracted by the Siamese-like networks are often insufficient to model the tracked targets and distractor objects, thereby hindering them from being robust and discriminative simultaneously. While most Siamese trackers focus on designing robust correlation operations, we propose a novel single-branch tracking framework inspired by the transformer. Unlike the Siamese-like feature extraction, our tracker deeply embeds cross-image feature correlation in multiple layers of the feature network. By extensively matching the features of the two images through multiple layers, it can suppress non-target features, resulting in target-aware feature extraction. The output features can be directly used for predicting target locations without additional correlation steps. Thus, we reformulate the two-branch Siamese tracking as a conceptually simple, fully transformer-based Single-Branch Tracking pipeline, dubbed SBT. After conducting an in-depth analysis of the SBT baseline, we summarize many effective design principles and propose an improved tracker dubbed SuperSBT. SuperSBT adopts a hierarchical architecture with a local modeling layer to enhance shallow-level features. A unified relation modeling is proposed to remove complex handcrafted layer pattern designs. SuperSBT is further improved by masked image modeling pre-training, integrating temporal modeling, and equipping with dedicated prediction heads. Thus, SuperSBT outperforms the SBT baseline by 4.7%,3.0%, and 4.5% AUC scores in LaSOT, TrackingNet, and GOT-10K. Notably, SuperSBT greatly raises the speed of SBT from 37 FPS to 81 FPS. Extensive experiments show that our method achieves superior results on eight VOT benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2401.12756",
        "abstract url": "https://arxiv.org/abs/2401.12756",
        "title": "What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The knowledge encapsulated in a model is the core factor determining its final performance on downstream tasks. Much research in NLP has focused on efficient methods for storing and adapting different types of knowledge, e.g., in dedicated modularized structures, and on how to effectively combine these, e.g., by learning additional parameters. However, given the many possible options, a thorough understanding of the mechanisms involved in these compositions is missing, and hence it remains unclear which strategies to utilize. To address this research gap, we propose a novel framework for zero-shot module composition, which encompasses existing and some novel variations for selecting, weighting, and combining parameter modules under a single unified notion. Focusing on the scenario of domain knowledge and adapter layers, our framework provides a systematic unification of concepts, allowing us to conduct the first comprehensive benchmarking study of various zero-shot knowledge composition strategies. In particular, we test two module combination methods and five selection and weighting strategies for their effectiveness and efficiency in an extensive experimental setup. Our results highlight the efficacy of ensembling but also hint at the power of simple though often-ignored weighting methods. Further in-depth analyses allow us to understand the role of weighting vs. top-k selection, and show that, to a certain extent, the performance of adapter composition can even be predicted.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted to Findings of the ACL: EACL 2024"
    },
    {
        "paper id": "2401.12794",
        "abstract url": "https://arxiv.org/abs/2401.12794",
        "title": "Benchmarking LLMs via Uncertainty Quantification",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The proliferation of open-source Large Language Models (LLMs) from various institutions has highlighted the urgent need for comprehensive evaluation methods. However, current evaluation platforms, such as the widely recognized HuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty, which is vital for thoroughly assessing LLMs. To bridge this gap, we introduce a new benchmarking approach for LLMs that integrates uncertainty quantification. Our examination involves eight LLMs (LLM series) spanning five representative natural language processing tasks. Our findings reveal that: I) LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs may display greater uncertainty compared to their smaller counterparts; and III) Instruction-finetuning tends to increase the uncertainty of LLMs. These results underscore the significance of incorporating uncertainty in the evaluation of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "25 pages, preprints"
    },
    {
        "paper id": "2401.12820",
        "abstract url": "https://arxiv.org/abs/2401.12820",
        "title": "DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained Self-supervised Vision Transformer",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Successive proposals of several self-supervised training schemes continue to emerge, taking one step closer to developing a universal foundation model. In this process, the unsupervised downstream tasks are recognized as one of the evaluation methods to validate the quality of visual features learned with a self-supervised training scheme. However, unsupervised dense semantic segmentation has not been explored as a downstream task, which can utilize and evaluate the quality of semantic information introduced in patch-level feature representations during self-supervised training of a vision transformer. Therefore, this paper proposes a novel data-driven approach for unsupervised semantic segmentation (DatUS^2) as a downstream task. DatUS^2 generates semantically consistent and dense pseudo annotate segmentation masks for the unlabeled image dataset without using any visual-prior or synchronized data. We compare these pseudo-annotated segmentation masks with ground truth masks for evaluating recent self-supervised training schemes to learn shared semantic properties at the patch level and discriminative semantic properties at the segment level. Finally, we evaluate existing state-of-the-art self-supervised training schemes with our proposed downstream task, i.e., DatUS^2. Also, the best version of DatUS^2 outperforms the existing state-of-the-art method for the unsupervised dense semantic segmentation task with 15.02% MiOU and 21.47% Pixel accuracy on the SUIM dataset. It also achieves a competitive level of accuracy for a large-scale and complex dataset, i.e., the COCO dataset.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "The manuscript contains 13 pages, 9 figures and 7 tables"
    },
    {
        "paper id": "2401.12826",
        "abstract url": "https://arxiv.org/abs/2401.12826",
        "title": "Digital Twin-Based Network Management for Better QoE in Multicast Short Video Streaming",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Multicast short video streaming can enhance bandwidth utilization by enabling simultaneous video transmission to multiple users over shared wireless channels. The existing network management schemes mainly rely on the sequential buffering principle and general quality of experience (QoE) model, which may deteriorate QoE when users' swipe behaviors exhibit distinct spatiotemporal variation. In this paper, we propose a digital twin (DT)-based network management scheme to enhance QoE. Firstly, user status emulated by the DT is utilized to estimate the transmission capabilities and watching probability distributions of sub-multicast groups (SMGs) for an adaptive segment buffering. The SMGs' buffers are aligned to the unique virtual buffers managed by the DT for a fine-grained buffer update. Then, a multicast QoE model consisting of rebuffering time, video quality, and quality variation is developed, by considering the mutual influence of segment buffering among SMGs. Finally, a joint optimization problem of segment version selection and slot division is formulated to maximize QoE. To efficiently solve the problem, a data-model-driven algorithm is proposed by integrating a convex optimization method and a deep reinforcement learning algorithm. Simulation results based on the real-world dataset demonstrate that the proposed DT-based network management scheme outperforms benchmark schemes in terms of QoE improvement.",
        "subjects": [
            "cs.NI",
            "eess.IV"
        ],
        "comment": "13 pages, 12 figures"
    },
    {
        "paper id": "2401.12873",
        "abstract url": "https://arxiv.org/abs/2401.12873",
        "title": "Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Insufficient modeling of human preferences within the reward model is a major obstacle for leveraging human feedback to improve translation quality. Fortunately, quality estimation (QE), which predicts the quality of a given translation without reference, has achieved impressive alignment with human evaluations in the last two years. In this work, we investigate the potential of employing the QE model as the reward model to predict human preferences for feedback training. We first identify the overoptimization problem during QE-based feedback training, manifested as an increase in reward while translation quality declines. We examine the problem and argue that the vulnerability of the QE model might lead to high rewards for incorrect translations, resulting in overoptimization and error propagation. To address the problem, we adopt a simple yet effective method that uses heuristic rules to detect the incorrect translations and assigns a penalty term to the reward scores of them. Experimental results show that the proposed QE-based feedback training achieves consistent and significant improvements across various settings, further verified through human preference studies. Our subsequent analysis demonstrates the high data efficiency of the proposed QE-based feedback training: it outperforms systems using larger parallel corpora by a small amount of monolingual data. Our code is available at: https://github.com/zwhe99/FeedbackMT",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "NAACL 2024"
    },
    {
        "paper id": "2401.12913",
        "abstract url": "https://arxiv.org/abs/2401.12913",
        "title": "Advancing Glitch Classification in Gravity Spy: Multi-view Fusion with Attention-based Machine Learning for Advanced LIGO's Fourth Observing Run",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "The first successful detection of gravitational waves by ground-based observatories, such as the Laser Interferometer Gravitational-Wave Observatory (LIGO), marked a revolutionary breakthrough in our comprehension of the Universe. However, due to the unprecedented sensitivity required to make such observations, gravitational-wave detectors also capture disruptive noise sources called glitches, potentially masking or appearing as gravitational-wave signals themselves. To address this problem, a community-science project, Gravity Spy, incorporates human insight and machine learning to classify glitches in LIGO data. The machine learning classifier, integrated into the project since 2017, has evolved over time to accommodate increasing numbers of glitch classes. Despite its success, limitations have arisen in the ongoing LIGO fourth observing run (O4) due to its architecture's simplicity, which led to poor generalization and inability to handle multi-time window inputs effectively. We propose an advanced classifier for O4 glitches. Our contributions include evaluating fusion strategies for multi-time window inputs, using label smoothing to counter noisy labels, and enhancing interpretability through attention module-generated weights. This development seeks to enhance glitch classification, aiding in the ongoing exploration of gravitational-wave phenomena.",
        "subjects": [
            "gr-qc",
            "astro-ph.IM",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12941",
        "abstract url": "https://arxiv.org/abs/2401.12941",
        "title": "Multicultural Name Recognition For Previously Unseen Names",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "State of the art Named Entity Recognition (NER) models have achieved an impressive ability to extract common phrases from text that belong to labels such as location, organization, time, and person. However, typical NER systems that rely on having seen a specific entity in their training data in order to label an entity perform poorly on rare or unseen entities ta in order to label an entity perform poorly on rare or unseen entities (Derczynski et al., 2017). This paper attempts to improve recognition of person names, a diverse category that can grow any time someone is born or changes their name. In order for downstream tasks to not exhibit bias based on cultural background, a model should perform well on names from a variety of backgrounds. In this paper I experiment with the training data and input structure of an English Bi-LSTM name recognition model. I look at names from 103 countries to compare how well the model performs on names from different cultures, specifically in the context of a downstream task where extracted names will be matched to information on file. I find that a model with combined character and word input outperforms word-only models and may improve on accuracy compared to classical NER models that are not geared toward identifying unseen entity values.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2401.12947",
        "abstract url": "https://arxiv.org/abs/2401.12947",
        "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models' behavior. The framework includes a representation that captures the general \\textit{syntax} of structural recursion, coupled with two different frameworks for understanding their \\textit{semantics} -- one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture. With our framework as a powerful conceptual tool, we identify different issues under various set-ups. The models trained to emulate recursive computations cannot fully capture the recursion yet instead fit short-cut algorithms and thus cannot solve certain edge cases that are under-represented in the training distribution. In addition, it is difficult for state-of-the-art large language models (LLMs) to mine recursive rules from in-context demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating reduction (step-wise computation) of the recursive function.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.FL",
            "cs.LO",
            "cs.PL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2305.14699"
    },
    {
        "paper id": "2401.12954",
        "abstract url": "https://arxiv.org/abs/2401.12954",
        "title": "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce meta-prompting, an effective scaffolding technique designed to enhance the functionality of language models (LMs). This approach transforms a single LM into a multi-faceted conductor, adept at managing and integrating multiple independent LM queries. By employing high-level instructions, meta-prompting guides the LM to break down complex tasks into smaller, more manageable subtasks. These subtasks are then handled by distinct \"expert\" instances of the same LM, each operating under specific, tailored instructions. Central to this process is the LM itself, in its role as the conductor, which ensures seamless communication and effective integration of the outputs from these expert models. It additionally employs its inherent critical thinking and robust verification processes to refine and authenticate the end result. This collaborative prompting approach empowers a single LM to simultaneously act as a comprehensive orchestrator and a panel of diverse experts, significantly enhancing its performance across a wide array of tasks. The zero-shot, task-agnostic nature of meta-prompting greatly simplifies user interaction by obviating the need for detailed, task-specific instructions. Furthermore, our research demonstrates the seamless integration of external tools, such as a Python interpreter, into the meta-prompting framework, thereby broadening its applicability and utility. Through rigorous experimentation with GPT-4, we establish the superiority of meta-prompting over conventional scaffolding methods: When averaged across all tasks, including the Game of 24, Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented with a Python interpreter functionality, surpasses standard prompting by 17.1%, expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "https://github.com/suzgunmirac/meta-prompting"
    },
    {
        "paper id": "2401.12963",
        "abstract url": "https://arxiv.org/abs/2401.12963",
        "title": "AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents",
        "rating": "1",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multiple buildings and collecting 77k real robot episodes via both teleoperation and autonomous robot policies. We experimentally show that such \"in-the-wild\" data collected by AutoRT is significantly more diverse, and that AutoRT's use of LLMs allows for instruction following data collection robots that can align to human preferences.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "26 pages, 9 figures"
    },
    {
        "paper id": "2401.12972",
        "abstract url": "https://arxiv.org/abs/2401.12972",
        "title": "On the Efficacy of Text-Based Input Modalities for Action Anticipation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Although the task of anticipating future actions is highly uncertain, information from additional modalities help to narrow down plausible action choices. Each modality provides different environmental context for the model to learn from. While previous multi-modal methods leverage information from modalities such as video and audio, we primarily explore how text inputs for actions and objects can also enable more accurate action anticipation. Therefore, we propose a Multi-modal Anticipative Transformer (MAT), an attention-based video transformer architecture that jointly learns from multi-modal features and text captions. We train our model in two-stages, where the model first learns to predict actions in the video clip by aligning with captions, and during the second stage, we fine-tune the model to predict future actions. Compared to existing methods, MAT has the advantage of learning additional environmental context from two kinds of text inputs: action descriptions during the pre-training stage, and the text inputs for detected objects and actions during modality feature fusion. Through extensive experiments, we evaluate the effectiveness of the pre-training stage, and show that our model outperforms previous methods on all datasets. In addition, we examine the impact of object and action information obtained via text and perform extensive ablations. We evaluate the performance on on three datasets: EpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that text descriptions do indeed aid in more effective action anticipation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12973",
        "abstract url": "https://arxiv.org/abs/2401.12973",
        "title": "In-Context Language Learning: Architectures and Algorithms",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large-scale neural language models exhibit a remarkable capacity for in-context learning (ICL): they can infer novel functions from datasets provided as input. Most of our current understanding of when and how ICL arises comes from LMs trained on extremely simple learning problems like linear regression and associative recall. There remains a significant gap between these model problems and the \"real\" ICL exhibited by LMs trained on large text corpora, which involves not just retrieval and function approximation but free-form generation of language and other structured outputs. In this paper, we study ICL through the lens of a new family of model problems we term in context language learning (ICLL). In ICLL, LMs are presented with a set of strings from a formal language, and must generate additional strings from the same language. We focus on in-context learning of regular languages generated by random finite automata. We evaluate a diverse set of neural sequence models (including several RNNs, Transformers, and state-space model variants) on regular ICLL tasks, aiming to answer three questions: (1) Which model classes are empirically capable of ICLL? (2) What algorithmic solutions do successful models implement to perform ICLL? (3) What architectural changes can improve ICLL in less performant models? We first show that Transformers significantly outperform neural sequence models with recurrent or convolutional representations on ICLL tasks. Next, we provide evidence that their ability to do so relies on specialized \"n-gram heads\" (higher-order variants of induction heads) that compute input-conditional next-token distributions. Finally, we show that hard-wiring these heads into neural models improves performance not just on ICLL, but natural language modeling -- improving the perplexity of 340M-parameter models by up to 1.14 points (6.7%) on the SlimPajama dataset.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Fixes a typo in the title, and adds additional references"
    },
    {
        "paper id": "2401.13051",
        "abstract url": "https://arxiv.org/abs/2401.13051",
        "title": "PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Segment Anything Model (SAM) has exhibited outstanding performance in various image segmentation tasks. Despite being trained with over a billion masks, SAM faces challenges in mask prediction quality in numerous scenarios, especially in real-world contexts. In this paper, we introduce a novel prompt-driven adapter into SAM, namely Prompt Adapter Segment Anything Model (PA-SAM), aiming to enhance the segmentation mask quality of the original SAM. By exclusively training the prompt adapter, PA-SAM extracts detailed information from images and optimizes the mask decoder feature at both sparse and dense prompt levels, improving the segmentation performance of SAM to produce high-quality masks. Experimental results demonstrate that our PA-SAM outperforms other SAM-based methods in high-quality, zero-shot, and open-set segmentation. We're making the source code and models available at https://github.com/xzz2/pa-sam.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "Code is available at https://github.com/xzz2/pa-sam"
    },
    {
        "paper id": "2401.13060",
        "abstract url": "https://arxiv.org/abs/2401.13060",
        "title": "TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks A and B. To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs. Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks. To identify unanswerable questions, we propose using a thresholding mechanism. Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13085",
        "abstract url": "https://arxiv.org/abs/2401.13085",
        "title": "IndiText Boost: Text Augmentation for Low Resource India Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Text Augmentation is an important task for low-resource languages. It helps deal with the problem of data scarcity. A data augmentation strategy is used to deal with the problem of data scarcity. Through the years, much work has been done on data augmentation for the English language. In contrast, very less work has been done on Indian languages. This is contrary to the fact that data augmentation is used to deal with data scarcity. In this work, we focus on implementing techniques like Easy Data Augmentation, Back Translation, Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for text classification on different languages. We focus on 6 Indian languages namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to our knowledge, no such work exists for text augmentation on Indian languages. We carry out binary as well as multi-class text classification to make our results more comparable. We get surprising results as basic data augmentation techniques surpass LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13086",
        "abstract url": "https://arxiv.org/abs/2401.13086",
        "title": "Towards Trustable Language Models: Investigating Information Quality of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2401.13087",
        "abstract url": "https://arxiv.org/abs/2401.13087",
        "title": "Open-source data pipeline for street-view images: a case study on community mobility during COVID-19 pandemic",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Street View Images (SVI) are a common source of valuable data for researchers. Researchers have used SVI data for estimating pedestrian volumes, demographic surveillance, and to better understand built and natural environments in cityscapes. However, the most common source of publicly available SVI data is Google Street View. Google Street View images are collected infrequently, making temporal analysis challenging, especially in low population density areas. Our main contribution is the development of an open-source data pipeline for processing 360-degree video recorded from a car-mounted camera. The video data is used to generate SVIs, which then can be used as an input for temporal analysis. We demonstrate the use of the pipeline by collecting a SVI dataset over a 38-month longitudinal survey of Seattle, WA, USA during the COVID-19 pandemic. The output of our pipeline is validated through statistical analyses of pedestrian traffic in the images. We confirm known results in the literature and provide new insights into outdoor pedestrian traffic patterns. This study demonstrates the feasibility and value of collecting and using SVI for research purposes beyond what is possible with currently available SVI data. Limitations and future improvements on the data pipeline and case study are also discussed.",
        "subjects": [
            "cs.CV",
            "stat.AP"
        ],
        "comment": "16 pages, 4 figures, two tables. Martell and Terry are equally contributing first authors"
    },
    {
        "paper id": "2401.13112",
        "abstract url": "https://arxiv.org/abs/2401.13112",
        "title": "DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorithm is accompanied by an analysis of its convergence rate. The efficacy of our proposed method is substantiated through a series of illustrative case studies, highlighting its potential in providing deep insights into decision-making models.",
        "subjects": [
            "cs.AI",
            "stat.ML"
        ],
        "comment": "Under review in ICML 2024"
    },
    {
        "paper id": "2401.13133",
        "abstract url": "https://arxiv.org/abs/2401.13133",
        "title": "Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace: Insights from a Manually Annotated Twitter Dataset",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Numerous successes have been achieved in combating the COVID-19 pandemic, initially using various precautionary measures like lockdowns, social distancing, and the use of face masks. More recently, various vaccinations have been developed to aid in the prevention or reduction of the severity of the COVID-19 infection. Despite the effectiveness of the precautionary measures and the vaccines, there are several controversies that are massively shared on social media platforms like Twitter. In this paper, we explore the use of state-of-the-art transformer-based language models to study people's acceptance of vaccines in Nigeria. We developed a novel dataset by crawling multi-lingual tweets using relevant hashtags and keywords. Our analysis and visualizations revealed that most tweets expressed neutral sentiments about COVID-19 vaccines, with some individuals expressing positive views, and there was no strong preference for specific vaccine types, although Moderna received slightly more positive sentiment. We also found out that fine-tuning a pre-trained LLM with an appropriate dataset can yield competitive results, even if the LLM was not initially pre-trained on the specific language of that dataset.",
        "subjects": [
            "cs.CL",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13136",
        "abstract url": "https://arxiv.org/abs/2401.13136",
        "title": "The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to alleviating such concerns. By comparing how state-of-the-art LLMs respond to the same set of malicious prompts written in higher- vs. lower-resource languages, we observe that (1) LLMs tend to generate unsafe responses much more often when a malicious prompt is written in a lower-resource language, and (2) LLMs tend to generate more irrelevant responses to malicious prompts in lower-resource languages. To understand where the discrepancy can be attributed, we study the effect of instruction tuning with reinforcement learning from human feedback (RLHF) or supervised finetuning (SFT) on the HH-RLHF dataset. Surprisingly, while training with high-resource languages improves model alignment, training in lower-resource languages yields minimal improvement. This suggests that the bottleneck of cross-lingual alignment is rooted in the pretraining stage. Our findings highlight the challenges in cross-lingual LLM safety, and we hope they inform future research in this direction.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13146",
        "abstract url": "https://arxiv.org/abs/2401.13146",
        "title": "Locality enhanced dynamic biasing and sampling strategies for contextual ASR",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automatic Speech Recognition (ASR) still face challenges when recognizing time-variant rare-phrases. Contextual biasing (CB) modules bias ASR model towards such contextually-relevant phrases. During training, a list of biasing phrases are selected from a large pool of phrases following a sampling strategy. In this work we firstly analyse different sampling strategies to provide insights into the training of CB for ASR with correlation plots between the bias embeddings among various training stages. Secondly, we introduce a neighbourhood attention (NA) that localizes self attention (SA) to the nearest neighbouring frames to further refine the CB output. The results show that this proposed approach provides on average a 25.84% relative WER improvement on LibriSpeech sets and rare-word evaluation compared to the baseline.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.SD"
        ],
        "comment": "Accepted for IEEE ASRU 2023"
    },
    {
        "paper id": "2401.13160",
        "abstract url": "https://arxiv.org/abs/2401.13160",
        "title": "SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Pre-training large language models is known to be extremely resource intensive and often times inefficient, under-utilizing the information encapsulated in the training text sequences. In this paper, we present SpacTor, a new training procedure consisting of (1) a hybrid objective combining span corruption (SC) and token replacement detection (RTD), and (2) a two-stage curriculum that optimizes the hybrid objective over the initial $\u03c4$ iterations, then transitions to standard SC loss. We show empirically that the effectiveness of the hybrid objective is tied to the two-stage pre-training schedule, and provide extensive analysis on why this is the case. In our experiments with encoder-decoder architectures (T5) on a variety of NLP tasks, SpacTor-T5 yields the same downstream performance as standard SC pre-training, while enabling a 50% reduction in pre-training iterations and 40% reduction in total FLOPs. Alternatively, given the same amount of computing budget, we find that SpacTor results in significantly improved downstream benchmark performance.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "9+13 pages, 5 figures"
    },
    {
        "paper id": "2401.13161",
        "abstract url": "https://arxiv.org/abs/2401.13161",
        "title": "A Generalized Multiscale Bundle-Based Hyperspectral Sparse Unmixing Algorithm",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In hyperspectral sparse unmixing, a successful approach employs spectral bundles to address the variability of the endmembers in the spatial domain. However, the regularization penalties usually employed aggregate substantial computational complexity, and the solutions are very noise-sensitive. We generalize a multiscale spatial regularization approach to solve the unmixing problem by incorporating group sparsity-inducing mixed norms. Then, we propose a noise-robust method that can take advantage of the bundle structure to deal with endmember variability while ensuring inter- and intra-class sparsity in abundance estimation with reasonable computational cost. We also present a general heuristic to select the \\emph{most representative} abundance estimation over multiple runs of the unmixing process, yielding a solution that is robust and highly reproducible. Experiments illustrate the robustness and consistency of the results when compared to related methods.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13165",
        "abstract url": "https://arxiv.org/abs/2401.13165",
        "title": "Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This chapter focuses on gender-related errors in machine translation (MT) in the context of low-resource languages. We begin by explaining what low-resource languages are, examining the inseparable social and computational factors that create such linguistic hierarchies. We demonstrate through a case study of our mother tongue Bengali, a global language spoken by almost 300 million people but still classified as low-resource, how gender is assumed and inferred in translations to and from the high(est)-resource English when no such information is provided in source texts. We discuss the postcolonial and societal impacts of such errors leading to linguistic erasure and representational harms, and conclude by discussing potential solutions towards uplifting languages by providing them more agency in MT conversations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Upcoming Publication, Gendered Technology in Translation and Interpreting Centering Rights in the Development of Language Technology, Routledge 2024"
    },
    {
        "paper id": "2401.13170",
        "abstract url": "https://arxiv.org/abs/2401.13170",
        "title": "CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evaluate answer correctness in accordance with adopted expert AE rules that are more aligned with human judgments.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "See arXiv:2402.11161"
    },
    {
        "paper id": "2401.13174",
        "abstract url": "https://arxiv.org/abs/2401.13174",
        "title": "Boundary and Relation Distillation for Semantic Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, it has been revealed that small semantic segmentation (SS) models exhibit a tendency to make errors in maintaining boundary region completeness and preserving target region connectivity, despite their effective segmentation of the main object regions. To address these errors, we propose a targeted boundary and relation distillation (BRD) strategy using knowledge distillation from large teacher models to small student models. Specifically, the boundary distillation extracts explicit object boundaries from the hierarchical feature maps of the backbone network, subsequently enhancing the student model's mask quality in boundary regions. Concurrently, the relation distillation transfers implicit relations from the teacher model to the student model using pixel-level self-relation as a bridge, ensuring that the student's mask has strong target region connectivity. The proposed BRD is designed concretely for SS and is characterized by simplicity and efficiency. Through experimental evaluations on multiple SS datasets, including Pascal VOC 2012, Cityscapes, ADE20K, and COCO-Stuff 10K, we demonstrated that BRD significantly surpasses the current methods without increasing the inference costs, generating crisp region boundaries and smooth connecting regions that are challenging for small models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13178",
        "abstract url": "https://arxiv.org/abs/2401.13178",
        "title": "AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assessment of agents for multi-faceted analysis through interactive visualization. This not only sheds light on the capabilities and limitations of LLM agents but also propels the interpretability of their performance to the forefront. Ultimately, AgentBoard serves as a significant step towards demystifying agent behaviors and accelerating the development of stronger LLM agents.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2401.13201",
        "abstract url": "https://arxiv.org/abs/2401.13201",
        "title": "MLLMReID: Multimodal Large Language Model-based Person Re-identification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal large language models (MLLM) have achieved satisfactory results in many tasks. However, their performance in the task of person re-identification (ReID) has not been explored to date. This paper will investigate how to adapt them for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID image-text datasets, and then use their visual encoder as a backbone for ReID. However, there still exist two apparent issues: (1) Designing instructions for ReID, MLLMs may overfit specific instructions, and designing a variety of instructions will lead to higher costs. (2) Latent image feature vectors from LLMs are not involved in loss computation. Instructional learning, aligning image-text features, results in indirect optimization and a learning objective that inadequately utilizes features, limiting effectiveness in person feature learning. To address these problems, this paper proposes MLLMReID: Multimodal Large Language Model-based ReID. Firstly, we proposed Common Instruction, a simple approach that leverages the essence ability of LLMs to continue writing, avoiding complex and diverse instruction design. Secondly, we proposed DirectReID, which effectively employs the latent image feature vectors of images outputted by LLMs in ReID tasks. The experimental results demonstrate the superiority of our method. We will open-source the code on GitHub.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13205",
        "abstract url": "https://arxiv.org/abs/2401.13205",
        "title": "Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Adversarial examples are one critical security threat to various visual applications, where injected human-imperceptible perturbations can confuse the output.Generating transferable adversarial examples in the black-box setting is crucial but challenging in practice. Existing input-diversity-based methods adopt different image transformations, but may be inefficient due to insufficient input diversity and an identical perturbation step size. Motivated by the fact that different image regions have distinctive weights in classification, this paper proposes a black-box adversarial generative framework by jointly designing enhanced input diversity and adaptive step sizes. We design local mixup to randomly mix a group of transformed adversarial images, strengthening the input diversity. For precise adversarial generation, we project the perturbation into the $tanh$ space to relax the boundary constraint. Moreover, the step sizes of different regions can be dynamically adjusted by integrating a second-order momentum.Extensive experiments on ImageNet validate that our framework can achieve superior transferability compared to state-of-the-art baselines.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13213",
        "abstract url": "https://arxiv.org/abs/2401.13213",
        "title": "Common-Sense Bias Discovery and Mitigation for Classification Tasks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Machine learning model bias can arise from dataset composition: sensitive features correlated to the learning target disturb the model decision rule and lead to performance differences along the features. Existing de-biasing work captures prominent and delicate image features which are traceable in model latent space, like colors of digits or background of animals. However, using the latent space is not sufficient to understand all dataset feature correlations. In this work, we propose a framework to extract feature clusters in a dataset based on image descriptions, allowing us to capture both subtle and coarse features of the images. The feature co-occurrence pattern is formulated and correlation is measured, utilizing a human-in-the-loop for examination. The analyzed features and correlations are human-interpretable, so we name the method Common-Sense Bias Discovery (CSBD). Having exposed sensitive correlations in a dataset, we demonstrate that downstream model bias can be mitigated by adjusting image sampling weights, without requiring a sensitive group label supervision. Experiments show that our method discovers novel biases on multiple classification tasks for two benchmark image datasets, and the intervention outperforms state-of-the-art unsupervised bias mitigation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13218",
        "abstract url": "https://arxiv.org/abs/2401.13218",
        "title": "ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore the capabilities of open source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To this end, we propose ULTRA, a hierarchical framework that extracts event arguments more cost-effectively -- the method needs as few as 50 annotations and doesn't require hitting costly API endpoints. Further, it alleviates the positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text chunks of a document to generate a candidate argument set, upon which ULTRA learns to drop non-pertinent candidates through self-refinement. We further introduce LEAFER to address the challenge LLMs face in locating the exact boundary of an argument span. ULTRA outperforms strong baselines, which include strong supervised models and ChatGPT, by 9.8% when evaluated by the exact match (EM) metric.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13223",
        "abstract url": "https://arxiv.org/abs/2401.13223",
        "title": "TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-wise Pipeline. The experimental results have verified that our TAT-LLM model can outperform all baseline models, including the previous best fine-tuned models and very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "ACL 2024 (Under Review)"
    },
    {
        "paper id": "2401.13714",
        "abstract url": "https://arxiv.org/abs/2401.13714",
        "title": "Value-Driven Mixed-Precision Quantization for Patch-Based Inference on Microcontrollers",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deploying neural networks on microcontroller units (MCUs) presents substantial challenges due to their constrained computation and memory resources. Previous researches have explored patch-based inference as a strategy to conserve memory without sacrificing model accuracy. However, this technique suffers from severe redundant computation overhead, leading to a substantial increase in execution latency. A feasible solution to address this issue is mixed-precision quantization, but it faces the challenges of accuracy degradation and a time-consuming search time. In this paper, we propose QuantMCU, a novel patch-based inference method that utilizes value-driven mixed-precision quantization to reduce redundant computation. We first utilize value-driven patch classification (VDPC) to maintain the model accuracy. VDPC classifies patches into two classes based on whether they contain outlier values. For patches containing outlier values, we apply 8-bit quantization to the feature maps on the dataflow branches that follow. In addition, for patches without outlier values, we utilize value-driven quantization search (VDQS) on the feature maps of their following dataflow branches to reduce search time. Specifically, VDQS introduces a novel quantization search metric that takes into account both computation and accuracy, and it employs entropy as an accuracy representation to avoid additional training. VDQS also adopts an iterative approach to determine the bitwidth of each feature map to further accelerate the search process. Experimental results on real-world MCU devices show that QuantMCU can reduce computation by 2.2x on average while maintaining comparable model accuracy compared to the state-of-the-art patch-based inference methods.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by the 27th Design, Automation and Test in Europe Conference (DATE 2024)"
    },
    {
        "paper id": "2401.16212",
        "abstract url": "https://arxiv.org/abs/2401.16212",
        "title": "Better Call GPT, Comparing Large Language Models Against Lawyers",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a groundbreaking comparison between Large Language Models and traditional legal contract reviewers, Junior Lawyers and Legal Process Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed, and cost efficiency during contract review. Our empirical analysis benchmarks LLMs against a ground truth set by Senior Lawyers, uncovering that advanced models match or exceed human accuracy in determining legal issues. In speed, LLMs complete reviews in mere seconds, eclipsing the hours required by their human counterparts. Cost wise, LLMs operate at a fraction of the price, offering a staggering 99.97 percent reduction in cost over traditional methods. These results are not just statistics, they signal a seismic shift in legal practice. LLMs stand poised to disrupt the legal industry, enhancing accessibility and efficiency of legal services. Our research asserts that the era of LLM dominance in legal contract review is upon us, challenging the status quo and calling for a reimagined future of legal workflows.",
        "subjects": [
            "cs.CY",
            "cs.CL"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2402.01690",
        "abstract url": "https://arxiv.org/abs/2402.01690",
        "title": "Linguistic-Based Mild Cognitive Impairment Detection Using Informative Loss",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a deep learning method using Natural Language Processing (NLP) techniques, to distinguish between Mild Cognitive Impairment (MCI) and Normal Cognitive (NC) conditions in older adults. We propose a framework that analyzes transcripts generated from video interviews collected within the I-CONECT study project, a randomized controlled trial aimed at improving cognitive functions through video chats. Our proposed NLP framework consists of two Transformer-based modules, namely Sentence Embedding (SE) and Sentence Cross Attention (SCA). First, the SE module captures contextual relationships between words within each sentence. Subsequently, the SCA module extracts temporal features from a sequence of sentences. This feature is then used by a Multi-Layer Perceptron (MLP) for the classification of subjects into MCI or NC. To build a robust model, we propose a novel loss function, called InfoLoss, that considers the reduction in entropy by observing each sequence of sentences to ultimately enhance the classification accuracy. The results of our comprehensive model evaluation using the I-CONECT dataset show that our framework can distinguish between MCI and NC with an average area under the curve of 84.75%.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01695",
        "abstract url": "https://arxiv.org/abs/2402.01695",
        "title": "Language-Guided World Models: A Model-Based Approach to AI Control",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Installing probabilistic world models into artificial agents opens an efficient channel for humans to communicate with and control these agents. In addition to updating agent policies, humans can modify their internal world models in order to influence their decisions. The challenge, however, is that currently existing world models are difficult for humans to adapt because they lack a natural communication interface. Aimed at addressing this shortcoming, we develop Language-Guided World Models (LWMs), which can capture environment dynamics by reading language descriptions. These models enhance agent communication efficiency, allowing humans to simultaneously alter their behavior on multiple tasks with concise language feedback. They also enable agents to self-learn from texts originally written to instruct humans. To facilitate the development of LWMs, we design a challenging benchmark based on the game of MESSENGER (Hanjie et al., 2021), requiring compositional generalization to new language descriptions and environment dynamics. Our experiments reveal that the current state-of-the-art Transformer architecture performs poorly on this benchmark, motivating us to design a more robust architecture. To showcase the practicality of our proposed LWMs, we simulate a scenario where these models augment the interpretability and safety of an agent by enabling it to generate and discuss plans with a human before execution. By effectively incorporating language feedback on the plan, the models boost the agent performance in the real environment by up to three times without collecting any interactive experiences in this environment.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01696",
        "abstract url": "https://arxiv.org/abs/2402.01696",
        "title": "HiGen: Hierarchy-Aware Sequence Generation for Hierarchical Text Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Hierarchical text classification (HTC) is a complex subtask under multi-label text classification, characterized by a hierarchical label taxonomy and data imbalance. The best-performing models aim to learn a static representation by combining document and hierarchical label information. However, the relevance of document sections can vary based on the hierarchy level, necessitating a dynamic document representation. To address this, we propose HiGen, a text-generation-based framework utilizing language models to encode dynamic text representations. We introduce a level-guided loss function to capture the relationship between text and label name semantics. Our approach incorporates a task-specific pretraining strategy, adapting the language model to in-domain knowledge and significantly enhancing performance for classes with limited examples. Furthermore, we present a new and valuable dataset called ENZYME, designed for HTC, which comprises articles from PubMed with the goal of predicting Enzyme Commission (EC) numbers. Through extensive experiments on the ENZYME dataset and the widely recognized WOS and NYT datasets, our methodology demonstrates superior performance, surpassing existing approaches while efficiently handling data and mitigating class imbalance. The data and code will be released publicly.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12508",
        "abstract url": "https://arxiv.org/abs/2401.12508",
        "title": "On the Stochastic (Variance-Reduced) Proximal Gradient Method for Regularized Expected Reward Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider a regularized expected reward optimization problem in the non-oblivious setting that covers many existing problems in reinforcement learning (RL). In order to solve such an optimization problem, we apply and analyze the classical stochastic proximal gradient method. In particular, the method has shown to admit an $O(\u03b5^{-4})$ sample complexity to an $\u03b5$-stationary point, under standard conditions. Since the variance of the classical stochastic gradient estimator is typically large which slows down the convergence, we also apply an efficient stochastic variance-reduce proximal gradient method with an importance sampling based ProbAbilistic Gradient Estimator (PAGE). To the best of our knowledge, the application of this method represents a novel approach in addressing the general regularized reward optimization problem. Our analysis shows that the sample complexity can be improved from $O(\u03b5^{-4})$ to $O(\u03b5^{-3})$ under additional conditions. Our results on the stochastic (variance-reduced) proximal gradient method match the sample complexity of their most competitive counterparts under similar settings in the RL literature.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2401.12509",
        "abstract url": "https://arxiv.org/abs/2401.12509",
        "title": "Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop a simulation framework for studying misinformation spread within online social networks that blends agent-based modeling and natural language processing techniques. While many other agent-based simulations exist in this space, questions over their fidelity and generalization to existing networks in part hinders their ability to provide actionable insights. To partially address these concerns, we create a 'digital clone' of a known misinformation sharing network by downloading social media histories for over ten thousand of its users. We parse these histories to both extract the structure of the network and model the nuanced ways in which information is shared and spread among its members. Unlike many other agent-based methods in this space, information sharing between users in our framework is sensitive to topic of discussion, user preferences, and online community dynamics. To evaluate the fidelity of our method, we seed our cloned network with a set of posts recorded in the base network and compare propagation dynamics between the two, observing reasonable agreement across the twin networks over a variety of metrics. Lastly, we explore how the cloned network may serve as a flexible, low-cost testbed for misinformation countermeasure evaluation and red teaming analysis. We hope the tools explored here augment existing efforts in the space and unlock new opportunities for misinformation countermeasure evaluation, a field that may become increasingly important to consider with the anticipated rise of misinformation campaigns fueled by generative artificial intelligence.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12533",
        "abstract url": "https://arxiv.org/abs/2401.12533",
        "title": "Near-Optimal Algorithms for Constrained k-Center Clustering with Instance-level Background Knowledge",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Center-based clustering has attracted significant research interest from both theory and practice. In many practical applications, input data often contain background knowledge that can be used to improve clustering results. In this work, we build on widely adopted $k$-center clustering and model its input background knowledge as must-link (ML) and cannot-link (CL) constraint sets. However, most clustering problems including $k$-center are inherently $\\mathcal{NP}$-hard, while the more complex constrained variants are known to suffer severer approximation and computation barriers that significantly limit their applicability. By employing a suite of techniques including reverse dominating sets, linear programming (LP) integral polyhedron, and LP duality, we arrive at the first efficient approximation algorithm for constrained $k$-center with the best possible ratio of 2. We also construct competitive baseline algorithms and empirically evaluate our approximation algorithm against them on a variety of real datasets. The results validate our theoretical findings and demonstrate the great advantages of our algorithm in terms of clustering cost, clustering quality, and running time.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12546",
        "abstract url": "https://arxiv.org/abs/2401.12546",
        "title": "On Building Myopic MPC Policies using Supervised Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The application of supervised learning techniques in combination with model predictive control (MPC) has recently generated significant interest, particularly in the area of approximate explicit MPC, where function approximators like deep neural networks are used to learn the MPC policy via optimal state-action pairs generated offline. While the aim of approximate explicit MPC is to closely replicate the MPC policy, substituting online optimization with a trained neural network, the performance guarantees that come with solving the online optimization problem are typically lost. This paper considers an alternative strategy, where supervised learning is used to learn the optimal value function offline instead of learning the optimal policy. This can then be used as the cost-to-go function in a myopic MPC with a very short prediction horizon, such that the online computation burden reduces significantly without affecting the controller performance. This approach differs from existing work on value function approximations in the sense that it learns the cost-to-go function by using offline-collected state-value pairs, rather than closed-loop performance data. The cost of generating the state-value pairs used for training is addressed using a sensitivity-based data augmentation scheme.",
        "subjects": [
            "cs.LG",
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12550",
        "abstract url": "https://arxiv.org/abs/2401.12550",
        "title": "UR4NNV: Neural Network Verification, Under-approximation Reachability Works!",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recently, formal verification of deep neural networks (DNNs) has garnered considerable attention, and over-approximation based methods have become popular due to their effectiveness and efficiency. However, these strategies face challenges in addressing the \"unknown dilemma\" concerning whether the exact output region or the introduced approximation error violates the property in question. To address this, this paper introduces the UR4NNV verification framework, which utilizes under-approximation reachability analysis for DNN verification for the first time. UR4NNV focuses on DNNs with Rectified Linear Unit (ReLU) activations and employs a binary tree branch-based under-approximation algorithm. In each epoch, UR4NNV under-approximates a sub-polytope of the reachable set and verifies this polytope against the given property. Through a trial-and-error approach, UR4NNV effectively falsifies DNN properties while providing confidence levels when reaching verification epoch bounds and failing falsifying properties. Experimental comparisons with existing verification methods demonstrate the effectiveness and efficiency of UR4NNV, significantly reducing the impact of the \"unknown dilemma\".",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2401.12554",
        "abstract url": "https://arxiv.org/abs/2401.12554",
        "title": "Can Large Language Models Write Parallel Code?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models are increasingly becoming a popular tool for software development. Their ability to model and generate source code has been demonstrated in a variety of contexts, including code completion, summarization, translation, and lookup. However, they often struggle to generate code for complex programs. In this paper, we study the capabilities of state-of-the-art language models to generate parallel code. In order to evaluate language models, we create a benchmark, ParEval, consisting of prompts that represent 420 different coding tasks. We use ParEval to evaluate the effectiveness of several state-of-the-art open- and closed-source language models on these tasks. We introduce novel metrics for evaluating the performance of generated code, and use them to explore how well each LLM performs for 12 different computational problem types and six different parallel programming models.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12557",
        "abstract url": "https://arxiv.org/abs/2401.12557",
        "title": "Balancing the AI Strength of Roles in Self-Play Training with Regret Matching+",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "When training artificial intelligence for games encompassing multiple roles, the development of a generalized model capable of controlling any character within the game presents a viable option. This strategy not only conserves computational resources and time during the training phase but also reduces resource requirements during deployment. training such a generalized model often encounters challenges related to uneven capabilities when controlling different roles. A simple method is introduced based on Regret Matching+, which facilitates a more balanced performance of strength by the model when controlling various roles.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12599",
        "abstract url": "https://arxiv.org/abs/2401.12599",
        "title": "Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the rapid development of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) has become a predominant method in the field of professional knowledge-based question answering. Presently, major foundation model companies have opened up Embedding and Chat API interfaces, and frameworks like LangChain have already integrated the RAG process. It appears that the key models and steps in RAG have been resolved, leading to the question: are professional knowledge QA systems now approaching perfection? This article discovers that current primary methods depend on the premise of accessing high-quality text corpora. However, since professional documents are mainly stored in PDFs, the low accuracy of PDF parsing significantly impacts the effectiveness of professional knowledge-based QA. We conducted an empirical RAG experiment across hundreds of questions from the corresponding real-world professional documents. The results show that, ChatDOC, a RAG system equipped with a panoptic and pinpoint PDF parser, retrieves more accurate and complete segments, and thus better answers. Empirical experiments show that ChatDOC is superior to baseline on nearly 47% of questions, ties for 38% of cases, and falls short on only 15% of cases. It shows that we may revolutionize RAG with enhanced PDF structure recognition.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "18 pages, 16 figures"
    },
    {
        "paper id": "2401.12611",
        "abstract url": "https://arxiv.org/abs/2401.12611",
        "title": "Prompt Smells: An Omen for Undesirable Generative AI Outputs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent Generative Artificial Intelligence (GenAI) trends focus on various applications, including creating stories, illustrations, poems, articles, computer code, music compositions, and videos. Extrinsic hallucinations are a critical limitation of such GenAI, which can lead to significant challenges in achieving and maintaining the trustworthiness of GenAI. In this paper, we propose two new concepts that we believe will aid the research community in addressing limitations associated with the application of GenAI models. First, we propose a definition for the \"desirability\" of GenAI outputs and three factors which are observed to influence it. Second, drawing inspiration from Martin Fowler's code smells, we propose the concept of \"prompt smells\" and the adverse effects they are observed to have on the desirability of GenAI outputs. We expect our work will contribute to the ongoing conversation about the desirability of GenAI outputs and help advance the field in a meaningful way.",
        "subjects": [
            "cs.LG",
            "cs.SE"
        ],
        "comment": "Accepted at CAIN 2024: Poster Track"
    },
    {
        "paper id": "2401.12630",
        "abstract url": "https://arxiv.org/abs/2401.12630",
        "title": "Full-Stack Optimization for CAM-Only DNN Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The accuracy of neural networks has greatly improved across various domains over the past years. Their ever-increasing complexity, however, leads to prohibitively high energy demands and latency in von Neumann systems. Several computing-in-memory (CIM) systems have recently been proposed to overcome this, but trade-offs involving accuracy, hardware reliability, and scalability for large models remain a challenge. Additionally, for some CIM designs, the activation movement still requires considerable time and energy. This paper explores the combination of algorithmic optimizations for ternary weight neural networks and associative processors (APs) implemented using racetrack memory (RTM). We propose a novel compilation flow to optimize convolutions on APs by reducing their arithmetic intensity. By leveraging the benefits of RTM-based APs, this approach substantially reduces data transfers within the memory while addressing accuracy, energy efficiency, and reliability concerns. Concretely, our solution improves the energy efficiency of ResNet-18 inference on ImageNet by 7.5x compared to crossbar in-memory accelerators while retaining software accuracy.",
        "subjects": [
            "cs.AR",
            "cs.ET",
            "cs.LG"
        ],
        "comment": "To be presented at DATE24"
    },
    {
        "paper id": "2401.12644",
        "abstract url": "https://arxiv.org/abs/2401.12644",
        "title": "Binary Feature Mask Optimization for Feature Selection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate feature selection problem for generic machine learning (ML) models. We introduce a novel framework that selects features considering the predictions of the model. Our framework innovates by using a novel feature masking approach to eliminate the features during the selection process, instead of completely removing them from the dataset. This allows us to use the same ML model during feature selection, unlike other feature selection methods where we need to train the ML model again as the dataset has different dimensions on each iteration. We obtain the mask operator using the predictions of the ML model, which offers a comprehensive view on the subsets of the features essential for the predictive performance of the model. A variety of approaches exist in the feature selection literature. However, no study has introduced a training-free framework for a generic ML model to select features while considering the importance of the feature subsets as a whole, instead of focusing on the individual features. We demonstrate significant performance improvements on the real-life datasets under different settings using LightGBM and Multi-Layer Perceptron as our ML models. Additionally, we openly share the implementation code for our methods to encourage the research and the contributions in this area.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12645",
        "abstract url": "https://arxiv.org/abs/2401.12645",
        "title": "On the Robustness of Deep Learning-aided Symbol Detectors to Varying Conditions and Imperfect Channel Knowledge",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, a data-driven Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm tailored to channels with intersymbol interference has been introduced. This so-called BCJRNet algorithm utilizes neural networks to calculate channel likelihoods. BCJRNet has demonstrated resilience against inaccurate channel tap estimations when applied to a time-invariant channel with ideal exponential decay profiles. However, its generalization capabilities for practically-relevant time-varying channels, where the receiver can only access incorrect channel parameters, remain largely unexplored. The primary contribution of this paper is to expand upon the results from existing literature to encompass a variety of imperfect channel knowledge cases that appear in real-world transmissions. Our findings demonstrate that BCJRNet significantly outperforms the conventional BCJR algorithm for stationary transmission scenarios when learning from noisy channel data and with imperfect channel decay profiles. However, this advantage is shown to diminish when the operating channel is also rapidly time-varying. Our results also show the importance of memory assumptions for conventional BCJR and BCJRNet. An underestimation of the memory largely degrades the performance of both BCJR and BCJRNet, especially in a slow-decaying channel. To mimic a situation closer to a practical scenario, we also combined channel tap uncertainty with imperfect channel memory knowledge. Somewhat surprisingly, our results revealed improved performance when employing the conventional BCJR with an underestimated memory assumption. BCJRNet, on the other hand, showed a consistent performance improvement as the level of accurate memory knowledge increased.",
        "subjects": [
            "cs.IT",
            "cs.LG",
            "eess.SP"
        ],
        "comment": "Accepted paper at IEEE Wireless Communications and Networking Conference (WCNC) 2024"
    },
    {
        "paper id": "2401.12646",
        "abstract url": "https://arxiv.org/abs/2401.12646",
        "title": "Emergent Cooperation under Uncertain Incentive Alignment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Understanding the emergence of cooperation in systems of computational agents is crucial for the development of effective cooperative AI. Interaction among individuals in real-world settings are often sparse and occur within a broad spectrum of incentives, which often are only partially known. In this work, we explore how cooperation can arise among reinforcement learning agents in scenarios characterised by infrequent encounters, and where agents face uncertainty about the alignment of their incentives with those of others. To do so, we train the agents under a wide spectrum of environments ranging from fully competitive, to fully cooperative, to mixed-motives. Under this type of uncertainty we study the effects of mechanisms, such as reputation and intrinsic rewards, that have been proposed in the literature to foster cooperation in mixed-motives environments. Our findings show that uncertainty substantially lowers the agents' ability to engage in cooperative behaviour, when that would be the best course of action. In this scenario, the use of effective reputation mechanisms and intrinsic rewards boosts the agents' capability to act nearly-optimally in cooperative environments, while greatly enhancing cooperation in mixed-motive environments as well.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12667",
        "abstract url": "https://arxiv.org/abs/2401.12667",
        "title": "Feature Selection via Robust Weighted Score for High Dimensional Binary Class-Imbalanced Gene Expression Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, a robust weighted score for unbalanced data (ROWSU) is proposed for selecting the most discriminative feature for high dimensional gene expression binary classification with class-imbalance problem. The method addresses one of the most challenging problems of highly skewed class distributions in gene expression datasets that adversely affect the performance of classification algorithms. First, the training dataset is balanced by synthetically generating data points from minority class observations. Second, a minimum subset of genes is selected using a greedy search approach. Third, a novel weighted robust score, where the weights are computed by support vectors, is introduced to obtain a refined set of genes. The highest-scoring genes based on this approach are combined with the minimum subset of genes selected by the greedy search approach to form the final set of genes. The novel method ensures the selection of the most discriminative genes, even in the presence of skewed class distribution, thus improving the performance of the classifiers. The performance of the proposed ROWSU method is evaluated on $6$ gene expression datasets. Classification accuracy and sensitivity are used as performance metrics to compare the proposed ROWSU algorithm with several other state-of-the-art methods. Boxplots and stability plots are also constructed for a better understanding of the results. The results show that the proposed method outperforms the existing feature selection procedures based on classification performance from k nearest neighbours (kNN) and random forest (RF) classifiers.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2401.12683",
        "abstract url": "https://arxiv.org/abs/2401.12683",
        "title": "LLpowershap: Logistic Loss-based Automated Shapley Values Feature Selection Method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Shapley values have been used extensively in machine learning, not only to explain black box machine learning models, but among other tasks, also to conduct model debugging, sensitivity and fairness analyses and to select important features for robust modelling and for further follow-up analyses. Shapley values satisfy certain axioms that promote fairness in distributing contributions of features toward prediction or reducing error, after accounting for non-linear relationships and interactions when complex machine learning models are employed. Recently, a number of feature selection methods utilising Shapley values have been introduced. Here, we present a novel feature selection method, LLpowershap, which makes use of loss-based Shapley values to identify informative features with minimal noise among the selected sets of features. Our simulation results show that LLpowershap not only identifies higher number of informative features but outputs fewer noise features compared to other state-of-the-art feature selection methods. Benchmarking results on four real-world datasets demonstrate higher or at par predictive performance of LLpowershap compared to other Shapley based wrapper methods, or filter methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12708",
        "abstract url": "https://arxiv.org/abs/2401.12708",
        "title": "Deep Neural Network Benchmarks for Selective Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the increasing deployment of machine learning models in many socially-sensitive tasks, there is a growing demand for reliable and trustworthy predictions. One way to accomplish these requirements is to allow a model to abstain from making a prediction when there is a high risk of making an error. This requires adding a selection mechanism to the model, which selects those examples for which the model will provide a prediction. The selective classification framework aims to design a mechanism that balances the fraction of rejected predictions (i.e., the proportion of examples for which the model does not make a prediction) versus the improvement in predictive performance on the selected predictions. Multiple selective classification frameworks exist, most of which rely on deep neural network architectures. However, the empirical evaluation of the existing approaches is still limited to partial comparisons among methods and settings, providing practitioners with little insight into their relative merits. We fill this gap by benchmarking 18 baselines on a diverse set of 44 datasets that includes both image and tabular data. Moreover, there is a mix of binary and multiclass tasks. We evaluate these approaches using several criteria, including selective error rate, empirical coverage, distribution of rejected instance's classes, and performance on out-of-distribution instances. The results indicate that there is not a single clear winner among the surveyed baselines, and the best method depends on the users' objectives.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12711",
        "abstract url": "https://arxiv.org/abs/2401.12711",
        "title": "When Redundancy Matters: Machine Teaching of Representations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In traditional machine teaching, a teacher wants to teach a concept to a learner, by means of a finite set of examples, the witness set. But concepts can have many equivalent representations. This redundancy strongly affects the search space, to the extent that teacher and learner may not be able to easily determine the equivalence class of each representation. In this common situation, instead of teaching concepts, we explore the idea of teaching representations. We work with several teaching schemas that exploit representation and witness size (Eager, Greedy and Optimal) and analyze the gains in teaching effectiveness for some representational languages (DNF expressions and Turing-complete P3 programs). Our theoretical and experimental results indicate that there are various types of redundancy, handled better by the Greedy schema introduced here than by the Eager schema, although both can be arbitrarily far away from the Optimal. For P3 programs we found that witness sets are usually smaller than the programs they identify, which is an illuminating justification of why machine teaching from examples makes sense at all.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2401.12714",
        "abstract url": "https://arxiv.org/abs/2401.12714",
        "title": "Evaluation of large language models for assessing code maintainability",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Increased availability of open-source software repositories and recent advances in code analysis using large language models (LLMs) has triggered a wave of new work to automate software engineering tasks that were previously very difficult to automate. In this paper, we investigate a recent line of work that hypothesises that comparing the probability of code generated by LLMs with the probability the current code would have had can indicate potential quality problems. We investigate the association between the cross-entropy of code generated by ten different models (based on GPT2 and Llama2) and the following quality aspects: readability, understandability, complexity, modularisation, and overall maintainability assessed by experts and available in an benchmark dataset. Our results show that, controlling for the number of logical lines of codes (LLOC), cross-entropy computed by LLMs is indeed a predictor of maintainability on a class level (the higher the cross-entropy the lower the maintainability). However, this relation is reversed when one does not control for LLOC (e.g., comparing small classes with longer ones). Furthermore, while the complexity of LLMs affects the range of cross-entropy (smaller models tend to have a wider range of cross-entropy), this plays a significant role in predicting maintainability aspects. Our study limits itself on ten different pretrained models (based on GPT2 and Llama2) and on maintainability aspects collected by Schnappinger et al. When controlling for logical lines of code (LLOC), cross-entropy is a predictor of maintainability. However, while related work has shown the potential usefulness of cross-entropy at the level of tokens or short sequences, at the class level this criterion alone may prove insufficient to predict maintainability and further research is needed to make best use of this information in practice.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "14 pages, 4 figures, 8 tables"
    },
    {
        "paper id": "2401.12722",
        "abstract url": "https://arxiv.org/abs/2401.12722",
        "title": "Falcon: Fair Active Learning using Multi-armed Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Biased data can lead to unfair machine learning models, highlighting the importance of embedding fairness at the beginning of data analysis, particularly during dataset curation and labeling. In response, we propose Falcon, a scalable fair active learning framework. Falcon adopts a data-centric approach that improves machine learning model fairness via strategic sample selection. Given a user-specified group fairness measure, Falcon identifies samples from \"target groups\" (e.g., (attribute=female, label=positive)) that are the most informative for improving fairness. However, a challenge arises since these target groups are defined using ground truth labels that are not available during sample selection. To handle this, we propose a novel trial-and-error method, where we postpone using a sample if the predicted label is different from the expected one and falls outside the target group. We also observe the trade-off that selecting more informative samples results in higher likelihood of postponing due to undesired label prediction, and the optimal balance varies per dataset. We capture the trade-off between informativeness and postpone rate as policies and propose to automatically select the best policy using adversarial multi-armed bandit methods, given their computational efficiency and theoretical guarantees. Experiments show that Falcon significantly outperforms existing fair active learning approaches in terms of fairness and accuracy and is more efficient. In particular, only Falcon supports a proper trade-off between accuracy and fairness where its maximum fairness score is 1.8-4.5x higher than the second-best results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to VLDB 2024"
    },
    {
        "paper id": "2401.12731",
        "abstract url": "https://arxiv.org/abs/2401.12731",
        "title": "The Distributional Uncertainty of the SHAP score in Explainable Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for the SHAP scores of all features. In particular, we pinpoint the complexity of these problems, and other related ones, showing them to be NP-complete. Finally, we present experiments on a real-world dataset, showing that our framework may contribute to a more robust feature scoring.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12733",
        "abstract url": "https://arxiv.org/abs/2401.12733",
        "title": "TNANet: A Temporal-Noise-Aware Neural Network for Suicidal Ideation Prediction with Noisy Physiological Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The robust generalization of deep learning models in the presence of inherent noise remains a significant challenge, especially when labels are subjective and noise is indiscernible in natural settings. This problem is particularly pronounced in many practical applications. In this paper, we address a special and important scenario of monitoring suicidal ideation, where time-series data, such as photoplethysmography (PPG), is susceptible to such noise. Current methods predominantly focus on image and text data or address artificially introduced noise, neglecting the complexities of natural noise in time-series analysis. To tackle this, we introduce a novel neural network model tailored for analyzing noisy physiological time-series data, named TNANet, which merges advanced encoding techniques with confidence learning, enhancing prediction accuracy. Another contribution of our work is the collection of a specialized dataset of PPG signals derived from real-world environments for suicidal ideation prediction. Employing this dataset, our TNANet achieves the prediction accuracy of 63.33% in a binary classification task, outperforming state-of-the-art models. Furthermore, comprehensive evaluations were conducted on three other well-known public datasets with artificially introduced noise to rigorously test the TNANet's capabilities. These tests consistently demonstrated TNANet's superior performance by achieving an accuracy improvement of more than 10% compared to baseline methods.",
        "subjects": [
            "cs.CY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12745",
        "abstract url": "https://arxiv.org/abs/2401.12745",
        "title": "On the Utility of Probing Trajectories for Algorithm-Selection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine-learning approaches to algorithm-selection typically take data describing an instance as input. Input data can take the form of features derived from the instance description or fitness landscape, or can be a direct representation of the instance itself, i.e. an image or textual description. Regardless of the choice of input, there is an implicit assumption that instances that are similar will elicit similar performance from algorithm, and that a model is capable of learning this relationship. We argue that viewing algorithm-selection purely from an instance perspective can be misleading as it fails to account for how an algorithm `views' similarity between instances. We propose a novel `algorithm-centric' method for describing instances that can be used to train models for algorithm-selection: specifically, we use short probing trajectories calculated by applying a solver to an instance for a very short period of time. The approach is demonstrated to be promising, providing comparable or better results to computationally expensive landscape-based feature-based approaches. Furthermore, projecting the trajectories into a 2-dimensional space illustrates that functions that are similar from an algorithm-perspective do not necessarily correspond to the accepted categorisation of these functions from a human perspective.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "comment": "To appear in the proceedings of the 27th International Conference, EvoApplications 2024"
    },
    {
        "paper id": "2401.12764",
        "abstract url": "https://arxiv.org/abs/2401.12764",
        "title": "Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $O(1/k)$ Finite-Sample Complexity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $O(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $O(1/k^{2/3})$. We illustrate this result by applying the proposed method to develop new reinforcement learning algorithms with improved performance.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12790",
        "abstract url": "https://arxiv.org/abs/2401.12790",
        "title": "MORPH: Towards Automated Concept Drift Adaptation for Malware Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Concept drift is a significant challenge for malware detection, as the performance of trained machine learning models degrades over time, rendering them impractical. While prior research in malware concept drift adaptation has primarily focused on active learning, which involves selecting representative samples to update the model, self-training has emerged as a promising approach to mitigate concept drift. Self-training involves retraining the model using pseudo labels to adapt to shifting data distributions. In this research, we propose MORPH -- an effective pseudo-label-based concept drift adaptation method specifically designed for neural networks. Through extensive experimental analysis of Android and Windows malware datasets, we demonstrate the efficacy of our approach in mitigating the impact of concept drift. Our method offers the advantage of reducing annotation efforts when combined with active learning. Furthermore, our method significantly improves over existing works in automated concept drift adaptation for malware detection.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12830",
        "abstract url": "https://arxiv.org/abs/2401.12830",
        "title": "Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the modern transportation industry, accurate prediction of travelers' next destinations brings multiple benefits to companies, such as customer satisfaction and targeted marketing. This study focuses on developing a precise model that captures the sequential patterns and dependencies in travel data, enabling accurate predictions of individual travelers' future destinations. To achieve this, a novel model architecture with a sliding window approach based on Long Short-Term Memory (LSTM) is proposed for destination prediction in the transportation industry. The experimental results highlight satisfactory performance and high scores achieved by the proposed model across different data sizes and performance metrics. This research contributes to advancing destination prediction methods, empowering companies to deliver personalized recommendations and optimize customer experiences in the dynamic travel landscape.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12842",
        "abstract url": "https://arxiv.org/abs/2401.12842",
        "title": "Iterated Relevance Matrix Analysis (IRMA) for the identification of class-discriminative subspaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce and investigate the iterated application of Generalized Matrix Learning Vector Quantizaton for the analysis of feature relevances in classification problems, as well as for the construction of class-discriminative subspaces. The suggested Iterated Relevance Matrix Analysis (IRMA) identifies a linear subspace representing the classification specific information of the considered data sets using Generalized Matrix Learning Vector Quantization (GMLVQ). By iteratively determining a new discriminative subspace while projecting out all previously identified ones, a combined subspace carrying all class-specific information can be found. This facilitates a detailed analysis of feature relevances, and enables improved low-dimensional representations and visualizations of labeled data sets. Additionally, the IRMA-based class-discriminative subspace can be used for dimensionality reduction and the training of robust classifiers with potentially improved performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 5 figures, 1 table. Submitted to Neurocomputing. Extension of 2023 ESANN conference contribution"
    },
    {
        "paper id": "2401.12849",
        "abstract url": "https://arxiv.org/abs/2401.12849",
        "title": "Learning safety critics via a non-contractive binary bellman operator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The inability to naturally enforce safety in Reinforcement Learning (RL), with limited failures, is a core challenge impeding its use in real-world applications. One notion of safety of vast practical relevance is the ability to avoid (unsafe) regions of the state space. Though such a safety goal can be captured by an action-value-like function, a.k.a. safety critics, the associated operator lacks the desired contraction and uniqueness properties that the classical Bellman operator enjoys. In this work, we overcome the non-contractiveness of safety critic operators by leveraging that safety is a binary property. To that end, we study the properties of the binary safety critic associated with a deterministic dynamical system that seeks to avoid reaching an unsafe region. We formulate the corresponding binary Bellman equation (B2E) for safety and study its properties. While the resulting operator is still non-contractive, we fully characterize its fixed points representing--except for a spurious solution--maximal persistently safe regions of the state space that can always avoid failure. We provide an algorithm that, by design, leverages axiomatic knowledge of safe data to avoid spurious fixed points.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12866",
        "abstract url": "https://arxiv.org/abs/2401.12866",
        "title": "Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Mobile crowdsourcing refers to systems where the completion of tasks necessarily requires physical movement of crowdworkers in an on-demand workforce. Evidence suggests that in such systems, tasks often get assigned to crowdworkers who struggle to complete those tasks successfully, resulting in high failure rates and low service quality. A promising solution to ensure higher quality of service is to continuously adapt the assignment and respond to failure-causing events by transferring tasks to better-suited workers who use different routes or vehicles. However, implementing task transfers in mobile crowdsourcing is difficult because workers are autonomous and may reject transfer requests. Moreover, task outcomes are uncertain and need to be predicted. In this paper, we propose different mechanisms to achieve outcome prediction and task coordination in mobile crowdsourcing. First, we analyze different data stream learning approaches for the prediction of task outcomes. Second, based on the suggested prediction model, we propose and evaluate two different approaches for task coordination with different degrees of autonomy: an opportunistic approach for crowdshipping with collaborative, but non-autonomous workers, and a market-based model with autonomous workers for crowdsensing.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12869",
        "abstract url": "https://arxiv.org/abs/2401.12869",
        "title": "TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Language models (LMs) can solve tasks such as answering questions about tables or images by writing programs. However, using primitive functions often leads to verbose and error-prone programs, and higher-level functions require expert design. To enable better solutions without human labor, we ask code LMs to curate reusable high-level functions, and use them to write solutions. We present TROVE, a training-free method of inducing a verifiable and efficient toolbox of functions, by generating via using, growing, and periodically trimming the toolbox. On 11 datasets from math, table question answering, and image reasoning tasks, TROVE consistently yields simpler solutions with higher accuracy than baselines using CODELLAMA and previous methods using GPT, while using 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more accurate human verification than baselines. With the same pipeline, it creates diverse functions for varied tasks and datasets, providing insights into their individual characteristics.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12882",
        "abstract url": "https://arxiv.org/abs/2401.12882",
        "title": "Model-Free $\u03b4$-Policy Iteration Based on Damped Newton Method for Nonlinear Continuous-Time H$\\infty$ Tracking Control",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a \u03b4-PI algorithm which is based on damped Newton method for the H{\\infty} tracking control problem of unknown continuous-time nonlinear system. A discounted performance function and an augmented system are used to get the tracking Hamilton-Jacobi-Isaac (HJI) equation. Tracking HJI equation is a nonlinear partial differential equation, traditional reinforcement learning methods for solving the tracking HJI equation are mostly based on the Newton method, which usually only satisfies local convergence and needs a good initial guess. Based upon the damped Newton iteration operator equation, a generalized tracking Bellman equation is derived firstly. The \u03b4-PI algorithm can seek the optimal solution of the tracking HJI equation by iteratively solving the generalized tracking Bellman equation. On-policy learning and off-policy learning \u03b4-PI reinforcement learning methods are provided, respectively. Off-policy version \u03b4-PI algorithm is a model-free algorithm which can be performed without making use of a priori knowledge of the system dynamics. NN-based implementation scheme for the off-policy \u03b4-PI algorithms is shown. The suitability of the model-free \u03b4-PI algorithm is illustrated with a nonlinear system simulation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 8 figures"
    },
    {
        "paper id": "2401.12895",
        "abstract url": "https://arxiv.org/abs/2401.12895",
        "title": "ESC: Edge-attributed Skyline Community Search in Large-scale Bipartite Graphs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Due to the ability of modeling relationships between two different types of entities, bipartite graphs are naturally employed in many real-world applications. Community Search in bipartite graphs is a fundamental problem and has gained much attention. However, existing studies focus on measuring the structural cohesiveness between two sets of vertices, while either completely ignoring the edge attributes or only considering one-dimensional importance in forming communities. In this paper, we introduce a novel community model, named edge-attributed skyline community (ESC), which not only preserves the structural cohesiveness but unravels the inherent dominance brought about by multi-dimensional attributes on the edges of bipartite graphs. To search the ESCs, we develop an elegant peeling algorithm by iteratively deleting edges with the minimum attribute in each dimension. In addition, we also devise a more efficient expanding algorithm to further reduce the search space and speed up the filtering of unpromising vertices, where a upper bound is proposed and proven. Extensive experiments on real-world large-scale datasets demonstrate the efficiency, effectiveness, and scalability of the proposed ESC search algorithms. A case study was conducted to compare with existing community models, substantiating that our approach facilitates the precision and diversity of results.",
        "subjects": [
            "cs.SI",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12923",
        "abstract url": "https://arxiv.org/abs/2401.12923",
        "title": "Deep multitask neural networks for solving some stochastic optimal control problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2401.12926",
        "abstract url": "https://arxiv.org/abs/2401.12926",
        "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with \"high quality\" data sources may not increase (and can even hurt) performance compared to randomly selecting data. To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously unseen tasks. Specifically, choosing target tasks representative of standard LM problems and evaluating on diverse held-out benchmarks, our selected datasets provide a 2x compute multiplier over baseline methods.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12934",
        "abstract url": "https://arxiv.org/abs/2401.12934",
        "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "comment": "conference version accepted at AISTATS 2024"
    },
    {
        "paper id": "2401.12950",
        "abstract url": "https://arxiv.org/abs/2401.12950",
        "title": "Bayesian Semi-structured Subspace Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach's efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Accepted at AISTATS 2024"
    },
    {
        "paper id": "2401.12961",
        "abstract url": "https://arxiv.org/abs/2401.12961",
        "title": "Chatterbox: Robust Transport for LLM Token Streaming under Unstable Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "To render each generated token in real time, the LLM server generates response tokens one by one and streams each generated token (or group of a few tokens) through the network to the user right after it is generated, which we refer to as LLM token streaming. However, under unstable network conditions, the LLM token streaming experience could suffer greatly from stalls since one packet loss could block the rendering of tokens contained in subsequent packets even if they arrive on time. With a real-world measurement study, we show that current applications including ChatGPT, Claude, and Bard all suffer from increased stall under unstable network. For this emerging token streaming problem in LLM Chatbots, we propose a novel transport layer scheme, called Chatterbox, which puts new generated tokens as well as currently unacknowledged tokens in the next outgoing packet. This ensures that each packet contains some new tokens and can be independently rendered when received, thus avoiding aforementioned stalls caused by missing packets. Through simulation under various network conditions, we show Chatterbox reduces stall ratio (proportion of token rendering wait time) by 71.0% compared to the token streaming method commonly used by real chatbot applications and by 31.6% compared to a custom packet duplication scheme. By tailoring Chatterbox to fit the token-by-token generation of LLM, we enable the Chatbots to respond like an eloquent speaker for users to better enjoy pervasive AI.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13009",
        "abstract url": "https://arxiv.org/abs/2401.13009",
        "title": "Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Nowadays, the need for causal discovery is ubiquitous. A better understanding of not just the stochastic dependencies between parts of a system, but also the actual cause-effect relations, is essential for all parts of science. Thus, the need for reliable methods to detect causal directions is growing constantly. In the last 50 years, many causal discovery algorithms have emerged, but most of them are applicable only under the assumption that the systems have no feedback loops and that they are causally sufficient, i.e. that there are no unmeasured subsystems that can affect multiple measured variables. This is unfortunate since those restrictions can often not be presumed in practice. Feedback is an integral feature of many processes, and real-world systems are rarely completely isolated and fully measured. Fortunately, in recent years, several techniques, that can cope with cyclic, causally insufficient systems, have been developed. And with multiple methods available, a practical application of those algorithms now requires knowledge of the respective strengths and weaknesses. Here, we focus on the problem of causal discovery for sparse linear models which are allowed to have cycles and hidden confounders. We have prepared a comprehensive and thorough comparative study of four causal discovery techniques: two versions of the LLC method [10] and two variants of the ASP-based algorithm [11]. The evaluation investigates the performance of those techniques for various experiments with multiple interventional setups and different dataset sizes.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13020",
        "abstract url": "https://arxiv.org/abs/2401.13020",
        "title": "A Safe Reinforcement Learning Algorithm for Supervisory Control of Power Plants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional control theory-based methods require tailored engineering for each system and constant fine-tuning. In power plant control, one often needs to obtain a precise representation of the system dynamics and carefully design the control scheme accordingly. Model-free Reinforcement learning (RL) has emerged as a promising solution for control tasks due to its ability to learn from trial-and-error interactions with the environment. It eliminates the need for explicitly modeling the environment's dynamics, which is potentially inaccurate. However, the direct imposition of state constraints in power plant control raises challenges for standard RL methods. To address this, we propose a chance-constrained RL algorithm based on Proximal Policy Optimization for supervisory control. Our method employs Lagrangian relaxation to convert the constrained optimization problem into an unconstrained objective, where trainable Lagrange multipliers enforce the state constraints. Our approach achieves the smallest distance of violation and violation rate in a load-follow maneuver for an advanced Nuclear Power Plant design.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13079",
        "abstract url": "https://arxiv.org/abs/2401.13079",
        "title": "No AI After Auschwitz? Bridging AI and Memory Ethics in the Context of Information Retrieval of Genocide-Related Information",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The growing application of artificial intelligence (AI) in the field of information retrieval (IR) affects different domains, including cultural heritage. By facilitating organisation and retrieval of large volumes of heritage-related content, AI-driven IR systems inform users about a broad range of historical phenomena, including genocides (e.g. the Holocaust). However, it is currently unclear to what degree IR systems are capable of dealing with multiple ethical challenges associated with the curation of genocide-related information. To address this question, this chapter provides an overview of ethical challenges associated with the human curation of genocide-related information using a three-part framework inspired by Belmont criteria (i.e. curation challenges associated with respect for individuals, beneficence and justice/fairness). Then, the chapter discusses to what degree the above-mentioned challenges are applicable to the ways in which AI-driven IR systems deal with genocide-related information and what can be the potential ways of bridging AI and memory ethics in this context.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2401.13099",
        "abstract url": "https://arxiv.org/abs/2401.13099",
        "title": "Sparse identification of nonlinear dynamics in the presence of library and system uncertainty",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The SINDy algorithm has been successfully used to identify the governing equations of dynamical systems from time series data. However, SINDy assumes the user has prior knowledge of the variables in the system and of a function library that can act as a basis for the system. In this paper, we demonstrate on real world data how the Augmented SINDy algorithm outperforms SINDy in the presence of system variable uncertainty. We then show SINDy can be further augmented to perform robustly when both kinds of uncertainty are present.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13110",
        "abstract url": "https://arxiv.org/abs/2401.13110",
        "title": "XAI for All: Can Large Language Models Simplify Explainable AI?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The field of Explainable Artificial Intelligence (XAI) often focuses on users with a strong technical background, making it challenging for non-experts to understand XAI methods. This paper presents \"x-[plAIn]\", a new approach to make XAI more accessible to a wider audience through a custom Large Language Model (LLM), developed using ChatGPT Builder. Our goal was to design a model that can generate clear, concise summaries of various XAI methods, tailored for different audiences, including business professionals and academics. The key feature of our model is its ability to adapt explanations to match each audience group's knowledge level and interests. Our approach still offers timely insights, facilitating the decision-making process by the end users. Results from our use-case studies show that our model is effective in providing easy-to-understand, audience-specific explanations, regardless of the XAI method used. This adaptability improves the accessibility of XAI, bridging the gap between complex AI technologies and their practical applications. Our findings indicate a promising direction for LLMs in making advanced AI concepts more accessible to a diverse range of users.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13138",
        "abstract url": "https://arxiv.org/abs/2401.13138",
        "title": "Visibility into AI Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Increased delegation of commercial, scientific, governmental, and personal activities to AI agents -- systems capable of pursuing complex goals with limited supervision -- may exacerbate existing societal risks and introduce new risks. Understanding and mitigating these risks involves critically evaluating existing governance structures, revising and adapting these structures where needed, and ensuring accountability of key stakeholders. Information about where, why, how, and by whom certain AI agents are used, which we refer to as visibility, is critical to these objectives. In this paper, we assess three categories of measures to increase visibility into AI agents: agent identifiers, real-time monitoring, and activity logging. For each, we outline potential implementations that vary in intrusiveness and informativeness. We analyze how the measures apply across a spectrum of centralized through decentralized deployment contexts, accounting for various actors in the supply chain including hardware and software service providers. Finally, we discuss the implications of our measures for privacy and concentration of power. Further work into understanding the measures and mitigating their negative impacts can help to build a foundation for the governance of AI agents.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": "Accepted to ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT 2024)"
    },
    {
        "paper id": "2401.13142",
        "abstract url": "https://arxiv.org/abs/2401.13142",
        "title": "Unsocial Intelligence: a Pluralistic, Democratic, and Participatory Investigation of AGI Discourse",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Dreams of machines that rival human intelligence have shaped the field of AI since its inception. Yet there remains no agreed-upon conception of what human-level AI or artificial general intelligence (AGI) means. We investigate key social, political, and ethical assumptions made by influential conceptions of AGI and human-level AI. We then draw on feminist, STS, and social science scholarship on the political and social character of intelligence in both humans and machines to defend a pluralistic, democratic, and participatory conception of the topic. We argue that framing AGI or human-level AI as a technical or value-neutral topic leads to political, ethical, and epistemic harm. AGI should not be developed without explicit attention to the values they encode, the people they include or exclude, and a view toward epistemic justice.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13177",
        "abstract url": "https://arxiv.org/abs/2401.13177",
        "title": "Deep Learning Model Reuse in the HuggingFace Community: Challenges, Benefit and Trends",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The ubiquity of large-scale Pre-Trained Models (PTMs) is on the rise, sparking interest in model hubs, and dedicated platforms for hosting PTMs. Despite this trend, a comprehensive exploration of the challenges that users encounter and how the community leverages PTMs remains lacking. To address this gap, we conducted an extensive mixed-methods empirical study by focusing on discussion forums and the model hub of HuggingFace, the largest public model hub. Based on our qualitative analysis, we present a taxonomy of the challenges and benefits associated with PTM reuse within this community. We then conduct a quantitative study to track model-type trends and model documentation evolution over time. Our findings highlight prevalent challenges such as limited guidance for beginner users, struggles with model output comprehensibility in training or inference, and a lack of model understanding. We also identified interesting trends among models where some models maintain high upload rates despite a decline in topics related to them. Additionally, we found that despite the introduction of model documentation tools, its quantity has not increased over time, leading to difficulties in model comprehension and selection among users. Our study sheds light on new challenges in reusing PTMs that were not reported before and we provide recommendations for various stakeholders involved in PTM reuse.",
        "subjects": [
            "cs.SE",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "Accepted by IEEE SANER 2024"
    },
    {
        "paper id": "2401.13185",
        "abstract url": "https://arxiv.org/abs/2401.13185",
        "title": "Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cross-validation is a widely used technique for assessing the performance of predictive models on unseen data. Many predictive models, such as Kernel-Based Partial Least-Squares (PLS) models, require the computation of $\\mathbf{X}^{\\mathbf{T}}\\mathbf{X}$ and $\\mathbf{X}^{\\mathbf{T}}\\mathbf{Y}$ using only training set samples from the input and output matrices, $\\mathbf{X}$ and $\\mathbf{Y}$, respectively. In this work, we present three algorithms that efficiently compute these matrices. The first one allows no column-wise preprocessing. The second one allows column-wise centering around the training set means. The third one allows column-wise centering and column-wise scaling around the training set means and standard deviations. Demonstrating correctness and superior computational complexity, they offer significant cross-validation speedup compared with straight-forward cross-validation and previous work on fast cross-validation - all without data leakage. Their suitability for parallelization is highlighted with an open-source Python implementation combining our algorithms with Improved Kernel PLS.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "comment": "24 pages, 1 table, 6 algorithms"
    },
    {
        "paper id": "2401.13199",
        "abstract url": "https://arxiv.org/abs/2401.13199",
        "title": "Why People Still Fall for Phishing Emails: An Empirical Investigation into How Users Make Email Response Decisions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Despite technical and non-technical countermeasures, humans continue to be tricked by phishing emails. How users make email response decisions is a missing piece in the puzzle to identifying why people still fall for phishing emails. We conducted an empirical study using a think-aloud method to investigate how people make 'response decisions' while reading emails. The grounded theory analysis of the in-depth qualitative data has enabled us to identify different elements of email users' decision-making that influence their email response decisions. Furthermore, we developed a theoretical model that explains how people could be driven to respond to emails based on the identified elements of users' email decision-making processes and the relationships uncovered from the data. The findings provide deeper insights into phishing email susceptibility due to people's email response decision-making behavior. We also discuss the implications of our findings for designers and researchers working in anti-phishing training, education, and awareness interventions",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13206",
        "abstract url": "https://arxiv.org/abs/2401.13206",
        "title": "Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a groundbreaking self-improving interference management framework tailored for wireless communications, integrating deep learning with uncertainty quantification to enhance overall system performance. Our approach addresses the computational challenges inherent in traditional optimization-based algorithms by harnessing deep learning models to predict optimal interference management solutions. A significant breakthrough of our framework is its acknowledgment of the limitations inherent in data-driven models, particularly in scenarios not adequately represented by the training dataset. To overcome these challenges, we propose a method for uncertainty quantification, accompanied by a qualifying criterion, to assess the trustworthiness of model predictions. This framework strategically alternates between model-generated solutions and traditional algorithms, guided by a criterion that assesses the prediction credibility based on quantified uncertainties. Experimental results validate the framework's efficacy, demonstrating its superiority over traditional deep learning models, notably in scenarios underrepresented in the training dataset. This work marks a pioneering endeavor in harnessing self-improving deep learning for interference management, through the lens of uncertainty quantification.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.14421",
        "abstract url": "https://arxiv.org/abs/2401.14421",
        "title": "Multi-Agent Based Transfer Learning for Data-Driven Air Traffic Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Research in developing data-driven models for Air Traffic Management (ATM) has gained a tremendous interest in recent years. However, data-driven models are known to have long training time and require large datasets to achieve good performance. To address the two issues, this paper proposes a Multi-Agent Bidirectional Encoder Representations from Transformers (MA-BERT) model that fully considers the multi-agent characteristic of the ATM system and learns air traffic controllers' decisions, and a pre-training and fine-tuning transfer learning framework. By pre-training the MA-BERT on a large dataset from a major airport and then fine-tuning it to other airports and specific air traffic applications, a large amount of the total training time can be saved. In addition, for newly adopted procedures and constructed airports where no historical data is available, this paper shows that the pre-trained MA-BERT can achieve high performance by updating regularly with little data. The proposed transfer learning framework and MA-BERT are tested with the automatic dependent surveillance-broadcast data recorded in 3 airports in South Korea in 2019.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "eess.SY",
            "stat.ML"
        ],
        "comment": "12 pages, 8 figures, submitted for IEEE Transactions on Intelligent Transportation System"
    },
    {
        "paper id": "2401.14422",
        "abstract url": "https://arxiv.org/abs/2401.14422",
        "title": "Location Agnostic Source-Free Domain Adaptive Learning to Predict Solar Power Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The prediction of solar power generation is a challenging task due to its dependence on climatic characteristics that exhibit spatial and temporal variability. The performance of a prediction model may vary across different places due to changes in data distribution, resulting in a model that works well in one region but not in others. Furthermore, as a consequence of global warming, there is a notable acceleration in the alteration of weather patterns on an annual basis. This phenomenon introduces the potential for diminished efficacy of existing models, even within the same geographical region, as time progresses. In this paper, a domain adaptive deep learning-based framework is proposed to estimate solar power generation using weather features that can solve the aforementioned challenges. A feed-forward deep convolutional network model is trained for a known location dataset in a supervised manner and utilized to predict the solar power of an unknown location later. This adaptive data-driven approach exhibits notable advantages in terms of computing speed, storage efficiency, and its ability to improve outcomes in scenarios where state-of-the-art non-adaptive methods fail. Our method has shown an improvement of $10.47 \\%$, $7.44 \\%$, $5.11\\%$ in solar power prediction accuracy compared to best performing non-adaptive method for California (CA), Florida (FL) and New York (NY), respectively.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.15513",
        "abstract url": "https://arxiv.org/abs/2402.15513",
        "title": "Investigating the Generalizability of Physiological Characteristics of Anxiety",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent works have demonstrated the effectiveness of machine learning (ML) techniques in detecting anxiety and stress using physiological signals, but it is unclear whether ML models are learning physiological features specific to stress. To address this ambiguity, we evaluated the generalizability of physiological features that have been shown to be correlated with anxiety and stress to high-arousal emotions. Specifically, we examine features extracted from electrocardiogram (ECG) and electrodermal (EDA) signals from the following three datasets: Anxiety Phases Dataset (APD), Wearable Stress and Affect Detection (WESAD), and the Continuously Annotated Signals of Emotion (CASE) dataset. We aim to understand whether these features are specific to anxiety or general to other high-arousal emotions through a statistical regression analysis, in addition to a within-corpus, cross-corpus, and leave-one-corpus-out cross-validation across instances of stress and arousal. We used the following classifiers: Support Vector Machines, LightGBM, Random Forest, XGBoost, and an ensemble of the aforementioned models. We found that models trained on an arousal dataset perform relatively well on a previously unseen stress dataset, and vice versa. Our experimental results suggest that the evaluated models may be identifying emotional arousal instead of stress. This work is the first cross-corpus evaluation across stress and arousal from ECG and EDA signals, contributing new findings about the generalizability of stress detection.",
        "subjects": [
            "cs.MM",
            "cs.LG",
            "eess.SP",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.16869",
        "abstract url": "https://arxiv.org/abs/2402.16869",
        "title": "Considering Fundamental Rights in the European Standardisation of Artificial Intelligence: Nonsense or Strategic Alliance?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the European context, both the EU AI Act proposal and the draft Standardisation Request on safe and trustworthy AI link standardisation to fundamental rights. However, these texts do not provide any guidelines that specify and detail the relationship between AI standards and fundamental rights, its meaning or implication. This chapter aims to clarify this critical regulatory blind spot. The main issue tackled is whether the adoption of AI harmonised standards, based on the future AI Act, should take into account fundamental rights. In our view, the response is yes. The high risks posed by certain AI systems relate in particular to infringements of fundamental rights. Therefore, mitigating such risks involves fundamental rights considerations and this is what future harmonised standards should reflect. At the same time, valid criticisms of the European standardisation process have to be addressed. Finally, the practical incorporation of fundamental rights considerations in the ongoing European standardisation of AI systems is discussed.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.03660",
        "abstract url": "https://arxiv.org/abs/2404.03660",
        "title": "Machine Learning in Proton Exchange Membrane Water Electrolysis -- Part I: A Knowledge-Integrated Framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we propose to adopt a novel framework, Knowledge-integrated Machine Learning, for advancing Proton Exchange Membrane Water Electrolysis (PEMWE) development. Given the significance of PEMWE in green hydrogen production and the inherent challenges in optimizing its performance, our framework aims to meld data-driven models with domain-specific insights systematically to address the domain challenges. We first identify the uncertainties originating from data acquisition conditions, data-driven model mechanisms, and domain expertise, highlighting their complementary characteristics in carrying information from different perspectives. Building upon this foundation, we showcase how to adeptly decompose knowledge and extract unique information to contribute to the data augmentation, modeling process, and knowledge discovery. We demonstrate a hierarchical three-level framework, termed the \"Ladder of Knowledge-integrated Machine Learning\", in the PEMWE context, applying it to three case studies within a context of cell degradation analysis to affirm its efficacy in interpolation, extrapolation, and information representation. This research lays the groundwork for more knowledge-informed enhancements in ML applications in engineering.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": "21 pages, 7 figures"
    },
    {
        "paper id": "2401.12532",
        "abstract url": "https://arxiv.org/abs/2401.12532",
        "title": "DAFA: Distance-Aware Fair Adversarial Training",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The disparity in accuracy between classes in standard training is amplified during adversarial training, a phenomenon termed the robust fairness problem. Existing methodologies aimed to enhance robust fairness by sacrificing the model's performance on easier classes in order to improve its performance on harder ones. However, we observe that under adversarial attacks, the majority of the model's predictions for samples from the worst class are biased towards classes similar to the worst class, rather than towards the easy classes. Through theoretical and empirical analysis, we demonstrate that robust fairness deteriorates as the distance between classes decreases. Motivated by these insights, we introduce the Distance-Aware Fair Adversarial training (DAFA) methodology, which addresses robust fairness by taking into account the similarities between classes. Specifically, our method assigns distinct loss weights and adversarial margins to each class and adjusts them to encourage a trade-off in robustness among similar classes. Experimental results across various datasets demonstrate that our method not only maintains average robust accuracy but also significantly improves the worst robust accuracy, indicating a marked improvement in robust fairness compared to existing methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to ICLR 2024"
    },
    {
        "paper id": "2401.12566",
        "abstract url": "https://arxiv.org/abs/2401.12566",
        "title": "Automated Fact-Checking of Climate Change Claims with Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents Climinator, a novel AI-based tool designed to automate the fact-checking of climate change claims. Utilizing an array of Large Language Models (LLMs) informed by authoritative sources like the IPCC reports and peer-reviewed scientific literature, Climinator employs an innovative Mediator-Advocate framework. This design allows Climinator to effectively synthesize varying scientific perspectives, leading to robust, evidence-based evaluations. Our model demonstrates remarkable accuracy when testing claims collected from Climate Feedback and Skeptical Science. Notably, when integrating an advocate with a climate science denial perspective in our framework, Climinator's iterative debate process reliably converges towards scientific consensus, underscoring its adeptness at reconciling diverse viewpoints into science-based, factual conclusions. While our research is subject to certain limitations and necessitates careful interpretation, our approach holds significant potential. We hope to stimulate further research and encourage exploring its applicability in other contexts, including political fact-checking and legal domains.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12570",
        "abstract url": "https://arxiv.org/abs/2401.12570",
        "title": "DiffMoog: a Differentiable Modular Synthesizer for Sound Matching",
        "rating": "0",
        "keywords": [
            [
                "Synthesizer"
            ],
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "This paper presents DiffMoog - a differentiable modular synthesizer with a comprehensive set of modules typically found in commercial instruments. Being differentiable, it allows integration into neural networks, enabling automated sound matching, to replicate a given audio input. Notably, DiffMoog facilitates modulation capabilities (FM/AM), low-frequency oscillators (LFOs), filters, envelope shapers, and the ability for users to create custom signal chains. We introduce an open-source platform that comprises DiffMoog and an end-to-end sound matching framework. This framework utilizes a novel signal-chain loss and an encoder network that self-programs its outputs to predict DiffMoogs parameters based on the user-defined modular architecture. Moreover, we provide insights and lessons learned towards sound matching using differentiable synthesis. Combining robust sound capabilities with a holistic platform, DiffMoog stands as a premier asset for expediting research in audio synthesis and machine learning.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "5 pages, 7 figures, 1 table, Our code is released at https://github.com/aisynth/diffmoog"
    },
    {
        "paper id": "2401.12587",
        "abstract url": "https://arxiv.org/abs/2401.12587",
        "title": "Fast Implicit Neural Representation Image Codec in Resource-limited Devices",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Displaying high-quality images on edge devices, such as augmented reality devices, is essential for enhancing the user experience. However, these devices often face power consumption and computing resource limitations, making it challenging to apply many deep learning-based image compression algorithms in this field. Implicit Neural Representation (INR) for image compression is an emerging technology that offers two key benefits compared to cutting-edge autoencoder models: low computational complexity and parameter-free decoding. It also outperforms many traditional and early neural compression methods in terms of quality. In this study, we introduce a new Mixed Autoregressive Model (MARM) to significantly reduce the decoding time for the current INR codec, along with a new synthesis network to enhance reconstruction quality. MARM includes our proposed Autoregressive Upsampler (ARU) blocks, which are highly computationally efficient, and ARM from previous work to balance decoding time and reconstruction quality. We also propose enhancing ARU's performance using a checkerboard two-stage decoding strategy. Moreover, the ratio of different modules can be adjusted to maintain a balance between quality and speed. Comprehensive experiments demonstrate that our method significantly improves computational efficiency while preserving image quality. With different parameter settings, our method can outperform popular AE-based codecs in constrained environments in terms of both quality and decoding time, or achieve state-of-the-art reconstruction quality compared to other INR codecs.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12596",
        "abstract url": "https://arxiv.org/abs/2401.12596",
        "title": "UniHDA: A Unified and Versatile Framework for Multi-Modal Hybrid Domain Adaptation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, generative domain adaptation has achieved remarkable progress, enabling us to adapt a pre-trained generator to a new target domain. However, existing methods simply adapt the generator to a single target domain and are limited to a single modality, either text-driven or image-driven. Moreover, they cannot maintain well consistency with the source domain, which impedes the inheritance of the diversity. In this paper, we propose UniHDA, a \\textbf{unified} and \\textbf{versatile} framework for generative hybrid domain adaptation with multi-modal references from multiple domains. We use CLIP encoder to project multi-modal references into a unified embedding space and then linearly interpolate the direction vectors from multiple target domains to achieve hybrid domain adaptation. To ensure \\textbf{consistency} with the source domain, we propose a novel cross-domain spatial structure (CSS) loss that maintains detailed spatial structure information between source and target generator. Experiments show that the adapted generator can synthesise realistic images with various attribute compositions. Additionally, our framework is generator-agnostic and versatile to multiple generators, e.g., StyleGAN, EG3D, and Diffusion Models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12648",
        "abstract url": "https://arxiv.org/abs/2401.12648",
        "title": "Consistency Enhancement-Based Deep Multiview Clustering via Contrastive Learning",
        "rating": "0",
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Multiview clustering (MVC) segregates data samples into meaningful clusters by synthesizing information across multiple views. Moreover, deep learning-based methods have demonstrated their strong feature learning capabilities in MVC scenarios. However, effectively generalizing feature representations while maintaining consistency is still an intractable problem. In addition, most existing deep clustering methods based on contrastive learning overlook the consistency of the clustering representations during the clustering process. In this paper, we show how the above problems can be overcome and propose a consistent enhancement-based deep MVC method via contrastive learning (CCEC). Specifically, semantic connection blocks are incorporated into a feature representation to preserve the consistent information among multiple views. Furthermore, the representation process for clustering is enhanced through spectral clustering, and the consistency across multiple views is improved. Experiments conducted on five datasets demonstrate the effectiveness and superiority of our method in comparison with the state-of-the-art (SOTA) methods. The code for this method can be accessed at https://anonymous.4open.science/r/CCEC-E84E/.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "There are multiple errors that need to be corrected, including some formulas and concept descriptions. We will re upload the paper after the modifications are completed"
    },
    {
        "paper id": "2401.12671",
        "abstract url": "https://arxiv.org/abs/2401.12671",
        "title": "Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the continuously advancing AI landscape, crafting context-rich and meaningful responses via Large Language Models (LLMs) is essential. Researchers are becoming more aware of the challenges that LLMs with fewer parameters encounter when trying to provide suitable answers to open-ended questions. To address these hurdles, the integration of cutting-edge strategies, augmentation of rich external domain knowledge to LLMs, offers significant improvements. This paper introduces a novel framework that combines graph-driven context retrieval in conjunction to knowledge graphs based enhancement, honing the proficiency of LLMs, especially in domain specific community question answering platforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on various LLMs with different parameter sizes to evaluate their ability to ground knowledge and determine factual accuracy in answers to open-ended questions. Our methodology GraphContextGen consistently outperforms dominant text-based retrieval systems, demonstrating its robustness and adaptability to a larger number of use cases. This advancement highlights the importance of pairing context rich data retrieval with LLMs, offering a renewed approach to knowledge sourcing and generation in AI systems. We also show that, due to rich contextual data retrieval, the crucial entities, along with the generated answer, remain factually coherent with the gold answer.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12686",
        "abstract url": "https://arxiv.org/abs/2401.12686",
        "title": "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ],
        "comment": "accepted at ICLR 2024"
    },
    {
        "paper id": "2401.12694",
        "abstract url": "https://arxiv.org/abs/2401.12694",
        "title": "Pragmatic Communication in Multi-Agent Collaborative Perception",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Collaborative perception allows each agent to enhance its perceptual abilities by exchanging messages with others. It inherently results in a trade-off between perception ability and communication costs. Previous works transmit complete full-frame high-dimensional feature maps among agents, resulting in substantial communication costs. To promote communication efficiency, we propose only transmitting the information needed for the collaborator's downstream task. This pragmatic communication strategy focuses on three key aspects: i) pragmatic message selection, which selects task-critical parts from the complete data, resulting in spatially and temporally sparse feature vectors; ii) pragmatic message representation, which achieves pragmatic approximation of high-dimensional feature vectors with a task-adaptive dictionary, enabling communicating with integer indices; iii) pragmatic collaborator selection, which identifies beneficial collaborators, pruning unnecessary communication links. Following this strategy, we first formulate a mathematical optimization framework for the perception-communication trade-off and then propose PragComm, a multi-agent collaborative perception system with two key components: i) single-agent detection and tracking and ii) pragmatic collaboration. The proposed PragComm promotes pragmatic communication and adapts to a wide range of communication conditions. We evaluate PragComm for both collaborative 3D object detection and tracking tasks in both real-world, V2V4Real, and simulation datasets, OPV2V and V2X-SIM2.0. PragComm consistently outperforms previous methods with more than 32.7K times lower communication volume on OPV2V. Code is available at github.com/PhyllisH/PragComm.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2401.12713",
        "abstract url": "https://arxiv.org/abs/2401.12713",
        "title": "Generating Zero-shot Abstractive Explanations for Rumour Verification",
        "rating": "0",
        "keywords": [
            [
                "GNN"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The task of rumour verification in social media concerns assessing the veracity of a claim on the basis of conversation threads that result from it. While previous work has focused on predicting a veracity label, here we reformulate the task to generate model-centric free-text explanations of a rumour's veracity. The approach is model agnostic in that it generalises to any model. Here we propose a novel GNN-based rumour verification model. We follow a zero-shot approach by first applying post-hoc explainability methods to score the most important posts within a thread and then we use these posts to generate informative explanations using opinion-guided summarisation. To evaluate the informativeness of the explanatory summaries, we exploit the few-shot learning capabilities of a large language model (LLM). Our experiments show that LLMs can have similar agreement to humans in evaluating summaries. Importantly, we show explanatory abstractive summaries are more informative and better reflect the predicted rumour veracity than just using the highest ranking posts in the thread.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Revised version of the original"
    },
    {
        "paper id": "2401.12751",
        "abstract url": "https://arxiv.org/abs/2401.12751",
        "title": "PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Surface reconstruction has traditionally relied on the Multi-View Stereo (MVS)-based pipeline, which often suffers from noisy and incomplete geometry. This is due to that although MVS has been proven to be an effective way to recover the geometry of the scenes, especially for locally detailed areas with rich textures, it struggles to deal with areas with low texture and large variations of illumination where the photometric consistency is unreliable. Recently, Neural Implicit Surface Reconstruction (NISR) combines surface rendering and volume rendering techniques and bypasses the MVS as an intermediate step, which has emerged as a promising alternative to overcome the limitations of traditional pipelines. While NISR has shown impressive results on simple scenes, it remains challenging to recover delicate geometry from uncontrolled real-world scenes which is caused by its underconstrained optimization. To this end, the framework PSDF is proposed which resorts to external geometric priors from a pretrained MVS network and internal geometric priors inherent in the NISR model to facilitate high-quality neural implicit surface learning. Specifically, the visibility-aware feature consistency loss and depth prior-assisted sampling based on external geometric priors are introduced. These proposals provide powerfully geometric consistency constraints and aid in locating surface intersection points, thereby significantly improving the accuracy and delicate reconstruction of NISR. Meanwhile, the internal prior-guided importance rendering is presented to enhance the fidelity of the reconstructed surface mesh by mitigating the biased rendering issue in NISR. Extensive experiments on the Tanks and Temples dataset show that PSDF achieves state-of-the-art performance on complex uncontrolled scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12798",
        "abstract url": "https://arxiv.org/abs/2401.12798",
        "title": "Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding",
        "rating": "0",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Entity alignment (EA), a pivotal process in integrating multi-source Knowledge Graphs (KGs), seeks to identify equivalent entity pairs across these graphs. Most existing approaches regard EA as a graph representation learning task, concentrating on enhancing graph encoders. However, the decoding process in EA - essential for effective operation and alignment accuracy - has received limited attention and remains tailored to specific datasets and model architectures, necessitating both entity and additional explicit relation embeddings. This specificity limits its applicability, particularly in GNN-based models. To address this gap, we introduce a novel, generalized, and efficient decoding approach for EA, relying solely on entity embeddings. Our method optimizes the decoding process by minimizing Dirichlet energy, leading to the gradient flow within the graph, to maximize graph homophily. The discretization of the gradient flow produces a fast and scalable approach, termed Triple Feature Propagation (TFP). TFP innovatively generalizes adjacency matrices to multi-views matrices:entity-to-entity, entity-to-relation, relation-to-entity, and relation-to-triple. The gradient flow through generalized matrices enables TFP to harness the multi-view structural information of KGs. Rigorous experimentation on diverse public datasets demonstrates that our approach significantly enhances various EA methods. Notably, the approach achieves these advancements with less than 6 seconds of additional computational time, establishing a new benchmark in efficiency and adaptability for future EA methods.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12835",
        "abstract url": "https://arxiv.org/abs/2401.12835",
        "title": "SGTR+: End-to-end Scene Graph Generation with Transformer",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Scene Graph Generation (SGG) remains a challenging visual understanding task due to its compositional property. Most previous works adopt a bottom-up, two-stage or point-based, one-stage approach, which often suffers from high time complexity or suboptimal designs. In this work, we propose a novel SGG method to address the aforementioned issues, formulating the task as a bipartite graph construction problem. To address the issues above, we create a transformer-based end-to-end framework to generate the entity and entity-aware predicate proposal set, and infer directed edges to form relation triplets. Moreover, we design a graph assembling module to infer the connectivity of the bipartite scene graph based on our entity-aware structure, enabling us to generate the scene graph in an end-to-end manner. Based on bipartite graph assembling paradigm, we further propose a new technical design to address the efficacy of entity-aware modeling and optimization stability of graph assembling. Equipped with the enhanced entity-aware design, our method achieves optimal performance and time-complexity. Extensive experimental results show that our design is able to achieve the state-of-the-art or comparable performance on three challenging benchmarks, surpassing most of the existing approaches and enjoying higher efficiency in inference. Code is available: https://github.com/Scarecrow0/SGTR",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by TPAMI: https://ieeexplore.ieee.org/document/10315230"
    },
    {
        "paper id": "2401.12850",
        "abstract url": "https://arxiv.org/abs/2401.12850",
        "title": "Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization",
        "rating": "0",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "Speaker diarization, the task of segmenting an audio recording based on speaker identity, constitutes an important speech pre-processing step for several downstream applications. The conventional approach to diarization involves multiple steps of embedding extraction and clustering, which are often optimized in an isolated fashion. While end-to-end diarization systems attempt to learn a single model for the task, they are often cumbersome to train and require large supervised datasets. In this paper, we propose an end-to-end supervised hierarchical clustering algorithm based on graph neural networks (GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). The E-SHARC approach uses front-end mel-filterbank features as input and jointly learns an embedding extractor and the GNN clustering module, performing representation learning, metric learning, and clustering with end-to-end optimization. Further, with additional inputs from an external overlap detector, the E-SHARC approach is capable of predicting the speakers in the overlapping speech regions. The experimental evaluation on several benchmark datasets like AMI, VoxConverse and DISPLACE, illustrates that the proposed E-SHARC framework improves significantly over the state-of-art diarization systems.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2401.12874",
        "abstract url": "https://arxiv.org/abs/2401.12874",
        "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "model editing"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Explainability for Large Language Models (LLMs) is a critical yet challenging aspect of natural language processing. As LLMs are increasingly integral to diverse applications, their \"black-box\" nature sparks significant concerns regarding transparency and ethical use. This survey underscores the imperative for increased explainability in LLMs, delving into both the research on explainability and the various methodologies and tasks that utilize an understanding of these models. Our focus is primarily on pre-trained Transformer-based LLMs, such as LLaMA family, which pose distinctive interpretability challenges due to their scale and complexity. In terms of existing methods, we classify them into local and global analyses, based on their explanatory objectives. When considering the utilization of explainability, we explore several compelling methods that concentrate on model editing, control generation, and model enhancement. Additionally, we examine representative evaluation metrics and datasets, elucidating their advantages and limitations. Our goal is to reconcile theoretical and empirical understanding with practical implementation, proposing exciting avenues for explanatory techniques and their applications in the LLMs era.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12945",
        "abstract url": "https://arxiv.org/abs/2401.12945",
        "title": "Lumiere: A Space-Time Diffusion Model for Video Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "synthesizing",
                "inpainting",
                "video editing",
                "text-to-video",
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Lumiere -- a text-to-video diffusion model designed for synthesizing videos that portray realistic, diverse and coherent motion -- a pivotal challenge in video synthesis. To this end, we introduce a Space-Time U-Net architecture that generates the entire temporal duration of the video at once, through a single pass in the model. This is in contrast to existing video models which synthesize distant keyframes followed by temporal super-resolution -- an approach that inherently makes global temporal consistency difficult to achieve. By deploying both spatial and (importantly) temporal down- and up-sampling and leveraging a pre-trained text-to-image diffusion model, our model learns to directly generate a full-frame-rate, low-resolution video by processing it in multiple space-time scales. We demonstrate state-of-the-art text-to-video generation results, and show that our design easily facilitates a wide range of content creation tasks and video editing applications, including image-to-video, video inpainting, and stylized generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Webpage: https://lumiere-video.github.io/ | Video: https://www.youtube.com/watch?v=wxLr02Dz2Sc"
    },
    {
        "paper id": "2401.12946",
        "abstract url": "https://arxiv.org/abs/2401.12946",
        "title": "Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skeletonization",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Coverage Axis++, a novel and efficient approach to 3D shape skeletonization. The current state-of-the-art approaches for this task often rely on the watertightness of the input or suffer from substantial computational costs, thereby limiting their practicality. To address this challenge, Coverage Axis++ proposes a heuristic algorithm to select skeletal points, offering a high-accuracy approximation of the Medial Axis Transform (MAT) while significantly mitigating computational intensity for various shape representations. We introduce a simple yet effective strategy that considers shape coverage, uniformity, and centrality to derive skeletal points. The selection procedure enforces consistency with the shape structure while favoring the dominant medial balls, which thus introduces a compact underlying shape representation in terms of MAT. As a result, Coverage Axis++ allows for skeletonization for various shape representations (e.g., water-tight meshes, triangle soups, point clouds), specification of the number of skeletal points, few hyperparameters, and highly efficient computation with improved reconstruction accuracy. Extensive experiments across a wide range of 3D shapes validate the efficiency and effectiveness of Coverage Axis++. The code will be publicly available once the paper is published.",
        "subjects": [
            "cs.CV",
            "cs.CG",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13006",
        "abstract url": "https://arxiv.org/abs/2401.13006",
        "title": "CIMGEN: Controlled Image Manipulation by Finetuning Pretrained Generative Models on Limited Data",
        "rating": "0",
        "keywords": [
            [
                "GAN",
                "image editing"
            ],
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "Content creation and image editing can benefit from flexible user controls. A common intermediate representation for conditional image generation is a semantic map, that has information of objects present in the image. When compared to raw RGB pixels, the modification of semantic map is much easier. One can take a semantic map and easily modify the map to selectively insert, remove, or replace objects in the map. The method proposed in this paper takes in the modified semantic map and alter the original image in accordance to the modified map. The method leverages traditional pre-trained image-to-image translation GANs, such as CycleGAN or Pix2Pix GAN, that are fine-tuned on a limited dataset of reference images associated with the semantic maps. We discuss the qualitative and quantitative performance of our technique to illustrate its capacity and possible applications in the fields of image forgery and image editing. We also demonstrate the effectiveness of the proposed image forgery technique in thwarting the numerous deep learning-based image forensic techniques, highlighting the urgent need to develop robust and generalizable image forensic tools in the fight against the spread of fake media.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13011",
        "abstract url": "https://arxiv.org/abs/2401.13011",
        "title": "CCA: Collaborative Competitive Agents for Image Editing",
        "rating": "0",
        "keywords": [
            [
                "Image Editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel generative model, Collaborative Competitive Agents (CCA), which leverages the capabilities of multiple Large Language Models (LLMs) based agents to execute complex tasks. Drawing inspiration from Generative Adversarial Networks (GANs), the CCA system employs two equal-status generator agents and a discriminator agent. The generators independently process user instructions and generate results, while the discriminator evaluates the outputs, and provides feedback for the generator agents to further reflect and improve the generation results. Unlike the previous generative model, our system can obtain the intermediate steps of generation. This allows each generator agent to learn from other successful executions due to its transparency, enabling a collaborative competition that enhances the quality and robustness of the system's results. The primary focus of this study is image editing, demonstrating the CCA's ability to handle intricate instructions robustly. The paper's main contributions include the introduction of a multi-agent-based generative model with controllable intermediate steps and iterative optimization, a detailed examination of agent relationships, and comprehensive experiments on image editing. Code is available at \\href{https://github.com/TiankaiHang/CCA}{https://github.com/TiankaiHang/CCA}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13034",
        "abstract url": "https://arxiv.org/abs/2401.13034",
        "title": "Locality Sensitive Sparse Encoding for Learning World Models Online",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Acquiring an accurate world model online for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features. We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift. We also show, in the Dyna MBRL setting, that our world models learned online using a single pass of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2401.13082",
        "abstract url": "https://arxiv.org/abs/2401.13082",
        "title": "PlaceFormer: Transformer-based Visual Place Recognition using Multi-Scale Patch Selection and Fusion",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual place recognition is a challenging task in the field of computer vision, and autonomous robotics and vehicles, which aims to identify a location or a place from visual inputs. Contemporary methods in visual place recognition employ convolutional neural networks and utilize every region within the image for the place recognition task. However, the presence of dynamic and distracting elements in the image may impact the effectiveness of the place recognition process. Therefore, it is meaningful to focus on task-relevant regions of the image for improved recognition. In this paper, we present PlaceFormer, a novel transformer-based approach for visual place recognition. PlaceFormer employs patch tokens from the transformer to create global image descriptors, which are then used for image retrieval. To re-rank the retrieved images, PlaceFormer merges the patch tokens from the transformer to form multi-scale patches. Utilizing the transformer's self-attention mechanism, it selects patches that correspond to task-relevant areas in an image. These selected patches undergo geometric verification, generating similarity scores across different patch sizes. Subsequently, spatial scores from each patch size are fused to produce a final similarity score. This score is then used to re-rank the images initially retrieved using global image descriptors. Extensive experiments on benchmark datasets demonstrate that PlaceFormer outperforms several state-of-the-art methods in terms of accuracy and computational efficiency, requiring less time and memory.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13097",
        "abstract url": "https://arxiv.org/abs/2401.13097",
        "title": "Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems",
        "rating": "0",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES). This trend is consistent across two datasets of international images and within the diverse economic and racial landscapes of the United States. This research contributes to understanding biases in computer vision, emphasizing the need for more inclusive and representative training datasets. By mitigating the bias in the computer vision pipelines, we can ensure fairer and more equitable outcomes for applied computer vision, including home valuation and smart home security systems. There is urgency in addressing these biases, which can significantly impact critical decisions in urban development and resource allocation. Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "20 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2401.13114",
        "abstract url": "https://arxiv.org/abs/2401.13114",
        "title": "Viewport Prediction, Bitrate Selection, and Beamforming Design for THz-Enabled 360-Degree Video Streaming",
        "rating": "0",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "360-degree videos require significant bandwidth to provide an immersive viewing experience. Wireless systems using terahertz (THz) frequency band can meet this high data rate demand. However, self-blockage is a challenge in such systems. To ensure reliable transmission, this paper explores THz-enabled 360-degree video streaming through multiple multi-antenna access points (APs). Guaranteeing users' quality of experience (QoE) requires accurate viewport prediction to determine which video tiles to send, followed by asynchronous bitrate selection for those tiles and beamforming design at the APs. To address users' privacy and data heterogeneity, we propose a content-based viewport prediction framework, wherein users' head movement prediction models are trained using a personalized federated learning algorithm. To address asynchronous decision-making for tile bitrates and dynamic THz link connections, we formulate the optimization of bitrate selection and beamforming as a macro-action decentralized partially observable Markov decision process (MacDec-POMDP) problem. To efficiently tackle this problem for multiple users, we develop two deep reinforcement learning (DRL) algorithms based on multi-agent actor-critic methods and propose a hierarchical learning framework to train the actor and critic networks. Experimental results show that our proposed approach provides a higher QoE when compared with three benchmark algorithms.",
        "subjects": [
            "eess.IV",
            "eess.SP"
        ],
        "comment": "14 pages, 11 figures. This paper has been submitted to an IEEE journal for possible publication"
    },
    {
        "paper id": "2401.13171",
        "abstract url": "https://arxiv.org/abs/2401.13171",
        "title": "Compositional Generative Inverse Design",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method generalizes to more objects for N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task. Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE"
        ],
        "comment": "ICLR 2024 spotlight. 30 pages, 17 figures"
    },
    {
        "paper id": "2401.13172",
        "abstract url": "https://arxiv.org/abs/2401.13172",
        "title": "ADMap: Anti-disturbance framework for reconstructing online vectorized HD map",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the field of autonomous driving, online high-definition (HD) map reconstruction is crucial for planning tasks. Recent research has developed several high-performance HD map reconstruction models to meet this necessity. However, the point sequences within the instance vectors may be jittery or jagged due to prediction bias, which can impact subsequent tasks. Therefore, this paper proposes the Anti-disturbance Map reconstruction framework (ADMap). To mitigate point-order jitter, the framework consists of three modules: Multi-Scale Perception Neck, Instance Interactive Attention (IIA), and Vector Direction Difference Loss (VDDL). By exploring the point-order relationships between and within instances in a cascading manner, the model can monitor the point-order prediction process more effectively. ADMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets. Extensive results demonstrate its ability to produce stable and reliable map elements in complex and changing driving scenarios. Code and more demos are available at https://github.com/hht1996ok/ADMap.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13212",
        "abstract url": "https://arxiv.org/abs/2401.13212",
        "title": "AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper describes a simple yet effective technique for refining a pretrained classifier network. The proposed AdCorDA method is based on modification of the training set and making use of the duality between network weights and layer inputs. We call this input space training. The method consists of two stages - adversarial correction followed by domain adaptation. Adversarial correction uses adversarial attacks to correct incorrect training-set classifications. The incorrectly classified samples of the training set are removed and replaced with the adversarially corrected samples to form a new training set, and then, in the second stage, domain adaptation is performed back to the original training set. Extensive experimental validations show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The technique can be straightforwardly applied to refinement of weight-quantized neural networks, where experiments show substantial enhancement in performance over the baseline. The adversarial correction technique also results in enhanced robustness to adversarial attacks.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13214",
        "abstract url": "https://arxiv.org/abs/2401.13214",
        "title": "AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network",
        "rating": "0",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, methods based on deep learning have been successfully applied to ship detection for synthetic aperture radar (SAR) images. Despite the development of numerous ship detection methodologies, detecting small and coastal ships remains a significant challenge due to the limited features and clutter in coastal environments. For that, a novel adaptive multi-hierarchical attention module (AMAM) is proposed to learn multi-scale features and adaptively aggregate salient features from various feature layers, even in complex environments. Specifically, we first fuse information from adjacent feature layers to enhance the detection of smaller targets, thereby achieving multi-scale feature enhancement. Then, to filter out the adverse effects of complex backgrounds, we dissect the previously fused multi-level features on the channel, individually excavate the salient regions, and adaptively amalgamate features originating from different channels. Thirdly, we present a novel adaptive multi-hierarchical attention network (AMANet) by embedding the AMAM between the backbone network and the feature pyramid network (FPN). Besides, the AMAM can be readily inserted between different frameworks to improve object detection. Lastly, extensive experiments on two large-scale SAR ship detection datasets demonstrate that our AMANet method is superior to state-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2401.13227",
        "abstract url": "https://arxiv.org/abs/2401.13227",
        "title": "LPNL: Scalable Link Prediction with Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Exploring the application of large language models (LLMs) to graph learning is a emerging endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This work focuses on the link prediction task and introduces $\\textbf{LPNL}$ (Link Prediction via Natural Language), a framework based on large language models designed for scalable link prediction on large-scale heterogeneous graphs. We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from the graphs, and a divide-and-conquer strategy to control the input tokens within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for link prediction. Extensive experimental results demonstrate that LPNL outperforms multiple advanced baselines in link prediction tasks on large-scale graphs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01692",
        "abstract url": "https://arxiv.org/abs/2402.01692",
        "title": "Maximizing Data Efficiency for Cross-Lingual TTS Adaptation by Self-Supervised Representation Mixing and Embedding Initialization",
        "rating": "0",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents an effective transfer learning framework for language adaptation in text-to-speech systems, with a focus on achieving language adaptation using minimal labeled and unlabeled data. While many works focus on reducing the usage of labeled data, very few consider minimizing the usage of unlabeled data. By utilizing self-supervised features in the pretraining stage, replacing the noisy portion of pseudo labels with these features during fine-tuning, and incorporating an embedding initialization trick, our method leverages more information from unlabeled data compared to conventional approaches. Experimental results show that our framework is able to synthesize intelligible speech in unseen languages with only 4 utterances of labeled data and 15 minutes of unlabeled data. Our methodology continues to surpass conventional techniques, even when a greater volume of data is accessible. These findings highlight the potential of our data-efficient language adaptation framework.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted by ASRU 2023"
    },
    {
        "paper id": "2401.12489",
        "abstract url": "https://arxiv.org/abs/2401.12489",
        "title": "Unsupervised Learning Method for the Wave Equation Based on Finite Difference Residual Constraints Loss",
        "rating": "-0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The wave equation is an important physical partial differential equation, and in recent years, deep learning has shown promise in accelerating or replacing traditional numerical methods for solving it. However, existing deep learning methods suffer from high data acquisition costs, low training efficiency, and insufficient generalization capability for boundary conditions. To address these issues, this paper proposes an unsupervised learning method for the wave equation based on finite difference residual constraints. We construct a novel finite difference residual constraint based on structured grids and finite difference methods, as well as an unsupervised training strategy, enabling convolutional neural networks to train without data and predict the forward propagation process of waves. Experimental results show that finite difference residual constraints have advantages over physics-informed neural networks (PINNs) type physical information constraints, such as easier fitting, lower computational costs, and stronger source term generalization capability, making our method more efficient in training and potent in application.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "in Chinese language"
    },
    {
        "paper id": "2401.12496",
        "abstract url": "https://arxiv.org/abs/2401.12496",
        "title": "DexTouch: Learning to Seek and Manipulate Objects with Tactile Dexterity",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The sense of touch is an essential ability for skillfully performing a variety of tasks, providing the capacity to search and manipulate objects without relying on visual information. Extensive research has been conducted over time to apply these human tactile abilities to robots. In this paper, we introduce a multi-finger robot system designed to search for and manipulate objects using the sense of touch without relying on visual information. Randomly located target objects are searched using tactile sensors, and the objects are manipulated for tasks that mimic daily-life. The objective of the study is to endow robots with human-like tactile capabilities. To achieve this, binary tactile sensors are implemented on one side of the robot hand to minimize the Sim2Real gap. Training the policy through reinforcement learning in simulation and transferring the trained policy to the real environment, we demonstrate that object search and manipulation using tactile sensors is possible even in an environment without vision information. In addition, an ablation study was conducted to analyze the effect of tactile information on manipulative tasks. Our project page is available at https://lee-kangwon.github.io/dextouch/",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Project page: https://lee-kangwon.github.io/dextouch/"
    },
    {
        "paper id": "2401.12507",
        "abstract url": "https://arxiv.org/abs/2401.12507",
        "title": "Open-Set Facial Expression Recognition",
        "rating": "-0.5",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Facial expression recognition (FER) models are typically trained on datasets with a fixed number of seven basic classes. However, recent research works point out that there are far more expressions than the basic ones. Thus, when these models are deployed in the real world, they may encounter unknown classes, such as compound expressions that cannot be classified into existing basic classes. To address this issue, we propose the open-set FER task for the first time. Though there are many existing open-set recognition methods, we argue that they do not work well for open-set FER because FER data are all human faces with very small inter-class distances, which makes the open-set samples very similar to close-set samples. In this paper, we are the first to transform the disadvantage of small inter-class distance into an advantage by proposing a new way for open-set FER. Specifically, we find that small inter-class distance allows for sparsely distributed pseudo labels of open-set samples, which can be viewed as symmetric noisy labels. Based on this novel observation, we convert the open-set FER to a noisy label detection problem. We further propose a novel method that incorporates attention map consistency and cycle training to detect the open-set samples. Extensive experiments on various FER datasets demonstrate that our method clearly outperforms state-of-the-art open-set recognition methods by large margins. Code is available at https://github.com/zyh-uaiaaaa.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI2024"
    },
    {
        "paper id": "2401.12564",
        "abstract url": "https://arxiv.org/abs/2401.12564",
        "title": "Graph Contrastive Invariant Learning from the Causal Perspective",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph contrastive learning (GCL), learning the node representation by contrasting two augmented graphs in a self-supervised way, has attracted considerable attention. GCL is usually believed to learn the invariant representation. However, does this understanding always hold in practice? In this paper, we first study GCL from the perspective of causality. By analyzing GCL with the structural causal model (SCM), we discover that traditional GCL may not well learn the invariant representations due to the non-causal information contained in the graph. How can we fix it and encourage the current GCL to learn better invariant representations? The SCM offers two requirements and motives us to propose a novel GCL method. Particularly, we introduce the spectral graph augmentation to simulate the intervention upon non-causal factors. Then we design the invariance objective and independence objective to better capture the causal factors. Specifically, (i) the invariance objective encourages the encoder to capture the invariant information contained in causal variables, and (ii) the independence objective aims to reduce the influence of confounders on the causal variables. Experimental results demonstrate the effectiveness of our approach on node classification tasks.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12588",
        "abstract url": "https://arxiv.org/abs/2401.12588",
        "title": "Interpreting Equivariant Representations",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Latent representations are used extensively for downstream tasks, such as visualization, interpolation or feature extraction of deep learning models. Invariant and equivariant neural networks are powerful and well-established models for enforcing inductive biases. In this paper, we demonstrate that the inductive bias imposed on the by an equivariant model must also be taken into account when using latent representations. We show how not accounting for the inductive biases leads to decreased performance on downstream tasks, and vice versa, how accounting for inductive biases can be done effectively by using an invariant projection of the latent representations. We propose principles for how to choose such a projection, and show the impact of using these principles in two common examples: First, we study a permutation equivariant variational auto-encoder trained for molecule graph generation; here we show that invariant projections can be designed that incur no loss of information in the resulting invariant representation. Next, we study a rotation-equivariant representation used for image classification. Here, we illustrate how random invariant projections can be used to obtain an invariant representation with a high degree of retained information. In both cases, the analysis of invariant latent representations proves superior to their equivariant counterparts. Finally, we illustrate that the phenomena documented here for equivariant neural networks have counterparts in standard neural networks where invariance is encouraged via augmentation. Thus, while these ambiguities may be known by experienced developers of equivariant models, we make both the knowledge as well as effective tools to handle the ambiguities available to the broader community.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12610",
        "abstract url": "https://arxiv.org/abs/2401.12610",
        "title": "The twin peaks of learning neural networks",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent works demonstrated the existence of a double-descent phenomenon for the generalization error of neural networks, where highly overparameterized models escape overfitting and achieve good test performance, at odds with the standard bias-variance trade-off described by statistical learning theory. In the present work, we explore a link between this phenomenon and the increase of complexity and sensitivity of the function represented by neural networks. In particular, we study the Boolean mean dimension (BMD), a metric developed in the context of Boolean function analysis. Focusing on a simple teacher-student setting for the random feature model, we derive a theoretical analysis based on the replica method that yields an interpretable expression for the BMD, in the high dimensional regime where the number of data points, the number of features, and the input size grow to infinity. We find that, as the degree of overparameterization of the network is increased, the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak, and then slowly approaches a low asymptotic value. The same phenomenology is then traced in numerical experiments with different model classes and training setups. Moreover, we find empirically that adversarially initialized models tend to show higher BMD values, and that models that are more robust to adversarial attacks exhibit a lower BMD.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "math.PR",
            "math.ST"
        ],
        "comment": "37 pages, 31 figures"
    },
    {
        "paper id": "2401.12624",
        "abstract url": "https://arxiv.org/abs/2401.12624",
        "title": "Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control",
        "rating": "-0.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.",
        "subjects": [
            "cs.AI",
            "cs.IT",
            "cs.LG",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12627",
        "abstract url": "https://arxiv.org/abs/2401.12627",
        "title": "Blind Channel Estimation and Joint Symbol Detection with Data-Driven Factor Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the application of the factor graph framework for blind joint channel estimation and symbol detection on time-variant linear inter-symbol interference channels. In particular, we consider the expectation maximization (EM) algorithm for maximum likelihood estimation, which typically suffers from high complexity as it requires the computation of the symbol-wise posterior distributions in every iteration. We address this issue by efficiently approximating the posteriors using the belief propagation (BP) algorithm on a suitable factor graph. By interweaving the iterations of BP and EM, the detection complexity can be further reduced to a single BP iteration per EM step. In addition, we propose a data-driven version of our algorithm that introduces momentum in the BP updates and learns a suitable EM parameter update schedule, thereby significantly improving the performance-complexity tradeoff with a few offline training samples. Our numerical experiments demonstrate the excellent performance of the proposed blind detector and show that it even outperforms coherent BP detection in high signal-to-noise scenarios.",
        "subjects": [
            "cs.IT",
            "cs.LG",
            "eess.SP"
        ],
        "comment": "Submitted to IEEE for peer review"
    },
    {
        "paper id": "2401.12632",
        "abstract url": "https://arxiv.org/abs/2401.12632",
        "title": "Modeling Resilience of Collaborative AI Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "A Collaborative Artificial Intelligence System (CAIS) performs actions in collaboration with the human to achieve a common goal. CAISs can use a trained AI model to control human-system interaction, or they can use human interaction to dynamically learn from humans in an online fashion. In online learning with human feedback, the AI model evolves by monitoring human interaction through the system sensors in the learning state, and actuates the autonomous components of the CAIS based on the learning in the operational state. Therefore, any disruptive event affecting these sensors may affect the AI model's ability to make accurate decisions and degrade the CAIS performance. Consequently, it is of paramount importance for CAIS managers to be able to automatically track the system performance to understand the resilience of the CAIS upon such disruptive events. In this paper, we provide a new framework to model CAIS performance when the system experiences a disruptive event. With our framework, we introduce a model of performance evolution of CAIS. The model is equipped with a set of measures that aim to support CAIS managers in the decision process to achieve the required resilience of the system. We tested our framework on a real-world case study of a robot collaborating online with the human, when the system is experiencing a disruptive event. The case study shows that our framework can be adopted in CAIS and integrated into the online execution of the CAIS activities.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "This paper is accepted at the 3rd International Conference on AI Engineering - Software Engineering for AI (CAIN 2024), Lisbon, Portugal"
    },
    {
        "paper id": "2401.12633",
        "abstract url": "https://arxiv.org/abs/2401.12633",
        "title": "Heterogeneity- and homophily-induced vulnerability of a P2P network formation model: the IOTA auto-peering protocol",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "IOTA is a distributed ledger technology that relies on a peer-to-peer (P2P) network for communications. Recently an auto-peering algorithm was proposed to build connections among IOTA peers according to their \"Mana\" endowment, which is an IOTA internal reputation system. This paper's goal is to detect potential vulnerabilities and evaluate the resilience of the P2P network generated using IOTA auto-peering algorithm against eclipse attacks. In order to do so, we interpret IOTA's auto-peering algorithm as a random network formation model and employ different network metrics to identify cost-efficient partitions of the network. As a result, we present a potential strategy that an attacker can use to eclipse a significant part of the network, providing estimates of costs and potential damage caused by the attack. On the side, we provide an analysis of the properties of IOTA auto-peering network ensemble, as an interesting class of homophile random networks in between 1D lattices and regular Poisson graphs.",
        "subjects": [
            "cs.SI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12662",
        "abstract url": "https://arxiv.org/abs/2401.12662",
        "title": "Integrating Human Expertise in Continuous Spaces: A Novel Interactive Bayesian Optimization Framework with Preference Expected Improvement",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Interactive Machine Learning (IML) seeks to integrate human expertise into machine learning processes. However, most existing algorithms cannot be applied to Realworld Scenarios because their state spaces and/or action spaces are limited to discrete values. Furthermore, the interaction of all existing methods is restricted to deciding between multiple proposals. We therefore propose a novel framework based on Bayesian Optimization (BO). Interactive Bayesian Optimization (IBO) enables collaboration between machine learning algorithms and humans. This framework captures user preferences and provides an interface for users to shape the strategy by hand. Additionally, we've incorporated a new acquisition function, Preference Expected Improvement (PEI), to refine the system's efficiency using a probabilistic model of the user preferences. Our approach is geared towards ensuring that machines can benefit from human expertise, aiming for a more aligned and effective learning process. In the course of this work, we applied our method to simulations and in a real world task using a Franka Panda robot to show human-robot collaboration.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12666",
        "abstract url": "https://arxiv.org/abs/2401.12666",
        "title": "EL-VIT: Probing Vision Transformer with Interactive Visualization",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Nowadays, Vision Transformer (ViT) is widely utilized in various computer vision tasks, owing to its unique self-attention mechanism. However, the model architecture of ViT is complex and often challenging to comprehend, leading to a steep learning curve. ViT developers and users frequently encounter difficulties in interpreting its inner workings. Therefore, a visualization system is needed to assist ViT users in understanding its functionality. This paper introduces EL-VIT, an interactive visual analytics system designed to probe the Vision Transformer and facilitate a better understanding of its operations. The system consists of four layers of visualization views. The first three layers include model overview, knowledge background graph, and model detail view. These three layers elucidate the operation process of ViT from three perspectives: the overall model architecture, detailed explanation, and mathematical operations, enabling users to understand the underlying principles and the transition process between layers. The fourth interpretation view helps ViT users and experts gain a deeper understanding by calculating the cosine similarity between patches. Our two usage scenarios demonstrate the effectiveness and usability of EL-VIT in helping ViT users understand the working mechanism of ViT.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "10 pages, 7 figures, conference"
    },
    {
        "paper id": "2401.12672",
        "abstract url": "https://arxiv.org/abs/2401.12672",
        "title": "ChatGraph: Chat with Your Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Graph analysis is fundamental in real-world applications. Traditional approaches rely on SPARQL-like languages or clicking-and-dragging interfaces to interact with graph data. However, these methods either require users to possess high programming skills or support only a limited range of graph analysis functionalities. To address the limitations, we propose a large language model (LLM)-based framework called ChatGraph. With ChatGraph, users can interact with graphs through natural language, making it easier to use and more flexible than traditional approaches. The core of ChatGraph lies in generating chains of graph analysis APIs based on the understanding of the texts and graphs inputted in the user prompts. To achieve this, ChatGraph consists of three main modules: an API retrieval module that searches for relevant APIs, a graph-aware LLM module that enables the LLM to comprehend graphs, and an API chain-oriented finetuning module that guides the LLM in generating API chains.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12681",
        "abstract url": "https://arxiv.org/abs/2401.12681",
        "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Kriging aims at estimating the attributes of unsampled geo-locations from observations in the spatial vicinity or physical connections, which helps mitigate skewed monitoring caused by under-deployed sensors. Existing works assume that neighbors' information offers the basis for estimating the attributes of the unobserved target while ignoring non-neighbors. However, non-neighbors could also offer constructive information, and neighbors could also be misleading. To this end, we propose ``Contrastive-Prototypical'' self-supervised learning for Kriging (KCP) to refine valuable information from neighbors and recycle the one from non-neighbors. As a pre-trained paradigm, we conduct the Kriging task from a new perspective of representation: we aim to first learn robust and general representations and then recover attributes from representations. A neighboring contrastive module is designed that coarsely learns the representations by narrowing the representation distance between the target and its neighbors while pushing away the non-neighbors. In parallel, a prototypical module is introduced to identify similar representations via exchanged prediction, thus refining the misleading neighbors and recycling the useful non-neighbors from the neighboring contrast component. As a result, not all the neighbors and some of the non-neighbors will be used to infer the target. To encourage the two modules above to learn general and robust representations, we design an adaptive augmentation module that incorporates data-driven attribute augmentation and centrality-based topology augmentation over the spatiotemporal Kriging graph data. Extensive experiments on real-world datasets demonstrate the superior performance of KCP compared to its peers with 6% improvements and exceptional transferability and robustness. The code is available at https://github.com/bonaldli/KCP",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted in AISTATS 2024"
    },
    {
        "paper id": "2401.12717",
        "abstract url": "https://arxiv.org/abs/2401.12717",
        "title": "Gas trap prediction from 3D seismic and well test data using machine learning",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The aim of this work is to create and apply a methodological approach for predicting gas traps from 3D seismic data and gas well testing. The paper formalizes the approach to creating a training dataset by selecting volumes with established gas saturation and filtration properties within the seismic wavefield. The training dataset thus created is used in a process stack of sequential application of data processing methods and ensemble machine learning algorithms. As a result, a cube of calibrated probabilities of belonging of the study space to gas reservoirs was obtained. The high efficiency of this approach is shown on a delayed test sample of three wells (blind wells). The final value of the gas reservoir prediction quality metric f1 score was 0.893846.",
        "subjects": [
            "physics.geo-ph",
            "cs.LG"
        ],
        "comment": "11 pages, 3 figures"
    },
    {
        "paper id": "2401.12780",
        "abstract url": "https://arxiv.org/abs/2401.12780",
        "title": "DeepRicci: Self-supervised Graph Structure-Feature Co-Refinement for Alleviating Over-squashing",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have shown great power for learning and mining on graphs, and Graph Structure Learning (GSL) plays an important role in boosting GNNs with a refined graph. In the literature, most GSL solutions either primarily focus on structure refinement with task-specific supervision (i.e., node classification), or overlook the inherent weakness of GNNs themselves (e.g., over-squashing), resulting in suboptimal performance despite sophisticated designs. In light of these limitations, we propose to study self-supervised graph structure-feature co-refinement for effectively alleviating the issue of over-squashing in typical GNNs. In this paper, we take a fundamentally different perspective of the Ricci curvature in Riemannian geometry, in which we encounter the challenges of modeling, utilizing and computing Ricci curvature. To tackle these challenges, we present a self-supervised Riemannian model, DeepRicci. Specifically, we introduce a latent Riemannian space of heterogeneous curvatures to model various Ricci curvatures, and propose a gyrovector feature mapping to utilize Ricci curvature for typical GNNs. Thereafter, we refine node features by geometric contrastive learning among different geometric views, and simultaneously refine graph structure by backward Ricci flow based on a novel formulation of differentiable Ricci curvature. Finally, extensive experiments on public datasets show the superiority of DeepRicci, and the connection between backward Ricci flow and over-squashing. Codes of our work are given in https://github.com/RiemanGraph/.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by IEEE ICDM 2023, Full paper, 10 pages"
    },
    {
        "paper id": "2401.12843",
        "abstract url": "https://arxiv.org/abs/2401.12843",
        "title": "An embedding-based distance for temporal graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We define a distance between temporal graphs based on graph embeddings built using time-respecting random walks. We study both the case of matched graphs, when there exists a known relation between the nodes, and the unmatched case, when such a relation is unavailable and the graphs may be of different sizes. We illustrate the interest of our distance definition, using both real and synthetic temporal network data, by showing its ability to discriminate between graphs with different structural and temporal properties. Leveraging state-of-the-art machine learning techniques, we propose an efficient implementation of distance computation that is viable for large-scale temporal graphs.",
        "subjects": [
            "cs.SI",
            "cs.LG",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12846",
        "abstract url": "https://arxiv.org/abs/2401.12846",
        "title": "How well can large language models explain business processes?",
        "rating": "-0.5",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are likely to play a prominent role in future AI-augmented business process management systems (ABPMSs) catering functionalities across all system lifecycle stages. One such system's functionality is Situation-Aware eXplainability (SAX), which relates to generating causally sound and yet human-interpretable explanations that take into account the process context in which the explained condition occurred. In this paper, we present the SAX4BPM framework developed to generate SAX explanations. The SAX4BPM suite consists of a set of services and a central knowledge repository. The functionality of these services is to elicit the various knowledge ingredients that underlie SAX explanations. A key innovative component among these ingredients is the causal process execution view. In this work, we integrate the framework with an LLM to leverage its power to synthesize the various input ingredients for the sake of improved SAX explanations. Since the use of LLMs for SAX is also accompanied by a certain degree of doubt related to its capacity to adequately fulfill SAX along with its tendency for hallucination and lack of inherent capacity to reason, we pursued a methodological evaluation of the quality of the generated explanations. To this aim, we developed a designated scale and conducted a rigorous user study. Our findings show that the input presented to the LLMs aided with the guard-railing of its performance, yielding SAX explanations having better-perceived fidelity. This improvement is moderated by the perception of trust and curiosity. More so, this improvement comes at the cost of the perceived interpretability of the explanation.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "39 pages, 12 figures"
    },
    {
        "paper id": "2401.12920",
        "abstract url": "https://arxiv.org/abs/2401.12920",
        "title": "Truck Parking Usage Prediction with Decomposed Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Truck parking on freight corridors faces various challenges, such as insufficient parking spaces and compliance with Hour-of-Service (HOS) regulations. These constraints often result in unauthorized parking practices, causing safety concerns. To enhance the safety of freight operations, providing accurate parking usage prediction proves to be a cost-effective solution. Despite the existing research demonstrating satisfactory accuracy for predicting individual truck parking site usage, few approaches have been proposed for predicting usage with spatial dependencies of multiple truck parking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN) as a predictive framework for assessing parking usage across the entire state to provide better truck parking information and mitigate unauthorized parking. The framework leverages the topological structures of truck parking site distributions and historical parking data to predict occupancy rates across a state. To achieve this, we introduce a Regional Decomposition approach, which effectively captures the geographical characteristics. We also introduce the spatial module working efficiently with the temporal module. Evaluation results demonstrate that the proposed model surpasses other baseline models, improving the performance by more than $20\\%$ compared with the original model. The proposed model allows truck parking sites' percipience of the topological structures and provides higher performance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "10 pages, 5 figures, 3 tables, Manuscript for IEEE Transactions on Intelligent Transportation Systems"
    },
    {
        "paper id": "2401.12924",
        "abstract url": "https://arxiv.org/abs/2401.12924",
        "title": "Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This article delves into the analysis of performance and utilization of Support Vector Machines (SVMs) for the critical task of forest fire detection using image datasets. With the increasing threat of forest fires to ecosystems and human settlements, the need for rapid and accurate detection systems is of utmost importance. SVMs, renowned for their strong classification capabilities, exhibit proficiency in recognizing patterns associated with fire within images. By training on labeled data, SVMs acquire the ability to identify distinctive attributes associated with fire, such as flames, smoke, or alterations in the visual characteristics of the forest area. The document thoroughly examines the use of SVMs, covering crucial elements like data preprocessing, feature extraction, and model training. It rigorously evaluates parameters such as accuracy, efficiency, and practical applicability. The knowledge gained from this study aids in the development of efficient forest fire detection systems, enabling prompt responses and improving disaster management. Moreover, the correlation between SVM accuracy and the difficulties presented by high-dimensional datasets is carefully investigated, demonstrated through a revealing case study. The relationship between accuracy scores and the different resolutions used for resizing the training datasets has also been discussed in this article. These comprehensive studies result in a definitive overview of the difficulties faced and the potential sectors requiring further improvement and focus.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": "19 pages, 8 figures"
    },
    {
        "paper id": "2401.13054",
        "abstract url": "https://arxiv.org/abs/2401.13054",
        "title": "Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A hypergraph is a generalization of a graph that arises naturally when attribute-sharing among entities is considered. Although a hypergraph can be converted into a graph by expanding its hyperedges into fully connected subgraphs, going the reverse way is computationally complex and NP-complete. We therefore hypothesize that a hypergraph contains more information than a graph. In addition, it is more convenient to manipulate a hypergraph directly, rather than expand it into a graph. An open problem in hypergraphs is how to accurately and efficiently calculate their node distances. Estimating node distances enables us to find a node's nearest neighbors, and perform label propagation on hypergraphs using a K-nearest neighbors (KNN) approach. In this paper, we propose a novel approach based on random walks to achieve label propagation on hypergraphs. We estimate node distances as the expected hitting times of random walks. We note that simple random walks (SRW) cannot accurately describe highly complex real-world hypergraphs, which motivates us to introduce frustrated random walks (FRW) to better describe them. We further benchmark our method against DeepWalk, and show that while the latter can achieve comparable results, FRW has a distinct computational advantage in cases where the number of targets is fairly small. For such cases, we show that FRW runs in significantly shorter time than DeepWalk. Finally, we analyze the time complexity of our method, and show that for large and sparse hypergraphs, the complexity is approximately linear, rendering it superior to the DeepWalk alternative.",
        "subjects": [
            "cs.SI",
            "cs.DM",
            "cs.LG"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2401.13115",
        "abstract url": "https://arxiv.org/abs/2401.13115",
        "title": "Contractive Diffusion Probabilistic Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion probabilistic models (DPMs) have emerged as a promising technology in generative modeling. The success of DPMs relies on two ingredients: time reversal of Markov diffusion processes and score matching. Most existing work implicitly assumes that score matching is close to perfect, while this assumption is questionable. In view of possibly unguaranteed score matching, we propose a new criterion -- the contraction of backward sampling in the design of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance preserving (sub-VP) stochastic differential equations (SDEs). The key insight is that the contraction in the backward process narrows score matching errors, as well as discretization error. Thus, the proposed CDPMs are robust to both sources of error. Our proposal is supported by theoretical results, and is corroborated by experiments. Notably, contractive sub-VP shows the best performance among all known SDE-based DPMs on the CIFAR-10 dataset.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13148",
        "abstract url": "https://arxiv.org/abs/2401.13148",
        "title": "NLBAC: A Neural Ordinary Differential Equations-based Framework for Stable and Safe Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning (RL) excels in applications such as video games and robotics, but ensuring safety and stability remains challenging when using RL to control real-world systems where using model-free algorithms suffering from low sample efficiency might be prohibitive. This paper first provides safety and stability definitions for the RL system, and then introduces a Neural ordinary differential equations-based Lyapunov-Barrier Actor-Critic (NLBAC) framework that leverages Neural Ordinary Differential Equations (NODEs) to approximate system dynamics and integrates the Control Barrier Function (CBF) and Control Lyapunov Function (CLF) frameworks with the actor-critic method to assist in maintaining the safety and stability for the system. Within this framework, we employ the augmented Lagrangian method to update the RL-based controller parameters. Additionally, we introduce an extra backup controller in situations where CBF constraints for safety and the CLF constraint for stability cannot be satisfied simultaneously. Simulation results demonstrate that the framework leads the system to approach the desired state and allows fewer violations of safety constraints with better sample efficiency compared to other methods.",
        "subjects": [
            "cs.LG",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "The comprehensive version of one paper submitted to 6th Annual Learning for Dynamics & Control Conference (L4DC 2024)"
    },
    {
        "paper id": "2401.13200",
        "abstract url": "https://arxiv.org/abs/2401.13200",
        "title": "Topology-aware Embedding Memory for Continual Learning on Expanding Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding networks, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from $\\mathcal{O}(nd^L)$ to $\\mathcal{O}(n)$, but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subnetwork via $\\textit{Topology-aware Embeddings}$ (TEs), which compress ego-subnetworks into compact vectors (i.e., TEs) to reduce the memory consumption. Based on this framework, we discover a unique $\\textit{pseudo-training effect}$ in continual learning on expanding networks and this effect motivates us to develop a novel $\\textit{coverage maximization sampling}$ strategy that can enhance the performance with a tight memory budget. Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13216",
        "abstract url": "https://arxiv.org/abs/2401.13216",
        "title": "On Principled Local Optimization Methods for Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions. First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective. Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled acceleration of FedAvg, which provably improves the convergence rate and communication efficiency. Our technique uses on a potential-based perturbed iterate analysis, a novel stability analysis of generalized accelerated SGD, and a strategic tradeoff between acceleration and stability. Third, we study the Federated Composite Optimization problem, which extends the classic smooth setting by incorporating a shared non-smooth regularizer. We show that direct extensions of FedAvg may suffer from the \"curse of primal averaging,\" resulting in slow convergence. As a solution, we propose a new primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of primal averaging by employing a novel inter-client dual averaging procedure.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "math.OC",
            "stat.ML"
        ],
        "comment": "Stanford University Doctoral Dissertation"
    },
    {
        "paper id": "2401.13708",
        "abstract url": "https://arxiv.org/abs/2401.13708",
        "title": "Accelerating hyperbolic t-SNE",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.LG",
            "q-bio.QM",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13713",
        "abstract url": "https://arxiv.org/abs/2401.13713",
        "title": "EMP: Effective Multidimensional Persistence for Graph Representation Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Topological data analysis (TDA) is gaining prominence across a wide spectrum of machine learning tasks that spans from manifold learning to graph classification. A pivotal technique within TDA is persistent homology (PH), which furnishes an exclusive topological imprint of data by tracing the evolution of latent structures as a scale parameter changes. Present PH tools are confined to analyzing data through a single filter parameter. However, many scenarios necessitate the consideration of multiple relevant parameters to attain finer insights into the data. We address this issue by introducing the Effective Multidimensional Persistence (EMP) framework. This framework empowers the exploration of data by simultaneously varying multiple scale parameters. The framework integrates descriptor functions into the analysis process, yielding a highly expressive data summary. It seamlessly integrates established single PH summaries into multidimensional counterparts like EMP Landscapes, Silhouettes, Images, and Surfaces. These summaries represent data's multidimensional aspects as matrices and arrays, aligning effectively with diverse ML models. We provide theoretical guarantees and stability proofs for EMP summaries. We demonstrate EMP's utility in graph classification tasks, showing its effectiveness. Results reveal that EMP enhances various single PH descriptors, outperforming cutting-edge methods on multiple benchmark datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2401.13157"
    },
    {
        "paper id": "2402.04896",
        "abstract url": "https://arxiv.org/abs/2402.04896",
        "title": "Learning from the Best: Active Learning for Wireless Communications",
        "rating": "-0.5",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Collecting an over-the-air wireless communications training dataset for deep learning-based communication tasks is relatively simple. However, labeling the dataset requires expert involvement and domain knowledge, may involve private intellectual properties, and is often computationally and financially expensive. Active learning is an emerging area of research in machine learning that aims to reduce the labeling overhead without accuracy degradation. Active learning algorithms identify the most critical and informative samples in an unlabeled dataset and label only those samples, instead of the complete set. In this paper, we introduce active learning for deep learning applications in wireless communications, and present its different categories. We present a case study of deep learning-based mmWave beam selection, where labeling is performed by a compute-intensive algorithm based on exhaustive search. We evaluate the performance of different active learning algorithms on a publicly available multi-modal dataset with different modalities including image and LiDAR. Our results show that using an active learning algorithm for class-imbalanced datasets can reduce labeling overhead by up to 50% for this dataset while maintaining the same accuracy as classical training.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12488",
        "abstract url": "https://arxiv.org/abs/2401.12488",
        "title": "An Automated Real-Time Approach for Image Processing and Segmentation of Fluoroscopic Images and Videos Using a Single Deep Learning Network",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "x-ray"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image segmentation in total knee arthroplasty is crucial for precise preoperative planning and accurate implant positioning, leading to improved surgical outcomes and patient satisfaction. The biggest challenges of image segmentation in total knee arthroplasty include accurately delineating complex anatomical structures, dealing with image artifacts and noise, and developing robust algorithms that can handle anatomical variations and pathologies commonly encountered in patients. The potential of using machine learning for image segmentation in total knee arthroplasty lies in its ability to improve segmentation accuracy, automate the process, and provide real-time assistance to surgeons, leading to enhanced surgical planning, implant placement, and patient outcomes. This paper proposes a methodology to use deep learning for robust and real-time total knee arthroplasty image segmentation. The deep learning model, trained on a large dataset, demonstrates outstanding performance in accurately segmenting both the implanted femur and tibia, achieving an impressive mean-Average-Precision (mAP) of 88.83 when compared to the ground truth while also achieving a real-time segmented speed of 20 frames per second (fps). We have introduced a novel methodology for segmenting implanted knee fluoroscopic or x-ray images that showcases remarkable levels of accuracy and speed, paving the way for various potential extended applications.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12542",
        "abstract url": "https://arxiv.org/abs/2401.12542",
        "title": "Multi-Party Private Set Intersection: A Circuit-Based Protocol with Jaccard Similarity for Secure and Efficient Anomaly Detection in Network Traffic",
        "rating": "-1",
        "keywords": [
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "We present a new circuit-based protocol for multi-party private set intersection (PSI) that allows m parties to compute the intersection of their datasets without revealing any additional information about the items outside the intersection. Building upon the two-party Sort-Compare-Shuffle (SCS) protocol, we seamlessly extend it to a multi-party setting. Demonstrating its practicality through implementation, our protocol exhibits acceptable performance. Specifically, with 7 parties, each possessing a set size of 2^{12}, our protocol completes in just 19 seconds. Moreover, circuit-based protocols like ours have an advantage over using custom protocols to perform more complex computation. We substantiate this advantage by incorporating a module for calculating the Jaccard similarity metric of the private sets which can be used in the application domain of network traffic analysis for anomaly detection. This extension showcases the versatility of our protocol beyond set intersection computations, demonstrating its efficacy in preserving privacy while efficiently identifying abnormal patterns in network flow.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12590",
        "abstract url": "https://arxiv.org/abs/2401.12590",
        "title": "PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative Filtering",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ]
        ],
        "abstract": "Collaborative Filtering (CF) is a pivotal research area in recommender systems that capitalizes on collaborative similarities between users and items to provide personalized recommendations. With the remarkable achievements of node embedding-based Graph Neural Networks (GNNs), we explore the upper bounds of expressiveness inherent to embedding-based methodologies and tackle the challenges by reframing the CF task as a graph signal processing problem. To this end, we propose PolyCF, a flexible graph signal filter that leverages polynomial graph filters to process interaction signals. PolyCF exhibits the capability to capture spectral features across multiple eigenspaces through a series of Generalized Gram filters and is able to approximate the optimal polynomial response function for recovering missing interactions. A graph optimization objective and a pair-wise ranking objective are jointly used to optimize the parameters of the convolution kernel. Experiments on three widely adopted datasets demonstrate the superiority of PolyCF over current state-of-the-art CF methods. Moreover, comprehensive studies empirically validate each component's efficacy in the proposed PolyCF.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12592",
        "abstract url": "https://arxiv.org/abs/2401.12592",
        "title": "RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "6d",
                "RGBD",
                "depth"
            ],
            [
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a new RGB-D object dataset captured in the wild called WildRGB-D. Unlike most existing real-world object-centric datasets which only come with RGB capturing, the direct capture of the depth channel allows better 3D annotations and broader downstream applications. WildRGB-D comprises large-scale category-level RGB-D object videos, which are taken using an iPhone to go around the objects in 360 degrees. It contains around 8500 recorded objects and nearly 20000 RGB-D videos across 46 common object categories. These videos are taken with diverse cluttered backgrounds with three setups to cover as many real-world scenarios as possible: (i) a single object in one video; (ii) multiple objects in one video; and (iii) an object with a static hand in one video. The dataset is annotated with object masks, real-world scale camera poses, and reconstructed aggregated point clouds from RGBD videos. We benchmark four tasks with WildRGB-D including novel view synthesis, camera pose estimation, object 6d pose estimation, and object surface reconstruction. Our experiments show that the large-scale capture of RGB-D objects provides a large potential to advance 3D object learning. Our project page is https://wildrgbd.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Our project page: https://wildrgbd.github.io/"
    },
    {
        "paper id": "2401.12638",
        "abstract url": "https://arxiv.org/abs/2401.12638",
        "title": "On The Axioms Of $\\mathcal{M},\\mathcal{N}$-Adhesive Categories",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Adhesive and quasiadhesive categories provide a general framework for the study of algebraic graph rewriting systems. In a quasiadhesive category any two regular subobjects have a join which is again a regular subobject. Vice versa, if regular monos are adhesive, then the existence of a regular join for any pair of regular subobjects entails quasiadhesivity. It is also known (quasi)adhesive categories can be embedded in a Grothendieck topos via a functor preserving pullbacks and pushouts along (regular) monomorphisms. In this paper we extend these results to $\\mathcal{M}, \\mathcal{N}$-adhesive categories, a concept recently introduced to generalize the notion of (quasi)adhesivity. We introduce the notion of $\\mathcal{N}$-adhesive morphism, which allows us to express $\\mathcal{M}, \\mathcal{N}$-adhesivity as a condition on the subobjects's posets. Moreover, $\\mathcal{N}$-adhesive morphisms allows us to show how an $\\mathcal{M},\\mathcal{N}$-adhesive category can be embedded into a Grothendieck topos, preserving pullbacks and $\\mathcal{M}, \\mathcal{N}$-pushouts.",
        "subjects": [
            "cs.LO",
            "math.CT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12649",
        "abstract url": "https://arxiv.org/abs/2401.12649",
        "title": "Space-time unfitted finite elements on moving explicit geometry representations",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This work proposes a novel variational approximation of partial differential equations on moving geometries determined by explicit boundary representations. The benefits of the proposed formulation are the ability to handle large displacements of explicitly represented domain boundaries without generating body-fitted meshes and remeshing techniques. For the space discretization, we use a background mesh and an unfitted method that relies on integration on cut cells only. We perform this intersection by using clipping algorithms. To deal with the mesh movement, we pullback the equations to a reference configuration (the spatial mesh at the initial time slab times the time interval) that is constant in time. This way, the geometrical intersection algorithm is only required in 3D, another key property of the proposed scheme. At the end of the time slab, we compute the deformed mesh, intersect the deformed boundary with the background mesh, and consider an exact transfer operator between meshes to compute jump terms in the time discontinuous Galerkin integration. The transfer is also computed using geometrical intersection algorithms. We demonstrate the applicability of the method to fluid problems around rotating (2D and 3D) geometries described by oriented boundary meshes. We also provide a set of numerical experiments that show the optimal convergence of the method.",
        "subjects": [
            "cs.CE",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12690",
        "abstract url": "https://arxiv.org/abs/2401.12690",
        "title": "Availability-aware Service Placement Policy in Fog Computing Based on Graph Partitions",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "This paper presents a policy for service placement of fog applications inspired on complex networks and graph theory. We propose a twofold partition process based on communities for the partition of the fog devices and based on transitive closures for the application services partition. The allocation of the services is performed sequentially by, firstly, mapping applications to device communities and, secondly, mapping service transitive closures to fog devices in the community. The underlying idea is to place as many inter-related services as possible in the most nearby devices to the users. The optimization objectives are the availability of the applications and the Quality of Service (QoS) of the system, measured as the number of requests that are executed before the application deadlines. We compared our solution with an Integer Linear Programming approach, and the simulation results showed that our proposal obtains higher QoS and availability when fails in the nodes are considered.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12729",
        "abstract url": "https://arxiv.org/abs/2401.12729",
        "title": "Enhancing Object Detection Performance for Small Objects through Synthetic Data Generation and Proportional Class-Balancing Technique: A Comparative Study in Industrial Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Object Detection (OD) has proven to be a significant computer vision method in extracting localized class information and has multiple applications in the industry. Although many of the state-of-the-art (SOTA) OD models perform well on medium and large sized objects, they seem to under perform on small objects. In most of the industrial use cases, it is difficult to collect and annotate data for small objects, as it is time-consuming and prone to human errors. Additionally, those datasets are likely to be unbalanced and often result in an inefficient model convergence. To tackle this challenge, this study presents a novel approach that injects additional data points to improve the performance of the OD models. Using synthetic data generation, the difficulties in data collection and annotations for small object data points can be minimized and to create a dataset with balanced distribution. This paper discusses the effects of a simple proportional class-balancing technique, to enable better anchor matching of the OD models. A comparison was carried out on the performances of the SOTA OD models: YOLOv5, YOLOv7 and SSD, for combinations of real and synthetic datasets within an industrial use case.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted and presented in conference ESAIM23 1st European Symposium on Artificial Intelligence in Manufacturing"
    },
    {
        "paper id": "2401.12761",
        "abstract url": "https://arxiv.org/abs/2401.12761",
        "title": "MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under Uncertainty",
        "rating": "-1",
        "keywords": [
            [
                "event camera"
            ],
            [
                "lidar",
                "radar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Achieving level-5 driving automation in autonomous vehicles necessitates a robust semantic visual perception system capable of parsing data from different sensors across diverse conditions. However, existing semantic perception datasets often lack important non-camera modalities typically used in autonomous vehicles, or they do not exploit such modalities to aid and improve semantic annotations in challenging conditions. To address this, we introduce MUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverse conditions under increased uncertainty. MUSES includes synchronized multimodal recordings with 2D panoptic annotations for 2500 images captured under diverse weather and illumination. The dataset integrates a frame camera, a lidar, a radar, an event camera, and an IMU/GNSS sensor. Our new two-stage panoptic annotation protocol captures both class-level and instance-level uncertainty in the ground truth and enables the novel task of uncertainty-aware panoptic segmentation we introduce, along with standard semantic and panoptic segmentation. MUSES proves both effective for training and challenging for evaluating models under diverse visual conditions, and it opens new avenues for research in multimodal and uncertainty-aware dense semantic perception. Our dataset and benchmark will be made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12768",
        "abstract url": "https://arxiv.org/abs/2401.12768",
        "title": "What Can Self-Admitted Technical Debt Tell Us About Security? A Mixed-Methods Study",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Self-Admitted Technical Debt (SATD) encompasses a wide array of sub-optimal design and implementation choices reported in software artefacts (e.g., code comments and commit messages) by developers themselves. Such reports have been central to the study of software maintenance and evolution over the last decades. However, they can also be deemed as dreadful sources of information on potentially exploitable vulnerabilities and security flaws. This work investigates the security implications of SATD from a technical and developer-centred perspective. On the one hand, it analyses whether security pointers disclosed inside SATD sources can be used to characterise vulnerabilities in Open-Source Software (OSS) projects and repositories. On the other hand, it delves into developers' perspectives regarding the motivations behind this practice, its prevalence, and its potential negative consequences. We followed a mixed-methods approach consisting of (i) the analysis of a preexisting dataset containing 8,812 SATD instances and (ii) an online survey with 222 OSS practitioners. We gathered 201 SATD instances through the dataset analysis and mapped them to different Common Weakness Enumeration (CWE) identifiers. Overall, 25 different types of CWEs were spotted across commit messages, pull requests, code comments, and issue sections, from which 8 appear among MITRE's Top-25 most dangerous ones. The survey shows that software practitioners often place security pointers across SATD artefacts to promote a security culture among their peers and help them spot flaky code sections, among other motives. However, they also consider such a practice risky as it may facilitate vulnerability exploits. Our findings suggest that preserving the contextual integrity of security pointers disseminated across SATD artefacts is critical to safeguard both commercial and OSS solutions against zero-day attacks.",
        "subjects": [
            "cs.SE",
            "cs.HC"
        ],
        "comment": "Accepted in the 21th International Conference on Mining Software Repositories (MSR '24)"
    },
    {
        "paper id": "2401.12771",
        "abstract url": "https://arxiv.org/abs/2401.12771",
        "title": "Deep Learning-based Intraoperative MRI Reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "surgery",
                "MRI",
                "tumor"
            ],
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: To evaluate the quality of deep learning reconstruction for prospectively accelerated intraoperative magnetic resonance imaging (iMRI) during resective brain tumor surgery. Materials and Methods: Accelerated iMRI was performed during brain surgery using dual surface coils positioned around the area of resection. A deep learning (DL) model was trained on the fastMRI neuro dataset to mimic the data from the iMRI protocol. Evaluation was performed on imaging material from 40 patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during tumor resection surgery. A comparative analysis was conducted between the conventional compressed sense (CS) method and the trained DL reconstruction method. Blinded evaluation of multiple image quality metrics was performed by two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the favored reconstruction variant. Results: The DL reconstruction was strongly favored or favored over the CS reconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3, respectively. Two of three readers consistently assigned higher ratings for the DL reconstructions, and the DL reconstructions had a higher score than their respective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2, and 3, respectively. Still, the DL reconstructions exhibited shortcomings such as a striping artifact and reduced signal. Conclusion: DL shows promise to allow for high-quality reconstructions of intraoperative MRI with equal to or improved perceived spatial resolution, signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, and spatial resolution compared to compressed sense.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12793",
        "abstract url": "https://arxiv.org/abs/2401.12793",
        "title": "Contractions in perfect graph",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper, we characterize the class of {\\em contraction perfect} graphs which are the graphs that remain perfect after the contraction of any edge set. We prove that a graph is contraction perfect if and only if it is perfect and the contraction of any single edge preserves its perfection. This yields a characterization of contraction perfect graphs in terms of forbidden induced subgraphs, and a polynomial algorithm to recognize them. We also define the utter graph $u(G)$ which is the graph whose stable sets are in bijection with the co-2-plexes of $G$, and prove that $u(G)$ is perfect if and only if $G$ is contraction perfect.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2401.12808",
        "abstract url": "https://arxiv.org/abs/2401.12808",
        "title": "A Robot Expressing Emotions Through Gestures: Everyone Outside of Italy Would Understand this?",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In the context of our research activities on affective computing and human-robot interaction we are working on both the recognition of human's emotions and the expression of emotions by robots. In our vision, robots will be increasingly present in schools, factories, and homes, and their empathetic behavior may foster their acceptance. In particular, in one of our research, we sought to replicate gestures associated with specific emotions on a social robot, NAO. Our focus was on Ekman's six primary emotions, along with five emotions selected from Plutchik's wheel of emotions. In our opinion the cultural component linked to the expression of emotions through gestures certainly influenced both us and the participants. Thus, we would like to investigate the influence of our culture in the gestural expression of emotion.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "MedCHI workshop 2024"
    },
    {
        "paper id": "2401.12848",
        "abstract url": "https://arxiv.org/abs/2401.12848",
        "title": "Optimal Evasion from a Sensing-Limited Pursuer",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This paper investigates a partial-information pursuit evasion game in which the Pursuer has a limited-range sensor to detect the Evader. Given a fixed final time, we derive the optimal evasion strategy for the Evader to maximize its distance from the pursuer at the end. Our analysis reveals that in certain parametric regimes, the optimal Evasion strategy involves a 'risky' maneuver, where the Evader's trajectory comes extremely close to the pursuer's sensing boundary before moving behind the Pursuer. Additionally, we explore a special case in which the Pursuer can choose the final time. In this scenario, we determine a (Nash) equilibrium pair for both the final time and the evasion strategy.",
        "subjects": [
            "cs.GT",
            "eess.SY"
        ],
        "comment": "Accepted for presentation at, and publication in the proceedings of, the 2024 American Control Conference"
    },
    {
        "paper id": "2401.12851",
        "abstract url": "https://arxiv.org/abs/2401.12851",
        "title": "Classification of grapevine varieties using UAV hyperspectral imaging",
        "rating": "-1",
        "keywords": [
            [
                "UAV",
                "hyperspectral imaging"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The classification of different grapevine varieties is a relevant phenotyping task in Precision Viticulture since it enables estimating the growth of vineyard rows dedicated to different varieties, among other applications concerning the wine industry. This task can be performed with destructive methods that require time-consuming tasks, including data collection and analysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a more efficient and less prohibitive approach to collecting hyperspectral data, despite acquiring noisier data. Therefore, the first task is the processing of these data to correct and downsample large amounts of data. In addition, the hyperspectral signatures of grape varieties are very similar. In this work, a Convolutional Neural Network (CNN) is proposed for classifying seventeen varieties of red and white grape variants. Rather than classifying single samples, these are processed together with their neighbourhood. Hence, the extraction of spatial and spectral features is addressed with 1) a spatial attention layer and 2) Inception blocks. The pipeline goes from processing to dataset elaboration, finishing with the training phase. The fitted model is evaluated in terms of response time, accuracy and data separability, and compared with other state-of-the-art CNNs for classifying hyperspectral data. Our network was proven to be much more lightweight with a reduced number of input bands, a lower number of trainable weights and therefore, reduced training time. Despite this, the evaluated metrics showed much better results for our network (~99% overall accuracy), in comparison with previous works barely achieving 81% OA.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12862",
        "abstract url": "https://arxiv.org/abs/2401.12862",
        "title": "FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units",
        "rating": "-1",
        "keywords": [
            [
                "LiDAR",
                "Vehicle"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Roadside unit (RSU) can significantly improve the safety and robustness of autonomous vehicles through Vehicle-to-Everything (V2X) communication. Currently, the usage of a single RSU mainly focuses on real-time inference and V2X collaboration, while neglecting the potential value of the high-quality data collected by RSU sensors. Integrating the vast amounts of data from numerous RSUs can provide a rich source of data for model training. However, the absence of ground truth annotations and the difficulty of transmitting enormous volumes of data are two inevitable barriers to fully exploiting this hidden value. In this paper, we introduce FedRSU, an innovative federated learning framework for self-supervised scene flow estimation. In FedRSU, we present a recurrent self-supervision training paradigm, where for each RSU, the scene flow prediction of points at every timestamp can be supervised by its subsequent future multi-modality observation. Another key component of FedRSU is federated learning, where multiple devices collaboratively train an ML model while keeping the training data local and private. With the power of the recurrent self-supervised learning paradigm, FL is able to leverage innumerable underutilized data from RSU. To verify the FedRSU framework, we construct a large-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSU clients, covering various scenarios, modalities, and sensor settings. Based on RSU-SF, we show that FedRSU can greatly improve model performance in ITS and provide a comprehensive benchmark under diverse FL scenarios. To the best of our knowledge, we provide the first real-world LiDAR-camera multi-modal dataset and benchmark for the FL community.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12868",
        "abstract url": "https://arxiv.org/abs/2401.12868",
        "title": "A database of physical therapy exercises with variability of execution collected by wearable sensors",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This document introduces the PHYTMO database, which contains data from physical therapies recorded with inertial sensors, including information from an optical reference system. PHYTMO includes the recording of 30 volunteers, aged between 20 and 70 years old. A total amount of 6 exercises and 3 gait variations were recorded. The volunteers performed two series with a minimum of 8 repetitions in each one. PHYTMO includes magneto-inertial data, together with a highly accurate location and orientation in the 3D space provided by the optical system. The files were stored in CSV format to ensure its usability. The aim of this dataset is the availability of data for two main purposes: the analysis of techniques for the identification and evaluation of exercises using inertial sensors and the validation of inertial sensor-based algorithms for human motion monitoring. Furthermore, the database stores enough data to apply Machine Learning-based algorithms. The participants' age range is large enough to establish age-based metrics for the exercises evaluation or the study of differences in motions between different groups.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12870",
        "abstract url": "https://arxiv.org/abs/2401.12870",
        "title": "Unlocking the Potential: Multi-task Deep Learning for Spaceborne Quantitative Monitoring of Fugitive Methane Plumes",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing",
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the intensification of global warming, the monitoring of methane emission and detection of gas plumes from landfills have increasingly received attention. We decompose methane emission monitoring into three sub-tasks: methane concentration inversion, plume segmentation, and emission rate estimation. Conventional algorithms have limitations: methane concentration inversion usually uses the matched filter, which is sensitive to global spectrum distribution and contains a large amount of noises. There is limited research on plume segmentation, with many studies resorting to manual segmentation that is likely to be subjective. The estimation of methane emission rate often utilizes IME algorithm, which relies on obtaining meteorological measurement data. Using the WENT landfill site in Hong Kong and PRISMA hyperspectral satellite imagery, we propose a new deep learning-based framework for quantitative monitoring of methane emissions from remote sensing images based on physical simulation. We generate simulated methane plumes using large eddy simulation (LES) and different concentration maps of fugitive emission using the radiative transfer equation (RTE), while combining augmentation techniques to create a simulated PRISMA dataset. We train a U-Net network for methane concentration inversion, a Mask R-CNN network for methane plume segmentation, and a ResNet-50 network for methane emission rate estimation. All three deep networks achieve higher validation accuracy compared to conventional algorithms. We further respectively combine the first two sub-tasks and the last two sub-tasks to design the multi-task learning models - MTL-01 and MTL-02, both of which achieve higher accuracy than single-task models. Our research serves as a demonstration of applying multi-task deep learning to quantitative methane monitoring and can be extended to a broad range of methane monitoring tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12872",
        "abstract url": "https://arxiv.org/abs/2401.12872",
        "title": "FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Depth"
            ]
        ],
        "abstract": "Gaze interaction presents a promising avenue in Virtual Reality (VR) due to its intuitive and efficient user experience. Yet, the depth control inherent in our visual system remains underutilized in current methods. In this study, we introduce FocusFlow, a hands-free interaction method that capitalizes on human visual depth perception within the 3D scenes of Virtual Reality. We first develop a binocular visual depth detection algorithm to understand eye input characteristics. We then propose a layer-based user interface and introduce the concept of 'Virtual Window' that offers an intuitive and robust gaze-depth VR interaction, despite the constraints of visual depth accuracy and precision spatially at further distances. Finally, to help novice users actively manipulate their visual depth, we propose two learning strategies that use different visual cues to help users master visual depth control. Our user studies on 24 participants demonstrate the usability of our proposed virtual window concept as a gaze-depth interaction method. In addition, our findings reveal that the user experience can be enhanced through an effective learning process with adaptive visual cues, helping users to develop muscle memory for this brand-new input mechanism. We conclude the paper by discussing strategies to optimize learning and potential research topics of gaze-depth interaction.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "ACM CHI 2024 Paper"
    },
    {
        "paper id": "2401.12881",
        "abstract url": "https://arxiv.org/abs/2401.12881",
        "title": "Computing Diameter+2 in Truly Subquadratic Time for Unit-Disk Graphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Finding the diameter of a graph in general cannot be done in truly subquadratic assuming the Strong Exponential Time Hypothesis (SETH), even when the underlying graph is unweighted and sparse. When restricting to concrete classes of graphs and assuming SETH, planar graphs and minor-free graphs admit truly subquadratic algorithms, while geometric intersection graphs of unit balls, congruent equilateral triangles, and unit segments do not. Unit-disk graphs are one of the major open cases where the complexity of diameter computation remains unknown. More generally, it is conjectured that a truly subquadratic time algorithm exists for pseudo-disk graphs. In this paper, we show a truly subquadratic algorithm of running time $\\tilde{O}(n^{2-1/18})$, for finding the diameter in a unit-disk graph, whose output differs from the optimal solution by at most 2. This is the first algorithm that provides an additive guarantee in distortion, independent of the size or the diameter of the graph. Our algorithm requires two important technical elements. First, we show that for the intersection graph of pseudo-disks, the graph VC-dimension, either of $k$-hop balls or the distance encoding vectors, is 4. This contracts to the VC dimension of the pseudo-disks themselves as geometric ranges (which is known to be 3). Second, we introduce a clique-based $r$-clustering for geometric intersection graphs, which is an analog of the $r$-division construction for planar graphs. We also showcase the new techniques by establishing new results for distance oracles for unit-disk graphs with subquadratic storage and $O(1)$ query time. The results naturally extend to unit $L_1$ or $L_\\infty$-disks and fat pseudo-disks of similar size. Last, if the pseudo-disks additionally have bounded ply, we have a truly subquadratic algorithm to find the exact diameter.",
        "subjects": [
            "cs.DS",
            "cs.CG"
        ],
        "comment": "28 pages, 7 figures"
    },
    {
        "paper id": "2401.12932",
        "abstract url": "https://arxiv.org/abs/2401.12932",
        "title": "Segmentation of tibiofemoral joint tissues from knee MRI using MtRA-Unet and incorporating shape information: Data from the Osteoarthritis Initiative",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Knee Osteoarthritis (KOA) is the third most prevalent Musculoskeletal Disorder (MSD) after neck and back pain. To monitor such a severe MSD, a segmentation map of the femur, tibia and tibiofemoral cartilage is usually accessed using the automated segmentation algorithm from the Magnetic Resonance Imaging (MRI) of the knee. But, in recent works, such segmentation is conceivable only from the multistage framework thus creating data handling issues and needing continuous manual inference rendering it unable to make a quick and precise clinical diagnosis. In order to solve these issues, in this paper the Multi-Resolution Attentive-Unet (MtRA-Unet) is proposed to segment the femur, tibia and tibiofemoral cartilage automatically. The proposed work has included a novel Multi-Resolution Feature Fusion (MRFF) and Shape Reconstruction (SR) loss that focuses on multi-contextual information and structural anatomical details of the femur, tibia and tibiofemoral cartilage. Unlike previous approaches, the proposed work is a single-stage and end-to-end framework producing a Dice Similarity Coefficient (DSC) of 98.5% for the femur, 98.4% for the tibia, 89.1% for Femoral Cartilage (FC) and 86.1% for Tibial Cartilage (TC) for critical MRI slices that can be helpful to clinicians for KOA grading. The time to segment MRI volume (160 slices) per subject is 22 sec. which is one of the fastest among state-of-the-art. Moreover, comprehensive experimentation on the segmentation of FC and TC which is of utmost importance for morphology-based studies to check KOA progression reveals that the proposed method has produced an excellent result with binary segmentation",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12943",
        "abstract url": "https://arxiv.org/abs/2401.12943",
        "title": "On Simplified 3D Finite Element Simulations of Three-core Armored Power Cables",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper analyzes different ways to simulate electromagnetically three-core armored cables in 3D by means of the finite element method. Full periodic models, as lengthy as 36 m, are developed to evaluate the accuracy when simulating only a small portion of the cable, as commonly employed in the literature. The adequate length and boundary conditions for having the same accuracy of full periodic models are also studied. To this aim, five medium voltage and high voltage armored cables are analyzed, obtaining the minimum length of the cable that may be simulated for having accurate results in shorter time and with less computational burden. This also results in the proposal of a new method comprising the advantages of short geometries and the applicability of periodic boundary conditions. Its accuracy is compared with experimental measurements and the IEC standard for 145 kV and 245 kV cables. The results show a very good agreement between simulations and measurements (errors below 4 %), obtaining a reduction in the computation time of about 90 %. This new method brings a more effective tool for saving time and computational resources in cable design and the development of new analytical expressions for improving the IEC standard.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12965",
        "abstract url": "https://arxiv.org/abs/2401.12965",
        "title": "Workspace Optimization Techniques to Improve Prediction of Human Motion During Human-Robot Collaboration",
        "rating": "-1",
        "keywords": [
            [
                "Robot",
                "navigation"
            ]
        ],
        "abstract": "Understanding human intentions is critical for safe and effective human-robot collaboration. While state of the art methods for human goal prediction utilize learned models to account for the uncertainty of human motion data, that data is inherently stochastic and high variance, hindering those models' utility for interactions requiring coordination, including safety-critical or close-proximity tasks. Our key insight is that robot teammates can deliberately configure shared workspaces prior to interaction in order to reduce the variance in human motion, realizing classifier-agnostic improvements in goal prediction. In this work, we present an algorithmic approach for a robot to arrange physical objects and project \"virtual obstacles\" using augmented reality in shared human-robot workspaces, optimizing for human legibility over a given set of tasks. We compare our approach against other workspace arrangement strategies using two human-subjects studies, one in a virtual 2D navigation domain and the other in a live tabletop manipulation domain involving a robotic manipulator arm. We evaluate the accuracy of human motion prediction models learned from each condition, demonstrating that our workspace optimization technique with virtual obstacles leads to higher robot prediction accuracy using less training data.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "International Conference on Human-Robot Interaction"
    },
    {
        "paper id": "2401.12974",
        "abstract url": "https://arxiv.org/abs/2401.12974",
        "title": "SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "radiology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering non-invasive and high-quality insights into the human body. Precise segmentation of MRIs into different organs and tissues would be highly beneficial since it would allow for a higher level of understanding of the image content and enable important measurements, which are essential for accurate diagnosis and effective treatment planning. Specifically, segmenting bones in MRI would allow for more quantitative assessments of musculoskeletal conditions, while such assessments are largely absent in current radiological practice. The difficulty of bone MRI segmentation is illustrated by the fact that limited algorithms are publicly available for use, and those contained in the literature typically address a specific anatomic area. In our study, we propose a versatile, publicly available deep-learning model for bone segmentation in MRI across multiple standard MRI locations. The proposed model can operate in two modes: fully automated segmentation and prompt-based segmentation. Our contributions include (1) collecting and annotating a new MRI dataset across various MRI protocols, encompassing over 300 annotated volumes and 8485 annotated slices across diverse anatomic regions; (2) investigating several standard network architectures and strategies for automated segmentation; (3) introducing SegmentAnyBone, an innovative foundational model-based approach that extends Segment Anything Model (SAM); (4) comparative analysis of our algorithm and previous approaches; and (5) generalization analysis of our algorithm across different anatomical locations and MRI sequences, as well as an external dataset. We publicly release our model at https://github.com/mazurowski-lab/SegmentAnyBone.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "q-bio.QM"
        ],
        "comment": "15 pages, 15 figures"
    },
    {
        "paper id": "2401.12978",
        "abstract url": "https://arxiv.org/abs/2401.12978",
        "title": "Zero-Shot Learning for the Primitives of 3D Affordance in General Objects",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "One of the major challenges in AI is teaching machines to precisely respond and utilize environmental functionalities, thereby achieving the affordance awareness that humans possess. Despite its importance, the field has been lagging in terms of learning, especially in 3D, as annotating affordance accompanies a laborious process due to the numerous variations of human-object interaction. The low availability of affordance data limits the learning in terms of generalization for object categories, and also simplifies the representation of affordance, capturing only a fraction of the affordance. To overcome these challenges, we propose a novel, self-supervised method to generate the 3D affordance examples given only a 3D object, without any manual annotations. The method starts by capturing the 3D object into images and creating 2D affordance images by inserting humans into the image via inpainting diffusion models, where we present the Adaptive Mask algorithm to enable human insertion without altering the original details of the object. The method consequently lifts inserted humans back to 3D to create 3D human-object pairs, where the depth ambiguity is resolved within a depth optimization framework that utilizes pre-generated human postures from multiple viewpoints. We also provide a novel affordance representation defined on relative orientations and proximity between dense human and object points, that can be easily aggregated from any 3D HOI datasets. The proposed representation serves as a primitive that can be manifested to conventional affordance representations via simple transformations, ranging from physically exerted affordances to nonphysical ones. We demonstrate the efficacy of our method and representation by generating the 3D affordance samples and deriving high-quality affordance examples from the representation, including contact, orientation, and spatial occupancies.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://sshowbiz.github.io/ZSP3A/"
    },
    {
        "paper id": "2401.12979",
        "abstract url": "https://arxiv.org/abs/2401.12979",
        "title": "GALA: Generating Animatable Layered Assets from a Single Scan",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "synthesis",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present GALA, a framework that takes as input a single-layer clothed 3D human mesh and decomposes it into complete multi-layered 3D assets. The outputs can then be combined with other assets to create novel clothed human avatars with any pose. Existing reconstruction approaches often treat clothed humans as a single-layer of geometry and overlook the inherent compositionality of humans with hairstyles, clothing, and accessories, thereby limiting the utility of the meshes for downstream applications. Decomposing a single-layer mesh into separate layers is a challenging task because it requires the synthesis of plausible geometry and texture for the severely occluded regions. Moreover, even with successful decomposition, meshes are not normalized in terms of poses and body shapes, failing coherent composition with novel identities and poses. To address these challenges, we propose to leverage the general knowledge of a pretrained 2D diffusion model as geometry and appearance prior for humans and other assets. We first separate the input mesh using the 3D surface segmentation extracted from multi-view 2D segmentations. Then we synthesize the missing geometry of different layers in both posed and canonical spaces using a novel pose-guided Score Distillation Sampling (SDS) loss. Once we complete inpainting high-fidelity 3D geometry, we also apply the same SDS loss to its texture to obtain the complete appearance including the initially occluded regions. Through a series of decomposition steps, we obtain multiple layers of 3D assets in a shared canonical space normalized in terms of poses and human shapes, hence supporting effortless composition to novel identities and reanimation with novel poses. Our experiments demonstrate the effectiveness of our approach for decomposition, canonicalization, and composition tasks compared to existing solutions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The project page is available at https://snuvclab.github.io/gala/"
    },
    {
        "paper id": "2401.13044",
        "abstract url": "https://arxiv.org/abs/2401.13044",
        "title": "Deterministic Collision-Free Exploration of Unknown Anonymous Graphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We consider the fundamental task of network exploration. A network is modeled as a simple connected undirected n-node graph with unlabeled nodes, and all ports at any node of degree d are arbitrarily numbered 0,.....,d-1. Each of two identical mobile agents, initially situated at distinct nodes, has to visit all nodes and stop. Agents execute the same deterministic algorithm and move in synchronous rounds: in each round, an agent can either remain at the same node or move to an adjacent node. Exploration must be collision-free: in every round at most one agent can be at any node. We assume that agents have vision of radius 2: an awake agent situated at a node v can see the subgraph induced by all nodes at a distance at most 2 from v, sees all port numbers in this subgraph, and the agents located at these nodes. Agents do not know the entire graph but they know an upper bound n on its size. The time of an exploration is the number of rounds since the wakeup of the later agent to the termination by both agents. We show a collision-free exploration algorithm working in time polynomial in n, for arbitrary graphs of size larger than 2. Moreover, we show that if agents have only vision of radius 1, then collision-free exploration is impossible, e.g., in any tree of diameter 2.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13059",
        "abstract url": "https://arxiv.org/abs/2401.13059",
        "title": "A BFF-Based Attention Mechanism for Trajectory Estimation in mmWave MIMO Communications",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "This paper explores a novel Neural Network (NN) architecture suitable for Beamformed Fingerprint (BFF) localization in a millimeter-wave (mmWave) multiple-input multiple-output (MIMO) outdoor system. The mmWave frequency bands have attracted significant attention due to their precise timing measurements, making them appealing for applications demanding accurate device localization and trajectory estimation. The proposed NN architecture captures BFF sequences originating from various user paths, and through the application of learning mechanisms, subsequently estimates these trajectories. Specifically, we propose a method for trajectory estimation, employing a transformer network (TN) that relies on attention mechanisms. This TN-based approach estimates wireless device trajectories using BFF sequences recorded within a mmWave MIMO outdoor system. To validate the efficacy of our proposed approach, numerical experiments are conducted using a comprehensive dataset of radio measurements in an outdoor setting, complemented with ray tracing to simulate wireless signal propagation at 28 GHz. The results illustrate that the TN-based trajectory estimator outperforms other methods from the existing literature and possesses the ability to generalize effectively to new trajectories outside the training dataset.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 7 figures, conference WCNC 2024"
    },
    {
        "paper id": "2401.13062",
        "abstract url": "https://arxiv.org/abs/2401.13062",
        "title": "Force sensing to reconstruct potential energy landscapes for cluttered large obstacle traversal",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Visual sensing of environmental geometry allows robots to use artificial potential fields to avoid sparse obstacles. Yet robots must further traverse cluttered large obstacles for applications like search and rescue through rubble and planetary exploration across Martain rocks. Recent studies discovered that to traverse cluttered large obstacles, multi-legged insects and insect-inspired robots make strenuous transitions across locomotor modes with major changes in body orientation. When viewed on a potential energy landscape resulting from locomotor-obstacle physical interaction, these are barrier-crossing transitions across landscape basins. This potential energy landscape approach may provide a modeling framework for cluttered large obstacle traversal. Here, we take the next step toward this vision by testing whether force sensing allows the reconstruction of the potential energy landscape. We developed a cockroach-inspired, minimalistic robot capable of sensing obstacle contact forces and torques around its body as it propelled forward against a pair of cluttered grass-like beam obstacles. We performed measurements over many traverses with systematically varied body orientations. Despite the forces and torques not being fully conservative, they well-matched the potential energy landscape gradients and the landscape reconstructed from them well-matched ground truth. In addition, inspired by cockroach observations, we found that robot head oscillation during traversal further improved the accuracies of force sensing and landscape reconstruction. We still need to study how to reconstruct landscape during a single traverse, as in applications, robots have little chance to use multiple traverses to sample the environment systematically and how to find landscape saddles for least-effort transitions to traverse.",
        "subjects": [
            "cs.RO",
            "eess.SY",
            "physics.bio-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13068",
        "abstract url": "https://arxiv.org/abs/2401.13068",
        "title": "Local Background Estimation for Improved Gas Plume Identification in Hyperspectral Images",
        "rating": "-1",
        "keywords": [
            [
                "Hyperspectral Images"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning identification models have shown promise for identifying gas plumes in Longwave IR hyperspectral images of urban scenes, particularly when a large library of gases are being considered. Because many gases have similar spectral signatures, it is important to properly estimate the signal from a detected plume. Typically, a scene's global mean spectrum and covariance matrix are estimated to whiten the plume's signal, which removes the background's signature from the gas signature. However, urban scenes can have many different background materials that are spatially and spectrally heterogeneous. This can lead to poor identification performance when the global background estimate is not representative of a given local background material. We use image segmentation, along with an iterative background estimation algorithm, to create local estimates for the various background materials that reside underneath a gas plume. Our method outperforms global background estimation on a set of simulated and real gas plumes. This method shows promise in increasing deep learning identification confidence, while being simple and easy to tune when considering diverse plumes.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Submitted to International Geoscience and Remote Sensing Symposium (IGARSS), 2024. 5 pages, 2 figures"
    },
    {
        "paper id": "2401.13076",
        "abstract url": "https://arxiv.org/abs/2401.13076",
        "title": "SemanticSLAM: Learning based Semantic Map Construction and Robust Camera Localization",
        "rating": "-1",
        "keywords": [
            [
                "RGB-D"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current techniques in Visual Simultaneous Localization and Mapping (VSLAM) estimate camera displacement by comparing image features of consecutive scenes. These algorithms depend on scene continuity, hence requires frequent camera inputs. However, processing images frequently can lead to significant memory usage and computation overhead. In this study, we introduce SemanticSLAM, an end-to-end visual-inertial odometry system that utilizes semantic features extracted from an RGB-D sensor. This approach enables the creation of a semantic map of the environment and ensures reliable camera localization. SemanticSLAM is scene-agnostic, which means it doesn't require retraining for different environments. It operates effectively in indoor settings, even with infrequent camera input, without prior knowledge. The strength of SemanticSLAM lies in its ability to gradually refine the semantic map and improve pose estimation. This is achieved by a convolutional long-short-term-memory (ConvLSTM) network, trained to correct errors during map construction. Compared to existing VSLAM algorithms, SemanticSLAM improves pose estimation by 17%. The resulting semantic map provides interpretable information about the environment and can be easily applied to various downstream tasks, such as path planning, obstacle avoidance, and robot navigation. The code will be publicly available at https://github.com/Leomingyangli/SemanticSLAM",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "2023 IEEE Symposium Series on Computational Intelligence (SSCI) 6 pages"
    },
    {
        "paper id": "2401.13078",
        "abstract url": "https://arxiv.org/abs/2401.13078",
        "title": "Open-Source, Cost-Aware Kinematically Feasible Planning for Mobile and Surface Robotics",
        "rating": "-1",
        "keywords": [
            [
                "Robotics"
            ]
        ],
        "abstract": "This paper introduces the Smac Planner, an openly available search-based planning framework with multiple algorithm implementations including 2D-A*, Hybrid-A*, and State Lattice planners. This work is motivated by the lack of performant and available feasible planners for mobile and surface robotics research. This paper contains three main contributions. First, it briefly describes a minimal open-source software framework where search-based planners may be easily added. Further, this paper characterizes new variations on the feasible planners - dubbed Cost-Aware - specific to mobile roboticist's needs. This fills the gap of missing kinematically feasible implementations suitable for academic, extension, and deployed use. Finally, we provide baseline benchmarking against other standard planning frameworks. Smac Planner has further significance by becoming the standard open-source planning system within ROS 2's Nav2 framework which powers thousands of robots in research and industry.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13081",
        "abstract url": "https://arxiv.org/abs/2401.13081",
        "title": "Free Form Medical Visual Question Answering in Radiology",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Radiology"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Visual Question Answering (VQA) in the medical domain presents a unique, interdisciplinary challenge, combining fields such as Computer Vision, Natural Language Processing, and Knowledge Representation. Despite its importance, research in medical VQA has been scant, only gaining momentum since 2018. Addressing this gap, our research delves into the effective representation of radiology images and the joint learning of multimodal representations, surpassing existing methods. We innovatively augment the SLAKE dataset, enabling our model to respond to a more diverse array of questions, not limited to the immediate content of radiology or pathology images. Our model achieves a top-1 accuracy of 79.55\\% with a less complex architecture, demonstrating comparable performance to current state-of-the-art models. This research not only advances medical VQA but also opens avenues for practical applications in diagnostic settings.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "6 pages and 4 figures"
    },
    {
        "paper id": "2401.13127",
        "abstract url": "https://arxiv.org/abs/2401.13127",
        "title": "Generalization of Heterogeneous Multi-Robot Policies via Awareness and Communication of Capabilities",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Recent advances in multi-agent reinforcement learning (MARL) are enabling impressive coordination in heterogeneous multi-robot teams. However, existing approaches often overlook the challenge of generalizing learned policies to teams of new compositions, sizes, and robots. While such generalization might not be important in teams of virtual agents that can retrain policies on-demand, it is pivotal in multi-robot systems that are deployed in the real-world and must readily adapt to inevitable changes. As such, multi-robot policies must remain robust to team changes -- an ability we call adaptive teaming. In this work, we investigate if awareness and communication of robot capabilities can provide such generalization by conducting detailed experiments involving an established multi-robot test bed. We demonstrate that shared decentralized policies, that enable robots to be both aware of and communicate their capabilities, can achieve adaptive teaming by implicitly capturing the fundamental relationship between collective capabilities and effective coordination. Videos of trained policies can be viewed at: https://sites.google.com/view/cap-comm",
        "subjects": [
            "cs.RO",
            "cs.MA"
        ],
        "comment": "Presented at the 7th Conference on Robot Learning (CoRL 2023), Atlanta, USA"
    },
    {
        "paper id": "2401.13140",
        "abstract url": "https://arxiv.org/abs/2401.13140",
        "title": "Dual-Domain Coarse-to-Fine Progressive Estimation Network for Simultaneous Denoising, Limited-View Reconstruction, and Attenuation Correction of Cardiac SPECT",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "CT",
                "Cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Single-Photon Emission Computed Tomography (SPECT) is widely applied for the diagnosis of coronary artery diseases. Low-dose (LD) SPECT aims to minimize radiation exposure but leads to increased image noise. Limited-view (LV) SPECT, such as the latest GE MyoSPECT ES system, enables accelerated scanning and reduces hardware expenses but degrades reconstruction accuracy. Additionally, Computed Tomography (CT) is commonly used to derive attenuation maps ($\u03bc$-maps) for attenuation correction (AC) of cardiac SPECT, but it will introduce additional radiation exposure and SPECT-CT misalignments. Although various methods have been developed to solely focus on LD denoising, LV reconstruction, or CT-free AC in SPECT, the solution for simultaneously addressing these tasks remains challenging and under-explored. Furthermore, it is essential to explore the potential of fusing cross-domain and cross-modality information across these interrelated tasks to further enhance the accuracy of each task. Thus, we propose a Dual-Domain Coarse-to-Fine Progressive Network (DuDoCFNet), a multi-task learning method for simultaneous LD denoising, LV reconstruction, and CT-free $\u03bc$-map generation of cardiac SPECT. Paired dual-domain networks in DuDoCFNet are cascaded using a multi-layer fusion mechanism for cross-domain and cross-modality feature fusion. Two-stage progressive learning strategies are applied in both projection and image domains to achieve coarse-to-fine estimations of SPECT projections and CT-derived $\u03bc$-maps. Our experiments demonstrate DuDoCFNet's superior accuracy in estimating projections, generating $\u03bc$-maps, and AC reconstructions compared to existing single- or multi-task learning methods, under various iterations and LD levels. The source code of this work is available at https://github.com/XiongchaoChen/DuDoCFNet-MultiTask.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "11 Pages, 10 figures, 4 tables"
    },
    {
        "paper id": "2401.13197",
        "abstract url": "https://arxiv.org/abs/2401.13197",
        "title": "Predicting Mitral Valve mTEER Surgery Outcomes Using Machine Learning and Deep Learning Techniques",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Mitral Transcatheter Edge-to-Edge Repair (mTEER) is a medical procedure utilized for the treatment of mitral valve disorders. However, predicting the outcome of the procedure poses a significant challenge. This paper makes the first attempt to harness classical machine learning (ML) and deep learning (DL) techniques for predicting mitral valve mTEER surgery outcomes. To achieve this, we compiled a dataset from 467 patients, encompassing labeled echocardiogram videos and patient reports containing Transesophageal Echocardiography (TEE) measurements detailing Mitral Valve Repair (MVR) treatment outcomes. Leveraging this dataset, we conducted a benchmark evaluation of six ML algorithms and two DL models. The results underscore the potential of ML and DL in predicting mTEER surgery outcomes, providing insight for future investigation and advancements in this domain.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2401.13203",
        "abstract url": "https://arxiv.org/abs/2401.13203",
        "title": "Style-Consistent 3D Indoor Scene Synthesis with Decoupled Objects",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Controllable 3D indoor scene synthesis stands at the forefront of technological progress, offering various applications like gaming, film, and augmented/virtual reality. The capability to stylize and de-couple objects within these scenarios is a crucial factor, providing an advanced level of control throughout the editing process. This control extends not just to manipulating geometric attributes like translation and scaling but also includes managing appearances, such as stylization. Current methods for scene stylization are limited to applying styles to the entire scene, without the ability to separate and customize individual objects. Addressing the intricacies of this challenge, we introduce a unique pipeline designed for synthesis 3D indoor scenes. Our approach involves strategically placing objects within the scene, utilizing information from professionally designed bounding boxes. Significantly, our pipeline prioritizes maintaining style consistency across multiple objects within the scene, ensuring a cohesive and visually appealing result aligned with the desired aesthetic. The core strength of our pipeline lies in its ability to generate 3D scenes that are not only visually impressive but also exhibit features like photorealism, multi-view consistency, and diversity. These scenes are crafted in response to various natural language prompts, demonstrating the versatility and adaptability of our model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13220",
        "abstract url": "https://arxiv.org/abs/2401.13220",
        "title": "Segment Any Cell: A SAM-based Auto-prompting Fine-tuning Framework for Nuclei Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "biomedical",
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the rapidly evolving field of AI research, foundational models like BERT and GPT have significantly advanced language and vision tasks. The advent of pretrain-prompting models such as ChatGPT and Segmentation Anything Model (SAM) has further revolutionized image segmentation. However, their applications in specialized areas, particularly in nuclei segmentation within medical imaging, reveal a key challenge: the generation of high-quality, informative prompts is as crucial as applying state-of-the-art (SOTA) fine-tuning techniques on foundation models. To address this, we introduce Segment Any Cell (SAC), an innovative framework that enhances SAM specifically for nuclei segmentation. SAC integrates a Low-Rank Adaptation (LoRA) within the attention layer of the Transformer to improve the fine-tuning process, outperforming existing SOTA methods. It also introduces an innovative auto-prompt generator that produces effective prompts to guide segmentation, a critical factor in handling the complexities of nuclei segmentation in biomedical imaging. Our extensive experiments demonstrate the superiority of SAC in nuclei segmentation tasks, proving its effectiveness as a tool for pathologists and researchers. Our contributions include a novel prompt generation strategy, automated adaptability for diverse segmentation tasks, the innovative application of Low-Rank Attention Adaptation in SAM, and a versatile framework for semantic segmentation challenges.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13221",
        "abstract url": "https://arxiv.org/abs/2401.13221",
        "title": "Unified-Width Adaptive Dynamic Network for All-In-One Image Restoration",
        "rating": "-1",
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In contrast to traditional image restoration methods, all-in-one image restoration techniques are gaining increased attention for their ability to restore images affected by diverse and unknown corruption types and levels. However, contemporary all-in-one image restoration methods omit task-wise difficulties and employ the same networks to reconstruct images afflicted by diverse degradations. This practice leads to an underestimation of the task correlations and suboptimal allocation of computational resources. To elucidate task-wise complexities, we introduce a novel concept positing that intricate image degradation can be represented in terms of elementary degradation. Building upon this foundation, we propose an innovative approach, termed the Unified-Width Adaptive Dynamic Network (U-WADN), consisting of two pivotal components: a Width Adaptive Backbone (WAB) and a Width Selector (WS). The WAB incorporates several nested sub-networks with varying widths, which facilitates the selection of the most apt computations tailored to each task, thereby striking a balance between accuracy and computational efficiency during runtime. For different inputs, the WS automatically selects the most appropriate sub-network width, taking into account both task-specific and sample-specific complexities. Extensive experiments across a variety of image restoration tasks demonstrate that the proposed U-WADN achieves better performance while simultaneously reducing up to 32.3\\% of FLOPs and providing approximately 15.7\\% real-time acceleration. The code has been made available at \\url{https://github.com/xuyimin0926/U-WADN}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01693",
        "abstract url": "https://arxiv.org/abs/2402.01693",
        "title": "Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Lab results are often confusing and hard to understand. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to get their questions answered. We aim to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to lab test-related questions asked by patients and to identify potential issues that can be mitigated with augmentation approaches. We first collected lab test results related question and answer data from Yahoo! Answers and selected 53 QA pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from four LLMs including GPT-4, Meta LLaMA 2, MedAlpaca, and ORCA_mini. We first assessed the similarity of their answers using standard QA similarity-based evaluation metrics including ROUGE, BLEU, METEOR, BERTScore. We also utilized an LLM-based evaluator to judge whether a target model has higher quality in terms of relevance, correctness, helpfulness, and safety than the baseline model. Finally, we performed a manual evaluation with medical experts for all the responses to seven selected questions on the same four aspects. The results of Win Rate and medical expert evaluation both showed that GPT-4's responses achieved better scores than all the other LLM responses and human responses on all four aspects (relevance, correctness, helpfulness, and safety). However, LLM responses occasionally also suffer from a lack of interpretation in one's medical context, incorrect statements, and lack of references. We find that compared to other three LLMs and human answer from the Q&A website, GPT-4's responses are more accurate, helpful, relevant, and safer. However, there are cases which GPT-4 responses are inaccurate and not individualized. We identified a number of ways to improve the quality of LLM responses.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08778",
        "abstract url": "https://arxiv.org/abs/2403.08778",
        "title": "Faster Projected GAN: Towards Faster Few-Shot Image Generation",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "GAN"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In order to solve the problems of long training time, large consumption of computing resources and huge parameter amount of GAN network in image generation, this paper proposes an improved GAN network model, which is named Faster Projected GAN, based on Projected GAN. The proposed network is mainly focuses on the improvement of generator of Projected GAN. By introducing depth separable convolution (DSC), the number of parameters of the Projected GAN is reduced, the training speed is accelerated, and memory is saved. Experimental results show that on ffhq-1k, art-painting, Landscape and other few-shot image datasets, a 20% speed increase and a 15% memory saving are achieved. At the same time, FID loss is less or no loss, and the amount of model parameters is better controlled. At the same time, significant training speed improvement has been achieved in the small sample image generation task of special scenes such as earthquake scenes with few public datasets.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "eess.IV"
        ],
        "comment": "9 pages,7 figures,4 tables"
    },
    {
        "paper id": "2401.12517",
        "abstract url": "https://arxiv.org/abs/2401.12517",
        "title": "DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations",
        "rating": "-1.5",
        "keywords": [
            [
                "3D",
                "Radiance Fields"
            ],
            [
                "Diffusion",
                "Synthesizing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent studies have introduced a new class of generative models for synthesizing implicit neural representations (INRs) that capture arbitrary continuous signals in various domains. These models opened the door for domain-agnostic generative models, but they often fail to achieve high-quality generation. We observed that the existing methods generate the weights of neural networks to parameterize INRs and evaluate the network with fixed positional embeddings (PEs). Arguably, this architecture limits the expressive power of generative models and results in low-quality INR generation. To address this limitation, we propose Domain-agnostic Latent Diffusion Model for INRs (DDMI) that generates adaptive positional embeddings instead of neural networks' weights. Specifically, we develop a Discrete-to-continuous space Variational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and the continuous signal functions in the shared latent space. Additionally, we introduce a novel conditioning mechanism for evaluating INRs with the hierarchically decomposed PEs to further enhance expressive power. Extensive experiments across four modalities, e.g., 2D images, 3D shapes, Neural Radiance Fields, and videos, with seven benchmark datasets, demonstrate the versatility of DDMI and its superior performance compared to the existing INR generative models.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12593",
        "abstract url": "https://arxiv.org/abs/2401.12593",
        "title": "MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multi-Objective Recommender Systems (MORSs) emerged as a paradigm to guarantee multiple (often conflicting) goals. Besides accuracy, a MORS can operate at the global level, where additional beyond-accuracy goals are met for the system as a whole, or at the individual level, meaning that the recommendations are tailored to the needs of each user. The state-of-the-art MORSs either operate at the global or individual level, without assuming the co-existence of the two perspectives. In this study, we show that when global and individual objectives co-exist, MORSs are not able to meet both types of goals. To overcome this issue, we present an approach that regulates the recommendation lists so as to guarantee both global and individual perspectives, while preserving its effectiveness. Specifically, as individual perspective, we tackle genre calibration and, as global perspective, provider fairness. We validate our approach on two real-world datasets, publicly released with this paper.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12594",
        "abstract url": "https://arxiv.org/abs/2401.12594",
        "title": "SCORPION Cyber Range: Fully Customizable Cyberexercises, Gamification and Learning Analytics to Train Cybersecurity Competencies",
        "rating": "-1.5",
        "keywords": [
            [
                "biometric"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "It is undeniable that we are witnessing an unprecedented digital revolution. However, recent years have been characterized by the explosion of cyberattacks, making cybercrime one of the most profitable businesses on the planet. That is why training in cybersecurity is increasingly essential to protect the assets of cyberspace. One of the most vital tools to train cybersecurity competencies is the Cyber Range, a virtualized environment that simulates realistic networks. The paper at hand introduces SCORPION, a fully functional and virtualized Cyber Range, which manages the authoring and automated deployment of scenarios. In addition, SCORPION includes several elements to improve student motivation, such as a gamification system with medals, points, or rankings, among other elements. Such a gamification system includes an adaptive learning module that is able to adapt the cyberexercise based on the users' performance. Moreover, SCORPION leverages learning analytics that collects and processes telemetric and biometric user data, including heart rate through a smartwatch, which is available through a dashboard for instructors. Finally, we developed a case study where SCORPION obtained 82.10% in usability and 4.57 out of 5 in usefulness from the viewpoint of a student and an instructor. The positive evaluation results are promising, indicating that SCORPION can become an effective, motivating, and advanced cybersecurity training tool to help fill current gaps in this context.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2401.12732",
        "abstract url": "https://arxiv.org/abs/2401.12732",
        "title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops the meta-learning paradigm to leverage user-specific preference, and further introduces a stochastic process by NP to capture the preference correlations among the overlapping and cold-start users, thus generating more powerful mapping functions by mapping the user-specific preference and common preference correlations to a predictive probability distribution. In addition, we also introduce a preference remainer to enhance the common preference from the overlapping users, and finally devises an adaptive conditional decoder with preference modulation to make prediction for cold-start users with items in the target domain. Experimental results demonstrate that CDRNP outperforms previous SOTA methods in three real-world CDR scenarios.",
        "subjects": [
            "cs.IR",
            "cs.SI"
        ],
        "comment": "This paper is accepted by WSDM'2024 Oral"
    },
    {
        "paper id": "2401.12755",
        "abstract url": "https://arxiv.org/abs/2401.12755",
        "title": "Towards Risk Analysis of the Impact of AI on the Deliberate Biological Threat Landscape",
        "rating": "-1.5",
        "keywords": [
            [
                "Biological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The perception that the convergence of biological engineering and artificial intelligence (AI) could enable increased biorisk has recently drawn attention to the governance of biotechnology and artificial intelligence. The 2023 Executive Order, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, requires an assessment of how artificial intelligence can increase biorisk. Within this perspective, we present a simplistic framework for evaluating biorisk and demonstrate how this framework falls short in achieving actionable outcomes for a biorisk manager. We then suggest a potential path forward that builds upon existing risk characterization work and justify why characterization efforts of AI-enabled tools for engineering biology is needed.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "11 pages, 2 tables"
    },
    {
        "paper id": "2401.12783",
        "abstract url": "https://arxiv.org/abs/2401.12783",
        "title": "A Review of Deep Learning Methods for Photoplethysmography Data",
        "rating": "-1.5",
        "keywords": [
            [
                "biometric",
                "medical",
                "health",
                "diagnosis"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Photoplethysmography (PPG) is a highly promising device due to its advantages in portability, user-friendly operation, and non-invasive capabilities to measure a wide range of physiological information. Recent advancements in deep learning have demonstrated remarkable outcomes by leveraging PPG signals for tasks related to personal health management and other multifaceted applications. In this review, we systematically reviewed papers that applied deep learning models to process PPG data between January 1st of 2017 and July 31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed from three key perspectives: tasks, models, and data. We finally extracted 193 papers where different deep learning frameworks were used to process PPG signals. Based on the tasks addressed in these papers, we categorized them into two major groups: medical-related, and non-medical-related. The medical-related tasks were further divided into seven subgroups, including blood pressure analysis, cardiovascular monitoring and diagnosis, sleep health, mental health, respiratory monitoring and analysis, blood glucose analysis, as well as others. The non-medical-related tasks were divided into four subgroups, which encompass signal processing, biometric identification, electrocardiogram reconstruction, and human activity recognition. In conclusion, significant progress has been made in the field of using deep learning methods to process PPG data recently. This allows for a more thorough exploration and utilization of the information contained in PPG signals. However, challenges remain, such as limited quantity and quality of publicly available databases, a lack of effective validation in real-world scenarios, and concerns about the interpretability, scalability, and complexity of deep learning models. Moreover, there are still emerging research areas that require further investigation.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12806",
        "abstract url": "https://arxiv.org/abs/2401.12806",
        "title": "Binary structured physics-informed neural networks for solving equations with rapidly changing solutions",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Physics-informed neural networks (PINNs), rooted in deep learning, have emerged as a promising approach for solving partial differential equations (PDEs). By embedding the physical information described by PDEs into feedforward neural networks, PINNs are trained as surrogate models to approximate solutions without the need for label data. Nevertheless, even though PINNs have shown remarkable performance, they can face difficulties, especially when dealing with equations featuring rapidly changing solutions. These difficulties encompass slow convergence, susceptibility to becoming trapped in local minima, and reduced solution accuracy. To address these issues, we propose a binary structured physics-informed neural network (BsPINN) framework, which employs binary structured neural network (BsNN) as the neural network component. By leveraging a binary structure that reduces inter-neuron connections compared to fully connected neural networks, BsPINNs excel in capturing the local features of solutions more effectively and efficiently. These features are particularly crucial for learning the rapidly changing in the nature of solutions. In a series of numerical experiments solving Burgers equation, Euler equation, Helmholtz equation, and high-dimension Poisson equation, BsPINNs exhibit superior convergence speed and heightened accuracy compared to PINNs. From these experiments, we discover that BsPINNs resolve the issues caused by increased hidden layers in PINNs resulting in over-smoothing, and prevent the decline in accuracy due to non-smoothness of PDEs solutions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12914",
        "abstract url": "https://arxiv.org/abs/2401.12914",
        "title": "Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things",
        "rating": "-1.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we leverage a multi-agent reinforcement learning (MARL) framework to jointly learn a computation offloading decision and multichannel access policy with corresponding signaling. Specifically, the base station and industrial Internet of Things mobile devices are reinforcement learning agents that need to cooperate to execute their computation tasks within a deadline constraint. We adopt an emergent communication protocol learning framework to solve this problem. The numerical results illustrate the effectiveness of emergent communication in improving the channel access success rate and the number of successfully computed tasks compared to contention-based, contention-free, and no-communication approaches. Moreover, the proposed task offloading policy outperforms remote and local computation baselines.",
        "subjects": [
            "cs.IT",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12930",
        "abstract url": "https://arxiv.org/abs/2401.12930",
        "title": "pyAKI -- An Open Source Solution to Automated KDIGO classification",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "diagnosis",
                "Disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Acute Kidney Injury (AKI) is a frequent complication in critically ill patients, affecting up to 50% of patients in the intensive care units. The lack of standardized and open-source tools for applying the Kidney Disease Improving Global Outcomes (KDIGO) criteria to time series data has a negative impact on workload and study quality. This project introduces pyAKI, an open-source pipeline addressing this gap by providing a comprehensive solution for consistent KDIGO criteria implementation. The pyAKI pipeline was developed and validated using a subset of the Medical Information Mart for Intensive Care (MIMIC)-IV database, a commonly used database in critical care research. We defined a standardized data model in order to ensure reproducibility. Validation against expert annotations demonstrated pyAKI's robust performance in implementing KDIGO criteria. Comparative analysis revealed its ability to surpass the quality of human labels. This work introduces pyAKI as an open-source solution for implementing the KDIGO criteria for AKI diagnosis using time series data with high accuracy and performance.",
        "subjects": [
            "cs.LG",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13045",
        "abstract url": "https://arxiv.org/abs/2401.13045",
        "title": "Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?",
        "rating": "-1.5",
        "keywords": [
            [
                "biological",
                "diagnosing",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the past decade, the intricacies of sports-related concussions among female athletes have become readily apparent. Traditional clinical methods for diagnosing concussions suffer limitations when applied to female athletes, often failing to capture subtle changes in brain structure and function. Advanced neuroinformatics techniques and machine learning models have become invaluable assets in this endeavor. While these technologies have been extensively employed in understanding concussion in male athletes, there remains a significant gap in our comprehension of their effectiveness for female athletes. With its remarkable data analysis capacity, machine learning offers a promising avenue to bridge this deficit. By harnessing the power of machine learning, researchers can link observed phenotypic neuroimaging data to sex-specific biological mechanisms, unraveling the mysteries of concussions in female athletes. Furthermore, embedding methods within machine learning enable examining brain architecture and its alterations beyond the conventional anatomical reference frame. In turn, allows researchers to gain deeper insights into the dynamics of concussions, treatment responses, and recovery processes. To guarantee that female athletes receive the optimal care they deserve, researchers must employ advanced neuroimaging techniques and sophisticated machine-learning models. These tools enable an in-depth investigation of the underlying mechanisms responsible for concussion symptoms stemming from neuronal dysfunction in female athletes. This paper endeavors to address the crucial issue of sex differences in multimodal neuroimaging experimental design and machine learning approaches within female athlete populations, ultimately ensuring that they receive the tailored care they require when facing the challenges of concussions.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.AP",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13107",
        "abstract url": "https://arxiv.org/abs/2401.13107",
        "title": "Development of a Causal Model for Improving Rural Seniors' Accessibility: Data Evidences",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Seniors residing in rural areas often encounter limited accessibility to opportunities, resources, and services. This paper introduces a model proposing that both aging and rural residency are factors contributing to the restricted accessibility faced by rural seniors. Leveraging data from the 2017 National Household Travel Survey, the study examines three hypotheses pertaining to this causal model. Multiple causal pathways emerge in the data analysis, with mobility identified as a mediator in one of them. The study further identifies specific challenges faced by rural seniors, such as the reduced accessibility in reaching medical services and assisting others. These challenges stem primarily from aging and geographic obstacles that not only diminish their willingness to travel but also restrict more in the group from choosing transportation modes with higher mobility. The insights gained from this study serve as a foundation for devising effective methods to enhance transportation accessibility for seniors in rural areas.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "12 pages 5 tables"
    },
    {
        "paper id": "2401.13157",
        "abstract url": "https://arxiv.org/abs/2401.13157",
        "title": "Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Learning time-evolving objects such as multivariate time series and dynamic networks requires the development of novel knowledge representation mechanisms and neural network architectures, which allow for capturing implicit time-dependent information contained in the data. Such information is typically not directly observed but plays a key role in the learning task performance. In turn, lack of time dimension in knowledge encoding mechanisms for time-dependent data leads to frequent model updates, poor learning performance, and, as a result, subpar decision-making. Here we propose a new approach to a time-aware knowledge representation mechanism that notably focuses on implicit time-dependent topological information along multiple geometric dimensions. In particular, we propose a new approach, named \\textit{Temporal MultiPersistence} (TMP), which produces multidimensional topological fingerprints of the data by using the existing single parameter topological summaries. The main idea behind TMP is to merge the two newest directions in topological representation learning, that is, multi-persistence which simultaneously describes data shape evolution along multiple key parameters, and zigzag persistence to enable us to extract the most salient data shape information over time. We derive theoretical guarantees of TMP vectorizations and show its utility, in application to forecasting on benchmark traffic flow, Ethereum blockchain, and electrocardiogram datasets, demonstrating the competitive performance, especially, in scenarios of limited data records. In addition, our TMP method improves the computational efficiency of the state-of-the-art multipersistence summaries up to 59.5 times.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13191",
        "abstract url": "https://arxiv.org/abs/2401.13191",
        "title": "Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion model",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Recently, deep learning-based facial landmark detection for in-the-wild faces has achieved significant improvement. However, there are still challenges in face landmark detection in other domains (e.g. cartoon, caricature, etc). This is due to the scarcity of extensively annotated training data. To tackle this concern, we design a two-stage training approach that effectively leverages limited datasets and the pre-trained diffusion model to obtain aligned pairs of landmarks and face in multiple domains. In the first stage, we train a landmark-conditioned face generation model on a large dataset of real faces. In the second stage, we fine-tune the above model on a small dataset of image-landmark pairs with text prompts for controlling the domain. Our new designs enable our method to generate high-quality synthetic paired datasets from multiple domains while preserving the alignment between landmarks and facial features. Finally, we fine-tuned a pre-trained face landmark detection model on the synthetic dataset to achieve multi-domain face landmark detection. Our qualitative and quantitative results demonstrate that our method outperforms existing methods on multi-domain face landmark detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, ICASSP 2024 accepted"
    },
    {
        "paper id": "2401.13192",
        "abstract url": "https://arxiv.org/abs/2401.13192",
        "title": "Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model",
        "rating": "-1.5",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "Diffusion",
                "synthesis"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Efficiently generating energetically stable crystal structures has long been a challenge in material design, primarily due to the immense arrangement of atoms in a crystal lattice. To facilitate the discovery of stable material, we present a framework for the generation of synthesizable materials, leveraging a point cloud representation to encode intricate structural information. At the heart of this framework lies the introduction of a diffusion model as its foundational pillar. To gauge the efficacy of our approach, we employ it to reconstruct input structures from our training datasets, rigorously validating its high reconstruction performance. Furthermore, we demonstrate the profound potential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely new materials, emphasizing their synthesizability. Our research stands as a noteworthy contribution to the advancement of materials design and synthesis through the cutting-edge avenue of generative design instead of the conventional substitution or experience-based discovery.",
        "subjects": [
            "cs.AI",
            "cond-mat.mtrl-sci",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": "I have submitted to a journal"
    },
    {
        "paper id": "2401.13210",
        "abstract url": "https://arxiv.org/abs/2401.13210",
        "title": "Multitask Active Learning for Graph Anomaly Detection",
        "rating": "-1.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the web era, graph machine learning has been widely used on ubiquitous graph-structured data. As a pivotal component for bolstering web security and enhancing the robustness of graph-based applications, the significance of graph anomaly detection is continually increasing. While Graph Neural Networks (GNNs) have demonstrated efficacy in supervised and semi-supervised graph anomaly detection, their performance is contingent upon the availability of sufficient ground truth labels. The labor-intensive nature of identifying anomalies from complex graph structures poses a significant challenge in real-world applications. Despite that, the indirect supervision signals from other tasks (e.g., node classification) are relatively abundant. In this paper, we propose a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE. Firstly, by coupling node classification tasks, MITIGATE obtains the capability to detect out-of-distribution nodes without known anomalies. Secondly, MITIGATE quantifies the informativeness of nodes by the confidence difference across tasks, allowing samples with conflicting predictions to provide informative yet not excessively challenging information for subsequent training. Finally, to enhance the likelihood of selecting representative nodes that are distant from known patterns, MITIGATE adopts a masked aggregation mechanism for distance measurement, considering both inherent features of nodes and current labeled status. Empirical studies on four datasets demonstrate that MITIGATE significantly outperforms the state-of-the-art methods for anomaly detection. Our code is publicly available at: https://github.com/AhaChang/MITIGATE.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": "Preprint. Under review. Code available at https://github.com/AhaChang/MITIGATE"
    },
    {
        "paper id": "2401.13219",
        "abstract url": "https://arxiv.org/abs/2401.13219",
        "title": "TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "A species' genetic code or genome encodes valuable evolutionary, biological, and phylogenetic information that aids in species recognition, taxonomic classification, and understanding genetic predispositions like drug resistance and virulence. However, the vast number of potential species poses significant challenges in developing a general-purpose whole genome classification tool. Traditional bioinformatics tools have made notable progress but lack scalability and are computationally expensive. Machine learning-based frameworks show promise but must address the issue of large classification vocabularies with long-tail distributions. In this study, we propose addressing this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a taxonomy-aware embedding space for reasoning and classification. This embedding space captures compositional and phylogenetic relationships of species, enabling predictions in extensive search spaces. We evaluate TEPI using two rigorous zero-shot settings and demonstrate its generalization capabilities qualitatively on curated, large-scale, publicly sourced data.",
        "subjects": [
            "q-bio.GN",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to IEEE JBHI"
    },
    {
        "paper id": "2402.01691",
        "abstract url": "https://arxiv.org/abs/2402.01691",
        "title": "Investigating Algorithm Review Boards for Organizational Responsible Artificial Intelligence Governance",
        "rating": "-1.5",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Organizations including companies, nonprofits, governments, and academic institutions are increasingly developing, deploying, and utilizing artificial intelligence (AI) tools. Responsible AI (RAI) governance approaches at organizations have emerged as important mechanisms to address potential AI risks and harms. In this work, we interviewed 17 technical contributors across organization types (Academic, Government, Industry, Nonprofit) and sectors (Finance, Health, Tech, Other) about their experiences with internal RAI governance. Our findings illuminated the variety of organizational definitions of RAI and accompanying internal governance approaches. We summarized the first detailed findings on algorithm review boards (ARBs) and similar review committees in practice, including their membership, scope, and measures of success. We confirmed known robust model governance in finance sectors and revealed extensive algorithm and AI governance with ARB-like review boards in health sectors. Our findings contradict the idea that Institutional Review Boards alone are sufficient for algorithm governance and posit that ARBs are among the more impactful internal RAI governance approaches. Our results suggest that integration with existing internal regulatory approaches and leadership buy-in are among the most important attributes for success and that financial tensions are the greatest challenge to effective organizational RAI. We make a variety of suggestions for how organizational partners can learn from these findings when building their own internal RAI frameworks. We outline future directions for developing and measuring effectiveness of ARBs and other internal RAI governance approaches.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12553",
        "abstract url": "https://arxiv.org/abs/2401.12553",
        "title": "InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Ranking items regarding individual user interests is a core technique of multiple downstream tasks such as recommender systems. Learning such a personalized ranker typically relies on the implicit feedback from users' past click-through behaviors. However, collected feedback is biased toward previously highly-ranked items and directly learning from it would result in a \"rich-get-richer\" phenomenon. In this paper, we propose a simple yet sufficient unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously address both position and popularity biases. We begin by consolidating the impacts of those biases into a single observation factor, thereby providing a unified approach to addressing bias-related issues. Subsequently, we minimize the mutual information between the observation estimation and the relevance estimation conditioned on the input features. By doing so, our relevance estimation can be proved to be free of bias. To implement InfoRank, we first incorporate an attention mechanism to capture latent correlations within user-item features, thereby generating estimations of observation and relevance. We then introduce a regularization term, grounded in conditional mutual information, to promote conditional independence between relevance estimation and observation estimation. Experimental evaluations conducted across three extensive recommendation and search datasets reveal that InfoRank learns more precise and unbiased ranking strategies.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "WWW 2024"
    },
    {
        "paper id": "2401.12561",
        "abstract url": "https://arxiv.org/abs/2401.12561",
        "title": "EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "voxel",
                "depth"
            ],
            [
                "surgical",
                "surgery",
                "Endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstructing deformable tissues from endoscopic videos is essential in many downstream surgical applications. However, existing methods suffer from slow rendering speed, greatly limiting their practical use. In this paper, we introduce EndoGaussian, a real-time endoscopic scene reconstruction framework built on 3D Gaussian Splatting (3DGS). By integrating the efficient Gaussian representation and highly-optimized rendering engine, our framework significantly boosts the rendering speed to a real-time level. To adapt 3DGS for endoscopic scenes, we propose two strategies, Holistic Gaussian Initialization (HGI) and Spatio-temporal Gaussian Tracking (SGT), to handle the non-trivial Gaussian initialization and tissue deformation problems, respectively. In HGI, we leverage recent depth estimation models to predict depth maps of input binocular/monocular image sequences, based on which pixels are re-projected and combined for holistic initialization. In SPT, we propose to model surface dynamics using a deformation field, which is composed of an efficient encoding voxel and a lightweight deformation decoder, allowing for Gaussian tracking with minor training and rendering burden. Experiments on public datasets demonstrate our efficacy against prior SOTAs in many aspects, including better rendering speed (195 FPS real-time, 100$\\times$ gain), better rendering quality (37.848 PSNR), and less training overhead (within 2 min/scene), showing significant promise for intraoperative surgery applications. Code is available at: \\url{https://yifliu3.github.io/EndoGaussian/}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12597",
        "abstract url": "https://arxiv.org/abs/2401.12597",
        "title": "Towards Privacy-, Budget-, and Deadline-Aware Service Optimization for Large Medical Image Processing across Hybrid Clouds",
        "rating": "-2",
        "keywords": [
            [
                "Medical",
                "diagnosing",
                "whole slide"
            ]
        ],
        "abstract": "Efficiently processing medical images, such as whole slide images in digital pathology, is essential for timely diagnosing high-risk diseases. However, this demands advanced computing infrastructure, e.g., GPU servers for deep learning inferencing, and local processing is time-consuming and costly. Besides, privacy concerns further complicate the employment of remote cloud infrastructures. While previous research has explored privacy and security-aware workflow scheduling in hybrid clouds for distributed processing, privacy-preserving data splitting, optimizing the service allocation of outsourcing computation on split data to the cloud, and privacy evaluation for large medical images still need to be addressed. This study focuses on tailoring a virtual infrastructure within a hybrid cloud environment and scheduling the image processing services while preserving privacy. We aim to minimize the use of untrusted nodes, lower monetary costs, and reduce execution time under privacy, budget, and deadline requirements. We consider a two-phase solution and develop 1) a privacy-preserving data splitting algorithm and 2) a greedy Pareto front-based algorithm for optimizing the service allocation. We conducted experiments with real and simulated data to validate and compare our method with a baseline. The results show that our privacy mechanism design outperforms the baseline regarding the average lower band on individual privacy and information gain for privacy evaluation. In addition, our approach can obtain various Pareto optimal-based allocations with users' preferences on the maximum number of untrusted nodes, budget, and time threshold. Our solutions often dominate the baseline's solution and are superior on a tight budget. Specifically, our approach has been ahead of baseline, up to 85.2% and 6.8% in terms of the total financial and time costs, respectively.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12603",
        "abstract url": "https://arxiv.org/abs/2401.12603",
        "title": "ASAP (Automatic Software for ASL Processing): A toolbox for processing Arterial Spin Labeling images",
        "rating": "-2",
        "keywords": [
            [
                "Disease"
            ]
        ],
        "abstract": "The method of Arterial Spin Labeling (ASL) has experienced a significant rise in its application to functional imaging, since it is the only technique capable of measuring blood perfusion in a truly non-invasive manner. Currently, there are no commercial packages for processing ASL data and there is no recognised standard for normalising ASL data to a common frame of reference. This work describes a new Automated Software for ASL Processing (ASAP) that can automatically process several ASL datasets. ASAP includes functions for all stages of image pre-processing: quantification, skull-stripping, co-registration, partial volume correction and normalization. To assess the applicability and validity of the toolbox, this work shows its application in the study of hypoperfusion in a sample of healthy subjects at risk of progressing to Alzheimer's Disease. ASAP requires limited user intervention, minimising the possibility of random and systematic errors, and produces cerebral blood flow maps that are ready for statistical group analysis. The software is easy to operate and results in excellent quality of spatial normalisation. The results found in this evaluation study are consistent with previous studies that find decreased perfusion",
        "subjects": [
            "cs.SE"
        ],
        "comment": "10 pages, 8 figures, 3 tables"
    },
    {
        "paper id": "2401.12604",
        "abstract url": "https://arxiv.org/abs/2401.12604",
        "title": "On Pigeonhole Principles and Ramsey in TFNP",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "The generalized pigeonhole principle says that if tN + 1 pigeons are put into N holes then there must be a hole containing at least t + 1 pigeons. Let t-PPP denote the class of all total NP-search problems reducible to finding such a t-collision of pigeons. We introduce a new hierarchy of classes defined by the problems t-PPP. In addition to being natural problems in TFNP, we show that classes in and above the hierarchy are related to the notion of multi-collision resistance in cryptography, and contain the problem underlying the breakthrough average-case quantum advantage result shown by Yamakawa & Zhandry (FOCS 2022). Finally, we give lower bound techniques for the black-box versions of t-PPP for any t. In particular, we prove that RAMSEY is not in t-PPP, for any t that is sub-polynomial in log (N), in the black-box setting. Goldberg and Papadimitriou conjectured that RAMSEY reduces to 2-PPP, we thus refute it and more in the black-box setting. We also provide an ensemble of black-box separations which resolve the relative complexity of the t-PPP classes with other well-known TFNP classes.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12703",
        "abstract url": "https://arxiv.org/abs/2401.12703",
        "title": "Small Test Suites for Active Automata Learning",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "A bottleneck in modern active automata learning is to test whether a hypothesized Mealy machine correctly describes the system under learning. The search space for possible counterexamples is given by so-called test suites, consisting of input sequences that have to be checked to decide whether a counterexample exists. This paper shows that significantly smaller test suites suffice under reasonable assumptions on the structure of the black box. These smaller test suites help to refute false hypotheses during active automata learning, even when the assumptions do not hold. We combine multiple test suites using a multi-armed bandit setup that adaptively selects a test suite. An extensive empirical evaluation shows the efficacy of our approach. For small to medium-sized models, the performance gain is limited. However, the approach allows learning models from large, industrial case studies that were beyond the reach of known methods.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Extended paper for TACAS 2024"
    },
    {
        "paper id": "2401.12720",
        "abstract url": "https://arxiv.org/abs/2401.12720",
        "title": "A Comprehensive View of the Biases of Toxicity and Sentiment Analysis Methods Towards Utterances with African American English Expressions",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "grammatical"
            ],
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Language is a dynamic aspect of our culture that changes when expressed in different technologies/communities. Online social networks have enabled the diffusion and evolution of different dialects, including African American English (AAE). However, this increased usage is not without barriers. One particular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity (Google's Perspective and the open-source Detoxify) methods present biases towards utterances with AAE expressions. Consider Google's Perspective to understand bias. Here, an utterance such as ``All n*ggers deserve to die respectfully. The police murder us.'' it reaches a higher toxicity than ``African-Americans deserve to die respectfully. The police murder us.''. This score difference likely arises because the tool cannot understand the re-appropriation of the term ``n*gger''. One explanation for this bias is that AI models are trained on limited datasets, and using such a term in training data is more likely to appear in a toxic utterance. While this may be plausible, the tool will make mistakes regardless. Here, we study bias on two Web-based (YouTube and Twitter) datasets and two spoken English datasets. Our analysis shows how most models present biases towards AAE in most settings. We isolate the impact of AAE expression usage via linguistic control features from the Linguistic Inquiry and Word Count (LIWC) software, grammatical control features extracted via Part-of-Speech (PoS) tagging from Natural Language Processing (NLP) models, and the semantic of utterances by comparing sentence embeddings from recent language models. We present consistent results on how a heavy usage of AAE expressions may cause the speaker to be considered substantially more toxic, even when speaking about nearly the same subject. Our study complements similar analyses focusing on small datasets and/or one method only.",
        "subjects": [
            "cs.CL",
            "cs.SI"
        ],
        "comment": "Under peer review"
    },
    {
        "paper id": "2401.12857",
        "abstract url": "https://arxiv.org/abs/2401.12857",
        "title": "Simultaneous exercise recognition and evaluation in prescribed routines: Approach to virtual coaches",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "Home-based physical therapies are effective if the prescribed exercises are correctly executed and patients adhere to these routines. This is specially important for older adults who can easily forget the guidelines from therapists. Inertial Measurement Units (IMUs) are commonly used for tracking exercise execution giving information of patients' motion data. In this work, we propose the use of Machine Learning techniques to recognize which exercise is being carried out and to assess if the recognized exercise is properly executed by using data from four IMUs placed on the person limbs. To the best of our knowledge, both tasks have never been addressed together as a unique complex task before. However, their combination is needed for the complete characterization of the performance of physical therapies. We evaluate the performance of six machine learning classifiers in three contexts: recognition and evaluation in a single classifier, recognition of correct exercises, excluding the wrongly performed exercises, and a two-stage approach that first recognizes the exercise and then evaluates it. We apply our proposal to a set of 8 exercises of the upper-and lower-limbs designed for maintaining elderly people health status. To do so, the motion of volunteers were monitored with 4 IMUs. We obtain accuracies of 88.4 \\% and the 91.4 \\% in the two initial scenarios. In the third one, the recognition provides an accuracy of 96.2 \\%, whereas the exercise evaluation varies between 93.6 \\% and 100.0 \\%. This work proves the feasibility of IMUs for a complete monitoring of physical therapies in which we can get information of which exercise is being performed and its quality, as a basis for designing virtual coaches.",
        "subjects": [
            "cs.HC",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12861",
        "abstract url": "https://arxiv.org/abs/2401.12861",
        "title": "Secure Communication with Unreliable Entanglement Assistance",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Secure communication is considered with unreliable entanglement assistance, where the adversary may intercept the legitimate receiver's entanglement resource before communication takes place. The communication setting of unreliable assistance, without security aspects, was originally motivated by the extreme photon loss in practical communication systems. The operational principle is to adapt the transmission rate to the availability of entanglement assistance, without resorting to feedback and repetition. Here, we require secrecy as well. An achievable secrecy rate region is derived for general quantum wiretap channels, and a multi-letter secrecy capacity formula for the special class of degraded channels.",
        "subjects": [
            "quant-ph",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12888",
        "abstract url": "https://arxiv.org/abs/2401.12888",
        "title": "Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies",
        "rating": "-2",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The aspiration of the next generation's autonomous driving (AD) technology relies on the dedicated integration and interaction among intelligent perception, prediction, planning, and low-level control. There has been a huge bottleneck regarding the upper bound of autonomous driving algorithm performance, a consensus from academia and industry believes that the key to surmount the bottleneck lies in data-centric autonomous driving technology. Recent advancement in AD simulation, closed-loop model training, and AD big data engine have gained some valuable experience. However, there is a lack of systematic knowledge and deep understanding regarding how to build efficient data-centric AD technology for AD algorithm self-evolution and better AD big data accumulation. To fill in the identified research gaps, this article will closely focus on reviewing the state-of-the-art data-driven autonomous driving technologies, with an emphasis on the comprehensive taxonomy of autonomous driving datasets characterized by milestone generations, key features, data acquisition settings, etc. Furthermore, we provide a systematic review of the existing benchmark closed-loop AD big data pipelines from the industrial frontier, including the procedure of closed-loop frameworks, key technologies, and empirical studies. Finally, the future directions, potential applications, limitations and concerns are discussed to arouse efforts from both academia and industry for promoting the further development of autonomous driving. The project repository is available at: https://github.com/LincanLi98/Awesome-Data-Centric-Autonomous-Driving.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12938",
        "abstract url": "https://arxiv.org/abs/2401.12938",
        "title": "Neural deformation fields for template-based reconstruction of cortical surfaces from MRI",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "MRI"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The reconstruction of cortical surfaces is a prerequisite for quantitative analyses of the cerebral cortex in magnetic resonance imaging (MRI). Existing segmentation-based methods separate the surface registration from the surface extraction, which is computationally inefficient and prone to distortions. We introduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique that learns a deformation field from a brain template to the cortical surfaces of an MRI scan. To this end, we present a geometric neural network that models the deformation-describing ordinary differential equation in a continuous manner. The network architecture comprises convolutional and graph-convolutional layers, which allows it to work with images and meshes at the same time. V2C-Flow is not only very fast, requiring less than two seconds to infer all four cortical surfaces, but also establishes vertex-wise correspondences to the template during reconstruction. In addition, V2C-Flow is the first approach for cortex reconstruction that models white matter and pial surfaces jointly, therefore avoiding intersections between them. Our comprehensive experiments on internal and external test data demonstrate that V2C-Flow results in cortical surfaces that are state-of-the-art in terms of accuracy. Moreover, we show that the established correspondences are more consistent than in FreeSurfer and that they can directly be utilized for cortex parcellation and group analyses of cortical thickness.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "To appear in Medical Image Analysis"
    },
    {
        "paper id": "2401.12956",
        "abstract url": "https://arxiv.org/abs/2401.12956",
        "title": "Examining the Role of Peer Acknowledgements on Social Annotations: Unraveling the Psychological Underpinnings",
        "rating": "-2",
        "keywords": [
            [
                "Psychological"
            ]
        ],
        "abstract": "This study explores the impact of peer acknowledgement on learner engagement and implicit psychological attributes in written annotations on an online social reading platform. Participants included 91 undergraduates from a large North American University. Using log file data, we analyzed the relationship between learners' received peer acknowledgement and their subsequent annotation behaviours using cross-lag regression. Higher peer acknowledgements correlate with increased initiation of annotations and responses to peer annotations. By applying text mining techniques and calculating Shapley values to analyze 1,969 social annotation entries, we identified prominent psychological themes within three dimensions (i.e., affect, cognition, and motivation) that foster peer acknowledgment in digital social annotation. These themes include positive affect, openness to learning and discussion, and expression of motivation. The findings assist educators in improving online learning communities and provide guidance to technology developers in designing effective prompts, drawing from both implicit psychological cues and explicit learning behaviours.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13049",
        "abstract url": "https://arxiv.org/abs/2401.13049",
        "title": "CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "surgical",
                "CT"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Advancements in medical imaging and endovascular grafting have facilitated minimally invasive treatments for aortic diseases. Accurate 3D segmentation of the aorta and its branches is crucial for interventions, as inaccurate segmentation can lead to erroneous surgical planning and endograft construction. Previous methods simplified aortic segmentation as a binary image segmentation problem, overlooking the necessity of distinguishing between individual aortic branches. In this paper, we introduce Context Infused Swin-UNet (CIS-UNet), a deep learning model designed for multi-class segmentation of the aorta and thirteen aortic branches. Combining the strengths of Convolutional Neural Networks (CNNs) and Swin transformers, CIS-UNet adopts a hierarchical encoder-decoder structure comprising a CNN encoder, symmetric decoder, skip connections, and a novel Context-aware Shifted Window Self-Attention (CSW-SA) as the bottleneck block. Notably, CSW-SA introduces a unique utilization of the patch merging layer, distinct from conventional Swin transformers. It efficiently condenses the feature map, providing a global spatial context and enhancing performance when applied at the bottleneck layer, offering superior computational efficiency and segmentation accuracy compared to the Swin transformers. We trained our model on computed tomography (CT) scans from 44 patients and tested it on 15 patients. CIS-UNet outperformed the state-of-the-art SwinUNetR segmentation model, which is solely based on Swin transformers, by achieving a superior mean Dice coefficient of 0.713 compared to 0.697, and a mean surface distance of 2.78 mm compared to 3.39 mm. CIS-UNet's superior 3D aortic segmentation offers improved precision and optimization for planning endovascular treatments. Our dataset and code will be publicly available.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13067",
        "abstract url": "https://arxiv.org/abs/2401.13067",
        "title": "A novel wavelet-based filtering strategy to remove powerline interference from electrocardiograms with atrial fibrillation",
        "rating": "-2",
        "keywords": [
            [
                "cardiac",
                "pathological"
            ]
        ],
        "abstract": "\"Objective: The electrocardiogram (ECG) is currently the most widely used recording to diagnose cardiac disorders, including the most common supraventricular arrhythmia, such as atrial fibrillation (AF). However, different types of electrical disturbances, in which power-line interference (PLI) is a major problem, can mask and distort the original ECG morphology. This is a significant issue in the context of AF, because accurate characterization of fibrillatory waves (f-waves) is unavoidably required to improve current knowledge about its mechanisms. This work introduces a new algorithm able to reduce high levels of PLI and preserve, simultaneously, the original ECG morphology. Approach: The method is based on stationary wavelet transform shrinking and makes use of a new thresholding function designed to work successfully in a wide variety of scenarios. In fact, it has been validated in a general context with 48 ECG recordings obtained from pathological and non-pathological conditions, as well as in the particular context of AF, where 380 synthesized and 20 long-term real ECG recordings were analyzed. Main results: In both situations, the algorithm has reported a notably better performance than common methods designed for the same purpose. Moreover, its effectiveness has proven to be optimal for dealing with ECG recordings affected by AF, since f-waves remained almost intact after removing very high levels of noise. Significance: The proposed algorithm may facilitate a reliable characterization of the f-waves, preventing them from not being masked by the PLI nor distorted by an unsuitable filtering applied to ECG recordings with AF.\"",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13147",
        "abstract url": "https://arxiv.org/abs/2401.13147",
        "title": "Deep Spatiotemporal Clutter Filtering of Transthoracic Echocardiographic Images Using a 3D Convolutional Auto-Encoder",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "clinical",
                "cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study presents a deep convolutional auto-encoder network for filtering reverberation artifacts, from transthoracic echocardiographic (TTE) image sequences. Given the spatiotemporal nature of these artifacts, the filtering network was built using 3D convolutional layers to suppress the clutter patterns throughout the cardiac cycle. The network was designed by taking advantage of: i) an attention mechanism to focus primarily on cluttered regions and ii) residual learning to preserve fine structures of the image frames. To train the deep network, a diverse set of artifact patterns was simulated and the simulated patterns were superimposed onto artifact-free ultra-realistic synthetic TTE sequences of six ultrasound vendors to generate input of the filtering network. The artifact-free sequences served as ground-truth. Performance of the filtering network was evaluated using unseen synthetic as well as in-vivo artifactual sequences. Satisfactory results obtained using the latter dataset confirmed the good generalization performance of the proposed network which was trained using the synthetic sequences and simulated artifact patterns. Suitability of the clutter-filtered sequences for further processing was assessed by computing segmental strain curves from them. The results showed that the large discrepancy between the strain profiles computed from the cluttered segments and their corresponding segments in the clutter-free images was significantly reduced after filtering the sequences using the proposed network. The trained deep network could process an artifactual TTE sequence in a fraction of a second and can be used for real-time clutter filtering. Moreover, it can improve the precision of the clinical indexes that are computed from the TTE sequences. The source code of the proposed method is available at: https://github.com/MahdiTabassian/Deep-Clutter-Filtering/tree/main.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "18 pages, 14 figures"
    },
    {
        "paper id": "2401.13156",
        "abstract url": "https://arxiv.org/abs/2401.13156",
        "title": "Local Hamiltonian decomposition and classical simulation of parametrized quantum circuits",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "In this paper we develop a classical algorithm of complexity $O(K \\, 2^n)$ to simulate parametrized quantum circuits (PQCs) of $n$ qubits, where $K$ is the total number of one-qubit and two-qubit control gates. The algorithm is developed by finding $2$-sparse unitary matrices of order $2^n$ explicitly corresponding to any single-qubit and two-qubit control gates in an $n$-qubit system. Finally, we determine analytical expression of Hamiltonians for any such gate and consequently a local Hamiltonian decomposition of any PQC is obtained. All results are validated with numerical simulations.",
        "subjects": [
            "quant-ph",
            "cs.SC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13194",
        "abstract url": "https://arxiv.org/abs/2401.13194",
        "title": "LightSleepNet: Design of a Personalized Portable Sleep Staging System Based on Single-Channel EEG",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "This paper proposed LightSleepNet - a light-weight, 1-d Convolutional Neural Network (CNN) based personalized architecture for real-time sleep staging, which can be implemented on various mobile platforms with limited hardware resources. The proposed architecture only requires an input of 30s single-channel EEG signal for the classification. Two residual blocks consisting of group 1-d convolution are used instead of the traditional convolution layers to remove the redundancy in the CNN. Channel shuffles are inserted into each convolution layer to improve the accuracy. In order to avoid over-fitting to the training set, a Global Average Pooling (GAP) layer is used to replace the fully connected layer, which further reduces the total number of the model parameters significantly. A personalized algorithm combining Adaptive Batch Normalization (AdaBN) and gradient re-weighting is proposed for unsupervised domain adaptation. A higher priority is given to examples that are easy to transfer to the new subject, and the algorithm could be personalized for new subjects without re-training. Experimental results show a state-of-the-art overall accuracy of 83.8% with only 45.76 Million Floating-point Operations per Second (MFLOPs) computation and 43.08 K parameters.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures, published by IEEE TCAS-II"
    },
    {
        "paper id": "2401.13712",
        "abstract url": "https://arxiv.org/abs/2401.13712",
        "title": "Engineering Yeast Cells to Facilitate Information Exchange",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Although continuous advances in theoretical modelling of Molecular Communications (MC) are observed, there is still an insuperable gap between theory and experimental testbeds, especially at the microscale. In this paper, the development of the first testbed incorporating engineered yeast cells is reported. Different from the existing literature, eukaryotic yeast cells are considered for both the sender and the receiver, with \u03b1-factor molecules facilitating the information transfer. The use of such cells is motivated mainly by the well understood biological mechanism of yeast mating, together with their genetic amenability. In addition, recent advances in yeast biosensing establish yeast as a suitable detector and a neat interface to in-body sensor networks. The system under consideration is presented first, and the mathematical models of the underlying biological processes leading to an end-to-end (E2E) system are given. The experimental setup is then described and used to obtain experimental results which validate the developed mathematical models. Beyond that, the ability of the system to effectively generate output pulses in response to repeated stimuli is demonstrated, reporting one event per two hours. However, fast RNA fluctuations indicate cell responses in less than three minutes, demonstrating the potential for much higher rates in the future.",
        "subjects": [
            "cs.ET",
            "cs.IT",
            "q-bio.MN"
        ],
        "comment": "18 pages, 9 figures (2 of which are not colored) all .png, recently accepted for publication at TMBMC"
    },
    {
        "paper id": "2402.16870",
        "abstract url": "https://arxiv.org/abs/2402.16870",
        "title": "Pioneering Deterministic Scheduling and Network Structure Optimization for Time-Critical Computing Tasks in Industrial IoT",
        "rating": "-2",
        "keywords": [
            [
                "Industrial",
                "IoT"
            ]
        ],
        "abstract": "The Industrial Internet of Things (IIoT) has become a critical technology to accelerate the process of digital and intelligent transformation of industries. As the cooperative relationship between smart devices in IIoT becomes more complex, getting deterministic responses of IIoT periodic time-critical computing tasks becomes a crucial and nontrivial problem. However, few current works in cloud/edge/fog computing focus on this problem. This paper is a pioneer to explore the deterministic scheduling and network structural optimization problems for IIoT periodic time-critical computing tasks. We first formulate the two problems and derive theorems to help quickly identify computation and network resource sharing conflicts. Based on this, we propose a deterministic scheduling algorithm, \\textit{IIoTBroker}, which realizes deterministic response for each IIoT task by optimizing the fine-grained computation and network resources allocations, and a network optimization algorithm, \\textit{IIoTDeployer}, providing a cost-effective structural upgrade solution for existing IIoT networks. Our methods are illustrated to be cost-friendly, scalable, and deterministic response guaranteed with low computation cost from our simulation results.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2401.12568",
        "abstract url": "https://arxiv.org/abs/2401.12568",
        "title": "NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for Talking Face Synthesis",
        "rating": "-2.5",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "Synthesis"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Talking face synthesis driven by audio is one of the current research hotspots in the fields of multidimensional signal processing and multimedia. Neural Radiance Field (NeRF) has recently been brought to this research field in order to enhance the realism and 3D effect of the generated faces. However, most existing NeRF-based methods either burden NeRF with complex learning tasks while lacking methods for supervised multimodal feature fusion, or cannot precisely map audio to the facial region related to speech movements. These reasons ultimately result in existing methods generating inaccurate lip shapes. This paper moves a portion of NeRF learning tasks ahead and proposes a talking face synthesis method via NeRF with attention-based disentanglement (NeRF-AD). In particular, an Attention-based Disentanglement module is introduced to disentangle the face into Audio-face and Identity-face using speech-related facial action unit (AU) information. To precisely regulate how audio affects the talking face, we only fuse the Audio-face with audio feature. In addition, AU information is also utilized to supervise the fusion of these two modalities. Extensive qualitative and quantitative experiments demonstrate that our NeRF-AD outperforms state-of-the-art methods in generating realistic talking face videos, including image quality and lip synchronization. To view video results, please refer to https://xiaoxingliu02.github.io/NeRF-AD.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2401.12700",
        "abstract url": "https://arxiv.org/abs/2401.12700",
        "title": "Securing Recommender System via Cooperative Training",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recommender systems are often susceptible to well-crafted fake profiles, leading to biased recommendations. Among existing defense methods, data-processing-based methods inevitably exclude normal samples, while model-based methods struggle to enjoy both generalization and robustness. To this end, we suggest integrating data processing and the robust model to propose a general framework, Triple Cooperative Defense (TCD), which employs three cooperative models that mutually enhance data and thereby improve recommendation robustness. Furthermore, Considering that existing attacks struggle to balance bi-level optimization and efficiency, we revisit poisoning attacks in recommender systems and introduce an efficient attack strategy, Co-training Attack (Co-Attack), which cooperatively optimizes the attack optimization and model training, considering the bi-level setting while maintaining attack efficiency. Moreover, we reveal a potential reason for the insufficient threat of existing attacks is their default assumption of optimizing attacks in undefended scenarios. This overly optimistic setting limits the potential of attacks. Consequently, we put forth a Game-based Co-training Attack (GCoAttack), which frames the proposed CoAttack and TCD as a game-theoretic process, thoroughly exploring CoAttack's attack potential in the cooperative training of attack and defense. Extensive experiments on three real datasets demonstrate TCD's superiority in enhancing model robustness. Additionally, we verify that the two proposed attack strategies significantly outperform existing attacks, with game-based GCoAttack posing a greater poisoning threat than CoAttack.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2210.13762"
    },
    {
        "paper id": "2401.12917",
        "abstract url": "https://arxiv.org/abs/2401.12917",
        "title": "Active Inference as a Model of Agency",
        "rating": "-2.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "biological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Is there a canonical way to think of agency beyond reward maximisation? In this paper, we show that any type of behaviour complying with physically sound assumptions about how macroscopic biological agents interact with the world canonically integrates exploration and exploitation in the sense of minimising risk and ambiguity about states of the world. This description, known as active inference, refines the free energy principle, a popular descriptive framework for action and perception originating in neuroscience. Active inference provides a normative Bayesian framework to simulate and model agency that is widely used in behavioural neuroscience, reinforcement learning (RL) and robotics. The usefulness of active inference for RL is three-fold. \\emph{a}) Active inference provides a principled solution to the exploration-exploitation dilemma that usefully simulates biological agency. \\emph{b}) It provides an explainable recipe to simulate behaviour, whence behaviour follows as an explainable mixture of exploration and exploitation under a generative world model, and all differences in behaviour are explicit in differences in world model. \\emph{c}) This framework is universal in the sense that it is theoretically possible to rewrite any RL algorithm conforming to the descriptive assumptions of active inference as an active inference algorithm. Thus, active inference can be used as a tool to uncover and compare the commitments and assumptions of more specific models of agency.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted in RLDM2022 for the workshop 'RL as a model of agency'"
    },
    {
        "paper id": "2401.13096",
        "abstract url": "https://arxiv.org/abs/2401.13096",
        "title": "Probabilistic Demand Forecasting with Graph Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Demand forecasting is a prominent business use case that allows retailers to optimize inventory planning, logistics, and core business decisions. One of the key challenges in demand forecasting is accounting for relationships and interactions between articles. Most modern forecasting approaches provide independent article-level predictions that do not consider the impact of related articles. Recent research has attempted addressing this challenge using Graph Neural Networks (GNNs) and showed promising results. This paper builds on previous research on GNNs and makes two contributions. First, we integrate a GNN encoder into a state-of-the-art DeepAR model. The combined model produces probabilistic forecasts, which are crucial for decision-making under uncertainty. Second, we propose to build graphs using article attribute similarity, which avoids reliance on a pre-defined graph structure. Experiments on three real-world datasets show that the proposed approach consistently outperforms non-graph benchmarks. We also show that our approach produces article embeddings that encode article similarity and demand dynamics and are useful for other downstream business tasks beyond forecasting.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Preprint of the paper accepted to ECML PKDD 2023 ML4ITS Workshop"
    },
    {
        "paper id": "2402.00046",
        "abstract url": "https://arxiv.org/abs/2402.00046",
        "title": "Introducing PetriRL: An Innovative Framework for JSSP Resolution Integrating Petri nets and Event-based Reinforcement Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Resource utilization and production process optimization are crucial for companies in today's competitive industrial landscape. Addressing the complexities of job shop scheduling problems (JSSP) is essential to improving productivity, reducing costs, and ensuring timely delivery. We propose PetriRL, a novel framework integrating Petri nets and deep reinforcement learning (DRL) for JSSP optimization. PetriRL capitalizes on the inherent strengths of Petri nets in modelling discrete event systems while leveraging the advantages of a graph structure. The Petri net governs automated components of the process, ensuring adherence to JSSP constraints. This allows for synergistic collaboration with optimization algorithms such as DRL, particularly in critical decision-making. Unlike traditional methods, PetriRL eliminates the need to preprocess JSSP instances into disjunctive graphs and enhances the explainability of process status through its graphical structure based on places and transitions. Additionally, the inherent graph structure of Petri nets enables the dynamic additions of job operations during the inference phase without requiring agent retraining, thus enhancing flexibility. Experimental results demonstrate PetriRL's robust generalization across various instance sizes and its competitive performance on public test benchmarks and randomly generated instances. Results are compared to a wide range of optimization solutions such as heuristics, metaheuristics, and learning-based algorithms. Finally, the added values of the framework's key elements, such as event-based control and action masking, are studied in the ablation study.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.09426",
        "abstract url": "https://arxiv.org/abs/2402.09426",
        "title": "Graph Koopman Autoencoder for Predictive Covert Communication Against UAV Surveillance",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "UAV"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Low Probability of Detection (LPD) communication aims to obscure the very presence of radio frequency (RF) signals, going beyond just hiding the content of the communication. However, the use of Unmanned Aerial Vehicles (UAVs) introduces a challenge, as UAVs can detect RF signals from the ground by hovering over specific areas of interest. With the growing utilization of UAVs in modern surveillance, there is a crucial need for a thorough understanding of their unknown nonlinear dynamic trajectories to effectively implement LPD communication. Unfortunately, this critical information is often not readily available, posing a significant hurdle in LPD communication. To address this issue, we consider a case-study for enabling terrestrial LPD communication in the presence of multiple UAVs that are engaged in surveillance. We introduce a novel framework that combines graph neural networks (GNN) with Koopman theory to predict the trajectories of multiple fixed-wing UAVs over an extended prediction horizon. Using the predicted UAV locations, we enable LPD communication in a terrestrial ad-hoc network by controlling nodes' transmit powers to keep the received power at UAVs' predicted locations minimized. Our extensive simulations validate the efficacy of the proposed framework in accurately predicting the trajectories of multiple UAVs, thereby effectively establishing LPD communication.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.16837",
        "abstract url": "https://arxiv.org/abs/2404.16837",
        "title": "The Security Performance Analysis of Blockchain System Based on Post-Quantum Cryptography -- A Case Study of Cryptocurrency Exchanges",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Quantum"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The current blockchain system for cryptocurrency exchanges primarily employs elliptic curve cryptography (ECC) for generating key pairs in wallets, and elliptic curve digital signature algorithms (ECDSA) for generating signatures in transactions. Consequently, with the maturation of quantum computing technology, the current blockchain system faces the risk of quantum computing attacks. Quantum computers may potentially counterfeit signatures produced by ECDSA. Therefore, this study analyzes the vulnerabilities of the current blockchain system to quantum computing attacks and proposes a post-quantum cryptography (PQC)-based blockchain system to enhance security by addressing and improving each identified weakness. Furthermore, this study proposes PQC-based wallets and PQC-based transactions, utilizing PQC digital signature algorithms to generate PQC-based signatures for the inputs in PQC-based transactions, thereby preventing signatures from being counterfeited by quantum computing. Experimental results demonstrate that the efficiency of the Dilithium algorithm, a PQC digital signature algorithm, in producing wallets, generating signatures, and verifying signatures surpasses that of ECDSA in the current blockchain system. Furthermore, the Dilithium algorithm also exhibits a higher security level.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.SE"
        ],
        "comment": "in Chinese language"
    },
    {
        "paper id": "2401.12622",
        "abstract url": "https://arxiv.org/abs/2401.12622",
        "title": "Nonlinear Distortion Radiated from Large Arrays and Active Reconfigurable Intelligent Surfaces",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "Extremely large aperture arrays (ELAAs) and reconfigurable intelligent surfaces (RISs) are candidate enablers to realize connectivity goals for the sixth-generation (6G) wireless networks. For instance, ELAAs can provide orders-of-magnitude higher area throughput compared to what massive multiple-input multiple-output (MIMO) can deliver through spatial multiplexing, while RISs can improve the propagation conditions over wireless channels but a passively reflecting RIS must be large to be effective. Active RIS with amplifiers can deal with this issue. In this paper, we study the distortion created by nonlinear amplifiers in both ELAAs and active RIS. We analytically obtain the angular directions and depth of the nonlinear distortion in both near- and far-field channels. The results are demonstrated numerically and we conclude that non-linearities can both create in-band and out-of-band distortion that is beamformed in entirely new directions and distances from the transmitter.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12725",
        "abstract url": "https://arxiv.org/abs/2401.12725",
        "title": "Two-View Topogram-Based Anatomy-Guided CT Reconstruction for Prospective Risk Minimization",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "GAN"
            ],
            [
                "CT",
                "organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To facilitate a prospective estimation of CT effective dose and risk minimization process, a prospective spatial dose estimation and the known anatomical structures are expected. To this end, a CT reconstruction method is required to reconstruct CT volumes from as few projections as possible, i.e. by using the topograms, with anatomical structures as correct as possible. In this work, an optimized CT reconstruction model based on a generative adversarial network (GAN) is proposed. The GAN is trained to reconstruct 3D volumes from an anterior-posterior and a lateral CT projection. To enhance anatomical structures, a pre-trained organ segmentation network and the 3D perceptual loss are applied during the training phase, so that the model can then generate both organ-enhanced CT volume and the organ segmentation mask. The proposed method can reconstruct CT volumes with PSNR of 26.49, RMSE of 196.17, and SSIM of 0.64, compared to 26.21, 201.55 and 0.63 using the baseline method. In terms of the anatomical structure, the proposed method effectively enhances the organ shape and boundary and allows for a straight-forward identification of the relevant anatomical structures. We note that conventional reconstruction metrics fail to indicate the enhancement of anatomical structures. In addition to such metrics, the evaluation is expanded with assessing the organ segmentation performance. The average organ dice of the proposed method is 0.71 compared with 0.63 in baseline model, indicating the enhancement of anatomical structures.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12890",
        "abstract url": "https://arxiv.org/abs/2401.12890",
        "title": "An Efficient Algorithm for Spatial-Spectral Partial Volume Compartment Mapping with Applications to Multicomponent Diffusion and Relaxation MRI",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "MRI"
            ]
        ],
        "abstract": "It has been previously shown that high-quality partial volume tissue compartment maps can be obtained by combining multiparametric contrast-encoded MRI data acquisition methods with spatially-regularized spectroscopic image estimation techniques. However, the advantages of this combined approach generally come at the expense of substantial computational complexity. In this work, we propose a new algorithm to solve this kind of estimation problem more efficiently. Our algorithm is based on the linearized alternating directions method of multipliers (LADMM), and relies on the introduction of novel quadratic penalty terms to substantially simplify the subproblems that must be solved at each iteration. We evaluate this algorithm on a variety of different estimation problems (diffusion-relaxation, relaxation-relaxation, relaxometry, and magnetic resonance fingerprinting), where we consistently observe substantial (roughly 5$\\times$-80$\\times$) speed improvements. We expect that this new faster algorithm will lower practical barriers to using spatial regularization and multiparametric contrast-encoded MRI data acquisition methods for partial volume compartment mapping.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12900",
        "abstract url": "https://arxiv.org/abs/2401.12900",
        "title": "PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar Animation with 3D Gaussian Splatting",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "Avatar"
            ],
            [
                "synthesis"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite much progress, achieving real-time high-fidelity head avatar animation is still difficult and existing methods have to trade-off between speed and quality. 3DMM based methods often fail to model non-facial structures such as eyeglasses and hairstyles, while neural implicit models suffer from deformation inflexibility and rendering inefficiency. Although 3D Gaussian has been demonstrated to possess promising capability for geometry representation and radiance field reconstruction, applying 3D Gaussian in head avatar creation remains a major challenge since it is difficult for 3D Gaussian to model the head shape variations caused by changing poses and expressions. In this paper, we introduce PSAvatar, a novel framework for animatable head avatar creation that utilizes discrete geometric primitive to create a parametric morphable shape model and employs 3D Gaussian for fine detail representation and high fidelity rendering. The parametric morphable shape model is a Point-based Morphable Shape Model (PMSM) which uses points instead of meshes for 3D representation to achieve enhanced representation flexibility. The PMSM first converts the FLAME mesh to points by sampling on the surfaces as well as off the meshes to enable the reconstruction of not only surface-like structures but also complex geometries such as eyeglasses and hairstyles. By aligning these points with the head shape in an analysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussian for fine detail representation and appearance modeling, thus enabling the creation of high-fidelity avatars. We show that PSAvatar can reconstruct high-fidelity head avatars of a variety of subjects and the avatars can be animated in real-time ($\\ge$ 25 fps at a resolution of 512 $\\times$ 512 ).",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "comment": "13 pages, 10 figures"
    },
    {
        "paper id": "2401.12977",
        "abstract url": "https://arxiv.org/abs/2401.12977",
        "title": "IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "synthesis"
            ],
            [
                "HDR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While numerous 3D reconstruction and novel-view synthesis methods allow for photorealistic rendering of a scene from multi-view images easily captured with consumer cameras, they bake illumination in their representations and fall short of supporting advanced applications like material editing, relighting, and virtual object insertion. The reconstruction of physically based material properties and lighting via inverse rendering promises to enable such applications. However, most inverse rendering techniques require high dynamic range (HDR) images as input, a setting that is inaccessible to most users. We present a method that recovers the physically based material properties and spatially-varying HDR lighting of a scene from multi-view, low-dynamic-range (LDR) images. We model the LDR image formation process in our inverse rendering pipeline and propose a novel optimization strategy for material, lighting, and a camera response model. We evaluate our approach with synthetic and real scenes compared to the state-of-the-art inverse rendering methods that take either LDR or HDR input. Our method outperforms existing methods taking LDR images as input, and allows for highly realistic relighting and object insertion.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project Website: https://irisldr.github.io/"
    },
    {
        "paper id": "2401.13103",
        "abstract url": "https://arxiv.org/abs/2401.13103",
        "title": "Self-organizing Nervous Systems for Robot Swarms",
        "rating": "-3",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "The system architecture controlling a group of robots is generally set before deployment and can be either centralized or decentralized. This dichotomy is highly constraining, because decentralized systems are typically fully self-organized and therefore difficult to design analytically, whereas centralized systems have single points of failure and limited scalability. To address this dichotomy, we present the Self-organizing Nervous System (SoNS), a novel robot swarm architecture based on self-organized hierarchy. The SoNS approach enables robots to autonomously establish, maintain, and reconfigure dynamic multi-level system architectures. For example, a robot swarm consisting of $n$ independent robots could transform into a single $n$-robot SoNS and then into several independent smaller SoNSs, where each SoNS uses a temporary and dynamic hierarchy. Leveraging the SoNS approach, we show that sensing, actuation, and decision-making can be coordinated in a locally centralized way, without sacrificing the benefits of scalability, flexibility, and fault tolerance, for which swarm robotics is usually studied. In several proof-of-concept robot missions -- including binary decision-making and search-and-rescue -- we demonstrate that the capabilities of the SoNS approach greatly advance the state of the art in swarm robotics. The missions are conducted with a real heterogeneous aerial-ground robot swarm, using a custom-developed quadrotor platform. We also demonstrate the scalability of the SoNS approach in swarms of up to 250 robots in a physics-based simulator, and demonstrate several types of system fault tolerance in simulation and reality.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "135 pages, 62 figues, and 14 embedded videos"
    },
    {
        "paper id": "2403.18774",
        "abstract url": "https://arxiv.org/abs/2403.18774",
        "title": "RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "attacks"
            ],
            [
                "Watermark"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Safeguarding intellectual property and preventing potential misuse of AI-generated images are of paramount importance. This paper introduces a robust and agile plug-and-play watermark detection framework, dubbed as RAW. As a departure from traditional encoder-decoder methods, which incorporate fixed binary codes as watermarks within latent representations, our approach introduces learnable watermarks directly into the original image data. Subsequently, we employ a classifier that is jointly trained with the watermark to detect the presence of the watermark. The proposed framework is compatible with various generative architectures and supports on-the-fly watermark injection after training. By incorporating state-of-the-art smoothing techniques, we show that the framework provides provable guarantees regarding the false positive rate for misclassifying a watermarked image, even in the presence of certain adversarial attacks targeting watermark removal. Experiments on a diverse range of images generated by state-of-the-art diffusion models reveal substantial performance enhancements compared to existing approaches. For instance, our method demonstrates a notable increase in AUROC, from 0.48 to 0.82, when compared to state-of-the-art approaches in detecting watermarked images under adversarial attacks, while maintaining image quality, as indicated by closely aligned FID and CLIP scores.",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12822",
        "abstract url": "https://arxiv.org/abs/2401.12822",
        "title": "Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms",
        "rating": "-3.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Phosphorus removal is vital in wastewater treatment to reduce reliance on limited resources. Deep reinforcement learning (DRL) is a machine learning technique that can optimize complex and nonlinear systems, including the processes in wastewater treatment plants, by learning control policies through trial and error. However, applying DRL to chemical and biological processes is challenging due to the need for accurate simulators. This study trained six models to identify the phosphorus removal process and used them to create a simulator for the DRL environment. Although the models achieved high accuracy (>97%), uncertainty and incorrect prediction behavior limited their performance as simulators over longer horizons. Compounding errors in the models' predictions were identified as one of the causes of this problem. This approach for improving process control involves creating simulation environments for DRL algorithms, using data from supervisory control and data acquisition (SCADA) systems with a sufficient historical horizon without complex system modeling or parameter estimation.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Journal Paper"
    },
    {
        "paper id": "2401.12824",
        "abstract url": "https://arxiv.org/abs/2401.12824",
        "title": "MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage",
        "rating": "-3.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or privacy individually but few probe into their interplays. In this paper, we propose a novel model-agnostic debiasing framework named MAPPING (\\underline{M}asking \\underline{A}nd \\underline{P}runing and Message-\\underline{P}assing train\\underline{ING}) for fair node classification, in which we adopt the distance covariance($dCov$)-based fairness constraints to simultaneously reduce feature and topology biases in arbitrary dimensions, and combine them with adversarial debiasing to confine the risks of attribute inference attacks. Experiments on real-world datasets with different GNN variants demonstrate the effectiveness and flexibility of MAPPING. Our results show that MAPPING can achieve better trade-offs between utility and fairness, and mitigate privacy risks of sensitive information leakage.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Finished May last year. Remember to submit all papers to arXiv early without compromising the principles of conferences"
    },
    {
        "paper id": "2401.12687",
        "abstract url": "https://arxiv.org/abs/2401.12687",
        "title": "DVL Calibration using Data-driven Methods",
        "rating": "-4.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "industrial"
            ],
            [
                "satellite",
                "seafloor"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Autonomous underwater vehicles (AUVs) are used in a wide range of underwater applications, ranging from seafloor mapping to industrial operations. While underwater, the AUV navigation solution commonly relies on the fusion between inertial sensors and Doppler velocity logs (DVL). To achieve accurate DVL measurements a calibration procedure should be conducted before the mission begins. Model-based calibration approaches include filtering approaches utilizing global navigation satellite system signals. In this paper, we propose an end-to-end deep-learning framework for the calibration procedure. Using stimulative data, we show that our proposed approach outperforms model-based approaches by 35% in accuracy and 80% in the required calibration time.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "5 pages , 3 figures , 5 tables"
    },
    {
        "paper id": "2401.12578",
        "abstract url": "https://arxiv.org/abs/2401.12578",
        "title": "ToDA: Target-oriented Diffusion Attacker against Recommendation System",
        "rating": "-5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "graph"
            ],
            [
                "attacks"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recommendation systems (RS) have become indispensable tools for web services to address information overload, thus enhancing user experiences and bolstering platforms' revenues. However, with their increasing ubiquity, security concerns have also emerged. As the public accessibility of RS, they are susceptible to specific malicious attacks where adversaries can manipulate user profiles, leading to biased recommendations. Recent research often integrates additional modules using generative models to craft these deceptive user profiles, ensuring them are imperceptible while causing the intended harm. Albeit their efficacy, these models face challenges of unstable training and the exploration-exploitation dilemma, which can lead to suboptimal results. In this paper, we pioneer to investigate the potential of diffusion models (DMs), for shilling attacks. Specifically, we propose a novel Target-oriented Diffusion Attack model (ToDA). It incorporates a pre-trained autoencoder that transforms user profiles into a high dimensional space, paired with a Latent Diffusion Attacker (LDA)-the core component of ToDA. LDA introduces noise into the profiles within this latent space, adeptly steering the approximation towards targeted items through cross-attention mechanisms. The global horizon, implemented by a bipartite graph, is involved in LDA and derived from the encoded user profile feature. This makes LDA possible to extend the generation outwards the on-processing user feature itself, and bridges the gap between diffused user features and target item features. Extensive experiments compared to several SOTA baselines demonstrate ToDA's effectiveness. Specific studies exploit the elaborative design of ToDA and underscore the potency of advanced generative models in such contexts.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13098",
        "abstract url": "https://arxiv.org/abs/2401.13098",
        "title": "Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge",
        "rating": "-5.5",
        "keywords": [
            [
                "biodiversity"
            ],
            [
                "forecast"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for assessing the invasion threat level given a pair of origin and destination. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% segmentation accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of invasive species risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing species invasion risks in a changing global landscape.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SI",
            "stat.AP"
        ],
        "comment": "26 pages, 7 figures, under review"
    },
    {
        "paper id": "2401.12852",
        "abstract url": "https://arxiv.org/abs/2401.12852",
        "title": "Control-Aware Trajectory Predictions for Communication-Efficient Drone Swarm Coordination in Cluttered Environments",
        "rating": "-6",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "UAV",
                "Drone"
            ]
        ],
        "abstract": "Swarms of Unmanned Aerial Vehicles (UAV) have demonstrated enormous potential in many industrial and commercial applications. However, before deploying UAVs in the real world, it is essential to ensure they can operate safely in complex environments, especially with limited communication capabilities. To address this challenge, we propose a control-aware learning-based trajectory prediction algorithm that can enable communication-efficient UAV swarm control in a cluttered environment. Specifically, our proposed algorithm can enable each UAV to predict the planned trajectories of its neighbors in scenarios with various levels of communication capabilities. The predicted planned trajectories will serve as input to a distributed model predictive control (DMPC) approach. The proposed algorithm combines (1) a trajectory compression and reconstruction model based on Variational Auto-Encoder, (2) a trajectory prediction model based on EvolveGCN, a graph convolutional network (GCN) that can handle dynamic graphs, and (3) a KKT-informed training approach that applies the Karush-Kuhn-Tucker (KKT) conditions in the training process to encode DMPC information into the trained neural network. We evaluate our proposed algorithm in a funnel-like environment. Results show that the proposed algorithm outperforms state-of-the-art benchmarks, providing close-to-optimal control performance and robustness to limited communication capabilities and measurement noises.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "15 pages, 15 figures, submitted to IEEE Transactions on Intelligent Vehicles"
    },
    {
        "paper id": "2401.12486",
        "abstract url": "https://arxiv.org/abs/2401.12486",
        "title": "Quaternary codes and their binary images",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, simplicial complexes are used in constructions of several infinite families of minimal and optimal linear codes by Hyun {\\em et al.} Building upon their research, in this paper more linear codes over the ring $\\mathbb{Z}_4$ are constructed by simplicial complexes. Specifically, the Lee weight distributions of the resulting quaternary codes are determined and two infinite families of four-Lee-weight quaternary codes are obtained. Compared to the databases of $\\mathbb Z_4$ codes by Aydin {\\em et al.}, at least nine new quaternary codes are found. Thanks to the special structure of the defining sets, we have the ability to determine whether the Gray images of certain obtained quaternary codes are linear or not. This allows us to obtain two infinite families of binary nonlinear codes and one infinite family of binary minimal linear codes. Furthermore, utilizing these minimal binary codes, some secret sharing schemes as a byproduct also are established.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2401.12499",
        "abstract url": "https://arxiv.org/abs/2401.12499",
        "title": "On the Fundamental Tradeoff of Joint Communication and Quickest Change Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we take the initiative in studying the fundamental tradeoff between communication and quickest change detection (QCD) under an integrated sensing and communication setting. We formally establish a joint communication and sensing problem for quickest change detection. Then, by utilizing constant subblock-composition codes and a modified QuSum detection rule, which we call subblock QuSum (SQS), we provide an inner bound on the fundamental tradeoff between communication rate and change point detection delay in the asymptotic regime of vanishing false alarm rate. We further provide a partial converse that matches our inner bound for a certain class of codes. This implies that the SQS detection strategy is asymptotically optimal for our codes as the false alarm rate constraint vanishes. We also present some canonical examples of the tradeoff region for a binary channel, a scalar Gaussian channel, and a MIMO Gaussian channel.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12521",
        "abstract url": "https://arxiv.org/abs/2401.12521",
        "title": "Exploring Virtual Reality through Ihde's Instrumental Realism",
        "rating": "-10",
        "keywords": [],
        "abstract": "Based on Ihde's theory, this paper explores the relationship between virtual reality (VR) as an instrument and phenomenology. It reviews the \"technological revolution\" spurred by the development of VR technology and discusses how VR has been used to study subjective experience, explore perception and embodiment, enhance empathy and perspective, and investigate altered states of consciousness. The paper emphasizes the role of VR as an instrumental technology, particularly its ability to expand human perception and cognition. Reflecting on this in conjunction with the work of Husserl and Ihde, among others, it revisits the potential of VR to provide new avenues for scientific inquiry and experience and to transform our understanding of the world through VR.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to iConference 2024 as a short paper"
    },
    {
        "paper id": "2401.12538",
        "abstract url": "https://arxiv.org/abs/2401.12538",
        "title": "Multi-Sources Information Fusion Learning for Multi-Points NLOS Localization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurate localization of mobile terminals is a pivotal aspect of integrated sensing and communication systems. Traditional fingerprint localization methods, which infer coordinates from channel information within pre-defined rectangular areas, often face challenges due to the heterogeneous distribution of fingerprints inherent in non-line-of-sight (NLOS) scenarios. To overcome this limitation, we have developed a novel multi-source information fusion learning framework referred to as the Autosync Multi-Domain NLOS Localization (AMDNLoc). Specifically, AMDNLoc employs a two-stage matched filter fused with a target tracking algorithm and iterative centroid-based clustering to automatically and irregularly segment NLOS regions, ensuring uniform fingerprint distribution within channel state information across frequency, power, and time-delay domains. Additionally, the framework utilizes a segment-specific linear classifier array, coupled with deep residual network-based feature extraction and fusion, to establish the correlation function between fingerprint features and coordinates within these regions. Simulation results demonstrate that AMDNLoc achieves an impressive accuracy of 1.46 meters on typical wireless artificial intelligence research datasets and offers interpretability, adaptability, and scalability in various scenarios.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12547",
        "abstract url": "https://arxiv.org/abs/2401.12547",
        "title": "Arrow's single peaked domains, richness, and domains for plurality and the Borda count",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we extend the study of Arrow's generalisation of Black's single-peaked domain and connect this to domains where voting rules satisfy different versions of independence of irrelevant alternatives. First we report on a computational generation of all non-isomorphic Arrow's single-peaked domains on $n\\leq 9$ alternatives. Next, we introduce a quantitative measure of richness for domains, as the largest number $r$ such that every alternative is given every rank between 1 and $r$ by the orders in the domain. We investigate the richness of Arrow's single-peaked domains and prove that Black's single-peaked domain has the highest possible richness, but it is not the only domain which attains the maximum. After this we connect Arrow's single-peaked domains to the discussion by Dasgupta, Maskin and others of domains on which plurality and the Borda count satisfy different versions of Independence of Irrelevant alternatives (IIA). For Nash's version of IIA and plurality, it turns out the domains are exactly the duals of Arrow's single-peaked domains. As a consequence there can be at most two alternatives which are ranked first in any such domain. For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum domain size which is exponentially smaller than $2^{n-1}$, the size of Black's single-peaked domain.",
        "subjects": [
            "econ.TH",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12556",
        "abstract url": "https://arxiv.org/abs/2401.12556",
        "title": "Approximate solution of stochastic infinite horizon optimal control problems for constrained linear uncertain systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a Model Predictive Control (MPC) with a single-step prediction horizon to solve infinite horizon optimal control problems with the expected sum of convex stage costs for constrained linear uncertain systems. The proposed method relies on two techniques. First, we estimate the expected values of the convex costs using a computationally tractable approximation, achieved by sampling across the space of disturbances. Second, we implement a data-driven approach to approximate the optimal value function and its corresponding domain, through systematic exploration of the system's state space. These estimates are subsequently used as the terminal cost and terminal set within the proposed MPC. We prove recursive feasibility, robust constraint satisfaction, and convergence in probability to the target set. Furthermore, we prove that the estimated value function converges to the optimal value function in a local region. The effectiveness of the proposed MPC is illustrated with detailed numerical simulations and comparisons with a value iteration method and a Learning MPC that minimizes a certainty equivalent cost.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "Submitted to the IEEE Transactions on Automatic Control"
    },
    {
        "paper id": "2401.12562",
        "abstract url": "https://arxiv.org/abs/2401.12562",
        "title": "Learning the cost-to-go for mixed-integer nonlinear model predictive control",
        "rating": "-10",
        "keywords": [],
        "abstract": "Application of nonlinear model predictive control (NMPC) to problems with hybrid dynamical systems, disjoint constraints, or discrete controls often results in mixed-integer formulations with both continuous and discrete decision variables. However, solving mixed-integer nonlinear programming problems (MINLP) in real-time is challenging, which can be a limiting factor in many applications. To address the computational complexity of solving mixed integer nonlinear model predictive control problem in real-time, this paper proposes an approximate mixed integer NMPC formulation based on value function approximation. Leveraging Bellman's principle of optimality, the key idea here is to divide the prediction horizon into two parts, where the optimal value function of the latter part of the prediction horizon is approximated offline using expert demonstrations. Doing so allows us to solve the MINMPC problem with a considerably shorter prediction horizon online, thereby reducing the online computation cost. The paper uses an inverted pendulum example with discrete controls to illustrate this approach.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12574",
        "abstract url": "https://arxiv.org/abs/2401.12574",
        "title": "Backpropagation Through Agents",
        "rating": "-10",
        "keywords": [],
        "abstract": "A fundamental challenge in multi-agent reinforcement learning (MARL) is to learn the joint policy in an extremely large search space, which grows exponentially with the number of agents. Moreover, fully decentralized policy factorization significantly restricts the search space, which may lead to sub-optimal policies. In contrast, the auto-regressive joint policy can represent a much richer class of joint policies by factorizing the joint policy into the product of a series of conditional individual policies. While such factorization introduces the action dependency among agents explicitly in sequential execution, it does not take full advantage of the dependency during learning. In particular, the subsequent agents do not give the preceding agents feedback about their decisions. In this paper, we propose a new framework Back-Propagation Through Agents (BPTA) that directly accounts for both agents' own policy updates and the learning of their dependent counterparts. This is achieved by propagating the feedback through action chains. With the proposed framework, our Bidirectional Proximal Policy Optimisation (BPPO) outperforms the state-of-the-art methods. Extensive experiments on matrix games, StarCraftII v2, Multi-agent MuJoCo, and Google Research Football demonstrate the effectiveness of the proposed method.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12582",
        "abstract url": "https://arxiv.org/abs/2401.12582",
        "title": "Investigation of FlexAlgo for User-driven Path Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper examines the Flexible Algorithm (FlexAlgo) for its potential to enable user-driven path control in intra-domain Segment Routing (SR) enabled networks. FlexAlgo is a relatively new approach to intra-domain routing that allows multiple custom algorithms to coexist within a single domain. This capability has the potential to provide users with greater control over the paths their data takes through a network. The research includes a thorough investigation of the FlexAlgo approach, including an examination of its underlying techniques, as well as a practical implementation of a FlexAlgo-based solution. We depict performed experiments where we implemented FlexAlgo in three different scenarios. We also present how we developed an automated tool for users to control traffic steering using preferred metrics and constraints. The results of this investigation demonstrate the capabilities of FlexAlgo as a means of enabling user-driven path control and therefore increase security and trust of users towards the network.",
        "subjects": [
            "cs.NI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12586",
        "abstract url": "https://arxiv.org/abs/2401.12586",
        "title": "C2Ideas: Supporting Creative Interior Color Design Ideation with Large Language Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts; Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes; and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and interpretable reasoning. C2Ideas has undergone a series of indoor cases and user studies, demonstrating its effectiveness and high recognition of interactive functionality by designers.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "26 pages, 11 figures"
    },
    {
        "paper id": "2401.12618",
        "abstract url": "https://arxiv.org/abs/2401.12618",
        "title": "Computation of classical and $v$-adic $L$-series of $t$-motives",
        "rating": "-10",
        "keywords": [],
        "abstract": "We design an algorithm for computing the $L$-series associated to an Anderson $t$-motives, exhibiting quasilinear complexity with respect to the target precision. Based on experiments, we conjecture that the order of vanishing at $T=1$ of the $v$-adic $L$-series of a given Anderson $t$-motive with good reduction does not depend on the finite place $v$.",
        "subjects": [
            "cs.SC",
            "math.NT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12625",
        "abstract url": "https://arxiv.org/abs/2401.12625",
        "title": "Benders decomposition for congested partial set covering location with uncertain demand",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce a mixed integer quadratic formulation for the congested variant of the partial set covering location problem, which involves determining a subset of facility locations to open and efficiently allocating customers to these facilities to minimize the combined costs of facility opening and congestion while ensuring target coverage. To enhance the resilience of the solution against demand fluctuations, we address the case under uncertain customer demand using $\u0393$-robustness. We formulate the deterministic problem and its robust counterpart as mixed-integer quadratic problems. We investigate the effect of the protection level in adapted instances from the literature to provide critical insights into how sensitive the planning is to the protection level. Moreover, since the size of the robust counterpart grows with the number of customers, which could be significant in real-world contexts, we propose the use of Benders decomposition to effectively reduce the number of variables by projecting out of the master problem all the variables dependent on the number of customers. We illustrate how to incorporate our Benders approach within a mixed-integer second-order cone programming (MISOCP) solver, addressing explicitly all the ingredients that are instrumental for its success. We discuss single-tree and multi-tree approaches and introduce a perturbation technique to deal with the degeneracy of the Benders subproblem efficiently. Our tailored Benders approaches outperform the perspective reformulation solved using the state-of-the-art MISOCP solver Gurobi on adapted instances from the literature.",
        "subjects": [
            "math.OC",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12634",
        "abstract url": "https://arxiv.org/abs/2401.12634",
        "title": "Assisted Requirements Selection by Clustering",
        "rating": "-10",
        "keywords": [],
        "abstract": "Requirements selection is a decision-making process that enables project managers to focus on the deliverables that add most value to the project outcome. This task is performed to define which features or requirements will be developed in the next release. It is a complex multi-criteria decision process that has been focused by many research works because a balance between business profits and investment is needed. The spectrum of prioritization techniques spans from simple and qualitative to elaborated analytic prioritization approaches that fall into the category of optimization algorithms. This work studies the combination of the qualitative MoSCoW method and cluster analysis for requirements selection. The feasibility of our methodology has been tested on three case studies (with 20, 50 and 100 requirements). In each of them, the requirements have been clustered, then the clustering configurations found have been evaluated using internal validation measures for the compactness, connectivity and separability of the clusters. The experimental results show the validity of clustering strategies for the identification of the core set of requirements for the software product, being the number of categories proposed by MoSCoW a good starting point in requirements prioritization and negotiation.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12636",
        "abstract url": "https://arxiv.org/abs/2401.12636",
        "title": "Stability prediction of the software requirements specification",
        "rating": "-10",
        "keywords": [],
        "abstract": "Complex decision-making is a prominent aspect of Requirements Engineering. This work presents the Bayesian network Requisites that predicts whether the requirements specification documents have to be revised. We show how to validate Requisites by means of metrics obtained from a large complex software project. Besides, this Bayesian network has been integrated into a software tool by defining a communication interface inside a multilayer architecture to add this a new decision making functionality. It provides requirements engineers a way of exploring the software requirement specification by combining requirement metrics and the probability values estimated by the Bayesian network.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12639",
        "abstract url": "https://arxiv.org/abs/2401.12639",
        "title": "Efficient Matching with Memoization for Regexes with Look-around and Atomic Grouping (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "Regular expression (regex) matching is fundamental in many applications, especially in web services. However, matching by backtracking -- preferred by most real-world implementations for its practical performance and backward compatibility -- can suffer from so-called catastrophic backtracking, which makes the number of backtracking super-linear and leads to the well-known ReDoS vulnerability. Inspired by a recent algorithm by Davis et al. that runs in linear time for (non-extended) regexes, we study efficient backtracking matching for regexes with two common extensions, namely look-around and atomic grouping. We present linear-time backtracking matching algorithms for these extended regexes. Their efficiency relies on memoization, much like the one by Davis et al.; we also strive for smaller memoization tables by carefully trimming their range. Our experiments -- we used some real-world regexes with the aforementioned extensions -- confirm the performance advantage of our algorithms.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "To appear in ESOP 2024"
    },
    {
        "paper id": "2401.12641",
        "abstract url": "https://arxiv.org/abs/2401.12641",
        "title": "Sequential discontinuity and first-order problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We explore the low levels of the structure of the continuous Weihrauch degrees of first-order problems. In particular, we show that there exists a minimal discontinuous first-order degree, namely that of $\\accn$, without any determinacy assumptions. The same degree is also revealed as the least sequentially discontinuous one, i.e. the least degree with a representative whose restriction to some sequence converging to a limit point is still discontinuous. The study of games related to continuous Weihrauch reducibility constitutes an important ingredient in the proof of the main theorem. We present some initial additional results about the degrees of first-order problems that can be obtained using this approach.",
        "subjects": [
            "math.LO",
            "cs.LO",
            "math.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12643",
        "abstract url": "https://arxiv.org/abs/2401.12643",
        "title": "Gray-Box Fuzzing via Gradient Descent and Boolean Expression Coverage (Technical Report)",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a novel gray-box fuzzing algorithm monitoring executions of instructions converting numerical values to Boolean ones. An important class of such instructions evaluate predicates, e.g., *cmp in LLVM. That alone allows us to infer the input dependency (c.f. the taint analysis) during the fuzzing on-the-fly with reasonable accuracy, which in turn enables an effective use of the gradient descent on these instructions (to invert the result of their evaluation). Although the fuzzing attempts to maximize the coverage of the instructions, there is an interesting correlation with the standard branch coverage, which we are able to achieve indirectly. The evaluation on Test-Comp 2023 benchmarks shows that our approach, despite being a pure gray-box fuzzing, is able to compete with the leading tools in the competition, which combine fuzzing with other powerful techniques like model checking, symbolic execution, or abstract interpretation.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "37 pages"
    },
    {
        "paper id": "2401.12652",
        "abstract url": "https://arxiv.org/abs/2401.12652",
        "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL Dataset",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing the textual and numerical data from corporate 10K filings and associated binary bankruptcy labels. Furthermore, we develop and critically evaluate several classical and neural bankruptcy prediction models using this dataset. Our findings suggest that the information contained in each data modality is complementary for bankruptcy prediction. We also see that the binary bankruptcy prediction target does not enable our models to distinguish next year bankruptcy from an unhealthy financial situation resulting in bankruptcy in later years. Finally, we explore the use of LLMs in the context of our task. We show how GPT-based models can be used to extract meaningful summaries from the textual data but zero-shot bankruptcy prediction results are poor. All resources required to access and update the dataset or replicate our experiments are available on github.com/henriarnoUG/ECL.",
        "subjects": [
            "cs.CE",
            "q-fin.CP"
        ],
        "comment": "Presented at the 6th Workshop on Financial Technology and Natural Language Processing (FinNLP) @ IJCNLP-AACL 2023 in Bali, Indonesia"
    },
    {
        "paper id": "2401.12653",
        "abstract url": "https://arxiv.org/abs/2401.12653",
        "title": "Robust Popular Matchings",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study popularity for matchings under preferences. This solution concept captures matchings that do not lose against any other matching in a majority vote by the agents. A popular matching is said to be robust if it is popular among multiple instances. We present a polynomial-time algorithm for deciding whether there exists a robust popular matching if instances only differ with respect to the preferences of a single agent while obtaining NP-completeness if two instances differ only by a downward shift of one alternative by four agents. Moreover, we find a complexity dichotomy based on preference completeness for the case where instances differ by making some options unavailable.",
        "subjects": [
            "cs.DS",
            "cs.GT"
        ],
        "comment": "Appears in: Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)"
    },
    {
        "paper id": "2401.12698",
        "abstract url": "https://arxiv.org/abs/2401.12698",
        "title": "Genetic Algorithm for Multi-Objective Optimization of Container Allocation in Cloud Architecture",
        "rating": "-10",
        "keywords": [],
        "abstract": "The use of containers in cloud architectures has become widespread because of advantages such as limited overhead, easier and faster deployment and higher portability. Moreover, they are a suitable architectural solution for deployment of applications created using a microservices development pattern. Despite the large number of solutions and implementations, open issues have not been addressed in container automation and management. Container resource allocation influences system performance and resource consumption so it is a key factor for cloud providers. We propose a genetic algorithm approach, using the Non-dominated Sorting Genetic Algorithm-II (NSGA-II), to optimize container allocation and elasticity management due to the good results obtained with this algorithm in other resource management optimization problems in cloud architectures. The optimization has been focused on a tight use of the resources and a reduction of the network overhead and system failure rate. A model for cloud cluster, containers, microservices and four optimization objectives is presented. Experimental results have shown that our approach is a suitable solution to address the problem of container allocation and elasticity and it obtains better objectives values than the container management policies implemented in Kubernetes.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12699",
        "abstract url": "https://arxiv.org/abs/2401.12699",
        "title": "A lightweight decentralized service placement policy for performance optimization in fog computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "A decentralized optimization policy for service placement in fog computing is presented. The optimization is addressed to place most popular services as closer to the users as possible. The experimental validation is done in the iFogSim simulator and by comparing our algorithm with the simulator's built-in policy. The simulation is characterized by modeling a microservice-based application for different experiment sizes. Results showed that our decentralized algorithm places most popular services closer to users, improving network usage and service latency of the most requested applications, at the expense of a latency increment for the less requested services and a greater number of service migrations.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12707",
        "abstract url": "https://arxiv.org/abs/2401.12707",
        "title": "Localized Data-driven Consensus Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers a localized data-driven consensus problem for leader-follower multi-agent systems with unknown discrete-time agent dynamics, where each follower computes its local control gain using only their locally collected state and input data. Both noiseless and noisy data-driven consensus protocols are presented, which can handle the challenge of the heterogeneity in control gains caused by the localized data sampling and achieve leader-follower consensus. The design of these data-driven consensus protocols involves low-dimensional linear matrix inequalities. In addition, the results are extended to the case where only the leader's data are collected and exploited. The effectiveness of the proposed methods is illustrated via simulation examples.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12724",
        "abstract url": "https://arxiv.org/abs/2401.12724",
        "title": "A Multi-scale Yarn Appearance Model with Fiber Details",
        "rating": "-10",
        "keywords": [],
        "abstract": "Rendering realistic cloth has always been a challenge due to its intricate structure. Cloth is made up of fibers, plies, and yarns, and previous curved-based models, while detailed, were computationally expensive and inflexible for large cloth. To address this, we propose a simplified approach. We introduce a geometric aggregation technique that reduces ray-tracing computation by using fewer curves, focusing only on yarn curves. Our model generates ply and fiber shapes implicitly, compensating for the lack of explicit geometry with a novel shadowing component. We also present a shading model that simplifies light interactions among fibers by categorizing them into four components, accurately capturing specular and scattered light in both forward and backward directions. To render large cloth efficiently, we propose a multi-scale solution based on pixel coverage. Our yarn shading model outperforms previous methods, achieving rendering speeds 3-5 times faster with less memory in near-field views. Additionally, our multi-scale solution offers a 20% speed boost for distant cloth observation.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12739",
        "abstract url": "https://arxiv.org/abs/2401.12739",
        "title": "Decoding University Hierarchy and Prestige in China through Domestic Ph.D. Hiring Network",
        "rating": "-10",
        "keywords": [],
        "abstract": "The academic job market for fresh Ph.D. students to pursue postdoctoral and junior faculty positions plays a crucial role in shaping the future orientations, developments, and status of the global academic system. In this work, we focus on the domestic Ph.D. hiring network among universities in China by exploring the doctoral education and academic employment of nearly 28,000 scientists across all Ph.D.-granting Chinese universities over three decades. We employ the minimum violation rankings algorithm to decode the rankings for universities based on the Ph.D. hiring network, which offers a deep understanding of the structure and dynamics within the network. Our results uncover a consistent, highly structured hierarchy within this hiring network, indicating the imbalances wherein a limited number of universities serve as the main sources of fresh Ph.D. across diverse disciplines. Furthermore, over time, it has become increasingly challenging for Chinese Ph.D. graduates to secure positions at institutions more prestigious than their alma maters. This study quantitatively captures the evolving structure of talent circulation in the domestic environment, providing valuable insights to enhance the organization, diversity, and talent distribution in China's academic enterprise.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12744",
        "abstract url": "https://arxiv.org/abs/2401.12744",
        "title": "Monadic Intersection Types, Relationally (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "We extend intersection types to a computational $\u03bb$-calculus with algebraic operations \u00e0 la Plotkin and Power. We achieve this by considering monadic intersections, whereby computational effects appear not only in the operational semantics, but also in the type system. Since in the effectful setting termination is not anymore the only property of interest, we want to analyze the interactive behavior of typed programs with the environment. Indeed, our type system is able to characterize the natural notion of observation, both in the finite and in the infinitary setting, and for a wide class of effects, such as output, cost, pure and probabilistic nondeterminism, and combinations thereof. The main technical tool is a novel combination of syntactic techniques with abstract relational reasoning, which allows us to lift all the required notions, e.g. of typability and logical relation, to the monadic setting.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12747",
        "abstract url": "https://arxiv.org/abs/2401.12747",
        "title": "COOCK project Smart Port 2025 D3.1: \"To Twin Or Not To Twin\"",
        "rating": "-10",
        "keywords": [],
        "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improving and accelerating the operational efficiency of a harbour eco-system through the application of intelligent technologies\". It reports on the needs of companies for modelling and simulation and AI-based techniques, with twinning systems in particular. This document categorizes the purposes and Properties of Interest for the use of Digital Twins. It further illustrates some of the twinning usages, and touches on some of the potential architectural compositions for twins. This last topic will be further elaborated in a followup report.",
        "subjects": [
            "eess.SY",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12763",
        "abstract url": "https://arxiv.org/abs/2401.12763",
        "title": "The State-Dependent Channel with a Rate-Limited Cribbing Helper",
        "rating": "-10",
        "keywords": [],
        "abstract": "The capacity of a memoryless state-dependent channel is derived for a setting in which the encoder is provided with rate-limited assistance from a cribbing helper that observes the state sequence causally and the past channel inputs strictly-causally. Said cribbing may increase capacity but not to the level achievable by a message-cognizant helper.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2401.12815",
        "abstract url": "https://arxiv.org/abs/2401.12815",
        "title": "COREC: Concurrent Non-Blocking Single-Queue Receive Driver for Low Latency Networking",
        "rating": "-10",
        "keywords": [],
        "abstract": "Existing network stacks tackle performance and scalability aspects by relying on multiple receive queues. However, at software level, each queue is processed by a single thread, which prevents simultaneous work on the same queue and limits performance in terms of tail latency. To overcome this limitation, we introduce COREC, the first software implementation of a concurrent non-blocking single-queue receive driver. By sharing a single queue among multiple threads, workload distribution is improved, leading to a work-conserving policy for network stacks. On the technical side, instead of relying on traditional critical sections - which would sequentialize the operations by threads - COREC coordinates the threads that concurrently access the same receive queue in non-blocking manner via atomic machine instructions from the Read-Modify-Write (RMW) class. These instructions allow threads to access and update memory locations atomically, based on specific conditions, such as the matching of a target value selected by the thread. Also, they enable making any update globally visible in the memory hierarchy, bypassing interference on memory consistency caused by the CPU store buffers. Extensive evaluation results demonstrate that the possible additional reordering, which our approach may occasionally cause, is non-critical and has minimal impact on performance, even in the worst-case scenario of a single large TCP flow, with performance impairments accounting to at most 2-3 percent. Conversely, substantial latency gains are achieved when handling UDP traffic, real-world traffic mix, and multiple shorter TCP flows.",
        "subjects": [
            "cs.NI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12818",
        "abstract url": "https://arxiv.org/abs/2401.12818",
        "title": "Binomial Channel: On the Capacity-Achieving Distribution and Bounds on the Capacity",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work considers a binomial noise channel. The paper can be roughly divided into two parts. The first part is concerned with the properties of the capacity-achieving distribution. In particular, for the binomial channel, it is not known if the capacity-achieving distribution is unique since the output space is finite (i.e., supported on integers $0, \\ldots, n)$ and the input space is infinite (i.e., supported on the interval $[0,1]$), and there are multiple distributions that induce the same output distribution. This paper shows that the capacity-achieving distribution is unique by appealing to the total positivity property of the binomial kernel. In addition, we provide upper and lower bounds on the cardinality of the support of the capacity-achieving distribution. Specifically, an upper bound of order $ \\frac{n}{2}$ is shown, which improves on the previous upper bound of order $n$ due to Witsenhausen. Moreover, a lower bound of order $\\sqrt{n}$ is shown. Finally, additional information about the locations and probability values of the support points is established. The second part of the paper focuses on deriving upper and lower bounds on capacity. In particular, firm bounds are established for all $n$ that show that the capacity scales as $\\frac{1}{2} \\log(n)$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "15 pages, 1 figure. Extended version of a paper submitted to IEEE ISIT 2024"
    },
    {
        "paper id": "2401.12853",
        "abstract url": "https://arxiv.org/abs/2401.12853",
        "title": "Hyper-Realist Rendering: A Theoretical Framework",
        "rating": "-10",
        "keywords": [],
        "abstract": "This is the first paper in a series on hyper-realist rendering. In this paper, we introduce the concept of hyper-realist rendering and present a theoretical framework to obtain hyper-realist images. We are using the term Hyper-realism as an umbrella word that captures all types of visual artifacts that can evoke an impression of reality. The hyper-realist artifacts are visual representations that are not necessarily created by following logical and physical principles and can still be perceived as representations of reality. This idea stems from the principles of representational arts, which attain visually acceptable renderings of scenes without implementing strict physical laws of optics and materials. The objective of this work is to demonstrate that it is possible to obtain visually acceptable illusions of reality by employing such artistic approaches. With representational art methods, we can even obtain an alternate illusion of reality that looks more real even when it is not real. This paper demonstrates that it is common to create illusions of reality in visual arts with examples of paintings by representational artists. We propose an approach to obtain expressive local and global illuminations to obtain these stylistic illusions with a set of well-defined and formal methods.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2401.12901",
        "abstract url": "https://arxiv.org/abs/2401.12901",
        "title": "Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we study a cell-free multiple-input multiple-output network equipped with integrated sensing and communication (ISAC) access points (APs). The distributed APs are used to jointly serve the communication needs of user equipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve). To increase the system's robustness towards said Eve, we develop an ISAC waveform model that includes artificial noise (AN) aimed at degrading the Eve channel quality. The central processing unit receives the observations from each AP and calculates the optimal precoding and AN covariance matrices by solving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB) minimization problem. Simulation results highlight an underlying trade-off between sensing and communication performances: in particular, the UEs signal-to-noise and interference ratio and the maximum Eve's signal to noise ratio are directly proportional to the CRB. Furthermore, the optimal AN covariance matrix is rank-1 and has a peak in the eve's direction, leading to a surprising inverse-proportionality between the UEs-Eve distance and optimal-CRB magnitude.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "To appear at WCNC 2024. \\c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media"
    },
    {
        "paper id": "2401.12919",
        "abstract url": "https://arxiv.org/abs/2401.12919",
        "title": "Inertial Sensors for Human Motion Analysis: A Comprehensive Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Inertial motion analysis is having a growing interest during the last decades due to its advantages over classical optical systems. The technological solution based on inertial measurement units allows the measurement of movements in daily living environments, such as in everyday life, which is key for a realistic assessment and understanding of movements. This is why research in this field is still developing and different approaches are proposed. This presents a systematic review of the different proposals for inertial motion analysis found in the literature. The search strategy has been carried out on eight different platforms, including journal articles and conference proceedings, which are written in English and published until August 2022. The results are analyzed in terms of the publishers, the sensors used, the applications, the monitored units, the algorithms of use, the participants of the studies, and the validation systems employed. In addition, we delve deeply into the machine learning techniques proposed in recent years and in the approaches to reduce the estimation error. In this way, we show an overview of the research carried out in this field, going into more detail in recent years, and providing some research directions for future work",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.12942",
        "abstract url": "https://arxiv.org/abs/2401.12942",
        "title": "Nonlinear dynamics in neuromorphic photonic networks: physical simulation in Verilog-A",
        "rating": "-10",
        "keywords": [],
        "abstract": "Advances in silicon photonics technology have enabled the field of neuromorphic photonics, where analog neuron-like processing elements are implemented in silicon photonics technology. Accurate and scalable simulation tools for photonic integrated circuits are critical for designing neuromorphic photonic circuits. This is especially important when designing networks with recurrent connections, where the dynamics of the system may give rise to unstable and oscillatory solutions which need to be accurately modelled. These tools must simultaneously simulate the analog electronics and the multi-channel (wavelength-division-multiplexed) photonics contained in a photonic neuron to accurately predict on-chip behaviour. In this paper, we utilize a Verilog-A model of the photonic neural network to investigate the dynamics of recurrent integrated circuits. We begin by reviewing the theory of continuous-time recurrent neural networks as dynamical systems and the relation of these dynamics to important physical features of photonic neurons such as cascadability. We then present the neural dynamics of systems of one and two neurons in the simulated Verilog-A circuit, which are compared to the expected dynamics of the abstract CTRNN model. Due to the presence of parasitic circuit elements in the Verilog-A simulation, it is seen that there is a topological equivalence, but not an exact isomorphism, between the theoretical model and the simulated model. The implications of these discrepancies for the design of neuromorphic photonic circuits are discussed. Our findings pave the way for the practical implementation of large-scale silicon photonic recurrent neural networks.",
        "subjects": [
            "cs.ET",
            "physics.app-ph",
            "physics.optics"
        ],
        "comment": "17 pages, 9 figures. Submitted to Physical Review Applied"
    },
    {
        "paper id": "2401.12959",
        "abstract url": "https://arxiv.org/abs/2401.12959",
        "title": "Understanding Emojis :) in Useful Code Review Comments",
        "rating": "-10",
        "keywords": [],
        "abstract": "Emojis and emoticons serve as non-verbal cues and are increasingly prevalent across various platforms, including Modern Code Review. These cues often carry emotive or instructive weight for developers. Our study dives into the utility of Code Review comments (CR comments) by scrutinizing the sentiments and semantics conveyed by emojis within these comments. To assess the usefulness of CR comments, we augment traditional 'textual' features and pre-trained embeddings with 'emoji-specific' features and pre-trained embeddings. To fortify our inquiry, we expand an existing dataset with emoji annotations, guided by existing research on GitHub emoji usage, and re-evaluate the CR comments accordingly. Our models, which incorporate textual and emoji-based sentiment features and semantic understandings of emojis, substantially outperform baseline metrics. The often-overlooked emoji elements in CR comments emerge as key indicators of usefulness, suggesting that these symbols carry significant weight.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper has been accepted for inclusion in the Proceedings of the 3rd Intl. Workshop on NL-based Software Engineering co-located at 46th International Conference on Software Engineering (NLBSE@ICSE 2024)"
    },
    {
        "paper id": "2401.12962",
        "abstract url": "https://arxiv.org/abs/2401.12962",
        "title": "Minimizing the Age of Two Heterogeneous Sources With Packet Drops Via Cyclic Schedulers",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a communication setting where multiple sources share a single channel to provide status updates to a remote monitor, source transmissions need to be scheduled appropriately to maintain timely communication between each of the sources and the monitor. We consider age-agnostic scheduling policies which are advantageous due to their simplicity of implementation. Further, we focus on a special class of age-agnostic policies, called cyclic schedulers, where each source is scheduled based on a fixed cyclic pattern. We use weighted average age of information (AoI) to quantify the timeliness of communication. We develop a Markov chain formulation to compute the exact mean AoI for the case of two-source cyclic schedulers. Based on the obtained age expression, we develop an algorithm that generates near-optimal cyclic schedulers to minimize the weighted average AoI for two heterogeneous sources, in the presence of channel errors.",
        "subjects": [
            "cs.IT",
            "cs.NI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13014",
        "abstract url": "https://arxiv.org/abs/2401.13014",
        "title": "A Novel Policy Iteration Algorithm for Nonlinear Continuous-Time H$\\infty$ Control Problem",
        "rating": "-10",
        "keywords": [],
        "abstract": "H{\\infty} control of nonlinear continuous-time system depends on the solution of the Hamilton-Jacobi-Isaacs (HJI) equation, which has been proved impossible to obtain a closed-form solution due to the nonlinearity of HJI equation. In order to solve HJI equation, many iterative algorithms were proposed, and most of the algorithms were essentially Newton method when the fixed-point equation was constructed in a Banach space. Newton method is a local optimization method, it has small convergence region and needs the initial guess to be sufficiently close to the solution. Whereas damped Newton method enhances the robustness with respect to initial condition and has larger convergence region. In this paper, a novel reinforcement learning method which is named \u03b1-policy iteration (\u03b1-PI) is introduced for solving HJI equation. First, by constructing a damped Newton iteration operator equation, a generalized Bellman equation (GBE) is obtained. The GBE is an extension of bellman equation. And then, by iterating on the GBE, an on-policy \u03b1-PI reinforcement learning method without using knowledge regarding to the system internal dynamics is proposed. Third, based on the on-policy \u03b1-PI reinforcement learning method, we develop an off-policy \u03b1-PI reinforcement learning method without requiring any knowledge of the system dynamics. Finally, the neural-network based adaptive critic implementation schemes of on-policy and off-policy \u03b1-PI algorithms are derived respectively, and the batch least-squares method is used for calculating the weight parameters of neural networks. The effectiveness of the off-policy \u03b1-PI algorithm is verified through computer simulation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "25 pages, 10 figures. arXiv admin note: text overlap with arXiv:2401.12882"
    },
    {
        "paper id": "2401.13019",
        "abstract url": "https://arxiv.org/abs/2401.13019",
        "title": "White-box validation of quantitative product lines by statistical model checking and process mining",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a novel methodology for validating software product line (PL) models by integrating Statistical Model Checking (SMC) with Process Mining (PM). Our approach focuses on the feature-oriented language QFLan in the PL engineering domain, allowing modeling of PLs with rich cross-tree and quantitative constraints, as well as aspects of dynamic PLs like staged configurations. This richness leads to models with infinite state-space, requiring simulation-based analysis techniques like SMC. For instance, we illustrate with a running example involving infinite state space. SMC involves generating samples of system dynamics to estimate properties such as event probabilities or expected values. On the other hand, PM uses data-driven techniques on execution logs to identify and reason about the underlying execution process. In this paper, we propose, for the first time, applying PM techniques to SMC simulations' byproducts to enhance the utility of SMC analyses. Typically, when SMC results are unexpected, modelers must determine whether they stem from actual system characteristics or model bugs in a black-box manner. We improve on this by using PM to provide a white-box perspective on the observed system dynamics. Samples from SMC are fed into PM tools, producing a compact graphical representation of observed dynamics. The mined PM model is then transformed into a QFLan model, accessible to PL engineers. Using two well-known PL models, we demonstrate the effectiveness and scalability of our methodology in pinpointing issues and suggesting fixes. Additionally, we show its generality by applying it to the security domain.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Pre-print Special Issue on Managing Variability in Complex Software-Intensive Systems of the Journal of Systems and Software"
    },
    {
        "paper id": "2401.13053",
        "abstract url": "https://arxiv.org/abs/2401.13053",
        "title": "Data Exchange Markets via Utility Balancing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper explores the design of a balanced data-sharing marketplace for entities with heterogeneous datasets and machine learning models that they seek to refine using data from other agents. The goal of the marketplace is to encourage participation for data sharing in the presence of such heterogeneity. Our market design approach for data sharing focuses on interim utility balance, where participants contribute and receive equitable utility from refinement of their models. We present such a market model for which we study computational complexity, solution existence, and approximation algorithms for welfare maximization and core stability. We finally support our theoretical insights with simulations on a mean estimation task inspired by road traffic delay estimation.",
        "subjects": [
            "cs.GT",
            "cs.DS"
        ],
        "comment": "To appear in WWW 2024"
    },
    {
        "paper id": "2401.13066",
        "abstract url": "https://arxiv.org/abs/2401.13066",
        "title": "Predictability and Randomness",
        "rating": "-10",
        "keywords": [],
        "abstract": "Algorithmic theories of randomness can be related to theories of probabilistic sequence prediction through the notion of a predictor, defined as a function which supplies lower bounds on initial-segment probabilities of infinite sequences. An infinite binary sequence $z$ is called unpredictable iff its initial-segment \"redundancy\" $n+\\log p(z(n))$ remains sufficiently low relative to every effective predictor $p$. A predictor which maximizes the initial-segment redundancy of a sequence is called optimal for that sequence. It turns out that a sequence is random iff it is unpredictable. More generally, a sequence is random relative to an arbitrary computable distribution iff the distribution is itself an optimal predictor for the sequence. Here \"random\" can be taken in the sense of Martin-L\u00f6f by using weak criteria of effectiveness, or in the sense of Schnorr by using stronger criteria of effectiveness. Under the weaker criteria of effectiveness it is possible to construct a universal predictor which is optimal for all infinite sequences. This predictor assigns nonvanishing limit probabilities precisely to the recursive sequences. Under the stronger criteria of effectiveness it is possible to establish a law of large numbers for sequences random relative to a computable distribution, which may be useful as a criterion of \"rationality\" for methods of probabilistic prediction. A remarkable feature of effective predictors is the fact that they are expressible in the special form first proposed by Solomonoff. In this form sequence prediction reduces to assigning high probabilities to initial segments with short and/or numerous encodings. This fact provides the link between theories of randomness and Solomonoff's theory of prediction.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "30 pages + refs. A re-typeset University of Alberta Technical Report, no longer available as such"
    },
    {
        "paper id": "2401.13105",
        "abstract url": "https://arxiv.org/abs/2401.13105",
        "title": "Smart Grids: A Comprehensive Survey of Challenges, Industry Applications, and Future Trends",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the increased energy demands of the 21st century, there is a clear need for developing a more sustainable method of energy generation, distribution, and transmission. The popularity of Smart Grid continues to grow as it presents its benefits, including interconnectivity, improved efficiency, the ability to integrate renewable energy sources, and many more. However, it is not without its challenges. This survey aims to provide an introductory background of smart grids, detail some of the main aspects and current challenges, and review the most recent papers and proposed solutions. It will also highlight the current state of implementation of the smart grid by describing various prototypes, as well as various countries and continents implementation plans and projects.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Paper has been submitted for review to the journal Energy Reports (January 23, 2024). 58 pages, 7 figures, 7 tables"
    },
    {
        "paper id": "2401.13128",
        "abstract url": "https://arxiv.org/abs/2401.13128",
        "title": "Polynomial Lyapunov Functions and Invariant Sets from a New Hierarchy of Quadratic Lyapunov Functions for LTV Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a new class of quadratic functions based on a hierarchy of linear time-varying (LTV) dynamical systems. These quadratic functions in the higher order space can be also seen as a non-homogeneous polynomial Lyapunov functions for the original system, i.e the first system in the hierarchy. These non-homogeneous polynomials are used to obtain accurate outer approximation for the reachable set given the initial condition and less conservative bounds for the impulse response peak of linear, possibly time-varying systems. In addition, we pose an extension to the presented approach to construct invariant sets that are not necessarily Lyapunov functions. The introduced methods are based on elementary linear systems theory and offer very much flexibility in defining arbitrary polynomial Lyapunov functions and invariant sets for LTV systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13150",
        "abstract url": "https://arxiv.org/abs/2401.13150",
        "title": "Automated Programmatic Performance Analysis of Parallel Programs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Developing efficient parallel applications is critical to advancing scientific development but requires significant performance analysis and optimization. Performance analysis tools help developers manage the increasing complexity and scale of performance data, but often rely on the user to manually explore low-level data and are rigid in how the data can be manipulated. We propose a Python-based API, Chopper, which provides high-level and flexible performance analysis for both single and multiple executions of parallel applications. Chopper facilitates performance analysis and reduces developer effort by providing configurable high-level methods for common performance analysis tasks such as calculating load imbalance, hot paths, scalability bottlenecks, correlation between metrics and CCT nodes, and causes of performance variability within a robust and mature Python environment that provides fluid access to lower-level data manipulations. We demonstrate how Chopper allows developers to quickly and succinctly explore performance and identify issues across applications such as AMG, Laghos, LULESH, Quicksilver and Tortuga.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13154",
        "abstract url": "https://arxiv.org/abs/2401.13154",
        "title": "MATRYOSHKA: Non-Exclusive Memory Tiering via Transactional Page Migration",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the advent of byte-addressable memory devices, such as CXL memory, persistent memory, and storage-class memory, tiered memory systems have become a reality. Page migration is the de facto method within operating systems for managing tiered memory. It aims to bring hot data whenever possible into fast memory to optimize the performance of data accesses while using slow memory to accommodate data spilled from fast memory. While the existing research has demonstrated the effectiveness of various optimizations on page migration, it falls short of addressing a fundamental question: Is exclusive memory tiering, in which a page is either present in fast memory or slow memory, but not both simultaneously, the optimal strategy for tiered memory management? We demonstrate that page migration-based exclusive memory tiering suffers significant performance degradation when fast memory is under pressure. In this paper, we propose non-exclusive memory tiering, a page management strategy that retains a copy of pages recently promoted from slow memory to fast memory to mitigate memory thrashing. To enable non-exclusive memory tiering, we develop MATRYOSHKA, a new mechanism that features transactional page migration and page shadowing. MATRYOSHKA removes page migration off the program's critical path and makes migration asynchronous. Evaluations with microbenchmarks and realworld applications show that MATRYOSHKA achieves 6x performance improvement over the state-of-the-art transparent page placement (TPP) approach under memory pressure. We also compare MATRYOSHKA with a recently proposed sampling-based migration approach and demonstrate MATRYOSHKA's strengths and potential weaknesses in various scenarios. Through the evaluations, we discover a serious issue facing all tested approaches, unfortunately including MATRYOSHKA, and call for further research on tiered memory-aware memory allocation.",
        "subjects": [
            "cs.OS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13169",
        "abstract url": "https://arxiv.org/abs/2401.13169",
        "title": "ReposVul: A Repository-Level High-Quality Vulnerability Dataset",
        "rating": "-10",
        "keywords": [],
        "abstract": "Open-Source Software (OSS) vulnerabilities bring great challenges to the software security and pose potential risks to our society. Enormous efforts have been devoted into automated vulnerability detection, among which deep learning (DL)-based approaches have proven to be the most effective. However, the current labeled data present the following limitations: (1) Tangled Patches: Developers may submit code changes unrelated to vulnerability fixes within patches, leading to tangled patches. (2) Lacking Inter-procedural Vulnerabilities: The existing vulnerability datasets typically contain function-level and file-level vulnerabilities, ignoring the relations between functions, thus rendering the approaches unable to detect the inter-procedural vulnerabilities. (3) Outdated Patches: The existing datasets usually contain outdated patches, which may bias the model during training. To address the above limitations, in this paper, we propose an automated data collection framework and construct the first repository-level high-quality vulnerability dataset named ReposVul. The proposed framework mainly contains three modules: (1) A vulnerability untangling module, aiming at distinguishing vulnerability-fixing related code changes from tangled patches, in which the Large Language Models (LLMs) and static analysis tools are jointly employed. (2) A multi-granularity dependency extraction module, aiming at capturing the inter-procedural call relationships of vulnerabilities, in which we construct multiple-granularity information for each vulnerability patch, including repository-level, file-level, function-level, and line-level. (3) A trace-based filtering module, aiming at filtering the outdated patches, which leverages the file path trace-based filter and commit time trace-based filter to construct an up-to-date dataset.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": "Accepted by ICSE 2024 Industry Challenge Track"
    },
    {
        "paper id": "2401.13182",
        "abstract url": "https://arxiv.org/abs/2401.13182",
        "title": "A Market-Clearing-based Sensitivity Model for Locational Marginal and Average Carbon Emission",
        "rating": "-10",
        "keywords": [],
        "abstract": "This letter proposes a market-clearing-based locational marginal carbon emission (LMCE) metric to assess the marginal carbon emission effect of nodal load demand. Unlike the prevalent carbon emission flow (CEF) method that relies on a hypothetical power-flow tracking process, the proposed LMCE metric depends on a novel sensitivity analysis of market-clearing results, capable of revealing both energy-dependent and network-dependent impacts on emissions. Additionally, we introduce a locational average carbon emission (LACE) metric, derived from LMCE, to effectively measure the general emission effect. It offers insights into demand-side carbon emission effects, such as a negative LMCE and LACE indicating emission reduction even as load increases. It can also prevent excessive demand-side emission allocations. Overall, the proposed method provides a clear perspective for the ongoing decarbonization policies.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13190",
        "abstract url": "https://arxiv.org/abs/2401.13190",
        "title": "A Comparison Between Lie Group- and Lie Algebra- Based Potential Functions for Geometric Impedance Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a comparison analysis between geometric impedance controls (GICs) derived from two different potential functions on SE(3) for robotic manipulators is presented. The first potential function is defined on the Lie group, utilizing the Frobenius norm of the configuration error matrix. The second potential function is defined utilizing the Lie algebra, i.e., log-map of the configuration error. Using a differential geometric approach, the detailed derivation of the distance metric and potential function on SE(3) is introduced. The GIC laws are respectively derived from the two potential functions, followed by extensive comparison analyses. In the qualitative analysis, the properties of the error function and control laws are analyzed, while the performances of the controllers are quantitatively compared using numerical simulation.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "This paper is accepted to American Control Conference (ACC) 2024"
    },
    {
        "paper id": "2401.13196",
        "abstract url": "https://arxiv.org/abs/2401.13196",
        "title": "Stable numerics for finite-strain elasticity",
        "rating": "-10",
        "keywords": [],
        "abstract": "A backward stable numerical calculation of a function with condition number $\u03ba$ will have a relative accuracy of $\u03ba\u03b5_{\\text{machine}}$. Standard formulations and software implementations of finite-strain elastic materials models make use of the deformation gradient $\\boldsymbol F = I + \\partial \\boldsymbol u/\\partial \\boldsymbol X$ and Cauchy-Green tensors. These formulations are not numerically stable, leading to loss of several digits of accuracy when used in the small strain regime, and often precluding the use of single precision floating point arithmetic. We trace the source of this instability to specific points of numerical cancellation, interpretable as ill-conditioned steps. We show how to compute various strain measures in a stable way and how to transform common constitutive models to their stable representations, formulated in either initial or current configuration. The stable formulations all provide accuracy of order $\u03b5_{\\text{machine}}$. In many cases, the stable formulations have elegant representations in terms of appropriate strain measures and offer geometric intuition that is lacking in their standard representation. We show that algorithmic differentiation can stably compute stresses so long as the strain energy is expressed stably, and give principles for stable computation that can be applied to inelastic materials.",
        "subjects": [
            "math.NA",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.13202",
        "abstract url": "https://arxiv.org/abs/2401.13202",
        "title": "PAC Learnability for Reliable Communication over Discrete Memoryless Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "In practical communication systems, knowledge of channel models is often absent, and consequently, transceivers need be designed based on empirical data. In this work, we study data-driven approaches to reliably choosing decoding metrics and code rates that facilitate reliable communication over unknown discrete memoryless channels (DMCs). Our analysis is inspired by the PAC (probably approximately correct) learning theory and does not rely on any assumptions on the statistical characteristics of DMCs. We show that a naive plug-in algorithm for choosing decoding metrics is likely to fail for finite training sets. We propose an alternative algorithm called the virtual sample algorithm and establish a non-asymptotic lower bound on its performance. The virtual sample algorithm is then used as a building block for constructing a learning algorithm that chooses a decoding metric and a code rate using which a transmitter and a receiver can reliably communicate at a rate arbitrarily close to the channel mutual information. Therefore, we conclude that DMCs are PAC learnable.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "10 pages, 4 figures, accepted by 2024 IEEE International Symposium on Information Theory"
    },
    {
        "paper id": "2401.13222",
        "abstract url": "https://arxiv.org/abs/2401.13222",
        "title": "It's About Time: Incorporating Temporality in Retrieval Augmented Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "The web serves as a global repository of knowledge, used by billions of people to search for information. Ensuring that users receive the most relevant and up-to-date information, especially in the presence of multiple versions of web content from different time points remains a critical challenge for information retrieval. This challenge has recently been compounded by the increased use of question answering tools trained on Wikipedia or web content and powered by large language models (LLMs) which have been found to make up information (or hallucinate), and in addition have been shown to struggle with the temporal dimensions of information. Even Retriever Augmented Language Models (RALMs) which incorporate a document database to reduce LLM hallucination are unable to handle temporal queries correctly. This leads to instances where RALMs respond to queries such as \"Who won the Wimbledon Championship?\", by retrieving document passages related to Wimbledon but without the ability to differentiate between them based on how recent they are. In this paper, we propose and evaluate, TempRALM, a temporally-aware Retriever Augmented Language Model (RALM) with few-shot learning extensions, which takes into account both semantically and temporally relevant documents relative to a given query, rather than relying on semantic similarity alone. We show that our approach results in up to 74% improvement in performance over the baseline RALM model, without requiring model pre-training, recalculating or replacing the RALM document index, or adding other computationally intensive elements.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.14420",
        "abstract url": "https://arxiv.org/abs/2401.14420",
        "title": "A Novel Blockchain Based Information Management Framework for Web 3.0",
        "rating": "-10",
        "keywords": [],
        "abstract": "Web 3.0 is the third generation of the World Wide Web (WWW), concentrating on the critical concepts of decentralization, availability, and increasing client usability. Although Web 3.0 is undoubtedly an essential component of the future Internet, it currently faces critical challenges, including decentralized data collection and management. To overcome these challenges, blockchain has emerged as one of the core technologies for the future development of Web 3.0. In this paper, we propose a novel blockchain-based information management framework, namely Smart Blockchain-based Web, to manage information in Web 3.0 effectively, enhance the security and privacy of users data, bring additional profits, and incentivize users to contribute information to the websites. Particularly, SBW utilizes blockchain technology and smart contracts to manage the decentralized data collection process for Web 3.0 effectively. Moreover, in this framework, we develop an effective consensus mechanism based on Proof-of-Stake to reward the user's information contribution and conduct game theoretical analysis to analyze the users behavior in the considered system. Additionally, we conduct simulations to assess the performance of SBW and investigate the impact of critical parameters on information contribution. The findings confirm our theoretical analysis and demonstrate that our proposed consensus mechanism can incentivize the nodes and users to contribute more information to our systems.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    }
]