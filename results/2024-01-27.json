[
    {
        "paper id": "2401.15499",
        "abstract url": "https://arxiv.org/abs/2401.15499",
        "title": "Semantic Properties of cosine based bias scores for word embeddings",
        "rating": 2,
        "keywords": [
            [
                "social biases"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Plenty of works have brought social biases in language models to attention and proposed methods to detect such biases. As a result, the literature contains a great deal of different bias tests and scores, each introduced with the premise to uncover yet more biases that other scores fail to detect. What severely lacks in the literature, however, are comparative studies that analyse such bias scores and help researchers to understand the benefits or limitations of the existing methods. In this work, we aim to close this gap for cosine based bias scores. By building on a geometric definition of bias, we propose requirements for bias scores to be considered meaningful for quantifying biases. Furthermore, we formally analyze cosine based scores from the literature with regard to these requirements. We underline these findings with experiments to show that the bias scores' limitations have an impact in the application case.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2401.15476",
        "abstract url": "https://arxiv.org/abs/2401.15476",
        "title": "To Burst or Not to Burst: Generating and Quantifying Improbable Text",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Workshop",
                "EMNLP"
            ]
        ],
        "abstract": "While large language models (LLMs) are extremely capable at text generation, their outputs are still distinguishable from human-authored text. We explore this separation across many metrics over text, many sampling techniques, many types of text data, and across two popular LLMs, LLaMA and Vicuna. Along the way, we introduce a new metric, recoverability, to highlight differences between human and machine text; and we propose a new sampling technique, burst sampling, designed to close this gap. We find that LLaMA and Vicuna have distinct distributions under many of the metrics, and that this influences our results: Recoverability separates real from fake text better than any other metric when using LLaMA. When using Vicuna, burst sampling produces text which is distributionally closer to real text compared to other sampling techniques.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Originally published at the Generation, Evaluation & Metrics (GEM) Workshop at EMNLP 2023. We are awaiting the release of the proceedings which we will reference here"
    },
    {
        "paper id": "2401.15312",
        "abstract url": "https://arxiv.org/abs/2401.15312",
        "title": "How We Refute Claims: Automatic Fact-Checking through Flaw Identification and Explanation",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automated fact-checking is a crucial task in the governance of internet content. Although various studies utilize advanced models to tackle this issue, a significant gap persists in addressing complex real-world rumors and deceptive claims. To address this challenge, this paper explores the novel task of flaw-oriented fact-checking, including aspect generation and flaw identification. We also introduce RefuteClaim, a new framework designed specifically for this task. Given the absence of an existing dataset, we present FlawCheck, a dataset created by extracting and transforming insights from expert reviews into relevant aspects and identified flaws. The experimental results underscore the efficacy of RefuteClaim, particularly in classifying and elucidating false claims.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15316",
        "abstract url": "https://arxiv.org/abs/2401.15316",
        "title": "UNSEE: Unsupervised Non-contrastive Sentence Embeddings",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We present UNSEE: Unsupervised Non-Contrastive Sentence Embeddings, a novel approach that outperforms SimCSE in the Massive Text Embedding benchmark. Our exploration begins by addressing the challenge of representation collapse, a phenomenon observed when contrastive objectives in SimCSE are replaced with non-contrastive objectives. To counter this issue, we propose a straightforward solution known as the target network, effectively mitigating representation collapse. The introduction of the target network allows us to leverage non-contrastive objectives, maintaining training stability while achieving performance improvements comparable to contrastive objectives. Our method has achieved peak performance in non-contrastive sentence embeddings through meticulous fine-tuning and optimization. This comprehensive effort has yielded superior sentence representation models, showcasing the effectiveness of our approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EACL 2024"
    },
    {
        "paper id": "2401.15328",
        "abstract url": "https://arxiv.org/abs/2401.15328",
        "title": "Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have exhibited an array of reasoning capabilities but face challenges like error propagation and hallucination, particularly in specialised areas like finance, where data is heterogeneous, and precision is paramount. We explore the potential of language model augmentation with external tools to mitigate these limitations and offload certain reasoning steps to external tools that are more suited for the task, instead of solely depending on the LLM's inherent abilities. More concretely, using financial domain question-answering datasets, we apply supervised fine-tuning on a LLaMA-2 13B Chat model to act both as a 'task router' and 'task solver'. The 'task router' dynamically directs a question to either be answered internally by the LLM or externally via the right tool from the tool set. Our tool-equipped SFT model, Raven, demonstrates an improvement of 35.2% and 5.06% over the base model and SFT-only baselines, respectively, and is highly competitive with strong GPT-3.5 results. To the best of our knowledge, our work is the first that investigates tool augmentation of language models for the finance domain.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EACL2024; code, model and dataset are available at https://raven-lm.github.io"
    },
    {
        "paper id": "2401.15347",
        "abstract url": "https://arxiv.org/abs/2401.15347",
        "title": "A Comprehensive Survey of Compression Algorithms for Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "How can we compress language models without sacrificing accuracy? The number of compression algorithms for language models is rapidly growing to benefit from remarkable advances of recent language models without side effects due to the gigantic size of language models, such as increased carbon emissions and expensive maintenance fees. While numerous compression algorithms have shown remarkable progress in compressing language models, it ironically becomes challenging to capture emerging trends and identify the fundamental concepts underlying them due to the excessive number of algorithms. In this paper, we survey and summarize diverse compression algorithms including pruning, quantization, knowledge distillation, low-rank approximation, parameter sharing, and efficient architecture design. We not only summarize the overall trend of diverse compression algorithms but also select representative algorithms and provide in-depth analyses of them. We discuss the value of each category of compression algorithms, and the desired properties of low-cost compression algorithms which have a significant impact due to the emergence of large language models. Finally, we introduce promising future research topics based on our survey results.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15360",
        "abstract url": "https://arxiv.org/abs/2401.15360",
        "title": "Importance-Aware Data Augmentation for Document-Level Neural Machine Translation",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Document-level neural machine translation (DocNMT) aims to generate translations that are both coherent and cohesive, in contrast to its sentence-level counterpart. However, due to its longer input length and limited availability of training data, DocNMT often faces the challenge of data sparsity. To overcome this issue, we propose a novel Importance-Aware Data Augmentation (IADA) algorithm for DocNMT that augments the training data based on token importance information estimated by the norm of hidden states and training gradients. We conduct comprehensive experiments on three widely-used DocNMT benchmarks. Our empirical results show that our proposed IADA outperforms strong DocNMT baselines as well as several data augmentation approaches, with statistical significance on both sentence-level and document-level BLEU.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "13 pages, 4 figures, 7 tables, accepted by EACL2024 main conference"
    },
    {
        "paper id": "2401.15362",
        "abstract url": "https://arxiv.org/abs/2401.15362",
        "title": "Transformer-based Clipped Contrastive Quantization Learning for Unsupervised Image Retrieval",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised image retrieval aims to learn the important visual characteristics without any given level to retrieve the similar images for a given query image. The Convolutional Neural Network (CNN)-based approaches have been extensively exploited with self-supervised contrastive learning for image hashing. However, the existing approaches suffer due to lack of effective utilization of global features by CNNs and biased-ness created by false negative pairs in the contrastive learning. In this paper, we propose a TransClippedCLR model by encoding the global context of an image using Transformer having local context through patch based processing, by generating the hash codes through product quantization and by avoiding the potential false negative pairs through clipped contrastive learning. The proposed model is tested with superior performance for unsupervised image retrieval on benchmark datasets, including CIFAR10, NUS-Wide and Flickr25K, as compared to the recent state-of-the-art deep models. The results using the proposed clipped contrastive learning are greatly improved on all datasets as compared to same backbone network with vanilla contrastive learning.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15365",
        "abstract url": "https://arxiv.org/abs/2401.15365",
        "title": "An open dataset for oracle bone script recognition and decipherment",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Oracle Bone Script (OBS), one of the earliest known forms of ancient Chinese writing, holds invaluable insights into the humanities and geography of the Shang Dynasty, dating back 3,000 years. The immense historical and cultural significance of these writings cannot be overstated. However, the passage of time has obscured much of their meaning, presenting a significant challenge in deciphering these ancient texts. With the advent of Artificial Intelligence (AI), employing AI to assist in interpreting OBS has become a feasible option. Yet, progress in this area has been hindered by a lack of high-quality datasets. To address this issue, this paper details the creation of the HUST-OBS dataset. This dataset encompasses 77,064 images of 1,588 individual deciphered scripts and 62,989 images of 9,411 undeciphered characters, with a total of 140,053 images, compiled from diverse sources. Additionally, all images and labels have been reviewed and corrected by experts in oracle bone studies. The hope is that this dataset could inspire and assist future research in deciphering those unknown OBS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15371",
        "abstract url": "https://arxiv.org/abs/2401.15371",
        "title": "LegalDuet: Learning Effective Representations for Legal Judgment Prediction through a Dual-View Legal Clue Reasoning",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Most existing Legal Judgment Prediction (LJP) models focus on discovering the legal triggers in the criminal fact description. However, in real-world scenarios, a professional judge not only needs to assimilate the law case experience that thrives on past sentenced legal judgments but also depends on the professional legal grounded reasoning that learned from professional legal knowledge. In this paper, we propose a LegalDuet model, which pretrains language models to learn a tailored embedding space for making legal judgments. It proposes a dual-view legal clue reasoning mechanism, which derives from two reasoning chains of judges: 1) Law Case Reasoning, which makes legal judgments according to the judgment experiences learned from analogy/confusing legal cases; 2) Legal Ground Reasoning, which lies in matching the legal clues between criminal cases and legal decisions. Our experiments show that LegalDuet achieves state-of-the-art performance on the CAIL2018 dataset and outperforms baselines with about 4% improvements on average. Our dual-view reasoning based pretraining can capture critical legal clues to learn a tailored embedding space to distinguish criminal cases. It reduces LegalDuet's uncertainty during prediction and brings pretraining advances to the confusing/low frequent charges. All codes are available at https://github.com/NEUIR/LegalDuet.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "we will update this paper and revise this paper in the near future"
    },
    {
        "paper id": "2401.15385",
        "abstract url": "https://arxiv.org/abs/2401.15385",
        "title": "Towards Event Extraction from Speech with Contextual Clues",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "While text-based event extraction has been an active research area and has seen successful application in many domains, extracting semantic events from speech directly is an under-explored problem. In this paper, we introduce the Speech Event Extraction (SpeechEE) task and construct three synthetic training sets and one human-spoken test set. Compared to event extraction from text, SpeechEE poses greater challenges mainly due to complex speech signals that are continuous and have no word boundaries. Additionally, unlike perceptible sound events, semantic events are more subtle and require a deeper understanding. To tackle these challenges, we introduce a sequence-to-structure generation paradigm that can produce events from speech signals in an end-to-end manner, together with a conditioned generation method that utilizes speech recognition transcripts as the contextual clue. We further propose to represent events with a flat format to make outputs more natural language-like. Our experimental results show that our method brings significant improvements on all datasets, achieving a maximum F1 gain of 10.7%. The code and datasets are released on https://github.com/jodie-kang/SpeechEE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2401.15391",
        "abstract url": "https://arxiv.org/abs/2401.15391",
        "title": "MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-augmented generation (RAG) augments large language models (LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations and enhancing response quality, thereby facilitating the great adoption of LLMs in practice. However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence. Furthermore, to our knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries. In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a knowledge base, a large collection of multi-hop queries, their ground-truth answers, and the associated supporting evidence. We detail the procedure of building the dataset, utilizing an English news article dataset as the underlying RAG knowledge base. We demonstrate the benchmarking utility of MultiHop-RAG in two experiments. The first experiment compares different embedding models for retrieving evidence for multi-hop queries. In the second experiment, we examine the capabilities of various state-of-the-art LLMs, including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop queries given the evidence. Both experiments reveal that existing RAG methods perform unsatisfactorily in retrieving and answering multi-hop queries. We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption of LLMs in practice. The MultiHop-RAG and implemented RAG system is publicly available at https://github.com/yixuantt/MultiHop-RAG/.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Link: https://github.com/yixuantt/MultiHop-RAG/"
    },
    {
        "paper id": "2401.15393",
        "abstract url": "https://arxiv.org/abs/2401.15393",
        "title": "Semantics of Multiword Expressions in Transformer-Based Models: A Survey",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multiword expressions (MWEs) are composed of multiple words and exhibit variable degrees of compositionality. As such, their meanings are notoriously difficult to model, and it is unclear to what extent this issue affects transformer architectures. Addressing this gap, we provide the first in-depth survey of MWE processing with transformer models. We overall find that they capture MWE semantics inconsistently, as shown by reliance on surface patterns and memorized information. MWE meaning is also strongly localized, predominantly in early layers of the architecture. Representations benefit from specific linguistic properties, such as lower semantic idiosyncrasy and ambiguity of target expressions. Our findings overall question the ability of transformer models to robustly capture fine-grained semantics. Furthermore, we highlight the need for more directly comparable evaluation setups.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to TACL 2024. This is a pre-MIT Press publication version"
    },
    {
        "paper id": "2401.15400",
        "abstract url": "https://arxiv.org/abs/2401.15400",
        "title": "Indexing Portuguese NLP Resources with PT-Pump-Up",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The recent advances in natural language processing (NLP) are linked to training processes that require vast amounts of corpora. Access to this data is commonly not a trivial process due to resource dispersion and the need to maintain these infrastructures online and up-to-date. New developments in NLP are often compromised due to the scarcity of data or lack of a shared repository that works as an entry point to the community. This is especially true in low and mid-resource languages, such as Portuguese, which lack data and proper resource management infrastructures. In this work, we propose PT-Pump-Up, a set of tools that aim to reduce resource dispersion and improve the accessibility to Portuguese NLP resources. Our proposal is divided into four software components: a) a web platform to list the available resources; b) a client-side Python package to simplify the loading of Portuguese NLP resources; c) an administrative Python package to manage the platform and d) a public GitHub repository to foster future collaboration and contributions. All four components are accessible using: https://linktr.ee/pt_pump_up",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Demo Track, 3 pages"
    },
    {
        "paper id": "2401.15449",
        "abstract url": "https://arxiv.org/abs/2401.15449",
        "title": "Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We evaluate the ability of Large Language Models (LLMs) to discern and express their internal knowledge state, a key factor in countering factual hallucination and ensuring reliable application of LLMs. We observe a robust self-awareness of internal knowledge state in LLMs, evidenced by over 85% accuracy in knowledge probing. However, LLMs often fail to express their internal knowledge during generation, leading to factual hallucinations. We develop an automated hallucination annotation tool, Dreamcatcher, which merges knowledge probing and consistency checking methods to rank factual preference data. Using knowledge preference as reward, We propose a Reinforcement Learning from Knowledge Feedback (RLKF) training framework, leveraging reinforcement learning to enhance the factuality and honesty of LLMs. Our experiments across multiple models show that RLKF training effectively enhances the ability of models to utilize their internal knowledge state, boosting performance in a variety of knowledge-based and honesty-related tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15455",
        "abstract url": "https://arxiv.org/abs/2401.15455",
        "title": "New Foggy Object Detecting Model",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Object detection in reduced visibility has become a prominent research area. The existing techniques are not accurate enough in recognizing objects under such circumstances. This paper introduces a new foggy object detection method through a two-staged architecture of region identification from input images and detecting objects in such regions. The paper confirms notable improvements of the proposed method's accuracy and detection time over existing techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15463",
        "abstract url": "https://arxiv.org/abs/2401.15463",
        "title": "DataFrame QA: A Universal LLM Framework on DataFrame Question Answering Without Data Exposure",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces DataFrame question answering (QA), a novel task that utilizes large language models (LLMs) to generate Pandas queries for information retrieval and data analysis on dataframes, emphasizing safe and non-revealing data handling. Our method, which solely relies on dataframe column names, not only ensures data privacy but also significantly reduces the context window in the prompt, streamlining information processing and addressing major challenges in LLM-based data analysis. We propose DataFrame QA as a comprehensive framework that includes safe Pandas query generation and code execution. Various LLMs, notably GPT-4, are evaluated using the pass@1 metric on the renowned WikiSQL and our newly developed 'UCI-DataFrameQA', tailored for complex data analysis queries. Our findings indicate that GPT-4 achieves pass@1 rates of 86% on WikiSQL and 97% on UCI-DataFrameQA, underscoring its capability in securely retrieving and aggregating dataframe values and conducting sophisticated data analyses. This approach, deployable in a zero-shot manner without prior training or adjustments, proves to be highly adaptable and secure for diverse applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15471",
        "abstract url": "https://arxiv.org/abs/2401.15471",
        "title": "ConvoSense: Overcoming Monotonous Commonsense Inferences for Conversational AI",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Mastering commonsense understanding and reasoning is a pivotal skill essential for conducting engaging conversations. While there have been several attempts to create datasets that facilitate commonsense inferences in dialogue contexts, existing datasets tend to lack in-depth details, restate information already present in the conversation, and often fail to capture the multifaceted nature of commonsense reasoning. In response to these limitations, we compile a new synthetic dataset for commonsense reasoning in dialogue contexts using GPT, ConvoSense, that boasts greater contextual novelty, offers a higher volume of inferences per example, and substantially enriches the detail conveyed by the inferences. Our dataset contains over 500,000 inferences across 12,000 dialogues with 10 popular inference types, which empowers the training of generative commonsense models for dialogue that are superior in producing plausible inferences with high novelty when compared to models trained on the previous datasets. To the best of our knowledge, ConvoSense is the first of its kind to provide such a multitude of novel inferences at such a large scale.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "accepted to TACL 2024; final author's version of paper; pre-MIT Press publication version"
    },
    {
        "paper id": "2401.15496",
        "abstract url": "https://arxiv.org/abs/2401.15496",
        "title": "Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) like Llama, Baichuan and Bloom models show remarkable ability with instruction fine-tuning in many natural language tasks. Nevertheless, for the dialogue summarization task, which aims to generate summaries for different roles in dialogue, most of the state-of-the-art methods conduct on small models (e.g Bart and Bert). Existing methods try to add task specified optimization on small models like adding global-local centrality score to models. In this paper, we propose an instruction fine-tuning model: Baichuan2-Sum, for role-oriented diaglouge summarization. By setting different instructions for different roles, the model can learn from the dialogue interactions and output the expected summaries. Furthermore, we applied NEFTune technique to add suitable noise during training to improve the results. The experiments demonstrate that the proposed model achieves the new state-of-the-art results on two public dialogue summarization datasets: CSDS and SAMSUM. We release our model and related codes to facilitate future studies on dialogue summarization task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15498",
        "abstract url": "https://arxiv.org/abs/2401.15498",
        "title": "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates the potential benefits of language-specific fact-checking models, focusing on the case of Chinese. We first demonstrate the limitations of translation-based methods and multilingual large language models (e.g., GPT-4), highlighting the need for language-specific systems. We further propose a Chinese fact-checking system that can better retrieve evidence from a document by incorporating context information. To better analyze token-level biases in different systems, we construct an adversarial dataset based on the CHEF dataset, where each instance has large word overlap with the original one but holds the opposite veracity label. Experimental results on the CHEF dataset and our adversarial dataset show that our proposed method outperforms translation-based methods and multilingual LLMs and is more robust toward biases, while there is still large room for improvement, emphasizing the importance of language-specific fact-checking systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15532",
        "abstract url": "https://arxiv.org/abs/2401.15532",
        "title": "Byte Pair Encoding Is All You Need For Automatic Bengali Speech Recognition",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Byte pair encoding (BPE) emerges as an effective tokenization method for tackling the out-of-vocabulary (OOV) challenge in various natural language and speech processing tasks. Recent research highlights the dependency of BPE subword tokenization's efficacy on the morphological nature of the language, particularly in languages rich in inflectional morphology, where fewer BPE merges suffice for generating highly productive tokens. Motivated by this, our study empirically identifies the optimal number of BPE tokens for Bengali, a language known for its morphological complexity, thus enhancing out-of-distribution automatic speech recognition (ASR) performance. Experimental evaluation reveals that an excessively high number of BPE tokens can lead to overfitting, while approximately 500-1000 tokens result in superior OOV performance. Furthermore, we conduct a comparative analysis of BPE with character-based and unigram-based tokenization methods. By introducing BPE tokenization to Bengali ASR, we achieve a substantial reduction in the word error rate (WER) from 66.44% in our character-based baseline system to 63.80% on the LB-ASRTD eval set and from 46.34% to 42.80% on the SHRUTI eval set, both of which include out-of-distribution data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under-review"
    },
    {
        "paper id": "2401.15535",
        "abstract url": "https://arxiv.org/abs/2401.15535",
        "title": "Quantifying Stereotypes in Language",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "A stereotype is a generalized perception of a specific group of humans. It is often potentially encoded in human language, which is more common in texts on social issues. Previous works simply define a sentence as stereotypical and anti-stereotypical. However, the stereotype of a sentence may require fine-grained quantification. In this paper, to fill this gap, we quantify stereotypes in language by annotating a dataset. We use the pre-trained language models (PLMs) to learn this dataset to predict stereotypes of sentences. Then, we discuss stereotypes about common social issues such as hate speech, sexism, sentiments, and disadvantaged and advantaged groups. We demonstrate the connections and differences between stereotypes and common social issues, and all four studies validate the general findings of the current studies. In addition, our work suggests that fine-grained stereotype scores are a highly relevant and competitive dimension for research on social issues.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "15 pages, 9 figures"
    },
    {
        "paper id": "2401.15555",
        "abstract url": "https://arxiv.org/abs/2401.15555",
        "title": "Augment before You Try: Knowledge-Enhanced Table Question Answering via Table Expansion",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Table question answering is a popular task that assesses a model's ability to understand and interact with structured data. However, the given table often does not contain sufficient information for answering the question, necessitating the integration of external knowledge. Existing methods either convert both the table and external knowledge into text, which neglects the structured nature of the table; or they embed queries for external sources in the interaction with the table, which complicates the process. In this paper, we propose a simple yet effective method to integrate external information in a given table. Our method first constructs an augmenting table containing the missing information and then generates a SQL query over the two tables to answer the question. Experiments show that our method outperforms strong baselines on three table QA benchmarks. Our code is publicly available at https://github.com/UCSB-NLP-Chang/Augment_tableQA.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01726",
        "abstract url": "https://arxiv.org/abs/2402.01726",
        "title": "AI Does Not Alter Perceptions of Text Messages",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "For many people, anxiety, depression, and other social and mental factors can make composing text messages an active challenge. To remedy this problem, large language models (LLMs) may yet prove to be the perfect tool to assist users that would otherwise find texting difficult or stressful. However, despite rapid uptake in LLM usage, considerations for their assistive usage in text message composition have not been explored. A primary concern regarding LLM usage is that poor public sentiment regarding AI introduces the possibility that its usage may harm perceptions of AI-assisted text messages, making usage counter-productive. To (in)validate this possibility, we explore how the belief that a text message did or did not receive AI assistance in composition alters its perceived tone, clarity, and ability to convey intent. In this study, we survey the perceptions of 26 participants on 18 randomly labeled pre-composed text messages. In analyzing the participants' ratings of message tone, clarity, and ability to convey intent, we find that there is no statistically significant evidence that the belief that AI is utilized alters recipient perceptions. This provides hopeful evidence that LLM-based text message composition assistance can be implemented without the risk of counter-productive outcomes.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01728",
        "abstract url": "https://arxiv.org/abs/2402.01728",
        "title": "Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the rapidly evolving semiconductor industry, where research, design, verification, and manufacturing are intricately linked, the potential of Large Language Models to revolutionize hardware design and security verification is immense. The primary challenge, however, lies in the complexity of hardware specific issues that are not adequately addressed by the natural language or software code knowledge typically acquired during the pretraining stage. Additionally, the scarcity of datasets specific to the hardware domain poses a significant hurdle in developing a foundational model. Addressing these challenges, this paper introduces Hardware Phi 1.5B, an innovative large language model specifically tailored for the hardware domain of the semiconductor industry. We have developed a specialized, tiered dataset comprising small, medium, and large subsets and focused our efforts on pretraining using the medium dataset. This approach harnesses the compact yet efficient architecture of the Phi 1.5B model. The creation of this first pretrained, hardware domain specific large language model marks a significant advancement, offering improved performance in hardware design and verification tasks and illustrating a promising path forward for AI applications in the semiconductor sector.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2402.09437",
        "abstract url": "https://arxiv.org/abs/2402.09437",
        "title": "Managing Household Waste through Transfer Learning",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "As the world continues to face the challenges of climate change, it is crucial to consider the environmental impact of the technologies we use. In this study, we investigate the performance and computational carbon emissions of various transfer learning models for garbage classification. We examine the MobileNet, ResNet50, ResNet101, and EfficientNetV2S and EfficientNetV2M models. Our findings indicate that the EfficientNetV2 family achieves the highest accuracy, recall, f1-score, and IoU values. However, the EfficientNetV2M model requires more time and produces higher carbon emissions. ResNet50 outperforms ResNet110 in terms of accuracy, recall, f1-score, and IoU, but it has a larger carbon footprint. We conclude that EfficientNetV2S is the most sustainable and accurate model with 96.41% accuracy. Our research highlights the significance of considering the ecological impact of machine learning models in garbage classification.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 9 figures"
    },
    {
        "paper id": "2401.15480",
        "abstract url": "https://arxiv.org/abs/2401.15480",
        "title": "Social Interpretable Reinforcement Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) bears the promise of being an enabling technology for many applications. However, since most of the literature in the field is currently focused on opaque models, the use of RL in high-stakes scenarios, where interpretability is crucial, is still limited. Recently, some approaches to interpretable RL, e.g., based on Decision Trees, have been proposed, but one of the main limitations of these techniques is their training cost. To overcome this limitation, we propose a new population-based method, called Social Interpretable RL (SIRL), inspired by social learning principles, to improve learning efficiency. Our method mimics a social learning process, where each agent in a group learns to solve a given task based both on its own individual experience as well as the experience acquired together with its peers. Our approach is divided into two phases. In the \\emph{collaborative phase}, all the agents in the population interact with a shared instance of the environment, where each agent observes the state and independently proposes an action. Then, voting is performed to choose the action that will actually be performed in the environment. In the \\emph{individual phase}, each agent refines its individual performance by interacting with its own instance of the environment. This mechanism makes the agents experience a larger number of episodes while simultaneously reducing the computational cost of the process. Our results on six well-known benchmarks show that SIRL reaches state-of-the-art performance w.r.t. the alternative interpretable methods from the literature.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 6 figures, submitted to IJCAI 2024"
    },
    {
        "paper id": "2401.15482",
        "abstract url": "https://arxiv.org/abs/2401.15482",
        "title": "Unsupervised Solution Operator Learning for Mean-Field Games via Sampling-Invariant Parametrizations",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in deep learning has witnessed many innovative frameworks that solve high dimensional mean-field games (MFG) accurately and efficiently. These methods, however, are restricted to solving single-instance MFG and demands extensive computational time per instance, limiting practicality. To overcome this, we develop a novel framework to learn the MFG solution operator. Our model takes a MFG instances as input and output their solutions with one forward pass. To ensure the proposed parametrization is well-suited for operator learning, we introduce and prove the notion of sampling invariance for our model, establishing its convergence to a continuous operator in the sampling limit. Our method features two key advantages. First, it is discretization-free, making it particularly suitable for learning operators of high-dimensional MFGs. Secondly, it can be trained without the need for access to supervised labels, significantly reducing the computational overhead associated with creating training datasets in existing operator learning methods. We test our framework on synthetic and realistic datasets with varying complexity and dimensionality to substantiate its robustness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15487",
        "abstract url": "https://arxiv.org/abs/2401.15487",
        "title": "Artificial Intelligence: Arguments for Catastrophic Risk",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Recent progress in artificial intelligence (AI) has drawn attention to the technology's transformative potential, including what some see as its prospects for causing large-scale harm. We review two influential arguments purporting to show how AI could pose catastrophic risks. The first argument -- the Problem of Power-Seeking -- claims that, under certain assumptions, advanced AI systems are likely to engage in dangerous power-seeking behavior in pursuit of their goals. We review reasons for thinking that AI systems might seek power, that they might obtain it, that this could lead to catastrophe, and that we might build and deploy such systems anyway. The second argument claims that the development of human-level AI will unlock rapid further progress, culminating in AI systems far more capable than any human -- this is the Singularity Hypothesis. Power-seeking behavior on the part of such systems might be particularly dangerous. We discuss a variety of objections to both arguments and conclude by assessing the state of the debate.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2401.15497",
        "abstract url": "https://arxiv.org/abs/2401.15497",
        "title": "Foregrounding Artist Opinions: A Survey Study on Transparency, Ownership, and Fairness in AI Generative Art",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Generative Artificial Intelligence (AI) tools are used to create art-like outputs and aid in the creative process. While these tools have potential benefits for artists, they also have the potential to harm the art workforce and infringe upon artistic and intellectual property rights. Without explicit consent from artists, Generative AI creators scrape artists' digital work to train Generative AI models and produce art-like model outputs at scale. These outputs are now being used to compete with human artists in the marketplace as well as being used by some artists in their generative processes to create art. We surveyed 459 artists to investigate the tension between artists' opinions on Generative AI art's potential utility and harm. This study surveys artists' opinions on the utility and threat of Generative AI art models, fair practices in the disclosure of artistic works in AI art training models, ownership and rights of AI art derivatives, and fair compensation. We find that artists, by and large, think that model creators should be required to disclose in detail what art and images they use to train their AI models. We also find that artists' opinions vary by professional status and practice, demographics, whether they have purchased art, and familiarity with and use of Generative AI. We hope the results of this work will further more meaningful collaboration and alignment between the art community and Generative AI researchers and developers.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15500",
        "abstract url": "https://arxiv.org/abs/2401.15500",
        "title": "Data-Driven Estimation of the False Positive Rate of the Bayes Binary Classifier via Soft Labels",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Classification is a fundamental task in many applications on which data-driven methods have shown outstanding performances. However, it is challenging to determine whether such methods have achieved the optimal performance. This is mainly because the best achievable performance is typically unknown and hence, effectively estimating it is of prime importance. In this paper, we consider binary classification problems and we propose an estimator for the false positive rate (FPR) of the Bayes classifier, that is, the optimal classifier with respect to accuracy, from a given dataset. Our method utilizes soft labels, or real-valued labels, which are gaining significant traction thanks to their properties. We thoroughly examine various theoretical properties of our estimator, including its consistency, unbiasedness, rate of convergence, and variance. To enhance the versatility of our estimator beyond soft labels, we also consider noisy labels, which encompass binary labels. For noisy labels, we develop effective FPR estimators by leveraging a denoising technique and the Nadaraya-Watson estimator. Due to the symmetry of the problem, our results can be readily applied to estimate the false negative rate of the Bayes classifier.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15520",
        "abstract url": "https://arxiv.org/abs/2401.15520",
        "title": "Oracle-Efficient Hybrid Online Learning with Unknown Distribution",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of oracle-efficient hybrid online learning when the features are generated by an unknown i.i.d. process and the labels are generated adversarially. Assuming access to an (offline) ERM oracle, we show that there exists a computationally efficient online predictor that achieves a regret upper bounded by $\\tilde{O}(T^{\\frac{3}{4}})$ for a finite-VC class, and upper bounded by $\\tilde{O}(T^{\\frac{p+1}{p+2}})$ for a class with $\u03b1$ fat-shattering dimension $\u03b1^{-p}$. This provides the first known oracle-efficient sublinear regret bounds for hybrid online learning with an unknown feature generation process. In particular, it confirms a conjecture of Lazaric and Munos (JCSS 2012). We then extend our result to the scenario of shifting distributions with $K$ changes, yielding a regret of order $\\tilde{O}(T^{\\frac{4}{5}}K^{\\frac{1}{5}})$. Finally, we establish a regret of $\\tilde{O}((K^{\\frac{2}{3}}(\\log|\\mathcal{H}|)^{\\frac{1}{3}}+K)\\cdot T^{\\frac{4}{5}})$ for the contextual $K$-armed bandits with a finite policy set $\\mathcal{H}$, i.i.d. generated contexts from an unknown distribution, and adversarially generated costs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15530",
        "abstract url": "https://arxiv.org/abs/2401.15530",
        "title": "An Information-Theoretic Analysis of In-Context Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Previous theoretical results pertaining to meta-learning on sequences build on contrived assumptions and are somewhat convoluted. We introduce new information-theoretic tools that lead to an elegant and very general decomposition of error into three components: irreducible error, meta-learning error, and intra-task error. These tools unify analyses across many meta-learning challenges. To illustrate, we apply them to establish new results about in-context learning with transformers. Our theoretical results characterizes how error decays in both the number of training sequences and sequence lengths. Our results are very general; for example, they avoid contrived mixing time assumptions made by all prior results that establish decay of error with sequence length.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16439",
        "abstract url": "https://arxiv.org/abs/2401.16439",
        "title": "Distribution-Specific Auditing For Subgroup Fairness",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of auditing classifiers with the notion of statistical subgroup fairness. Kearns et al. (2018) has shown that the problem of auditing combinatorial subgroups fairness is as hard as agnostic learning. Essentially all work on remedying statistical measures of discrimination against subgroups assumes access to an oracle for this problem, despite the fact that no efficient algorithms are known for it. If we assume the data distribution is Gaussian, or even merely log-concave, then a recent line of work has discovered efficient agnostic learning algorithms for halfspaces. Unfortunately, the reduction of Kearns et al. was formulated in terms of weak, \"distribution-free\" learning, and thus did not establish a connection for families such as log-concave distributions. In this work, we give positive and negative results on auditing for Gaussian distributions: On the positive side, we present an alternative approach to leverage these advances in agnostic learning and thereby obtain the first polynomial-time approximation scheme (PTAS) for auditing nontrivial combinatorial subgroup fairness: we show how to audit statistical notions of fairness over homogeneous halfspace subgroups when the features are Gaussian. On the negative side, we find that under cryptographic assumptions, no polynomial-time algorithm can guarantee any nontrivial auditing, even under Gaussian feature distributions, for general halfspace subgroups.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16440",
        "abstract url": "https://arxiv.org/abs/2401.16440",
        "title": "Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has been considerable recent interest in scoring properties on the basis of eviction risk. The success of methods for eviction prediction is typically evaluated using different measures of predictive accuracy. However, the underlying goal of such prediction is to direct appropriate assistance to households that may be at greater risk so they remain stably housed. Thus, we must ask the question of how useful such predictions are in targeting outreach efforts - informing action. In this paper, we investigate this question using a novel dataset that matches information on properties, evictions, and owners. We perform an eviction prediction task to produce risk scores and then use these risk scores to plan targeted outreach policies. We show that the risk scores are, in fact, useful, enabling a theoretical team of caseworkers to reach more eviction-prone properties in the same amount of time, compared to outreach policies that are either neighborhood-based or focus on buildings with a recent history of evictions. We also discuss the importance of neighborhood and ownership features in both risk prediction and targeted outreach.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16441",
        "abstract url": "https://arxiv.org/abs/2401.16441",
        "title": "FaKnow: A Unified Library for Fake News Detection",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the past years, a large number of fake news detection algorithms based on deep learning have emerged. However, they are often developed under different frameworks, each mandating distinct utilization methodologies, consequently hindering reproducibility. Additionally, a substantial amount of redundancy characterizes the code development of such fake news detection models. To address these concerns, we propose FaKnow, a unified and comprehensive fake news detection algorithm library. It encompasses a variety of widely used fake news detection models, categorized as content-based and social context-based approaches. This library covers the full spectrum of the model training and evaluation process, effectively organizing the data, models, and training procedures within a unified framework. Furthermore, it furnishes a series of auxiliary functionalities and tools, including visualization, and logging. Our work contributes to the standardization and unification of fake news detection research, concurrently facilitating the endeavors of researchers in this field. The open-source code and documentation can be accessed at https://github.com/NPURG/FaKnow and https://faknow.readthedocs.io, respectively.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01727",
        "abstract url": "https://arxiv.org/abs/2402.01727",
        "title": "Prompting Diverse Ideas: Increasing AI Idea Variance",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Unlike routine tasks where consistency is prized, in creativity and innovation the goal is to create a diverse set of ideas. This paper delves into the burgeoning interest in employing Artificial Intelligence (AI) to enhance the productivity and quality of the idea generation process. While previous studies have found that the average quality of AI ideas is quite high, prior research also has pointed to the inability of AI-based brainstorming to create sufficient dispersion of ideas, which limits novelty and the quality of the overall best idea. Our research investigates methods to increase the dispersion in AI-generated ideas. Using GPT-4, we explore the effect of different prompting methods on Cosine Similarity, the number of unique ideas, and the speed with which the idea space gets exhausted. We do this in the domain of developing a new product development for college students, priced under $50. In this context, we find that (1) pools of ideas generated by GPT-4 with various plausible prompts are less diverse than ideas generated by groups of human subjects (2) the diversity of AI generated ideas can be substantially improved using prompt engineering (3) Chain-of-Thought (CoT) prompting leads to the highest diversity of ideas of all prompts we evaluated and was able to come close to what is achieved by groups of human subjects. It also was capable of generating the highest number of unique ideas of any prompt we studied.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15378",
        "abstract url": "https://arxiv.org/abs/2401.15378",
        "title": "A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM",
        "rating": 0,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Challenges exist in learning and understanding religions, such as the complexity and depth of religious doctrines and teachings. Chatbots as question-answering systems can help in solving these challenges. LLM chatbots use NLP techniques to establish connections between topics and accurately respond to complex questions. These capabilities make it perfect for enlightenment on religion as a question-answering chatbot. However, LLMs also tend to generate false information, known as hallucination. Also, the chatbots' responses can include content that insults personal religious beliefs, interfaith conflicts, and controversial or sensitive topics. It must avoid such cases without promoting hate speech or offending certain groups of people or their beliefs. This study uses a vector database-based Retrieval Augmented Generation (RAG) approach to enhance the accuracy and transparency of LLMs. Our question-answering system is called \"MufassirQAS\". We created a database consisting of several open-access books that include Turkish context. These books contain Turkish translations and interpretations of Islam. This database is utilized to answer religion-related questions and ensure our answers are trustworthy. The relevant part of the dataset, which LLM also uses, is presented along with the answer. We have put careful effort into creating system prompts that give instructions to prevent harmful, offensive, or disrespectful responses to respect people's values and provide reliable results. The system answers and shares additional information, such as the page number from the respective book and the articles referenced for obtaining the information. MufassirQAS and ChatGPT are also tested with sensitive questions. We got better performance with our system. Study and enhancements are still in progress. Results and future works are given.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15447",
        "abstract url": "https://arxiv.org/abs/2401.15447",
        "title": "Continuous Treatment Effect Estimation Using Gradient Interpolation and Kernel Smoothing",
        "rating": 0.0,
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "We address the Individualized continuous treatment effect (ICTE) estimation problem where we predict the effect of any continuous-valued treatment on an individual using observational data. The main challenge in this estimation task is the potential confounding of treatment assignment with an individual's covariates in the training data, whereas during inference ICTE requires prediction on independently sampled treatments. In contrast to prior work that relied on regularizers or unstable GAN training, we advocate the direct approach of augmenting training individuals with independently sampled treatments and inferred counterfactual outcomes. We infer counterfactual outcomes using a two-pronged strategy: a Gradient Interpolation for close-to-observed treatments, and a Gaussian Process based Kernel Smoothing which allows us to downweigh high variance inferences. We evaluate our method on five benchmarks and show that our method outperforms six state-of-the-art methods on the counterfactual estimation error. We analyze the superior performance of our method by showing that (1) our inferred counterfactual responses are more accurate, and (2) adding them to the training data reduces the distributional distance between the confounded training distribution and test distribution where treatment is independent of covariates. Our proposed method is model-agnostic and we show that it improves ICTE accuracy of several existing models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at AAAI 24"
    },
    {
        "paper id": "2401.15458",
        "abstract url": "https://arxiv.org/abs/2401.15458",
        "title": "A New Method for Vehicle Logo Recognition Based on Swin Transformer",
        "rating": 0,
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Intelligent Transportation Systems (ITS) utilize sensors, cameras, and big data analysis to monitor real-time traffic conditions, aiming to improve traffic efficiency and safety. Accurate vehicle recognition is crucial in this process, and Vehicle Logo Recognition (VLR) stands as a key method. VLR enables effective management and monitoring by distinguishing vehicles on the road. Convolutional Neural Networks (CNNs) have made impressive strides in VLR research. However, achieving higher performance demands significant time and computational resources for training. Recently, the rise of Transformer models has brought new opportunities to VLR. Swin Transformer, with its efficient computation and global feature modeling capabilities, outperforms CNNs under challenging conditions. In this paper, we implement real-time VLR using Swin Transformer and fine-tune it for optimal performance. Extensive experiments conducted on three public vehicle logo datasets (HFUT-VL1, XMU, CTGU-VLD) demonstrate impressive top accuracy results of 99.28%, 100%, and 99.17%, respectively. Additionally, the use of a transfer learning strategy enables our method to be on par with state-of-the-art VLR methods. These findings affirm the superiority of our approach over existing methods. Future research can explore and optimize the application of the Swin Transformer in other vehicle vision recognition tasks to drive advancements in ITS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15509",
        "abstract url": "https://arxiv.org/abs/2401.15509",
        "title": "Style-News: Incorporating Stylized News Generation and Adversarial Verification for Neural Fake News Detection",
        "rating": 0,
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the improvements in generative models, the issues of producing hallucinations in various domains (e.g., law, writing) have been brought to people's attention due to concerns about misinformation. In this paper, we focus on neural fake news, which refers to content generated by neural networks aiming to mimic the style of real news to deceive people. To prevent harmful disinformation spreading fallaciously from malicious social media (e.g., content farms), we propose a novel verification framework, Style-News, using publisher metadata to imply a publisher's template with the corresponding text types, political stance, and credibility. Based on threat modeling aspects, a style-aware neural news generator is introduced as an adversary for generating news content conditioning for a specific publisher, and style and source discriminators are trained to defend against this attack by identifying which publisher the style corresponds with, and discriminating whether the source of the given news is human-written or machine-generated. To evaluate the quality of the generated content, we integrate various dimensional metrics (language fluency, content preservation, and style adherence) and demonstrate that Style-News significantly outperforms the previous approaches by a margin of 0.35 for fluency, 15.24 for content, and 0.38 for style at most. Moreover, our discriminative model outperforms state-of-the-art baselines in terms of publisher prediction (up to 4.64%) and neural fake news detection (+6.94% $\\sim$ 31.72%).",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL 2024 Main Track"
    },
    {
        "paper id": "2401.15526",
        "abstract url": "https://arxiv.org/abs/2401.15526",
        "title": "Exploring the Transferability of a Foundation Model for Fundus Images: Application to Hypertensive Retinopathy",
        "rating": 0,
        "keywords": [
            [
                "vision-language"
            ],
            [
                "medical",
                "diagnosis",
                "retina"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Using deep learning models pre-trained on Imagenet is the traditional solution for medical image classification to deal with data scarcity. Nevertheless, relevant literature supports that this strategy may offer limited gains due to the high dissimilarity between domains. Currently, the paradigm of adapting domain-specialized foundation models is proving to be a promising alternative. However, how to perform such knowledge transfer, and the benefits and limitations it presents, are under study. The CGI-HRDC challenge for Hypertensive Retinopathy diagnosis on fundus images introduces an appealing opportunity to evaluate the transferability of a recently released vision-language foundation model of the retina, FLAIR. In this work, we explore the potential of using FLAIR features as starting point for fundus image classification, and we compare its performance with regard to Imagenet initialization on two popular transfer learning methods: Linear Probing (LP) and Fine-Tuning (FP). Our empirical observations suggest that, in any case, the use of the traditional strategy provides performance gains. In contrast, direct transferability from FLAIR model allows gains of 2.5%. When fine-tuning the whole network, the performance gap increases up to 4%. In this case, we show that avoiding feature deterioration via LP initialization of the classifier allows the best re-use of the rich pre-trained features. Although direct transferability using LP still offers limited performance, we believe that foundation models such as FLAIR will drive the evolution of deep-learning-based fundus image analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CGI 2023"
    },
    {
        "paper id": "2401.15563",
        "abstract url": "https://arxiv.org/abs/2401.15563",
        "title": "BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents BrepGen, a diffusion-based generative approach that directly outputs a Boundary representation (B-rep) Computer-Aided Design (CAD) model. BrepGen represents a B-rep model as a novel structured latent geometry in a hierarchical tree. With the root node representing a whole CAD solid, each element of a B-rep model (i.e., a face, an edge, or a vertex) progressively turns into a child-node from top to bottom. B-rep geometry information goes into the nodes as the global bounding box of each primitive along with a latent code describing the local geometric shape. The B-rep topology information is implicitly represented by node duplication. When two faces share an edge, the edge curve will appear twice in the tree, and a T-junction vertex with three incident edges appears six times in the tree with identical node features. Starting from the root and progressing to the leaf, BrepGen employs Transformer-based diffusion models to sequentially denoise node features while duplicated nodes are detected and merged, recovering the B-Rep topology information. Extensive experiments show that BrepGen sets a new milestone in CAD B-rep generation, surpassing existing methods on various benchmarks. Results on our newly collected furniture dataset further showcase its exceptional capability in generating complicated geometry. While previous methods were limited to generating simple prismatic shapes, BrepGen incorporates free-form and doubly-curved surfaces for the first time. Additional applications of BrepGen include CAD autocomplete and design interpolation. The code, pretrained models, and dataset will be released.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01725",
        "abstract url": "https://arxiv.org/abs/2402.01725",
        "title": "Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing Security in Large Language Models",
        "rating": 0,
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) have significantly enhanced capabilities in natural language processing and artificial intelligence. These models, including GPT-3.5 and LLaMA-2, have revolutionized text generation, translation, and question-answering tasks due to the transformative Transformer model. Despite their widespread use, LLMs present challenges such as ethical dilemmas when models are compelled to respond inappropriately, susceptibility to phishing attacks, and privacy violations. This paper addresses these challenges by introducing a multi-pronged approach that includes: 1) filtering sensitive vocabulary from user input to prevent unethical responses; 2) detecting role-playing to halt interactions that could lead to 'prison break' scenarios; 3) implementing custom rule engines to restrict the generation of prohibited content; and 4) extending these methodologies to various LLM derivatives like Multi-Model Large Language Models (MLLMs). Our approach not only fortifies models against unethical manipulations and privacy breaches but also maintains their high performance across tasks. We demonstrate state-of-the-art performance under various attack prompts, without compromising the model's core functionalities. Furthermore, the introduction of differentiated security levels empowers users to control their personal data disclosure. Our methods contribute to reducing social risks and conflicts arising from technological abuse, enhance data protection, and promote social equity. Collectively, this research provides a framework for balancing the efficiency of question-answering systems with user privacy and ethical standards, ensuring a safer user experience and fostering trust in AI technology.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15304",
        "abstract url": "https://arxiv.org/abs/2401.15304",
        "title": "Adaptive Least Mean Squares Graph Neural Networks and Online Graph Signal Estimation",
        "rating": -0.5,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The online prediction of multivariate signals, existing simultaneously in space and time, from noisy partial observations is a fundamental task in numerous applications. We propose an efficient Neural Network architecture for the online estimation of time-varying graph signals named the Adaptive Least Mean Squares Graph Neural Networks (LMS-GNN). LMS-GNN aims to capture the time variation and bridge the cross-space-time interactions under the condition that signals are corrupted by noise and missing values. The LMS-GNN is a combination of adaptive graph filters and Graph Neural Networks (GNN). At each time step, the forward propagation of LMS-GNN is similar to adaptive graph filters where the output is based on the error between the observation and the prediction similar to GNN. The filter coefficients are updated via backpropagation as in GNN. Experimenting on real-world temperature data reveals that our LMS-GNN achieves more accurate online predictions compared to graph-based methods like adaptive graph filters and graph convolutional neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15323",
        "abstract url": "https://arxiv.org/abs/2401.15323",
        "title": "Music Auto-Tagging with Robust Music Representation Learned via Domain Adversarial Training",
        "rating": -0.5,
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Music auto-tagging is crucial for enhancing music discovery and recommendation. Existing models in Music Information Retrieval (MIR) struggle with real-world noise such as environmental and speech sounds in multimedia content. This study proposes a method inspired by speech-related tasks to enhance music auto-tagging performance in noisy settings. The approach integrates Domain Adversarial Training (DAT) into the music domain, enabling robust music representations that withstand noise. Unlike previous research, this approach involves an additional pretraining phase for the domain classifier, to avoid performance degradation in the subsequent phase. Adding various synthesized noisy music data improves the model's generalization across different noise levels. The proposed architecture demonstrates enhanced performance in music auto-tagging by effectively utilizing unlabeled noisy music data. Additional experiments with supplementary unlabeled data further improves the model's performance, underscoring its robust generalization capabilities and broad applicability.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "5 pages, 3 figures, accepted to ICASSP 2024"
    },
    {
        "paper id": "2401.15443",
        "abstract url": "https://arxiv.org/abs/2401.15443",
        "title": "DiffuserLite: Towards Real-time Diffusion Planning",
        "rating": -0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Diffusion planning has been recognized as an effective decision-making paradigm in various domains. The capability of conditionally generating high-quality long-horizon trajectories makes it a promising research direction. However, existing diffusion planning methods suffer from low decision-making frequencies due to the expensive iterative sampling cost. To address this issue, we introduce DiffuserLite, a super fast and lightweight diffusion planning framework. DiffuserLite employs a planning refinement process (PRP) to generate coarse-to-fine-grained trajectories, significantly reducing the modeling of redundant information and leading to notable increases in decision-making frequency. Our experimental results demonstrate that DiffuserLite achieves a decision-making frequency of $122$Hz ($112.7$x faster than previous mainstream frameworks) and reaches state-of-the-art performance on D4RL benchmarks. In addition, our neat DiffuserLite framework can serve as a flexible plugin to enhance decision frequency in other diffusion planning algorithms, providing a structural design reference for future works. More details and visualizations are available at https://diffuserlite.github.io/.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15444",
        "abstract url": "https://arxiv.org/abs/2401.15444",
        "title": "Towards Causal Classification: A Comprehensive Study on Graph Neural Networks",
        "rating": -0.5,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The exploration of Graph Neural Networks (GNNs) for processing graph-structured data has expanded, particularly their potential for causal analysis due to their universal approximation capabilities. Anticipated to significantly enhance common graph-based tasks such as classification and prediction, the development of a causally enhanced GNN framework is yet to be thoroughly investigated. Addressing this shortfall, our study delves into nine benchmark graph classification models, testing their strength and versatility across seven datasets spanning three varied domains to discern the impact of causality on the predictive prowess of GNNs. This research offers a detailed assessment of these models, shedding light on their efficiency, and flexibility in different data environments, and highlighting areas needing advancement. Our findings are instrumental in furthering the understanding and practical application of GNNs in diverse datacentric fields",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15543",
        "abstract url": "https://arxiv.org/abs/2401.15543",
        "title": "Anomaly Detection of Particle Orbit in Accelerator using LSTM Deep Learning Technology",
        "rating": -0.5,
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A stable, reliable, and controllable orbit lock system is crucial to an electron (or ion) accelerator because the beam orbit and beam energy instability strongly affect the quality of the beam delivered to experimental halls. Currently, when the orbit lock system fails operators must manually intervene. This paper develops a Machine Learning based fault detection methodology to identify orbit lock anomalies and notify accelerator operations staff of the off-normal behavior. Our method is unsupervised, so it does not require labeled data. It uses Long-Short Memory Networks (LSTM) Auto Encoder to capture normal patterns and predict future values of monitoring sensors in the orbit lock system. Anomalies are detected when the prediction error exceeds a threshold. We conducted experiments using monitoring data from Jefferson Lab's Continuous Electron Beam Accelerator Facility (CEBAF). The results are promising: the percentage of real anomalies identified by our solution is 68.6%-89.3% using monitoring data of a single component in the orbit lock control system. The accuracy can be as high as 82%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2401.15307",
        "abstract url": "https://arxiv.org/abs/2401.15307",
        "title": "ParaTransCNN: Parallelized TransCNN Encoder for Medical Image Segmentation",
        "rating": -1,
        "keywords": [
            [
                "Medical",
                "cardiac",
                "organ"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The convolutional neural network-based methods have become more and more popular for medical image segmentation due to their outstanding performance. However, they struggle with capturing long-range dependencies, which are essential for accurately modeling global contextual correlations. Thanks to the ability to model long-range dependencies by expanding the receptive field, the transformer-based methods have gained prominence. Inspired by this, we propose an advanced 2D feature extraction method by combining the convolutional neural network and Transformer architectures. More specifically, we introduce a parallelized encoder structure, where one branch uses ResNet to extract local information from images, while the other branch uses Transformer to extract global information. Furthermore, we integrate pyramid structures into the Transformer to extract global information at varying resolutions, especially in intensive prediction tasks. To efficiently utilize the different information in the parallelized encoder at the decoder stage, we use a channel attention module to merge the features of the encoder and propagate them through skip connections and bottlenecks. Intensive numerical experiments are performed on both aortic vessel tree, cardiac, and multi-organ datasets. By comparing with state-of-the-art medical image segmentation methods, our method is shown with better segmentation accuracy, especially on small organs. The code is publicly available on https://github.com/HongkunSun/ParaTransCNN.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15315",
        "abstract url": "https://arxiv.org/abs/2401.15315",
        "title": "Learning Online Belief Prediction for Efficient POMDP Planning in Autonomous Driving",
        "rating": -1,
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ]
        ],
        "abstract": "Effective decision-making in autonomous driving relies on accurate inference of other traffic agents' future behaviors. To achieve this, we propose an online learning-based behavior prediction model and an efficient planner for Partially Observable Markov Decision Processes (POMDPs). We develop a learning-based prediction model, enhanced with a recurrent neural memory network, to dynamically update latent belief states and infer the intentions of other agents. The model can also integrate the ego vehicle's intentions to reflect closed-loop interactions among agents, and it learns from both offline data and online interactions. For planning, we employ an option-based Monte-Carlo Tree Search (MCTS) planner, which reduces computational complexity by searching over action sequences. Inside the MCTS planner, we use predicted long-term multi-modal trajectories to approximate future updates, which eliminates iterative belief updating and improves the running efficiency. Our approach also incorporates deep Q-learning (DQN) as a search prior, which significantly improves the performance of the MCTS planner. Experimental results from simulated environments validate the effectiveness of our proposed method. The online belief update model can significantly enhance the accuracy and temporal consistency of predictions, leading to improved decision-making performance. Employing DQN as a search prior in the MCTS planner considerably boosts its performance and outperforms an imitation learning-based prior. Additionally, we show that the option-based MCTS substantially outperforms the vanilla method in terms of performance and efficiency.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15319",
        "abstract url": "https://arxiv.org/abs/2401.15319",
        "title": "You Only Look Bottom-Up for Monocular 3D Object Detection",
        "rating": -1,
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular 3D Object Detection is an essential task for autonomous driving. Meanwhile, accurate 3D object detection from pure images is very challenging due to the loss of depth information. Most existing image-based methods infer objects' location in 3D space based on their 2D sizes on the image plane, which usually ignores the intrinsic position clues from images, leading to unsatisfactory performances. Motivated by the fact that humans could leverage the bottom-up positional clues to locate objects in 3D space from a single image, in this paper, we explore the position modeling from the image feature column and propose a new method named You Only Look Bottum-Up (YOLOBU). Specifically, our YOLOBU leverages Column-based Cross Attention to determine how much a pixel contributes to pixels above it. Next, the Row-based Reverse Cumulative Sum (RRCS) is introduced to build the connections of pixels in the bottom-up direction. Our YOLOBU fully explores the position clues for monocular 3D detection via building the relationship of pixels from the bottom-up way. Extensive experiments on the KITTI dataset demonstrate the effectiveness and superiority of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE Robotics and Automation Letters (RA-L)"
    },
    {
        "paper id": "2401.15335",
        "abstract url": "https://arxiv.org/abs/2401.15335",
        "title": "L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks",
        "rating": -1,
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "In the rapidly evolving field of machine learning, adversarial attacks present a significant challenge to model robustness and security. Decision-based attacks, which only require feedback on the decision of a model rather than detailed probabilities or scores, are particularly insidious and difficult to defend against. This work introduces L-AutoDA (Large Language Model-based Automated Decision-based Adversarial Attacks), a novel approach leveraging the generative capabilities of Large Language Models (LLMs) to automate the design of these attacks. By iteratively interacting with LLMs in an evolutionary framework, L-AutoDA automatically designs competitive attack algorithms efficiently without much human effort. We demonstrate the efficacy of L-AutoDA on CIFAR-10 dataset, showing significant improvements over baseline methods in both success rate and computational efficiency. Our findings underscore the potential of language models as tools for adversarial attack generation and highlight new avenues for the development of robust AI systems.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Under Review of IJCNN 2024"
    },
    {
        "paper id": "2401.15351",
        "abstract url": "https://arxiv.org/abs/2401.15351",
        "title": "A Survey on Neural Topic Models: Methods, Applications, and Challenges",
        "rating": -1,
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Topic models have been prevalent for decades to discover latent topics and infer topic proportions of documents in an unsupervised fashion. They have been widely used in various applications like text analysis and context recommendation. Recently, the rise of neural networks has facilitated the emergence of a new research field -- Neural Topic Models (NTMs). Different from conventional topic models, NTMs directly optimize parameters without requiring model-specific derivations. This endows NTMs with better scalability and flexibility, resulting in significant research attention and plentiful new methods and applications. In this paper, we present a comprehensive survey on neural topic models concerning methods, applications, and challenges. Specifically, we systematically organize current NTM methods according to their network structures and introduce the NTMs for various scenarios like short texts and cross-lingual documents. We also discuss a wide range of popular applications built on NTMs. Finally, we highlight the challenges confronted by NTMs to inspire future research.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to Artifcial Intelligence Review. See https://doi.org/10.1007/s10462-023-10661-7 and a paper list at https://github.com/BobXWu/Paper-Neural-Topic-Models"
    },
    {
        "paper id": "2401.15354",
        "abstract url": "https://arxiv.org/abs/2401.15354",
        "title": "DeepGI: An Automated Approach for Gastrointestinal Tract Segmentation in MRI Scans",
        "rating": -1,
        "keywords": [
            [
                "health",
                "MRI"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Gastrointestinal (GI) tract cancers pose a global health challenge, demanding precise radiotherapy planning for optimal treatment outcomes. This paper introduces a cutting-edge approach to automate the segmentation of GI tract regions in magnetic resonance imaging (MRI) scans. Leveraging advanced deep learning architectures, the proposed model integrates Inception-V4 for initial classification, UNet++ with a VGG19 encoder for 2.5D data, and Edge UNet for grayscale data segmentation. Meticulous data preprocessing, including innovative 2.5D processing, is employed to enhance adaptability, robustness, and accuracy. This work addresses the manual and time-consuming segmentation process in current radiotherapy planning, presenting a unified model that captures intricate anatomical details. The integration of diverse architectures, each specializing in unique aspects of the segmentation task, signifies a novel and comprehensive solution. This model emerges as an efficient and accurate tool for clinicians, marking a significant advancement in the field of GI tract image segmentation for radiotherapy planning.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15379",
        "abstract url": "https://arxiv.org/abs/2401.15379",
        "title": "Time-modulated phased array controlled with nonideal bipolar squared periodic sequences",
        "rating": -1,
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "Bipolar (+/-1) sequences with no zero state suit particularly well for safeguarding the switched feeding network efficiency when applied to time-modulated arrays (TMAs). During the zero state of a conventional time-modulating sequence, if a given array element is switched off, a certain amount of energy of the transmitted/received signal is wasted. We propose a novel single sideband time-modulated phased array (TMPA) architecture governed by realistic bipolar squared sequences in which the rise/fall time of the switches is considered. By using single-pole dual-throw switches and non-reconfigurable passive devices, the TMPA exploits, exclusively, the first positive harmonic pattern while exhibiting an excellent performance in terms of efficiency and control level of the undesired harmonics without using synthesis optimization algorithms (software simplicity).",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 5 figures, published in IEEE Antennas and Wireless Propagation Letters"
    },
    {
        "paper id": "2401.15380",
        "abstract url": "https://arxiv.org/abs/2401.15380",
        "title": "Open-RadVLAD: Fast and Robust Radar Place Recognition",
        "rating": -1,
        "keywords": [
            [
                "Radar",
                "vehicle"
            ]
        ],
        "abstract": "Radar place recognition often involves encoding a live scan as a vector and matching this vector to a database in order to recognise that the vehicle is in a location that it has visited before. Radar is inherently robust to lighting or weather conditions, but place recognition with this sensor is still affected by: (1) viewpoint variation, i.e. translation and rotation, (2) sensor artefacts or \"noises\". For 360-degree scanning radar, rotation is readily dealt with by in some way aggregating across azimuths. Also, we argue in this work that it is more critical to deal with the richness of representation and sensor noises than it is to deal with translational invariance - particularly in urban driving where vehicles predominantly follow the same lane when repeating a route. In our method, for computational efficiency, we use only the polar representation. For partial translation invariance and robustness to signal noise, we use only a one-dimensional Fourier Transform along radial returns. We also achieve rotational invariance and a very discriminative descriptor space by building a vector of locally aggregated descriptors. Our method is more comprehensively tested than all prior radar place recognition work - over an exhaustive combination of all 870 pairs of trajectories from 30 Oxford Radar RobotCar Dataset sequences (each approximately 10 km). Code and detailed results are provided at github.com/mttgdd/open-radvlad, as an open implementation and benchmark for future work in this area. We achieve a median of 91.52% in Recall@1, outstripping the 69.55% for the only other open implementation, RaPlace, and at a fraction of its computational cost (relying on fewer integral transforms e.g. Radon, Fourier, and inverse Fourier).",
        "subjects": [
            "cs.RO"
        ],
        "comment": "accepted at 2024 IEEE Radar Conference"
    },
    {
        "paper id": "2401.15386",
        "abstract url": "https://arxiv.org/abs/2401.15386",
        "title": "Time-modulated array beamforming with periodic stair-step pulses",
        "rating": -1,
        "keywords": [
            [
                "synthesizing"
            ]
        ],
        "abstract": "Time-modulated arrays (TMAs) are able to improve the side-lobe level of the radiation pattern at the fundamental mode but cannot steer the beam at such a mode towards a given direction. Beam-steering is possible in a TMA, but only at the harmonic patterns and at the expense of a severe TMA efficiency reduction. In this work we propose a TMA approach that simultaneously performs both features over the same beam by using two sets of switches: (1) single-pole four-throw switches to generate periodic stair-step pulses suitable for efficiently synthesizing a uniform steerable beam over the first positive harmonic, and (2) single-pole single-throw switches to reconfigure the side-lobe level of the previous beam. Performance, small size, cost-effectiveness, and performance invariability with the carrier frequency are features that make this TMA approach a competitive solution for analog beamforming. Accordingly, the structure is an attractive proposal for the design of multibeam transceivers.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages, 9 figures, published in Signal Processing"
    },
    {
        "paper id": "2401.15394",
        "abstract url": "https://arxiv.org/abs/2401.15394",
        "title": "Partitioning a Planar Graph into two Triangle-Forests",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "We show that the vertices of every planar graph can be partitioned into two sets, each inducing a so-called triangle-forest, i.e., a graph with no cycles of length more than three.",
        "subjects": [
            "math.CO"
        ],
        "comment": "6 pages, 3 figures"
    },
    {
        "paper id": "2401.15448",
        "abstract url": "https://arxiv.org/abs/2401.15448",
        "title": "A Systematic Review of Available Datasets in Additive Manufacturing",
        "rating": -1,
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In-situ monitoring incorporating data from visual and other sensor technologies, allows the collection of extensive datasets during the Additive Manufacturing (AM) process. These datasets have potential for determining the quality of the manufactured output and the detection of defects through the use of Machine Learning during the manufacturing process. Open and annotated datasets derived from AM processes are necessary for the machine learning community to address this opportunity, which creates difficulties in the application of computer vision-related machine learning in AM. This systematic review investigates the availability of open image-based datasets originating from AM processes that align with a number of pre-defined selection criteria. The review identifies existing gaps among the current image-based datasets in the domain of AM, and points to the need for greater availability of open datasets in order to allow quality assessment and defect detection during additive manufacturing, to develop.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2401.15489",
        "abstract url": "https://arxiv.org/abs/2401.15489",
        "title": "Distilling Privileged Multimodal Information for Expression Recognition using Optimal Transport",
        "rating": -1,
        "keywords": [
            [
                "Biovid"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning models for multimodal expression recognition have reached remarkable performance in controlled laboratory environments because of their ability to learn complementary and redundant semantic information. However, these models struggle in the wild, mainly because of the unavailability and quality of modalities used for training. In practice, only a subset of the training-time modalities may be available at test time. Learning with privileged information enables models to exploit data from additional modalities that are only available during training. State-of-the-art knowledge distillation (KD) methods have been proposed to distill information from multiple teacher models (each trained on a modality) to a common student model. These privileged KD methods typically utilize point-to-point matching, yet have no explicit mechanism to capture the structural information in the teacher representation space formed by introducing the privileged modality. Experiments were performed on two challenging problems - pain estimation on the Biovid dataset (ordinal classification) and arousal-valance prediction on the Affwild2 dataset (regression). Results show that our proposed method can outperform state-of-the-art privileged KD methods on these problems. The diversity among modalities and fusion architectures indicates that PKDOT is modality- and model-agnostic.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15501",
        "abstract url": "https://arxiv.org/abs/2401.15501",
        "title": "FloodLense: A Framework for ChatGPT-based Real-time Flood Detection",
        "rating": -1,
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study addresses the vital issue of real-time flood detection and management. It innovatively combines advanced deep learning models with Large language models (LLM), enhancing flood monitoring and response capabilities. This approach addresses the limitations of current methods by offering a more accurate, versatile, user-friendly and accessible solution. The integration of UNet, RDN, and ViT models with natural language processing significantly improves flood area detection in diverse environments, including using aerial and satellite imagery. The experimental evaluation demonstrates the models' efficacy in accurately identifying and mapping flood zones, showcasing the project's potential in transforming environmental monitoring and disaster management fields.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15511",
        "abstract url": "https://arxiv.org/abs/2401.15511",
        "title": "Distributed Resilient Interval Observer Synthesis for Nonlinear Discrete-Time Systems",
        "rating": -1,
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "This paper introduces a novel recursive distributed estimation algorithm aimed at synthesizing input and state interval observers for nonlinear bounded-error discrete-time multi-agent systems. The considered systems have sensors and actuators that are susceptible to unknown or adversarial inputs. To solve this problem, we first identify conditions that allow agents to obtain nonlinear bounded-error equations characterizing the input. Then, we propose a distributed interval-valued observer that is guaranteed to contain the disturbance and system states. To do this, we first detail a gain design procedure that uses global problem data to minimize an upper bound on the $\\ell_1$ norm of the observer error. We then propose a gain design approach that does not require global information, using only values that are local to each agent. The second method improves on the computational tractability of the first, at the expense of some added conservatism. Further, we discuss some possible ways of extending the results to a broader class of systems. We conclude by demonstrating our observer on two examples. The first is a unicycle system, for which we apply the first gain design method. The second is a 145-bus power system, which showcases the benefits of the second method, due to the first approach being intractable for systems with high dimensional state spaces.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "submitted as a journal submission"
    },
    {
        "paper id": "2401.15513",
        "abstract url": "https://arxiv.org/abs/2401.15513",
        "title": "MiTU-Net: A fine-tuned U-Net with SegFormer backbone for segmenting pubic symphysis-fetal head",
        "rating": -1,
        "keywords": [
            [
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Ultrasound measurements have been examined as potential tools for predicting the likelihood of successful vaginal delivery. The angle of progression (AoP) is a measurable parameter that can be obtained during the initial stage of labor. The AoP is defined as the angle between a straight line along the longitudinal axis of the pubic symphysis (PS) and a line from the inferior edge of the PS to the leading edge of the fetal head (FH). However, the process of measuring AoP on ultrasound images is time consuming and prone to errors. To address this challenge, we propose the Mix Transformer U-Net (MiTU-Net) network, for automatic fetal head-pubic symphysis segmentation and AoP measurement. The MiTU-Net model is based on an encoder-decoder framework, utilizing a pre-trained efficient transformer to enhance feature representation. Within the efficient transformer encoder, the model significantly reduces the trainable parameters of the encoder-decoder model. The effectiveness of the proposed method is demonstrated through experiments conducted on a recent transperineal ultrasound dataset. Our model achieves competitive performance, ranking 5th compared to existing approaches. The MiTU-Net presents an efficient method for automatic segmentation and AoP measurement, reducing errors and assisting sonographers in clinical practice. Reproducibility: Framework implementation and models available on https://github.com/13204942/MiTU-Net.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "The 5th place in the Pubic Symphysis-Fetal Head Segmentation Challenge in MICCAI 2023"
    },
    {
        "paper id": "2401.15523",
        "abstract url": "https://arxiv.org/abs/2401.15523",
        "title": "Performance-Based Biped Control using a Consumer Depth Camera",
        "rating": -1,
        "keywords": [
            [
                "Depth"
            ]
        ],
        "abstract": "We present a technique for controlling physically simulated characters using user inputs from an off-the-shelf depth camera. Our controller takes a real-time stream of user poses as input, and simulates a stream of target poses of a biped based on it. The simulated biped mimics the user's actions while moving forward at a modest speed and maintaining balance. The controller is parameterized over a set of modulated reference motions that aims to cover the range of possible user actions. For real-time simulation, the best set of control parameters for the current input pose is chosen from the parameterized sets of pre-computed control parameters via a regression method. By applying the chosen parameters at each moment, the simulated biped can imitate a range of user actions while walking in various interactive scenarios.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "Eurographics 2017"
    },
    {
        "paper id": "2401.15550",
        "abstract url": "https://arxiv.org/abs/2401.15550",
        "title": "Dynamic Maximal Matching in Clique Networks",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We consider the problem of computing a maximal matching with a distributed algorithm in the presence of batch-dynamic changes to the graph topology. We assume that a graph of $n$ nodes is vertex-partitioned among $k$ players that communicate via message passing. Our goal is to provide an efficient algorithm that quickly updates the matching even if an adversary determines batches of $\\ell$ edge insertions or deletions. Assuming a link bandwidth of $O(\u03b2\\log n)$ bits per round, for a parameter $\u03b2\\ge 1$, we first show a lower bound of $\u03a9( \\frac{\\ell\\,\\log k}{\u03b2\\,k^2\\log n})$ rounds for recomputing a matching assuming an oblivious adversary who is unaware of the initial (random) vertex partition as well as the current state of the players, and a stronger lower bound of $\u03a9(\\frac{\\ell}{\u03b2\\,k\\log n})$ rounds against an adaptive adversary, who may choose any balanced (but not necessarily random) vertex partition initially and who knows the current state of the players. We also present a randomized algorithm that has an initialization time of $O( \\lceil\\frac{n}{\u03b2\\,k}\\rceil\\log n )$ rounds, while achieving an update time that that is independent of $n$: In more detail, the update time is $O( \\lceil \\frac{\\ell}{\u03b2\\,k} \\rceil \\log(\u03b2\\,k))$ against an oblivious adversary, who must fix all updates in advance. If we consider the stronger adaptive adversary, the update time becomes $O( \\lceil \\frac{\\ell}{\\sqrt{\u03b2\\,k}}\\rceil \\log(\u03b2\\,k))$ rounds.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Appeared at ITCS 2024"
    },
    {
        "paper id": "2401.15554",
        "abstract url": "https://arxiv.org/abs/2401.15554",
        "title": "Pericoronary adipose tissue feature analysis in CT calcium score images with comparison to coronary CTA",
        "rating": -1,
        "keywords": [
            [
                "CT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We investigated the feasibility and advantages of using non-contrast CT calcium score (CTCS) images to assess pericoronary adipose tissue (PCAT) and its association with major adverse cardiovascular events (MACE). PCAT features from coronary CTA (CCTA) have been shown to be associated with cardiovascular risk but are potentially confounded by iodine. If PCAT in CTCS images can be similarly analyzed, it would avoid this issue and enable its inclusion in formal risk assessment from readily available, low-cost CTCS images. To identify coronaries in CTCS images that have subtle visual evidence of vessels, we registered CTCS with paired CCTA images having coronary labels. We developed a novel axial-disk method giving regions for analyzing PCAT features in three main coronary arteries. We analyzed novel hand-crafted and radiomic features using univariate and multivariate logistic regression prediction of MACE and compared results against those from CCTA. Registration accuracy was sufficient to enable the identification of PCAT regions in CTCS images. Motion or beam hardening artifacts were often present in high-contrast CCTA but not CTCS. Mean HU and volume were increased in both CTCS and CCTA for MACE group. There were significant positive correlations between some CTCS and CCTA features, suggesting that similar characteristics were obtained. Using hand-crafted/radiomics from CTCS and CCTA, AUCs were 0.82/0.79 and 0.83/0.77 respectively, while Agatston gave AUC=0.73. Preliminarily, PCAT features can be assessed from three main coronary arteries in non-contrast CTCS images with performance characteristics that are at the very least comparable to CCTA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "24 pages,10 figures"
    },
    {
        "paper id": "2401.15559",
        "abstract url": "https://arxiv.org/abs/2401.15559",
        "title": "IntentTuner: An Interactive Framework for Integrating Human Intents in Fine-tuning Text-to-Image Generative Models",
        "rating": -1,
        "keywords": [
            [
                "Text-to-Image"
            ]
        ],
        "abstract": "Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment, allowing intent-aware monitoring and evaluation of model training. Application exemplars and user studies demonstrate that IntentTuner streamlines fine-tuning, reducing cognitive effort and yielding superior models compared to the common baseline tool.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "26 pages, 10 figures"
    },
    {
        "paper id": "2401.15561",
        "abstract url": "https://arxiv.org/abs/2401.15561",
        "title": "A Parameter Privacy-Preserving Strategy for Mixed-Autonomy Platoon Control",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "It has been demonstrated that leading cruise control (LCC) can improve the operation of mixed-autonomy platoons by allowing connected and automated vehicles (CAVs) to make longitudinal control decisions based on the information provided by surrounding vehicles. However, LCC generally requires surrounding human-driven vehicles (HDVs) to share their real-time states, which can be used by adversaries to infer drivers' car-following behavior, potentially leading to financial losses or safety concerns. This paper aims to address such privacy concerns and protect the behavioral characteristics of HDVs by devising a parameter privacy-preserving approach for mixed-autonomy platoon control. First, we integrate a parameter privacy filter into LCC to protect sensitive car-following parameters. The privacy filter allows each vehicle to generate seemingly realistic pseudo states by distorting the true parameters to pseudo parameters, which can protect drivers' privacy in behavioral parameters without significantly influencing the control performance. Second, to enhance the practicality and reliability of the privacy filter within LCC, we first extend the current approach to accommodate continuous parameter spaces through a neural network estimator. Subsequently, we introduce an individual-level parameter privacy preservation constraint, focusing on the privacy level of each individual parameter pair, further enhancing the approach's reliability. Third, analysis of head-to-tail string stability reveals the potential impact of privacy filters in degrading mixed traffic flow performance. Simulation shows that this approach can effectively trade off privacy and control performance in LCC. We further demonstrate the benefit of such an approach in networked systems, i.e., by applying the privacy filter to a proceeding vehicle, one can also achieve a certain level of privacy for the following vehicle.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15330",
        "abstract url": "https://arxiv.org/abs/2401.15330",
        "title": "Optimal Sparse Survival Trees",
        "rating": -1.5,
        "keywords": [
            [
                "biotechnology",
                "health",
                "Survival"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Interpretability is crucial for doctors, hospitals, pharmaceutical companies and biotechnology corporations to analyze and make decisions for high stakes problems that involve human health. Tree-based methods have been widely adopted for survival analysis due to their appealing interpretablility and their ability to capture complex relationships. However, most existing methods to produce survival trees rely on heuristic (or greedy) algorithms, which risk producing sub-optimal models. We present a dynamic-programming-with-bounds approach that finds provably-optimal sparse survival tree models, frequently in only a few seconds.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "AISTATS2024 camera ready version. arXiv admin note: text overlap with arXiv:2211.14980"
    },
    {
        "paper id": "2401.15337",
        "abstract url": "https://arxiv.org/abs/2401.15337",
        "title": "Deep Learning with Information Fusion and Model Interpretation for Health Monitoring of Fetus based on Long-term Prenatal Electronic Fetal Heart Rate Monitoring Data",
        "rating": -1.5,
        "keywords": [
            [
                "Health",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Long-term fetal heart rate (FHR) monitoring during the antepartum period, increasingly popularized by electronic FHR monitoring, represents a growing approach in FHR monitoring. This kind of continuous monitoring, in contrast to the short-term one, collects an extended period of fetal heart data. This offers a more comprehensive understanding of fetus's conditions. However, the interpretation of long-term antenatal fetal heart monitoring is still in its early stages, lacking corresponding clinical standards. Furthermore, the substantial amount of data generated by continuous monitoring imposes a significant burden on clinical work when analyzed manually. To address above challenges, this study develops an automatic analysis system named LARA (Long-term Antepartum Risk Analysis system) for continuous FHR monitoring, combining deep learning and information fusion methods. LARA's core is a well-established convolutional neural network (CNN) model. It processes long-term FHR data as input and generates a Risk Distribution Map (RDM) and Risk Index (RI) as the analysis results. We evaluate LARA on inner test dataset, the performance metrics are as follows: AUC 0.872, accuracy 0.816, specificity 0.811, sensitivity 0.806, precision 0.271, and F1 score 0.415. In our study, we observe that long-term FHR monitoring data with higher RI is more likely to result in adverse outcomes (p=0.0021). In conclusion, this study introduces LARA, the first automated analysis system for long-term FHR monitoring, initiating the further explorations into its clinical value in the future.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15356",
        "abstract url": "https://arxiv.org/abs/2401.15356",
        "title": "A Decision Theoretic Framework for Measuring AI Reliance",
        "rating": -1.5,
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Humans frequently make decisions with the aid of artificially intelligent (AI) systems. A common pattern is for the AI to recommend an action to the human who retains control over the final decision. Researchers have identified ensuring that a human has appropriate reliance on an AI as a critical component of achieving complementary performance. We argue that the current definition of appropriate reliance used in such research lacks formal statistical grounding and can lead to contradictions. We propose a formal definition of reliance, based on statistical decision theory, which separates the concepts of reliance as the probability the decision-maker follows the AI's recommendation from challenges a human may face in differentiating the signals and forming accurate beliefs about the situation. Our definition gives rise to a framework that can be used to guide the design and interpretation of studies on human-AI complementarity and reliance. Using recent AI-advised decision making studies from literature, we demonstrate how our framework can be used to separate the loss due to mis-reliance from the loss due to not accurately differentiating the signals. We evaluate these losses by comparing to a baseline and a benchmark for complementary performance defined by the expected payoff achieved by a rational decision-maker facing the same decision task as the behavioral decision-makers.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15377",
        "abstract url": "https://arxiv.org/abs/2401.15377",
        "title": "Validation of artificial neural networks to model the acoustic behaviour of induction motors",
        "rating": -1.5,
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the last decade, the sound quality of electric induction motors is a hot topic in the research field. Specially, due to its high number of applications, the population is exposed to physical and psychological discomfort caused by the noise emission. Therefore, it is necessary to minimise its psychological impact on the population. In this way, the main goal of this work is to evaluate the use of multitask artificial neural networks as a modelling technique for simultaneously predicting psychoacoustic parameters of induction motors. Several inputs are used, such as, the electrical magnitudes of the motor power signal and the number of poles, instead of separating the noise of the electric motor from the environmental noise. Two different kind of artificial neural networks are proposed to evaluate the acoustic quality of induction motors, by using the equivalent sound pressure, the loudness, the roughness and the sharpness as outputs. Concretely, two different topologies have been considered: simple models and more complex models. The former are more interpretable, while the later lead to higher accuracy at the cost of hiding the cause-effect relationship. Focusing on the simple interpretable models, product unit neural networks achieved the best results: for MSE and for SEP. The main benefit of this product unit model is its simplicity, since only 10 inputs variables are used, outlining the effective transfer mechanism of multitask artificial neural networks to extract common features of multiple tasks. Finally, a deep analysis of the acoustic quality of induction motors in done using the best product unit neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15544",
        "abstract url": "https://arxiv.org/abs/2401.15544",
        "title": "Analog and Multi-modal Manufacturing Datasets Acquired on the Future Factories Platform",
        "rating": -1.5,
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Two industry-grade datasets are presented in this paper that were collected at the Future Factories Lab at the University of South Carolina on December 11th and 12th of 2023. These datasets are generated by a manufacturing assembly line that utilizes industrial standards with respect to actuators, control mechanisms, and transducers. The two datasets were both generated simultaneously by operating the assembly line for 30 consecutive hours (with minor filtering) and collecting data from sensors equipped throughout the system. During operation, defects were also introduced into the assembly operation by manually removing parts needed for the final assembly. The datasets generated include a time series analog dataset and the other is a time series multi-modal dataset which includes images of the system alongside the analog data. These datasets were generated with the objective of providing tools to further the research towards enhancing intelligence in manufacturing. Real manufacturing datasets can be scarce let alone datasets with anomalies or defects. As such these datasets hope to address this gap and provide researchers with a foundation to build and train Artificial Intelligence models applicable for the manufacturing industry. Finally, these datasets are the first iteration of published data from the future Factories lab and can be further adjusted to fit more researchers needs moving forward.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "11 pages, datasets for Future Factories"
    },
    {
        "paper id": "2401.15298",
        "abstract url": "https://arxiv.org/abs/2401.15298",
        "title": "Together We Go Further: LLMs and IDE Static Analysis for Extract Method Refactoring",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Long methods that encapsulate multiple responsibilities within a single method are challenging to maintain. Choosing which statements to extract into new methods has been the target of many research tools. Despite steady improvements, these tools often fail to generate refactorings that align with developers' preferences and acceptance criteria. Given that Large Language Models (LLMs) have been trained on large code corpora, if we harness their familiarity with the way developers form functions, we could suggest refactorings that developers are likely to accept. In this paper, we advance the science and practice of refactoring by synergistically combining the insights of LLMs with the power of IDEs to perform Extract Method (EM). Our formative study on 1752 EM scenarios revealed that LLMs are very effective for giving expert suggestions, yet they are unreliable: up to 76.3% of the suggestions are hallucinations. We designed a novel approach that removes hallucinations from the candidates suggested by LLMs, then further enhances and ranks suggestions based on static analysis techniques from program slicing, and finally leverages the IDE to execute refactorings correctly. We implemented this approach in an IntelliJ IDEA plugin called EM-Assist. We empirically evaluated EM-Assist on a diverse corpus that replicates 1752 actual refactorings from open-source projects. We found that EM-Assist outperforms previous state of the art tools: EM-Assist suggests the developerperformed refactoring in 53.4% of cases, improving over the recall rate of 39.4% for previous best-in-class tools. Furthermore, we conducted firehouse surveys with 16 industrial developers and suggested refactorings on their recent commits. 81.3% of them agreed with the recommendations provided by EM-Assist.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15299",
        "abstract url": "https://arxiv.org/abs/2401.15299",
        "title": "SupplyGraph: A Benchmark Dataset for Supply Chain Planning using Graph Neural Networks",
        "rating": -2.0,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "bio-informatics"
            ],
            [
                "cs.LG"
            ],
            [
                "workshop",
                "AAAI"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have gained traction across different domains such as transportation, bio-informatics, language processing, and computer vision. However, there is a noticeable absence of research on applying GNNs to supply chain networks. Supply chain networks are inherently graph-like in structure, making them prime candidates for applying GNN methodologies. This opens up a world of possibilities for optimizing, predicting, and solving even the most complex supply chain problems. A major setback in this approach lies in the absence of real-world benchmark datasets to facilitate the research and resolution of supply chain problems using GNNs. To address the issue, we present a real-world benchmark dataset for temporal tasks, obtained from one of the leading FMCG companies in Bangladesh, focusing on supply chain planning for production purposes. The dataset includes temporal data as node features to enable sales predictions, production planning, and the identification of factory issues. By utilizing this dataset, researchers can employ GNNs to address numerous supply chain problems, thereby advancing the field of supply chain analytics and planning. Source: https://github.com/CIOL-SUST/SupplyGraph",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 8 figures; Accepted to 4th workshop on Graphs and more Complex structures for Learning and Reasoning, colocated with AAAI 2024"
    },
    {
        "paper id": "2401.15305",
        "abstract url": "https://arxiv.org/abs/2401.15305",
        "title": "A Practical Probabilistic Benchmark for AI Weather Models",
        "rating": -2,
        "keywords": [
            [
                "forecast"
            ]
        ],
        "abstract": "Since the weather is chaotic, forecasts aim to predict the distribution of future states rather than make a single prediction. Recently, multiple data driven weather models have emerged claiming breakthroughs in skill. However, these have mostly been benchmarked using deterministic skill scores, and little is known about their probabilistic skill. Unfortunately, it is hard to fairly compare AI weather models in a probabilistic sense, since variations in choice of ensemble initialization, definition of state, and noise injection methodology become confounding. Moreover, even obtaining ensemble forecast baselines is a substantial engineering challenge given the data volumes involved. We sidestep both problems by applying a decades-old idea -- lagged ensembles -- whereby an ensemble can be constructed from a moderately-sized library of deterministic forecasts. This allows the first parameter-free intercomparison of leading AI weather models' probabilistic skill against an operational baseline. The results reveal that two leading AI weather models, i.e. GraphCast and Pangu, are tied on the probabilistic CRPS metric even though the former outperforms the latter in deterministic scoring. We also reveal how multiple time-step loss functions, which many data-driven weather models have employed, are counter-productive: they improve deterministic metrics at the cost of increased dissipation, deteriorating probabilistic skill. This is confirmed through ablations applied to a spherical Fourier Neural Operator (SFNO) approach to AI weather forecasting. Separate SFNO ablations modulating effective resolution reveal it has a useful effect on ensemble dispersion relevant to achieving good ensemble calibration. We hope these and forthcoming insights from lagged ensembles can help guide the development of AI weather forecasts and have thus shared the diagnostic code.",
        "subjects": [
            "physics.ao-ph"
        ],
        "comment": "15 pages, 5 figures"
    },
    {
        "paper id": "2401.15313",
        "abstract url": "https://arxiv.org/abs/2401.15313",
        "title": "Multi-Robot Relative Pose Estimation in SE(2) with Observability Analysis: A Comparison of Extended Kalman Filtering and Robust Pose Graph Optimization",
        "rating": -2,
        "keywords": [
            [
                "Robot"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "In this study, we address multi-robot localization issues, with a specific focus on cooperative localization and observability analysis of relative pose estimation. Cooperative localization involves enhancing each robot's information through a communication network and message passing. If odometry data from a target robot can be transmitted to the ego robot, observability of their relative pose estimation can be achieved through range-only or bearing-only measurements, provided both robots have non-zero linear velocities. In cases where odometry data from a target robot are not directly transmitted but estimated by the ego robot, both range and bearing measurements are necessary to ensure observability of relative pose estimation. For ROS/Gazebo simulations, we explore four sensing and communication structures. We compare extended Kalman filtering (EKF) and pose graph optimization (PGO) estimation using different robust loss functions (filtering and smoothing with varying batch sizes of sliding windows) in terms of estimation accuracy. In hardware experiments, two Turtlebot3 equipped with UWB modules are used for real-world inter-robot relative pose estimation, applying both EKF and PGO and comparing their performance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20 pages, 21 figures"
    },
    {
        "paper id": "2401.15321",
        "abstract url": "https://arxiv.org/abs/2401.15321",
        "title": "Localization of Dummy Data Injection Attacks in Power Systems Considering Incomplete Topological Information: A Spatio-Temporal Graph Wavelet Convolutional Neural Network Approach",
        "rating": -2,
        "keywords": [
            [
                "Graph"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "The emergence of novel the dummy data injection attack (DDIA) poses a severe threat to the secure and stable operation of power systems. These attacks are particularly perilous due to the minimal Euclidean spatial separation between the injected malicious data and legitimate data, rendering their precise detection challenging using conventional distance-based methods. Furthermore, existing research predominantly focuses on various machine learning techniques, often analyzing the temporal data sequences post-attack or relying solely on Euclidean spatial characteristics. Unfortunately, this approach tends to overlook the inherent topological correlations within the non-Euclidean spatial attributes of power grid data, consequently leading to diminished accuracy in attack localization. To address this issue, this study takes a comprehensive approach. Initially, it examines the underlying principles of these new DDIAs on power systems. Here, an intricate mathematical model of the DDIA is designed, accounting for incomplete topological knowledge and alternating current (AC) state estimation from an attacker's perspective. Subsequently, by integrating a priori knowledge of grid topology and considering the temporal correlations within measurement data and the topology-dependent attributes of the power grid, this study introduces temporal and spatial attention matrices. These matrices adaptively capture the spatio-temporal correlations within the attacks. Leveraging gated stacked causal convolution and graph wavelet sparse convolution, the study jointly extracts spatio-temporal DDIA features. Finally, the research proposes a DDIA localization method based on spatio-temporal graph neural networks. The accuracy and effectiveness of the DDIA model are rigorously demonstrated through comprehensive analytical cases.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted by Applied Energy"
    },
    {
        "paper id": "2401.15344",
        "abstract url": "https://arxiv.org/abs/2401.15344",
        "title": "IRS Aided Millimeter-Wave Sensing and Communication: Beam Scanning, Beam Splitting, and Performance Analysis",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Integrated sensing and communication (ISAC) has attracted growing interests for enabling the future 6G wireless networks, due to its capability of sharing spectrum and hardware resources between communication and sensing systems. However, existing works on ISAC usually need to modify the communication protocol to cater for the new sensing performance requirement, which may be difficult to implement in practice. In this paper, we study a new intelligent reflecting surface (IRS) aided millimeter-wave (mmWave) ISAC system by exploiting the distinct beam scanning operation in mmWave communications to achieve efficient sensing at the same time. First, we propose a two-phase ISAC protocol aided by a semi-passive IRS, consisting of beam scanning and data transmission. Specifically, in the beam scanning phase, the IRS finds the optimal beam for reflecting signals from the base station to a communication user via its passive elements. Meanwhile, the IRS directly estimates the angle of a nearby target based on echo signals from the target using its equipped active sensing element. Then, in the data transmission phase, the sensing accuracy is further improved by leveraging the data signals via possible IRS beam splitting. Next, we derive the achievable rate of the communication user as well as the Cram\u00e9r-Rao bound and the approximate mean square error of the target angle estimation Finally, extensive simulation results are provided to verify our analysis as well as the effectiveness of the proposed scheme.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "submitted to IEEE TWC"
    },
    {
        "paper id": "2401.15348",
        "abstract url": "https://arxiv.org/abs/2401.15348",
        "title": "AniDress: Animatable Loose-Dressed Avatar from Sparse Views Using Garment Rigging Model",
        "rating": -2,
        "keywords": [
            [
                "Avatar"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent communities have seen significant progress in building photo-realistic animatable avatars from sparse multi-view videos. However, current workflows struggle to render realistic garment dynamics for loose-fitting characters as they predominantly rely on naked body models for human modeling while leaving the garment part un-modeled. This is mainly due to that the deformations yielded by loose garments are highly non-rigid, and capturing such deformations often requires dense views as supervision. In this paper, we introduce AniDress, a novel method for generating animatable human avatars in loose clothes using very sparse multi-view videos (4-8 in our setting). To allow the capturing and appearance learning of loose garments in such a situation, we employ a virtual bone-based garment rigging model obtained from physics-based simulation data. Such a model allows us to capture and render complex garment dynamics through a set of low-dimensional bone transformations. Technically, we develop a novel method for estimating temporal coherent garment dynamics from a sparse multi-view video. To build a realistic rendering for unseen garment status using coarse estimations, a pose-driven deformable neural radiance field conditioned on both body and garment motions is introduced, providing explicit control of both parts. At test time, the new garment poses can be captured from unseen situations, derived from a physics-based or neural network-based simulator to drive unseen garment dynamics. To evaluate our approach, we create a multi-view dataset that captures loose-dressed performers with diverse motions. Experiments show that our method is able to render natural garment dynamics that deviate highly from the body and generalize well to both unseen views and poses, surpassing the performance of existing methods. The code and data will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15363",
        "abstract url": "https://arxiv.org/abs/2401.15363",
        "title": "Fair and Efficient Ridesharing: A Dynamic Programming-based Relocation Approach",
        "rating": -2,
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Recommending routes by their probability of having a rider has long been the goal of conventional route recommendation systems. While this maximizes the platform-specific criteria of efficiency, it results in sub-optimal outcomes with the disparity among the income of drivers who work for similar time frames. Pioneer studies on fairness in ridesharing platforms have focused on algorithms that match drivers and riders. However, these studies do not consider the time schedules of different riders sharing a ride in the ridesharing mode. To overcome this shortcoming, we present the first route recommendation system for ridesharing networks that explicitly considers fairness as an evaluation criterion. In particular, we design a routing mechanism that reduces the inequality among drivers and provides them with routes that have a similar probability of finding riders over a period of time. However, while optimizing fairness the efficiency of the platform should not be affected as both of these goals are important for the long-term sustainability of the system. In order to jointly optimize fairness and efficiency we consider repositioning drivers with low income to the areas that have a higher probability of finding riders in future. While applying driver repositioning, we design a future-aware policy and allocate the areas to the drivers considering the destination of requests in the corresponding area. Extensive simulations on real-world datasets of Washington DC and New York demonstrate superior performance by our proposed system in comparison to the existing baselines.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15366",
        "abstract url": "https://arxiv.org/abs/2401.15366",
        "title": "Face to Cartoon Incremental Super-Resolution using Knowledge Distillation",
        "rating": -2,
        "keywords": [
            [
                "GAN",
                "Super-Resolution"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial super-resolution/hallucination is an important area of research that seeks to enhance low-resolution facial images for a variety of applications. While Generative Adversarial Networks (GANs) have shown promise in this area, their ability to adapt to new, unseen data remains a challenge. This paper addresses this problem by proposing an incremental super-resolution using GANs with knowledge distillation (ISR-KD) for face to cartoon. Previous research in this area has not investigated incremental learning, which is critical for real-world applications where new data is continually being generated. The proposed ISR-KD aims to develop a novel unified framework for facial super-resolution that can handle different settings, including different types of faces such as cartoon face and various levels of detail. To achieve this, a GAN-based super-resolution network was pre-trained on the CelebA dataset and then incrementally trained on the iCartoonFace dataset, using knowledge distillation to retain performance on the CelebA test set while improving the performance on iCartoonFace test set. Our experiments demonstrate the effectiveness of knowledge distillation in incrementally adding capability to the model for cartoon face super-resolution while retaining the learned knowledge for facial hallucination tasks in GANs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15368",
        "abstract url": "https://arxiv.org/abs/2401.15368",
        "title": "The Capacity of the Weighted Read Channel",
        "rating": -2,
        "keywords": [
            [
                "DNA"
            ]
        ],
        "abstract": "One of the primary sequencing methods gaining prominence in DNA storage is nanopore sequencing, attributed to various factors. In this work, we consider a simplified model of the sequencer, characterized as a channel. This channel takes a sequence and processes it using a sliding window of length $\\ell$, shifting the window by $\u03b4$ characters each time. The output of this channel, which we refer to as the read vector, is a vector containing the sums of the entries in each of the windows. The capacity of the channel is defined as the maximal information rate of the channel. Previous works have already revealed capacity values for certain parameters $\\ell$ and $\u03b4$. In this work, we show that when $\u03b4< \\ell < 2\u03b4$, the capacity value is given by $\\frac{1}\u03b4\\log_2 \\frac{1}{2}(\\ell+1+ \\sqrt{(\\ell+1)^2 - 4(\\ell - \u03b4)(\\ell-\u03b4+1)})$. Additionally, we construct an upper bound when $2\u03b4< \\ell$. Finally, we extend the model to the two-dimensional case and present several results on its capacity.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15369",
        "abstract url": "https://arxiv.org/abs/2401.15369",
        "title": "Privacy-Preserving Cross-Domain Sequential Recommendation",
        "rating": -2,
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Cross-domain sequential recommendation is an important development direction of recommender systems. It combines the characteristics of sequential recommender systems and cross-domain recommender systems, which can capture the dynamic preferences of users and alleviate the problem of cold-start users. However, in recent years, people pay more and more attention to their privacy. They do not want other people to know what they just bought, what videos they just watched, and where they just came from. How to protect the users' privacy has become an urgent problem to be solved. In this paper, we propose a novel privacy-preserving cross-domain sequential recommender system (PriCDSR), which can provide users with recommendation services while preserving their privacy at the same time. Specifically, we define a new differential privacy on the data, taking into account both the ID information and the order information. Then, we design a random mechanism that satisfies this differential privacy and provide its theoretical proof. Our PriCDSR is a non-invasive method that can adopt any cross-domain sequential recommender system as a base model without any modification to it. To the best of our knowledge, our PriCDSR is the first work to investigate privacy issues in cross-domain sequential recommender systems. We conduct experiments on three domains, and the results demonstrate that our PriCDSR, despite introducing noise, still outperforms recommender systems that only use data from a single domain.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15376",
        "abstract url": "https://arxiv.org/abs/2401.15376",
        "title": "Bit error probability and capacity bound of OFDM systems in deterministic doubly-selective channels",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Doubly-selective channels, such as those that occur when the transmitter and the receiver move relative to each other at high speeds, are a key scenario for fifth generation (5G) cellular systems, which are mostly based in the use of the orthogonal frequency-division multiplexing (OFDM) modulation. In this paper, we consider an OFDM system using quadrature amplitude modulation (QAM) symbols and we show that, when transmitting over deterministic doubly-selective channels, the inter-carrier interference (ICI) affecting a symbol can be well approximated by a complex-valued normal distribution. Based on this, we derive a lower bound for the link capacity using the Shannon-Hartley theorem. Finally, we provide an approximation of the bit error probability (BEP) using the well-known BEP expressions for Gray-coded QAM constellations over additive white Gaussian noise (AWGN) channels, and show numerical results that confirm that the proposed BEP expression approximates accurately the bit error ratio (BER) of the OFDM system for standardized channel models. The proposed closed-form analytical expressions for the capacity and the BEP do not only allow for discarding the need of computationally-costly Monte-Carlo system simulations, but also provide a theoretical framework to optimize the system parameters directly impacting on the achievable performance.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "12 pages, 11 figures, published in IEEE Transactions on Vehicular Technology"
    },
    {
        "paper id": "2401.15390",
        "abstract url": "https://arxiv.org/abs/2401.15390",
        "title": "A microservice architecture for real-time IoT data processing: A reusable Web of things approach for smart ports",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Major advances in telecommunications and the Internet of Things have given rise to numerous smart city scenarios in which smart services are provided. What was once a dream for the future has now become reality. However, the need to provide these smart services quickly, efficiently, in an interoperable manner and in real time is a cutting-edge technological challenge. Although some software architectures offer solutions in this area, these are often limited in terms of reusability and maintenance by independent modules, involving the need for system downtime when maintaining or evolving, as well as by a lack of standards in terms of the interoperability of their interface. In this paper, we propose a fully reusable microservice architecture, standardized through the use of the Web of things paradigm, and with high efficiency in real-time data processing, supported by complex event processing techniques. To illustrate the proposal, we present a fully reusable implementation of the microservices necessary for the deployment of the architecture in the field of air quality monitoring and alerting in smart ports. The performance evaluation of this architecture shows excellent results.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15399",
        "abstract url": "https://arxiv.org/abs/2401.15399",
        "title": "Parallel Self-assembly for Modular USVs with Diverse Docking Mechanism Layouts",
        "rating": -2,
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Self-assembly enables multi-robot systems to merge diverse capabilities and accomplish tasks beyond the reach of individual robots. Incorporating varied docking mechanisms layouts (DMLs) can enhance robot versatility or reduce costs. However, assembling multiple heterogeneous robots with diverse DMLs is still a research gap. This paper addresses this problem by introducing CuBoat, an omnidirectional unmanned surface vehicle (USV). CuBoat can be equipped with or without docking systems on its four sides to emulate heterogeneous robots. We implement a multi-robot system based on multiple CuBoats. To enhance maneuverability, a linear active disturbance rejection control (LADRC) scheme is proposed. Additionally, we present a generalized parallel self-assembly planning algorithm for efficient assembly among CuBoats with different DMLs. Validation is conducted through simulation within 2 scenarios across 4 distinct maps, demonstrating the performance of the self-assembly planning algorithm. Moreover, trajectory tracking tests confirm the effectiveness of the LADRC controller. Self-assembly experiments on 5 maps with different target structures affirm the algorithm's feasibility and generality. This study advances robotic self-assembly, enabling multi-robot systems to collaboratively tackle complex tasks beyond the capabilities of individual robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15415",
        "abstract url": "https://arxiv.org/abs/2401.15415",
        "title": "Optimal blind focusing on perturbation-inducing targets in sub-unitary complex media",
        "rating": -2,
        "keywords": [
            [
                "bioelectronics"
            ]
        ],
        "abstract": "The scattering of waves in a complex medium is perturbed by polarizability changes or motion of embedded targets. These perturbations could serve as perfectly non-invasive guidestars for focusing on the targets. In this Letter, we theoretically derive a fundamental difference between these two perturbation types (the change of the scattering matrix is of rank one [two] for target polarizability changes [motion]) and identify accordingly optimal strategies to perfectly focus on the target in both cases. For target motion, at least two displacements are necessary. Furthermore, for the case of dynamic complex media additionally featuring parasitic perturbers, we establish a non-invasive scheme to achieve optimal time-averaged power delivery to a perturbation-inducing target. In all cases, no assumptions about the unitarity of the system's scattering matrix or the size of the perturbation are necessary. We experimentally demonstrate all results in the microwave regime using a strongly sub-unitary lossy chaotic cavity as complex medium. Our experiments highlight that the target's \"structural scattering\" is irrelevant [must be negligible] in the case of target polarizability changes [motion]. We expect our results to find applications in communications, cybersecurity, bioelectronics, flow-cytometry and self-propelled nano-swimmers.",
        "subjects": [
            "physics.optics"
        ],
        "comment": "6 pages including 4 figures + 12 pages Supplemental Material"
    },
    {
        "paper id": "2401.15434",
        "abstract url": "https://arxiv.org/abs/2401.15434",
        "title": "Decentralized Gossip Mutual Learning (GML) for brain tumor segmentation on multi-parametric MRI",
        "rating": -2,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "medical",
                "MRI",
                "clinical",
                "tumor"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Federated Learning (FL) enables collaborative model training among medical centers without sharing private data. However, traditional FL risks on server failures and suboptimal performance on local data due to the nature of centralized model aggregation. To address these issues, we present Gossip Mutual Learning (GML), a decentralized framework that uses Gossip Protocol for direct peer-to-peer communication. In addition, GML encourages each site to optimize its local model through mutual learning to account for data variations among different sites. For the task of tumor segmentation using 146 cases from four clinical sites in BraTS 2021 dataset, we demonstrated GML outperformed local models and achieved similar performance as FedAvg with only 25% communication overhead.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "3 pages, 1 figure, accepted to IEEE EMBS 2023. arXiv admin note: text overlap with arXiv:2401.06180"
    },
    {
        "paper id": "2401.15439",
        "abstract url": "https://arxiv.org/abs/2401.15439",
        "title": "Pre-training and Diagnosing Knowledge Base Completion Models",
        "rating": -2,
        "keywords": [
            [
                "Graph"
            ],
            [
                "Diagnosing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we introduce and analyze an approach to knowledge transfer from one collection of facts to another without the need for entity or relation matching. The method works for both canonicalized knowledge bases and uncanonicalized or open knowledge bases, i.e., knowledge bases where more than one copy of a real-world entity or relation may exist. The main contribution is a method that can make use of large-scale pre-training on facts, which were collected from unstructured text, to improve predictions on structured data from a specific domain. The introduced method is most impactful on small datasets such as ReVerb20k, where a 6% absolute increase of mean reciprocal rank and 65% relative decrease of mean rank over the previously best method was achieved, despite not relying on large pre-trained models like Bert. To understand the obtained pre-trained models better, we then introduce a novel dataset for the analysis of pre-trained models for Open Knowledge Base Completion, called Doge (Diagnostics of Open knowledge Graph Embeddings). It consists of 6 subsets and is designed to measure multiple properties of a pre-trained model: robustness against synonyms, ability to perform deductive reasoning, presence of gender stereotypes, consistency with reverse relations, and coverage of different areas of general knowledge. Using the introduced dataset, we show that the existing OKBC models lack consistency in the presence of synonyms and inverse relations and are unable to perform deductive reasoning. Moreover, their predictions often align with gender stereotypes, which persist even when presented with counterevidence. We additionally investigate the role of pre-trained word embeddings and demonstrate that avoiding biased word embeddings is not a sufficient measure to prevent biased behavior of OKBC models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to AIJ, reference to follow. arXiv admin note: substantial text overlap with arXiv:2108.13073"
    },
    {
        "paper id": "2401.15441",
        "abstract url": "https://arxiv.org/abs/2401.15441",
        "title": "An overview of IoT architectures, technologies, and existing open-source projects",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Today's needs for monitoring and control of different devices in organizations require an Internet of Things (IoT) platform that can integrate heterogeneous elements provided by multiple vendors and using different protocols, data formats and communication technologies. This article provides a comprehensive review of all the architectures, technologies, protocols and data formats most commonly used by existing IoT platforms. On this basis, a comparative analysis of the most widely used open source IoT platforms is presented. This exhaustive comparison is based on multiple characteristics that will be essential to select the platform that best suits the needs of each organization.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "15 pages, 4 figures, Published in Internet of Things"
    },
    {
        "paper id": "2401.15473",
        "abstract url": "https://arxiv.org/abs/2401.15473",
        "title": "iDeLog: Iterative Dual Spatial and Kinematic Extraction of Sigma-Lognormal Parameters",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "biological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Kinematic Theory of rapid movements and its associated Sigma-Lognormal model have been extensively used in a large variety of applications. While the physical and biological meaning of the model have been widely tested and validated for rapid movements, some shortcomings have been detected when it is used with continuous long and complex movements. To alleviate such drawbacks, and inspired by the motor equivalence theory and a conceivable visual feedback, this paper proposes a novel framework to extract the Sigma-Lognormal parameters, namely iDeLog. Specifically, iDeLog consists of two steps. The first one, influenced by the motor equivalence model, separately derives an initial action plan defined by a set of virtual points and angles from the trajectory and a sequence of lognormals from the velocity. In the second step, based on a hypothetical visual feedback compatible with an open-loop motor control, the virtual target points of the action plan are iteratively moved to improve the matching between the observed and reconstructed trajectory and velocity. During experiments conducted with handwritten signatures, iDeLog obtained promising results as compared to the previous development of the Sigma-Lognormal.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted Version published by Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
        "paper id": "2401.15508",
        "abstract url": "https://arxiv.org/abs/2401.15508",
        "title": "Proto-MPC: An Encoder-Prototype-Decoder Approach for Quadrotor Control in Challenging Winds",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Quadrotors are increasingly used in the evolving field of aerial robotics for their agility and mechanical simplicity. However, inherent uncertainties, such as aerodynamic effects coupled with quadrotors' operation in dynamically changing environments, pose significant challenges for traditional, nominal model-based control designs. We propose a multi-task meta-learning method called Encoder-Prototype-Decoder (EPD), which has the advantage of effectively balancing shared and distinctive representations across diverse training tasks. Subsequently, we integrate the EPD model into a model predictive control problem (Proto-MPC) to enhance the quadrotor's ability to adapt and operate across a spectrum of dynamically changing tasks with an efficient online implementation. We validate the proposed method in simulations, which demonstrates Proto-MPC's robust performance in trajectory tracking of a quadrotor being subject to static and spatially varying side winds.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15510",
        "abstract url": "https://arxiv.org/abs/2401.15510",
        "title": "DocuBits: VR Document Decomposition for Procedural Task Completion",
        "rating": -2,
        "keywords": [
            [
                "chemistry"
            ]
        ],
        "abstract": "Reading monolithic instructional documents in VR is often challenging, especially when tasks are collaborative. Here we present DocuBits, a novel method for transforming monolithic documents into small, interactive instructional elements. Our approach allows users to:(i) create instructional elements (ii) position them within VR and (iii) use them to monitor and share progress in a multi-user VR learning environment. We describe our design methodology as well as two user studies evaluating how both individual users and pairs of users interact with DocuBits compared to monolithic documents while performing a chemistry lab task. Our analysis shows that, for both studies, DocuBits had substantially higher usability, while decreasing perceived workload (p < 0.001$. Our collaborative study showed that participants perceived higher social presence, collaborator awareness as well as immersion and presence (p < 0.001). We discuss our insights for using text-based instructions to support enhanced collaboration in VR environments.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15529",
        "abstract url": "https://arxiv.org/abs/2401.15529",
        "title": "A Thorough Study of State Leakage Mitigation in Quantum Computing with One-Time Pad",
        "rating": -2,
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The ability for users to access quantum computers through the cloud has increased rapidly in recent years. Despite still being Noisy Intermediate-Scale Quantum (NISQ) machines, modern quantum computers are now being actively employed for research and by numerous startups. Quantum algorithms typically produce probabilistic results, necessitating repeated execution to produce the desired outcomes. In order for the execution to begin from the specified ground state each time and for the results of the prior execution not to interfere with the results of the subsequent execution, the reset mechanism must be performed between each iteration to effectively reset the qubits. However, due to noise and errors in quantum computers and specifically these reset mechanisms, a noisy reset operation may lead to systematic errors in the overall computation, as well as potential security and privacy vulnerabilities of information leakage. To counter this issue, we thoroughly examine the state leakage problem in quantum computing, and then propose a solution by employing the classical and quantum one-time pads before the reset mechanism to prevent the state leakage, which works by randomly applying simple gates for each execution of the circuit. In addition, this work explores conditions under which the classical one-time pad, which uses fewer resources, is sufficient to protect state leakage. Finally, we study the role of various errors in state leakage, by evaluating the degrees of leakage under different error levels of gate, measurement, and sampling errors. Our findings offer new perspectives on the design of reset mechanisms and secure quantum computing systems.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "11 pages, 7 figures. In Proceedings of the IEEE International Symposium on Hardware Oriented Security and Trust (HOST) 2024"
    },
    {
        "paper id": "2402.04268",
        "abstract url": "https://arxiv.org/abs/2402.04268",
        "title": "ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning",
        "rating": -2,
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Designing de novo proteins beyond those found in nature holds significant promise for advancements in both scientific and engineering applications. Current methodologies for protein design often rely on AI-based models, such as surrogate models that address end-to-end problems by linking protein structure to material properties or vice versa. However, these models frequently focus on specific material objectives or structural properties, limiting their flexibility when incorporating out-of-domain knowledge into the design process or comprehensive data analysis is required. In this study, we introduce ProtAgents, a platform for de novo protein design based on Large Language Models (LLMs), where multiple AI agents with distinct capabilities collaboratively address complex tasks within a dynamic environment. The versatility in agent development allows for expertise in diverse domains, including knowledge retrieval, protein structure analysis, physics-based simulations, and results analysis. The dynamic collaboration between agents, empowered by LLMs, provides a versatile approach to tackling protein design and analysis problems, as demonstrated through diverse examples in this study. The problems of interest encompass designing new proteins, analyzing protein structures and obtaining new first-principles data -- natural vibrational frequencies -- via physics simulations. The concerted effort of the system allows for powerful automated and synergistic design of de novo proteins with targeted mechanical properties. The flexibility in designing the agents, on one hand, and their capacity in autonomous collaboration through the dynamic LLM-based multi-agent environment on the other hand, unleashes great potentials of LLMs in addressing multi-objective materials problems and opens up new avenues for autonomous materials discovery and design.",
        "subjects": [
            "cond-mat.soft"
        ],
        "comment": null
    },
    {
        "paper id": "2402.09438",
        "abstract url": "https://arxiv.org/abs/2402.09438",
        "title": "Subject-Independent Deep Architecture for EEG-based Motor Imagery Classification",
        "rating": -2,
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "Motor imagery (MI) classification based on electroencephalogram (EEG) is a widely-used technique in non-invasive brain-computer interface (BCI) systems. Since EEG recordings suffer from heterogeneity across subjects and labeled data insufficiency, designing a classifier that performs the MI independently from the subject with limited labeled samples would be desirable. To overcome these limitations, we propose a novel subject-independent semi-supervised deep architecture (SSDA). The proposed SSDA consists of two parts: an unsupervised and a supervised element. The training set contains both labeled and unlabeled data samples from multiple subjects. First, the unsupervised part, known as the columnar spatiotemporal auto-encoder (CST-AE), extracts latent features from all the training samples by maximizing the similarity between the original and reconstructed data. A dimensional scaling approach is employed to reduce the dimensionality of the representations while preserving their discriminability. Second, a supervised part learns a classifier based on the labeled training samples using the latent features acquired in the unsupervised part. Moreover, we employ center loss in the supervised part to minimize the embedding space distance of each point in a class to its center. The model optimizes both parts of the network in an end-to-end fashion. The performance of the proposed SSDA is evaluated on test subjects who were not seen by the model during the training phase. To assess the performance, we use two benchmark EEG-based MI task datasets. The results demonstrate that SSDA outperforms state-of-the-art methods and that a small number of labeled training samples can be sufficient for strong classification performance.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15422",
        "abstract url": "https://arxiv.org/abs/2401.15422",
        "title": "A Survey on Data Augmentation in Large Model Era",
        "rating": -2.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large models, encompassing large language and diffusion models, have shown exceptional promise in approximating human-level intelligence, garnering significant interest from both academic and industrial spheres. However, the training of these large models necessitates vast quantities of high-quality data, and with continuous updates to these models, the existing reservoir of high-quality data may soon be depleted. This challenge has catalyzed a surge in research focused on data augmentation methods. Leveraging large models, these data augmentation techniques have outperformed traditional approaches. This paper offers an exhaustive review of large model-driven data augmentation methods, adopting a comprehensive perspective. We begin by establishing a classification of relevant studies into three main categories: image augmentation, text augmentation, and paired data augmentation. Following this, we delve into various data post-processing techniques pertinent to large model-based data augmentation. Our discussion then expands to encompass the array of applications for these data augmentation methods within natural language processing, computer vision, and audio signal processing. We proceed to evaluate the successes and limitations of large model-based data augmentation across different scenarios. Concluding our review, we highlight prospective challenges and avenues for future exploration in the field of data augmentation. Our objective is to furnish researchers with critical insights, ultimately contributing to the advancement of more sophisticated large models. We consistently maintain the related open-source materials at: https://github.com/MLGroup-JLU/LLM-data-aug-survey.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "33 pages; https://github.com/MLGroup-JLU/LLM-data-aug-survey"
    },
    {
        "paper id": "2401.15469",
        "abstract url": "https://arxiv.org/abs/2401.15469",
        "title": "Wind speed super-resolution and validation: from ERA5 to CERRA via diffusion models",
        "rating": -2.5,
        "keywords": [
            [
                "diffusion",
                "super-resolution"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Copernicus Regional Reanalysis for Europe, CERRA, is a high-resolution regional reanalysis dataset for the European domain. In recent years it has shown significant utility across various climate-related tasks, ranging from forecasting and climate change research to renewable energy prediction, resource management, air quality risk assessment, and the forecasting of rare events, among others. Unfortunately, the availability of CERRA is lagging two years behind the current date, due to constraints in acquiring the requisite external data and the intensive computational demands inherent in its generation. As a solution, this paper introduces a novel method using diffusion models to approximate CERRA downscaling in a data-driven manner, without additional informations. By leveraging the lower resolution ERA5 dataset, which provides boundary conditions for CERRA, we approach this as a super-resolution task. Focusing on wind speed around Italy, our model, trained on existing CERRA data, shows promising results, closely mirroring original CERRA data. Validation with in-situ observations further confirms the model's accuracy in approximating ground measurements.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15324",
        "abstract url": "https://arxiv.org/abs/2401.15324",
        "title": "Neutrino Reconstruction in TRIDENT Based on Graph Neural Network",
        "rating": -3,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "TRopIcal DEep-sea Neutrino Telescope (TRIDENT) is a next-generation neutrino telescope to be located in the South China Sea. With a large detector volume and the use of advanced hybrid digital optical modules (hDOMs), TRIDENT aims to discover multiple astrophysical neutrino sources and probe all-flavor neutrino physics. The reconstruction resolution of primary neutrinos is on the critical path to these scientific goals. We have developed a novel reconstruction method based on graph neural network (GNN) for TRIDENT. In this paper, we present the reconstruction performance of the GNN-based approach on both track- and shower-like neutrino events in TRIDENT.",
        "subjects": [
            "hep-ex"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15472",
        "abstract url": "https://arxiv.org/abs/2401.15472",
        "title": "Temporal evolution in synthetic handwriting",
        "rating": -3,
        "keywords": [
            [
                "synthesizer"
            ],
            [
                "trajectory"
            ],
            [
                "biometric"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "New methods for generating synthetic handwriting images for biometric applications have recently been developed. The temporal evolution of handwriting from childhood to adulthood is usually left unexplored in these works. This paper proposes a novel methodology for including temporal evolution in a handwriting synthesizer by means of simplifying the text trajectory plan and handwriting dynamics. This is achieved through a tailored version of the kinematic theory of rapid human movements and the neuromotor inspired handwriting synthesizer. The realism of the proposed method has been evaluated by comparing the temporal evolution of real and synthetic samples both quantitatively and subjectively. The quantitative test is based on a visual perception algorithm that compares the letter variability and the number of strokes in the real and synthetic handwriting produced at different ages. In the subjective test, 30 people are asked to evaluate the perceived realism of the evolution of the synthetic handwriting.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published in Pattern Recognition"
    },
    {
        "paper id": "2401.15478",
        "abstract url": "https://arxiv.org/abs/2401.15478",
        "title": "Product Manifold Representations for Learning on Biological Pathways",
        "rating": -3,
        "keywords": [
            [
                "graph"
            ],
            [
                "Biological",
                "disease"
            ]
        ],
        "abstract": "Machine learning models that embed graphs in non-Euclidean spaces have shown substantial benefits in a variety of contexts, but their application has not been studied extensively in the biological domain, particularly with respect to biological pathway graphs. Such graphs exhibit a variety of complex network structures, presenting challenges to existing embedding approaches. Learning high-quality embeddings for biological pathway graphs is important for researchers looking to understand the underpinnings of disease and train high-quality predictive models on these networks. In this work, we investigate the effects of embedding pathway graphs in non-Euclidean mixed-curvature spaces and compare against traditional Euclidean graph representation learning models. We then train a supervised model using the learned node embeddings to predict missing protein-protein interactions in pathway graphs. We find large reductions in distortion and boosts on in-distribution edge prediction performance as a result of using mixed-curvature embeddings and their corresponding graph neural network models. However, we find that mixed-curvature representations underperform existing baselines on out-of-distribution edge prediction performance suggesting that these representations may overfit to the training graph topology. We provide our mixed-curvature product GCN code at https://github.com/mcneela/Mixed-Curvature-GCN and our pathway analysis code at https://github.com/mcneela/Mixed-Curvature-Pathways.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": "28 pages, 19 figures"
    },
    {
        "paper id": "2401.15562",
        "abstract url": "https://arxiv.org/abs/2401.15562",
        "title": "A Survey on Integrated Sensing and Communication with Intelligent Metasurfaces: Trends, Challenges, and Opportunities",
        "rating": -3,
        "keywords": [
            [
                "radar"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "The emergence of various technologies demanding both high data rates and precise sensing performance, such as autonomous vehicles and internet of things devices, has propelled an increasing popularity of integrated sensing and communication (ISAC) in recent years. ISAC offers an efficient framework for communication and sensing where both functionalities are carried out in a shared spectrum, utilizing the same hardware, beamformer and waveform design. At the same time, intelligent metasurfaces have been identified as an architectural enabler for the upcoming sixth-generation (6G) of wireless communication due to their ability to control the propagation environment in an energy-efficient manner. Due to the potential of metasurfaces to enhance both communication and sensing performance, numerous papers have explored the performance gains of using metasurfaces to improve ISAC. This survey reviews the existing literature on metasurface-assisted ISAC, detailing the associated challenges and opportunities. To provide a comprehensive overview, we commence by offering relevant background information on standalone metasurface-assisted communication and metasurface-assisted sensing systems, followed by a discussion on the fundamentals of ISAC. The core part of the paper then summarizes the state-of-the-art studies on metasurface-assisted ISAC with metasurfaces employed as separate entities placed between the transmitter and receiver, also known as reconfigurable intelligent surfaces, with an emphasis on its two levels of integration: radio-communications co-existence and dual-function radar-communications. We also review the current works in the area of holographic ISAC where metasurfaces are used to form part of ISAC transmitter. Within each category, the challenges, opportunities and future research directions are also highlighted.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to IEEE for possible publication"
    },
    {
        "paper id": "2401.15564",
        "abstract url": "https://arxiv.org/abs/2401.15564",
        "title": "Design of UAV flight state recognition and trajectory prediction system based on trajectory feature construction",
        "rating": -3,
        "keywords": [
            [
                "trajectory",
                "flight"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "With the impact of artificial intelligence on the traditional UAV industry, autonomous UAV flight has become a current hot research field. Based on the demand for research on critical technologies for autonomous flying UAVs, this paper addresses the field of flight state recognition and trajectory prediction of UAVs. This paper proposes a method to improve the accuracy of UAV trajectory prediction based on UAV flight state recognition and verifies it using two prediction models. Firstly, UAV flight data acquisition and data preprocessing are carried out; secondly, UAV flight trajectory features are extracted based on data fusion and a UAV flight state recognition model based on PCA-DAGSVM model is established; finally, two UAV flight trajectory prediction models are established and the trajectory prediction errors of the two prediction models are compared and analyzed after flight state recognition. The results show that: 1) the UAV flight state recognition model based on PCA-DAGSVM has good recognition effect. 2) compared with the traditional UAV trajectory prediction model, the prediction model based on flight state recognition can effectively reduce the prediction error.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17320",
        "abstract url": "https://arxiv.org/abs/2401.17320",
        "title": "Sigma-lognormal modeling of speech",
        "rating": -3,
        "keywords": [
            [
                "robotics"
            ],
            [
                "health"
            ]
        ],
        "abstract": "Human movement studies and analyses have been fundamental in many scientific domains, ranging from neuroscience to education, pattern recognition to robotics, health care to sports, and beyond. Previous speech motor models were proposed to understand how speech movement is produced and how the resulting speech varies when some parameters are changed. However, the inverse approach, in which the muscular response parameters and the subject's age are derived from real continuous speech, is not possible with such models. Instead, in the handwriting field, the kinematic theory of rapid human movements and its associated Sigma-lognormal model have been applied successfully to obtain the muscular response parameters. This work presents a speech kinematics based model that can be used to study, analyze, and reconstruct complex speech kinematics in a simplified manner. A method based on the kinematic theory of rapid human movements and its associated Sigma lognormal model are applied to describe and to parameterize the asymptotic impulse response of the neuromuscular networks involved in speech as a response to a neuromotor command. The method used to carry out transformations from formants to a movement observation is also presented. Experiments carried out with the (English) VTR TIMIT database and the (German) Saarbrucken Voice Database, including people of different ages, with and without laryngeal pathologies, corroborate the link between the extracted parameters and aging, on the one hand, and the proportion between the first and second formants required in applying the kinematic theory of rapid human movements, on the other. The results should drive innovative developments in the modeling and understanding of speech kinematics.",
        "subjects": [
            "q-bio.NC"
        ],
        "comment": "Published in Open Acces"
    },
    {
        "paper id": "2402.01724",
        "abstract url": "https://arxiv.org/abs/2402.01724",
        "title": "CERM: Context-aware Literature-based Discovery via Sentiment Analysis",
        "rating": -3,
        "keywords": [
            [
                "biomedical",
                "health"
            ],
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Driven by the abundance of biomedical publications, we introduce a sentiment analysis task to understand food-health relationship. Prior attempts to incorporate health into recipe recommendation and analysis systems have primarily focused on ingredient nutritional components or utilized basic computational models trained on curated labeled data. Enhanced models that capture the inherent relationship between food ingredients and biomedical concepts can be more beneficial for food-related research, given the wealth of information in biomedical texts. Considering the costly data labeling process, these models should effectively utilize both labeled and unlabeled data. This paper introduces Entity Relationship Sentiment Analysis (ERSA), a new task that captures the sentiment of a text based on an entity pair. ERSA extends the widely studied Aspect Based Sentiment Analysis (ABSA) task. Specifically, our study concentrates on the ERSA task applied to biomedical texts, focusing on (entity-entity) pairs of biomedical and food concepts. ERSA poses a significant challenge compared to traditional sentiment analysis tasks, as sentence sentiment may not align with entity relationship sentiment. Additionally, we propose CERM, a semi-supervised architecture that combines different word embeddings to enhance the encoding of the ERSA task. Experimental results showcase the model's efficiency across diverse learning scenarios.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15417",
        "abstract url": "https://arxiv.org/abs/2401.15417",
        "title": "Fault Diagnosis on Induction Motor using Machine Learning and Signal Processing",
        "rating": -3.5,
        "keywords": [
            [
                "Diagnosis"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The detection and identification of induction motor faults using machine learning and signal processing is a valuable approach to avoiding plant disturbances and shutdowns in the context of Industry 4.0. In this work, we present a study on the detection and identification of induction motor faults using machine learning and signal processing with MATLAB Simulink. We developed a model of a three-phase induction motor in MATLAB Simulink to generate healthy and faulty motor data. The data collected included stator currents, rotor currents, input power, slip, rotor speed, and efficiency. We generated four faults in the induction motor: open circuit fault, short circuit fault, overload, and broken rotor bars. We collected a total of 150,000 data points with a 60-40% ratio of healthy to faulty motor data. We applied Fast Fourier Transform (FFT) to detect and identify healthy and unhealthy conditions and added a distinctive feature in our data. The generated dataset was trained different machine learning models. On comparing the accuracy of the models on the test set, we concluded that the Decision Tree algorithm performed the best with an accuracy of about 92%. Our study contributes to the literature by providing a valuable approach to fault detection and classification with machine learning models for industrial applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "6 pages, 17 figures, 2 tables"
    },
    {
        "paper id": "2401.15318",
        "abstract url": "https://arxiv.org/abs/2401.15318",
        "title": "Gaussian Splashing: Dynamic Fluid Synthesis with Gaussian Splatting",
        "rating": -4,
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Synthesis"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "We demonstrate the feasibility of integrating physics-based animations of solids and fluids with 3D Gaussian Splatting (3DGS) to create novel effects in virtual scenes reconstructed using 3DGS. Leveraging the coherence of the Gaussian splatting and position-based dynamics (PBD) in the underlying representation, we manage rendering, view synthesis, and the dynamics of solids and fluids in a cohesive manner. Similar to Gaussian shader, we enhance each Gaussian kernel with an added normal, aligning the kernel's orientation with the surface normal to refine the PBD simulation. This approach effectively eliminates spiky noises that arise from rotational deformation in solids. It also allows us to integrate physically based rendering to augment the dynamic surface reflections on fluids. Consequently, our framework is capable of realistically reproducing surface highlights on dynamic fluids and facilitating interactions between scene objects and fluids from new views. For more information, please visit our project page at \\url{https://amysteriouscat.github.io/GaussianSplashing/}.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15414",
        "abstract url": "https://arxiv.org/abs/2401.15414",
        "title": "An Implicit Physical Face Model Driven by Expression and Style",
        "rating": -5,
        "keywords": [
            [
                "3D"
            ],
            [
                "synthesizing"
            ],
            [
                "facial"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D facial animation is often produced by manipulating facial deformation models (or rigs), that are traditionally parameterized by expression controls. A key component that is usually overlooked is expression 'style', as in, how a particular expression is performed. Although it is common to define a semantic basis of expressions that characters can perform, most characters perform each expression in their own style. To date, style is usually entangled with the expression, and it is not possible to transfer the style of one character to another when considering facial animation. We present a new face model, based on a data-driven implicit neural physics model, that can be driven by both expression and style separately. At the core, we present a framework for learning implicit physics-based actuations for multiple subjects simultaneously, trained on a few arbitrary performance capture sequences from a small set of identities. Once trained, our method allows generalized physics-based facial animation for any of the trained identities, extending to unseen performances. Furthermore, it grants control over the animation style, enabling style transfer from one character to another or blending styles of different characters. Lastly, as a physics-based model, it is capable of synthesizing physical effects, such as collision handling, setting our method apart from conventional approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to SIGGRAPH ASIA 2023. Project page: https://studios.disneyresearch.com/2023/11/29/an-implicit-physical-face-model-driven-by-expression-and-style/ Video: https://www.youtube.com/watch?v=-qM_XUv-JhA&t"
    },
    {
        "paper id": "2401.15541",
        "abstract url": "https://arxiv.org/abs/2401.15541",
        "title": "Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO Satellite Learning",
        "rating": -5,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "IoT"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "In the ambitious realm of space AI, the integration of federated learning (FL) with low Earth orbit (LEO) satellite constellations holds immense promise. However, many challenges persist in terms of feasibility, learning efficiency, and convergence. These hurdles stem from the bottleneck in communication, characterized by sporadic and irregular connectivity between LEO satellites and ground stations, coupled with the limited computation capability of satellite edge computing (SEC). This paper proposes a novel FL-SEC framework that empowers LEO satellites to execute large-scale machine learning (ML) tasks onboard efficiently. Its key components include i) personalized learning via divide-and-conquer, which identifies and eliminates redundant satellite images and converts complex multi-class classification problems to simple binary classification, enabling rapid and energy-efficient training of lightweight ML models suitable for IoT/edge devices on satellites; ii) orbital model retraining, which generates an aggregated \"orbital model\" per orbit and retrains it before sending to the ground station, significantly reducing the required communication rounds. We conducted experiments using Jetson Nano, an edge device closely mimicking the limited compute on LEO satellites, and a real satellite dataset. The results underscore the effectiveness of our approach, highlighting SEC's ability to run lightweight ML models on real and high-resolution satellite imagery. Our approach dramatically reduces FL convergence time by nearly 30 times, and satellite energy consumption down to as low as 1.38 watts, all while maintaining an exceptional accuracy of up to 96%.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15308",
        "abstract url": "https://arxiv.org/abs/2401.15308",
        "title": "Construction of Locally Repairable Array Codes with Optimal Repair Bandwidth under the Rack-Aware Storage Model",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we discuss codes for distributed storage systems with hierarchical repair properties. Specifically, we devote attention to the repair problem of the rack-aware storage model with locality, aiming to enhance the system's ability to repair a small number of erasures within each rack by locality and efficiently handling a rack erasure with a small repair bandwidth. By employing the regenerating coding technique, we construct a family of array codes with $(r,u-r+1)$-locality, where the $u$ nodes of each repair set are systematically organized into a rack. When the number of failures is less than $u - r + 1$, these failures can be repaired without counting the system bandwidth. In cases where the number of failures exceeds the locality, the failed nodes within a single rack can be recovered with optimal cross-rack bandwidth.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15317",
        "abstract url": "https://arxiv.org/abs/2401.15317",
        "title": "Floorplanning of VLSI by Mixed-Variable Optimization",
        "rating": -10,
        "keywords": [],
        "abstract": "By formulating the floorplanning of VLSI as a mixed-variable optimization problem, this paper proposes to solve it by memetic algorithms, where the discrete orientation variables are addressed by the distribution evolutionary algorithm based on a population of probability model (DEA-PPM), and the continuous coordination variables are optimized by the conjugate sub-gradient algorithm (CSA). Accordingly, the fixed-outline floorplanning algorithm based on CSA and DEA-PPM (FFA-CD) and the floorplanning algorithm with golden section strategy (FA-GSS) are proposed for the floorplanning problems with and without fixed-outline constraint. %FF-CD is committed to optimizing wirelength targets within a fixed profile. FA-GSS uses the Golden Section strategy to optimize both wirelength and area targets. The CSA is used to solve the proposed non-smooth optimization model, and the DEA-PPM is used to explore the module rotation scheme to enhance the flexibility of the algorithm. Numerical experiments on GSRC test circuits show that the proposed algorithms are superior to some celebrated B*-tree based floorplanning algorithms, and are expected to be applied to large-scale floorplanning problems due to their low time complexity.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15332",
        "abstract url": "https://arxiv.org/abs/2401.15332",
        "title": "Efficient yet Accurate End-to-End SC Accelerator Design",
        "rating": -10,
        "keywords": [],
        "abstract": "Providing end-to-end stochastic computing (SC) neural network acceleration for state-of-the-art (SOTA) models has become an increasingly challenging task, requiring the pursuit of accuracy while maintaining efficiency. It also necessitates flexible support for different types and sizes of operations in models by end-to-end SC circuits. In this paper, we summarize our recent research on end-to-end SC neural network acceleration. We introduce an accurate end-to-end SC accelerator based on a deterministic coding and sorting network. In addition, we propose an SC-friendly model that combines low-precision data paths with high-precision residuals. We introduce approximate computing techniques to optimize SC nonlinear adders and provide some new SC designs for arithmetic operations required by SOTA models. Overall, our approach allows for further significant improvements in circuit efficiency, flexibility, and compatibility through circuit design and model co-optimization. The results demonstrate that the proposed end-to-end SC architecture achieves accurate and efficient neural network acceleration while flexibly accommodating model requirements, showcasing the potential of SC in neural network acceleration.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15343",
        "abstract url": "https://arxiv.org/abs/2401.15343",
        "title": "Optimal Quality and Efficiency in Adaptive Live Streaming with JND-Aware Low latency Encoding",
        "rating": -10,
        "keywords": [],
        "abstract": "In HTTP adaptive live streaming applications, video segments are encoded at a fixed set of bitrate-resolution pairs known as bitrate ladder. Live encoders use the fastest available encoding configuration, referred to as preset, to ensure the minimum possible latency in video encoding. However, an optimized preset and optimized number of CPU threads for each encoding instance may result in (i) increased quality and (ii) efficient CPU utilization while encoding. For low latency live encoders, the encoding speed is expected to be more than or equal to the video framerate. To this light, this paper introduces a Just Noticeable Difference (JND)-Aware Low latency Encoding Scheme (JALE), which uses random forest-based models to jointly determine the optimized encoder preset and thread count for each representation, based on video complexity features, the target encoding speed, the total number of available CPU threads, and the target encoder. Experimental results show that, on average, JALE yield a quality improvement of 1.32 dB PSNR and 5.38 VMAF points with the same bitrate, compared to the fastest preset encoding of the HTTP Live Streaming (HLS) bitrate ladder using x265 HEVC open-source encoder with eight CPU threads used for each representation. These enhancements are achieved while maintaining the desired encoding speed. Furthermore, on average, JALE results in an overall storage reduction of 72.70 %, a reduction in the total number of CPU threads used by 63.83 %, and a 37.87 % reduction in the overall encoding time, considering a JND of six VMAF points.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "2024 Mile High Video (MHV)"
    },
    {
        "paper id": "2401.15346",
        "abstract url": "https://arxiv.org/abs/2401.15346",
        "title": "Energy-efficient Adaptive Video Streaming with Latency-Aware Dynamic Resolution Encoding",
        "rating": -10,
        "keywords": [],
        "abstract": "Traditional per-title encoding schemes aim to optimize encoding resolutions to deliver the highest perceptual quality for each representation. However, keeping the encoding time within an acceptable threshold for a smooth user experience is important to reduce the carbon footprint and energy consumption on encoding servers in video streaming applications. Toward this realization, we introduce an encoding latency-a ware dynamic resolution encoding scheme (LADRE) for adaptive video streaming applications. LADRE determines the encoding resolution for each target bitrate by utilizing a random forest-based prediction model for every video segment based on spatiotemporal features and the acceptable target latency. Experimental results show that LADRE achieves an overall average quality improvement of 0.58 dB PSNR and 0.43 dB XPSNR while maintaining the same bitrate, compared to the HTTP Live Streaming (HLS) bitrate ladder encoding of 200 s segments using the VVenC encoder, when the encoding latency for each representation is set to remain below the 200 s threshold. This is accompanied by an 84.17 % reduction in overall encoding energy consumption.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "2024 Mile High Video (MHV)"
    },
    {
        "paper id": "2401.15352",
        "abstract url": "https://arxiv.org/abs/2401.15352",
        "title": "Randomized query composition and product distributions",
        "rating": -10,
        "keywords": [],
        "abstract": "Let R_eps denote randomized query complexity for error probability eps, and R:=R_{1/3}. In this work we investigate whether a perfect composition theorem R(f o g^n)=Omega(R(f).R(g)) holds for a relation f in {0,1}^n * S and a total inner function g:{0,1}^m \\to {0, 1}. Let D^(prod) denote the maximum distributional query complexity with respect to any product (over variables) distribution. In this work we show the composition theorem R(f o g^n)=Omega(R(f).D^{prod}(g)) up to logarithmic factors. In light of the minimax theorem which states that R(g) is the maximum distributional complexity of g over any distribution, our result makes progress towards answering the composition question. We prove our result by means of a complexity measure R^(prod)_(eps) that we define for total Boolean functions. We show it to be equivalent (up to logarithmic factors) to the sabotage complexity measure RS() defined by Ben-David and Kothari (ICALP 2019): RS(g) = Theta(R^(prod)_(1/3)(g)) (up to log factors). We ask if our bound RS(g) = Omega(D^(prod)(g)) (up to log factors) is tight. We answer this question in the negative, by showing that for the NAND tree function, sabotage complexity is polynomially larger than D^(prod). Our proof yields an alternative and different derivation of the tight lower bound on the bounded error randomized query complexity of the NAND tree function (originally proved by Santha in 1985), which may be of independent interest. Our result gives an explicit polynomial separation between R and D^(prod) which, to our knowledge, was not known prior to our work.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "Accepted to STACS 2024"
    },
    {
        "paper id": "2401.15355",
        "abstract url": "https://arxiv.org/abs/2401.15355",
        "title": "Improved bounds on the interactive capacity via error pattern analysis",
        "rating": -10,
        "keywords": [],
        "abstract": "Any interactive protocol between a pair of parties can be reliably simulated in the presence of noise with a multiplicative overhead on the number of rounds (Schulman 1996). The reciprocal of the best (least) overhead is called the interactive capacity of the noisy channel. In this work, we present lower bounds on the interactive capacity of the binary erasure channel. Our lower bound improves the best known bound due to Ben-Yishai et al. 2021 by roughly a factor of 1.75. The improvement is due to a tighter analysis of the correctness of the simulation protocol using error pattern analysis. More precisely, instead of using the well-known technique of bounding the least number of erasures needed to make the simulation fail, we identify and bound the probability of specific erasure patterns causing simulation failure. We remark that error pattern analysis can be useful in solving other problems involving stochastic noise, such as bounding the interactive capacity of different channels.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Shorter version accepted at ISIT 2024"
    },
    {
        "paper id": "2401.15381",
        "abstract url": "https://arxiv.org/abs/2401.15381",
        "title": "Golay Complementary Sequences of Arbitrary Length and Asymptotic Existence of Hadamard Matrices",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we construct $4$-phase Golay complementary sequence (GCS) set of cardinality $2^{3+\\lceil \\log_2 r \\rceil}$ with arbitrary sequence length $n$, where the $10^{13}$-base expansion of $n$ has $r$ nonzero digits. Specifically, the GCS octets (eight sequences) cover all the lengths no greater than $10^{13}$. Besides, based on the representation theory of signed symmetric group, we construct Hadamard matrices from some special GCS to improve their asymptotic existence: there exist Hadamard matrices of order $2^t m$ for any odd number $m$, where $t = 6\\lfloor \\frac{1}{40}\\log_{2}m\\rfloor + 10$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15384",
        "abstract url": "https://arxiv.org/abs/2401.15384",
        "title": "Half-positional $\u03c9$-regular languages",
        "rating": -10,
        "keywords": [],
        "abstract": "In the context of two-player games over graphs, a language $L$ is called half-positional if, in all games using $L$ as winning objective, the protagonist can play optimally using positional strategies, that is, strategies that do not depend on the history of the play. In this work, we describe the class of parity automata recognising half-positional languages, providing a complete characterisation of half-positionality for $\u03c9$-regular languages. As corollaries, we establish decidability of half-positionality in polynomial time, finite-to-infinite and 1-to-2-players lifts, and show the closure under union of prefix-independent half-positional objectives, answering a conjecture by Kopczy\u0144ski.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15436",
        "abstract url": "https://arxiv.org/abs/2401.15436",
        "title": "A simple and complete discrete exterior calculus on general polygonal meshes",
        "rating": -10,
        "keywords": [],
        "abstract": "Discrete exterior calculus (DEC) offers a coordinate-free discretization of exterior calculus especially suited for computations on curved spaces. In this work, we present an extended version of DEC on surface meshes formed by general polygons that bypasses the need for combinatorial subdivision and does not involve any dual mesh. At its core, our approach introduces a new polygonal wedge product that is compatible with the discrete exterior derivative in the sense that it satisfies the Leibniz product rule. Based on the discrete wedge product, we then derive a novel primal-to-primal Hodge star operator. Combining these three `basic operators' we then define new discrete versions of the contraction operator and Lie derivative, codifferential and Laplace operator. We discuss the numerical convergence of each one of these proposed operators and compare them to existing DEC methods. Finally, we show simple applications of our operators on Helmholtz-Hodge decomposition, Laplacian surface fairing, and Lie advection of functions and vector fields on meshes formed by general polygons.",
        "subjects": [
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15453",
        "abstract url": "https://arxiv.org/abs/2401.15453",
        "title": "Bayesian Inference Accelerator for Spiking Neural Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Bayesian neural networks offer better estimates of model uncertainty compared to frequentist networks. However, inference involving Bayesian models requires multiple instantiations or sampling of the network parameters, requiring significant computational resources. Compared to traditional deep learning networks, spiking neural networks (SNNs) have the potential to reduce computational area and power, thanks to their event-driven and spike-based computational framework. Most works in literature either address frequentist SNN models or non-spiking Bayesian neural networks. In this work, we demonstrate an optimization framework for developing and implementing efficient Bayesian SNNs in hardware by additionally restricting network weights to be binary-valued to further decrease power and area consumption. We demonstrate accuracies comparable to Bayesian binary networks with full-precision Bernoulli parameters, while requiring up to $25\\times$ less spikes than equivalent binary SNN implementations. We show the feasibility of the design by mapping it onto Zynq-7000, a lightweight SoC, and achieve a $6.5 \\times$ improvement in GOPS/DSP while utilizing up to 30 times less power compared to the state-of-the-art.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "Submitted and Accepted in ISCAS 2024"
    },
    {
        "paper id": "2401.15456",
        "abstract url": "https://arxiv.org/abs/2401.15456",
        "title": "Product Mixing in Compact Lie Groups",
        "rating": -10,
        "keywords": [],
        "abstract": "If $G$ is a group, we say a subset $S$ of $G$ is product-free if the equation $xy=z$ has no solutions with $x,y,z \\in S$. For $D \\in \\mathbb{N}$, a group $G$ is said to be $D$-quasirandom if the minimal dimension of a nontrivial complex irreducible representation of $G$ is at least $D$. Gowers showed that in a $D$-quasirandom finite group $G$, the maximal size of a product-free set is at most $|G|/D^{1/3}$. This disproved a longstanding conjecture of Babai and S\u00f3s from 1985. For the special unitary group, $G=SU(n)$, Gowers observed that his argument yields an upper bound of $n^{-1/3}$ on the measure of a measurable product-free subset. In this paper, we improve Gowers' upper bound to $\\exp(-cn^{1/3})$, where $c>0$ is an absolute constant. In fact, we establish something stronger, namely, product-mixing for measurable subsets of $SU(n)$ with measure at least $\\exp(-cn^{1/3})$; for this product-mixing result, the $n^{1/3}$ in the exponent is sharp. Our approach involves introducing novel hypercontractive inequalities, which imply that the non-Abelian Fourier spectrum of the indicator function of a small set concentrates on high-dimensional irreducible representations. Our hypercontractive inequalities are obtained via methods from representation theory, harmonic analysis, random matrix theory and differential geometry. We generalize our hypercontractive inequalities from $SU(n)$ to an arbitrary $D$-quasirandom compact connected Lie group for $D$ at least an absolute constant, thereby extending our results on product-free sets to such groups. We also demonstrate various other applications of our inequalities to geometry (viz., non-Abelian Brunn-Minkowski type inequalities), mixing times, and the theory of growth in compact Lie groups.",
        "subjects": [
            "math.CO"
        ],
        "comment": "References updated"
    },
    {
        "paper id": "2401.15459",
        "abstract url": "https://arxiv.org/abs/2401.15459",
        "title": "Multi-LLM Collaboration + Data-Centric Innovation = 2x Better Vulnerability Repair",
        "rating": -10,
        "keywords": [],
        "abstract": "The advances of deep learning (DL) have paved the way for automatic software vulnerability repair approaches, which effectively learn the mapping from the vulnerable code to the fixed code. Nevertheless, existing DL-based vulnerability repair methods face notable limitations: 1) they struggle to handle lengthy vulnerable code, 2) they treat code as natural language texts, neglecting its inherent structure, and 3) they do not tap into the valuable expert knowledge present in the expert system. To address this, we propose VulMaster, a Transformer-based neural network model that excels at generating vulnerability repairs through data-centric innovation. Specifically, VulMaster introduces the utilization and combination of various types of input data, including complete vulnerable code of any size, vulnerable code structures, and expert knowledge from the CWE system. Additionally, VulMaster leverages the collaboration between two Large Language Models (LLMs), CodeT5 and ChatGPT: CodeT5 acts as the customizable backbone LLM, fine-tuned with the training data, while ChatGPT supplements by providing missing relevant inputs to CodeT5. We evaluated VulMaster on a real-world C/C++ vulnerability repair dataset comprising 1,754 projects with 5,800 vulnerable functions. The experimental results demonstrated that VulMaster exhibits substantial improvements compared to the learning-based state-of-the-art vulnerability repair approach. Specifically, VulMaster improves the EM, BLEU, and CodeBLEU scores from 10.2\\% to 20.0\\%, 21.3\\% to 29.3\\%, and 32.5\\% to 40.9\\%, respectively.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted in the ICSE 2024 Research Track with a different title \"Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by Broadening Input Ranges and Sources\""
    },
    {
        "paper id": "2401.15462",
        "abstract url": "https://arxiv.org/abs/2401.15462",
        "title": "On the monotonicity of discrete entropy for log-concave random vectors on $\\mathbb{Z}^d$",
        "rating": -10,
        "keywords": [],
        "abstract": "We prove the following type of discrete entropy monotonicity for isotropic log-concave sums of independent identically distributed random vectors $X_1,\\dots,X_{n+1}$ on $\\mathbb{Z}^d$: $$ H(X_1+\\cdots+X_{n+1}) \\geq H(X_1+\\cdots+X_{n}) + \\frac{d}{2}\\log{\\Bigl(\\frac{n+1}{n}\\Bigr)} +o(1), $$ where $o(1)$ vanishes as $H(X_1) \\to \\infty$. Moreover, for the $o(1)$-term we obtain a rate of convergence $ O\\Bigl({H(X_1)}{e^{-\\frac{1}{d}H(X_1)}}\\Bigr)$, where the implied constants depend on $d$ and $n$. This generalizes to $\\mathbb{Z}^d$ the one-dimensional result of the second named author (2023). As in dimension one, our strategy is to establish that the discrete entropy $H(X_1+\\cdots+X_{n})$ is close to the differential (continuous) entropy $h(X_1+U_1+\\cdots+X_{n}+U_{n})$, where $U_1,\\dots, U_n$ are independent and identically distributed uniform random vectors on $[0,1]^d$ and to apply the theorem of Artstein, Ball, Barthe and Naor (2004) on the monotonicity of differential entropy. However, in dimension $d\\ge2$, more involved tools from convex geometry are needed because a suitable position is required. We show that for a log-concave function on $\\mathbb{R}^d$ in isotropic position, its integral, its barycenter and its covariance matrix are close to their discrete counterparts. One of our technical tools is a discrete analogue to the upper bound on the isotropic constant of a log-concave function, which generalises a result of Bobkov, Marsiglietti and Melbourne (2022) and may be of independent interest.",
        "subjects": [
            "math.PR"
        ],
        "comment": "24 pages, no figures"
    },
    {
        "paper id": "2401.15468",
        "abstract url": "https://arxiv.org/abs/2401.15468",
        "title": "Large Language Model for Vulnerability Detection: Emerging Results and Future Directions",
        "rating": -10,
        "keywords": [],
        "abstract": "Previous learning-based vulnerability detection methods relied on either medium-sized pre-trained models or smaller neural networks from scratch. Recent advancements in Large Pre-Trained Language Models (LLMs) have showcased remarkable few-shot learning capabilities in various tasks. However, the effectiveness of LLMs in detecting software vulnerabilities is largely unexplored. This paper aims to bridge this gap by exploring how LLMs perform with various prompts, particularly focusing on two state-of-the-art LLMs: GPT-3.5 and GPT-4. Our experimental results showed that GPT-3.5 achieves competitive performance with the prior state-of-the-art vulnerability detection approach and GPT-4 consistently outperformed the state-of-the-art.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted in the New Ideas and Emerging Results Track at ICSE 2024"
    },
    {
        "paper id": "2401.15475",
        "abstract url": "https://arxiv.org/abs/2401.15475",
        "title": "Epidemic Population Games And Perturbed Best Response Dynamics",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper proposes an approach to mitigate epidemic spread in a population of strategic agents by encouraging safer behaviors through carefully designed rewards. These rewards, which vary according to the state of the epidemic, are ascribed by a dynamic payoff mechanism we seek to design. We use a modified SIRS model to track how the epidemic progresses in response to the population's agents strategic choices. By employing perturbed best response evolutionary dynamics to model the population's strategic behavior, we extend previous related work so as to allow for noise in the agents' perceptions of the rewards and intrinsic costs of the available strategies. Central to our approach is the use of system-theoretic methods and passivity concepts to obtain a Lyapunov function, ensuring the global asymptotic stability of an endemic equilibrium with minimized infection prevalence, under budget constraints. We use the Lyapunov function to construct anytime upper bounds for the size of the population's infectious fraction. For a class of one-parameter perturbed best response models, we propose a method to learn the model's parameter from data.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15479",
        "abstract url": "https://arxiv.org/abs/2401.15479",
        "title": "Navigating the Post-API Dilemma | Search Engine Results Pages Present a Biased View of Social Media Data",
        "rating": -10,
        "keywords": [],
        "abstract": "Recent decisions to discontinue access to social media APIs are having detrimental effects on Internet research and the field of computational social science as a whole. This lack of access to data has been dubbed the Post-API era of Internet research. Fortunately, popular search engines have the means to crawl, capture, and surface social media data on their Search Engine Results Pages (SERP) if provided the proper search query, and may provide a solution to this dilemma. In the present work we ask: does SERP provide a complete and unbiased sample of social media data? Is SERP a viable alternative to direct API-access? To answer these questions, we perform a comparative analysis between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We find that SERP results are highly biased in favor of popular posts; against political, pornographic, and vulgar posts; are more positive in their sentiment; and have large topical gaps. Overall, we conclude that SERP is not a viable alternative to social media API access.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Proceedings of the ACM Web Conference 2024 (WWW '24)"
    },
    {
        "paper id": "2401.15481",
        "abstract url": "https://arxiv.org/abs/2401.15481",
        "title": "BugsInPy: A Database of Existing Bugs in Python Programs to Enable Controlled Testing and Debugging Studies",
        "rating": -10,
        "keywords": [],
        "abstract": "The 2019 edition of Stack Overflow developer survey highlights that, for the first time, Python outperformed Java in terms of popularity. The gap between Python and Java further widened in the 2020 edition of the survey. Unfortunately, despite the rapid increase in Python's popularity, there are not many testing and debugging tools that are designed for Python. This is in stark contrast with the abundance of testing and debugging tools for Java. Thus, there is a need to push research on tools that can help Python developers. One factor that contributed to the rapid growth of Java testing and debugging tools is the availability of benchmarks. A popular benchmark is the Defects4J benchmark; its initial version contained 357 real bugs from 5 real-world Java programs. Each bug comes with a test suite that can expose the bug. Defects4J has been used by hundreds of testing and debugging studies and has helped to push the frontier of research in these directions. In this project, inspired by Defects4J, we create another benchmark database and tool that contain 493 real bugs from 17 real-world Python programs. We hope our benchmark can help catalyze future work on testing and debugging tools that work on Python programs.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15484",
        "abstract url": "https://arxiv.org/abs/2401.15484",
        "title": "R$\\times$R: Rapid eXploration for Reinforcement Learning via Sampling-based Reset Distributions and Imitation Pre-training",
        "rating": -10,
        "keywords": [],
        "abstract": "We present a method for enabling Reinforcement Learning of motor control policies for complex skills such as dexterous manipulation. We posit that a key difficulty for training such policies is the difficulty of exploring the problem state space, as the accessible and useful regions of this space form a complex structure along manifolds of the original high-dimensional state space. This work presents a method to enable and support exploration with Sampling-based Planning. We use a generally applicable non-holonomic Rapidly-exploring Random Trees algorithm and present multiple methods to use the resulting structure to bootstrap model-free Reinforcement Learning. Our method is effective at learning various challenging dexterous motor control skills of higher difficulty than previously shown. In particular, we achieve dexterous in-hand manipulation of complex objects while simultaneously securing the object without the use of passive support surfaces. These policies also transfer effectively to real robots. A number of example videos can also be found on the project website: https://sbrl.cs.columbia.edu",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20 pages, 14 figures, submitted to Autonomous Robots, RSS 2023 Special Issue. arXiv admin note: substantial text overlap with arXiv:2303.03486"
    },
    {
        "paper id": "2401.15486",
        "abstract url": "https://arxiv.org/abs/2401.15486",
        "title": "Pulse-Width Modulation Technique With Harmonic Injection in the Modulating Wave and Discontinuous Frequency Modulation for the Carrier Wave for Multilevel Inverters: An Application to the Reduction of Acoustic Noise in Induction Motors",
        "rating": -10,
        "keywords": [],
        "abstract": "An implementation of a harmonic injection pulse width modulation frequency-modulated triangular carrier (HIPWM-FMTC) control strategy applied to a multilevel power inverter feeding an asynchronous motor is presented. The aim was to justify the reduction in acoustic noise emitted by the machine compared with other strategies in the technical literature. In addition, we checked how the THD at the inverter output was reduced compared to the other control techniques used as a reference. The proposed strategy is based on frequency modulation of the triangular carrier. The main advantage of the proposed method is that only one control parameter is required for modifying the electrical spectrum. Therefore, the mechanical natural frequencies and spatial harmonics of the machine can be avoided, and acoustic noise can be reduced. The effectiveness of the technique was demonstrated after laboratory validation by comparing the acoustic results for a 1 kW motor. The results obtained from the laboratory tests are presented and compared with those of other acoustic measurements using different PWM strategies.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15492",
        "abstract url": "https://arxiv.org/abs/2401.15492",
        "title": "Cholesky-like Preconditioner for Hodge Laplacians via Heavy Collapsible Subcomplex",
        "rating": -10,
        "keywords": [],
        "abstract": "Techniques based on $k$-th order Hodge Laplacian operators $L_k$ are widely used to describe the topology as well as the governing dynamics of high-order systems modeled as simplicial complexes. In all of them, it is required to solve a number of least square problems with $L_k$ as coefficient matrix, for example in order to compute some portions of the spectrum or integrate the dynamical system. In this work, we introduce the notion of optimal collapsible subcomplex and we present a fast combinatorial algorithm for the computation of a sparse Cholesky-like preconditioner for $L_k$ that exploits the topological structure of the simplicial complex. The performance of the preconditioner is tested for conjugate gradient method for least square problems (CGLS) on a variety of simplicial complexes with different dimensions and edge densities. We show that, for sparse simplicial complexes, the new preconditioner reduces significantly the condition number of $L_k$ and performs better than the standard incomplete Cholesky factorization.",
        "subjects": [
            "math.NA"
        ],
        "comment": "22 pages, 8 figures"
    },
    {
        "paper id": "2401.15495",
        "abstract url": "https://arxiv.org/abs/2401.15495",
        "title": "Nobody Expects a Differential Equation: Minimum Energy-Per-Bit for the Gaussian Relay Channel with Rank-1 Linear Relaying",
        "rating": -10,
        "keywords": [],
        "abstract": "Motivated by the design of low-complexity low-power coding solutions for the Gaussian relay channel, this work presents an upper bound on the minimum energy-per-bit achievable on the Gaussian relay channel using rank-1 linear relaying. Our study addresses high-dimensional relay codes and presents bounds that outperform prior known bounds using 2-dimensional schemes. A novelty of our analysis ties the optimization problem at hand to the solution of a certain differential equation which, in turn, leads to a low energy-per-bit achievable scheme.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to the IEEE International Symposium on Information Theory, 2024. 13 pages, 1 figure"
    },
    {
        "paper id": "2401.15502",
        "abstract url": "https://arxiv.org/abs/2401.15502",
        "title": "Differentially private Bayesian tests",
        "rating": -10,
        "keywords": [],
        "abstract": "Differential privacy has emerged as an significant cornerstone in the realm of scientific hypothesis testing utilizing confidential data. In reporting scientific discoveries, Bayesian tests are widely adopted since they effectively circumnavigate the key criticisms of P-values, namely, lack of interpretability and inability to quantify evidence in support of the competing hypotheses. We present a novel differentially private Bayesian hypotheses testing framework that arise naturally under a principled data generative mechanism, inherently maintaining the interpretability of the resulting inferences. Furthermore, by focusing on differentially private Bayes factors based on widely used test statistics, we circumvent the need to model the complete data generative mechanism and ensure substantial computational benefits. We also provide a set of sufficient conditions to establish results on Bayes factor consistency under the proposed framework. The utility of the devised technology is showcased via several numerical experiments.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15503",
        "abstract url": "https://arxiv.org/abs/2401.15503",
        "title": "Dawn of the Dead(line Misses): Impact of Job Dismiss on the Deadline Miss Rate",
        "rating": -10,
        "keywords": [],
        "abstract": "Occasional deadline misses are acceptable for soft real-time systems. Quantifying probabilistic and deterministic characteristics of deadline misses is therefore essential to ensure that deadline misses indeed happen only occasionally. This is supported by recent research activities on probabilistic worst-case execution time, worst-case deadline failure probability, the maximum number of deadline misses, upper bounds on the deadline miss probability, and the deadline miss rate. This paper focuses on the deadline miss rate of a periodic soft real-time task in the long run. Our model assumes that this soft real-time task has an arbitrary relative deadline and that a job can still be executed after a deadline-miss until a dismiss point. This model generalizes the existing models that either dismiss a job immediately after its deadline miss or never dismiss a job. We provide mathematical notation on the convergence of the deadline miss rate in the long run and essential properties to calculate the deadline miss rate. Specifically, we use a Markov chain to model the execution behavior of a periodic soft real-time task. We present the required ergodicity property to ensure that the deadline miss rate in the long run is described by a stationary distribution.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15504",
        "abstract url": "https://arxiv.org/abs/2401.15504",
        "title": "Membership problems in nilpotent groups",
        "rating": -10,
        "keywords": [],
        "abstract": "We study both the Submonoid Membership problem and the Rational Subset Membership problem in finitely generated nilpotent groups. We give two reductions with important applications. First, Submonoid Membership in any nilpotent group can be reduced to Rational Subset Membership in smaller groups. As a corollary, we prove the existence of a group with decidable Submonoid Membership and undecidable Rational Subset Membership, confirming a conjecture of Lohrey and Steinberg. Second, the Rational Subset Membership problem in $H_3(\\mathbb Z)$ can be reduced to the Knapsack problem in the same group, and is therefore decidable. Combining both results, we deduce that the filiform $3$-step nilpotent group has decidable Submonoid Membership.",
        "subjects": [
            "math.GR"
        ],
        "comment": "24 pages, 5 figures. Comments are welcome"
    },
    {
        "paper id": "2401.15507",
        "abstract url": "https://arxiv.org/abs/2401.15507",
        "title": "\"May I Speak?\": Multi-modal Attention Guidance in Social VR Group Conversations",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we present a novel multi-modal attention guidance method designed to address the challenges of turn-taking dynamics in meetings and enhance group conversations within virtual reality (VR) environments. Recognizing the difficulties posed by a confined field of view and the absence of detailed gesture tracking in VR, our proposed method aims to mitigate the challenges of noticing new speakers attempting to join the conversation. This approach tailors attention guidance, providing a nuanced experience for highly engaged participants while offering subtler cues for those less engaged, thereby enriching the overall meeting dynamics. Through group interview studies, we gathered insights to guide our design, resulting in a prototype that employs \"light\" as a diegetic guidance mechanism, complemented by spatial audio. The combination creates an intuitive and immersive meeting environment, effectively directing users' attention to new speakers. An evaluation study, comparing our method to state-of-the-art attention guidance approaches, demonstrated significantly faster response times (p < 0.001), heightened perceived conversation satisfaction (p < 0.001), and preference (p < 0.001) for our method. Our findings contribute to the understanding of design implications for VR social attention guidance, opening avenues for future research and development.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15517",
        "abstract url": "https://arxiv.org/abs/2401.15517",
        "title": "Signal Recovery From Product of Two Vandermonde Matrices",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we present some new results for compressed sensing and phase retrieval. For compressed sensing, it is shown that if the unknown $n$-dimensional vector can be expressed as a linear combination of $s$ unknown Vandermonde vectors (with Fourier vectors as a special case) and the measurement matrix is a Vandermonde matrix, exact recovery of the vector with $2s$ measurements and $O(\\mathrm{poly}(s))$ complexity is possible when $n \\geq 2s$. Based on this result, a new class of measurement matrices is presented from which it is possible to recover $s$-sparse $n$-dimensional vectors for $n \\geq 2s$ with as few as $2s$ measurements and with a recovery algorithm of $O(\\mathrm{poly}(s))$ complexity. In the second part of the work, these results are extended to the challenging problem of phase retrieval. The most significant discovery in this direction is that if the unknown $n$-dimensional vector is composed of $s$ frequencies with at least one being non-harmonic, $n \\geq 4s - 1$ and we take at least $8s-3$ Fourier measurements, there are, remarkably, only two possible vectors producing the observed measurement values and they are easily obtainable from each other. The two vectors can be found by an algorithm with only $O(\\mathrm{poly}(s))$ complexity. An immediate application of the new result is construction of a measurement matrix from which it is possible to recover almost all $s$-sparse $n$-dimensional signals (up to a global phase) from $O(s)$ magnitude-only measurements and $O(\\mathrm{poly}(s))$ recovery complexity when $n \\geq 4s - 1$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15519",
        "abstract url": "https://arxiv.org/abs/2401.15519",
        "title": "Large Deviation Analysis of Score-based Hypothesis Testing",
        "rating": -10,
        "keywords": [],
        "abstract": "Score-based statistical models play an important role in modern machine learning, statistics, and signal processing. For hypothesis testing, a score-based hypothesis test is proposed in \\cite{wu2022score}. We analyze the performance of this score-based hypothesis testing procedure and derive upper bounds on the probabilities of its Type I and II errors. We prove that the exponents of our error bounds are asymptotically (in the number of samples) tight for the case of simple null and alternative hypotheses. We calculate these error exponents explicitly in specific cases and provide numerical studies for various other scenarios of interest.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15525",
        "abstract url": "https://arxiv.org/abs/2401.15525",
        "title": "Multi-Interval Energy-Reserve Co-Optimization with SoC-Dependent Bids from Battery Storage",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider the problem of co-optimized energy-reserve market clearing with state-of-charge (SoC) dependent bids from battery storage participants. While SoC-dependent bidding accurately captures storage's degradation and opportunity costs, such bids result in a non-convex optimization in the market clearing process. More challenging is the regulation reserve capacity clearing, where the SoC-dependent cost is uncertain as it depends on the unknown regulation trajectories ex-post of the market clearing. Addressing the nonconvexity and uncertainty in a multi-interval co-optimized real-time energy-reserve market, we introduce a simple restriction on the SoC-dependent bids along with a robust optimization formulation, transforming the non-convex market clearing under uncertainty into a standard convex piece-wise linear program and making it possible for large-scale storage integration. Under reasonable assumptions, we show that SoC-dependent bids yield higher profit for storage participants than that from SoC-independent bids. Numerical simulations demonstrate a 28%-150% profit increase of the proposed SoC-dependent bids compared with the SoC-independent counterpart.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15534",
        "abstract url": "https://arxiv.org/abs/2401.15534",
        "title": "CRYSTALS-Kyber With Lattice Quantizer",
        "rating": -10,
        "keywords": [],
        "abstract": "Module Learning with Errors (M-LWE) based key reconciliation mechanisms (KRM) can be viewed as quantizing an M-LWE sample according to a lattice codebook. This paper describes a generic M-LWE-based KRM framework, valid for any dimensional lattices and any modulus $q$ without a dither. Our main result is an explicit upper bound on the decryption failure rate (DFR) of M-LWE-based KRM. This bound allows us to construct optimal lattice quantizers to reduce the DFR and communication cost simultaneously. Moreover, we present a KRM scheme using the same security parameters $(q,k,\u03b7_1,\u03b7_2)$ as in Kyber. Compared with Kyber, the communication cost is reduced by up to $36.47\\%$ and the DFR is reduced by a factor of up to $2^{99}$. The security arguments remain the same as Kyber.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages,6 tables"
    },
    {
        "paper id": "2401.15545",
        "abstract url": "https://arxiv.org/abs/2401.15545",
        "title": "PPM: Automated Generation of Diverse Programming Problems for Benchmarking Code Generation Models",
        "rating": -10,
        "keywords": [],
        "abstract": "In recent times, a plethora of Large Code Generation Models (LCGMs) have been proposed, showcasing significant potential in assisting developers with complex programming tasks. Benchmarking LCGMs necessitates the creation of a set of diverse programming problems, and each problem comprises the prompt (including the task description), canonical solution, and test inputs. The existing methods for constructing such a problem set can be categorized into two main types: manual methods and perturbation-based methods. However, manual methods demand high effort and lack scalability, while also risking data integrity due to LCGMs' potentially contaminated data collection, and perturbation-based approaches mainly generate semantically homogeneous problems with the same canonical solutions and introduce typos that can be easily auto-corrected by IDE, making them ineffective and unrealistic. In this work, we propose the idea of programming problem merging (PPM) and provide two implementation of this idea, we utilize our tool on two widely-used datasets and compare it against nine baseline methods using eight code generation models. The results demonstrate the effectiveness of our tool in generating more challenging, diverse, and natural programming problems, comparing to the baselines.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper has been accepted to The ACM International Conference on the Foundations of Software Engineering FSE 2024"
    },
    {
        "paper id": "2401.15558",
        "abstract url": "https://arxiv.org/abs/2401.15558",
        "title": "numaPTE: Managing Page-Tables and TLBs on NUMA Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Memory management operations that modify page-tables, typically performed during memory allocation/deallocation, are infamous for their poor performance in highly threaded applications, largely due to process-wide TLB shootdowns that the OS must issue due to the lack of hardware support for TLB coherence. We study these operations in NUMA settings, where we observe up to 40x overhead for basic operations such as munmap or mprotect. The overhead further increases if page-table replication is used, where complete coherent copies of the page-tables are maintained across all NUMA nodes. While eager system-wide replication is extremely effective at localizing page-table reads during address translation, we find that it creates additional penalties upon any page-table changes due to the need to maintain all replicas coherent. In this paper, we propose a novel page-table management mechanism, called numaPTE, to enable transparent, on-demand, and partial page-table replication across NUMA nodes in order to perform address translation locally, while avoiding the overheads and scalability issues of system-wide full page-table replication. We then show that numaPTE's precise knowledge of page-table sharers can be leveraged to significantly reduce the number of TLB shootdowns issued upon any memory-management operation. As a result, numaPTE not only avoids replication-related slowdowns, but also provides significant speedup over the baseline on memory allocation/deallocation and access control operations. We implement numaPTEin Linux on x86_64, evaluate it on 4- and 8-socket systems, and show that numaPTE achieves the full benefits of eager page-table replication on a wide range of applications, while also achieving a 12% and 36% runtime improvement on Webserver and Memcached respectively due to a significant reduction in TLB shootdowns.",
        "subjects": [
            "cs.OS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.15560",
        "abstract url": "https://arxiv.org/abs/2401.15560",
        "title": "An Analysis of Letter Dynamics in the English Alphabet",
        "rating": -10,
        "keywords": [],
        "abstract": "The frequency with which the letters of the English alphabet appear in writings has been applied to the field of cryptography, the development of keyboard mechanics, and the study of linguistics. We expanded on the statistical analysis of the English alphabet by examining the average frequency which each letter appears in different categories of writings. We evaluated news articles, novels, plays, scientific publications and calculated the frequency of each letter of the alphabet, the information density of each letter, and the overall letter distribution. Furthermore, we developed a metric known as distance, d that can be used to algorithmically recognize different categories of writings. The results of our study can be applied to information transmission, large data curation, and linguistics.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "22 pages, 6 figures, 5 tables"
    },
    {
        "paper id": "2401.15566",
        "abstract url": "https://arxiv.org/abs/2401.15566",
        "title": "On the Robustness of Cross-Concentrated Sampling for Matrix Completion",
        "rating": -10,
        "keywords": [],
        "abstract": "Matrix completion is one of the crucial tools in modern data science research. Recently, a novel sampling model for matrix completion coined cross-concentrated sampling (CCS) has caught much attention. However, the robustness of the CCS model against sparse outliers remains unclear in the existing studies. In this paper, we aim to answer this question by exploring a novel Robust CCS Completion problem. A highly efficient non-convex iterative algorithm, dubbed Robust CUR Completion (RCURC), is proposed. The empirical performance of the proposed algorithm, in terms of both efficiency and robustness, is verified in synthetic and real datasets.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "58th Annual Conference of Information Sciences and Systems"
    },
    {
        "paper id": "2401.16443",
        "abstract url": "https://arxiv.org/abs/2401.16443",
        "title": "Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions",
        "rating": -10,
        "keywords": [],
        "abstract": "As VR devices become more prevalent in the consumer space, VR applications are likely to be increasingly used by users unfamiliar with VR. Detecting the familiarity level of a user with VR as an interaction medium provides the potential of providing on-demand training for acclimatization and prevents the user from being burdened by the VR environment in accomplishing their tasks. In this work, we present preliminary results of using deep classifiers to conduct automatic detection of familiarity with VR by using hand tracking of the user as they interact with a numeric passcode entry panel to unlock a VR door. We use a VR door as we envision it to the first point of entry to collaborative virtual spaces, such as meeting rooms, offices, or clinics. Users who are unfamiliar with VR will have used their hands to open doors with passcode entry panels in the real world. Thus, while the user may not be familiar with VR, they would be familiar with the task of opening the door. Using a pilot dataset consisting of 7 users familiar with VR, and 7 not familiar with VR, we acquire highest accuracy of 88.03\\% when 6 test users, 3 familiar and 3 not familiar, are evaluated with classifiers trained using data from the remaining 8 users. Our results indicate potential for using user movement data to detect familiarity for the simple yet important task of secure passcode-based access.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "AIxVR 2024 poster paper"
    },
    {
        "paper id": "2403.08781",
        "abstract url": "https://arxiv.org/abs/2403.08781",
        "title": "Time-Quantitatively Nonblocking Supervisory Control of Timed Discrete-Event Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Recently we proposed an automaton property of quantitative nonblockingness in supervisory control of discrete-event systems, which quantifies the standard nonblocking property by capturing the practical requirement that all tasks be completed within a bounded number of steps. However, in practice tasks may be further required to be completed in specific time; this requirement cannot be fulfilled by the quantitatively nonblocking supervisor. To meet this new requirement, in this paper we introduce the concept of time-quantitative nonblockingness, which extends the concept of quantitative nonblockingness from untimed discrete-event systems (DES) to timed DES. This property requires that each task must be completed within a bounded time. Accordingly, we formulate a new time-quantitatively nonblocking supervisory control problem of TDES, and characterize its solvability in terms of a new concept of time-quantitative language completability. It is proved that there exists a unique supremal time-quantitatively completable sublanguage of a given language, and we develop an automaton-based algorithm to compute the supremal sublanguage. Finally, we present an approach to compute a maximally permissive supervisory control solution to the new time-quantitative nonblocking supervisory control problem.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2108.00721"
    },
    {
        "paper id": "2405.00007",
        "abstract url": "https://arxiv.org/abs/2405.00007",
        "title": "Cantera-Based Python Computer Program for Solving Steam Power Cycles with Superheating",
        "rating": -10,
        "keywords": [],
        "abstract": "One of the main sources of electricity generation is power plants that use water (steam) to rotate turbines, which drive large electric generators. The steam can be generated from renewable or non-renewable energy sources, such as geothermal energy and nuclear fuels. Having an analysis tool for modeling the performance of such steam power plants can greatly help in reaching optimum designs, leading to less fuel consumption, reduced pollution, and cheaper electricity. It is further advantageous if such modeling tool is free to access, does not require many inputs from the user, and gives results in a very short time. These remarks establish a motivation for the current study. This article documents a computer code written in the Python programming language for numerically analysing the main processes in a steam power cycle with superheating. The code utilizes built-in thermodynamic properties for water in the open-source software package \"Cantera\". A validation case with a benchmarking example in the literature using an independent source of water properties suggests that the developed code is correct. The code can be viewed as an extension to the Python examples for thermodynamic and power generation applications. Cantera can handle both subcritical and supercritical types of superheating. In the subcritical superheating, the steam absolute pressure does not exceed 220.9 bar. In the supercritical superheating, water becomes in a special condition called supercritical fluid, with absolute pressures above 220.9 bar.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "11 pages, 4 tables, journal paper"
    }
]