[
    {
        "paper id": "2401.16923",
        "abstract url": "https://arxiv.org/abs/2401.16923",
        "title": "Fourier Prompt Tuning for Modality-Incomplete Scene Segmentation",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Integrating information from multiple modalities enhances the robustness of scene perception systems in autonomous vehicles, providing a more comprehensive and reliable sensory framework. However, the modality incompleteness in multi-modal segmentation remains under-explored. In this work, we establish a task called Modality-Incomplete Scene Segmentation (MISS), which encompasses both system-level modality absence and sensor-level modality errors. To avoid the predominant modality reliance in multi-modal fusion, we introduce a Missing-aware Modal Switch (MMS) strategy to proactively manage missing modalities during training. Utilizing bit-level batch-wise sampling enhances the model's performance in both complete and incomplete testing scenarios. Furthermore, we introduce the Fourier Prompt Tuning (FPT) method to incorporate representative spectral information into a limited number of learnable prompts that maintain robustness against all MISS scenarios. Akin to fine-tuning effects but with fewer tunable parameters (1.1%). Extensive experiments prove the efficacy of our proposed approach, showcasing an improvement of 5.84% mIoU over the prior state-of-the-art parameter-efficient methods in modality missing. The source code is publicly available at https://github.com/RuipingL/MISS.",
        "subjects": [
            "cs.CV",
            "cs.RO",
            "eess.IV"
        ],
        "comment": "Accepted to IEEE IV 2024. The source code is publicly available at https://github.com/RuipingL/MISS"
    },
    {
        "paper id": "2401.17221",
        "abstract url": "https://arxiv.org/abs/2401.17221",
        "title": "MouSi: Poly-Visual-Expert Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Current large vision-language models (VLMs) often encounter challenges such as insufficient capabilities of a single visual component and excessively long visual tokens. These issues can limit the model's effectiveness in accurately interpreting complex visual information and over-lengthy contextual information. Addressing these challenges is crucial for enhancing the performance and applicability of VLMs. This paper proposes the use of ensemble experts technique to synergizes the capabilities of individual visual encoders, including those skilled in image-text matching, OCR, image segmentation, etc. This technique introduces a fusion network to unify the processing of outputs from different visual experts, while bridging the gap between image encoders and pre-trained LLMs. In addition, we explore different positional encoding schemes to alleviate the waste of positional encoding caused by lengthy image feature sequences, effectively addressing the issue of position overflow and length limitations. For instance, in our implementation, this technique significantly reduces the positional occupancy in models like SAM, from a substantial 4096 to a more efficient and manageable 64 or even down to 1. Experimental results demonstrate that VLMs with multiple experts exhibit consistently superior performance over isolated visual encoders and mark a significant performance boost as more experts are integrated. We have open-sourced the training code used in this report. All of these resources can be found on our project website.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17270",
        "abstract url": "https://arxiv.org/abs/2401.17270",
        "title": "YOLO-World: Real-Time Open-Vocabulary Object Detection",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools. However, their reliance on predefined and trained object categories limits their applicability in open scenarios. Addressing this limitation, we introduce YOLO-World, an innovative approach that enhances YOLO with open-vocabulary detection capabilities through vision-language modeling and pre-training on large-scale datasets. Specifically, we propose a new Re-parameterizable Vision-Language Path Aggregation Network (RepVL-PAN) and region-text contrastive loss to facilitate the interaction between visual and linguistic information. Our method excels in detecting a wide range of objects in a zero-shot manner with high efficiency. On the challenging LVIS dataset, YOLO-World achieves 35.4 AP with 52.0 FPS on V100, which outperforms many state-of-the-art methods in terms of both accuracy and speed. Furthermore, the fine-tuned YOLO-World achieves remarkable performance on several downstream tasks, including object detection and open-vocabulary instance segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Work still in progress. Code & models are available at: https://github.com/AILab-CVC/YOLO-World"
    },
    {
        "paper id": "2401.17099",
        "abstract url": "https://arxiv.org/abs/2401.17099",
        "title": "MT-Ranker: Reference-free machine translation evaluation by inter-system ranking",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Traditionally, Machine Translation (MT) Evaluation has been treated as a regression problem -- producing an absolute translation-quality score. This approach has two limitations: i) the scores lack interpretability, and human annotators struggle with giving consistent scores; ii) most scoring methods are based on (reference, translation) pairs, limiting their applicability in real-world scenarios where references are absent. In practice, we often care about whether a new MT system is better or worse than some competitors. In addition, reference-free MT evaluation is increasingly practical and necessary. Unfortunately, these two practical considerations have yet to be jointly explored. In this work, we formulate the reference-free MT evaluation into a pairwise ranking problem. Given the source sentence and a pair of translations, our system predicts which translation is better. In addition to proposing this new formulation, we further show that this new paradigm can demonstrate superior correlation with human judgments by merely using indirect supervision from natural language inference and weak supervision from our synthetic data. In the context of reference-free evaluation, MT-Ranker, trained without any human annotations, achieves state-of-the-art results on the WMT Shared Metrics Task benchmarks DARR20, MQM20, and MQM21. On a more challenging benchmark, ACES, which contains fine-grained evaluation criteria such as addition, omission, and mistranslation errors, MT-Ranker marks state-of-the-art against reference-free as well as reference-based baselines.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages, 4 figures, to be published in ICLR'24, Code available at https://github.com/ibraheem-moosa/mt-ranker"
    },
    {
        "paper id": "2401.17186",
        "abstract url": "https://arxiv.org/abs/2401.17186",
        "title": "Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning",
        "rating": "1.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "While vision-language pre-trained models (VL-PTMs) have advanced multimodal research in recent years, their mastery in a few languages like English restricts their applicability in broader communities. To this end, there is an increasing interest in developing multilingual VL models via a joint-learning setup, which, however, could be unrealistic due to expensive costs and data availability. In this work, we propose to extend VL-PTMs' language capacity by continual language learning (CLL), where a model needs to update its linguistic knowledge incrementally without suffering from catastrophic forgetting (CF). We begin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP, a prevailing VL-PTM that has acquired image-English text alignment. Specifically, CLL-CLIP contains an expandable token embedding layer to handle linguistic differences. It solely trains token embeddings to improve memory stability and is optimized under cross-modal and cross-lingual objectives to learn the alignment between images and multilingual texts. To alleviate CF raised by covariate shift and lexical overlap, we further propose a novel approach that ensures the identical distribution of all token embeddings during initialization and regularizes token embedding learning during training. We construct a CLL benchmark covering 36 languages based on MSCOCO and XM3600 datasets and then evaluate multilingual image-text retrieval performance. Extensive experiments verify the effectiveness of CLL-CLIP and show that our approach can boost CLL-CLIP, e.g., by 6.7% in text-to-image average Recall@1 on XM3600, and improve various state-of-the-art methods consistently. Our code and data are available at \\url{https://github.com/yangbang18/CLFM}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "Accepted by AAAI'2024, 15 pages (with appendix), 7 figures, 10 tables"
    },
    {
        "paper id": "2401.17343",
        "abstract url": "https://arxiv.org/abs/2401.17343",
        "title": "YTCommentQA: Video Question Answerability in Instructional Videos",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Instructional videos provide detailed how-to guides for various tasks, with viewers often posing questions regarding the content. Addressing these questions is vital for comprehending the content, yet receiving immediate answers is difficult. While numerous computational models have been developed for Video Question Answering (Video QA) tasks, they are primarily trained on questions generated based on video content, aiming to produce answers from within the content. However, in real-world situations, users may pose questions that go beyond the video's informational boundaries, highlighting the necessity to determine if a video can provide the answer. Discerning whether a question can be answered by video content is challenging due to the multi-modal nature of videos, where visual and verbal information are intertwined. To bridge this gap, we present the YTCommentQA dataset, which contains naturally-generated questions from YouTube, categorized by their answerability and required modality to answer -- visual, script, or both. Experiments with answerability classification tasks demonstrate the complexity of YTCommentQA and emphasize the need to comprehend the combined role of visual and script information in video reasoning. The dataset is available at https://github.com/lgresearch/YTCommentQA.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "AAAI 2024"
    },
    {
        "paper id": "2401.17345",
        "abstract url": "https://arxiv.org/abs/2401.17345",
        "title": "Reproducibility, energy efficiency and performance of pseudorandom number generators in machine learning: a comparative study of python, numpy, tensorflow, and pytorch implementations",
        "rating": "1.5",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Pseudo-Random Number Generators (PRNGs) have become ubiquitous in machine learning technologies because they are interesting for numerous methods. The field of machine learning holds the potential for substantial advancements across various domains, as exemplified by recent breakthroughs in Large Language Models (LLMs). However, despite the growing interest, persistent concerns include issues related to reproducibility and energy consumption. Reproducibility is crucial for robust scientific inquiry and explainability, while energy efficiency underscores the imperative to conserve finite global resources. This study delves into the investigation of whether the leading Pseudo-Random Number Generators (PRNGs) employed in machine learning languages, libraries, and frameworks uphold statistical quality and numerical reproducibility when compared to the original C implementation of the respective PRNG algorithms. Additionally, we aim to evaluate the time efficiency and energy consumption of various implementations. Our experiments encompass Python, NumPy, TensorFlow, and PyTorch, utilizing the Mersenne Twister, PCG, and Philox algorithms. Remarkably, we verified that the temporal performance of machine learning technologies closely aligns with that of C-based implementations, with instances of achieving even superior performances. On the other hand, it is noteworthy that ML technologies consumed only 10% more energy than their C-implementation counterparts. However, while statistical quality was found to be comparable, achieving numerical reproducibility across different platforms for identical seeds and algorithms was not achieved.",
        "subjects": [
            "cs.MS",
            "cs.LG"
        ],
        "comment": "20 pages, 10 tables, 1 figure"
    },
    {
        "paper id": "2401.17390",
        "abstract url": "https://arxiv.org/abs/2401.17390",
        "title": "Customizing Language Model Responses with Contrastive In-Context Learning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Large language models (LLMs) are becoming increasingly important for machine learning applications. However, it can be challenging to align LLMs with our intent, particularly when we want to generate content that is preferable over others or when we want the LLM to respond in a certain style or tone that is hard to describe. To address this challenge, we propose an approach that uses contrastive examples to better describe our intent. This involves providing positive examples that illustrate the true intent, along with negative examples that show what characteristics we want LLMs to avoid. The negative examples can be retrieved from labeled data, written by a human, or generated by the LLM itself. Before generating an answer, we ask the model to analyze the examples to teach itself what to avoid. This reasoning step provides the model with the appropriate articulation of the user's need and guides it towards generting a better answer. We tested our approach on both synthesized and real-world datasets, including StackExchange and Reddit, and found that it significantly improves performance compared to standard few-shot prompting",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted to appear at AAAI 2024"
    },
    {
        "paper id": "2401.17461",
        "abstract url": "https://arxiv.org/abs/2401.17461",
        "title": "Synthetic Dialogue Dataset Generation using LLM Agents",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Linear programming (LP) problems are pervasive in real-life applications. However, despite their apparent simplicity, an untrained user may find it difficult to determine the linear model of their specific problem. We envisage the creation of a goal-oriented conversational agent that will engage in conversation with the user to elicit all information required so that a subsequent agent can generate the linear model. In this paper, we present an approach for the generation of sample dialogues that can be used to develop and train such a conversational agent. Using prompt engineering, we develop two agents that \"talk\" to each other, one acting as the conversational agent, and the other acting as the user. Using a set of text descriptions of linear problems from NL4Opt available to the user only, the agent and the user engage in conversation until the agent has retrieved all key information from the original problem description. We also propose an extrinsic evaluation of the dialogues by assessing how well the summaries generated by the dialogues match the original problem descriptions. We conduct human and automatic evaluations, including an evaluation approach that uses GPT-4 to mimic the human evaluation metrics. The evaluation results show an overall good quality of the dialogues, though research is still needed to improve the quality of the GPT-4 evaluation metrics. The resulting dialogues, including the human annotations of a subset, are available to the research community. The conversational agent used for the generation of the dialogues can be used as a baseline.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "GEM Workshop @ EMNLP 2023"
    },
    {
        "paper id": "2402.00067",
        "abstract url": "https://arxiv.org/abs/2402.00067",
        "title": "Online speaker diarization of meetings guided by speech separation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Overlapped speech is notoriously problematic for speaker diarization systems. Consequently, the use of speech separation has recently been proposed to improve their performance. Although promising, speech separation models struggle with realistic data because they are trained on simulated mixtures with a fixed number of speakers. In this work, we introduce a new speech separation-guided diarization scheme suitable for the online speaker diarization of long meeting recordings with a variable number of speakers, as present in the AMI corpus. We envisage ConvTasNet and DPRNN as alternatives for the separation networks, with two or three output sources. To obtain the speaker diarization result, voice activity detection is applied on each estimated source. The final model is fine-tuned end-to-end, after first adapting the separation to real data using AMI. The system operates on short segments, and inference is performed by stitching the local predictions using speaker embeddings and incremental clustering. The results show that our system improves the state-of-the-art on the AMI headset mix, using no oracle information and under full evaluation (no collar and including overlapped speech). Finally, we show the strength of our system particularly on overlapped speech sections.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD",
            "eess.SP"
        ],
        "comment": "Accepted at ICASSP 2024"
    },
    {
        "paper id": "2403.09669",
        "abstract url": "https://arxiv.org/abs/2403.09669",
        "title": "STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Image generative models have made significant progress in generating realistic and diverse images, supported by comprehensive guidance from various evaluation metrics. However, current video generative models struggle to generate even short video clips, with limited tools that provide insights for improvements. Current video evaluation metrics are simple adaptations of image metrics by switching the embeddings with video embedding networks, which may underestimate the unique characteristics of video. Our analysis reveals that the widely used Frechet Video Distance (FVD) has a stronger emphasis on the spatial aspect than the temporal naturalness of video and is inherently constrained by the input size of the embedding networks used, limiting it to 16 frames. Additionally, it demonstrates considerable instability and diverges from human evaluations. To address the limitations, we propose STREAM, a new video evaluation metric uniquely designed to independently evaluate spatial and temporal aspects. This feature allows comprehensive analysis and evaluation of video generative models from various perspectives, unconstrained by video length. We provide analytical and experimental evidence demonstrating that STREAM provides an effective evaluation tool for both visual and temporal quality of videos, offering insights into area of improvement for video generative models. To the best of our knowledge, STREAM is the first evaluation metric that can separately assess the temporal and spatial aspects of videos. Our code is available at https://github.com/pro2nit/STREAM.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Our work is accepted to ICLR 2024"
    },
    {
        "paper id": "2401.16748",
        "abstract url": "https://arxiv.org/abs/2401.16748",
        "title": "Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Racism is an alarming phenomenon in our country as well as all over the world. Every day we have come across some racist comments in our daily life and virtual life. Though we can eradicate this racism from virtual life (such as Social Media). In this paper, we have tried to detect those racist comments with NLP and deep learning techniques. We have built a novel dataset in the Bengali Language. Further, we annotated the dataset and conducted data label validation. After extensive utilization of deep learning methodologies, we have successfully achieved text detection with an impressive accuracy rate of 87.94\\% using the Ensemble approach. We have applied RNN and LSTM models using BERT Embeddings. However, the MCNN-LSTM model performed highest among all those models. Lastly, the Ensemble approach has been followed to combine all the model results to increase overall performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16760",
        "abstract url": "https://arxiv.org/abs/2401.16760",
        "title": "One-Step Forward and Backtrack: Overcoming Zig-Zagging in Loss-Aware Quantization Training",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Weight quantization is an effective technique to compress deep neural networks for their deployment on edge devices with limited resources. Traditional loss-aware quantization methods commonly use the quantized gradient to replace the full-precision gradient. However, we discover that the gradient error will lead to an unexpected zig-zagging-like issue in the gradient descent learning procedures, where the gradient directions rapidly oscillate or zig-zag, and such issue seriously slows down the model convergence. Accordingly, this paper proposes a one-step forward and backtrack way for loss-aware quantization to get more accurate and stable gradient direction to defy this issue. During the gradient descent learning, a one-step forward search is designed to find the trial gradient of the next-step, which is adopted to adjust the gradient of current step towards the direction of fast convergence. After that, we backtrack the current step to update the full-precision and quantized weights through the current-step gradient and the trial gradient. A series of theoretical analysis and experiments on benchmark deep models have demonstrated the effectiveness and competitiveness of the proposed method, and our method especially outperforms others on the convergence performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 13 figures,accepted by AAAI-24"
    },
    {
        "paper id": "2401.16788",
        "abstract url": "https://arxiv.org/abs/2401.16788",
        "title": "Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Despite the utility of Large Language Models (LLMs) across a wide range of tasks and scenarios, developing a method for reliably evaluating LLMs across varied contexts continues to be challenging. Modern evaluation approaches often use LLMs to assess responses generated by LLMs. However, the meta-evaluation conducted to assess the effectiveness of these LLMs as evaluators is typically constrained by the coverage of existing benchmarks or requires extensive human annotation. This underscores the urgency of methods for scalable meta-evaluation that can effectively, reliably, and efficiently evaluate the performance of LLMs as evaluators across diverse tasks and scenarios, particularly in potentially new, user-defined scenarios. To fill this gap, we propose ScaleEval, an agent-debate-assisted meta-evaluation framework that leverages the capabilities of multiple communicative LLM agents. This framework supports multi-round discussions to assist human annotators in discerning the most capable LLMs as evaluators, which significantly eases their workload in cases that used to require large-scale annotations during meta-evaluation. We release the code for our framework, which is publicly available at: \\url{https://github.com/GAIR-NLP/scaleeval}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16803",
        "abstract url": "https://arxiv.org/abs/2401.16803",
        "title": "PBSCSR: The Piano Bootleg Score Composer Style Recognition Dataset",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This article motivates, describes, and presents the PBSCSR dataset for studying composer style recognition of piano sheet music. Our overarching goal was to create a dataset for studying composer style recognition that is \"as accessible as MNIST and as challenging as ImageNet\". To achieve this goal, we use a previously proposed feature representation of sheet music called a bootleg score, which encodes the position of noteheads relative to the staff lines. Using this representation, we sample fixed-length bootleg score fragments from piano sheet music images on IMSLP. The dataset itself contains 40,000 62x64 bootleg score images for a 9-way classification task, 100,000 62x64 bootleg score images for a 100-way classification task, and 29,310 unlabeled variable-length bootleg score images for pretraining. The labeled data is presented in a form that mirrors MNIST images, in order to make it extremely easy to visualize, manipulate, and train models in an efficient manner. Additionally, we include relevant metadata to allow access to the underlying raw sheet music images and other related data on IMSLP. We describe several research tasks that could be studied with the dataset, including variations of composer style recognition in a few-shot or zero-shot setting. For tasks that have previously proposed models, we release code and baseline results for future works to compare against. We also discuss open research questions that the PBSCSR data is especially well suited to facilitate research on and areas of fruitful exploration in future work.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "15 pages, 4 figures"
    },
    {
        "paper id": "2401.16811",
        "abstract url": "https://arxiv.org/abs/2401.16811",
        "title": "Reviving Undersampling for Long-Tailed Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The training datasets used in long-tailed recognition are extremely unbalanced, resulting in significant variation in per-class accuracy across categories. Prior works mostly used average accuracy to evaluate their algorithms, which easily ignores those worst-performing categories. In this paper, we aim to enhance the accuracy of the worst-performing categories and utilize the harmonic mean and geometric mean to assess the model's performance. We revive the balanced undersampling idea to achieve this goal. In few-shot learning, balanced subsets are few-shot and will surely under-fit, hence it is not used in modern long-tailed learning. But, we find that it produces a more equitable distribution of accuracy across categories with much higher harmonic and geometric mean accuracy, and, but lower average accuracy. Moreover, we devise a straightforward model ensemble strategy, which does not result in any additional overhead and achieves improved harmonic and geometric mean while keeping the average accuracy almost intact when compared to state-of-the-art long-tailed learning methods. We validate the effectiveness of our approach on widely utilized benchmark datasets for long-tailed learning. Our code is at \\href{https://github.com/yuhao318/BTM/}{https://github.com/yuhao318/BTM/}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16812",
        "abstract url": "https://arxiv.org/abs/2401.16812",
        "title": "SpeechBERTScore: Reference-Aware Automatic Evaluation of Speech Generation Leveraging NLP Evaluation Metrics",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "While subjective assessments have been the gold standard for evaluating speech generation, there is a growing need for objective metrics that are highly correlated with human subjective judgments due to their cost efficiency. This paper proposes reference-aware automatic evaluation methods for speech generation inspired by evaluation metrics in natural language processing. The proposed SpeechBERTScore computes the BERTScore for self-supervised dense speech features of the generated and reference speech, which can have different sequential lengths. We also propose SpeechBLEU and SpeechTokenDistance, which are computed on speech discrete tokens. The evaluations on synthesized speech show that our method correlates better with human subjective ratings than mel cepstral distortion and a recent mean opinion score prediction model. Also, they are effective in noisy speech evaluation and have cross-lingual applicability.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16818",
        "abstract url": "https://arxiv.org/abs/2401.16818",
        "title": "H2O-Danube-1.8B Technical Report",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We present H2O-Danube, a series of small 1.8B language models consisting of H2O-Danube-1.8B, trained on 1T tokens, and the incremental improved H2O-Danube2-1.8B trained on an additional 2T tokens. Our models exhibit highly competitive metrics across a multitude of benchmarks and, as of the time of this writing, H2O-Danube2-1.8B achieves the top ranking on Open LLM Leaderboard for all models below the 2B parameter range. The models follow core principles of LLama 2 and Mistral, and we leverage and refine various techniques for pre-training large language models. We additionally release chat models trained with supervised fine-tuning followed by direct preference optimization. We make all models openly available under Apache 2.0 license further democratizing LLMs to a wider audience economically.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16819",
        "abstract url": "https://arxiv.org/abs/2401.16819",
        "title": "Localizing uniformly moving mono-frequent sources using an inverse 2.5D approach",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Localizing linearly moving sound sources using microphone arrays is particularly challenging as the transient nature of the signal leads to relatively short observation periods. Commonly, a moving focus is used and most methods operate at least partially in the time domain. In contrast, here an inverse source localization algorithm for mono-frequent uniformly moving sources that acts entirely in the frequency domain is presented. For this, a 2.5D approach is utilized and a transfer function between sources and a microphone grid is derived. By solving a least squares problem using the data at the microphone grid, the unknown source distribution in the moving frame can be determined. For that the measured time signals need to be transformed into the frequency domain using a windowed discrete Fourier transform (DFT), which leads to effects such as spectral leakage that depends on the length of the time interval and the analysis window used. To include these effects in the numerical model, the calculation of the transfer matrix is modified using the Fourier transform of the analysis window. Currently, this approach is limited to mono-frequent sources as this allows a simplification of the calculation and reduces the computational effort. The least squares problem is solved using a Tikhonov regularization employing an L-curve approach to determine a suitable regularization parameter. As a moving source is considered, the Doppler effect allows to enhance the stability of the system by combining the transfer functions for multiple frequencies in the measured signals. The performance of the approach is validated using simulated data of a moving point source with or without a reflecting ground. Numerical experiments are performed to show the effect of the choice of frequencies in the receiver spectrum, the effect of the DFT, the frequency of the source, and the distance of source and receiver.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "27 pages, 15 figures"
    },
    {
        "paper id": "2401.16850",
        "abstract url": "https://arxiv.org/abs/2401.16850",
        "title": "Spatial-Temporal Activity-Informed Diarization and Separation",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "A robust multichannel speaker diarization and separation system is proposed by exploiting the spatio-temporal activity of the speakers. The system is realized in a hybrid architecture that combines the array signal processing units and the deep learning units. For speaker diarization, a spatial coherence matrix across time frames is computed based on the whitened relative transfer functions (wRTFs) of the microphone array. This serves as a robust feature for subsequent machine learning without the need for prior knowledge of the array configuration. A computationally efficient Spatial Activity-driven Speaker Diarization network (SASDnet) is constructed to estimate the speaker activity directly from the spatial coherence matrix. For speaker separation, we propose the Global and Local Activity-driven Speaker Extraction network (GLASEnet) to separate speaker signals via speaker-specific global and local spatial activity functions. The local spatial activity functions depend on the coherence between the wRTFs of each time-frequency bin and the target speaker-dominant bins. The global spatial activity functions are computed from the global spatial coherence functions based on frequency-averaged local spatial activity functions. Experimental results have demonstrated superior speaker, diarization, counting, and separation performance achieved by the proposed system with low computational complexity compared to the pre-selected baselines.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2401.16862",
        "abstract url": "https://arxiv.org/abs/2401.16862",
        "title": "State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recently, low-resource dialogue state tracking (DST) has received increasing attention. First obtaining state values then based on values to generate slot types has made great progress in this task. However, obtaining state values is still an under-studied problem. Existing extraction-based approaches cannot capture values that require the understanding of context and are not generalizable either. To address these issues, we propose a novel State VAlue Generation based framework (SVAG), decomposing DST into state value generation and domain slot generation. Specifically, we propose to generate state values and use self-training to further improve state value generation. Moreover, we design an estimator aiming at detecting incomplete generation and incorrect generation for pseudo-labeled data selection during self-training. Experimental results on the MultiWOZ 2.1 dataset show that our method which has only less than 1 billion parameters achieves state-of-the-art performance under the data ratio settings of 5%, 10%, and 25% when limited to models under 100 billion parameters. Compared to models with more than 100 billion parameters, SVAG still reaches competitive results.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ACML 2023"
    },
    {
        "paper id": "2401.16876",
        "abstract url": "https://arxiv.org/abs/2401.16876",
        "title": "Zero-shot Classification using Hyperdimensional Computing",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Classification based on Zero-shot Learning (ZSL) is the ability of a model to classify inputs into novel classes on which the model has not previously seen any training examples. Providing an auxiliary descriptor in the form of a set of attributes describing the new classes involved in the ZSL-based classification is one of the favored approaches to solving this challenging task. In this work, inspired by Hyperdimensional Computing (HDC), we propose the use of stationary binary codebooks of symbol-like distributed representations inside an attribute encoder to compactly represent a computationally simple end-to-end trainable model, which we name Hyperdimensional Computing Zero-shot Classifier~(HDC-ZSC). It consists of a trainable image encoder, an attribute encoder based on HDC, and a similarity kernel. We show that HDC-ZSC can be used to first perform zero-shot attribute extraction tasks and, can later be repurposed for Zero-shot Classification tasks with minimal architectural changes and minimal model retraining. HDC-ZSC achieves Pareto optimal results with a 63.8% top-1 classification accuracy on the CUB-200 dataset by having only 26.6 million trainable parameters. Compared to two other state-of-the-art non-generative approaches, HDC-ZSC achieves 4.3% and 9.9% better accuracy, while they require more than 1.85x and 1.72x parameters compared to HDC-ZSC, respectively.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "This is the extended version of a paper accepted in the Design, Automation, and Test in Europe Conference (DATE), 2024"
    },
    {
        "paper id": "2401.16895",
        "abstract url": "https://arxiv.org/abs/2401.16895",
        "title": "Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Although multilingual language models exhibit impressive cross-lingual transfer capabilities on unseen languages, the performance on downstream tasks is impacted when there is a script disparity with the languages used in the multilingual model's pre-training data. Using transliteration offers a straightforward yet effective means to align the script of a resource-rich language with a target language, thereby enhancing cross-lingual transfer capabilities. However, for mixed languages, this approach is suboptimal, since only a subset of the language benefits from the cross-lingual transfer while the remainder is impeded. In this work, we focus on Maltese, a Semitic language, with substantial influences from Arabic, Italian, and English, and notably written in Latin script. We present a novel dataset annotated with word-level etymology. We use this dataset to train a classifier that enables us to make informed decisions regarding the appropriate processing of each token in the Maltese language. We contrast indiscriminate transliteration or translation to mixing processing pipelines that only transliterate words of Arabic origin, thereby resulting in text with a mixture of scripts. We fine-tune the processed data on four downstream tasks and show that conditional transliteration based on word etymology yields the best results, surpassing fine-tuning with raw Maltese or Maltese processed with non-selective pipelines.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL 2024 camera-ready version"
    },
    {
        "paper id": "2401.16936",
        "abstract url": "https://arxiv.org/abs/2401.16936",
        "title": "Multi-modal Representation Learning for Cross-modal Prediction of Continuous Weather Patterns from Discrete Low-Dimensional Data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "World is looking for clean and renewable energy sources that do not pollute the environment, in an attempt to reduce greenhouse gas emissions that contribute to global warming. Wind energy has significant potential to not only reduce greenhouse emission, but also meet the ever increasing demand for energy. To enable the effective utilization of wind energy, addressing the following three challenges in wind data analysis is crucial. Firstly, improving data resolution in various climate conditions to ensure an ample supply of information for assessing potential energy resources. Secondly, implementing dimensionality reduction techniques for data collected from sensors/simulations to efficiently manage and store large datasets. Thirdly, extrapolating wind data from one spatial specification to another, particularly in cases where data acquisition may be impractical or costly. We propose a deep learning based approach to achieve multi-modal continuous resolution wind data prediction from discontinuous wind data, along with data dimensionality reduction.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16937",
        "abstract url": "https://arxiv.org/abs/2401.16937",
        "title": "Segmentation and Characterization of Macerated Fibers and Vessels Using Deep Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Purpose: Wood comprises different cell types, such as fibers and vessels, defining its properties. Studying their shape, size, and arrangement in microscopic images is crucial for understanding wood samples. Typically, this involves macerating (soaking) samples in a solution to separate cells, then spreading them on slides for imaging with a microscope that covers a wide area, capturing thousands of cells. However, these cells often cluster and overlap in images, making the segmentation difficult and time-consuming using standard image-processing methods. Results: In this work, we develop an automatic deep learning segmentation approach that utilizes the one-stage YOLOv8 model for fast and accurate fiber and vessel segmentation and characterization in microscopy images. The model can analyze 32640 x 25920 pixels images and demonstrate effective cell detection and segmentation, achieving a mAP_0.5-0.95 of 78 %. To assess the model's robustness, we examined fibers from a genetically modified tree line known for longer fibers. The outcomes were comparable to previous manual measurements. Additionally, we created a user-friendly web application for image analysis and provided the code for use on Google Colab. Conclusion: By leveraging YOLOv8's advances, this work provides a deep learning solution to enable efficient quantification and analysis of wood cells suitable for practical applications.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "7 figures"
    },
    {
        "paper id": "2401.16968",
        "abstract url": "https://arxiv.org/abs/2401.16968",
        "title": "Distinguishing Fictional Voices: a Study of Authorship Verification Models for Quotation Attribution",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent approaches to automatically detect the speaker of an utterance of direct speech often disregard general information about characters in favor of local information found in the context, such as surrounding mentions of entities. In this work, we explore stylistic representations of characters built by encoding their quotes with off-the-shelf pretrained Authorship Verification models in a large corpus of English novels (the Project Dialogism Novel Corpus). Results suggest that the combination of stylistic and topical information captured in some of these models accurately distinguish characters among each other, but does not necessarily improve over semantic-only models when attributing quotes. However, these results vary across novels and more investigation of stylometric models particularly tailored for literary texts and the study of characters should be conducted.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at EACL 2024's workshop LaTeCH-CLfL"
    },
    {
        "paper id": "2401.17026",
        "abstract url": "https://arxiv.org/abs/2401.17026",
        "title": "Static and Dynamic Synthesis of Bengali and Devanagari Signatures",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Developing an automatic signature verification system is challenging and demands a large number of training samples. This is why synthetic handwriting generation is an emerging topic in document image analysis. Some handwriting synthesizers use the motor equivalence model, the well-established hypothesis from neuroscience, which analyses how a human being accomplishes movement. Specifically, a motor equivalence model divides human actions into two steps: 1) the effector independent step at cognitive level and 2) the effector dependent step at motor level. In fact, recent work reports the successful application to Western scripts of a handwriting synthesizer, based on this theory. This paper aims to adapt this scheme for the generation of synthetic signatures in two Indic scripts, Bengali (Bangla), and Devanagari (Hindi). For this purpose, we use two different online and offline databases for both Bengali and Devanagari signatures. This paper reports an effective synthesizer for static and dynamic signatures written in Devanagari or Bengali scripts. We obtain promising results with artificially generated signatures in terms of appearance and performance when we compare the results with those for real signatures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted version. Published on IEEE Transactions on Cybernetics [ISSN 2168-2267], v. 48(10), p. 2896-2907"
    },
    {
        "paper id": "2401.17039",
        "abstract url": "https://arxiv.org/abs/2401.17039",
        "title": "Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Clarification requests are a mechanism to help solve communication problems, e.g. due to ambiguity or underspecification, in instruction-following interactions. Despite their importance, even skilful models struggle with producing or interpreting such repair acts. In this work, we test three hypotheses concerning the effects of action taking as an auxiliary task in modelling iCR policies. Contrary to initial expectations, we conclude that its contribution to learning an iCR policy is limited, but some information can still be extracted from prediction uncertainty. We present further evidence that even well-motivated, Transformer-based models fail to learn good policies for when to ask Instruction CRs (iCRs), while the task of determining what to ask about can be more successfully modelled. Considering the implications of these findings, we further discuss the shortcomings of the data-driven paradigm for learning meta-communication acts.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to UnImplicit workshop at EACL 2024"
    },
    {
        "paper id": "2401.17043",
        "abstract url": "https://arxiv.org/abs/2401.17043",
        "title": "CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by incorporating external knowledge sources. This method addresses common LLM limitations, including outdated information and the tendency to produce inaccurate \"hallucinated\" content. However, the evaluation of RAG systems is challenging, as existing benchmarks are limited in scope and diversity. Most of the current benchmarks predominantly assess question-answering applications, overlooking the broader spectrum of situations where RAG could prove advantageous. Moreover, they only evaluate the performance of the LLM component of the RAG pipeline in the experiments, and neglect the influence of the retrieval component and the external knowledge database. To address these issues, this paper constructs a large-scale and more comprehensive benchmark, and evaluates all the components of RAG systems in various RAG application scenarios. Specifically, we have categorized the range of RAG applications into four distinct types-Create, Read, Update, and Delete (CRUD), each representing a unique use case. \"Create\" refers to scenarios requiring the generation of original, varied content. \"Read\" involves responding to intricate questions in knowledge-intensive situations. \"Update\" focuses on revising and rectifying inaccuracies or inconsistencies in pre-existing texts. \"Delete\" pertains to the task of summarizing extensive texts into more concise forms. For each of these CRUD categories, we have developed comprehensive datasets to evaluate the performance of RAG systems. We also analyze the effects of various components of the RAG system, such as the retriever, the context length, the knowledge base construction, and the LLM. Finally, we provide useful insights for optimizing the RAG technology for different scenarios.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "26 Pages"
    },
    {
        "paper id": "2401.17050",
        "abstract url": "https://arxiv.org/abs/2401.17050",
        "title": "ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "As computer vision continues to advance and finds widespread applications across various domains, the need for interpretability in deep learning models becomes paramount. Existing methods often resort to post-hoc techniques or prototypes to explain the decision-making process, which can be indirect and lack intrinsic illustration. In this research, we introduce ViTree, a novel approach for fine-grained visual categorization that combines the popular vision transformer as a feature extraction backbone with neural decision trees. By traversing the tree paths, ViTree effectively selects patches from transformer-processed features to highlight informative local regions, thereby refining representations in a step-wise manner. Unlike previous tree-based models that rely on soft distributions or ensembles of paths, ViTree selects a single tree path, offering a clearer and simpler decision-making process. This patch and path selectivity enhances model interpretability of ViTree, enabling better insights into the model's inner workings. Remarkably, extensive experimentation validates that this streamlined approach surpasses various strong competitors and achieves state-of-the-art performance while maintaining exceptional interpretability which is proved by multi-perspective methods. Code can be found at https://github.com/SJTU-DeepVisionLab/ViTree.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17072",
        "abstract url": "https://arxiv.org/abs/2401.17072",
        "title": "SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable advancements in their ability to generate fitting responses to natural language instructions. However, many current works rely on manual evaluation to judge the quality of generated responses. Since such manual evaluation is time-consuming, it does not easily scale to the evaluation of multiple models and model variants. In this short paper, we propose a straightforward but remarkably effective evaluation metric called SemScore, in which we directly compare model outputs to gold target responses using semantic textual similarity (STS). We conduct a comparative evaluation of the model outputs of 12 prominent instruction-tuned LLMs using 8 widely-used evaluation metrics for text generation. We find that our proposed SemScore metric outperforms all other, in many cases more complex, evaluation metrics in terms of correlation to human evaluation. These findings indicate the utility of our proposed metric for the evaluation of instruction-tuned LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17092",
        "abstract url": "https://arxiv.org/abs/2401.17092",
        "title": "NNOSE: Nearest Neighbor Occupational Skill Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The labor market is changing rapidly, prompting increased interest in the automatic extraction of occupational skills from text. With the advent of English benchmark job description datasets, there is a need for systems that handle their diversity well. We tackle the complexity in occupational skill datasets tasks -- combining and leveraging multiple datasets for skill extraction, to identify rarely observed skills within a dataset, and overcoming the scarcity of skills across datasets. In particular, we investigate the retrieval-augmentation of language models, employing an external datastore for retrieving similar skills in a dataset-unifying manner. Our proposed method, \\textbf{N}earest \\textbf{N}eighbor \\textbf{O}ccupational \\textbf{S}kill \\textbf{E}xtraction (NNOSE) effectively leverages multiple datasets by retrieving neighboring skills from other datasets in the datastore. This improves skill extraction \\emph{without} additional fine-tuning. Crucially, we observe a performance gain in predicting infrequent patterns, with substantial gains of up to 30\\% span-F1 in cross-dataset settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at EACL 2024 Main"
    },
    {
        "paper id": "2401.17093",
        "abstract url": "https://arxiv.org/abs/2401.17093",
        "title": "StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "To leverage LLMs for visual synthesis, traditional methods convert raster image information into discrete grid tokens through specialized visual modules, while disrupting the model's ability to capture the true semantic representation of visual scenes. This paper posits that an alternative representation of images, vector graphics, can effectively surmount this limitation by enabling a more natural and semantically coherent segmentation of the image information. Thus, we introduce StrokeNUWA, a pioneering work exploring a better visual representation ''stroke tokens'' on vector graphics, which is inherently visual semantics rich, naturally compatible with LLMs, and highly compressed. Equipped with stroke tokens, StrokeNUWA can significantly surpass traditional LLM-based and optimization-based methods across various metrics in the vector graphic generation task. Besides, StrokeNUWA achieves up to a 94x speedup in inference over the speed of prior methods with an exceptional SVG code compression ratio of 6.9%.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17098",
        "abstract url": "https://arxiv.org/abs/2401.17098",
        "title": "Deep Learning-Driven Approach for Handwritten Chinese Character Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Handwritten character recognition (HCR) is a challenging problem for machine learning researchers. Unlike printed text data, handwritten character datasets have more variation due to human-introduced bias. With numerous unique character classes present, some data, such as Logographic Scripts or Sino-Korean character sequences, bring new complications to the HCR problem. The classification task on such datasets requires the model to learn high-complexity details of the images that share similar features. With recent advances in computational resource availability and further computer vision theory development, some research teams have effectively addressed the arising challenges. Although known for achieving high accuracy while keeping the number of parameters small, many common approaches are still not generalizable and use dataset-specific solutions to achieve better results. Due to complex structure, existing methods frequently prevent the solutions from gaining popularity. This paper proposes a highly scalable approach for detailed character image classification by introducing the model architecture, data preprocessing steps, and testing design instructions. We also perform experiments to compare the performance of our method with that of existing ones to show the improvements achieved.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "30 pages, 9 figures, 2 tables, preprint v2"
    },
    {
        "paper id": "2401.17109",
        "abstract url": "https://arxiv.org/abs/2401.17109",
        "title": "Evaluation in Neural Style Transfer: A Review",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The field of Neural Style Transfer (NST) has witnessed remarkable progress in the past few years, with approaches being able to synthesize artistic and photorealistic images and videos of exceptional quality. To evaluate such results, a diverse landscape of evaluation methods and metrics is used, including authors' opinions based on side-by-side comparisons, human evaluation studies that quantify the subjective judgements of participants, and a multitude of quantitative computational metrics which objectively assess the different aspects of an algorithm's performance. However, there is no consensus regarding the most suitable and effective evaluation procedure that can guarantee the reliability of the results. In this review, we provide an in-depth analysis of existing evaluation techniques, identify the inconsistencies and limitations of current evaluation methods, and give recommendations for standardized evaluation practices. We believe that the development of a robust evaluation framework will not only enable more meaningful and fairer comparisons among NST methods but will also enhance the comprehension and interpretation of research findings in the field.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "21 pages, 8 figures"
    },
    {
        "paper id": "2401.17133",
        "abstract url": "https://arxiv.org/abs/2401.17133",
        "title": "A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Singing voice conversion (SVC) automates song covers by converting one singer's singing voice into another target singer's singing voice with the original lyrics and melody. However, it raises serious concerns about copyright and civil right infringements to multiple entities. This work proposes SongBsAb, the first proactive approach to mitigate unauthorized SVC-based illegal song covers. SongBsAb introduces human-imperceptible perturbations to singing voices before releasing them, so that when they are used, the generation process of SVC will be interfered, resulting in unexpected singing voices. SongBsAb features a dual prevention effect by causing both (singer) identity disruption and lyric disruption, namely, the SVC-covered singing voice neither imitates the target singer nor preserves the original lyrics. To improve the imperceptibility of perturbations, we refine a psychoacoustic model-based loss with the backing track as an additional masker, a unique accompanying element for singing voices compared to ordinary speech voices. To enhance the transferability, we propose to utilize a frame-level interaction reduction-based loss. We demonstrate the prevention effectiveness, utility, and robustness of SongBsAb on three SVC models and two datasets using both objective and human study-based subjective metrics. Our work fosters an emerging research direction for mitigating illegal automated song covers.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CR",
            "cs.LG",
            "cs.MM",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17139",
        "abstract url": "https://arxiv.org/abs/2401.17139",
        "title": "Large Language Model Evaluation via Matrix Entropy",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have revolutionized the field of natural language processing, extending their strong capabilities into multi-modal domains. Thus, it is vital to define proper and diversified metrics for the evaluation of LLMs. In this paper, we introduce matrix entropy, a novel metric rooted in information theory and geometry principles to quantify the data compression proficiency in LLMs. It reflects the model's ability to extract relevant information and eliminate unnecessary elements, thereby providing insight into the language model's intrinsic capability. Specifically, we demonstrate its applicability in both single-modal (language) and multi-modal settings. For language models, our findings reveal that the matrix entropy of representations follows a scaling law type reduction when the model scales up, serving as a complement to the traditional loss scaling law. For the multi-modal setting, we also propose an evaluation method based on matrix entropy for assessing alignment quality and we find that modern large multi-modal models exhibit great alignment performance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17151",
        "abstract url": "https://arxiv.org/abs/2401.17151",
        "title": "An Open Software Suite for Event-Based Video",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "While traditional video representations are organized around discrete image frames, event-based video is a new paradigm that forgoes image frames altogether. Rather, pixel samples are temporally asynchronous and independent of one another. Until now, researchers have lacked a cohesive software framework for exploring the representation, compression, and applications of event-based video. I present the AD$\u0394$ER software suite to fill this gap. This framework includes utilities for transcoding framed and multimodal event-based video sources to a common representation, rate control mechanisms, lossy compression, application support, and an interactive GUI for transcoding and playback. In this paper, I describe these various software components and their usage.",
        "subjects": [
            "cs.MM",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17167",
        "abstract url": "https://arxiv.org/abs/2401.17167",
        "title": "Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The recent trend of using Large Language Models (LLMs) as tool agents in real-world applications underscores the necessity for comprehensive evaluations of their capabilities, particularly in complex scenarios involving planning, creating, and using tools. However, existing benchmarks typically focus on simple synthesized queries that do not reflect real-world complexity, thereby offering limited perspectives in evaluating tool utilization. To address this issue, we present UltraTool, a novel benchmark designed to improve and evaluate LLMs' ability in tool utilization within real-world scenarios. UltraTool focuses on the entire process of using tools - from planning and creating to applying them in complex tasks. It emphasizes real-world complexities, demanding accurate, multi-step planning for effective problem-solving. A key feature of UltraTool is its independent evaluation of planning with natural language, which happens before tool usage and simplifies the task solving by mapping out the intermediate steps. Thus, unlike previous work, it eliminates the restriction of pre-defined toolset. Through extensive experiments on various LLMs, we offer novel insights into the evaluation of capabilities of LLMs in tool utilization, thereby contributing a fresh perspective to this rapidly evolving field. The benchmark is publicly available at https://github.com/JoeYing1019/UltraTool.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17169",
        "abstract url": "https://arxiv.org/abs/2401.17169",
        "title": "Conditional and Modal Reasoning in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The reasoning abilities of large language models (LLMs) are the topic of a growing body of research in artificial intelligence and cognitive science. In this paper, we probe the extent to which a dozen LLMs are able to distinguish logically correct inferences from logically fallacious ones. We focus on inference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These inference patterns have been of special interest to logicians, philosophers, and linguists, since they plausibly play a central role in human reasoning. Assessing LLMs on these inference patterns is thus highly relevant to the question of how much the reasoning abilities of LLMs match those of humans. Among the LLMs we tested, all but GPT-4 often make basic mistakes with conditionals. Moreover, even GPT-4 displays logically inconsistent judgments across inference patterns involving epistemic modals.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LO"
        ],
        "comment": "11 pages, 16 figures. Code and data available at https://github.com/wesholliday/llm-logic"
    },
    {
        "paper id": "2401.17200",
        "abstract url": "https://arxiv.org/abs/2401.17200",
        "title": "NormEnsembleXAI: Unveiling the Strengths and Weaknesses of XAI Ensemble Techniques",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a comprehensive comparative analysis of explainable artificial intelligence (XAI) ensembling methods. Our research brings three significant contributions. Firstly, we introduce a novel ensembling method, NormEnsembleXAI, that leverages minimum, maximum, and average functions in conjunction with normalization techniques to enhance interpretability. Secondly, we offer insights into the strengths and weaknesses of XAI ensemble methods. Lastly, we provide a library, facilitating the practical implementation of XAI ensembling, thus promoting the adoption of transparent and interpretable deep learning models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17203",
        "abstract url": "https://arxiv.org/abs/2401.17203",
        "title": "CPR++: Object Localization via Single Coarse Point Supervision",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Point-based object localization (POL), which pursues high-performance object sensing under low-cost data annotation, has attracted increased attention. However, the point annotation mode inevitably introduces semantic variance due to the inconsistency of annotated points. Existing POL heavily rely on strict annotation rules, which are difficult to define and apply, to handle the problem. In this study, we propose coarse point refinement (CPR), which to our best knowledge is the first attempt to alleviate semantic variance from an algorithmic perspective. CPR reduces the semantic variance by selecting a semantic centre point in a neighbourhood region to replace the initial annotated point. Furthermore, We design a sampling region estimation module to dynamically compute a sampling region for each object and use a cascaded structure to achieve end-to-end optimization. We further integrate a variance regularization into the structure to concentrate the predicted scores, yielding CPR++. We observe that CPR++ can obtain scale information and further reduce the semantic variance in a global region, thus guaranteeing high-performance object localization. Extensive experiments on four challenging datasets validate the effectiveness of both CPR and CPR++. We hope our work can inspire more research on designing algorithms rather than annotation rules to address the semantic variance problem in POL. The dataset and code will be public at github.com/ucas-vg/PointTinyBenchmark.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accpted by TPAMI 2024"
    },
    {
        "paper id": "2401.17217",
        "abstract url": "https://arxiv.org/abs/2401.17217",
        "title": "GazeGPT: Augmenting Human Capabilities using Gaze-contingent Contextual AI for Smart Eyewear",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal large language models (LMMs) excel in world knowledge and problem-solving abilities. Through the use of a world-facing camera and contextual AI, emerging smart accessories aim to provide a seamless interface between humans and LMMs. Yet, these wearable computing systems lack an understanding of the user's attention. We introduce GazeGPT as a new user interaction paradigm for contextual AI. GazeGPT uses eye tracking to help the LMM understand which object in the world-facing camera view a user is paying attention to. Using extensive user evaluations, we show that this gaze-contingent mechanism is a faster and more accurate pointing mechanism than alternatives; that it augments human capabilities by significantly improving their accuracy in a dog-breed classification task; and that it is consistently ranked as more natural than head- or body-driven selection mechanisms for contextual AI. Moreover, we prototype a variety of application scenarios that suggest GazeGPT could be of significant value to users as part of future AI-driven personal assistants.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "comment": "Project video: https://youtu.be/AuDFHHTK_m8"
    },
    {
        "paper id": "2401.17228",
        "abstract url": "https://arxiv.org/abs/2401.17228",
        "title": "Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in NLP show that language models retain a discernible level of knowledge in deontological ethics and moral norms. However, existing works often treat morality as binary, ranging from right to wrong. This simplistic view does not capture the nuances of moral judgment. Pluralist moral philosophers argue that human morality can be deconstructed into a finite number of elements, respecting individual differences in moral judgment. In line with this view, we build a pluralist moral sentence embedding space via a state-of-the-art contrastive learning approach. We systematically investigate the embedding space by studying the emergence of relationships among moral elements, both quantitatively and qualitatively. Our results show that a pluralist approach to morality can be captured in an embedding space. However, moral pluralism is challenging to deduce via self-supervision alone and requires a supervised approach with human labels.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "To appear in Findings of EACL 2024"
    },
    {
        "paper id": "2401.17230",
        "abstract url": "https://arxiv.org/abs/2401.17230",
        "title": "ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces ESPnet-SPK, a toolkit designed with several objectives for training speaker embedding extractors. First, we provide an open-source platform for researchers in the speaker recognition community to effortlessly build models. We provide several models, ranging from x-vector to recent SKA-TDNN. Through the modularized architecture design, variants can be developed easily. We also aspire to bridge developed models with other domains, facilitating the broad research community to effortlessly incorporate state-of-the-art embedding extractors. Pre-trained embedding extractors can be accessed in an off-the-shelf manner and we demonstrate the toolkit's versatility by showcasing its integration with two tasks. Another goal is to integrate with diverse self-supervised learning features. We release a reproducible recipe that achieves an equal error rate of 0.39% on the Vox1-O evaluation protocol using WavLM-Large with ECAPA-TDNN.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "5 pages, 3 figures, 7 tables"
    },
    {
        "paper id": "2401.17246",
        "abstract url": "https://arxiv.org/abs/2401.17246",
        "title": "SLIC: A Learned Image Codec Using Structure and Color",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We propose the structure and color based learned image codec (SLIC) in which the task of compression is split into that of luminance and chrominance. The deep learning model is built with a novel multi-scale architecture for Y and UV channels in the encoder, where the features from various stages are combined to obtain the latent representation. An autoregressive context model is employed for backward adaptation and a hyperprior block for forward adaptation. Various experiments are carried out to study and analyze the performance of the proposed model, and to compare it with other image codecs. We also illustrate the advantages of our method through the visualization of channel impulse responses, latent channels and various ablation studies. The model achieves Bj\u00f8ntegaard delta bitrate gains of 7.5% and 4.66% in terms of MS-SSIM and CIEDE2000 metrics with respect to other state-of-the-art reference codecs.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepter paper for Data Compression Conference 2024"
    },
    {
        "paper id": "2401.17268",
        "abstract url": "https://arxiv.org/abs/2401.17268",
        "title": "Weaver: Foundation Models for Creative Writing",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This work introduces Weaver, our first family of large language models (LLMs) dedicated to content creation. Weaver is pre-trained on a carefully selected corpus that focuses on improving the writing capabilities of large language models. We then fine-tune Weaver for creative and professional writing purposes and align it to the preference of professional writers using a suit of novel methods for instruction data synthesis and LLM alignment, making it able to produce more human-like texts and follow more diverse instructions for content creation. The Weaver family consists of models of Weaver Mini (1.8B), Weaver Base (6B), Weaver Pro (14B), and Weaver Ultra (34B) sizes, suitable for different applications and can be dynamically dispatched by a routing agent according to query complexity to balance response quality and computation cost. Evaluation on a carefully curated benchmark for assessing the writing capabilities of LLMs shows Weaver models of all sizes outperform generalist LLMs several times larger than them. Notably, our most-capable Weaver Ultra model surpasses GPT-4, a state-of-the-art generalist LLM, on various writing scenarios, demonstrating the advantage of training specialized LLMs for writing purposes. Moreover, Weaver natively supports retrieval-augmented generation (RAG) and function calling (tool usage). We present various use cases of these abilities for improving AI-assisted writing systems, including integration of external knowledge bases, tools, or APIs, and providing personalized writing assistance. Furthermore, we discuss and summarize a guideline and best practices for pre-training and fine-tuning domain-specific LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17271",
        "abstract url": "https://arxiv.org/abs/2401.17271",
        "title": "A simple, strong baseline for building damage detection on the xBD dataset",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We construct a strong baseline method for building damage detection by starting with the highly-engineered winning solution of the xView2 competition, and gradually stripping away components. This way, we obtain a much simpler method, while retaining adequate performance. We expect the simplified solution to be more widely and easily applicable. This expectation is based on the reduced complexity, as well as the fact that we choose hyperparameters based on simple heuristics, that transfer to other datasets. We then re-arrange the xView2 dataset splits such that the test locations are not seen during training, contrary to the competition setup. In this setting, we find that both the complex and the simplified model fail to generalize to unseen locations. Analyzing the dataset indicates that this failure to generalize is not only a model-based problem, but that the difficulty might also be influenced by the unequal class distributions between events. Code, including the baseline model, is available under https://github.com/PaulBorneP/Xview2_Strong_Baseline",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2401.17373",
        "abstract url": "https://arxiv.org/abs/2401.17373",
        "title": "Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Speech acts are a speakers actions when performing an utterance within a conversation, such as asking, recommending, greeting, or thanking someone, expressing a thought, or making a suggestion. Understanding speech acts helps interpret the intended meaning and actions behind a speakers or writers words. This paper proposes a Twitter dialectal Arabic speech act classification approach based on a transformer deep learning neural network. Twitter and social media, are becoming more and more integrated into daily life. As a result, they have evolved into a vital source of information that represents the views and attitudes of their users. We proposed a BERT based weighted ensemble learning approach to integrate the advantages of various BERT models in dialectal Arabic speech acts classification. We compared the proposed model against several variants of Arabic BERT models and sequence-based models. We developed a dialectal Arabic tweet act dataset by annotating a subset of a large existing Arabic sentiment analysis dataset (ASAD) based on six speech act categories. We also evaluated the models on a previously developed Arabic Tweet Act dataset (ArSAS). To overcome the class imbalance issue commonly observed in speech act problems, a transformer-based data augmentation model was implemented to generate an equal proportion of speech act categories. The results show that the best BERT model is araBERTv2-Twitter models with a macro-averaged F1 score and an accuracy of 0.73 and 0.84, respectively. The performance improved using a BERT-based ensemble method with a 0.74 and 0.85 averaged F1 score and accuracy on our dataset, respectively.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "16 pages, 6 figures"
    },
    {
        "paper id": "2401.17377",
        "abstract url": "https://arxiv.org/abs/2401.17377",
        "title": "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Are $n$-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we showcase their values in both text analysis and improving neural LLMs. This was done by modernizing $n$-gram LMs in two aspects. First, we train them at the same data scale as neural LLMs -- 5 trillion tokens. This is the largest $n$-gram LM ever built. Second, existing $n$-gram LMs use small $n$ which hinders their performance; we instead allow $n$ to be arbitrarily large, by introducing a new $\\infty$-gram LM with backoff. Instead of pre-computing $n$-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\\infty$-gram (as well as $n$-gram with arbitrary $n$) probabilities with millisecond-level latency. The $\\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\\infty$-gram LM has fairly high accuracy for next-token prediction (47%), and can complement neural LLMs to greatly reduce their perplexity. When analyzing machine-generated text, we also observe irregularities in the machine--$\\infty$-gram agreement level with respect to the suffix length, which indicates deficiencies in neural LLM pretraining and the positional embeddings of Transformers.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17396",
        "abstract url": "https://arxiv.org/abs/2401.17396",
        "title": "Fine-tuning Transformer-based Encoder for Turkish Language Understanding Tasks",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Deep learning-based and lately Transformer-based language models have been dominating the studies of natural language processing in the last years. Thanks to their accurate and fast fine-tuning characteristics, they have outperformed traditional machine learning-based approaches and achieved state-of-the-art results for many challenging natural language understanding (NLU) problems. Recent studies showed that the Transformer-based models such as BERT, which is Bidirectional Encoder Representations from Transformers, have reached impressive achievements on many tasks. Moreover, thanks to their transfer learning capacity, these architectures allow us to transfer pre-built models and fine-tune them to specific NLU tasks such as question answering. In this study, we provide a Transformer-based model and a baseline benchmark for the Turkish Language. We successfully fine-tuned a Turkish BERT model, namely BERTurk that is trained with base settings, to many downstream tasks and evaluated with a the Turkish Benchmark dataset. We showed that our studies significantly outperformed other existing baseline approaches for Named-Entity Recognition, Sentiment Analysis, Question Answering and Text Classification in Turkish Language. We publicly released these four fine-tuned models and resources in reproducibility and with the view of supporting other Turkish researchers and applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17400",
        "abstract url": "https://arxiv.org/abs/2401.17400",
        "title": "CALM: Convolution As Local Mixture",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we showed that the feature map of a convolution layer is equivalent to the unnormalized log posterior of a special kind of Gaussian mixture for image modeling. Then we expanded the model to drive diverse features and proposed a corresponding EM algorithm to learn the model. Learning convolution weights using this approach is efficient, guaranteed to converge, and does not need supervised information. Code is available at: https://github.com/LifanLiang/CALM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17417",
        "abstract url": "https://arxiv.org/abs/2401.17417",
        "title": "Through-Wall Imaging based on WiFi Channel State Information",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This work presents a seminal approach for synthesizing images from WiFi Channel State Information (CSI) in through-wall scenarios. Leveraging the strengths of WiFi, such as cost-effectiveness, illumination invariance, and wall-penetrating capabilities, our approach enables visual monitoring of indoor environments beyond room boundaries and without the need for cameras. More generally, it improves the interpretability of WiFi CSI by unlocking the option to perform image-based downstream tasks, e.g., visual activity recognition. In order to achieve this crossmodal translation from WiFi CSI to images, we rely on a multimodal Variational Autoencoder (VAE) adapted to our problem specifics. We extensively evaluate our proposed methodology through an ablation study on architecture configuration and a quantitative/qualitative assessment of reconstructed images. Our results demonstrate the viability of our method and highlight its potential for practical applications.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17435",
        "abstract url": "https://arxiv.org/abs/2401.17435",
        "title": "Can Large Language Models Replace Economic Choice Prediction Labs?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Economic choice prediction is an essential challenging task, often constrained by the difficulties in acquiring human choice data. Indeed, experimental economics studies had focused mostly on simple choice settings. The AI community has recently contributed to that effort in two ways: considering whether LLMs can substitute for humans in the above-mentioned simple choice prediction settings, and the study through ML lens of more elaborated but still rigorous experimental economics settings, employing incomplete information, repetitive play, and natural language communication, notably language-based persuasion games. This leaves us with a major inspiration: can LLMs be used to fully simulate the economic environment and generate data for efficient human choice prediction, substituting for the elaborated economic lab studies? We pioneer the study of this subject, demonstrating its feasibility. In particular, we show that a model trained solely on LLM-generated data can effectively predict human behavior in a language-based persuasion game, and can even outperform models trained on actual human data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.GT",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17464",
        "abstract url": "https://arxiv.org/abs/2401.17464",
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning. In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding and calling of external tools in parallel, which avoids the inference delay caused by waiting for tool responses. In mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average ~6% absolute QA accuracy improvement. LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17497",
        "abstract url": "https://arxiv.org/abs/2401.17497",
        "title": "Towards Visual Syntactical Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Syntax is usually studied in the realm of linguistics and refers to the arrangement of words in a sentence. Similarly, an image can be considered as a visual 'sentence', with the semantic parts of the image acting as 'words'. While visual syntactic understanding occurs naturally to humans, it is interesting to explore whether deep neural networks (DNNs) are equipped with such reasoning. To that end, we alter the syntax of natural images (e.g. swapping the eye and nose of a face), referred to as 'incorrect' images, to investigate the sensitivity of DNNs to such syntactic anomaly. Through our experiments, we discover an intriguing property of DNNs where we observe that state-of-the-art convolutional neural networks, as well as vision transformers, fail to discriminate between syntactically correct and incorrect images when trained on only correct ones. To counter this issue and enable visual syntactic understanding with DNNs, we propose a three-stage framework- (i) the 'words' (or the sub-features) in the image are detected, (ii) the detected words are sequentially masked and reconstructed using an autoencoder, (iii) the original and reconstructed parts are compared at each location to determine syntactic correctness. The reconstruction module is trained with BERT-like masked autoencoding for images, with the motivation to leverage language model inspired training to better capture the syntax. Note, our proposed approach is unsupervised in the sense that the incorrect images are only used during testing and the correct versus incorrect labels are never used for training. We perform experiments on CelebA, and AFHQ datasets and obtain classification accuracy of 92.10%, and 90.89%, respectively. Notably, the approach generalizes well to ImageNet samples which share common classes with CelebA and AFHQ without explicitly training on them.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17498",
        "abstract url": "https://arxiv.org/abs/2401.17498",
        "title": "Improving QA Model Performance with Cartographic Inoculation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "QA models are faced with complex and open-ended contextual reasoning problems, but can often learn well-performing solution heuristics by exploiting dataset-specific patterns in their training data. These patterns, or \"dataset artifacts\", reduce the model's ability to generalize to real-world QA problems. Utilizing an ElectraSmallDiscriminator model trained for QA, we analyze the impacts and incidence of dataset artifacts using an adversarial challenge set designed to confuse models reliant on artifacts for prediction. Extending existing work on methods for mitigating artifact impacts, we propose cartographic inoculation, a novel method that fine-tunes models on an optimized subset of the challenge data to reduce model reliance on dataset artifacts. We show that by selectively fine-tuning a model on ambiguous adversarial examples from a challenge set, significant performance improvements can be made on the full challenge dataset with minimal loss of model generalizability to other challenging environments and QA datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 pages, 6 figures"
    },
    {
        "paper id": "2401.17505",
        "abstract url": "https://arxiv.org/abs/2401.17505",
        "title": "Arrows of Time for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We study the probabilistic modeling performed by Autoregressive Large Language Models through the angle of time directionality. We empirically find a time asymmetry exhibited by such models in their ability to model natural language: a difference in the average log-perplexity when trying to predict the next token versus when trying to predict the previous one. This difference is at the same time subtle and very consistent across various modalities (language, model size, training time, ...). Theoretically, this is surprising: from an information-theoretic point of view, there should be no such difference. We provide a theoretical framework to explain how such an asymmetry can appear from sparsity and computational complexity considerations, and outline a number of perspectives opened by our results.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Updated 1 figure, minor corrections to text. 11 figures, 16 pages"
    },
    {
        "paper id": "2401.17514",
        "abstract url": "https://arxiv.org/abs/2401.17514",
        "title": "How Useful is Continued Pre-Training for Generative Unsupervised Domain Adaptation?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent breakthroughs in scale have enabled the emergence of powerful generative language models, and the ability to fine-tune these models on various tasks by casting them into prompts or instructions. In this landscape, the problem of Unsupervised Domain Adaptation (UDA), or the problem of leveraging knowledge from a labeled source domain to an unlabeled target domain, has been left behind, with recent UDA methods still addressing discriminative classification. In particular, two popular UDA approaches, involving Continued Pre-Training (CPT) and learning domain invariant representations, have been under-explored in the generative setting, signaling a gap. In this work, we evaluate the utility of CPT for generative UDA. We first perform an empirical evaluation to measure the trade-offs between CPT and strong methods promoting domain invariance. We further evaluate how well the benefits of CPT extend to different architectures, tuning methods and data regimes. We then motivate the use of CPT by studying to what degree it benefits classification performance on the target domain. Finally, we attempt to understand the mechanism behind which CPT improves classification performance on the unlabeled target domain. Our findings suggest that a implicitly learns the downstream task while predicting masked words informative to that task. Our work connects the body of UDA research with that of instruction tuning, enabling an initial step towards a wider applicability of modern language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17573",
        "abstract url": "https://arxiv.org/abs/2401.17573",
        "title": "Tensor-based process control and monitoring for semiconductor manufacturing with unstable disturbances",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "With the development and popularity of sensors installed in manufacturing systems, complex data are collected during manufacturing processes, which brings challenges for traditional process control methods. This paper proposes a novel process control and monitoring method for the complex structure of high-dimensional image-based overlay errors (modeled in tensor form), which are collected in semiconductor manufacturing processes. The proposed method aims to reduce overlay errors using limited control recipes. We first build a high-dimensional process model and propose different tensor-on-vector regression algorithms to estimate parameters in the model to alleviate the curse of dimensionality. Then, based on the estimate of tensor parameters, the exponentially weighted moving average (EWMA) controller for tensor data is designed whose stability is theoretically guaranteed. Considering the fact that low-dimensional control recipes cannot compensate for all high-dimensional disturbances on the image, control residuals are monitored to prevent significant drifts of uncontrollable high-dimensional disturbances. Through extensive simulations and real case studies, the performances of parameter estimation algorithms and the EWMA controller in tensor space are evaluated. Compared with existing image-based feedback controllers, the superiority of our method is verified especially when disturbances are not stable.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.IV",
            "eess.SY"
        ],
        "comment": "30 pages, 5 figures"
    },
    {
        "paper id": "2401.17574",
        "abstract url": "https://arxiv.org/abs/2401.17574",
        "title": "Scavenging Hyena: Distilling Transformers into Long Convolution Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid evolution of Large Language Models (LLMs), epitomized by architectures like GPT-4, has reshaped the landscape of natural language processing. This paper introduces a pioneering approach to address the efficiency concerns associated with LLM pre-training, proposing the use of knowledge distillation for cross-architecture transfer. Leveraging insights from the efficient Hyena mechanism, our method replaces attention heads in transformer models by Hyena, offering a cost-effective alternative to traditional pre-training while confronting the challenge of processing long contextual information, inherent in quadratic attention mechanisms. Unlike conventional compression-focused methods, our technique not only enhances inference speed but also surpasses pre-training in terms of both accuracy and efficiency. In the era of evolving LLMs, our work contributes to the pursuit of sustainable AI solutions, striking a balance between computational power and environmental impact.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "9 pages, 2 figures"
    },
    {
        "paper id": "2401.17588",
        "abstract url": "https://arxiv.org/abs/2401.17588",
        "title": "Local and Global Contexts for Conversation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The context in conversation is the dialog history crucial for multi-turn dialogue. Learning from the relevant contexts in dialog history for grounded conversation is a challenging problem. Local context is the most neighbor and more sensitive to the subsequent response, and global context is relevant to a whole conversation far beyond neighboring utterances. Currently, pretrained transformer models for conversation challenge capturing the correlation and connection between local and global contexts. We introduce a local and global conversation model (LGCM) for general-purpose conversation in open domain. It is a local-global hierarchical transformer model that excels at accurately discerning and assimilating the relevant contexts necessary for generating responses. It employs a local encoder to grasp the local context at the level of individual utterances and a global encoder to understand the broader context at the dialogue level. The seamless fusion of these locally and globally contextualized encodings ensures a comprehensive comprehension of the conversation. Experiments on popular datasets show that LGCM outperforms the existing conversation models on the performance of automatic metrics with significant margins.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages, 3 figures"
    },
    {
        "paper id": "2401.17597",
        "abstract url": "https://arxiv.org/abs/2401.17597",
        "title": "SPECTRUM: Speaker-Enhanced Pre-Training for Long Dialogue Summarization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multi-turn dialogues are characterized by their extended length and the presence of turn-taking conversations. Traditional language models often overlook the distinct features of these dialogues by treating them as regular text. In this paper, we propose a speaker-enhanced pre-training method for long dialogue summarization, which leverages the inherent structure of multiple-turn dialogues. To support our study, we curate a diverse dataset that includes transcripts from real-world scenarios, movie or TV show transcripts, and dialogues generated by a Large Language Model. We then perform a pre-training, which encompasses the detection of speaker changes, and masked utterance generation. Experimental results of fine-tuned models demonstrate that our model achieves state-of-the-art performance on downstream benchmarks with long context, surpassing baseline models and highlighting the effectiveness of our approach. Our findings highlight the importance of curating pre-training datasets that exhibit diversity and variations in length distribution to ensure effective alignment with downstream datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages, 2 figures"
    },
    {
        "paper id": "2402.00070",
        "abstract url": "https://arxiv.org/abs/2402.00070",
        "title": "EvoMerge: Neuroevolution for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Extensive fine-tuning on Large Language Models does not always yield better results. Oftentimes, models tend to get better at imitating one form of data without gaining greater reasoning ability and may even end up losing some intelligence. Here I introduce EvoMerge, a systematic approach to large language model training and merging. Leveraging model merging for weight crossover and fine-tuning for weight mutation, EvoMerge establishes an evolutionary process aimed at pushing models beyond the limits of conventional fine-tuning.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "The current submission is the first draft, published for the sole purpose of sharing an idea and encouraging community effort. A more consolidated version may come later"
    },
    {
        "paper id": "2402.00075",
        "abstract url": "https://arxiv.org/abs/2402.00075",
        "title": "D-Nikud: Enhancing Hebrew Diacritization with LSTM and Pretrained Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "D-Nikud, a novel approach to Hebrew diacritization that integrates the strengths of LSTM networks and BERT-based (transformer) pre-trained model. Inspired by the methodologies employed in Nakdimon, we integrate it with the TavBERT pre-trained model, our system incorporates advanced architectural choices and diverse training data. Our experiments showcase state-of-the-art results on several benchmark datasets, with a particular emphasis on modern texts and more specified diacritization like gender.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00891",
        "abstract url": "https://arxiv.org/abs/2402.00891",
        "title": "Large Language Models in Cybersecurity: State-of-the-Art",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rise of Large Language Models (LLMs) has revolutionized our comprehension of intelligence bringing us closer to Artificial Intelligence. Since their introduction, researchers have actively explored the applications of LLMs across diverse fields, significantly elevating capabilities. Cybersecurity, traditionally resistant to data-driven solutions and slow to embrace machine learning, stands out as a domain. This study examines the existing literature, providing a thorough characterization of both defensive and adversarial applications of LLMs within the realm of cybersecurity. Our review not only surveys and categorizes the current landscape but also identifies critical research gaps. By evaluating both offensive and defensive applications, we aim to provide a holistic understanding of the potential risks and opportunities associated with LLM-driven cybersecurity.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01750",
        "abstract url": "https://arxiv.org/abs/2402.01750",
        "title": "PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Current communication technologies face limitations in terms of theoretical capacity, spectrum availability, and power resources. Pragmatic communication, leveraging terminal intelligence for selective data transmission, offers resource conservation. Existing research lacks universal intention resolution tools, limiting applicability to specific tasks. This paper proposes an image pragmatic communication framework based on a Pragmatic Agent for Communication Efficiency (PACE) using Large Language Models (LLM). In this framework, PACE sequentially performs semantic perception, intention resolution, and intention-oriented coding. To ensure the effective utilization of LLM in communication, a knowledge base is designed to supplement the necessary knowledge, dedicated prompts are introduced to facilitate understanding of pragmatic communication scenarios and task requirements, and a chain of thought is designed to assist in making reasonable trade-offs between transmission efficiency and cost. For experimental validation, this paper constructs an image pragmatic communication dataset along with corresponding evaluation standards. Simulation results indicate that the proposed method outperforms traditional and non-LLM-based pragmatic communication in terms of transmission efficiency.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "11 pages,11 figures, submitted to IJCAI 2024"
    },
    {
        "paper id": "2402.01752",
        "abstract url": "https://arxiv.org/abs/2402.01752",
        "title": "Identifying False Content and Hate Speech in Sinhala YouTube Videos by Analyzing the Audio",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "YouTube faces a global crisis with the dissemination of false information and hate speech. To counter these issues, YouTube has implemented strict rules against uploading content that includes false information or promotes hate speech. While numerous studies have been conducted to reduce offensive English-language content, there's a significant lack of research on Sinhala content. This study aims to address the aforementioned gap by proposing a solution to minimize the spread of violence and misinformation in Sinhala YouTube videos. The approach involves developing a rating system that assesses whether a video contains false information by comparing the title and description with the audio content and evaluating whether the video includes hate speech. The methodology encompasses several steps, including audio extraction using the Pytube library, audio transcription via the fine-tuned Whisper model, hate speech detection employing the distilroberta-base model and a text classification LSTM model, and text summarization through the fine-tuned BART-Large- XSUM model. Notably, the Whisper model achieved a 48.99\\% word error rate, while the distilroberta-base model demonstrated an F1 score of 0.856 and a recall value of 0.861 in comparison to the LSTM model, which exhibited signs of overfitting.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01758",
        "abstract url": "https://arxiv.org/abs/2402.01758",
        "title": "Aalap: AI Assistant for Legal & Paralegal Functions in India",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Using proprietary Large Language Models on legal tasks poses challenges due to data privacy issues, domain data heterogeneity, domain knowledge sophistication, and domain objectives uniqueness. We created Aalalp, a fine-tuned Mistral 7B model on instructions data related to specific Indian legal tasks. The performance of Aalap is better than gpt-3.5-turbo in 31\\% of our test data and obtains an equivalent score in 34\\% of the test data as evaluated by GPT4. Training Aalap mainly focuses on teaching legal reasoning rather than legal recall. Aalap is definitely helpful for the day-to-day activities of lawyers, judges, or anyone working in legal systems.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01760",
        "abstract url": "https://arxiv.org/abs/2402.01760",
        "title": "Trust and ethical considerations in a multi-modal, explainable AI-driven chatbot tutoring system: The case of collaboratively solving Rubik's Cube",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Artificial intelligence (AI) has the potential to transform education with its power of uncovering insights from massive data about student learning patterns. However, ethical and trustworthy concerns of AI have been raised but are unsolved. Prominent ethical issues in high school AI education include data privacy, information leakage, abusive language, and fairness. This paper describes technological components that were built to address ethical and trustworthy concerns in a multi-modal collaborative platform (called ALLURE chatbot) for high school students to collaborate with AI to solve the Rubik's cube. In data privacy, we want to ensure that the informed consent of children, parents, and teachers, is at the center of any data that is managed. Since children are involved, language, whether textual, audio, or visual, is acceptable both from users and AI and the system can steer interaction away from dangerous situations. In information management, we also want to ensure that the system, while learning to improve over time, does not leak information about users from one group to another.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": "Accepted at 'Neural Conversational AI Workshop - What's left to TEACH (Trustworthy, Enhanced, Adaptable, Capable, and Human-centric) chatbots?' at ICML 2023"
    },
    {
        "paper id": "2402.01761",
        "abstract url": "https://arxiv.org/abs/2402.01761",
        "title": "Rethinking Interpretability in the Era of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Interpretable machine learning has exploded as an area of interest over the last decade, sparked by the rise of increasingly large datasets and deep neural networks. Simultaneously, large language models (LLMs) have demonstrated remarkable capabilities across a wide array of tasks, offering a chance to rethink opportunities in interpretable machine learning. Notably, the capability to explain in natural language allows LLMs to expand the scale and complexity of patterns that can be given to a human. However, these new capabilities raise new challenges, such as hallucinated explanations and immense computational costs. In this position paper, we start by reviewing existing methods to evaluate the emerging field of LLM interpretation (both interpreting LLMs and using LLMs for explanation). We contend that, despite their limitations, LLMs hold the opportunity to redefine interpretability with a more ambitious scope across many applications, including in auditing LLMs themselves. We highlight two emerging research priorities for LLM interpretation: using LLMs to directly analyze new datasets and to generate interactive explanations.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2402.01763",
        "abstract url": "https://arxiv.org/abs/2402.01763",
        "title": "When Large Language Models Meet Vector Databases: A Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This survey explores the synergistic potential of Large Language Models (LLMs) and Vector Databases (VecDBs), a burgeoning but rapidly evolving research area. With the proliferation of LLMs comes a host of challenges, including hallucinations, outdated knowledge, prohibitive commercial application costs, and memory issues. VecDBs emerge as a compelling solution to these issues by offering an efficient means to store, retrieve, and manage the high-dimensional vector representations intrinsic to LLM operations. Through this nuanced review, we delineate the foundational principles of LLMs and VecDBs and critically analyze their integration's impact on enhancing LLM functionalities. This discourse extends into a discussion on the speculative future developments in this domain, aiming to catalyze further research into optimizing the confluence of LLMs and VecDBs for advanced data handling and knowledge extraction capabilities.",
        "subjects": [
            "cs.DB",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.07913",
        "abstract url": "https://arxiv.org/abs/2402.07913",
        "title": "QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In online learning platforms, particularly in rapidly growing computer programming courses, addressing the thousands of students' learning queries requires considerable human cost. The creation of intelligent assistant large language models (LLMs) tailored for programming education necessitates distinct data support. However, in real application scenarios, the data resources for training such LLMs are relatively scarce. Therefore, to address the data scarcity in intelligent educational systems for programming, this paper proposes a new Chinese question-and-answer dataset for Python learners. To ensure the authenticity and reliability of the sources of the questions, we collected questions from actual student questions and categorized them according to various dimensions such as the type of questions and the type of learners. This annotation principle is designed to enhance the effectiveness and quality of online programming education, providing a solid data foundation for developing the programming teaching assists (TA). Furthermore, we conducted comprehensive evaluations of various LLMs proficient in processing and generating Chinese content, highlighting the potential limitations of general LLMs as intelligent teaching assistants in computer programming courses.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08788",
        "abstract url": "https://arxiv.org/abs/2403.08788",
        "title": "Verification for Object Detection -- IBP IoU",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a novel Interval Bound Propagation (IBP) approach for the formal verification of object detection models, specifically targeting the Intersection over Union (IoU) metric. The approach has been implemented in an open source code, named IBP IoU, compatible with popular abstract interpretation based verification tools. The resulting verifier is evaluated on landing approach runway detection and handwritten digit recognition case studies. Comparisons against a baseline (Vanilla IBP IoU) highlight the superior performance of IBP IoU in ensuring accuracy and stability, contributing to more secure and robust machine learning applications.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08793",
        "abstract url": "https://arxiv.org/abs/2403.08793",
        "title": "Neural Loss Function Evolution for Large-Scale Image Classifier Convolutional Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "For classification, neural networks typically learn by minimizing cross-entropy, but are evaluated and compared using accuracy. This disparity suggests neural loss function search (NLFS), the search for a drop-in replacement loss function of cross-entropy for neural networks. We apply NLFS to image classifier convolutional neural networks. We propose a new search space for NLFS that encourages more diverse loss functions to be explored, and a surrogate function that accurately transfers to large-scale convolutional neural networks. We search the space using regularized evolution, a mutation-only aging genetic algorithm. After evolution and a proposed loss function elimination protocol, we transferred the final loss functions across multiple architectures, datasets, and image augmentation techniques to assess generalization. In the end, we discovered three new loss functions, called NeuroLoss1, NeuroLoss2, and NeuroLoss3 that were able to outperform cross-entropy in terms of a higher mean test accuracy as a simple drop-in replacement loss function across the majority of experiments.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.16038",
        "abstract url": "https://arxiv.org/abs/2404.16038",
        "title": "A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper offers an insightful examination of how currently top-trending AI technologies, i.e., generative artificial intelligence (Generative AI) and large language models (LLMs), are reshaping the field of video technology, including video generation, understanding, and streaming. It highlights the innovative use of these technologies in producing highly realistic videos, a significant leap in bridging the gap between real-world dynamics and digital creation. The study also delves into the advanced capabilities of LLMs in video understanding, demonstrating their effectiveness in extracting meaningful information from visual content, thereby enhancing our interaction with videos. In the realm of video streaming, the paper discusses how LLMs contribute to more efficient and user-centric streaming experiences, adapting content delivery to individual viewer preferences. This comprehensive review navigates through the current achievements, ongoing challenges, and future possibilities of applying Generative AI and LLMs to video-related tasks, underscoring the immense potential these technologies hold for advancing the field of video technology related to multimedia, networking, and AI communities.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "16 pages, 10 figures, 4 tables"
    },
    {
        "paper id": "2401.16757",
        "abstract url": "https://arxiv.org/abs/2401.16757",
        "title": "SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Executing deep neural networks (DNNs) on edge artificial intelligence (AI) devices enables various autonomous mobile computing applications. However, the memory budget of edge AI devices restricts the number and complexity of DNNs allowed in such applications. Existing solutions, such as model compression or cloud offloading, reduce the memory footprint of DNN inference at the cost of decreased model accuracy or autonomy. To avoid these drawbacks, we divide DNN into blocks and swap them in and out in order, such that large DNNs can execute within a small memory budget. Nevertheless, naive swapping on edge AI devices induces significant delays due to the redundant memory operations in the DNN development ecosystem for edge AI devices. To this end, we develop SwapNet, an efficient DNN block swapping middleware for edge AI devices. We systematically eliminate the unnecessary memory operations during block swapping while retaining compatible with the deep learning frameworks, GPU backends, and hardware architectures of edge AI devices. We further showcase the utility of SwapNet via a multi-DNN scheduling scheme. Evaluations on eleven DNN inference tasks in three applications demonstrate that SwapNet achieves almost the same latency as the case with sufficient memory even when DNNs demand 2.32x to 5.81x memory beyond the available budget. The design of SwapNet also provides novel and feasible insights for deploying large language models (LLMs) on edge AI devices in the future.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "14 pages, 19 figures, accepted by IEEE Transactions on Mobile Computing"
    },
    {
        "paper id": "2401.16772",
        "abstract url": "https://arxiv.org/abs/2401.16772",
        "title": "Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Imitation learning is often used in addition to reinforcement learning in environments where reward design is difficult or where the reward is sparse, but it is difficult to be able to imitate well in unknown states from a small amount of expert data and sampling data. Supervised learning methods such as Behavioral Cloning do not require sampling data, but usually suffer from distribution shift. The methods based on reinforcement learning, such as inverse reinforcement learning and Generative Adversarial imitation learning (GAIL), can learn from only a few expert data. However, they often need to interact with the environment. Soft Q imitation learning (SQIL) addressed the problems, and it was shown that it could learn efficiently by combining Behavioral Cloning and soft Q-learning with constant rewards. In order to make this algorithm more robust to distribution shift, we propose more efficient and robust algorithm by adding to this method a reward function based on adversarial inverse reinforcement learning that rewards the agent for performing actions in status similar to the demo. We call this algorithm Discriminator Soft Q Imitation Learning (DSQIL). We evaluated it on MuJoCo environments.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "9 pages, 4 figures. arXiv admin note: text overlap with arXiv:2001.06808"
    },
    {
        "paper id": "2401.16775",
        "abstract url": "https://arxiv.org/abs/2401.16775",
        "title": "Activity Detection for Massive Connectivity in Cell-free Networks with Unknown Large-scale Fading, Channel Statistics, Noise Variance, and Activity Probability: A Bayesian Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Activity detection is an important task in the next generation grant-free multiple access. While there are a number of existing algorithms designed for this purpose, they mostly require precise information about the network, such as large-scale fading coefficients, small-scale fading channel statistics, noise variance at the access points, and user activity probability. Acquiring these information would take a significant overhead and their estimated values might not be accurate. This problem is even more severe in cell-free networks as there are many of these parameters to be acquired. Therefore, this paper sets out to investigate the activity detection problem without the above-mentioned information. In order to handle so many unknown parameters, this paper employs the Bayesian approach, where the unknown variables are endowed with prior distributions which effectively act as regularizations. Together with the likelihood function, a maximum a posteriori (MAP) estimator and a variational inference algorithm are derived. Extensive simulations demonstrate that the proposed methods, even without the knowledge of these system parameters, perform better than existing state-of-the-art methods, such as covariance-based and approximate message passing methods.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": "16 pages, 9 figures, accepted for publication in IEEE Transactions on Signal Processing"
    },
    {
        "paper id": "2401.16776",
        "abstract url": "https://arxiv.org/abs/2401.16776",
        "title": "Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. They are devoted to learning the posterior from adaptively proposed simulations using neural network-based conditional density estimators. As a SNPE technique, the automatic posterior transformation (APT) method proposed by Greenberg et al. (2019) performs notably and scales to high dimensional data. However, the APT method bears the computation of an expectation of the logarithm of an intractable normalizing constant, i.e., a nested expectation. Although atomic APT was proposed to solve this by discretizing the normalizing constant, it remains challenging to analyze the convergence of learning. In this paper, we propose a nested APT method to estimate the involved nested expectation instead. This facilitates establishing the convergence analysis. Since the nested estimators for the loss function and its gradient are biased, we make use of unbiased multi-level Monte Carlo (MLMC) estimators for debiasing. To further reduce the excessive variance of the unbiased estimators, this paper also develops some truncated MLMC estimators by taking account of the trade-off between the bias and the average cost. Numerical experiments for approximating complex posteriors with multimodal in moderate dimensions are provided.",
        "subjects": [
            "stat.CO",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "28 pages, 4 figures"
    },
    {
        "paper id": "2401.16785",
        "abstract url": "https://arxiv.org/abs/2401.16785",
        "title": "HawkEye: Advancing Robust Regression with Bounded, Smooth, and Insensitive Loss Function",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Support vector regression (SVR) has garnered significant popularity over the past two decades owing to its wide range of applications across various fields. Despite its versatility, SVR encounters challenges when confronted with outliers and noise, primarily due to the use of the $\\varepsilon$-insensitive loss function. To address this limitation, SVR with bounded loss functions has emerged as an appealing alternative, offering enhanced generalization performance and robustness. Notably, recent developments focus on designing bounded loss functions with smooth characteristics, facilitating the adoption of gradient-based optimization algorithms. However, it's crucial to highlight that these bounded and smooth loss functions do not possess an insensitive zone. In this paper, we address the aforementioned constraints by introducing a novel symmetric loss function named the HawkEye loss function. It is worth noting that the HawkEye loss function stands out as the first loss function in SVR literature to be bounded, smooth, and simultaneously possess an insensitive zone. Leveraging this breakthrough, we integrate the HawkEye loss function into the least squares framework of SVR and yield a new fast and robust model termed HE-LSSVR. The optimization problem inherent to HE-LSSVR is addressed by harnessing the adaptive moment estimation (Adam) algorithm, known for its adaptive learning rate and efficacy in handling large-scale problems. To our knowledge, this is the first time Adam has been employed to solve an SVR problem. To empirically validate the proposed HE-LSSVR model, we evaluate it on UCI, synthetic, and time series datasets. The experimental outcomes unequivocally reveal the superiority of the HE-LSSVR model both in terms of its remarkable generalization performance and its efficiency in training time.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16791",
        "abstract url": "https://arxiv.org/abs/2401.16791",
        "title": "Accelerated Cloud for Artificial Intelligence (ACAI)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training an effective Machine learning (ML) model is an iterative process that requires effort in multiple dimensions. Vertically, a single pipeline typically includes an initial ETL (Extract, Transform, Load) of raw datasets, a model training stage, and an evaluation stage where the practitioners obtain statistics of the model performance. Horizontally, many such pipelines may be required to find the best model within a search space of model configurations. Many practitioners resort to maintaining logs manually and writing simple glue code to automate the workflow. However, carrying out this process on the cloud is not a trivial task in terms of resource provisioning, data management, and bookkeeping of job histories to make sure the results are reproducible. We propose an end-to-end cloud-based machine learning platform, Accelerated Cloud for AI (ACAI), to help improve the productivity of ML practitioners. ACAI achieves this goal by enabling cloud-based storage of indexed, labeled, and searchable data, as well as automatic resource provisioning, job scheduling, and experiment tracking. Specifically, ACAI provides practitioners (1) a data lake for storing versioned datasets and their corresponding metadata, and (2) an execution engine for executing ML jobs on the cloud with automatic resource provisioning (auto-provision), logging and provenance tracking. To evaluate ACAI, we test the efficacy of our auto-provisioner on the MNIST handwritten digit classification task, and we study the usability of our system using experiments and interviews. We show that our auto-provisioner produces a 1.7x speed-up and 39% cost reduction, and our system reduces experiment time for ML scientists by 20% on typical ML use cases.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16795",
        "abstract url": "https://arxiv.org/abs/2401.16795",
        "title": "Performance Insights-based AI-driven Football Transfer Fee Prediction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We developed an artificial intelligence approach to predict the transfer fee of a football player. This model can help clubs make better decisions about which players to buy and sell, which can lead to improved performance and increased club budgets. Having collected data on player performance, transfer fees, and other factors that might affect a player's value, we then used this data to train a machine learning model that can accurately predict a player's impact on the game. We further passed the obtained results as one of the features to the predictor of transfer fees. The model can help clubs identify players who are undervalued and who could be sold for a profit. It can also help clubs avoid overpaying for players. We believe that our model can be a valuable tool for football clubs. It can help them make better decisions about player recruitment and transfers.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16807",
        "abstract url": "https://arxiv.org/abs/2401.16807",
        "title": "Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs), exemplified by ChatGPT, have significantly reshaped text generation, particularly in the realm of writing assistance. While ethical considerations underscore the importance of transparently acknowledging LLM use, especially in scientific communication, genuine acknowledgment remains infrequent. A potential avenue to encourage accurate acknowledging of LLM-assisted writing involves employing automated detectors. Our evaluation of four cutting-edge LLM-generated text detectors reveals their suboptimal performance compared to a simple ad-hoc detector designed to identify abrupt writing style changes around the time of LLM proliferation. We contend that the development of specialized detectors exclusively dedicated to LLM-assisted writing detection is necessary. Such detectors could play a crucial role in fostering more authentic recognition of LLM involvement in scientific communication, addressing the current challenges in acknowledgment practices.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16832",
        "abstract url": "https://arxiv.org/abs/2401.16832",
        "title": "Analysis of Knowledge Tracing performance on synthesised student data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Knowledge Tracing (KT) aims to predict the future performance of students by tracking the development of their knowledge states. Despite all the recent progress made in this field, the application of KT models in education systems is still restricted from the data perspectives: 1) limited access to real life data due to data protection concerns, 2) lack of diversity in public datasets, 3) noises in benchmark datasets such as duplicate records. To resolve these problems, we simulated student data with three statistical strategies based on public datasets and tested their performance on two KT baselines. While we observe only minor performance improvement with additional synthetic data, our work shows that using only synthetic data for training can lead to similar performance as real data.",
        "subjects": [
            "cs.CY",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Accepted at AI4AI Education workshop 2023 ( https://sme.uni-bamberg.de/ai4ai/ )"
    },
    {
        "paper id": "2401.16844",
        "abstract url": "https://arxiv.org/abs/2401.16844",
        "title": "Congestion Pricing for Efficiency and Equity: Theory and Applications to the San Francisco Bay Area",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Congestion pricing, while adopted by many cities to alleviate traffic congestion, raises concerns about widening socioeconomic disparities due to its disproportionate impact on low-income travelers. In this study, we address this concern by proposing a new class of congestion pricing schemes that not only minimize congestion levels but also incorporate an equity objective to reduce cost disparities among travelers with different willingness-to-pay. Our analysis builds on a congestion game model with heterogeneous traveler populations. We present four pricing schemes that account for practical considerations, such as the ability to charge differentiated tolls to various traveler populations and the option to toll all or only a subset of edges in the network. We evaluate our pricing schemes in the calibrated freeway network of the San Francisco Bay Area. We demonstrate that the proposed congestion pricing schemes improve both efficiency (in terms of reduced average travel time) and equity (the disparities of travel costs experienced by different populations) compared to the current pricing scheme. Moreover, our pricing schemes also generate a total revenue comparable to the current pricing scheme. Our results further show that pricing schemes charging differentiated prices to traveler populations with varying willingness-to-pay lead to a more equitable distribution of travel costs compared to those that charge a homogeneous price to all.",
        "subjects": [
            "cs.GT",
            "cs.CY",
            "cs.MA",
            "econ.EM",
            "eess.SY"
        ],
        "comment": "42 pages, 11 figures"
    },
    {
        "paper id": "2401.16852",
        "abstract url": "https://arxiv.org/abs/2401.16852",
        "title": "Checkmating One, by Using Many: Combining Mixture of Experts with MCTS to Improve in Chess",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a new approach that integrates deep learning with computational chess, using both the Mixture of Experts (MoE) method and Monte-Carlo Tree Search (MCTS). Our methodology employs a suite of specialized models, each designed to respond to specific changes in the game's input data. This results in a framework with sparsely activated models, which provides significant computational benefits. Our framework combines the MoE method with MCTS, in order to align it with the strategic phases of chess, thus departing from the conventional ``one-for-all'' model. Instead, we utilize distinct game phase definitions to effectively distribute computational tasks across multiple expert neural networks. Our empirical research shows a substantial improvement in playing strength, surpassing the traditional single-model framework. This validates the efficacy of our integrated approach and highlights the potential of incorporating expert knowledge and strategic principles into neural network design. The fusion of MoE and MCTS offers a promising avenue for advancing machine learning architectures.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Code available under https://github.com/HelpstoneX/CrazyAra"
    },
    {
        "paper id": "2401.16863",
        "abstract url": "https://arxiv.org/abs/2401.16863",
        "title": "Enabling the Digital Democratic Revival: A Research Program for Digital Democracy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This white paper outlines a long-term scientific vision for the development of digital-democracy technology. We contend that if digital democracy is to meet the ambition of enabling a participatory renewal in our societies, then a comprehensive multi-methods research effort is required that could, over the years, support its development in a democratically principled, empirically and computationally informed way. The paper is co-authored by an international and interdisciplinary team of researchers and arose from the Lorentz Center Workshop on ``Algorithmic Technology for Democracy'' (Leiden, October 2022).",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16920",
        "abstract url": "https://arxiv.org/abs/2401.16920",
        "title": "Sparse Portfolio Selection via Topological Data Analysis based Clustering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper uses topological data analysis (TDA) tools and introduces a data-driven clustering-based stock selection strategy tailored for sparse portfolio construction. Our asset selection strategy exploits the topological features of stock price movements to select a subset of topologically similar (different) assets for a sparse index tracking (Markowitz) portfolio. We introduce new distance measures, which serve as an input to the clustering algorithm, on the space of persistence diagrams and landscapes that consider the time component of a time series. We conduct an empirical analysis on the S\\&P index from 2009 to 2020, including a study on the COVID-19 data to validate the robustness of our methodology. Our strategy to integrate TDA with the clustering algorithm significantly enhanced the performance of sparse portfolios across various performance measures in diverse market scenarios.",
        "subjects": [
            "q-fin.PM",
            "cs.LG",
            "q-fin.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16945",
        "abstract url": "https://arxiv.org/abs/2401.16945",
        "title": "Online Resource Allocation with Non-Stationary Customers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel algorithm for online resource allocation with non-stationary customer arrivals and unknown click-through rates. We assume multiple types of customers arrive in a nonstationary stochastic fashion, with unknown arrival rates in each period, and that customers' click-through rates are unknown and can only be learned online. By leveraging results from the stochastic contextual bandit with knapsack and online matching with adversarial arrivals, we develop an online scheme to allocate the resources to nonstationary customers. We prove that under mild conditions, our scheme achieves a ``best-of-both-world'' result: the scheme has a sublinear regret when the customer arrivals are near-stationary, and enjoys an optimal competitive ratio under general (non-stationary) customer arrival distributions. Finally, we conduct extensive numerical experiments to show our approach generates near-optimal revenues for all different customer scenarios.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16974",
        "abstract url": "https://arxiv.org/abs/2401.16974",
        "title": "CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Causal discovery is the challenging task of inferring causal structure from data. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passive observations alone are not enough to distinguish correlation from causation, there has been a recent push to incorporate interventions into machine learning research. Reinforcement learning provides a convenient framework for such an active approach to learning. This paper presents CORE, a deep reinforcement learning-based approach for causal discovery and intervention planning. CORE learns to sequentially reconstruct causal graphs from data while learning to perform informative interventions. Our results demonstrate that CORE generalizes to unseen graphs and efficiently uncovers causal structures. Furthermore, CORE scales to larger graphs with up to 10 variables and outperforms existing approaches in structure estimation accuracy and sample efficiency. All relevant code and supplementary material can be found at https://github.com/sa-and/CORE",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "To be published In Proc. of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024), Auckland, New Zealand, May 6 - 10, 2024, IFAAMAS"
    },
    {
        "paper id": "2401.16981",
        "abstract url": "https://arxiv.org/abs/2401.16981",
        "title": "Selection of gamma events from IACT images with deep learning methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Imaging Atmospheric Cherenkov Telescopes (IACTs) of gamma ray observatory TAIGA detect the Extesnive Air Showers (EASs) originating from the cosmic or gamma rays interactions with the atmosphere. Thereby, telescopes obtain images of the EASs. The ability to segregate gamma rays images from the hadronic cosmic ray background is one of the main features of this type of detectors. However, in actual IACT observations simultaneous observation of the background and the source of gamma ray is needed. This observation mode (called wobbling) modifies images of events, which affects the quality of selection by neural networks. Thus, in this work, the results of the application of neural networks (NN) for image classification task on Monte Carlo (MC) images of TAIGA-IACTs are presented. The wobbling mode is considered together with the image adaptation for adequate analysis by NNs. Simultaneously, we explore several neural network structures that classify events both directly from images or through Hillas parameters extracted from images. In addition, by employing NNs, MC simulation data are used to evaluate the quality of the segregation of rare gamma events with the account of all necessary image modifications.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.HE",
            "cs.LG"
        ],
        "comment": "Version of article, submitted to journal"
    },
    {
        "paper id": "2401.16982",
        "abstract url": "https://arxiv.org/abs/2401.16982",
        "title": "ActDroid: An active learning framework for Android malware detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The growing popularity of Android requires malware detection systems that can keep up with the pace of new software being released. According to a recent study, a new piece of malware appears online every 12 seconds. To address this, we treat Android malware detection as a streaming data problem and explore the use of active online learning as a means of mitigating the problem of labelling applications in a timely and cost-effective manner. Our resulting framework achieves accuracies of up to 96\\%, requires as little of 24\\% of the training data to be labelled, and compensates for concept drift that occurs between the release and labelling of an application. We also consider the broader practicalities of online learning within Android malware detection, and systematically explore the trade-offs between using different static, dynamic and hybrid feature sets to classify malware.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16986",
        "abstract url": "https://arxiv.org/abs/2401.16986",
        "title": "Causal Machine Learning for Cost-Effective Allocation of Development Aid",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Sustainable Development Goals (SDGs) of the United Nations provide a blueprint of a better future by 'leaving no one behind', and, to achieve the SDGs by 2030, poor countries require immense volumes of development aid. In this paper, we develop a causal machine learning framework for predicting heterogeneous treatment effects of aid disbursements to inform effective aid allocation. Specifically, our framework comprises three components: (i) a balancing autoencoder that uses representation learning to embed high-dimensional country characteristics while addressing treatment selection bias; (ii) a counterfactual generator to compute counterfactual outcomes for varying aid volumes to address small sample-size settings; and (iii) an inference model that is used to predict heterogeneous treatment-response curves. We demonstrate the effectiveness of our framework using data with official development aid earmarked to end HIV/AIDS in 105 countries, amounting to more than USD 5.2 billion. For this, we first show that our framework successfully computes heterogeneous treatment-response curves using semi-synthetic data. Then, we demonstrate our framework using real-world HIV data. Our framework points to large opportunities for a more effective aid allocation, suggesting that the total number of new HIV infections could be reduced by up to 3.3% (~50,000 cases) compared to the current allocation practice.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17010",
        "abstract url": "https://arxiv.org/abs/2401.17010",
        "title": "Finetuning Large Language Models for Vulnerability Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, handling class imbalance, and improving performance on difficult vulnerability detection datasets. This demonstrates the potential for transfer learning by finetuning large pretrained language models for specialized source code analysis tasks.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17027",
        "abstract url": "https://arxiv.org/abs/2401.17027",
        "title": "Heterogeneous treatment effect estimation with subpopulation identification for personalized medicine in opioid use disorder",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning models have demonstrated promising results in estimating treatment effects (TEE). However, most of them overlook the variations in treatment outcomes among subgroups with distinct characteristics. This limitation hinders their ability to provide accurate estimations and treatment recommendations for specific subgroups. In this study, we introduce a novel neural network-based framework, named SubgroupTE, which incorporates subgroup identification and treatment effect estimation. SubgroupTE identifies diverse subgroups and simultaneously estimates treatment effects for each subgroup, improving the treatment effect estimation by considering the heterogeneity of treatment responses. Comparative experiments on synthetic data show that SubgroupTE outperforms existing models in treatment effect estimation. Furthermore, experiments on a real-world dataset related to opioid use disorder (OUD) demonstrate the potential of our approach to enhance personalized treatment recommendations for OUD patients.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "2023 IEEE International Conference on Data Mining (ICDM)"
    },
    {
        "paper id": "2401.17029",
        "abstract url": "https://arxiv.org/abs/2401.17029",
        "title": "LADDER: Revisiting the Cosmic Distance Ladder with Deep Learning Approaches and Exploring its Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the prospect of reconstructing the ``cosmic distance ladder'' of the Universe using a novel deep learning framework called LADDER - Learning Algorithm for Deep Distance Estimation and Reconstruction. LADDER is trained on the apparent magnitude data from the Pantheon Type Ia supernovae compilation, incorporating the full covariance information among data points, to produce predictions along with corresponding errors. After employing several validation tests with a number of deep learning models, we pick LADDER as the best performing one. We then demonstrate applications of our method in the cosmological context, that include serving as a model-independent tool for consistency checks for other datasets like baryon acoustic oscillations, calibration of high-redshift datasets such as gamma ray bursts, use as a model-independent mock catalog generator for future probes, etc. Our analysis advocates for interesting yet cautious consideration of machine learning applications in these contexts.",
        "subjects": [
            "astro-ph.CO",
            "astro-ph.IM",
            "cs.LG"
        ],
        "comment": "11 pages, 4 figures, 3 tables. Comments are welcome"
    },
    {
        "paper id": "2401.17035",
        "abstract url": "https://arxiv.org/abs/2401.17035",
        "title": "Robust Kernel Sparse Subspace Clustering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Kernel methods are applied to many problems in pattern recognition, including subspace clustering (SC). That way, nonlinear problems in the input data space become linear in mapped high-dimensional feature space. Thereby, computationally tractable nonlinear algorithms are enabled through implicit mapping by the virtue of kernel trick. However, kernelization of linear algorithms is possible only if square of the Froebenious norm of the error term is used in related optimization problem. That, however, implies normal distribution of the error. That is not appropriate for non-Gaussian errors such as gross sparse corruptions that are modeled by -norm. Herein, to the best of our knowledge, we propose for the first time robust kernel sparse SC (RKSSC) algorithm for data with gross sparse corruptions. The concept, in principle, can be applied to other SC algorithms to achieve robustness to the presence of such type of corruption. We validated proposed approach on two well-known datasets with linear robust SSC algorithm as a baseline model. According to Wilcoxon test, clustering performance obtained by the RKSSC algorithm is statistically significantly better than corresponding performance obtained by the robust SSC algorithm. MATLAB code of proposed RKSSC algorithm is posted on https://github.com/ikopriva/RKSSC.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 2 tables"
    },
    {
        "paper id": "2401.17036",
        "abstract url": "https://arxiv.org/abs/2401.17036",
        "title": "Intrinsic Data Constraints and Upper Bounds in Binary Classification Performance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The structure of data organization is widely recognized as having a substantial influence on the efficacy of machine learning algorithms, particularly in binary classification tasks. Our research provides a theoretical framework suggesting that the maximum potential of binary classifiers on a given dataset is primarily constrained by the inherent qualities of the data. Through both theoretical reasoning and empirical examination, we employed standard objective functions, evaluative metrics, and binary classifiers to arrive at two principal conclusions. Firstly, we show that the theoretical upper bound of binary classification performance on actual datasets can be theoretically attained. This upper boundary represents a calculable equilibrium between the learning loss and the metric of evaluation. Secondly, we have computed the precise upper bounds for three commonly used evaluation metrics, uncovering a fundamental uniformity with our overarching thesis: the upper bound is intricately linked to the dataset's characteristics, independent of the classifier in use. Additionally, our subsequent analysis uncovers a detailed relationship between the upper limit of performance and the level of class overlap within the binary classification data. This relationship is instrumental for pinpointing the most effective feature subsets for use in feature engineering.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "physics.data-an"
        ],
        "comment": "48 pages, 11 figures"
    },
    {
        "paper id": "2401.17037",
        "abstract url": "https://arxiv.org/abs/2401.17037",
        "title": "Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper studies Bayesian optimization with noise-free observations. We introduce new algorithms rooted in scattered data approximation that rely on a random exploration step to ensure that the fill-distance of query points decays at a near-optimal rate. Our algorithms retain the ease of implementation of the classical GP-UCB algorithm and satisfy cumulative regret bounds that nearly match those conjectured in arXiv:2002.05096, hence solving a COLT open problem. Furthermore, the new algorithms outperform GP-UCB and other popular Bayesian optimization strategies in several examples.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17045",
        "abstract url": "https://arxiv.org/abs/2401.17045",
        "title": "Explaining Explanations in Probabilistic Logic Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The emergence of tools based on artificial intelligence has also led to the need of producing explanations which are understandable by a human being. In some approaches, the system is not transparent (often referred to as a \"black box\"), making it difficult to generate appropriate explanations. In this work, though, we consider probabilistic logic programming, a combination of logic programming (for knowledge representation) and probability (to model uncertainty). In this setting, one can say that models are interpretable, which eases its understanding. However, given a particular query, the usual notion of \"explanation\" is associated with a set of choices, one for each random variable of the model. Unfortunately, this set does not have a causal structure and, in fact, some of the choices are actually irrelevant to the considered query. In order to overcome these shortcomings, we present an approach to explaining explanations which is based on the definition of a query-driven inference mechanism for probabilistic logic programs.",
        "subjects": [
            "cs.AI",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17062",
        "abstract url": "https://arxiv.org/abs/2401.17062",
        "title": "Outline of an Independent Systematic Blackbox Test for ML-based Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This article proposes a test procedure that can be used to test ML models and ML-based systems independently of the actual training process. In this way, the typical quality statements such as accuracy and precision of these models and system can be verified independently, taking into account their black box character and the immanent stochastic properties of ML models and their training data. The article presents first results from a set of test experiments and suggest extensions to existing test methods reflecting the stochastic nature of ML models and ML-based systems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17095",
        "abstract url": "https://arxiv.org/abs/2401.17095",
        "title": "Traffic estimation in unobserved network locations using data-driven macroscopic models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper leverages macroscopic models and multi-source spatiotemporal data collected from automatic traffic counters and probe vehicles to accurately estimate traffic flow and travel time in links where these measurements are unavailable. This problem is critical in transportation planning applications where the sensor coverage is low and the planned interventions have network-wide impacts. The proposed model, named the Macroscopic Traffic Estimator (MaTE), can perform network-wide estimations of traffic flow and travel time only using the set of observed measurements of these quantities. Because MaTE is grounded in macroscopic flow theory, all parameters and variables are interpretable. The estimated traffic flow satisfies fundamental flow conservation constraints and exhibits an increasing monotonic relationship with the estimated travel time. Using logit-based stochastic traffic assignment as the principle for routing flow behavior makes the model fully differentiable with respect to the model parameters. This property facilitates the application of computational graphs to learn parameters from vast amounts of spatiotemporal data. We also integrate neural networks and polynomial kernel functions to capture link flow interactions and enrich the mapping of traffic flows into travel times. MaTE also adds a destination choice model and a trip generation model that uses historical data on the number of trips generated by location. Experiments on synthetic data show that the model can accurately estimate travel time and traffic flow in out-of-sample links. Results obtained using real-world multi-source data from a large-scale transportation network suggest that MaTE outperforms data-driven benchmarks, especially in travel time estimation. The estimated parameters of MaTE are also informative about the hourly change in travel demand and supply characteristics of the transportation network.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "34 pages, 28 figures, 6 tables"
    },
    {
        "paper id": "2401.17118",
        "abstract url": "https://arxiv.org/abs/2401.17118",
        "title": "Explainable data-driven modeling via mixture of experts: towards effective blending of grey and black-box models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional models grounded in first principles often struggle with accuracy as the system's complexity increases. Conversely, machine learning approaches, while powerful, face challenges in interpretability and in handling physical constraints. Efforts to combine these models often often stumble upon difficulties in finding a balance between accuracy and complexity. To address these issues, we propose a comprehensive framework based on a \"mixture of experts\" rationale. This approach enables the data-based fusion of diverse local models, leveraging the full potential of first-principle-based priors. Our solution allows independent training of experts, drawing on techniques from both machine learning and system identification, and it supports both collaborative and competitive learning paradigms. To enhance interpretability, we penalize abrupt variations in the expert's combination. Experimental results validate the effectiveness of our approach in producing an interpretable combination of models closely resembling the target phenomena.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Submitted to Automatica"
    },
    {
        "paper id": "2401.17127",
        "abstract url": "https://arxiv.org/abs/2401.17127",
        "title": "Personalized Differential Privacy for Ridge Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "The increased application of machine learning (ML) in sensitive domains requires protecting the training data through privacy frameworks, such as differential privacy (DP). DP requires to specify a uniform privacy level $\\varepsilon$ that expresses the maximum privacy loss that each data point in the entire dataset is willing to tolerate. Yet, in practice, different data points often have different privacy requirements. Having to set one uniform privacy level is usually too restrictive, often forcing a learner to guarantee the stringent privacy requirement, at a large cost to accuracy. To overcome this limitation, we introduce our novel Personalized-DP Output Perturbation method (PDP-OP) that enables to train Ridge regression models with individual per data point privacy levels. We provide rigorous privacy proofs for our PDP-OP as well as accuracy guarantees for the resulting model. This work is the first to provide such theoretical accuracy guarantees when it comes to personalized DP in machine learning, whereas previous work only provided empirical evaluations. We empirically evaluate PDP-OP on synthetic and real datasets and with diverse privacy distributions. We show that by enabling each data point to specify their own privacy requirement, we can significantly improve the privacy-accuracy trade-offs in DP. We also show that PDP-OP outperforms the personalized privacy techniques of Jorgensen et al. (2015).",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.CY"
        ],
        "comment": "30 pages"
    },
    {
        "paper id": "2401.17159",
        "abstract url": "https://arxiv.org/abs/2401.17159",
        "title": "Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Modern SMT solvers, such as Z3, offer user-controllable strategies, enabling users to tailor solving strategies for their unique set of instances, thus dramatically enhancing solver performance for their use case. However, this approach of strategy customization presents a significant challenge: handcrafting an optimized strategy for a class of SMT instances remains a complex and demanding task for both solver developers and users alike. In this paper, we address this problem of automatic SMT strategy synthesis via a novel Monte Carlo Tree Search (MCTS) based method. Our method treats strategy synthesis as a sequential decision-making process, whose search tree corresponds to the strategy space, and employs MCTS to navigate this vast search space. The key innovations that enable our method to identify effective strategies, while keeping costs low, are the ideas of layered and staged MCTS search. These novel heuristics allow for a deeper and more efficient exploration of the strategy space, enabling us to synthesize more effective strategies than the default ones in state-of-the-art (SOTA) SMT solvers. We implement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Through extensive evaluations across six important SMT logics, Z3alpha demonstrates superior performance compared to the SOTA synthesis tool FastSMT, the default Z3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challenging QF_BV benchmark set, Z3alpha solves 42.7% more instances than the default strategy in the Z3 SMT solver.",
        "subjects": [
            "cs.AI",
            "cs.LO",
            "cs.SE"
        ],
        "comment": "Accepted at IJCAI 2024"
    },
    {
        "paper id": "2401.17172",
        "abstract url": "https://arxiv.org/abs/2401.17172",
        "title": "Learning Domain-Independent Green's Function For Elliptic Partial Differential Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Green's function characterizes a partial differential equation (PDE) and maps its solution in the entire domain as integrals. Finding the analytical form of Green's function is a non-trivial exercise, especially for a PDE defined on a complex domain or a PDE with variable coefficients. In this paper, we propose a novel boundary integral network to learn the domain-independent Green's function, referred to as BIN-G. We evaluate the Green's function in the BIN-G using a radial basis function (RBF) kernel-based neural network. We train the BIN-G by minimizing the residual of the PDE and the mean squared errors of the solutions to the boundary integral equations for prescribed test functions. By leveraging the symmetry of the Green's function and controlling refinements of the RBF kernel near the singularity of the Green function, we demonstrate that our numerical scheme enables fast training and accurate evaluation of the Green's function for PDEs with variable coefficients. The learned Green's function is independent of the domain geometries, forcing terms, and boundary conditions in the boundary integral formulation. Numerical experiments verify the desired properties of the method and the expected accuracy for the two-dimensional Poisson and Helmholtz equations with variable coefficients.",
        "subjects": [
            "physics.comp-ph",
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17173",
        "abstract url": "https://arxiv.org/abs/2401.17173",
        "title": "Zero-Shot Reinforcement Learning via Function Encoders",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Although reinforcement learning (RL) can solve many challenging sequential decision making problems, achieving zero-shot transfer across related tasks remains a challenge. The difficulty lies in finding a good representation for the current task so that the agent understands how it relates to previously seen tasks. To achieve zero-shot transfer, we introduce the function encoder, a representation learning algorithm which represents a function as a weighted combination of learned, non-linear basis functions. By using a function encoder to represent the reward function or the transition function, the agent has information on how the current task relates to previously seen tasks via a coherent vector representation. Thus, the agent is able to achieve transfer between related tasks at run time with no additional training. We demonstrate state-of-the-art data efficiency, asymptotic performance, and training stability in three RL fields by augmenting basic RL algorithms with a function encoder task representation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17177",
        "abstract url": "https://arxiv.org/abs/2401.17177",
        "title": "Data-Driven Discovery of PDEs via the Adjoint Method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we present an adjoint-based method for discovering the underlying governing partial differential equations (PDEs) given data. The idea is to consider a parameterized PDE in a general form, and formulate the optimization problem that minimizes the error of PDE solution from data. Using variational calculus, we obtain an evolution equation for the Lagrange multipliers (adjoint equations) allowing us to compute the gradient of the objective function with respect to the parameters of PDEs given data in a straightforward manner. In particular, for a family of parameterized and nonlinear PDEs, we show how the corresponding adjoint equations can be derived. Here, we show that given smooth data set, the proposed adjoint method can recover the true PDE up to machine accuracy. However, in the presence of noise, the accuracy of the adjoint method becomes comparable to the famous PDE Functional Identification of Nonlinear Dynamics method known as PDE-FIND (Rudy et al., 2017). Even though the presented adjoint method relies on forward/backward solvers, it outperforms PDE-FIND for large data sets thanks to the analytic expressions for gradients of the cost function with respect to each PDE parameter.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17342",
        "abstract url": "https://arxiv.org/abs/2401.17342",
        "title": "A Latent Space Metric for Enhancing Prediction Confidence in Earth Observation Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study presents a new approach for estimating confidence in machine learning model predictions, specifically in regression tasks utilizing Earth Observation (EO) data, with a particular focus on mosquito abundance (MA) estimation. We take advantage of a Variational AutoEncoder architecture, to derive a confidence metric by the latent space representations of EO datasets. This methodology is pivotal in establishing a correlation between the Euclidean distance in latent representations and the Absolute Error (AE) in individual MA predictions. Our research focuses on EO datasets from the Veneto region in Italy and the Upper Rhine Valley in Germany, targeting areas significantly affected by mosquito populations. A key finding is a notable correlation of 0.46 between the AE of MA predictions and the proposed confidence metric. This correlation signifies a robust, new metric for quantifying the reliability and enhancing the trustworthiness of the AI model's predictions in the context of both EO data analysis and mosquito abundance studies.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17401",
        "abstract url": "https://arxiv.org/abs/2401.17401",
        "title": "Step-size Optimization for Continual Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In continual learning, a learner has to keep learning from the data over its whole life time. A key issue is to decide what knowledge to keep and what knowledge to let go. In a neural network, this can be implemented by using a step-size vector to scale how much gradient samples change network weights. Common algorithms, like RMSProp and Adam, use heuristics, specifically normalization, to adapt this step-size vector. In this paper, we show that those heuristics ignore the effect of their adaptation on the overall objective function, for example by moving the step-size vector away from better step-size vectors. On the other hand, stochastic meta-gradient descent algorithms, like IDBD (Sutton, 1992), explicitly optimize the step-size vector with respect to the overall objective function. On simple problems, we show that IDBD is able to consistently improve step-size vectors, where RMSProp and Adam do not. We explain the differences between the two approaches and their respective limitations. We conclude by suggesting that combining both approaches could be a promising future direction to improve the performance of neural networks in continual learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17408",
        "abstract url": "https://arxiv.org/abs/2401.17408",
        "title": "Solving Boltzmann Optimization Problems with Deep Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Decades of exponential scaling in high performance computing (HPC) efficiency is coming to an end. Transistor based logic in complementary metal-oxide semiconductor (CMOS) technology is approaching physical limits beyond which further miniaturization will be impossible. Future HPC efficiency gains will necessarily rely on new technologies and paradigms of compute. The Ising model shows particular promise as a future framework for highly energy efficient computation. Ising systems are able to operate at energies approaching thermodynamic limits for energy consumption of computation. Ising systems can function as both logic and memory. Thus, they have the potential to significantly reduce energy costs inherent to CMOS computing by eliminating costly data movement. The challenge in creating Ising-based hardware is in optimizing useful circuits that produce correct results on fundamentally nondeterministic hardware. The contribution of this paper is a novel machine learning approach, a combination of deep neural networks and random forests, for efficiently solving optimization problems that minimize sources of error in the Ising model. In addition, we provide a process to express a Boltzmann probability optimization problem as a supervised machine learning problem.",
        "subjects": [
            "cs.LG",
            "cs.ET",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17426",
        "abstract url": "https://arxiv.org/abs/2401.17426",
        "title": "Superiority of Multi-Head Attention in In-Context Linear Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present a theoretical analysis of the performance of transformer with softmax attention in in-context learning with linear regression tasks. While the existing literature predominantly focuses on the convergence of transformers with single-/multi-head attention, our research centers on comparing their performance. We conduct an exact theoretical analysis to demonstrate that multi-head attention with a substantial embedding dimension performs better than single-head attention. When the number of in-context examples D increases, the prediction loss using single-/multi-head attention is in O(1/D), and the one for multi-head attention has a smaller multiplicative constant. In addition to the simplest data distribution setting, we consider more scenarios, e.g., noisy labels, local examples, correlated features, and prior knowledge. We observe that, in general, multi-head attention is preferred over single-head attention. Our results verify the effectiveness of the design of multi-head attention in the transformer architecture.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17428",
        "abstract url": "https://arxiv.org/abs/2401.17428",
        "title": "Metaverse Perspectives from Japan: A Participatory Speculative Design Case Study",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Currently, the development of the metaverse lies in the hands of industry. Citizens have little influence on this process. Instead, to do justice to the pluralism of (digital) societies, we should strive for an open discourse including many different perspectives on the metaverse and its core technologies such as AI. We utilize a participatory speculative design (PSD) approach to explore Japanese citizens' perspectives on future metaverse societies, as well as social and ethical implications. Our contributions are twofold. Firstly, we demonstrate the effectiveness of PSD in engaging citizens in critical discourse on emerging technologies like the metaverse, offering our workshop framework as a methodological contribution. Secondly, we identify key themes from participants' perspectives, providing insights for culturally sensitive design and development of virtual environments. Our analysis shows that participants imagine the metaverse to have the potential to solve a variety of societal issues; for example, breaking down barriers of physical environments for communication, social interaction, crisis preparation, and political participation, or tackling identity-related issues. Regarding future metaverse societies, participants' imaginations raise critical questions about human-AI relations, technical solutionism, politics and technology, globalization and local cultures, and immersive technologies. We discuss implications and contribute to expanding conversations on metaverse developments.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17434",
        "abstract url": "https://arxiv.org/abs/2401.17434",
        "title": "Integrating Generative AI in Hackathons: Opportunities, Challenges, and Educational Implications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Hackathons and software competitions, increasingly pivotal in the software industry, serve as vital catalysts for innovation and skill development for both organizations and students. These platforms enable companies to prototype ideas swiftly, while students gain enriched learning experiences, enhancing their practical skills. Over the years, hackathons have transitioned from mere competitive events to significant educational tools, fusing theoretical knowledge with real-world problem-solving. The integration of hackathons into computer science and software engineering curricula aims to align educational proficiencies within a collaborative context, promoting peer connectivity and enriched learning via industry-academia collaborations. However, the infusion of advanced technologies, notably artificial intelligence (AI), and machine learning, into hackathons is revolutionizing their structure and outcomes. This evolution brings forth both opportunities, like enhanced learning experiences, and challenges, such as ethical concerns. This study delves into the impact of generative AI, examining its influence on student's technological choices based on a case study on the University of Iowa 2023 event. The exploration provides insights into AI's role in hackathons, and its educational implications, and offers a roadmap for the integration of such technologies in future events, ensuring innovation is balanced with ethical and educational considerations.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "8491 words, 23 pages, 12 figures"
    },
    {
        "paper id": "2401.17436",
        "abstract url": "https://arxiv.org/abs/2401.17436",
        "title": "Difficulty Modelling in Mobile Puzzle Games: An Empirical Study on Different Methods to Combine Player Analytics and Simulated Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Difficulty is one of the key drivers of player engagement and it is often one of the aspects that designers tweak most to optimise the player experience; operationalising it is, therefore, a crucial task for game development studios. A common practice consists of creating metrics out of data collected by player interactions with the content; however, this allows for estimation only after the content is released and does not consider the characteristics of potential future players. In this article, we present a number of potential solutions for the estimation of difficulty under such conditions, and we showcase the results of a comparative study intended to understand which method and which types of data perform better in different scenarios. The results reveal that models trained on a combination of cohort statistics and simulated data produce the most accurate estimations of difficulty in all scenarios. Furthermore, among these models, artificial neural networks show the most consistent results.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17441",
        "abstract url": "https://arxiv.org/abs/2401.17441",
        "title": "Explaining Predictive Uncertainty by Exposing Second-Order Effects",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Explainable AI has brought transparency into complex ML blackboxes, enabling, in particular, to identify which features these models use for their predictions. So far, the question of explaining predictive uncertainty, i.e. why a model 'doubts', has been scarcely studied. Our investigation reveals that predictive uncertainty is dominated by second-order effects, involving single features or product interactions between them. We contribute a new method for explaining predictive uncertainty based on these second-order effects. Computationally, our method reduces to a simple covariance computation over a collection of first-order explanations. Our method is generally applicable, allowing for turning common attribution techniques (LRP, Gradient x Input, etc.) into powerful second-order uncertainty explainers, which we call CovLRP, CovGI, etc. The accuracy of the explanations our method produces is demonstrated through systematic quantitative evaluations, and the overall usefulness of our method is demonstrated via two practical showcases.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "12 pages + supplement"
    },
    {
        "paper id": "2401.17443",
        "abstract url": "https://arxiv.org/abs/2401.17443",
        "title": "Liquid Democracy for Low-Cost Ensemble Pruning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We argue that there is a strong connection between ensemble learning and a delegative voting paradigm -- liquid democracy -- that can be leveraged to reduce ensemble training costs. We present an incremental training procedure that identifies and removes redundant classifiers from an ensemble via delegation mechanisms inspired by liquid democracy. Through both analysis and extensive experiments we show that this process greatly reduces the computational cost of training compared to training a full ensemble. By carefully selecting the underlying delegation mechanism, weight centralization in the classifier population is avoided, leading to higher accuracy than some boosting methods. Furthermore, this work serves as an exemplar of how frameworks from computational social choice literature can be applied to problems in nontraditional domains.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "30 pages, 20 figures. Extended abstract to appear at AAMAS 2024"
    },
    {
        "paper id": "2401.17459",
        "abstract url": "https://arxiv.org/abs/2401.17459",
        "title": "A Preliminary Study on Using Large Language Models in Software Pentesting",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models (LLM) are perceived to offer promising potentials for automating security tasks, such as those found in security operation centers (SOCs). As a first step towards evaluating this perceived potential, we investigate the use of LLMs in software pentesting, where the main task is to automatically identify software security vulnerabilities in source code. We hypothesize that an LLM-based AI agent can be improved over time for a specific security task as human operators interact with it. Such improvement can be made, as a first step, by engineering prompts fed to the LLM based on the responses produced, to include relevant contexts and structures so that the model provides more accurate results. Such engineering efforts become sustainable if the prompts that are engineered to produce better results on current tasks, also produce better results on future unknown tasks. To examine this hypothesis, we utilize the OWASP Benchmark Project 1.2 which contains 2,740 hand-crafted source code test cases containing various types of vulnerabilities. We divide the test cases into training and testing data, where we engineer the prompts based on the training data (only), and evaluate the final system on the testing data. We compare the AI agent's performance on the testing data against the performance of the agent without the prompt engineering. We also compare the AI agent's results against those from SonarQube, a widely used static code analyzer for security testing. We built and tested multiple versions of the AI agent using different off-the-shelf LLMs -- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with both chat completion and assistant APIs). The results show that using LLMs is a viable approach to build an AI agent for software pentesting that can improve through repeated use and prompt engineering.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17467",
        "abstract url": "https://arxiv.org/abs/2401.17467",
        "title": "An entropy-based measurement for understanding origin-destination trip distributions: a case study of New York City taxis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "A comprehensive understanding of human mobility patterns in urban areas is essential for urban development and transportation planning. In this study, we create entropy-based measurements to capture the geographical distribution diversity of trip origins and destinations. Specifically, we develop origin-entropy and destination-entropy based on taxi and ride-sharing trip records. The origin-entropy for a given zone accounts for all the trips that originate from this zone and calculates the level of geographical distribution diversity of these trips destinations. Likewise, the destination-entropy for a given zone considers all the trips that end in this zone and calculates the level of geographical distribution diversity of these trips origins. Furthermore, we have created an interactive geovisualization that enables researchers to delve into and juxtapose the spatial and temporal dynamics of origin and destination entropy, in conjunction with trip counts for both origins and destinations. Results indicate that entropy-based measurements effectively capture shifts in the diversity of trips geographical origins and destinations, reflecting changes in travel decisions due to major events like the COVID-19 pandemic. These measurements, alongside trip counts, offer a more comprehensive understanding of urban human flows.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17512",
        "abstract url": "https://arxiv.org/abs/2401.17512",
        "title": "A Cradle-to-Gate Life Cycle Analysis of Bitcoin Mining Equipment Using Sphera LCA and ecoinvent Databases",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Bitcoin mining is regularly pointed out for its massive energy consumption and associated greenhouse gas emissions, hence contributing significantly to climate change. However, most studies ignore the environmental impacts of producing mining equipment, which is problematic given the short lifespan of such highly specific hardware. In this study, we perform a cradle-to-gate life cycle assessment (LCA) of dedicated Bitcoin mining equipment, considering their specific architecture. Our results show that the application-specific integrated circuit designed for Bitcoin mining is the main contributor to production-related impacts. This observation applies to most impact categories, including the global warming potential. In addition, this finding stresses out the necessity to carefully consider the specificity of the hardware. By comparing these results with several usage scenarios, we also demonstrate that the impacts of producing this type of equipment can be significant (up to 80% of the total life cycle impacts), depending on the sources of electricity supply for the use phase. Therefore, we highlight the need to consider the production phase when assessing the environmental impacts of Bitcoin mining hardware. To test the validity of our results, we use the Sphera LCA and ecoinvent databases for the background modeling of our system. Surprisingly, it leads to results with variations of up to 4 orders of magnitude for toxicity-related indicators, despite using the same foreground modeling. This database mismatch phenomenon, already identified in previous studies, calls for better understanding, consideration and discussion of environmental impacts in the field of electronics, going well beyond climate change indicators.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "13 pages, 6 figures, 2 tables. Supplementary Information not available"
    },
    {
        "paper id": "2401.17513",
        "abstract url": "https://arxiv.org/abs/2401.17513",
        "title": "A PNP ion channel deep learning solver with local neural network and finite element input data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, a deep learning method for solving an improved one-dimensional Poisson-Nernst-Planck ion channel (PNPic) model, called the PNPic deep learning solver, is presented. In particular, it combines a novel local neural network scheme with an effective PNPic finite element solver. Since the input data of the neural network scheme only involves a small local patch of coarse grid solutions, which the finite element solver can quickly produce, the PNPic deep learning solver can be trained much faster than any corresponding conventional global neural network solvers. After properly trained, it can output a predicted PNPic solution in a much higher degree of accuracy than the low cost coarse grid solutions and can reflect different perturbation cases on the parameters, ion channel subregions, and interface and boundary values, etc. Consequently, the PNPic deep learning solver can generate a numerical solution with high accuracy for a family of PNPic models. As an initial study, two types of numerical tests were done by perturbing one and two parameters of the PNPic model, respectively, as well as the tests done by using a few perturbed interface positions of the model as training samples. These tests demonstrate that the PNPic deep learning solver can generate highly accurate PNPic numerical solutions.",
        "subjects": [
            "physics.bio-ph",
            "cs.AI",
            "physics.comp-ph"
        ],
        "comment": "17 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2401.17541",
        "abstract url": "https://arxiv.org/abs/2401.17541",
        "title": "Towards Understanding Variants of Invariant Risk Minimization through the Lens of Calibration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models traditionally assume that training and test data are independently and identically distributed. However, in real-world applications, the test distribution often differs from training. This problem, known as out-of-distribution generalization, challenges conventional models. Invariant Risk Minimization (IRM) emerges as a solution, aiming to identify features invariant across different environments to enhance out-of-distribution robustness. However, IRM's complexity, particularly its bi-level optimization, has led to the development of various approximate methods. Our study investigates these approximate IRM techniques, employing the Expected Calibration Error (ECE) as a key metric. ECE, which measures the reliability of model prediction, serves as an indicator of whether models effectively capture environment-invariant features. Through a comparative analysis of datasets with distributional shifts, we observe that Information Bottleneck-based IRM, which condenses representational information, achieves a balance in improving ECE while preserving accuracy relatively. This finding is pivotal, as it demonstrates a feasible path to maintaining robustness without compromising accuracy. Nonetheless, our experiments also caution against over-regularization, which can diminish accuracy. This underscores the necessity for a systematic approach in evaluating out-of-distribution generalization metrics, one that beyond mere accuracy to address the nuanced interplay between accuracy and calibration.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00069",
        "abstract url": "https://arxiv.org/abs/2402.00069",
        "title": "Using the Abstract Computer Architecture Description Language to Model AI Hardware Accelerators",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) has witnessed remarkable growth, particularly through the proliferation of Deep Neural Networks (DNNs). These powerful models drive technological advancements across various domains. However, to harness their potential in real-world applications, specialized hardware accelerators are essential. This demand has sparked a market for parameterizable AI hardware accelerators offered by different vendors. Manufacturers of AI-integrated products face a critical challenge: selecting an accelerator that aligns with their product's performance requirements. The decision involves choosing the right hardware and configuring a suitable set of parameters. However, comparing different accelerator design alternatives remains a complex task. Often, engineers rely on data sheets, spreadsheet calculations, or slow black-box simulators, which only offer a coarse understanding of the performance characteristics. The Abstract Computer Architecture Description Language (ACADL) is a concise formalization of computer architecture block diagrams, which helps to communicate computer architecture on different abstraction levels and allows for inferring performance characteristics. In this paper, we demonstrate how to use the ACADL to model AI hardware accelerators, use their ACADL description to map DNNs onto them, and explain the timing simulation semantics to gather performance results.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "comment": "Accepted Version for: MBMV'24"
    },
    {
        "paper id": "2402.00076",
        "abstract url": "https://arxiv.org/abs/2402.00076",
        "title": "Exploitation Strategies in Conditional Markov Chain Search: A case study on the three-index assignment problem",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Conditional Markov Chain Search (CMCS) is a framework for automated design of metaheuristics for discrete combinatorial optimisation problems. Given a set of algorithmic components such as hill climbers and mutations, CMCS decides in which order to apply those components. The decisions are dictated by the CMCS configuration that can be learnt offline. CMCS does not have an acceptance criterion; any moves are accepted by the framework. As a result, it is particularly good in exploration but is not as good at exploitation. In this study, we explore several extensions of the framework to improve its exploitation abilities. To perform a computational study, we applied the framework to the three-index assignment problem. The results of our experiments showed that a two-stage CMCS is indeed superior to a single-stage CMCS.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2402.01753",
        "abstract url": "https://arxiv.org/abs/2402.01753",
        "title": "SpecDiff-GAN: A Spectrally-Shaped Noise Diffusion GAN for Speech and Music Synthesis",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "GAN"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Generative adversarial network (GAN) models can synthesize highquality audio signals while ensuring fast sample generation. However, they are difficult to train and are prone to several issues including mode collapse and divergence. In this paper, we introduce SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was initially devised for speech synthesis from mel spectrogram. In our model, the training stability is enhanced by means of a forward diffusion process which consists in injecting noise from a Gaussian distribution to both real and fake samples before inputting them to the discriminator. We further improve the model by exploiting a spectrally-shaped noise distribution with the aim to make the discriminator's task more challenging. We then show the merits of our proposed model for speech and music synthesis on several datasets. Our experiments confirm that our model compares favorably in audio quality and efficiency compared to several baselines.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS",
            "eess.SP"
        ],
        "comment": "Accepted at ICASSP 2024"
    },
    {
        "paper id": "2402.01764",
        "abstract url": "https://arxiv.org/abs/2402.01764",
        "title": "XP2021 Experience Report: Five Strategies for the Future of Work: Accelerating Innovation through Tech Transfer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This experience report outlines five tech transfer strategies developed over a period of 25 years at four Global 1000 companies (HP, Cisco, Qualcomm, and Nortel) to mitigate R&D challenges associated with duplicated effort, product quality, and time-to-market. The five strategies accelerate innovation through open knowledge sharing, rather than licensing intellectual property rights (IPR) such as patents, trade secrets, and copyrights. The strategies are based on corporate tech forums, conference panels, exploratory workshops, research reviews (at universities and companies), and talent exchanges. While the initial objective was to foster the corporate adoption of software best practices, over time the strategies had broader impact on company innovation, including incubating cross-company R&D collaborations, capturing organizational memory, cultivating and leveraging external research partnerships, and feeding company talent pipelines.",
        "subjects": [
            "cs.CY",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03363",
        "abstract url": "https://arxiv.org/abs/2402.03363",
        "title": "Exploring Prime Number Classification: Achieving High Recall Rate and Rapid Convergence with Sparse Encoding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a novel approach at the intersection of machine learning and number theory, focusing on the classification of prime and non-prime numbers. At the core of our research is the development of a highly sparse encoding method, integrated with conventional neural network architectures. This combination has shown promising results, achieving a recall of over 99\\% in identifying prime numbers and 79\\% for non-prime numbers from an inherently imbalanced sequential series of integers, while exhibiting rapid model convergence before the completion of a single training epoch. We performed training using $10^6$ integers starting from a specified integer and tested on a different range of $2 \\times 10^6$ integers extending from $10^6$ to $3 \\times 10^6$, offset by the same starting integer. While constrained by the memory capacity of our resources, which limited our analysis to a span of $3\\times10^6$, we believe that our study contribute to the application of machine learning in prime number analysis. This work aims to demonstrate the potential of such applications and hopes to inspire further exploration and possibilities in diverse fields.",
        "subjects": [
            "math.NT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.07911",
        "abstract url": "https://arxiv.org/abs/2402.07911",
        "title": "Does mapping elites illuminate search spaces? A large-scale user study of MAP--Elites applied to human--AI collaborative design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Two studies of a human-AI collaborative design tool were carried out in order to understand the influence design recommendations have on the design process. The tool investigated is based on an evolutionary algorithm attempting to design a virtual car to travel as far as possible in a fixed time. Participants were able to design their own cars, make recommendations to the algorithm and view sets of recommendations from the algorithm. The algorithm-recommended sets were designs which had been previously tested; some sets were simply randomly picked and other sets were picked using MAP-Elites. In the first study 808 design sessions were recorded as part of a science outreach program, each with analytical data of how each participant used the tool. To provide context to this quantitative data, a smaller double-blind lab study was also carried out with 12 participants. In the lab study the same quantitative data from the large scale study was collected alongside responses to interview questions. Although there is some evidence that the MAP-Elites provide higher-quality individual recommendations, neither study provides convincing evidence that these recommendations have a more positive influence on the design process than simply a random selection of designs. In fact, it seems that providing a combination of MAP-Elites and randomly selected recommendations is beneficial to the process. Furthermore, simply viewing recommendations from the MAP-Elites had a positive influence on engagement in the design task and the quality of the final design produced. Our findings are significant both for researchers designing new mixed-initiative tools, and those who wish to evaluate existing tools. Most significantly, we found that metrics researchers currently use to evaluate the success of human-AI collaborative algorithms do not measure the full influence these algorithms have on the design process.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CE",
            "cs.NE"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2402.09442",
        "abstract url": "https://arxiv.org/abs/2402.09442",
        "title": "Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the era of Internet of Things, how to develop a smart sensor system with sustainable power supply, easy deployment and flexible use has become a difficult problem to be solved. The traditional power supply has problems such as frequent replacement or charging when in use, which limits the development of wearable devices. The contact-to-separate friction nanogenerator (TENG) was prepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Human motion energy was collected by human body arrangement, and human motion posture was monitored according to the changes of output electrical signals. In 2012, Academician Wang Zhong lin and his team invented the triboelectric nanogenerator (TENG), which uses Maxwell displacement current as a driving force to directly convert mechanical stimuli into electrical signals, so it can be used as a self-driven sensor. Teng-based sensors have the advantages of simple structure and high instantaneous power density, which provides an important means for building intelligent sensor systems. At the same time, machine learning, as a technology with low cost, short development cycle, strong data processing ability and prediction ability, has a significant effect on the processing of a large number of electrical signals generated by TENG, and the combination with TENG sensors will promote the rapid development of intelligent sensor networks in the future. Therefore, this paper is based on the intelligent sound monitoring and recognition system of TENG, which has good sound recognition capability, and aims to evaluate the feasibility of the sound perception module architecture in ubiquitous sensor networks.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "comment": "This aticle was accepted by ieee conference"
    },
    {
        "paper id": "2402.10224",
        "abstract url": "https://arxiv.org/abs/2402.10224",
        "title": "Human-Centric Goal Reasoning with Ripple-Down Rules",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "ActorSim is a goal reasoning framework developed at the Naval Research Laboratory. Originally, all goal reasoning rules were hand-crafted. This work extends ActorSim with the capability of learning by demonstration, that is, when a human trainer disagrees with a decision made by the system, the trainer can take over and show the system the correct decision. The learning component uses Ripple-Down Rules (RDR) to build new decision rules to correctly handle similar cases in the future. The system is demonstrated using the RoboCup Rescue Agent Simulation, which simulates a city-wide disaster, requiring emergency services, including fire, ambulance and police, to be dispatched to different sites to evacuate civilians from dangerous situations. The RDRs are implemented in a scripting language, FrameScript, which is used to mediate between ActorSim and the agent simulator. Using Ripple-Down Rules, ActorSim can scale to an order of magnitude more goals than the previous version.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "Proceedings of the Ninth Goal Reasoning Workshop (Advances in Cognitive Systems, 2021)"
    },
    {
        "paper id": "2403.08790",
        "abstract url": "https://arxiv.org/abs/2403.08790",
        "title": "Using Sequential Runtime Distributions for the Parallel Speedup Prediction of SAT Local Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents a detailed analysis of the scalability and parallelization of local search algorithms for the Satisfiability problem. We propose a framework to estimate the parallel performance of a given algorithm by analyzing the runtime behavior of its sequential version. Indeed, by approximating the runtime distribution of the sequential process with statistical methods, the runtime behavior of the parallel process can be predicted by a model based on order statistics. We apply this approach to study the parallel performance of two SAT local search solvers, namely Sparrow and CCASAT, and compare the predicted performances to the results of an actual experimentation on parallel hardware up to 384 cores. We show that the model is accurate and predicts performance close to the empirical data. Moreover, as we study different types of instances (random and crafted), we observe that the local search solvers exhibit different behaviors and that their runtime distributions can be approximated by two types of distributions: exponential (shifted and non-shifted) and lognormal.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18932",
        "abstract url": "https://arxiv.org/abs/2404.18932",
        "title": "Dynamic Model Switching for Improved Accuracy in Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the dynamic landscape of machine learning, where datasets vary widely in size and complexity, selecting the most effective model poses a significant challenge. Rather than fixating on a single model, our research propels the field forward with a novel emphasis on dynamic model switching. This paradigm shift allows us to harness the inherent strengths of different models based on the evolving size of the dataset. Consider the scenario where CatBoost demonstrates exceptional efficacy in handling smaller datasets, providing nuanced insights and accurate predictions. However, as datasets grow in size and intricacy, XGBoost, with its scalability and robustness, becomes the preferred choice. Our approach introduces an adaptive ensemble that intuitively transitions between CatBoost and XGBoost. This seamless switching is not arbitrary; instead, it's guided by a user-defined accuracy threshold, ensuring a meticulous balance between model sophistication and data requirements. The user sets a benchmark, say 80% accuracy, prompting the system to dynamically shift to the new model only if it guarantees improved performance. This dynamic model-switching mechanism aligns with the evolving nature of data in real-world scenarios. It offers practitioners a flexible and efficient solution, catering to diverse dataset sizes and optimising predictive accuracy at every juncture. Our research, therefore, stands at the forefront of innovation, redefining how machine learning models adapt and excel in the face of varying dataset dynamics.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16762",
        "abstract url": "https://arxiv.org/abs/2401.16762",
        "title": "Pick-and-Draw: Training-free Semantic Guidance for Text-to-Image Personalization",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion-based text-to-image personalization have achieved great success in generating subjects specified by users among various contexts. Even though, existing finetuning-based methods still suffer from model overfitting, which greatly harms the generative diversity, especially when given subject images are few. To this end, we propose Pick-and-Draw, a training-free semantic guidance approach to boost identity consistency and generative diversity for personalization methods. Our approach consists of two components: appearance picking guidance and layout drawing guidance. As for the former, we construct an appearance palette with visual features from the reference image, where we pick local patterns for generating the specified subject with consistent identity. As for layout drawing, we outline the subject's contour by referring to a generative template from the vanilla diffusion model, and inherit the strong image prior to synthesize diverse contexts according to different text conditions. The proposed approach can be applied to any personalized diffusion models and requires as few as a single reference image. Qualitative and quantitative experiments show that Pick-and-Draw consistently improves identity consistency and generative diversity, pushing the trade-off between subject fidelity and image-text fidelity to a new Pareto frontier.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16766",
        "abstract url": "https://arxiv.org/abs/2401.16766",
        "title": "Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep Neural Network (DNN) models when implemented on executing devices as the inference engines are susceptible to Fault Injection Attacks (FIAs) that manipulate model parameters to disrupt inference execution with disastrous performance. This work introduces Contrastive Learning (CL) of visual representations i.e., a self-supervised learning approach into the deep learning training and inference pipeline to implement DNN inference engines with self-resilience under FIAs. Our proposed CL based FIA Detection and Recovery (CFDR) framework features (i) real-time detection with only a single batch of testing data and (ii) fast recovery effective even with only a small amount of unlabeled testing data. Evaluated with the CIFAR-10 dataset on multiple types of FIAs, our CFDR shows promising detection and recovery effectiveness.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.CV"
        ],
        "comment": "Published in AdvML 2021"
    },
    {
        "paper id": "2401.16810",
        "abstract url": "https://arxiv.org/abs/2401.16810",
        "title": "An Embeddable Implicit IUVD Representation for Part-based 3D Human Surface Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To reconstruct a 3D human surface from a single image, it is important to consider human pose, shape and clothing details simultaneously. In recent years, a combination of parametric body models (such as SMPL) that capture body pose and shape prior, and neural implicit functions that learn flexible clothing details, has been used to integrate the advantages of both approaches. However, the combined representation introduces additional computation, e.g. signed distance calculation, in 3D body feature extraction, which exacerbates the redundancy of the implicit query-and-infer process and fails to preserve the underlying body shape prior. To address these issues, we propose a novel IUVD-Feedback representation, which consists of an IUVD occupancy function and a feedback query algorithm. With this representation, the time-consuming signed distance calculation is replaced by a simple linear transformation in the IUVD space, leveraging the SMPL UV maps. Additionally, the redundant query points in the query-and-infer process are reduced through a feedback mechanism. This leads to more reasonable 3D body features and more effective query points, successfully preserving the parametric body prior. Moreover, the IUVD-Feedback representation can be embedded into any existing implicit human reconstruction pipelines without modifying the trained neural networks. Experiments on THuman2.0 dataset demonstrate that the proposed IUVD-Feedback representation improves result robustness and achieves three times faster acceleration in the query-and-infer process. Furthermore, this representation has the potential to be used in generative applications by leveraging its inherited semantic information from the parametric body model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16830",
        "abstract url": "https://arxiv.org/abs/2401.16830",
        "title": "LATENTPATCH: A Non-Parametric Approach for Face Generation and Editing",
        "rating": "0",
        "keywords": [
            [
                "image editing"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "This paper presents LatentPatch, a new method for generating realistic images from a small dataset of only a few images. We use a lightweight model with only a few thousand parameters. Unlike traditional few-shot generation methods that finetune pre-trained large-scale generative models, our approach is computed directly on the latent distribution by sequential feature matching, and is explainable by design. Avoiding large models based on transformers, recursive networks, or self-attention, which are not suitable for small datasets, our method is inspired by non-parametric texture synthesis and style transfer models, and ensures that generated image features are sampled from the source distribution. We extend previous single-image models to work with a few images and demonstrate that our method can generate realistic images, as well as enable conditional sampling and image editing. We conduct experiments on face datasets and show that our simplistic model is effective and versatile.",
        "subjects": [
            "cs.MM",
            "eess.IV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16861",
        "abstract url": "https://arxiv.org/abs/2401.16861",
        "title": "Repositioning the Subject within Image",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current image manipulation primarily centers on static manipulation, such as replacing specific regions within an image or altering its overall style. In this paper, we introduce an innovative dynamic manipulation task, subject repositioning. This task involves relocating a user-specified subject to a desired position while preserving the image's fidelity. Our research reveals that the fundamental sub-tasks of subject repositioning, which include filling the void left by the repositioned subject, reconstructing obscured portions of the subject and blending the subject to be consistent with surrounding areas, can be effectively reformulated as a unified, prompt-guided inpainting task. Consequently, we can employ a single diffusion generative model to address these sub-tasks using various task prompts learned through our proposed task inversion technique. Additionally, we integrate pre-processing and post-processing techniques to further enhance the quality of subject repositioning. These elements together form our SEgment-gEnerate-and-bLEnd (SEELE) framework. To assess SEELE's effectiveness in subject repositioning, we assemble a real-world subject repositioning dataset called ReS. Results of SEELE on ReS demonstrate its efficacy.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://yikai-wang.github.io/seele/. Dataset: https://github.com/Yikai-Wang/ReS. Arxiv version uses small size images for fast preview. Full size PDF is available at project page"
    },
    {
        "paper id": "2401.16960",
        "abstract url": "https://arxiv.org/abs/2401.16960",
        "title": "Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Entity alignment, which is a prerequisite for creating a more comprehensive Knowledge Graph (KG), involves pinpointing equivalent entities across disparate KGs. Contemporary methods for entity alignment have predominantly utilized knowledge embedding models to procure entity embeddings that encapsulate various similarities-structural, relational, and attributive. These embeddings are then integrated through attention-based information fusion mechanisms. Despite this progress, effectively harnessing multifaceted information remains challenging due to inherent heterogeneity. Moreover, while Large Language Models (LLMs) have exhibited exceptional performance across diverse downstream tasks by implicitly capturing entity semantics, this implicit knowledge has yet to be exploited for entity alignment. In this study, we propose a Large Language Model-enhanced Entity Alignment framework (LLMEA), integrating structural knowledge from KGs with semantic knowledge from LLMs to enhance entity alignment. Specifically, LLMEA identifies candidate alignments for a given entity by considering both embedding similarities between entities across KGs and edit distances to a virtual equivalent entity. It then engages an LLM iteratively, posing multiple multi-choice questions to draw upon the LLM's inference capability. The final prediction of the equivalent entity is derived from the LLM's output. Experiments conducted on three public datasets reveal that LLMEA surpasses leading baseline models. Additional ablation studies underscore the efficacy of our proposed framework.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17013",
        "abstract url": "https://arxiv.org/abs/2401.17013",
        "title": "Evaluation of Out-of-Distribution Detection Performance on Autonomous Driving Datasets",
        "rating": "0",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Safety measures need to be systemically investigated to what extent they evaluate the intended performance of Deep Neural Networks (DNNs) for critical applications. Due to a lack of verification methods for high-dimensional DNNs, a trade-off is needed between accepted performance and handling of out-of-distribution (OOD) samples. This work evaluates rejecting outputs from semantic segmentation DNNs by applying a Mahalanobis distance (MD) based on the most probable class-conditional Gaussian distribution for the predicted class as an OOD score. The evaluation follows three DNNs trained on the Cityscapes dataset and tested on four automotive datasets and finds that classification risk can drastically be reduced at the cost of pixel coverage, even when applied on unseen datasets. The applicability of our findings will support legitimizing safety measures and motivate their usage when arguing for safe usage of DNNs in automotive perception.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Preprint to 2023 IEEE International Conference On Artificial Intelligence Testing"
    },
    {
        "paper id": "2401.17023",
        "abstract url": "https://arxiv.org/abs/2401.17023",
        "title": "MF-MOS: A Motion-Focused Model for Moving Object Segmentation",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Moving object segmentation (MOS) provides a reliable solution for detecting traffic participants and thus is of great interest in the autonomous driving field. Dynamic capture is always critical in the MOS problem. Previous methods capture motion features from the range images directly. Differently, we argue that the residual maps provide greater potential for motion information, while range images contain rich semantic guidance. Based on this intuition, we propose MF-MOS, a novel motion-focused model with a dual-branch structure for LiDAR moving object segmentation. Novelly, we decouple the spatial-temporal information by capturing the motion from residual maps and generating semantic features from range images, which are used as movable object guidance for the motion branch. Our straightforward yet distinctive solution can make the most use of both range images and residual maps, thus greatly improving the performance of the LiDAR-based MOS task. Remarkably, our MF-MOS achieved a leading IoU of 76.7% on the MOS leaderboard of the SemanticKITTI dataset upon submission, demonstrating the current state-of-the-art performance. The implementation of our MF-MOS has been released at https://github.com/SCNU-RISLAB/MF-MOS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICRA2024"
    },
    {
        "paper id": "2401.17032",
        "abstract url": "https://arxiv.org/abs/2401.17032",
        "title": "M2CURL: Sample-Efficient Multimodal Reinforcement Learning via Self-Supervised Representation Learning for Robotic Manipulation",
        "rating": "0",
        "keywords": [
            [
                "Robotic Manipulation"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "One of the most critical aspects of multimodal Reinforcement Learning (RL) is the effective integration of different observation modalities. Having robust and accurate representations derived from these modalities is key to enhancing the robustness and sample efficiency of RL algorithms. However, learning representations in RL settings for visuotactile data poses significant challenges, particularly due to the high dimensionality of the data and the complexity involved in correlating visual and tactile inputs with the dynamic environment and task objectives. To address these challenges, we propose Multimodal Contrastive Unsupervised Reinforcement Learning (M2CURL). Our approach employs a novel multimodal self-supervised learning technique that learns efficient representations and contributes to faster convergence of RL algorithms. Our method is agnostic to the RL algorithm, thus enabling its integration with any available RL algorithm. We evaluate M2CURL on the Tactile Gym 2 simulator and we show that it significantly enhances the learning efficiency in different manipulation tasks. This is evidenced by faster convergence rates and higher cumulative rewards per episode, compared to standard RL algorithms without our representation learning approach.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project website: https://sites.google.com/view/M2CURL/home"
    },
    {
        "paper id": "2401.17033",
        "abstract url": "https://arxiv.org/abs/2401.17033",
        "title": "Multilayer Graph Approach to Deep Subspace Clustering",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep subspace clustering (DSC) networks based on self-expressive model learn representation matrix, often implemented in terms of fully connected network, in the embedded space. After the learning is finished, representation matrix is used by spectral clustering module to assign labels to clusters. However, such approach ignores complementary information that exist in other layers of the encoder (including the input data themselves). Herein, we apply selected linear subspace clustering algorithm to learn representation matrices from representations learned by all layers of encoder network including the input data. Afterward, we learn a multilayer graph that in a multi-view like manner integrates information from graph Laplacians of all used layers. That improves further performance of selected DSC network. Furthermore, we also provide formulation of our approach to cluster out-of-sample/test data points. We validate proposed approach on four well-known datasets with two DSC networks as baseline models. In almost all the cases, proposed approach achieved statistically significant improvement in three performance metrics. MATLAB code of proposed algorithm is posted on https://github.com/lovro-sinda/MLG-DSC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 4 tables"
    },
    {
        "paper id": "2401.17058",
        "abstract url": "https://arxiv.org/abs/2401.17058",
        "title": "Atlanta Scaled layouts from non-central panoramas",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this work we present a novel approach for 3D layout recovery of indoor environments using a non-central acquisition system. From a non-central panorama, full and scaled 3D lines can be independently recovered by geometry reasoning without geometric nor scale assumptions. However, their sensitivity to noise and complex geometric modeling has led these panoramas being little investigated. Our new pipeline aims to extract the boundaries of the structural lines of an indoor environment with a neural network and exploit the properties of non-central projection systems in a new geometrical processing to recover an scaled 3D layout. The results of our experiments show that we improve state-of-the-art methods for layout reconstruction and line extraction in non-central projection systems. We completely solve the problem in Manhattan and Atlanta environments, handling occlusions and retrieving the metric scale of the room without extra measurements. As far as the authors knowledge goes, our approach is the first work using deep learning on non-central panoramas and recovering scaled layouts from single panoramas.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17064",
        "abstract url": "https://arxiv.org/abs/2401.17064",
        "title": "Efficient Gesture Recognition on Spiking Convolutional Networks Through Sensor Fusion of Event-Based and Depth Data",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As intelligent systems become increasingly important in our daily lives, new ways of interaction are needed. Classical user interfaces pose issues for the physically impaired and are partially not practical or convenient. Gesture recognition is an alternative, but often not reactive enough when conventional cameras are used. This work proposes a Spiking Convolutional Neural Network, processing event- and depth data for gesture recognition. The network is simulated using the open-source neuromorphic computing framework LAVA for offline training and evaluation on an embedded system. For the evaluation three open source data sets are used. Since these do not represent the applied bi-modality, a new data set with synchronized event- and depth data was recorded. The results show the viability of temporal encoding on depth information and modality fusion, even on differently encoded data, to be beneficial to network performance and generalization capabilities.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.NE"
        ],
        "comment": "Accepted to IEEE International Conference on Robotics and Automation (ICRA 2024)"
    },
    {
        "paper id": "2401.17075",
        "abstract url": "https://arxiv.org/abs/2401.17075",
        "title": "Non-central panorama indoor dataset",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Omnidirectional images are one of the main sources of information for learning based scene understanding algorithms. However, annotated datasets of omnidirectional images cannot keep the pace of these learning based algorithms development. Among the different panoramas and in contrast to standard central ones, non-central panoramas provide geometrical information in the distortion of the image from which we can retrieve 3D information of the environment [2]. However, due to the lack of commercial non-central devices, up until now there was no dataset of these kinds of panoramas. In this data paper, we present the first dataset of non-central panoramas for indoor scene understanding. The dataset is composed by {\\bf 2574} RGB non-central panoramas taken in around 650 different rooms. Each panorama has associated a depth map and annotations to obtain the layout of the room from the image as a structural edge map, list of corners in the image, the 3D corners of the room and the camera pose. The images are taken from photorealistic virtual environments and pixel-wise automatically annotated.",
        "subjects": [
            "cs.DB",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17086",
        "abstract url": "https://arxiv.org/abs/2401.17086",
        "title": "Active Generation Network of Human Skeleton for Action Recognition",
        "rating": "0",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Data generation is a data augmentation technique for enhancing the generalization ability for skeleton-based human action recognition. Most existing data generation methods face challenges to ensure the temporal consistency of the dynamic information for action. In addition, the data generated by these methods lack diversity when only a few training samples are available. To solve those problems, We propose a novel active generative network (AGN), which can adaptively learn various action categories by motion style transfer to generate new actions when the data for a particular action is only a single sample or few samples. The AGN consists of an action generation network and an uncertainty metric network. The former, with ST-GCN as the Backbone, can implicitly learn the morphological features of the target action while preserving the category features of the source action. The latter guides generating actions. Specifically, an action recognition model generates prediction vectors for each action, which is then scored using an uncertainty metric. Finally, UMN provides the uncertainty sampling basis for the generated actions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17181",
        "abstract url": "https://arxiv.org/abs/2401.17181",
        "title": "Transfer Learning for Text Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this report, we explore the potential for text diffusion to replace autoregressive (AR) decoding for the training and deployment of large language models (LLMs). We are particularly interested to see whether pretrained AR models can be transformed into text diffusion models through a lightweight adaptation procedure we call ``AR2Diff''. We begin by establishing a strong baseline setup for training text diffusion models. Comparing across multiple architectures and pretraining objectives, we find that training a decoder-only model with a prefix LM objective is best or near-best across several tasks. Building on this finding, we test various transfer learning setups for text diffusion models. On machine translation, we find that text diffusion underperforms the standard AR approach. However, on code synthesis and extractive QA, we find diffusion models trained from scratch outperform AR models in many cases. We also observe quality gains from AR2Diff -- adapting AR models to use diffusion decoding. These results are promising given that text diffusion is relatively underexplored and can be significantly faster than AR decoding for long text generation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17196",
        "abstract url": "https://arxiv.org/abs/2401.17196",
        "title": "Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In text classification, creating an adversarial example means subtly perturbing a few words in a sentence without changing its meaning, causing it to be misclassified by a classifier. A concerning observation is that a significant portion of adversarial examples generated by existing methods change only one word. This single-word perturbation vulnerability represents a significant weakness in classifiers, which malicious users can exploit to efficiently create a multitude of adversarial examples. This paper studies this problem and makes the following key contributions: (1) We introduce a novel metric \\r{ho} to quantitatively assess a classifier's robustness against single-word perturbation. (2) We present the SP-Attack, designed to exploit the single-word perturbation vulnerability, achieving a higher attack success rate, better preserving sentence meaning, while reducing computation costs compared to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims to improve \\r{ho} by applying data augmentation in learning. Experimental results on 4 datasets and BERT and distilBERT classifiers show that SP-Defense improves \\r{ho} by 14.6% and 13.9% and decreases the attack success rate of SP-Attack by 30.4% and 21.2% on two classifiers respectively, and decreases the attack success rate of existing attack methods that involve multiple-word perturbations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17207",
        "abstract url": "https://arxiv.org/abs/2401.17207",
        "title": "Self-Supervised Representation Learning for Nerve Fiber Distribution Patterns in 3D-PLI",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A comprehensive understanding of the organizational principles in the human brain requires, among other factors, well-quantifiable descriptors of nerve fiber architecture. Three-dimensional polarized light imaging (3D-PLI) is a microscopic imaging technique that enables insights into the fine-grained organization of myelinated nerve fibers with high resolution. Descriptors characterizing the fiber architecture observed in 3D-PLI would enable downstream analysis tasks such as multimodal correlation studies, clustering, and mapping. However, best practices for observer-independent characterization of fiber architecture in 3D-PLI are not yet available. To this end, we propose the application of a fully data-driven approach to characterize nerve fiber architecture in 3D-PLI images using self-supervised representation learning. We introduce a 3D-Context Contrastive Learning (CL-3D) objective that utilizes the spatial neighborhood of texture examples across histological brain sections of a 3D reconstructed volume to sample positive pairs for contrastive learning. We combine this sampling strategy with specifically designed image augmentations to gain robustness to typical variations in 3D-PLI parameter maps. The approach is demonstrated for the 3D reconstructed occipital lobe of a vervet monkey brain. We show that extracted features are highly sensitive to different configurations of nerve fibers, yet robust to variations between consecutive brain sections arising from histological processing. We demonstrate their practical applicability for retrieving clusters of homogeneous fiber architecture and performing data mining for interactively selected templates of specific components of fiber architecture such as U-fibers.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17256",
        "abstract url": "https://arxiv.org/abs/2401.17256",
        "title": "Weak-to-Strong Jailbreaking on Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are vulnerable to jailbreak attacks - resulting in harmful, unethical, or biased text generations. However, existing jailbreaking methods are computationally costly. In this paper, we propose the weak-to-strong jailbreaking attack, an efficient method to attack aligned LLMs to produce harmful text. Our key intuition is based on the observation that jailbroken and aligned models only differ in their initial decoding distributions. The weak-to-strong attack's key technical insight is using two smaller models (a safe and an unsafe one) to adversarially modify a significantly larger safe model's decoding probabilities. We evaluate the weak-to-strong attack on 5 diverse LLMs from 3 organizations. The results show our method can increase the misalignment rate to over 99% on two datasets with just one forward pass per example. Our study exposes an urgent safety issue that needs to be addressed when aligning LLMs. As an initial attempt, we propose a defense strategy to protect against such attacks, but creating more advanced defenses remains challenging. The code for replicating the method is available at https://github.com/XuandongZhao/weak-to-strong",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17258",
        "abstract url": "https://arxiv.org/abs/2401.17258",
        "title": "You Only Need One Step: Fast Super-Resolution with Stable Diffusion via Scale Distillation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce YONOS-SR, a novel stable diffusion-based approach for image super-resolution that yields state-of-the-art results using only a single DDIM step. We propose a novel scale distillation approach to train our SR model. Instead of directly training our SR model on the scale factor of interest, we start by training a teacher model on a smaller magnification scale, thereby making the SR problem simpler for the teacher. We then train a student model for a higher magnification scale, using the predictions of the teacher as a target during the training. This process is repeated iteratively until we reach the target scale factor of the final model. The rationale behind our scale distillation is that the teacher aids the student diffusion model training by i) providing a target adapted to the current noise level rather than using the same target coming from ground truth data for all noise levels and ii) providing an accurate target as the teacher has a simpler task to solve. We empirically show that the distilled model significantly outperforms the model trained for high scales directly, specifically with few steps during inference. Having a strong diffusion model that requires only one step allows us to freeze the U-Net and fine-tune the decoder on top of it. We show that the combination of spatially distilled U-Net and fine-tuned decoder outperforms state-of-the-art methods requiring 200 steps with only one single step.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17263",
        "abstract url": "https://arxiv.org/abs/2401.17263",
        "title": "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on benign use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success rate of the strongest attack on GPT-4, GUARD, from 92% to 6%.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "website and code available at https://andyz245.github.io/rpo/"
    },
    {
        "paper id": "2401.17509",
        "abstract url": "https://arxiv.org/abs/2401.17509",
        "title": "Anything in Any Scene: Photorealistic Video Object Insertion",
        "rating": "0",
        "keywords": [
            [
                "video editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Realistic video simulation has shown significant potential across diverse applications, from virtual reality to film production. This is particularly true for scenarios where capturing videos in real-world settings is either impractical or expensive. Existing approaches in video simulation often fail to accurately model the lighting environment, represent the object geometry, or achieve high levels of photorealism. In this paper, we propose Anything in Any Scene, a novel and generic framework for realistic video simulation that seamlessly inserts any object into an existing dynamic video with a strong emphasis on physical realism. Our proposed general framework encompasses three key processes: 1) integrating a realistic object into a given scene video with proper placement to ensure geometric realism; 2) estimating the sky and environmental lighting distribution and simulating realistic shadows to enhance the light realism; 3) employing a style transfer network that refines the final video output to maximize photorealism. We experimentally demonstrate that Anything in Any Scene framework produces simulated videos of great geometric realism, lighting realism, and photorealism. By significantly mitigating the challenges associated with video data generation, our framework offers an efficient and cost-effective solution for acquiring high-quality videos. Furthermore, its applications extend well beyond video data augmentation, showing promising potential in virtual reality, video editing, and various other video-centric applications. Please check our project website https://anythinginanyscene.github.io for access to our project code and more high-resolution video results.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17536",
        "abstract url": "https://arxiv.org/abs/2401.17536",
        "title": "PipeNet: Question Answering with Semantic Pruning over Knowledge Graphs",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "It is well acknowledged that incorporating explicit knowledge graphs (KGs) can benefit question answering. Existing approaches typically follow a grounding-reasoning pipeline in which entity nodes are first grounded for the query (question and candidate answers), and then a reasoning module reasons over the matched multi-hop subgraph for answer prediction. Although the pipeline largely alleviates the issue of extracting essential information from giant KGs, efficiency is still an open challenge when scaling up hops in grounding the subgraphs. In this paper, we target at finding semantically related entity nodes in the subgraph to improve the efficiency of graph reasoning with KG. We propose a grounding-pruning-reasoning pipeline to prune noisy nodes, remarkably reducing the computation cost and memory usage while also obtaining decent subgraph representation. In detail, the pruning module first scores concept nodes based on the dependency distance between matched spans and then prunes the nodes according to score ranks. To facilitate the evaluation of pruned subgraphs, we also propose a graph attention network (GAT) based module to reason with the subgraph data. Experimental results on CommonsenseQA and OpenBookQA demonstrate the effectiveness of our method.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2401.17583",
        "abstract url": "https://arxiv.org/abs/2401.17583",
        "title": "Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion",
        "rating": "0",
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Legged robots navigating cluttered environments must be jointly agile for efficient task execution and safe to avoid collisions with obstacles or humans. Existing studies either develop conservative controllers (< 1.0 m/s) to ensure safety, or focus on agility without considering potentially fatal collisions. This paper introduces Agile But Safe (ABS), a learning-based control framework that enables agile and collision-free locomotion for quadrupedal robots. ABS involves an agile policy to execute agile motor skills amidst obstacles and a recovery policy to prevent failures, collaboratively achieving high-speed and collision-free navigation. The policy switch in ABS is governed by a learned control-theoretic reach-avoid value network, which also guides the recovery policy as an objective function, thereby safeguarding the robot in a closed loop. The training process involves the learning of the agile policy, the reach-avoid value network, the recovery policy, and an exteroception representation network, all in simulation. These trained modules can be directly deployed in the real world with onboard sensing and computation, leading to high-speed and collision-free navigation in confined indoor and outdoor spaces with both static and dynamic obstacles.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Project website: https://agile-but-safe.github.io/"
    },
    {
        "paper id": "2401.17585",
        "abstract url": "https://arxiv.org/abs/2401.17585",
        "title": "Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks",
        "rating": "0",
        "keywords": [
            [
                "Knowledge Editing"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Current approaches of knowledge editing struggle to effectively propagate updates to interconnected facts. In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel reasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editing dataset) -- which covers six common reasoning schemes in real world. We conduct a thorough analysis of existing knowledge editing techniques, including input augmentation, finetuning, and locate-and-edit. We found that all model editing methods show notably low performance on this dataset, especially in certain reasoning schemes. Our analysis over the chain-of-thought generation of edited models further uncover key reasons behind the inadequacy of existing knowledge editing methods from a reasoning standpoint, involving aspects on fact-wise editing, fact recall ability, and coherence in generation. We will make our benchmark publicly available.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "stat.ME"
        ],
        "comment": "22 pages, 14 figures, 5 tables"
    },
    {
        "paper id": "2402.00892",
        "abstract url": "https://arxiv.org/abs/2402.00892",
        "title": "EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The advent of Large Models marks a new era in machine learning, significantly outperforming smaller models by leveraging vast datasets to capture and synthesize complex patterns. Despite these advancements, the exploration into scaling, especially in the audio generation domain, remains limited, with previous efforts didn't extend into the high-fidelity (HiFi) 44.1kHz domain and suffering from both spectral discontinuities and blurriness in the high-frequency domain, alongside a lack of robustness against out-of-domain data. These limitations restrict the applicability of models to diverse use cases, including music and singing generation. Our work introduces Enhanced Various Audio Generation via Scalable Generative Adversarial Networks (EVA-GAN), yields significant improvements over previous state-of-the-art in spectral and high-frequency reconstruction and robustness in out-of-domain data performance, enabling the generation of HiFi audios by employing an extensive dataset of 36,000 hours of 44.1kHz audio, a context-aware module, a Human-In-The-Loop artifact measurement toolkit, and expands the model to approximately 200 million parameters. Demonstrations of our work are available at https://double-blind-eva-gan.cc.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16753",
        "abstract url": "https://arxiv.org/abs/2401.16753",
        "title": "MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images",
        "rating": "-0.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "This paper studies zero-shot anomaly classification (AC) and segmentation (AS) in industrial vision. We reveal that the abundant normal and abnormal cues implicit in unlabeled test images can be exploited for anomaly determination, which is ignored by prior methods. Our key observation is that for the industrial product images, the normal image patches could find a relatively large number of similar patches in other unlabeled images, while the abnormal ones only have a few similar patches. We leverage such a discriminative characteristic to design a novel zero-shot AC/AS method by Mutual Scoring (MuSc) of the unlabeled images, which does not need any training or prompts. Specifically, we perform Local Neighborhood Aggregation with Multiple Degrees (LNAMD) to obtain the patch features that are capable of representing anomalies in varying sizes. Then we propose the Mutual Scoring Mechanism (MSM) to leverage the unlabeled test images to assign the anomaly score to each other. Furthermore, we present an optimization approach named Re-scoring with Constrained Image-level Neighborhood (RsCIN) for image-level anomaly classification to suppress the false positives caused by noises in normal images. The superior performance on the challenging MVTec AD and VisA datasets demonstrates the effectiveness of our approach. Compared with the state-of-the-art zero-shot approaches, MuSc achieves a $\\textbf{21.1%}$ PRO absolute gain (from 72.7% to 93.8%) on MVTec AD, a $\\textbf{19.4%}$ pixel-AP gain and a $\\textbf{14.7%}$ pixel-AUROC gain on VisA. In addition, our zero-shot approach outperforms most of the few-shot approaches and is comparable to some one-class methods. Code is available at https://github.com/xrli-U/MuSc.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ICLR2024"
    },
    {
        "paper id": "2401.16755",
        "abstract url": "https://arxiv.org/abs/2401.16755",
        "title": "Diffusion model for relational inference",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Dynamical behaviors of complex interacting systems, including brain activities, financial price movements, and physical collective phenomena, are associated with underlying interactions between the system's components. The issue of uncovering interaction relations in such systems using observable dynamics is called relational inference. In this study, we propose a Diffusion model for Relational Inference (DiffRI), inspired by a self-supervised method for probabilistic time series imputation. DiffRI learns to infer the probability of the presence of connections between components through conditional diffusion modeling. Experiments on both simulated and quasi-real datasets show that DiffRI is highly competent compared with other state-of-the-art models in discovering ground truth interactions in an unsupervised manner. Our code will be made public soon.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16765",
        "abstract url": "https://arxiv.org/abs/2401.16765",
        "title": "A Cross-Language Investigation into Jailbreak Attacks in Large Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have become increasingly popular for their advanced text generation capabilities across various domains. However, like any software, they face security challenges, including the risk of 'jailbreak' attacks that manipulate LLMs to produce prohibited content. A particularly underexplored area is the Multilingual Jailbreak attack, where malicious questions are translated into various languages to evade safety filters. Currently, there is a lack of comprehensive empirical studies addressing this specific threat. To address this research gap, we conducted an extensive empirical study on Multilingual Jailbreak attacks. We developed a novel semantic-preserving algorithm to create a multilingual jailbreak dataset and conducted an exhaustive evaluation on both widely-used open-source and commercial LLMs, including GPT-4 and LLaMa. Additionally, we performed interpretability analysis to uncover patterns in Multilingual Jailbreak attacks and implemented a fine-tuning mitigation method. Our findings reveal that our mitigation strategy significantly enhances model defense, reducing the attack success rate by 96.2%. This study provides valuable insights into understanding and mitigating Multilingual Jailbreak attacks.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16771",
        "abstract url": "https://arxiv.org/abs/2401.16771",
        "title": "MolPLA: A Molecular Pretraining Framework for Learning Cores, R-Groups and their Linker Joints",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Molecular core structures and R-groups are essential concepts in drug development. Integration of these concepts with conventional graph pre-training approaches can promote deeper understanding in molecules. We propose MolPLA, a novel pre-training framework that employs masked graph contrastive learning in understanding the underlying decomposable parts inmolecules that implicate their core structure and peripheral R-groups. Furthermore, we formulate an additional framework that grants MolPLA the ability to help chemists find replaceable R-groups in lead optimization scenarios. Experimental results on molecular property prediction show that MolPLA exhibits predictability comparable to current state-of-the-art models. Qualitative analysis implicate that MolPLA is capable of distinguishing core and R-group sub-structures, identifying decomposable regions in molecules and contributing to lead optimization scenarios by rationally suggesting R-group replacements given various query core templates. The code implementation for MolPLA and its pre-trained model checkpoint is available at https://github.com/dmis-lab/MolPLA",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16784",
        "abstract url": "https://arxiv.org/abs/2401.16784",
        "title": "Graph Fairness Learning under Distribution Shifts",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) have achieved remarkable performance on graph-structured data. However, GNNs may inherit prejudice from the training data and make discriminatory predictions based on sensitive attributes, such as gender and race. Recently, there has been an increasing interest in ensuring fairness on GNNs, but all of them are under the assumption that the training and testing data are under the same distribution, i.e., training data and testing data are from the same graph. Will graph fairness performance decrease under distribution shifts? How does distribution shifts affect graph fairness learning? All these open questions are largely unexplored from a theoretical perspective. To answer these questions, we first theoretically identify the factors that determine bias on a graph. Subsequently, we explore the factors influencing fairness on testing graphs, with a noteworthy factor being the representation distances of certain groups between the training and testing graph. Motivated by our theoretical analysis, we propose our framework FatraGNN. Specifically, to guarantee fairness performance on unknown testing graphs, we propose a graph generator to produce numerous graphs with significant bias and under different distributions. Then we minimize the representation distances for each certain group between the training graph and generated graphs. This empowers our model to achieve high classification and fairness performance even on generated graphs with significant bias, thereby effectively handling unknown testing graphs. Experiments on real-world and semi-synthetic datasets demonstrate the effectiveness of our model in terms of both accuracy and fairness.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "comment": "Accepted by WWW 2024"
    },
    {
        "paper id": "2401.16843",
        "abstract url": "https://arxiv.org/abs/2401.16843",
        "title": "Evaluating ML-Based Anomaly Detection Across Datasets of Varied Integrity: A Case Study",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cybersecurity remains a critical challenge in the digital age, with network traffic flow anomaly detection being a key pivotal instrument in the fight against cyber threats. In this study, we address the prevalent issue of data integrity in network traffic datasets, which are instrumental in developing machine learning (ML) models for anomaly detection. We introduce two refined versions of the CICIDS-2017 dataset, NFS-2023-nTE and NFS-2023-TE, processed using NFStream to ensure methodologically sound flow expiration and labeling. Our research contrasts the performance of the Random Forest (RF) algorithm across the original CICIDS-2017, its refined counterparts WTMC-2021 and CRiSIS-2022, and our NFStream-generated datasets, in both binary and multi-class classification contexts. We observe that the RF model exhibits exceptional robustness, achieving consistent high-performance metrics irrespective of the underlying dataset quality, which prompts a critical discussion on the actual impact of data integrity on ML efficacy. Our study underscores the importance of continual refinement and methodological rigor in dataset generation for network security research. As the landscape of network threats evolves, so must the tools and techniques used to detect and analyze them.",
        "subjects": [
            "cs.LG",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16889",
        "abstract url": "https://arxiv.org/abs/2401.16889",
        "title": "Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents a comprehensive study on using deep reinforcement learning (RL) to create dynamic locomotion controllers for bipedal robots. Going beyond focusing on a single locomotion skill, we develop a general control solution that can be used for a range of dynamic bipedal skills, from periodic walking and running to aperiodic jumping and standing. Our RL-based controller incorporates a novel dual-history architecture, utilizing both a long-term and short-term input/output (I/O) history of the robot. This control architecture, when trained through the proposed end-to-end RL approach, consistently outperforms other methods across a diverse range of skills in both simulation and the real world.The study also delves into the adaptivity and robustness introduced by the proposed RL system in developing locomotion controllers. We demonstrate that the proposed architecture can adapt to both time-invariant dynamics shifts and time-variant changes, such as contact events, by effectively using the robot's I/O history. Additionally, we identify task randomization as another key source of robustness, fostering better task generalization and compliance to disturbances. The resulting control policies can be successfully deployed on Cassie, a torque-controlled human-sized bipedal robot. This work pushes the limits of agility for bipedal robots through extensive real-world experiments. We demonstrate a diverse range of locomotion skills, including: robust standing, versatile walking, fast running with a demonstration of a 400-meter dash, and a diverse set of jumping skills, such as standing long jumps and high jumps.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16914",
        "abstract url": "https://arxiv.org/abs/2401.16914",
        "title": "Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Lattices are architected metamaterials whose properties strongly depend on their geometrical design. The analogy between lattices and graphs enables the use of graph neural networks (GNNs) as a faster surrogate model compared to traditional methods such as finite element modelling. In this work, we generate a big dataset of structure-property relationships for strut-based lattices. The dataset is made available to the community which can fuel the development of methods anchored in physical principles for the fitting of fourth-order tensors. In addition, we present a higher-order GNN model trained on this dataset. The key features of the model are (i) SE(3) equivariance, and (ii) consistency with the thermodynamic law of conservation of energy. We compare the model to non-equivariant models based on a number of error metrics and demonstrate its benefits in terms of predictive performance and reduced training requirements. Finally, we demonstrate an example application of the model to an architected material design task. The methods which we developed are applicable to fourth-order tensors beyond elasticity such as piezo-optical tensor etc.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "comment": "International Conference on Learning Representations 2024"
    },
    {
        "paper id": "2401.17044",
        "abstract url": "https://arxiv.org/abs/2401.17044",
        "title": "Scalable Mechanism Design for Multi-Agent Path Finding",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multi-Agent Path Finding (MAPF) involves determining paths for multiple agents to travel simultaneously and collision-free through a shared area toward given goal locations. This problem is computationally complex, especially when dealing with large numbers of agents, as is common in realistic applications like autonomous vehicle coordination. Finding an optimal solution is often computationally infeasible, making the use of approximate, suboptimal algorithms essential. Adding to the complexity, agents might act in a self-interested and strategic way, possibly misrepresenting their goals to the MAPF algorithm if it benefits them. Although the field of mechanism design offers tools to align incentives, using these tools without careful consideration can fail when only having access to approximately optimal outcomes. In this work, we introduce the problem of scalable mechanism design for MAPF and propose three strategyproof mechanisms, two of which even use approximate MAPF algorithms. We test our mechanisms on realistic MAPF domains with problem sizes ranging from dozens to hundreds of agents. We find that they improve welfare beyond a simple baseline.",
        "subjects": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ],
        "comment": "12 pages, 5 figures. IJCAI'24 camera-ready version"
    },
    {
        "paper id": "2401.17178",
        "abstract url": "https://arxiv.org/abs/2401.17178",
        "title": "GraphViz2Vec: A Structure-aware Feature Generation Model to Improve Classification in GNNs",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "GNNs are widely used to solve various tasks including node classification and link prediction. Most of the GNN architectures assume the initial embedding to be random or generated from popular distributions. These initial embeddings require multiple layers of transformation to converge into a meaningful latent representation. While number of layers allow accumulation of larger neighbourhood of a node it also introduce the problem of over-smoothing. In addition, GNNs are inept at representing structural information. For example, the output embedding of a node does not capture its triangles participation. In this paper, we presented a novel feature extraction methodology GraphViz2Vec that can capture the structural information of a node's local neighbourhood to create meaningful initial embeddings for a GNN model. These initial embeddings helps existing models achieve state-of-the-art results in various classification tasks. Further, these initial embeddings help the model to produce desired results with only two layers which in turn reduce the problem of over-smoothing. The initial encoding of a node is obtained from an image classification model trained on multiple energy diagrams of its local neighbourhood. These energy diagrams are generated with the induced sub-graph of the nodes traversed by multiple random walks. The generated encodings increase the performance of existing models on classification tasks (with a mean increase of $4.65\\%$ and $2.58\\%$ for the node and link classification tasks, respectively), with some models achieving state-of-the-art results.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17212",
        "abstract url": "https://arxiv.org/abs/2401.17212",
        "title": "ContactGen: Contact-Guided Interactive 3D Human Generation for Partners",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Among various interactions between humans, such as eye contact and gestures, physical interactions by contact can act as an essential moment in understanding human behaviors. Inspired by this fact, given a 3D partner human with the desired interaction label, we introduce a new task of 3D human generation in terms of physical contact. Unlike previous works of interacting with static objects or scenes, a given partner human can have diverse poses and different contact regions according to the type of interaction. To handle this challenge, we propose a novel method of generating interactive 3D humans for a given partner human based on a guided diffusion framework. Specifically, we newly present a contact prediction module that adaptively estimates potential contact regions between two input humans according to the interaction label. Using the estimated potential contact regions as complementary guidances, we dynamically enforce ContactGen to generate interactive 3D humans for a given partner human within a guided diffusion model. We demonstrate ContactGen on the CHI3D dataset, where our method generates physically plausible and diverse poses compared to comparison methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2401.17350",
        "abstract url": "https://arxiv.org/abs/2401.17350",
        "title": "Time Series Supplier Allocation via Deep Black-Litterman Model",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Time Series Supplier Allocation (TSSA) poses a complex NP-hard challenge, aimed at refining future order dispatching strategies to satisfy order demands with maximum supply efficiency fully. Traditionally derived from financial portfolio management, the Black-Litterman (BL) model offers a new perspective for the TSSA scenario by balancing expected returns against insufficient supply risks. However, its application within TSSA is constrained by the reliance on manually constructed perspective matrices and spatio-temporal market dynamics, coupled with the absence of supervisory signals and data unreliability inherent to supplier information. To solve these limitations, we introduce the pioneering Deep Black-Litterman Model (DBLM), which innovatively adapts the BL model from financial roots to supply chain context. Leveraging the Spatio-Temporal Graph Neural Networks (STGNNS), DBLM automatically generates future perspective matrices for TSSA, by integrating spatio-temporal dependency. Moreover, a novel Spearman rank correlation distinctively supervises our approach to address the lack of supervisory signals, specifically designed to navigate through the complexities of supplier risks and interactions. This is further enhanced by a masking mechanism aimed at counteracting the biases from unreliable data, thereby improving the model's precision and reliability. Extensive experimentation on two datasets unequivocally demonstrates DBLM's enhanced performance in TSSA, setting new standards for the field. Our findings and methodology are made available for community access and further development.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "In submission to SIGKDD 2024"
    },
    {
        "paper id": "2401.17380",
        "abstract url": "https://arxiv.org/abs/2401.17380",
        "title": "Detecting gamma-band responses to the speech envelope for the ICASSP 2024 Auditory EEG Decoding Signal Processing Grand Challenge",
        "rating": "-0.5",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "The 2024 ICASSP Auditory EEG Signal Processing Grand Challenge concerns the decoding of electroencephalography (EEG) measurements taken from participants who listened to speech material. This work details our solution to the match-mismatch sub-task: given a short temporal segment of EEG recordings and several candidate speech segments, the task is to classify which of the speech segments was time-aligned with the EEG signals. We show that high-frequency gamma-band responses to the speech envelope can be detected with a high accuracy. By jointly assessing gamma-band responses and low-frequency envelope tracking, we develop a match-mismatch decoder which placed first in this task.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted for ICASSP 2024 (challenge track)"
    },
    {
        "paper id": "2401.17455",
        "abstract url": "https://arxiv.org/abs/2401.17455",
        "title": "Multiscale Parallel Tempering for Fast Sampling on Redistricting Plans",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.SI"
            ]
        ],
        "abstract": "When auditing a redistricting plan, a persuasive method is to compare the plan with an ensemble of neutrally drawn redistricting plans. Ensembles are generated via algorithms that sample distributions on balanced graph partitions. To audit the partisan difference between the ensemble and a given plan, one must ensure that the non-partisan criteria are matched so that we may conclude that partisan differences come from bias rather than, for example, levels of compactness or differences in community preservation. Certain sampling algorithms allow one to explicitly state the policy-based probability distribution on plans, however, these algorithms have shown poor mixing times for large graphs (i.e. redistricting spaces) for all but a few specialized measures. In this work, we generate a multiscale parallel tempering approach that makes local moves at each scale. The local moves allow us to adopt a wide variety of policy-based measures. We examine our method in the state of Connecticut and succeed at achieving fast mixing on a policy-based distribution that has never before been sampled at this scale. Our algorithm shows promise to expand to a significantly wider class of measures that will (i) allow for more principled and situation-based comparisons and (ii) probe for the typical partisan impact that policy can have on redistricting.",
        "subjects": [
            "physics.soc-ph",
            "cs.AI",
            "cs.SI",
            "math.PR"
        ],
        "comment": "26 pages with appendix; 11 figures"
    },
    {
        "paper id": "2401.17460",
        "abstract url": "https://arxiv.org/abs/2401.17460",
        "title": "Rendering Wireless Environments Useful for Gradient Estimators: A Zero-Order Stochastic Federated Learning Method",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) is a novel approach to machine learning that allows multiple edge devices to collaboratively train a model without disclosing their raw data. However, several challenges hinder the practical implementation of this approach, especially when devices and the server communicate over wireless channels, as it suffers from communication and computation bottlenecks in this case. By utilizing a communication-efficient framework, we propose a novel zero-order (ZO) method with a one-point gradient estimator that harnesses the nature of the wireless communication channel without requiring the knowledge of the channel state coefficient. It is the first method that includes the wireless channel in the learning algorithm itself instead of wasting resources to analyze it and remove its impact. The two main difficulties of this work are that in FL, the objective function is usually not convex, which makes the extension of FL to ZO methods challenging, and that including the impact of wireless channels requires extra attention. However, we overcome these difficulties and comprehensively analyze the proposed zero-order federated learning (ZOFL) framework. We establish its convergence theoretically, and we prove a convergence rate of $O(\\frac{1}{\\sqrt[3]{K}})$ in the nonconvex setting. We further demonstrate the potential of our algorithm with experimental results, taking into account independent and identically distributed (IID) and non-IID device data distributions.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17504",
        "abstract url": "https://arxiv.org/abs/2401.17504",
        "title": "CaMU: Disentangling Causal Effects in Deep Model Unlearning",
        "rating": "-0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine unlearning requires removing the information of forgetting data while keeping the necessary information of remaining data. Despite recent advancements in this area, existing methodologies mainly focus on the effect of removing forgetting data without considering the negative impact this can have on the information of the remaining data, resulting in significant performance degradation after data removal. Although some methods try to repair the performance of remaining data after removal, the forgotten information can also return after repair. Such an issue is due to the intricate intertwining of the forgetting and remaining data. Without adequately differentiating the influence of these two kinds of data on the model, existing algorithms take the risk of either inadequate removal of the forgetting data or unnecessary loss of valuable information from the remaining data. To address this shortcoming, the present study undertakes a causal analysis of the unlearning and introduces a novel framework termed Causal Machine Unlearning (CaMU). This framework adds intervention on the information of remaining data to disentangle the causal effects between forgetting data and remaining data. Then CaMU eliminates the causal impact associated with forgetting data while concurrently preserving the causal relevance of the remaining data. Comprehensive empirical results on various datasets and models suggest that CaMU enhances performance on the remaining data and effectively minimizes the influences of forgetting data. Notably, this work is the first to interpret deep model unlearning tasks from a new perspective of causality and provide a solution based on causal analysis, which opens up new possibilities for future research in deep model unlearning.",
        "subjects": [
            "cs.LG",
            "stat.ME"
        ],
        "comment": "Full version of the paper accepted for the SDM 24 conference"
    },
    {
        "paper id": "2401.17523",
        "abstract url": "https://arxiv.org/abs/2401.17523",
        "title": "Game-Theoretic Unlearnable Example Generator",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem. However, directly solving this optimization problem is intractable for deep neural networks. In this paper, we investigate unlearnable example attacks from a game-theoretic perspective, by formulating the attack as a nonzero sum Stackelberg game. First, the existence of game equilibria is proved under the normal setting and the adversarial training setting. It is shown that the game equilibrium gives the most powerful poison attack in that the victim has the lowest test accuracy among all networks within the same hypothesis space, when certain loss functions are used. Second, we propose a novel attack method, called the Game Unlearnable Example (GUE), which has three main gradients. (1) The poisons are obtained by directly solving the equilibrium of the Stackelberg game with a first-order algorithm. (2) We employ an autoencoder-like generative network model as the poison attacker. (3) A novel payoff function is introduced to evaluate the performance of the poison. Comprehensive experiments demonstrate that GUE can effectively poison the model in various scenarios. Furthermore, the GUE still works by using a relatively small percentage of the training data to train the generator, and the poison generator can generalize to unseen data well. Our implementation code can be found at https://github.com/hong-xian/gue.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17527",
        "abstract url": "https://arxiv.org/abs/2401.17527",
        "title": "Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Cutting planes (cuts) play an important role in solving mixed-integer linear programs (MILPs), as they significantly tighten the dual bounds and improve the solving performance. A key problem for cuts is when to stop cuts generation, which is important for the efficiency of solving MILPs. However, many modern MILP solvers employ hard-coded heuristics to tackle this problem, which tends to neglect underlying patterns among MILPs from certain applications. To address this challenge, we formulate the cuts generation stopping problem as a reinforcement learning problem and propose a novel hybrid graph representation model (HYGRO) to learn effective stopping strategies. An appealing feature of HYGRO is that it can effectively capture both the dynamic and static features of MILPs, enabling dynamic decision-making for the stopping strategies. To the best of our knowledge, HYGRO is the first data-driven method to tackle the cuts generation stopping problem. By integrating our approach with modern solvers, experiments demonstrate that HYGRO significantly improves the efficiency of solving MILPs compared to competitive baselines, achieving up to 31% improvement.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17539",
        "abstract url": "https://arxiv.org/abs/2401.17539",
        "title": "Enhancing Score-Based Sampling Methods with Ensembles",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce ensembles within score-based sampling methods to develop gradient-free approximate sampling techniques that leverage the collective dynamics of particle ensembles to compute approximate reverse diffusion drifts. We introduce the underlying methodology, emphasizing its relationship with generative diffusion models and the previously introduced F\u00f6llmer sampler. We demonstrate the efficacy of ensemble strategies through various examples, ranging from low- to medium-dimensionality sampling problems, including multi-modal and highly non-Gaussian probability distributions, and provide comparisons to traditional methods like NUTS. Our findings highlight the potential of ensemble strategies for modeling complex probability distributions in situations where gradients are unavailable. Finally, we showcase its application in the context of Bayesian inversion problems within the geophysical sciences.",
        "subjects": [
            "cs.LG",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17546",
        "abstract url": "https://arxiv.org/abs/2401.17546",
        "title": "Effective Multi-Stage Training Model For Edge Computing Devices In Intrusion Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Intrusion detection poses a significant challenge within expansive and persistently interconnected environments. As malicious code continues to advance and sophisticated attack methodologies proliferate, various advanced deep learning-based detection approaches have been proposed. Nevertheless, the complexity and accuracy of intrusion detection models still need further enhancement to render them more adaptable to diverse system categories, particularly within resource-constrained devices, such as those embedded in edge computing systems. This research introduces a three-stage training paradigm, augmented by an enhanced pruning methodology and model compression techniques. The objective is to elevate the system's effectiveness, concurrently maintaining a high level of accuracy for intrusion detection. Empirical assessments conducted on the UNSW-NB15 dataset evince that this solution notably reduces the model's dimensions, while upholding accuracy levels equivalent to similar proposals.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16764",
        "abstract url": "https://arxiv.org/abs/2401.16764",
        "title": "BoostDream: Efficient Refining for High-Quality Text-to-3D Generation from Multi-View Diffusion",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Witnessing the evolution of text-to-image diffusion models, significant strides have been made in text-to-3D generation. Currently, two primary paradigms dominate the field of text-to-3D: the feed-forward generation solutions, capable of swiftly producing 3D assets but often yielding coarse results, and the Score Distillation Sampling (SDS) based solutions, known for generating high-fidelity 3D assets albeit at a slower pace. The synergistic integration of these methods holds substantial promise for advancing 3D generation techniques. In this paper, we present BoostDream, a highly efficient plug-and-play 3D refining method designed to transform coarse 3D assets into high-quality. The BoostDream framework comprises three distinct processes: (1) We introduce 3D model distillation that fits differentiable representations from the 3D assets obtained through feed-forward generation. (2) A novel multi-view SDS loss is designed, which utilizes a multi-view aware 2D diffusion model to refine the 3D assets. (3) We propose to use prompt and multi-view consistent normal maps as guidance in refinement.Our extensive experiment is conducted on different differentiable 3D representations, revealing that BoostDream excels in generating high-quality 3D assets rapidly, overcoming the Janus problem compared to conventional SDS-based methods. This breakthrough signifies a substantial advancement in both the efficiency and quality of 3D generation processes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16801",
        "abstract url": "https://arxiv.org/abs/2401.16801",
        "title": "Kinematic Optimization of a Robotic Arm for Automation Tasks with Human Demonstration",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Robotic arms are highly common in various automation processes such as manufacturing lines. However, these highly capable robots are usually degraded to simple repetitive tasks such as pick-and-place. On the other hand, designing an optimal robot for one specific task consumes large resources of engineering time and costs. In this paper, we propose a novel concept for optimizing the fitness of a robotic arm to perform a specific task based on human demonstration. Fitness of a robot arm is a measure of its ability to follow recorded human arm and hand paths. The optimization is conducted using a modified variant of the Particle Swarm Optimization for the robot design problem. In the proposed approach, we generate an optimal robot design along with the required path to complete the task. The approach could reduce the time-to-market of robotic arms and enable the standardization of modular robotic parts. Novice users could easily apply a minimal robot arm to various tasks. Two test cases of common manufacturing tasks are presented yielding optimal designs and reduced computational effort by up to 92%.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "2024 IEEE Conference on Robotics and Automation (ICRA)"
    },
    {
        "paper id": "2401.16802",
        "abstract url": "https://arxiv.org/abs/2401.16802",
        "title": "Kinesthetic-based In-Hand Object Recognition with an Underactuated Robotic Hand",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Tendon-based underactuated hands are intended to be simple, compliant and affordable. Often, they are 3D printed and do not include tactile sensors. Hence, performing in-hand object recognition with direct touch sensing is not feasible. Adding tactile sensors can complicate the hardware and introduce extra costs to the robotic hand. Also, the common approach of visual perception may not be available due to occlusions. In this paper, we explore whether kinesthetic haptics can provide in-direct information regarding the geometry of a grasped object during in-hand manipulation with an underactuated hand. By solely sensing actuator positions and torques over a period of time during motion, we show that a classifier can recognize an object from a set of trained ones with a high success rate of almost 95%. In addition, the implementation of a real-time majority vote during manipulation further improves recognition. Additionally, a trained classifier is also shown to be successful in distinguishing between shape categories rather than just specific objects.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "2024 IEEE Conference on Robotics and Automation (ICRA)"
    },
    {
        "paper id": "2401.16822",
        "abstract url": "https://arxiv.org/abs/2401.16822",
        "title": "EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain",
        "rating": "-1",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "radar",
                "infrared"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal large language models (MLLMs) have demonstrated remarkable success in vision and visual-language tasks within the natural image domain. Owing to the significant diversities between the natural and remote sensing (RS) images, the development of MLLMs in the RS domain is still in the infant stage. To fill the gap, a pioneer MLLM named EarthGPT integrating various multi-sensor RS interpretation tasks uniformly is proposed in this paper for universal RS image comprehension. In EarthGPT, three key techniques are developed including a visual-enhanced perception mechanism, a cross-modal mutual comprehension approach, and a unified instruction tuning method for multi-sensor multi-task in the RS domain. More importantly, a dataset named MMRS-1M featuring large-scale multi-sensor multi-modal RS instruction-following is constructed, comprising over 1M image-text pairs based on 34 existing diverse RS datasets and including multi-sensor images such as optical, synthetic aperture radar (SAR), and infrared. The MMRS-1M dataset addresses the drawback of MLLMs on RS expert knowledge and stimulates the development of MLLMs in the RS domain. Extensive experiments are conducted, demonstrating the EarthGPT's superior performance in various RS visual interpretation tasks compared with the other specialist models and MLLMs, proving the effectiveness of the proposed EarthGPT and offering a versatile paradigm for open-set reasoning tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16831",
        "abstract url": "https://arxiv.org/abs/2401.16831",
        "title": "Maximal planar graphs that embed as centers",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A maximal planar graph is a graph which can be embedded in the plane such that every face of the graph is a triangle. The center of a graph is the subgraph induced by the vertices of minimum eccentricity. We introduce the notion of quasi-eccentric vertices, and use this to characterize maximal planar graphs that are the center of some planar graph. We also present some easier to check only necessary / only sufficient conditions for planar and maximal planar graphs to be the center of a planar graph. Finally, we use the aforementioned characterization to prove that all maximal planar graphs of order at most 8 are the center of some planar graph -- and this bound is sharp.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "24 pages, 18 figures. An early version of this work appeared in the Author's thesis \"Distances in Planar Graphs\", available on the UCT open thesis repository (2021)"
    },
    {
        "paper id": "2401.16867",
        "abstract url": "https://arxiv.org/abs/2401.16867",
        "title": "A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration",
        "rating": "-1",
        "keywords": [
            [
                "CT",
                "cancer"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The transformation model is an essential component of any deformable image registration approach. It provides a representation of physical deformations between images, thereby defining the range and realism of registrations that can be found. Two types of transformation models have emerged as popular choices: B-spline models and mesh models. Although both models have been investigated in detail, a direct comparison has not yet been made, since the models are optimized using very different optimization methods in practice. B-spline models are predominantly optimized using gradient-descent methods, while mesh models are typically optimized using finite-element method solvers or evolutionary algorithms. Multi-objective optimization methods, which aim to find a diverse set of high-quality trade-off registrations, are increasingly acknowledged to be important in deformable image registration. Since these methods search for a diverse set of registrations, they can provide a more complete picture of the capabilities of different transformation models, making them suitable for a comparison of models. In this work, we conduct the first direct comparison between B-spline and mesh transformation models, by optimizing both models with the same state-of-the-art multi-objective optimization method, the Multi-Objective Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm (MO-RV-GOMEA). The combination with B-spline transformation models, moreover, is novel. We experimentally compare both models on two different registration problems that are both based on pelvic CT scans of cervical cancer patients, featuring large deformations. Our results, on three cervical cancer patients, indicate that the choice of transformation model can have a profound impact on the diversity and quality of achieved registration outcomes.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.NE"
        ],
        "comment": "Pre-print for the SPIE Medical Imaging: Image Processing Conference"
    },
    {
        "paper id": "2401.16886",
        "abstract url": "https://arxiv.org/abs/2401.16886",
        "title": "CAFCT: Contextual and Attentional Feature Fusions of Convolutional Neural Networks and Transformer for Liver Tumor Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "CT",
                "Tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical image semantic segmentation techniques can help identify tumors automatically from computed tomography (CT) scans. In this paper, we propose a Contextual and Attentional feature Fusions enhanced Convolutional Neural Network (CNN) and Transformer hybrid network (CAFCT) model for liver tumor segmentation. In the proposed model, three other modules are introduced in the network architecture: Attentional Feature Fusion (AFF), Atrous Spatial Pyramid Pooling (ASPP) of DeepLabv3, and Attention Gates (AGs) to improve contextual information related to tumor boundaries for accurate segmentation. Experimental results show that the proposed CAFCT achieves a mean Intersection over Union (IoU) of 90.38% and Dice score of 86.78%, respectively, on the Liver Tumor Segmentation Benchmark (LiTS) dataset, outperforming pure CNN or Transformer methods, e.g., Attention U-Net, and PVTFormer.",
        "subjects": [
            "cs.CV",
            "eess.SP",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16893",
        "abstract url": "https://arxiv.org/abs/2401.16893",
        "title": "Computational Power of Opaque Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "In the field of distributed computing by robot swarms, the research comprehends manifold models where robots operate in the Euclidean plane through a sequence of look-compute-move cycles. Models under study differ for (i) the possibility of storing constant-size information, (ii) the possibility of communicating constant-size information, and (iii) the synchronization mode. By varying features (i,ii), we obtain the noted four base models: OBLOT (silent and oblivious robots), FSTA (silent and finite-state robots), FCOM (oblivious and finite-communication robots), and LUMI (finite-state and finite-communication robots). Combining each base model with the three main synchronization modes (fully synchronous, semi-synchronous, and asynchronous), we obtain the well-known 12 models. Extensive research has studied their computational power, proving the hierarchical relations between different models. However, only transparent robots have been considered. In this work, we study the taxonomy of the 12 models considering collision-intolerant opaque robots. We present six witness problems that prove the majority of the computational relations between the 12 models. In particular, the last witness problem depicts a peculiar issue occurring in the case of obstructed visibility and asynchrony.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16899",
        "abstract url": "https://arxiv.org/abs/2401.16899",
        "title": "MAkEable: Memory-centered and Affordance-based Task Execution Framework for Transferable Mobile Manipulation Skills",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "To perform versatile mobile manipulation tasks in human-centered environments, the ability to efficiently transfer learned tasks and experiences from one robot to another or across different environments is key. In this paper, we present MAkEable, a versatile uni- and multi-manual mobile manipulation framework that facilitates the transfer of capabilities and knowledge across different tasks, environments, and robots. Our framework integrates an affordance-based task description into the memory-centric cognitive architecture of the ARMAR humanoid robot family, which supports the sharing of experiences and demonstrations for transfer learning. By representing mobile manipulation actions through affordances, i.e., interaction possibilities of the robot with its environment, we provide a unifying framework for the autonomous uni- and multi-manual manipulation of known and unknown objects in various environments. We demonstrate the applicability of the framework in real-world experiments for multiple robots, tasks, and environments. This includes grasping known and unknown objects, object placing, bimanual object grasping, memory-enabled skill transfer in a drawer opening scenario across two different humanoid robots, and a pouring task learned from human demonstration.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16928",
        "abstract url": "https://arxiv.org/abs/2401.16928",
        "title": "Dynamic MRI reconstruction using low-rank plus sparse decomposition with smoothness regularization",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "cardiac"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The low-rank plus sparse (L+S) decomposition model has enabled better reconstruction of dynamic magnetic resonance imaging (dMRI) with separation into background (L) and dynamic (S) component. However, use of low-rank prior alone may not fully explain the slow variations or smoothness of the background part at the local scale. In this paper, we propose a smoothness-regularized L+S (SR-L+S) model for dMRI reconstruction from highly undersampled k-t-space data. We exploit joint low-rank and smooth priors on the background component of dMRI to better capture both its global and local temporal correlated structures. Extending the L+S formulation, the low-rank property is encoded by the nuclear norm, while the smoothness by a general \\ell_{p}-norm penalty on the local differences of the columns of L. The additional smoothness regularizer can promote piecewise local consistency between neighboring frames. By smoothing out the noise and dynamic activities, it allows accurate recovery of the background part, and subsequently more robust dMRI reconstruction. Extensive experiments on multi-coil cardiac and synthetic data shows that the SR-L+S model outp",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2401.16947",
        "abstract url": "https://arxiv.org/abs/2401.16947",
        "title": "WGAN-AFL: Seed Generation Augmented Fuzzer with Wasserstein-GAN",
        "rating": "-1",
        "keywords": [
            [
                "GAN"
            ]
        ],
        "abstract": "The importance of addressing security vulnerabilities is indisputable, with software becoming crucial in sectors such as national defense and finance. Consequently, The security issues caused by software vulnerabilities cannot be ignored. Fuzz testing is an automated software testing technology that can detect vulnerabilities in the software. However, most previous fuzzers encounter challenges that fuzzing performance is sensitive to initial input seeds. In the absence of high-quality initial input seeds, fuzzers may expend significant resources on program path exploration, leading to a substantial decrease in the efficiency of vulnerability detection. To address this issue, we propose WGAN-AFL. By collecting high-quality testcases, we train a generative adversarial network (GAN) to learn their features, thereby obtaining high-quality initial input seeds. To overcome drawbacks like mode collapse and training instability inherent in GANs, we utilize the Wasserstein GAN (WGAN) architecture for training, further enhancing the quality of the generated seeds. Experimental results demonstrate that WGAN-AFL significantly outperforms the original AFL in terms of code coverage, new paths, and vulnerability discovery, demonstrating the effective enhancement of seed quality by WGAN-AFL.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16963",
        "abstract url": "https://arxiv.org/abs/2401.16963",
        "title": "Sub-Optimal Fast Fourier Series Approximation for Initial Trajectory Design",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory",
                "flight"
            ]
        ],
        "abstract": "The Finite Fourier Series (FFS) Shape-Based (SB) trajectory approximation method has been used to rapidly generate initial trajectories that satisfy the dynamics, trajectory boundary conditions, and limitation on maximum thrust acceleration. The FFS SB approach solves a nonlinear programming problem (NLP) in searching for feasible trajectories. This paper extends the development of the FFS SB approach to generate sub optimal solutions. Specifically, the objective function of the NLP problem is modified to include also a measure for the time of flight. Numerical results presented in this paper show several solutions that differ from those of the original FFS SB ones. The sub-optimal trajectories generated using a time of flight minimization are shown to be physically feasible trajectories and potential candidates for direct solvers.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "physics.space-ph"
        ],
        "comment": "2021 AAS/AIAA Astrodynamics Specialist Conference, Big Sky, Virtual, August 9-11, 2021"
    },
    {
        "paper id": "2401.16972",
        "abstract url": "https://arxiv.org/abs/2401.16972",
        "title": "Deep 3D World Models for Multi-Image Super-Resolution Beyond Optical Flow",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Super-Resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Multi-image super-resolution (MISR) allows to increase the spatial resolution of a low-resolution (LR) acquisition by combining multiple images carrying complementary information in the form of sub-pixel offsets in the scene sampling, and can be significantly more effective than its single-image counterpart. Its main difficulty lies in accurately registering and fusing the multi-image information. Currently studied settings, such as burst photography, typically involve assumptions of small geometric disparity between the LR images and rely on optical flow for image registration. We study a MISR method that can increase the resolution of sets of images acquired with arbitrary, and potentially wildly different, camera positions and orientations, generalizing the currently studied MISR settings. Our proposed model, called EpiMISR, moves away from optical flow and explicitly uses the epipolar geometry of the acquisition process, together with transformer-based processing of radiance feature fields to substantially improve over state-of-the-art MISR methods in presence of large disparities in the LR images.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16991",
        "abstract url": "https://arxiv.org/abs/2401.16991",
        "title": "Category-wise Fine-Tuning: Resisting Incorrect Pseudo-Labels in Multi-Label Image Classification with Partial Labels",
        "rating": "-1",
        "keywords": [
            [
                "X-ray"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale image datasets are often partially labeled, where only a few categories' labels are known for each image. Assigning pseudo-labels to unknown labels to gain additional training signals has become prevalent for training deep classification models. However, some pseudo-labels are inevitably incorrect, leading to a notable decline in the model classification performance. In this paper, we propose a novel method called Category-wise Fine-Tuning (CFT), aiming to reduce model inaccuracies caused by the wrong pseudo-labels. In particular, CFT employs known labels without pseudo-labels to fine-tune the logistic regressions of trained models individually to calibrate each category's model predictions. Genetic Algorithm, seldom used for training deep models, is also utilized in CFT to maximize the classification performance directly. CFT is applied to well-trained models, unlike most existing methods that train models from scratch. Hence, CFT is general and compatible with models trained with different methods and schemes, as demonstrated through extensive experiments. CFT requires only a few seconds for each category for calibration with consumer-grade GPUs. We achieve state-of-the-art results on three benchmarking datasets, including the CheXpert chest X-ray competition dataset (ensemble mAUC 93.33%, single model 91.82%), partially labeled MS-COCO (average mAP 83.69%), and Open Image V3 (mAP 85.31%), outperforming the previous bests by 0.28%, 2.21%, 2.50%, and 0.91%, respectively. The single model on CheXpert has been officially evaluated by the competition server, endorsing the correctness of the result. The outstanding results and generalizability indicate that CFT could be substantial and prevalent for classification model development. Code is available at: https://github.com/maxium0526/category-wise-fine-tuning.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17053",
        "abstract url": "https://arxiv.org/abs/2401.17053",
        "title": "BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We present BlockFusion, a diffusion-based model that generates 3D scenes as unit blocks and seamlessly incorporates new blocks to extend the scene. BlockFusion is trained using datasets of 3D blocks that are randomly cropped from complete 3D scene meshes. Through per-block fitting, all training blocks are converted into the hybrid neural fields: with a tri-plane containing the geometry features, followed by a Multi-layer Perceptron (MLP) for decoding the signed distance values. A variational auto-encoder is employed to compress the tri-planes into the latent tri-plane space, on which the denoising diffusion process is performed. Diffusion applied to the latent representations allows for high-quality and diverse 3D scene generation. To expand a scene during generation, one needs only to append empty blocks to overlap with the current scene and extrapolate existing latent tri-planes to populate new blocks. The extrapolation is done by conditioning the generation process with the feature samples from the overlapping tri-planes during the denoising iterations. Latent tri-plane extrapolation produces semantically and geometrically meaningful transitions that harmoniously blend with the existing scene. A 2D layout conditioning mechanism is used to control the placement and arrangement of scene elements. Experimental results indicate that BlockFusion is capable of generating diverse, geometrically consistent and unbounded large 3D scenes with unprecedented high-quality shapes in both indoor and outdoor scenarios.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "Video: https://www.youtube.com/watch?v=PxIBtd6G0mA"
    },
    {
        "paper id": "2401.17057",
        "abstract url": "https://arxiv.org/abs/2401.17057",
        "title": "What can Information Guess? Guessing Advantage vs. R\u00e9nyi Entropy for Small Leakages",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "We leverage the Gibbs inequality and its natural generalization to R\u00e9nyi entropies to derive closed-form parametric expressions of the optimal lower bounds of $\u03c1$th-order guessing entropy (guessing moment) of a secret taking values on a finite set, in terms of the R\u00e9nyi-Arimoto $\u03b1$-entropy. This is carried out in an non-asymptotic regime when side information may be available. The resulting bounds yield a theoretical solution to a fundamental problem in side-channel analysis: Ensure that an adversary will not gain much guessing advantage when the leakage information is sufficiently weakened by proper countermeasures in a given cryptographic implementation. Practical evaluation for classical leakage models show that the proposed bounds greatly improve previous ones for analyzing the capability of an adversary to perform side-channel attacks.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17061",
        "abstract url": "https://arxiv.org/abs/2401.17061",
        "title": "OmniSCV: An Omnidirectional Synthetic Image Generator for Computer Vision",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Omnidirectional and 360\u00b0 images are becoming widespread in industry and in consumer society, causing omnidirectional computer vision to gain attention. Their wide field of view allows the gathering of a great amount of information about the environment from only an image. However, the distortion of these images requires the development of specific algorithms for their treatment and interpretation. Moreover, a high number of images is essential for the correct training of computer vision algorithms based on learning. In this paper, we present a tool for generating datasets of omnidirectional images with semantic and depth information. These images are synthesized from a set of captures that are acquired in a realistic virtual environment for Unreal Engine 4 through an interface plugin. We gather a variety of well-known projection models such as equirectangular and cylindrical panoramas, different fish-eye lenses, catadioptric systems, and empiric models. Furthermore, we include in our tool photorealistic non-central-projection systems as non-central panoramas and non-central catadioptric systems. As far as we know, this is the first reported tool for generating photorealistic non-central images in the literature. Moreover, since the omnidirectional images are made virtually, we provide pixel-wise information about semantics and depth as well as perfect knowledge of the calibration parameters of the cameras. This allows the creation of ground-truth information with pixel precision for training learning algorithms and testing 3D vision approaches. To validate the proposed tool, different computer vision algorithms are tested as line extractions from dioptric and catadioptric central images, 3D Layout recovery and SLAM using equirectangular panoramas, and 3D reconstruction from non-central panoramas.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17065",
        "abstract url": "https://arxiv.org/abs/2401.17065",
        "title": "Platoon Fundamental Diagram estimation can be Markovian: evidence from human- and self-driven vehicle trajectories",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "We propose a simple and effective method to derive the Fundamental Diagram (FD) from platoon vehicle trajectories. Average traffic state variables are computed using Edie's generalized definitions within time-dependent trapezoidal space-time areas. To obtain a clear FD, we employ a bivariate data aggregation technique to eliminate scatter. Our findings are as follows: (i) The proposed method demonstrates a remarkably consistent relation between the traffic variables and a clear triangular shape for autonomously-driven vehicles. (ii) The FDs are invariant to several factors of heterogeneity such as the platoon length, vehicle characteristics, road particularities, and data acquisition accuracy. (iii) ACC-driven vehicle platoons with minimum headway setting achieve much higher capacity, roughly 90\\% than those with a large headway setting. (iv) Connectivity might increase capacity. (v) Human drivers have a wider near-capacity operation area, showing different behaviors at high speeds than low ones, and (vi) Safety concerns might arise due to high values of backward wave speed for ACC-driven vehicles. Comparative analysis with the state-of-the-art confirms the validity of our approach. The proposed method stands out due to its simplicity and accuracy, which paves the way for practical applications in real-time traffic flow monitoring and control within modern intelligent transportation systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "14 pages, 8 figures, preprint"
    },
    {
        "paper id": "2401.17082",
        "abstract url": "https://arxiv.org/abs/2401.17082",
        "title": "Casting manipulation of unknown string by robot arm",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Casting manipulation has been studied to expand the robot's movable range. In this manipulation, the robot throws and reaches the end effector to a distant target. Usually, a special casting manipulator, which consists of rigid arm links and specific flexible linear objects, is constructed for an effective casting manipulation. However, the special manipulator cannot perform normal manipulations, such as picking and placing, grasping, and operating objects. We propose that the normal robot arm, which can perform normal tasks, picks up an unknown string in the surrounding environment and realizes casting manipulation with it. As the properties of the string are not provided in advance, it is crucial how to reflect it in casting manipulation. This is realized by the motion generation of the robot arm with the simulation of string movement, actual string manipulation by the robot arm, and string parameter estimation from the actual string movement. After repeating these three steps, the simulated string movement approximates the actual to realize casting manipulation with the unknown string. We confirmed the effectiveness of the proposed method through experiments. The try of this study will lead to enhancement of the performance of home service robot, exploration robot, rescue robot and entertainment robot.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IROS 2021"
    },
    {
        "paper id": "2401.17104",
        "abstract url": "https://arxiv.org/abs/2401.17104",
        "title": "H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: To develop a method for automated segmentation of hypothalamus subregions informed by ultra-high resolution ex vivo magnetic resonance images (MRI), which generalizes across MRI sequences and resolutions without retraining. Materials and Methods: We trained our deep learning method, H-synEx, with synthetic images derived from label maps built from ultra-high resolution ex vivo MRI scans, which enables finer-grained manual segmentation when compared with 1mm isometric in vivo images. We validated this retrospective study using 1535 in vivo images from six datasets and six MRI sequences. The quantitative evaluation used the Dice Coefficient (DC) and Average Hausdorff distance (AVD). Statistical analysis compared hypothalamic subregion volumes in controls, Alzheimer's disease (AD), and behavioral variant frontotemporal dementia (bvFTD) subjects using the area under the curve (AUC) and Wilcoxon rank sum test. Results: H-SynEx can segment the hypothalamus across various MRI sequences, encompassing FLAIR sequences with significant slice spacing (5mm). Using hypothalamic volumes on T1w images to distinguish control from AD and bvFTD patients, we observed AUC values of 0.74 and 0.79 respectively. Additionally, AUC=0.66 was found for volume variation on FLAIR scans when comparing control and non-patients. Conclusion: Our results show that H-SynEx successfully leverages information from ultra-high resolution scans to segment in vivo from different MRI sequences such as T1w, T2w, PD, qT1, FA, and FLAIR. We also found that our automated segmentation was able to discriminate controls versus patients on FLAIR images with 5mm spacing. H-SynEx is openly available at https://github.com/liviamarodrigues/hsynex.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17120",
        "abstract url": "https://arxiv.org/abs/2401.17120",
        "title": "PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI) enable automated generation of landscape renderings, the end-to-end methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of GAI models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, illustration module converts scene layouts into realistic landscape renderings using a fine-tuned low-rank adaptation diffusion model. PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "27 pages, 14 figures, The ACM CHI 2024 conference"
    },
    {
        "paper id": "2401.17121",
        "abstract url": "https://arxiv.org/abs/2401.17121",
        "title": "Physical Priors Augmented Event-Based 3D Reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth",
                "NeRF",
                "radiance fields"
            ]
        ],
        "abstract": "3D neural implicit representations play a significant component in many robotic applications. However, reconstructing neural radiance fields (NeRF) from realistic event data remains a challenge due to the sparsities and the lack of information when only event streams are available. In this paper, we utilize motion, geometry, and density priors behind event data to impose strong physical constraints to augment NeRF training. The proposed novel pipeline can directly benefit from those priors to reconstruct 3D scenes without additional inputs. Moreover, we present a novel density-guided patch-based sampling strategy for robust and efficient learning, which not only accelerates training procedures but also conduces to expressions of local geometries. More importantly, we establish the first large dataset for event-based 3D reconstruction, which contains 101 objects with various materials and geometries, along with the groundtruth of images and depth maps for all camera viewpoints, which significantly facilitates other research in the related fields. The code and dataset will be publicly available at https://github.com/Mercerai/PAEv3d.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages, 6 figures, ICRA 2024"
    },
    {
        "paper id": "2401.17146",
        "abstract url": "https://arxiv.org/abs/2401.17146",
        "title": "Dependency-Aware Online Caching",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We consider a variant of the online caching problem where the items exhibit dependencies among each other: an item can reside in the cache only if all its dependent items are also in the cache. The dependency relations can form any directed acyclic graph. These requirements arise e.g., in systems such as CacheFlow (SOSR 2016) that cache forwarding rules for packet classification in IP-based communication networks. First, we present an optimal randomized online caching algorithm which accounts for dependencies among the items. Our randomized algorithm is $O( \\log k)$-competitive, where $k$ is the size of the cache, meaning that our algorithm never incurs the cost of $O(\\log k)$ times higher than even an optimal algorithm that knows the future input sequence. Second, we consider the bypassing model, where requests can be served at a fixed price without fetching the item and its dependencies into the cache -- a variant of caching with dependencies introduced by Bienkowski et al. at SPAA 2017. For this setting, we give an $O( \\sqrt{k \\cdot \\log k})$-competitive algorithm, which significantly improves the best known competitiveness. We conduct a small case study, to find out that our algorithm incurs on average 2x lower cost.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "INFOCOM 2024"
    },
    {
        "paper id": "2401.17187",
        "abstract url": "https://arxiv.org/abs/2401.17187",
        "title": "Formal Synthesis of Uncertainty Reduction Controllers",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "In its quest for approaches to taming uncertainty in self-adaptive systems (SAS), the research community has largely focused on solutions that adapt the SAS architecture or behaviour in response to uncertainty. By comparison, solutions that reduce the uncertainty affecting SAS (other than through the blanket monitoring of their components and environment) remain underexplored. Our paper proposes a more nuanced, adaptive approach to SAS uncertainty reduction. To that end, we introduce a SAS architecture comprising an uncertainty reduction controller that drives the adaptive acquisition of new information within the SAS adaptation loop, and a tool-supported method that uses probabilistic model checking to synthesise such controllers. The controllers generated by our method deliver optimal trade-offs between SAS uncertainty reduction benefits and new information acquisition costs. We illustrate the use and evaluate the effectiveness of our approach for mobile robot navigation and server infrastructure management SAS.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17197",
        "abstract url": "https://arxiv.org/abs/2401.17197",
        "title": "Data-efficient Fine-tuning for LLM-based Recommendation",
        "rating": "-1",
        "keywords": [
            [
                "efficient Fine-tuning"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Leveraging Large Language Models (LLMs) for recommendation has recently garnered considerable attention, where fine-tuning plays a key role in LLMs' adaptation. However, the cost of fine-tuning LLMs on rapidly expanding recommendation data limits their practical application. To address this challenge, few-shot fine-tuning offers a promising approach to quickly adapt LLMs to new recommendation data. We propose the task of data pruning for efficient LLM-based recommendation, aimed at identifying representative samples tailored for LLMs' few-shot fine-tuning. While coreset selection is closely related to the proposed task, existing coreset selection methods often rely on suboptimal heuristic metrics or entail costly optimization on large-scale recommendation data. To tackle these issues, we introduce two objectives for the data pruning task in the context of LLM-based recommendation: 1) high accuracy aims to identify the influential samples that can lead to high overall performance; and 2) high efficiency underlines the low costs of the data pruning process. To pursue the two objectives, we propose a novel data pruning method based on two scores, i.e., influence score and effort score, to efficiently identify the influential samples. Particularly, the influence score is introduced to accurately estimate the influence of sample removal on the overall performance. To achieve low costs of the data pruning process, we use a small-sized surrogate model to replace LLMs to obtain the influence score. Considering the potential gap between the surrogate model and LLMs, we further propose an effort score to prioritize some hard samples specifically for LLMs. Empirical results on three real-world datasets validate the effectiveness of our proposed method. In particular, the proposed method uses only 2% samples to surpass the full data fine-tuning, reducing time costs by 97%.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17206",
        "abstract url": "https://arxiv.org/abs/2401.17206",
        "title": "Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT Semantic Embeddings K-Means-Infused CRF Model",
        "rating": "-1",
        "keywords": [
            [
                "Named Entity Recognition"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Named Entity Recognition (NER) is a sub-task of Natural Language Processing (NLP) that distinguishes entities from unorganized text into predefined categorization. In recent years, a lot of Bangla NLP subtasks have received quite a lot of attention; but Named Entity Recognition in Bangla still lags behind. In this research, we explored the existing state of research in Bangla Named Entity Recognition. We tried to figure out the limitations that current techniques and datasets face, and we would like to address these limitations in our research. Additionally, We developed a Gazetteer that has the ability to significantly boost the performance of NER. We also proposed a new NER solution by taking advantage of state-of-the-art NLP tools that outperform conventional techniques.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17219",
        "abstract url": "https://arxiv.org/abs/2401.17219",
        "title": "Faster coloring and embedding in dense hypergraphs via stability",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The classical Andr\u00e1sfai-Erd\u0151s-S\u00f3s Theorem states that for $\\ell\\ge 2$, every $n$-vertex $K_{\\ell+1}$-free graph with minimum degree greater than $\\frac{3\\ell-4}{3\\ell-1}n$ must be $\\ell$-partite. We establish a simple criterion for $r$-graphs, $r \\geq 2$, to exhibit an Andr\u00e1sfai-Erd\u0151s-S\u00f3s-type property (AES), leading to a classification of most previously studied hypergraph families with this property. For every AES $r$-graph $F$, we present a simple algorithm to decide the $F$-freeness of an $n$-vertex $r$-graph with minimum degree greater than $(\u03c0(F) - \\varepsilon_F)\\binom{n}{r-1}$ in time $O(n^r)$, where $\\varepsilon_F >0$ is a constant. In particular, for the complete graph $K_{\\ell+1}$, we can take $\\varepsilon_{K_{\\ell+1}} = (3\\ell^2-\\ell)^{-1}$. Based on a result by Chen-Huang-Kanj-Xia, we show that for every fixed $C > 0$, this problem cannot be solved in time $n^{o(\\ell)}$ if we replace $\\varepsilon_{K_{\\ell+1}}$ with $(C\\ell)^{-1}$ unless ETH fails. Furthermore, we establish an algorithm to decide the $K_{\\ell+1}$-freeness of an $n$-vertex graph with $\\mathrm{ex}(n,K_{\\ell+1})-k$ edges in time $(\\ell+1)n^2$ for $k \\le n/30\\ell$ and $\\ell \\le \\sqrt{n/6}$, partially improving upon the recently provided running time of $2.49^k n^{O(1)}$ by Fomin--Golovach--Sagunov--Simonov. Moreover, we show that for every fixed $\u03b4> 0$, this problem cannot be solved in time $n^{o(\\ell)}$ if $k$ is of order $n^{1+\u03b4}$ unless ETH fails. As an intermediate step, we show that for a specific class of $r$-graphs $F$, the (surjective) $F$-coloring problem can be solved in time $O(n^r)$, provided the input $r$-graph has $n$ vertices and a large minimum degree, refining several previous results.",
        "subjects": [
            "math.CO",
            "cs.CC"
        ],
        "comment": "added a new statement in THM 1.2, fixed some typo, added a new reference"
    },
    {
        "paper id": "2401.17226",
        "abstract url": "https://arxiv.org/abs/2401.17226",
        "title": "Knowledge Problems in Protocol Analysis: Extending the Notion of Subterm Convergent",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We introduce a new form of restricted term rewrite system, the graph-embedded term rewrite system. These systems, and thus the name, are inspired by the graph minor relation and are more flexible extensions of the well-known homeomorphic-embedded property of term rewrite systems. As a motivating application area, we consider the symbolic analysis of security protocols, and more precisely the two knowledge problems defined by the deduction problem and the static equivalence problem. In this field restricted term rewrite systems, such as subterm convergent ones, have proven useful since the knowledge problems are decidable for such systems. Many of the same decision procedures still work for examples of systems which are \"beyond subterm convergent\". However, the applicability of the corresponding decision procedures to these examples must often be proven on an individual basis. This is due to the problem that they don't fit into an existing syntactic definition for which the procedures are known to work. Here we show that many of these systems belong to a particular subclass of graph-embedded convergent systems, called contracting convergent systems. On the one hand, we show that the knowledge problems are decidable for the subclass of contracting convergent systems. On the other hand, we show that the knowledge problems are undecidable for the class of graph-embedded systems. Going further, we compare and contrast these graph embedded systems with several notions and properties already known in the protocol analysis literature. Finally, we provide several combination results, both for the combination of multiple contracting convergent systems, and then for the combination of contracting convergent systems with particular permutative equational theories.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Preprint submitted to Logical Methods in Computer Science"
    },
    {
        "paper id": "2401.17231",
        "abstract url": "https://arxiv.org/abs/2401.17231",
        "title": "Achieving More Human Brain-Like Vision via Human EEG Representational Alignment",
        "rating": "-1",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Despite advancements in artificial intelligence, object recognition models still lag behind in emulating visual information processing in human brains. Recent studies have highlighted the potential of using neural data to mimic brain processing; however, these often rely on invasive neural recordings from non-human subjects, leaving a critical gap in understanding human visual perception. Addressing this gap, we present, for the first time, 'Re(presentational)Al(ignment)net', a vision model aligned with human brain activity based on non-invasive EEG, demonstrating a significantly higher similarity to human brain representations. Our innovative image-to-brain multi-layer encoding framework advances human neural alignment by optimizing multiple model layers and enabling the model to efficiently learn and mimic human brain's visual representational patterns across object categories and different modalities. Our findings suggest that ReAlnet represents a breakthrough in bridging the gap between artificial and human vision, and paving the way for more brain-like artificial intelligence systems.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.NE",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17257",
        "abstract url": "https://arxiv.org/abs/2401.17257",
        "title": "Low Thrust Trajectory Design Using A Semi-Analytic Approach",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "Space missions that use low-thrust propulsion technology are becoming increasingly popular since they utilize propellant more efficiently and thus reduce mission costs. However, optimizing continuous-thrust trajectories is complex, time-consuming, and extremely sensitive to initial guesses. Hence, generating approximate trajectories that can be used as reliable initial guesses in trajectory generators is essential. This paper presents a semi-analytic approach for designing planar and three-dimensional trajectories using Hills equations. The spacecraft is assumed to be acted upon by a constant thrust acceleration magnitude. The proposed equations are employed in a Nonlinear Programming Problem (NLP) solver to obtain the thrust directions. Their applicability is tested for various design scenarios like orbit raising, orbit insertion, and rendezvous. The trajectory solutions are then validated as initial guesses in high-fidelity optimal control tools. The usefulness of this method lies in the preliminary stages of low-thrust mission design, where speed and reliability are key.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "physics.space-ph"
        ],
        "comment": "2022 AAS/AIAA Astrodynamics Specialist Conference, Charlotte, NC, August 7-11, 2022"
    },
    {
        "paper id": "2401.17264",
        "abstract url": "https://arxiv.org/abs/2401.17264",
        "title": "Proactive Detection of Voice Cloning with Localized Watermarking",
        "rating": "-1",
        "keywords": [
            [
                "Watermarking"
            ],
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "In the rapidly evolving field of speech generative models, there is a pressing need to ensure audio authenticity against the risks of voice cloning. We present AudioSeal, the first audio watermarking technique designed specifically for localized detection of AI-generated speech. AudioSeal employs a generator/detector architecture trained jointly with a localization loss to enable localized watermark detection up to the sample level, and a novel perceptual loss inspired by auditory masking, that enables AudioSeal to achieve better imperceptibility. AudioSeal achieves state-of-the-art performance in terms of robustness to real life audio manipulations and imperceptibility based on automatic and human evaluation metrics. Additionally, AudioSeal is designed with a fast, single-pass detector, that significantly surpasses existing models in speed - achieving detection up to two orders of magnitude faster, making it ideal for large-scale and real-time applications.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "Code at https://github.com/facebookresearch/audioseal"
    },
    {
        "paper id": "2401.17405",
        "abstract url": "https://arxiv.org/abs/2401.17405",
        "title": "Camouflage Adversarial Attacks on Multiple Agent Systems",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "The multi-agent reinforcement learning systems (MARL) based on the Markov decision process (MDP) have emerged in many critical applications. To improve the robustness/defense of MARL systems against adversarial attacks, the study of various adversarial attacks on reinforcement learning systems is very important. Previous works on adversarial attacks considered some possible features to attack in MDP, such as the action poisoning attacks, the reward poisoning attacks, and the state perception attacks. In this paper, we propose a brand-new form of attack called the camouflage attack in the MARL systems. In the camouflage attack, the attackers change the appearances of some objects without changing the actual objects themselves; and the camouflaged appearances may look the same to all the targeted recipient (victim) agents. The camouflaged appearances can mislead the recipient agents to misguided actions. We design algorithms that give the optimal camouflage attacks minimizing the rewards of recipient agents. Our numerical and theoretical results show that camouflage attacks can rival the more conventional, but likely more difficult state perception attacks. We also investigate cost-constrained camouflage attacks and showed numerically how cost budgets affect the attack performance.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2311.00859"
    },
    {
        "paper id": "2401.17409",
        "abstract url": "https://arxiv.org/abs/2401.17409",
        "title": "EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Our hands serve as a fundamental means of interaction with the world around us. Therefore, understanding hand poses and interaction context is critical for human-computer interaction. We present EchoWrist, a low-power wristband that continuously estimates 3D hand pose and recognizes hand-object interactions using active acoustic sensing. EchoWrist is equipped with two speakers emitting inaudible sound waves toward the hand. These sound waves interact with the hand and its surroundings through reflections and diffractions, carrying rich information about the hand's shape and the objects it interacts with. The information captured by the two microphones goes through a deep learning inference system that recovers hand poses and identifies various everyday hand activities. Results from the two 12-participant user studies show that EchoWrist is effective and efficient at tracking 3D hand poses and recognizing hand-object interactions. Operating at 57.9mW, EchoWrist is able to continuously reconstruct 20 3D hand joints with MJEDE of 4.81mm and recognize 12 naturalistic hand-object interactions with 97.6% accuracy.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17477",
        "abstract url": "https://arxiv.org/abs/2401.17477",
        "title": "Detecting mental disorder on social media: a ChatGPT-augmented explainable approach",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "In the digital era, the prevalence of depressive symptoms expressed on social media has raised serious concerns, necessitating advanced methodologies for timely detection. This paper addresses the challenge of interpretable depression detection by proposing a novel methodology that effectively combines Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and conversational agents like ChatGPT. In our methodology, explanations are achieved by integrating BERTweet, a Twitter-specific variant of BERT, into a novel self-explanatory model, namely BERT-XDD, capable of providing both classification and explanations via masked attention. The interpretability is further enhanced using ChatGPT to transform technical explanations into human-readable commentaries. By introducing an effective and modular approach for interpretable depression detection, our methodology can contribute to the development of socially responsible digital platforms, fostering early intervention and support for mental health challenges under the guidance of qualified healthcare professionals.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17480",
        "abstract url": "https://arxiv.org/abs/2401.17480",
        "title": "Colony-Enhanced Recurrent Neural Architecture Search: Collaborative Ant-Based Optimization",
        "rating": "-1",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ]
        ],
        "abstract": "Crafting neural network architectures manually is a formidable challenge often leading to suboptimal and inefficient structures. The pursuit of the perfect neural configuration is a complex task, prompting the need for a metaheuristic approach such as Neural Architecture Search (NAS). Drawing inspiration from the ingenious mechanisms of nature, this paper introduces Collaborative Ant-based Neural Topology Search (CANTS-N), pushing the boundaries of NAS and Neural Evolution (NE). In this innovative approach, ant-inspired agents meticulously construct neural network structures, dynamically adapting within a dynamic environment, much like their natural counterparts. Guided by Particle Swarm Optimization (PSO), CANTS-N's colonies optimize architecture searches, achieving remarkable improvements in mean squared error (MSE) over established methods, including BP-free CANTS, BP CANTS, and ANTS. Scalable, adaptable, and forward-looking, CANTS-N has the potential to reshape the landscape of NAS and NE. This paper provides detailed insights into its methodology, results, and far-reaching implications.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17481",
        "abstract url": "https://arxiv.org/abs/2401.17481",
        "title": "Navigating the Unknown: Uncertainty-Aware Compute-in-Memory Autonomy of Edge Robotics",
        "rating": "-1",
        "keywords": [
            [
                "Robotics"
            ]
        ],
        "abstract": "This paper addresses the challenging problem of energy-efficient and uncertainty-aware pose estimation in insect-scale drones, which is crucial for tasks such as surveillance in constricted spaces and for enabling non-intrusive spatial intelligence in smart homes. Since tiny drones operate in highly dynamic environments, where factors like lighting and human movement impact their predictive accuracy, it is crucial to deploy uncertainty-aware prediction algorithms that can account for environmental variations and express not only the prediction but also confidence in the prediction. We address both of these challenges with Compute-in-Memory (CIM) which has become a pivotal technology for deep learning acceleration at the edge. While traditional CIM techniques are promising for energy-efficient deep learning, to bring in the robustness of uncertainty-aware predictions at the edge, we introduce a suite of novel techniques: First, we discuss CIM-based acceleration of Bayesian filtering methods uniquely by leveraging the Gaussian-like switching current of CMOS inverters along with co-design of kernel functions to operate with extreme parallelism and with extreme energy efficiency. Secondly, we discuss the CIM-based acceleration of variational inference of deep learning models through probabilistic processing while unfolding iterative computations of the method with a compute reuse strategy to significantly minimize the workload. Overall, our co-design methodologies demonstrate the potential of CIM to improve the processing efficiency of uncertainty-aware algorithms by orders of magnitude, thereby enabling edge robotics to access the robustness of sophisticated prediction frameworks within their extremely stringent area/power resources.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17493",
        "abstract url": "https://arxiv.org/abs/2401.17493",
        "title": "CLAIRE: Scalable GPU-Accelerated Algorithms for Diffeomorphic Image Registration in 3D",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "We present our work on scalable, GPU-accelerated algorithms for diffeomorphic image registration. The associated software package is termed CLAIRE. Image registration is a non-linear inverse problem. It is about computing a spatial mapping from one image of the same object or scene to another. In diffeomorphic image registration, the set of admissible spatial transformations is restricted to maps that are smooth, one-to-one, and have a smooth inverse. We formulate diffeomorphic image registration as a variational problem governed by transport equations. We use an inexact, globalized (Gauss--)Newton--Krylov method for numerical optimization. We consider semi-Lagrangian methods for numerical time integration. Our solver features mixed-precision, hardware-accelerated computational kernels for optimal computational throughput. We use the message-passing interface for distributed-memory parallelism and deploy our code on modern high-performance computing architectures. Our solver allows us to solve clinically relevant problems in under four seconds on a single GPU. It can also be applied to large-scale 3D imaging applications with data that is discretized on meshes with billions of voxels. We demonstrate that our numerical framework yields high-fidelity results in only a few seconds, even if we search for an optimal regularization parameter.",
        "subjects": [
            "math.OC",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17499",
        "abstract url": "https://arxiv.org/abs/2401.17499",
        "title": "AdvGPS: Adversarial GPS for Multi-Agent Perception Attack",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "Attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The multi-agent perception system collects visual data from sensors located on various agents and leverages their relative poses determined by GPS signals to effectively fuse information, mitigating the limitations of single-agent sensing, such as occlusion. However, the precision of GPS signals can be influenced by a range of factors, including wireless transmission and obstructions like buildings. Given the pivotal role of GPS signals in perception fusion and the potential for various interference, it becomes imperative to investigate whether specific GPS signals can easily mislead the multi-agent perception system. To address this concern, we frame the task as an adversarial attack challenge and introduce \\textsc{AdvGPS}, a method capable of generating adversarial GPS signals which are also stealthy for individual agents within the system, significantly reducing object detection accuracy. To enhance the success rates of these attacks in a black-box scenario, we introduce three types of statistically sensitive natural discrepancies: appearance-based discrepancy, distribution-based discrepancy, and task-aware discrepancy. Our extensive experiments on the OPV2V dataset demonstrate that these attacks substantially undermine the performance of state-of-the-art methods, showcasing remarkable transferability across different point cloud based 3D detection systems. This alarming revelation underscores the pressing need to address security implications within multi-agent perception systems, thereby underscoring a critical area of research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by the 2024 IEEE International Conference on Robotics and Automation (ICRA)"
    },
    {
        "paper id": "2401.17511",
        "abstract url": "https://arxiv.org/abs/2401.17511",
        "title": "Linguistically Communicating Uncertainty in Patient-Facing Risk Prediction Models",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper addresses the unique challenges associated with uncertainty quantification in AI models when applied to patient-facing contexts within healthcare. Unlike traditional eXplainable Artificial Intelligence (XAI) methods tailored for model developers or domain experts, additional considerations of communicating in natural language, its presentation and evaluating understandability are necessary. We identify the challenges in communication model performance, confidence, reasoning and unknown knowns using natural language in the context of risk prediction. We propose a design aimed at addressing these challenges, focusing on the specific application of in-vitro fertilisation outcome prediction.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17515",
        "abstract url": "https://arxiv.org/abs/2401.17515",
        "title": "Towards Image Semantics and Syntax Sequence Learning",
        "rating": "-1",
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Convolutional neural networks and vision transformers have achieved outstanding performance in machine perception, particularly for image classification. Although these image classifiers excel at predicting image-level class labels, they may not discriminate missing or shifted parts within an object. As a result, they may fail to detect corrupted images that involve missing or disarrayed semantic information in the object composition. On the contrary, human perception easily distinguishes such corruptions. To mitigate this gap, we introduce the concept of \"image grammar\", consisting of \"image semantics\" and \"image syntax\", to denote the semantics of parts or patches of an image and the order in which these parts are arranged to create a meaningful object. To learn the image grammar relative to a class of visual objects/scenes, we propose a weakly supervised two-stage approach. In the first stage, we use a deep clustering framework that relies on iterative clustering and feature refinement to produce part-semantic segmentation. In the second stage, we incorporate a recurrent bi-LSTM module to process a sequence of semantic segmentation patches to capture the image syntax. Our framework is trained to reason over patch semantics and detect faulty syntax. We benchmark the performance of several grammar learning models in detecting patch corruptions. Finally, we verify the capabilities of our framework in Celeb and SUNRGBD datasets and demonstrate that it can achieve a grammar validation accuracy of 70 to 90% in a wide variety of semantic and syntactical corruption scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "21 pages, 22 figures, 5 tables"
    },
    {
        "paper id": "2401.17517",
        "abstract url": "https://arxiv.org/abs/2401.17517",
        "title": "Force Push: Robust Single-Point Pushing with Force Feedback",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "We present the first controller for quasistatic robotic planar pushing with single-point contact using only force feedback. We consider an omnidirectional mobile robot pushing an object (the \"slider\") along a given path, where the robot is equipped with a force-torque sensor to measure the force at the contact point with the slider. The geometric, inertial, and frictional parameters of the slider are not known to the controller, nor are measurements of the slider's pose. We assume that the robot can be localized so that the global position of the contact point is always known and that the approximate initial position of the slider is provided. Simulations and real-world experiments show that our controller yields stable pushes that are robust to a wide range of slider parameters and state perturbations along both straight and curved paths. Furthermore, we use an admittance controller to adjust the pushing velocity based on the measured force when the slider contacts obstacles like walls.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to IEEE Robotics and Automation Letters (RA-L). arXiv admin note: text overlap with arXiv:2305.11048"
    },
    {
        "paper id": "2401.17542",
        "abstract url": "https://arxiv.org/abs/2401.17542",
        "title": "A Medical Data-Effective Learning Benchmark for Highly Efficient Pre-training of Foundation Models",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Foundation models, pre-trained on massive datasets, have achieved unprecedented generalizability. However, is it truly necessary to involve such vast amounts of data in pre-training, consuming extensive computational resources? This paper introduces data-effective learning, aiming to use data in the most impactful way to pre-train foundation models. This involves strategies that focus on data quality rather than quantity, ensuring the data used for training has high informational value. Data-effective learning plays a profound role in accelerating foundation model training, reducing computational costs, and saving data storage, which is very important as the volume of medical data in recent years has grown beyond many people's expectations. However, due to the lack of standards and comprehensive benchmarks, research on medical data-effective learning is poorly studied. To address this gap, our paper introduces a comprehensive benchmark specifically for evaluating data-effective learning in the medical field. This benchmark includes a dataset with millions of data samples from 31 medical centers (DataDEL), a baseline method for comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively measure data-effective learning performance. Our extensive experimental results show the baseline MedDEL can achieve performance comparable to the original large dataset with only 5% of the data. Establishing such an open data-effective learning benchmark is crucial for the medical foundation model research community because it facilitates efficient data use, promotes collaborative breakthroughs, and fosters the development of cost-effective, scalable, and impactful healthcare solutions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17543",
        "abstract url": "https://arxiv.org/abs/2401.17543",
        "title": "Fr\u00e9chet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels",
        "rating": "-1",
        "keywords": [
            [
                "text-to-image"
            ]
        ],
        "abstract": "The rapid advancement of natural language processing, information retrieval (IR), computer vision, and other technologies has presented significant challenges in evaluating the performance of these systems. One of the main challenges is the scarcity of human-labeled data, which hinders the fair and accurate assessment of these systems. In this work, we specifically focus on evaluating IR systems with sparse labels, borrowing from recent research on evaluating computer vision tasks. taking inspiration from the success of using Fr\u00e9chet Inception Distance (FID) in assessing text-to-image generation systems. We propose leveraging the Fr\u00e9chet Distance to measure the distance between the distributions of relevant judged items and retrieved results. Our experimental results on MS MARCO V1 dataset and TREC Deep Learning Tracks query sets demonstrate the effectiveness of the Fr\u00e9chet Distance as a metric for evaluating IR systems, particularly in settings where a few labels are available. This approach contributes to the advancement of evaluation methodologies in real-world scenarios such as the assessment of generative IR systems.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17544",
        "abstract url": "https://arxiv.org/abs/2401.17544",
        "title": "Trainable Fixed-Point Quantization for Deep Learning Acceleration on FPGAs",
        "rating": "-1",
        "keywords": [
            [
                "FPGAs"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Quantization is a crucial technique for deploying deep learning models on resource-constrained devices, such as embedded FPGAs. Prior efforts mostly focus on quantizing matrix multiplications, leaving other layers like BatchNorm or shortcuts in floating-point form, even though fixed-point arithmetic is more efficient on FPGAs. A common practice is to fine-tune a pre-trained model to fixed-point for FPGA deployment, but potentially degrading accuracy. This work presents QFX, a novel trainable fixed-point quantization approach that automatically learns the binary-point position during model training. Additionally, we introduce a multiplier-free quantization strategy within QFX to minimize DSP usage. QFX is implemented as a PyTorch-based library that efficiently emulates fixed-point arithmetic, supported by FPGA HLS, in a differentiable manner during backpropagation. With minimal effort, models trained with QFX can readily be deployed through HLS, producing the same numerical results as their software counterparts. Our evaluation shows that compared to post-training quantization, QFX can quantize models trained with element-wise layers quantized to fewer bits and achieve higher accuracy on both CIFAR-10 and ImageNet datasets. We further demonstrate the efficacy of multiplier-free quantization using a state-of-the-art binarized neural network accelerator designed for an embedded FPGA (AMD Xilinx Ultra96 v2). We plan to release QFX in open-source format.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17548",
        "abstract url": "https://arxiv.org/abs/2401.17548",
        "title": "Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators",
        "rating": "-1",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Recently, channel-independent methods have achieved state-of-the-art performance in multivariate time series (MTS) forecasting. Despite reducing overfitting risks, these methods miss potential opportunities in utilizing channel dependence for accurate predictions. We argue that there exist locally stationary lead-lag relationships between variates, i.e., some lagged variates may follow the leading indicators within a short time period. Exploiting such channel dependence is beneficial since leading indicators offer advance information that can be used to reduce the forecasting difficulty of the lagged variates. In this paper, we propose a new method named LIFT that first efficiently estimates leading indicators and their leading steps at each time step and then judiciously allows the lagged variates to utilize the advance information from leading indicators. LIFT plays as a plugin that can be seamlessly collaborated with arbitrary time series forecasting methods. Extensive experiments on six real-world datasets demonstrate that LIFT improves the state-of-the-art methods by 5.5% in average forecasting performance. Our code is available at https://github.com/SJTU-Quant/LIFT.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to ICLR 2024. Code is at https://github.com/SJTU-Quant/LIFT"
    },
    {
        "paper id": "2401.17571",
        "abstract url": "https://arxiv.org/abs/2401.17571",
        "title": "Is Registering Raw Tagged-MR Enough for Strain Estimation in the Era of Deep Learning?",
        "rating": "-1",
        "keywords": [
            [
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Magnetic Resonance Imaging with tagging (tMRI) has long been utilized for quantifying tissue motion and strain during deformation. However, a phenomenon known as tag fading, a gradual decrease in tag visibility over time, often complicates post-processing. The first contribution of this study is to model tag fading by considering the interplay between $T_1$ relaxation and the repeated application of radio frequency (RF) pulses during serial imaging sequences. This is a factor that has been overlooked in prior research on tMRI post-processing. Further, we have observed an emerging trend of utilizing raw tagged MRI within a deep learning-based (DL) registration framework for motion estimation. In this work, we evaluate and analyze the impact of commonly used image similarity objectives in training DL registrations on raw tMRI. This is then compared with the Harmonic Phase-based approach, a traditional approach which is claimed to be robust to tag fading. Our findings, derived from both simulated images and an actual phantom scan, reveal the limitations of various similarity losses in raw tMRI and emphasize caution in registration tasks where image intensity changes over time.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted to SPIE Medical Imaging 2024 (oral)"
    },
    {
        "paper id": "2401.17575",
        "abstract url": "https://arxiv.org/abs/2401.17575",
        "title": "Can We Improve Channel Reciprocity via Loop-back Compensation for RIS-assisted Physical Layer Key Generation",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Reconfigurable intelligent surface (RIS) facilitates the extraction of unpredictable channel features for physical layer key generation (PKG), securing communications among legitimate users with symmetric keys. Previous works have demonstrated that channel reciprocity plays a crucial role in generating symmetric keys in PKG systems, whereas, in reality, reciprocity is greatly affected by hardware interference and RIS-based jamming attacks. This motivates us to propose LoCKey, a novel approach that aims to improve channel reciprocity by mitigating interferences and attacks with a loop-back compensation scheme, thus maximizing the secrecy performance of the PKG system. Specifically, our proposed LoCKey is capable of effectively compensating for the CSI non-reciprocity by the combination of transmit-back signal value and error minimization module. Firstly, we introduce the entire flowchart of our method and provide an in-depth discussion of each step. Following that, we delve into a theoretical analysis of the performance optimizations when our LoCKey is applied for CSI reciprocity enhancement. Finally, we conduct experiments to verify the effectiveness of the proposed LoCKey in improving channel reciprocity under various interferences for RIS-assisted wireless communications. The results demonstrate a significant improvement in both the rate of key generation assisted by the RIS and the consistency of the generated keys, showing great potential for the practical deployment of our LoCKey in future wireless systems.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Accepted by ICC 2024"
    },
    {
        "paper id": "2402.00072",
        "abstract url": "https://arxiv.org/abs/2402.00072",
        "title": "Explainable AI for survival analysis: a median-SHAP approach",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "survival",
                "clinical"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "With the adoption of machine learning into routine clinical practice comes the need for Explainable AI methods tailored to medical applications. Shapley values have sparked wide interest for locally explaining models. Here, we demonstrate their interpretation strongly depends on both the summary statistic and the estimator for it, which in turn define what we identify as an 'anchor point'. We show that the convention of using a mean anchor point may generate misleading interpretations for survival analysis and introduce median-SHAP, a method for explaining black-box models predicting individual survival times.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": "Accepted to the Interpretable Machine Learning for Healthcare (IMLH) workshop of the ICML 2022 Conference"
    },
    {
        "paper id": "2402.00893",
        "abstract url": "https://arxiv.org/abs/2402.00893",
        "title": "MoDE: A Mixture-of-Experts Model with Mutual Distillation among the Experts",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "The application of mixture-of-experts (MoE) is gaining popularity due to its ability to improve model's performance. In an MoE structure, the gate layer plays a significant role in distinguishing and routing input features to different experts. This enables each expert to specialize in processing their corresponding sub-tasks. However, the gate's routing mechanism also gives rise to narrow vision: the individual MoE's expert fails to use more samples in learning the allocated sub-task, which in turn limits the MoE to further improve its generalization ability. To effectively address this, we propose a method called Mixture-of-Distilled-Expert (MoDE), which applies moderate mutual distillation among experts to enable each expert to pick up more features learned by other experts and gain more accurate perceptions on their original allocated sub-tasks. We conduct plenty experiments including tabular, NLP and CV datasets, which shows MoDE's effectiveness, universality and robustness. Furthermore, we develop a parallel study through innovatively constructing \"expert probing\", to experimentally prove why MoDE works: moderate distilling knowledge can improve each individual expert's test performances on their assigned tasks, leading to MoE's overall performance improvement.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted by AAAI-24"
    },
    {
        "paper id": "2402.01751",
        "abstract url": "https://arxiv.org/abs/2402.01751",
        "title": "Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) find increasing applications in many fields. Here, three LLM chatbots (ChatGPT-3.5, ChatGPT-4 and Bard) are assessed - in their current form, as publicly available - for their ability to recognize Alzheimer's Dementia (AD) and Cognitively Normal (CN) individuals using textual input derived from spontaneous speech recordings. Zero-shot learning approach is used at two levels of independent queries, with the second query (chain-of-thought prompting) eliciting more detailed than the first. Each LLM chatbot's performance is evaluated on the prediction generated in terms of accuracy, sensitivity, specificity, precision and F1 score. LLM chatbots generated three-class outcome (\"AD\", \"CN\", or \"Unsure\"). When positively identifying AD, Bard produced highest true-positives (89% recall) and highest F1 score (71%), but tended to misidentify CN as AD, with high confidence (low \"Unsure\" rates); for positively identifying CN, GPT-4 resulted in the highest true-negatives at 56% and highest F1 score (62%), adopting a diplomatic stance (moderate \"Unsure\" rates). Overall, three LLM chatbots identify AD vs CN surpassing chance-levels but do not currently satisfy clinical application.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2402.01759",
        "abstract url": "https://arxiv.org/abs/2402.01759",
        "title": "Systematic Literature Review: Computational Approaches for Humour Style Classification",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Understanding various humour styles is essential for comprehending the multifaceted nature of humour and its impact on fields such as psychology and artificial intelligence. This understanding has revealed that humour, depending on the style employed, can either have therapeutic or detrimental effects on an individual's health and relationships. Although studies dedicated exclusively to computational-based humour style analysis remain somewhat rare, an expansive body of research thrives within related task, particularly binary humour and sarcasm recognition. In this systematic literature review (SLR), we survey the landscape of computational techniques applied to these related tasks and also uncover their fundamental relevance to humour style analysis. Through this study, we unveil common approaches, illuminate various datasets and evaluation metrics, and effectively navigate the complex terrain of humour research. Our efforts determine potential research gaps and outlined promising directions. Furthermore, the SLR identifies a range of features and computational models that can seamlessly transition from related tasks like binary humour and sarcasm detection to invigorate humour style classification. These features encompass incongruity, sentiment and polarity analysis, ambiguity detection, acoustic nuances, visual cues, contextual insights, and more. The computational models that emerge contain traditional machine learning paradigms, neural network architectures, transformer-based models, and specialised models attuned to the nuances of humour. Finally, the SLR provides access to existing datasets related to humour and sarcasm, facilitating the work of future researchers.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03362",
        "abstract url": "https://arxiv.org/abs/2402.03362",
        "title": "NanoNER: Named Entity Recognition for nanobiology using experts' knowledge and distant supervision",
        "rating": "-1",
        "keywords": [
            [
                "Named Entity Recognition"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Here we present the training and evaluation of NanoNER, a Named Entity Recognition (NER) model for Nanobiology. NER consists in the identification of specific entities in spans of unstructured texts and is often a primary task in Natural Language Processing (NLP) and Information Extraction. The aim of our model is to recognise entities previously identified by domain experts as constituting the essential knowledge of the domain. Relying on ontologies, which provide us with a domain vocabulary and taxonomy, we implemented an iterative process enabling experts to determine the entities relevant to the domain at hand. We then delve into the potential of distant supervision learning in NER, supporting how this method can increase the quantity of annotated data with minimal additional manpower. On our full corpus of 728 full-text nanobiology articles, containing more than 120k entity occurrences, NanoNER obtained a F1-score of 0.98 on the recognition of previously known entities. Our model also demonstrated its ability to discover new entities in the text, with precision scores ranging from 0.77 to 0.81. Ablation experiments further confirmed this and allowed us to assess the dependency of our approach on the external resources. It highlighted the dependency of the approach to the resource, while also confirming its ability to rediscover up to 30% of the ablated terms. This paper details the methodology employed, experimental design, and key findings, providing valuable insights and directions for future related researches on NER in specialized domain. Furthermore, since our approach require minimal manpower , we believe that it can be generalized to other specialized fields.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08789",
        "abstract url": "https://arxiv.org/abs/2403.08789",
        "title": "Bridging Human Concepts and Computer Vision for Explainable Face Verification",
        "rating": "-1",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With Artificial Intelligence (AI) influencing the decision-making process of sensitive applications such as Face Verification, it is fundamental to ensure the transparency, fairness, and accountability of decisions. Although Explainable Artificial Intelligence (XAI) techniques exist to clarify AI decisions, it is equally important to provide interpretability of these decisions to humans. In this paper, we present an approach to combine computer and human vision to increase the explanation's interpretability of a face verification algorithm. In particular, we are inspired by the human perceptual process to understand how machines perceive face's human-semantic areas during face comparison tasks. We use Mediapipe, which provides a segmentation technique that identifies distinct human-semantic facial regions, enabling the machine's perception analysis. Additionally, we adapted two model-agnostic algorithms to provide human-interpretable insights into the decision-making processes.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16754",
        "abstract url": "https://arxiv.org/abs/2401.16754",
        "title": "AI Oversight and Human Mistakes: Evidence from Centre Court",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Powered by the increasing predictive capabilities of machine learning algorithms, artificial intelligence (AI) systems have begun to be used to overrule human mistakes in many settings. We provide the first field evidence this AI oversight carries psychological costs that can impact human decision-making. We investigate one of the highest visibility settings in which AI oversight has occurred: the Hawk-Eye review of umpires in top tennis tournaments. We find that umpires lowered their overall mistake rate after the introduction of Hawk-Eye review, in line with rational inattention given psychological costs of being overruled by AI. We also find that umpires increased the rate at which they called balls in, which produced a shift from making Type II errors (calling a ball out when in) to Type I errors (calling a ball in when out). We structurally estimate the psychological costs of being overruled by AI using a model of rational inattentive umpires, and our results suggest that because of these costs, umpires cared twice as much about Type II errors under AI oversight.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "econ.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16777",
        "abstract url": "https://arxiv.org/abs/2401.16777",
        "title": "Addressing Distribution Shift in Time Series Forecasting with Instance Normalization Flows",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Due to non-stationarity of time series, the distribution shift problem largely hinders the performance of time series forecasting. Existing solutions either fail for the shifts beyond simple statistics or the limited compatibility with forecasting models. In this paper, we propose a general decoupled formulation for time series forecasting, with no reliance on fixed statistics and no restriction on forecasting architectures. Then, we make such a formulation formalized into a bi-level optimization problem, to enable the joint learning of the transformation (outer loop) and forecasting (inner loop). Moreover, the special requirements of expressiveness and bi-direction for the transformation motivate us to propose instance normalization flows (IN-Flow), a novel invertible network for time series transformation. Extensive experiments demonstrate our method consistently outperforms state-of-the-art baselines on both synthetic and real-world data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2401.16796",
        "abstract url": "https://arxiv.org/abs/2401.16796",
        "title": "Learnable Prompt as Pseudo-Imputation: Reassessing the Necessity of Traditional EHR Data Imputation in Downstream Clinical Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "health",
                "Clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Analyzing the health status of patients based on Electronic Health Records (EHR) is a fundamental research problem in medical informatics. The presence of extensive missing values in EHR makes it challenging for deep neural networks to directly model the patient's health status based on EHR. Existing deep learning training protocols require the use of statistical information or imputation models to reconstruct missing values; however, the protocols inject non-realistic data into downstream EHR analysis models, significantly limiting model performance. This paper introduces Learnable Prompt as Pseudo Imputation (PAI) as a new training protocol. PAI no longer introduces any imputed data but constructs a learnable prompt to model the implicit preferences of the downstream model for missing values, resulting in a significant performance improvement for all EHR analysis models. Additionally, our experiments show that PAI exhibits higher robustness in situations of data insufficiency and high missing rates. More importantly, in a real-world application involving cross-institutional data with zero-shot evaluation, PAI demonstrates stronger model generalization capabilities for non-overlapping features.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16808",
        "abstract url": "https://arxiv.org/abs/2401.16808",
        "title": "Encoding Temporal Statistical-space Priors via Augmented Representation",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Modeling time series data remains a pervasive issue as the temporal dimension is inherent to numerous domains. Despite significant strides in time series forecasting, high noise-to-signal ratio, non-normality, non-stationarity, and lack of data continue challenging practitioners. In response, we leverage a simple representation augmentation technique to overcome these challenges. Our augmented representation acts as a statistical-space prior encoded at each time step. In response, we name our method Statistical-space Augmented Representation (SSAR). The underlying high-dimensional data-generating process inspires our representation augmentation. We rigorously examine the empirical generalization performance on two data sets with two downstream temporal learning algorithms. Our approach significantly beats all five up-to-date baselines. Moreover, the highly modular nature of our approach can easily be applied to various settings. Lastly, fully-fledged theoretical perspectives are available throughout the writing for a clear and rigorous understanding.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "pre-print"
    },
    {
        "paper id": "2401.16836",
        "abstract url": "https://arxiv.org/abs/2401.16836",
        "title": "Coseparable Nonnegative Tensor Factorization With T-CUR Decomposition",
        "rating": "-1.5",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Nonnegative Matrix Factorization (NMF) is an important unsupervised learning method to extract meaningful features from data. To address the NMF problem within a polynomial time framework, researchers have introduced a separability assumption, which has recently evolved into the concept of coseparability. This advancement offers a more efficient core representation for the original data. However, in the real world, the data is more natural to be represented as a multi-dimensional array, such as images or videos. The NMF's application to high-dimensional data involves vectorization, which risks losing essential multi-dimensional correlations. To retain these inherent correlations in the data, we turn to tensors (multidimensional arrays) and leverage the tensor t-product. This approach extends the coseparable NMF to the tensor setting, creating what we term coseparable Nonnegative Tensor Factorization (NTF). In this work, we provide an alternating index selection method to select the coseparable core. Furthermore, we validate the t-CUR sampling theory and integrate it with the tensor Discrete Empirical Interpolation Method (t-DEIM) to introduce an alternative, randomized index selection process. These methods have been tested on both synthetic and facial analysis datasets. The results demonstrate the efficiency of coseparable NTF when compared to coseparable NMF.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16985",
        "abstract url": "https://arxiv.org/abs/2401.16985",
        "title": "Multiple Yield Curve Modeling and Forecasting using Deep Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This manuscript introduces deep learning models that simultaneously describe the dynamics of several yield curves. We aim to learn the dependence structure among the different yield curves induced by the globalization of financial markets and exploit it to produce more accurate forecasts. By combining the self-attention mechanism and nonparametric quantile regression, our model generates both point and interval forecasts of future yields. The architecture is designed to avoid quantile crossing issues affecting multiple quantile regression models. Numerical experiments conducted on two different datasets confirm the effectiveness of our approach. Finally, we explore potential extensions and enhancements by incorporating deep ensemble methods and transfer learning mechanisms.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17042",
        "abstract url": "https://arxiv.org/abs/2401.17042",
        "title": "Forecasting VIX using Bayesian Deep Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, deep learning techniques are gradually replacing traditional statistical and machine learning models as the first choice for price forecasting tasks. In this paper, we leverage probabilistic deep learning for inferring the volatility index VIX. We employ the probabilistic counterpart of WaveNet, Temporal Convolutional Network (TCN), and Transformers. We show that TCN outperforms all models with an RMSE around 0.189. In addition, it has been well known that modern neural networks provide inaccurate uncertainty estimates. For solving this problem, we use the standard deviation scaling to calibrate the networks. Furthermore, we found out that MNF with Gaussian prior outperforms Reparameterization Trick and Flipout models in terms of precision and uncertainty predictions. Finally, we claim that MNF with Cauchy and LogUniform prior distributions yield well calibrated TCN and WaveNet networks being the former that best infer the VIX values.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17077",
        "abstract url": "https://arxiv.org/abs/2401.17077",
        "title": "Dynamical Survival Analysis with Controlled Latent States",
        "rating": "-1.5",
        "keywords": [
            [
                "Survival"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the task of learning individual-specific intensities of counting processes from a set of static variables and irregularly sampled time series. We introduce a novel modelization approach in which the intensity is the solution to a controlled differential equation. We first design a neural estimator by building on neural controlled differential equations. In a second time, we show that our model can be linearized in the signature space under sufficient regularity conditions, yielding a signature-based estimator which we call CoxSig. We provide theoretical learning guarantees for both estimators, before showcasing the performance of our models on a vast array of simulated and real-world datasets from finance, predictive maintenance and food supply chain management.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "41 pages, 27 figures"
    },
    {
        "paper id": "2401.17174",
        "abstract url": "https://arxiv.org/abs/2401.17174",
        "title": "A large dataset curation and benchmark for drug target interaction",
        "rating": "-1.5",
        "keywords": [
            [
                "Bioactivity"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bioactivity data plays a key role in drug discovery and repurposing. The resource-demanding nature of \\textit{in vitro} and \\textit{in vivo} experiments, as well as the recent advances in data-driven computational biochemistry research, highlight the importance of \\textit{in silico} drug target interaction (DTI) prediction approaches. While numerous large public bioactivity data sources exist, research in the field could benefit from better standardization of existing data resources. At present, different research works that share similar goals are often difficult to compare properly because of different choices of data sources and train/validation/test split strategies. Additionally, many works are based on small data subsets, leading to results and insights of possible limited validity. In this paper we propose a way to standardize and represent efficiently a very large dataset curated from multiple public sources, split the data into train, validation and test sets based on different meaningful strategies, and provide a concrete evaluation protocol to accomplish a benchmark. We analyze the proposed data curation, prove its usefulness and validate the proposed benchmark through experimental studies based on an existing neural network model.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17188",
        "abstract url": "https://arxiv.org/abs/2401.17188",
        "title": "Nested Construction of Polar Codes via Transformers",
        "rating": "-1.5",
        "keywords": [
            [
                "5G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Tailoring polar code construction for decoding algorithms beyond successive cancellation has remained a topic of significant interest in the field. However, despite the inherent nested structure of polar codes, the use of sequence models in polar code construction is understudied. In this work, we propose using a sequence modeling framework to iteratively construct a polar code for any given length and rate under various channel conditions. Simulations show that polar codes designed via sequential modeling using transformers outperform both 5G-NR sequence and Density Evolution based approaches for both AWGN and Rayleigh fading channels.",
        "subjects": [
            "cs.IT",
            "cs.AI"
        ],
        "comment": "7 pages; 8 figures"
    },
    {
        "paper id": "2401.17205",
        "abstract url": "https://arxiv.org/abs/2401.17205",
        "title": "Adaptive Experiment Design with Synthetic Controls",
        "rating": "-1.5",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations - especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through experiments.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "Proceedings of the 27th International Conference on Artificial Intelligence and Statistics"
    },
    {
        "paper id": "2401.17267",
        "abstract url": "https://arxiv.org/abs/2401.17267",
        "title": "ReacLLaMA: Merging chemical and textual information in chemical reactivity AI models",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Chemical reactivity models are developed to predict chemical reaction outcomes in the form of classification (success/failure) or regression (product yield) tasks. The vast majority of the reported models are trained solely on chemical information such as reactants, products, reagents, and solvents, but not on the details of a synthetic protocol. Herein incorporation of procedural text with the aim to augment the Graphormer reactivity model and improve its accuracy is presented. Two major approaches are used: training an adapter Graphormer model that is provided with a GPT-2-derived latent representation of the text procedure (ReacLLaMA-Adapter) and labeling an unlabeled part of a dataset with the LLaMA 2 model followed by training the Graphormer on an extended dataset (Zero-Shot Labeling ReacLLaMA). Both methodologies enhance the discernment of unpromising reactions, thereby providing more accurate models with improved specificity.",
        "subjects": [
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17269",
        "abstract url": "https://arxiv.org/abs/2401.17269",
        "title": "Effect of Weight Quantization on Learning Models by Typical Case Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper examines the quantization methods used in large-scale data analysis models and their hyperparameter choices. The recent surge in data analysis scale has significantly increased computational resource requirements. To address this, quantizing model weights has become a prevalent practice in data analysis applications such as deep learning. Quantization is particularly vital for deploying large models on devices with limited computational resources. However, the selection of quantization hyperparameters, like the number of bits and value range for weight quantization, remains an underexplored area. In this study, we employ the typical case analysis from statistical physics, specifically the replica method, to explore the impact of hyperparameters on the quantization of simple learning models. Our analysis yields three key findings: (i) an unstable hyperparameter phase, known as replica symmetry breaking, occurs with a small number of bits and a large quantization width; (ii) there is an optimal quantization width that minimizes error; and (iii) quantization delays the onset of overparameterization, helping to mitigate overfitting as indicated by the double descent phenomenon. We also discover that non-uniform quantization can enhance stability. Additionally, we develop an approximate message-passing algorithm to validate our theoretical results.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17500",
        "abstract url": "https://arxiv.org/abs/2401.17500",
        "title": "LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization",
        "rating": "-1.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces LeTO, a method for learning constrained visuomotor policy via differentiable trajectory optimization. Our approach uniquely integrates a differentiable optimization layer into the neural network. By formulating the optimization layer as a trajectory optimization problem, we enable the model to end-to-end generate actions in a safe and controlled fashion without extra modules. Our method allows for the introduction of constraints information during the training process, thereby balancing the training objectives of satisfying constraints, smoothing the trajectories, and minimizing errors with demonstrations. This \"gray box\" method marries the optimization-based safety and interpretability with the powerful representational abilities of neural networks. We quantitatively evaluate LeTO in simulation and on the real robot. In simulation, LeTO achieves a success rate comparable to state-of-the-art imitation learning methods, but the generated trajectories are of less uncertainty, higher quality, and smoother. In real-world experiments, we deployed LeTO to handle constraints-critical tasks. The results show the effectiveness of LeTO comparing with state-of-the-art imitation learning approaches. We release our code at https://github.com/ZhengtongXu/LeTO.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2402.00071",
        "abstract url": "https://arxiv.org/abs/2402.00071",
        "title": "Unraveling the Impact of Initial Choices and In-Loop Interventions on Learning Dynamics in Autonomous Scanning Probe Microscopy",
        "rating": "-1.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Kernel Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The current focus in Autonomous Experimentation (AE) is on developing robust workflows to conduct the AE effectively. This entails the need for well-defined approaches to guide the AE process, including strategies for hyperparameter tuning and high-level human interventions within the workflow loop. This paper presents a comprehensive analysis of the influence of initial experimental conditions and in-loop interventions on the learning dynamics of Deep Kernel Learning (DKL) within the realm of AE in Scanning Probe Microscopy. We explore the concept of 'seed effect', where the initial experiment setup has a substantial impact on the subsequent learning trajectory. Additionally, we introduce an approach of the seed point interventions in AE allowing the operator to influence the exploration process. Using a dataset from Piezoresponse Force Microscopy (PFM) on PbTiO3 thin films, we illustrate the impact of the 'seed effect' and in-loop seed interventions on the effectiveness of DKL in predicting material properties. The study highlights the importance of initial choices and adaptive interventions in optimizing learning rates and enhancing the efficiency of automated material characterization. This work offers valuable insights into designing more robust and effective AE workflows in microscopy with potential applications across various characterization techniques. The analysis code that supports the funding is publicly available at https://github.com/Slautin/2024_Seed_effect_DKL_BO.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "comment": "24 pages, 11 figures"
    },
    {
        "paper id": "2402.00077",
        "abstract url": "https://arxiv.org/abs/2402.00077",
        "title": "Unlocking the Power of Multi-institutional Data: Integrating and Harmonizing Genomic Data Across Institutions",
        "rating": "-1.5",
        "keywords": [
            [
                "survival",
                "Cancer",
                "disease",
                "clinical",
                "tumor"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cancer is a complex disease driven by genomic alterations, and tumor sequencing is becoming a mainstay of clinical care for cancer patients. The emergence of multi-institution sequencing data presents a powerful resource for learning real-world evidence to enhance precision oncology. GENIE BPC, led by the American Association for Cancer Research, establishes a unique database linking genomic data with clinical information for patients treated at multiple cancer centers. However, leveraging such multi-institutional sequencing data presents significant challenges. Variations in gene panels result in loss of information when the analysis is conducted on common gene sets. Additionally, differences in sequencing techniques and patient heterogeneity across institutions add complexity. High data dimensionality, sparse gene mutation patterns, and weak signals at the individual gene level further complicate matters. Motivated by these real-world challenges, we introduce the Bridge model. It uses a quantile-matched latent variable approach to derive integrated features to preserve information beyond common genes and maximize the utilization of all available data while leveraging information sharing to enhance both learning efficiency and the model's capacity to generalize. By extracting harmonized and noise-reduced lower-dimensional latent variables, the true mutation pattern unique to each individual is captured. We assess the model's performance and parameter estimation through extensive simulation studies. The extracted latent features from the Bridge model consistently excel in predicting patient survival across six cancer types in GENIE BPC data.",
        "subjects": [
            "q-bio.GN",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01762",
        "abstract url": "https://arxiv.org/abs/2402.01762",
        "title": "Commercial AI, Conflict, and Moral Responsibility: A theoretical analysis and practical approach to the moral responsibilities associated with dual-use AI technology",
        "rating": "-1.5",
        "keywords": [
            [
                "watermarking"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "This paper presents a theoretical analysis and practical approach to the moral responsibilities when developing AI systems for non-military applications that may nonetheless be used for conflict applications. We argue that AI represents a form of crossover technology that is different from previous historical examples of dual- or multi-use technology as it has a multiplicative effect across other technologies. As a result, existing analyses of ethical responsibilities around dual-use technologies do not necessarily work for AI systems. We instead argue that stakeholders involved in the AI system lifecycle are morally responsible for uses of their systems that are reasonably foreseeable. The core idea is that an agent's moral responsibility for some action is not necessarily determined by their intentions alone; we must also consider what the agent could reasonably have foreseen to be potential outcomes of their action, such as the potential use of a system in conflict even when it is not designed for that. In particular, we contend that it is reasonably foreseeable that: (1) civilian AI systems will be applied to active conflict, including conflict support activities, (2) the use of civilian AI systems in conflict will impact applications of the law of armed conflict, and (3) crossover AI technology will be applied to conflicts that fall short of armed conflict. Given these reasonably foreseeably outcomes, we present three technically feasible actions that developers of civilian AIs can take to potentially mitigate their moral responsibility: (a) establishing systematic approaches to multi-perspective capability testing, (b) integrating digital watermarking in model weight matrices, and (c) utilizing monitoring and reporting mechanisms for conflict-related AI applications.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2402.09443",
        "abstract url": "https://arxiv.org/abs/2402.09443",
        "title": "Review of algorithms for predicting fatigue using EEG",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "EEG",
                "physiological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Fatigue detection is of paramount importance in enhancing safety, productivity, and well-being across diverse domains, including transportation, healthcare, and industry. This scientific paper presents a comprehensive investigation into the application of machine learning algorithms for the detection of physiological fatigue using Electroencephalogram (EEG) signals. The primary objective of this study was to assess the efficacy of various algorithms in predicting an individual's level of fatigue based on EEG data.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2401.15766"
    },
    {
        "paper id": "2402.10926",
        "abstract url": "https://arxiv.org/abs/2402.10926",
        "title": "Numerical analysis of physics-informed neural networks and related models in physics-informed machine learning",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-informed neural networks (PINNs) and their variants have been very popular in recent years as algorithms for the numerical simulation of both forward and inverse problems for partial differential equations. This article aims to provide a comprehensive review of currently available results on the numerical analysis of PINNs and related models that constitute the backbone of physics-informed machine learning. We provide a unified framework in which analysis of the various components of the error incurred by PINNs in approximating PDEs can be effectively carried out. A detailed review of available results on approximation, generalization and training errors and their behavior with respect to the type of the PDE and the dimension of the underlying domain is presented. In particular, the role of the regularity of the solutions and their stability to perturbations in the error analysis is elucidated. Numerical results are also presented to illustrate the theory. We identify training errors as a key bottleneck which can adversely affect the overall performance of various models in physics-informed machine learning.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16779",
        "abstract url": "https://arxiv.org/abs/2401.16779",
        "title": "All-optical complex field imaging using diffractive processors",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "biomedical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Complex field imaging, which captures both the amplitude and phase information of input optical fields or objects, can offer rich structural insights into samples, such as their absorption and refractive index distributions. However, conventional image sensors are intensity-based and inherently lack the capability to directly measure the phase distribution of a field. This limitation can be overcome using interferometric or holographic methods, often supplemented by iterative phase retrieval algorithms, leading to a considerable increase in hardware complexity and computational demand. Here, we present a complex field imager design that enables snapshot imaging of both the amplitude and quantitative phase information of input fields using an intensity-based sensor array without any digital processing. Our design utilizes successive deep learning-optimized diffractive surfaces that are structured to collectively modulate the input complex field, forming two independent imaging channels that perform amplitude-to-amplitude and phase-to-intensity transformations between the input and output planes within a compact optical design, axially spanning ~100 wavelengths. The intensity distributions of the output fields at these two channels on the sensor plane directly correspond to the amplitude and quantitative phase profiles of the input complex field, eliminating the need for any digital image reconstruction algorithms. We experimentally validated the efficacy of our complex field diffractive imager designs through 3D-printed prototypes operating at the terahertz spectrum, with the output amplitude and phase channel images closely aligning with our numerical simulations. We envision that this complex field imager will have various applications in security, biomedical imaging, sensing and material science, among others.",
        "subjects": [
            "physics.optics",
            "cs.CV",
            "physics.app-ph"
        ],
        "comment": "25 Pages, 6 Figures"
    },
    {
        "paper id": "2401.16823",
        "abstract url": "https://arxiv.org/abs/2401.16823",
        "title": "Application of Methods of Artificial Intelligence in Systems for Continuous Automatic Monitoring of Dust Concentration and Deposits in Mine Atmosphere",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "With the growth of coal production, the load on the production capacity of coal enterprises also increases, which leads to a concomitant increase in dust formation in both opencast and underground methods of mining coal deposits. Dust, generated during drilling, blasting operations, excavation, loading, crushing and transportation of mined rock is one of the factors that has a negative impact on the health of mining workers and on the level of environmental pollution with solid particles. Thus, increasing the efficiency of controlling the concentration of solid particles in the mine atmosphere and dust deposits is an urgent scientific and technical task. In doing so, the use of modern digital technologies within the framework of the industry 4.0 concept makes it possible to develop approaches that can significantly improve the quality of monitoring the state of the mine atmosphere at coal mining enterprises. This article provides a theoretical basis and test results for a system for continuous automatic monitoring of dust concentration in a mine atmosphere as the component of the multifunctional coal mine safety system. It is shown that monitoring the state of mine workings aerological safety can be carried out in real time through the system of the new generation using artificial intelligence. The ability of the proposed system to measure basic physical parameters affecting dust deposition (disperse composition, air humidity, dust concentration and air flow velocity) is noted.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, in Russian language"
    },
    {
        "paper id": "2401.16875",
        "abstract url": "https://arxiv.org/abs/2401.16875",
        "title": "Quantum Circuit Mapping for Universal and Scalable Computing in MZI-based Integrated Photonics",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Linear optical quantum computing (LOQC) offers a quantum computation paradigm based on well-established and robust technology and flexible environmental conditions following DiVincenzo's criteria. Within this framework, integrated photonics can be utilized to achieve gate-based quantum computing, defining qubits by path-encoding, quantum gates through the use of Mach-Zehnder interferometers (MZIs) as fundamental building blocks, and measurements through single-photon detectors. In particular, universal two-qubit gates can be achieved by suitable structures of MZIs together with post-selection or heralding. The most resource-efficient choice is given by the post-selected CZ gate. However, this implementation is characterized by a design which has a non-regular structure and cannot be cascaded. This limits the implementation of large-scale LOQC. Starting from these issues, we suggest an approach to move toward a universal and scalable LOQC on the integrated photonic platform. First of all, choosing the post-selected CZ as universal two-qubit gate, we extend the path-encoded dual-rail qubit to a triplet of waveguides, composed of an auxiliary waveguide and the pair of waveguides corresponding to the qubit basis states. Additionally, we introduce a swap photonic network that maps the regularly-labeled structure of the new path-encoded qubits to the structure needed for the post-selected CZ. We also discuss the optical swap gate that allows the connection of non-nearest neighbor path-encoded qubits. In this way, we can deterministically exchange the locations of the qubits and execute controlled quantum gates between any path-encoded qubits. Next, by truncating the auxiliary waveguides after any post-selected CZ, we find that it is possible to cascade this optical gate when it acts on different pairs that share only one qubit.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16901",
        "abstract url": "https://arxiv.org/abs/2401.16901",
        "title": "Deep Contextual Bandit and Reinforcement Learning for IRS-Assisted MU-MIMO Systems",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "The combination of multiple-input multiple-output (MIMO) systems and intelligent reflecting surfaces (IRSs) is foreseen as a critical enabler of beyond 5G (B5G) and 6G. In this work, two different approaches are considered for the joint optimization of the IRS phase-shift matrix and MIMO precoders of an IRS-assisted multi-stream (MS) multi-user MIMO (MU-MIMO) system. Both approaches aim to maximize the system sum-rate for every channel realization. The first proposed solution is a novel contextual bandit (CB) framework with continuous state and action spaces called deep contextual bandit-oriented deep deterministic policy gradient (DCB-DDPG). The second is an innovative deep reinforcement learning (DRL) formulation where the states, actions, and rewards are selected such that the Markov decision process (MDP) property of reinforcement learning (RL) is appropriately met. Both proposals perform remarkably better than state-of-the-art heuristic methods in scenarios with high multi-user interference.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16906",
        "abstract url": "https://arxiv.org/abs/2401.16906",
        "title": "Quantum-Secure Hybrid Blockchain System for DID-based Verifiable Random Function with NTRU Linkable Ring Signature",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "In this study, we present a secure smart contract-based Verifiable Random Function (VRF) model, addressing the shortcomings of existing systems. As quantum computing emerges, conventional public key cryptography faces potential vulnerabilities. To enhance our VRF's robustness, we employ post-quantum Ring-LWE encryption for generating pseudo-random sequences. Given the computational intensity of this approach and associated on-chain gas costs, we propose a hybrid architecture of VRF system where on-chain and off-chain can communicate in a scalable and secure way. To ensure the validity and integrity of the off-chain computations (e.g., Ring-LWE encryption), we employ a quantum-secure linkable ring signature scheme on NTRU lattice and also delegated key generation (DKG) with a secure key encapsulation mechanism (KEM). Our decentralized VRF employs multi-party computation (MPC) with blockchain-based decentralized identifiers (DID), ensuring the collective efforts of enhanced randomness and security. We show the security and privacy advantages of our proposed VRF model with the approximated estimation of overall temporal and spatial complexities. We also evaluate our VRF MPC model's entropy and outline its Solidity smart contract integration. This research also provides a method to produce and verify the VRF output's proof, optimal for scenarios necessitating randomness and validation. Lastly, using NIST SP800-22 test suite for randomness, we demonstrate the commendable result with a 97.73% overall pass rate on 11 standard tests and 0.5459 of average p-value for the total 176 tests.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": "25 pages, 5 figures, 2023 International Journal on Cryptography and Information Security (IJCIS). arXiv admin note: text overlap with arXiv:2311.11734"
    },
    {
        "paper id": "2401.16919",
        "abstract url": "https://arxiv.org/abs/2401.16919",
        "title": "Bit-flipping Decoder Failure Rate Estimation for (v,w)-regular Codes",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Providing closed form estimates of the decoding failure rate of iterative decoder for low- and moderate-density parity check codes has attracted significant interest in the research community over the years. This interest has raised recently due to the use of iterative decoders in post-quantum cryptosystems, where the desired decoding failure rates are impossible to estimate via Monte Carlo simulations. In this work, we propose a new technique to provide accurate estimates of the DFR of a two-iterations (parallel) bit flipping decoder, which is also employable for cryptographic purposes. In doing so, we successfully tackle the estimation of the bit flipping probabilities at the second decoder iteration, and provide a fitting estimate for the syndrome weight distribution at the first iteration. We numerically validate our results, providing comparisons of the modeled and simulated weight of the syndrome, incorrectly-guessed error bit distribution at the end of the first iteration, and two-iteration Decoding Failure Rates (DFR), both in the floor and waterfall regime for simulatable codes. Finally, we apply our method to estimate the DFR of LEDAcrypt parameters, showing improvements by factors larger than $2^{70}$ (for NIST category $1$) with respect to the previous estimation techniques. This allows for a $\\approx 20$% shortening in public key and ciphertext sizes, at no security loss, making the smallest ciphertext for NIST category $1$ only $6$% larger than the one of BIKE. We note that the analyzed two-iterations decoder is applicable in BIKE, where swapping it with the current black-gray decoder (and adjusting the parameters) would provide strong IND-CCA$2$ guarantees.",
        "subjects": [
            "cs.CR",
            "cs.IT"
        ],
        "comment": "Fixed typos: derivation of a from a=(x-y+v)/2 to a=(y-x+v)/2; replaced (x-y+v)/2 with (y-x+v)/2 and (x-y+v-1)/2 with (y-x+v-1)/2 in rho(x,y,l); replaced d+ with d- in the def. of delta-(d-); replaced epsilon01-l with l in zeta(tc,l,epsilon01) and epsilon11-l with l in lambda(tc,l,epsilon11) (apart from the def.s); explicited epsilon01 and epsilon11 in zeta and chi_odd"
    },
    {
        "paper id": "2401.16922",
        "abstract url": "https://arxiv.org/abs/2401.16922",
        "title": "Learning Properties of Quantum States Without the I.I.D. Assumption",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We develop a framework for learning properties of quantum states beyond the assumption of independent and identically distributed (i.i.d.) input states. We prove that, given any learning problem (under reasonable assumptions), an algorithm designed for i.i.d. input states can be adapted to handle input states of any nature, albeit at the expense of a polynomial increase in copy complexity. Furthermore, we establish that algorithms which perform non-adaptive incoherent measurements can be extended to encompass non-i.i.d. input states while maintaining comparable error probabilities. This allows us, among others applications, to generalize the classical shadows of Huang, Kueng, and Preskill to the non-i.i.d. setting at the cost of a small loss in efficiency. Additionally, we can efficiently verify any pure state using Clifford measurements, in a way that is independent of the ideal state. Our main techniques are based on de Finetti-style theorems supported by tools from information theory. In particular, we prove a new randomized local de Finetti theorem that can be of independent interest.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "math.PR",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16993",
        "abstract url": "https://arxiv.org/abs/2401.16993",
        "title": "Randomized Key Encapsulation/Consolidation",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "This article bridges the gap between two topics used in sharing an encryption key: (i) Key Consolidation, i.e., extracting two identical strings of bits from two information sources with similarities (common randomness). (ii) Quantum-safe Key Encapsulation by incorporating randomness in Public/Private Key pairs. In the context of Key Consolidation, the proposed scheme adds to the complexity Eve faces in extracting useful data from leaked information. In this context, it is applied to the method proposed in [1] for establishing common randomness from round-trip travel times in a packet data network. The proposed method allows adapting the secrecy level to the amount of similarity in common randomness. It can even encapsulate a Quantum-safe encryption key in the extreme case that no common randomness is available. In the latter case, it is shown that the proposed scheme offers improvements with respect to the McEliece cryptosystem which currently forms the foundation for Quantum safe key encapsulation. [1] A. K. Khandani, \"Looping for Encryption Key Generation Over the Internet: A New Frontier in Physical Layer Security,\" 2023 Biennial Symposium on Communications (BSC), Montreal, QC, Canada, 2023, pp. 59-64",
        "subjects": [
            "cs.CR",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17063",
        "abstract url": "https://arxiv.org/abs/2401.17063",
        "title": "SPViz: A DSL-Driven Approach for Software Project Visualization Tooling",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "For most service architectures, such as OSGi and Spring, architecture-specific tools allow software developers and architects to visualize otherwise obscure configurations hidden in the project files. Such visualization tools are often used for documentation purposes and help to better understand programs than with source code alone. However, such tools often do not address project-specific peculiarities or do not exist at all for less common architectures, requiring developers to use different visualization and analysis tools within the same architecture. Furthermore, many generic modeling tools and architecture visualization tools require their users to create and maintain models manually. We here propose a DSL-driven approach that allows software architects to define and adapt their own project visualization tool. The approach, which we refer to as Software Project Visualization (SPViz), uses two DSLs, one to describe architectural elements and their relationships, and one to describe how these should be visualized. We demonstrate how SPViz can then automatically synthesize a customized, project-specific visualization tool that can adapt to changes in the underlying project automatically. We implemented our approach in an open-source library, also termed SPViz and discuss and analyze four different tools that follow this concept, including open-source projects and projects from an industrial partner in the railway domain.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "14 pages, 14 figures"
    },
    {
        "paper id": "2401.17070",
        "abstract url": "https://arxiv.org/abs/2401.17070",
        "title": "Ultra-low power sensor devices for monitoring physical activity and respiratory frequency in farmed fish",
        "rating": "-2",
        "keywords": [
            [
                "biosensor"
            ]
        ],
        "abstract": "Integration of technological solutions aims to improve accuracy, precision and repeatability in farming operations, and biosensor devices are increasingly used for understanding basic biology during livestock production. The aim of this study was to design and validate a miniaturized tri-axial accelerometer for non-invasive monitoring of farmed fish with re-programmable schedule protocols.The device was attached to the operculum of gilthead sea bream and European sea bass juveniles for monitoring their physical activity by measurements of movement accelerations in x and y-axes, while records of operculum beats served as a measurement of respiratory frequency. Data post-processing of exercised fish in swimming test chambers revealed an exponential increase of fish accelerations with the increase of fish speed from 1 body-length to 4 body-lengths per second, while a close relationship between oxygen consumption and opercular frequency was consistently found.The usefulness of low computational load for data pre-processing with on-board algorithms was verified from low to submaximal exercise, increasing this procedure the autonomy of the system up to 6 h of data recording with different programmable schedules. Visual observations regarding tissue damage, feeding behavior and circulating levels of stress markers did not reveal at short term a negative impact of device tagging. Reduced plasma levels of triglycerides revealed a transient inhibition of feed intake in small fish, but this disturbance was not detected in larger fish. All this considered together is the proof of concept that miniaturized devices are suitable for non-invasive and reliable metabolic phenotyping of farmed fish to improve their overall performance and welfare. Further work is underway for improving the attachment procedure and the full device packaging.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "Preprint. Published on Frontiers in Physiology 29 May 2019 Sec. Aquatic Physiology Volume 10 - 2019 | https://doi.org/10.3389/fphys.2019.00667"
    },
    {
        "paper id": "2401.17083",
        "abstract url": "https://arxiv.org/abs/2401.17083",
        "title": "Online Robot Navigation and Manipulation with Distilled Vision-Language Models",
        "rating": "-2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Robot",
                "Navigation"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Autonomous robot navigation within the dynamic unknown environment is of crucial significance for mobile robotic applications including robot navigation in last-mile delivery and robot-enabled automated supplies in industrial and hospital delivery applications. Current solutions still suffer from limitations, such as the robot cannot recognize unknown objects in real time and cannot navigate freely in a dynamic, narrow, and complex environment. We propose a complete software framework for autonomous robot perception and navigation within very dense obstacles and dense human crowds. First, we propose a framework that accurately detects and segments open-world object categories in a zero-shot manner, which overcomes the over-segmentation limitation of the current SAM model. Second, we proposed the distillation strategy to distill the knowledge to segment the free space of the walkway for robot navigation without the label. In the meantime, we design the trimming strategy that works collaboratively with distillation to enable lightweight inference to deploy the neural network on edge devices such as NVIDIA-TX2 or Xavier NX during autonomous navigation. Integrated into the robot navigation system, extensive experiments demonstrate that our proposed framework has achieved superior performance in terms of both accuracy and efficiency in robot scene perception and autonomous robot navigation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Withdrawn for it may include a few sensitive project data"
    },
    {
        "paper id": "2401.17108",
        "abstract url": "https://arxiv.org/abs/2401.17108",
        "title": "Joint Semantic Communication and Target Sensing for 6G Communication System",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "This paper investigates the secure resource allocation for a downlink integrated sensing and communication system with multiple legal users and potential eavesdroppers. In the considered model, the base station (BS) simultaneously transmits sensing and communication signals through beamforming design, where the sensing signals can be viewed as artificial noise to enhance the security of communication signals. To further enhance the security in the semantic layer, the semantic information is extracted from the original information before transmission. The user side can only successfully recover the received information with the help of the knowledge base shared with the BS, which is stored in advance. Our aim is to maximize the sum semantic secrecy rate of all users while maintaining the minimum quality of service for each user and guaranteeing overall sensing performance. To solve this sum semantic secrecy rate maximization problem, an iterative algorithm is proposed using the alternating optimization method. The simulation results demonstrate the superiority of the proposed algorithm in terms of secure semantic communication and reliable detection.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17115",
        "abstract url": "https://arxiv.org/abs/2401.17115",
        "title": "Identifying Quality Mersenne Twister Streams For Parallel Stochastic Simulations",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "The Mersenne Twister (MT) is a pseudo-random number generator (PRNG) widely used in High Performance Computing for parallel stochastic simulations. We aim to assess the quality of common parallelization techniques used to generate large streams of MT pseudo-random numbers. We compare three techniques: sequence splitting, random spacing and MT indexed sequence. The TestU01 Big Crush battery is used to evaluate the quality of 4096 streams for each technique on three different hardware configurations. Surprisingly, all techniques exhibited almost 30% of defects with no technique showing better quality than the others. While all 106 Big Crush tests showed failures, the failure rate was limited to a small number of tests (maximum of 6 tests failed per stream, resulting in over 94% success rate). Thanks to 33 CPU years, high-quality streams identified are given. They can be used for sensitive parallel simulations such as nuclear medicine and precise high-energy physics applications.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "14 pages, 3 tables, 2 figures. To be published in Winter Simulation Conference 2023. (Accepted paper, already presented at conf) Publication by ACM/IEEE should happen soon. We revised the layout"
    },
    {
        "paper id": "2401.17157",
        "abstract url": "https://arxiv.org/abs/2401.17157",
        "title": "CHoKI-based MPC for blood glucose regulation in Artificial Pancreas",
        "rating": "-2",
        "keywords": [
            [
                "disease",
                "physiological"
            ]
        ],
        "abstract": "This work presents a Model Predictive Control (MPC) for the artificial pancreas, which is able to autonomously manage basal insulin injections in type 1 diabetic patients. Specifically, the MPC goal is to maintain the patients' blood glucose level inside the safe range of 70-180 mg/dL, acting on the insulin amount and respecting all the imposed constraints, taking into consideration also the Insulin On Board (IOB), to avoid excess of insulin infusion. MPC uses a model to make predictions of the system behaviour. In this work, due to the complexity of the diabetes disease that complicates the identification of a general physiological model, a data-driven learning method is employed instead. The Componentwise H\u00f6lder Kinky Inference (CHoKI) method is adopted, to have a customized controller for each patient. For the data collection phase and also to test the proposed controller, the virtual patients of the FDA-accepted UVA/Padova simulator are exploited. The proposed MPC is also tested on a modified version of the simulator, that takes into consideration also the variability of the insulin sensitivity. The final results are satisfying since the proposed controller reduces the time in hypoglycemia (which is more dangerous) if compared to the outcome obtained with the standard constant basal insulin therapy provided by the simulator, satisfying also the time in range requirements and avoiding long-term hyperglycemia events.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17180",
        "abstract url": "https://arxiv.org/abs/2401.17180",
        "title": "Channel Characterization of UAV-RIS-aided Systems with Adaptive Phase-shift Configuration",
        "rating": "-2",
        "keywords": [
            [
                "UAV"
            ]
        ],
        "abstract": "This letter considers a UAV aiding communication between a ground transmitter and a ground receiver in the presence of co-channel interference. A discrete-time Markov process is adopted to model the complex nature of the Air-to-Ground (A2G) channel, including the occurrence of Line-of-Sight, Non-Line-of-Sight, and blockage events. Moreover, an adaptive phase-shift-enabled Reconfigurable Intelligent Surface (RIS) is deployed to combat A2G blockage events. Novel frameworks based on the shadowed Rician distribution are proposed to derive closed-form expressions for Ground-to-Air/A2G SINR' distributions. Numerical results show that RISs with large numbers of elements, e.g., 256 RIS elements, improve end-to-end Outage Probability (OP) and reduce blockages.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17185",
        "abstract url": "https://arxiv.org/abs/2401.17185",
        "title": "Multi-Camera Asynchronous Ball Localization and Trajectory Prediction with Factor Graphs and Human Poses",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Trajectory",
                "flight"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid and precise localization and prediction of a ball are critical for developing agile robots in ball sports, particularly in sports like tennis characterized by high-speed ball movements and powerful spins. The Magnus effect induced by spin adds complexity to trajectory prediction during flight and bounce dynamics upon contact with the ground. In this study, we introduce an innovative approach that combines a multi-camera system with factor graphs for real-time and asynchronous 3D tennis ball localization. Additionally, we estimate hidden states like velocity and spin for trajectory prediction. Furthermore, to enhance spin inference early in the ball's flight, where limited observations are available, we integrate human pose data using a temporal convolutional network (TCN) to compute spin priors within the factor graph. This refinement provides more accurate spin priors at the beginning of the factor graph, leading to improved early-stage hidden state inference for prediction. Our result shows the trained TCN can predict the spin priors with RMSE of 5.27 Hz. Integrating TCN into the factor graph reduces the prediction error of landing positions by over 63.6% compared to a baseline method that utilized an adaptive extended Kalman filter.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Accepted by ICRA 2024"
    },
    {
        "paper id": "2401.17191",
        "abstract url": "https://arxiv.org/abs/2401.17191",
        "title": "Semantic Belief Behavior Graph: Enabling Autonomous Robot Inspection in Unknown Environments",
        "rating": "-2",
        "keywords": [
            [
                "Robot"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "This paper addresses the problem of autonomous robotic inspection in complex and unknown environments. This capability is crucial for efficient and precise inspections in various real-world scenarios, even when faced with perceptual uncertainty and lack of prior knowledge of the environment. Existing methods for real-world autonomous inspections typically rely on predefined targets and waypoints and often fail to adapt to dynamic or unknown settings. In this work, we introduce the Semantic Belief Behavior Graph (SB2G) framework as a novel approach to semantic-aware autonomous robot inspection. SB2G generates a control policy for the robot, featuring behavior nodes that encapsulate various semantic-based policies designed for inspecting different classes of objects. We design an active semantic search behavior to guide the robot in locating objects for inspection while reducing semantic information uncertainty. The edges in the SB2G encode transitions between these behaviors. We validate our approach through simulation and real-world urban inspections using a legged robotic platform. Our results show that SB2G enables a more efficient inspection policy, exhibiting performance comparable to human-operated inspections.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17244",
        "abstract url": "https://arxiv.org/abs/2401.17244",
        "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Reducing hallucination of Large Language Models (LLMs) is imperative for use in the sciences where reproducibility is crucial. However, LLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and inevitably biased task to fine-tune them on domain-specific literature and data. Here we introduce LLaMP, a multimodal retrieval-augmented generation (RAG) framework of multiple data-aware reasoning-and-acting (ReAct) agents that dynamically interact with computational and experimental data on Materials Project (MP). Without fine-tuning, LLaMP demonstrates an ability to comprehend and integrate various modalities of materials science concepts, fetch relevant data stores on the fly, process higher-order data (such as crystal structures and elastic tensors), and summarize multi-step procedures for solid-state synthesis. We show that LLaMP effectively corrects errors in GPT-3.5's intrinsic knowledge, reducing a 5.21% MAPE on frequently-documented bandgaps and a significant 1103.54% MAPE on formation energies -- errors that GPT-3.5 seems to derive from mixed data sources. Additionally, LLaMP substantially reduces the hallucinated volumetric strain in a diamond cubic silicon structure from 66.3% to 0. The proposed framework offers an intuitive and nearly hallucination-free approach to exploring materials informatics and establishes a pathway for knowledge distillation and fine-tuning other language models. We envision the framework as a valuable component for scientific hypotheses and a foundation for future autonomous laboratories where multiple LLM agents communicate and cooperate with robotics to drive material synthesis and chemical reactions without hard-coded human logic and intervention.",
        "subjects": [
            "cs.CL",
            "cond-mat.mtrl-sci",
            "cs.AI"
        ],
        "comment": "22 pages, 4 figures"
    },
    {
        "paper id": "2401.17252",
        "abstract url": "https://arxiv.org/abs/2401.17252",
        "title": "Quantum $X$-Secure $B$-Byzantine $T$-Colluding Private Information Retrieval",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We consider the problems arising from the presence of Byzantine servers in a quantum private information retrieval (QPIR) setting. This is the first work to precisely define what the capabilities of Byzantine servers could be in a QPIR context. We show that quantum Byzantine servers have more capabilities than their classical counterparts due to the possibilities created by quantum encoding procedures. We focus on quantum Byzantine servers that can apply any reversible operation on their individual qudits. In this case, Byzantine servers can generate any error, i.e., this covers \\emph{all} possible single qudit operations that can be applied by Byzantine servers on their qudits. We design a scheme based on cross-subspace alignment (CSA) and we show that this scheme achieves superdense coding gain in some cases.",
        "subjects": [
            "cs.IT",
            "cs.CR",
            "cs.NI",
            "eess.SP",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17351",
        "abstract url": "https://arxiv.org/abs/2401.17351",
        "title": "Supporting Meta-model-based Language Evolution and Rapid Prototyping with Automated Grammar Optimization",
        "rating": "-2",
        "keywords": [
            [
                "Grammar"
            ]
        ],
        "abstract": "In model-driven engineering, developing a textual domain-specific language (DSL) involves constructing a meta-model, which defines an underlying abstract syntax, and a grammar, which defines the concrete syntax for the DSL. Language workbenches such as Xtext allow the grammar to be automatically generated from the meta-model, yet the generated grammar usually needs to be manually optimized to improve its usability. When the meta-model changes during rapid prototyping or language evolution, it can become necessary to re-generate the grammar and optimize it again, causing repeated effort and potential for errors. In this paper, we present GrammarOptimizer, an approach for optimizing generated grammars in the context of meta-model-based language evolution. To reduce the effort for language engineers during rapid prototyping and language evolution, it offers a catalog of configurable grammar optimization rules. Once configured, these rules can be automatically applied and re-applied after future evolution steps, greatly reducing redundant manual effort. In addition, some of the supported optimizations can globally change the style of concrete syntax elements, further significantly reducing the effort for manual optimizations. The grammar optimization rules were extracted from a comparison of generated and existing, expert-created grammars, based on seven available DSLs.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": "34 pages"
    },
    {
        "paper id": "2401.17399",
        "abstract url": "https://arxiv.org/abs/2401.17399",
        "title": "ATPPNet: Attention based Temporal Point cloud Prediction Network",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Point cloud"
            ],
            [
                "autonomous driving",
                "trajectory",
                "LiDAR"
            ]
        ],
        "abstract": "Point cloud prediction is an important yet challenging task in the field of autonomous driving. The goal is to predict future point cloud sequences that maintain object structures while accurately representing their temporal motion. These predicted point clouds help in other subsequent tasks like object trajectory estimation for collision avoidance or estimating locations with the least odometry drift. In this work, we present ATPPNet, a novel architecture that predicts future point cloud sequences given a sequence of previous time step point clouds obtained with LiDAR sensor. ATPPNet leverages Conv-LSTM along with channel-wise and spatial attention dually complemented by a 3D-CNN branch for extracting an enhanced spatio-temporal context to recover high quality fidel predictions of future point clouds. We conduct extensive experiments on publicly available datasets and report impressive performance outperforming the existing methods. We also conduct a thorough ablative study of the proposed architecture and provide an application study that highlights the potential of our model for tasks like odometry estimation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for presentation at the 2024 IEEE International Conference on Robotics and Automation (ICRA)"
    },
    {
        "paper id": "2401.17404",
        "abstract url": "https://arxiv.org/abs/2401.17404",
        "title": "ROAMER: Robust Offroad Autonomy using Multimodal State Estimation with Radar Velocity Integration",
        "rating": "-2",
        "keywords": [
            [
                "LiDAR",
                "Radar",
                "vehicle"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Reliable offroad autonomy requires low-latency, high-accuracy state estimates of pose as well as velocity, which remain viable throughout environments with sub-optimal operating conditions for the utilized perception modalities. As state estimation remains a single point of failure system in the majority of aspiring autonomous systems, failing to address the environmental degradation the perception sensors could potentially experience given the operating conditions, can be a mission-critical shortcoming. In this work, a method for integration of radar velocity information in a LiDAR-inertial odometry solution is proposed, enabling consistent estimation performance even with degraded LiDAR-inertial odometry. The proposed method utilizes the direct velocity-measuring capabilities of an Frequency Modulated Continuous Wave (FMCW) radar sensor to enhance the LiDAR-inertial smoother solution onboard the vehicle through integration of the forward velocity measurement into the graph-based smoother. This leads to increased robustness in the overall estimation solution, even in the absence of LiDAR data. This method was validated by hardware experiments conducted onboard an all-terrain vehicle traveling at high speed, ~12 m/s, in demanding offroad environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17418",
        "abstract url": "https://arxiv.org/abs/2401.17418",
        "title": "Towards Model Predictive Control for Acrobatic Quadrotor Flights",
        "rating": "-2",
        "keywords": [
            [
                "trajectory",
                "flight"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "This study explores modeling and control for quadrotor acrobatics, focusing on executing flip maneuvers. Flips are an elegant way to deliver sensor probes into no-fly or hazardous zones, like volcanic vents. Successful flips require feasible trajectories and precise control, influenced by rotor dynamics, thrust allocation, and control methodologies. The research introduces a novel approach using Model Predictive Control (MPC) for real-time trajectory planning. The MPC considers dynamic constraints and environmental variables, ensuring system stability during maneuvers. The proposed methodology's effectiveness is examined through simulation studies in ROS and Gazebo, providing insights into quadrotor behavior, response time, and trajectory accuracy. Real-time flight experiments on a custom agile quadrotor using PixHawk 4 and Hardkernel Odroid validate MPC-designed controllers. Experiments confirm successful execution and adaptability to real-world scenarios. Outcomes contribute to autonomous aerial robotics, especially aerial acrobatics, enhancing mission capabilities. MPC controllers find applications in probe throws and optimal image capture views through efficient flight paths, e.g., full roll maneuvers. This research paves the way for quadrotors in demanding scenarios, showcasing groundbreaking applications. Video Link: \\url{ https://www.youtube.com/watch?v=UzR0PWjy9W4}",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17447",
        "abstract url": "https://arxiv.org/abs/2401.17447",
        "title": "Reversing information flow: retrodiction in semicartesian categories",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "In statistical inference, retrodiction is the act of inferring potential causes in the past based on knowledge of the effects in the present and the dynamics leading to the present. Retrodiction is applicable even when the dynamics is not reversible, and it agrees with the reverse dynamics when it exists, so that retrodiction may be viewed as an extension of inversion, i.e., time-reversal. Recently, an axiomatic definition of retrodiction has been made in a way that is applicable to both classical and quantum probability using ideas from category theory. Almost simultaneously, a framework for information flow in in terms of semicartesian categories has been proposed in the setting of categorical probability theory. Here, we formulate a general definition of retrodiction to add to the information flow axioms in semicartesian categories, thus providing an abstract framework for retrodiction beyond classical and quantum probability theory. More precisely, we extend Bayesian inference, and more generally Jeffrey's probability kinematics, to arbitrary semicartesian categories.",
        "subjects": [
            "math.CT",
            "cs.IT",
            "math.PR",
            "quant-ph"
        ],
        "comment": "20.5 pages + references, some diagrams"
    },
    {
        "paper id": "2401.17450",
        "abstract url": "https://arxiv.org/abs/2401.17450",
        "title": "Qplacer: Frequency-Aware Component Placement for Superconducting Quantum Computers",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Noisy Intermediate-Scale Quantum (NISQ) computers face a critical limitation in qubit numbers, hindering their progression towards large-scale and fault-tolerant quantum computing. A significant challenge impeding scaling is crosstalk, characterized by unwanted interactions among neighboring components on quantum chips, including qubits, resonators, and substrate. We motivate a general approach to systematically resolving multifaceted crosstalks in a limited substrate area. We propose Qplacer, a frequency-aware electrostatic-based placement framework tailored for superconducting quantum computers, to alleviate crosstalk by isolating these components in spatial and frequency domains alongside compact substrate design. Qplacer commences with a frequency assigner that ensures frequency domain isolation for qubits and resonators. It then incorporates a padding strategy and resonator partitioning for layout flexibility. Central to our approach is the conceptualization of quantum components as charged particles, enabling strategic spatial isolation through a 'frequency repulsive force' concept. Our results demonstrate that Qplacer carefully crafts the physical component layout in mitigating various crosstalk impacts while maintaining a compact substrate size. On various device topologies and NISQ benchmarks, Qplacer improves fidelity by an average of 36.7x and reduces spatial violations (susceptible to crosstalk) by an average of 12.76x, compared to classical placement engines. Regarding area optimization, compared to manual designs, Qplacer can reduce the required layout area by 2.14x on average",
        "subjects": [
            "quant-ph",
            "cs.AR",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17451",
        "abstract url": "https://arxiv.org/abs/2401.17451",
        "title": "URLLC-Aware Proactive UAV Placement in Internet of Vehicles",
        "rating": "-2",
        "keywords": [
            [
                "UAV"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) are envisioned to provide diverse services from the air. The service quality may rely on the wireless performance which is affected by the UAV's position. In this paper, we focus on the UAV placement problem in the Internet of Vehicles, where the UAV is deployed to monitor the road traffic and sends the monitored videos to vehicles. The studied problem is formulated as video resolution maximization by optimizing over the UAV's position. Moreover, we take into account the maximal transmission delay and impose a probabilistic constraint. To solve the formulated problem, we first leverage the techniques in extreme value theory (EVT) and Gaussian process regression (GPR) to characterize the influence of the UAV's position on the delay performance. Based on this characterization, we subsequently propose a proactive resolution selection and UAV placement approach, which adaptively places the UAV according to the geographic distribution of vehicles. Numerical results justify the joint usage of EVT and GPR for maximal delay characterization. Through investigating the maximal transmission delay, the proposed approach nearly achieves the optimal performance when vehicles are evenly distributed, and reduces 10% and 19% of the 999-th 1000-quantile over two baselines when vehicles are biased distributed.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "Accepted in the IEEE Transactions on Intelligent Transportation Systems"
    },
    {
        "paper id": "2401.17463",
        "abstract url": "https://arxiv.org/abs/2401.17463",
        "title": "A Group Theoretic Metric for Robot State Estimation Leveraging Chebyshev Interpolation",
        "rating": "-2",
        "keywords": [
            [
                "trajectory",
                "SLAM"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "We propose a new metric for robot state estimation based on the recently introduced $\\text{SE}_2(3)$ Lie group definition. Our metric is related to prior metrics for SLAM but explicitly takes into account the linear velocity of the state estimate, improving over current pose-based trajectory analysis. This has the benefit of providing a single, quantitative metric to evaluate state estimation algorithms against, while being compatible with existing tools and libraries. Since ground truth data generally consists of pose data from motion capture systems, we also propose an approach to compute the ground truth linear velocity based on polynomial interpolation. Using Chebyshev interpolation and a pseudospectral parameterization, we can accurately estimate the ground truth linear velocity of the trajectory in an optimal fashion with best approximation error. We demonstrate how this approach performs on multiple robotic platforms where accurate state estimation is vital, and compare it to alternative approaches such as finite differences. The pseudospectral parameterization also provides a means of trajectory data compression as an additional benefit. Experimental results show our method provides a valid and accurate means of comparing state estimation systems, which is also easy to interpret and report.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to ICRA 2024"
    },
    {
        "paper id": "2401.17484",
        "abstract url": "https://arxiv.org/abs/2401.17484",
        "title": "Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "vehicle"
            ],
            [
                "Navigation"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Understanding terrain topology at long-range is crucial for the success of off-road robotic missions, especially when navigating at high-speeds. LiDAR sensors, which are currently heavily relied upon for geometric mapping, provide sparse measurements when mapping at greater distances. To address this challenge, we present a novel learning-based approach capable of predicting terrain elevation maps at long-range using only onboard egocentric images in real-time. Our proposed method is comprised of three main elements. First, a transformer-based encoder is introduced that learns cross-view associations between the egocentric views and prior bird-eye-view elevation map predictions. Second, an orientation-aware positional encoding is proposed to incorporate the 3D vehicle pose information over complex unstructured terrain with multi-view visual image features. Lastly, a history-augmented learn-able map embedding is proposed to achieve better temporal consistency between elevation map predictions to facilitate the downstream navigational tasks. We experimentally validate the applicability of our proposed approach for autonomous offroad robotic navigation in complex and unstructured terrain using real-world offroad driving data. Furthermore, the method is qualitatively and quantitatively compared against the current state-of-the-art methods. Extensive field experiments demonstrate that our method surpasses baseline models in accurately predicting terrain elevation while effectively capturing the overall terrain topology at long-ranges. Finally, ablation studies are conducted to highlight and understand the effect of key components of the proposed approach and validate their suitability to improve offroad robotic navigation capabilities.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "8 pages, 6 figures, Accepted in IEEE Robotics and Automation Letters (RA-L)"
    },
    {
        "paper id": "2401.17503",
        "abstract url": "https://arxiv.org/abs/2401.17503",
        "title": "Differentiated Service Entanglement Routing for Quantum Networks",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The entanglement distribution networks with various topologies are mainly implemented by active wavelength multiplexing routing strategies. However, designing an entanglement routing scheme, which achieves the maximized network connections and the optimal overall network efficiency simultaneously, remains a huge challenge for quantum networks. In this article, we propose a differentiated service entanglement routing (DSER) scheme, which firstly finds out the lowest loss paths and supported wavelength channels with the tensor-based path searching algorithm, and then allocates the paired channels with the differentiated routing strategies. The evaluation results show that the proposed DSER scheme can be performed for constructing various large scale quantum networks.",
        "subjects": [
            "quant-ph",
            "cs.NI"
        ],
        "comment": "25 pages, 14 figures"
    },
    {
        "paper id": "2401.17545",
        "abstract url": "https://arxiv.org/abs/2401.17545",
        "title": "Three-Stage Adjusted Regression Forecasting (TSARF) for Software Defect Prediction",
        "rating": "-2",
        "keywords": [
            [
                "Forecasting"
            ]
        ],
        "abstract": "Software reliability growth models (SRGM) enable failure data collected during testing. Specifically, nonhomogeneous Poisson process (NHPP) SRGM are the most commonly employed models. While software reliability growth models are important, efficient modeling of complex software systems increases the complexity of models. Increased model complexity presents a challenge in identifying robust and computationally efficient algorithms to identify model parameters and reduces the generalizability of the models. Existing studies on traditional software reliability growth models suggest that NHPP models characterize defect data as a smooth continuous curve and fail to capture changes in the defect discovery process. Therefore, the model fits well under ideal conditions, but it is not adaptable and will only fit appropriately shaped data. Neural networks and other machine learning methods have been applied to greater effect [5], however limited due to lack of large samples of defect data especially at earlier stages of testing.",
        "subjects": [
            "cs.SE",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17547",
        "abstract url": "https://arxiv.org/abs/2401.17547",
        "title": "Task-Oriented Diffusion Model Compression",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "image editing",
                "Text-to-Image"
            ],
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As recent advancements in large-scale Text-to-Image (T2I) diffusion models have yielded remarkable high-quality image generation, diverse downstream Image-to-Image (I2I) applications have emerged. Despite the impressive results achieved by these I2I models, their practical utility is hampered by their large model size and the computational burden of the iterative denoising process. In this paper, we explore the compression potential of these I2I models in a task-oriented manner and introduce a novel method for reducing both model size and the number of timesteps. Through extensive experiments, we observe key insights and use our empirical knowledge to develop practical solutions that aim for near-optimal results with minimal exploration costs. We validate the effectiveness of our method by applying it to InstructPix2Pix for image editing and StableSR for image restoration. Our approach achieves satisfactory output quality with 39.2% and 56.4% reduction in model footprint and 81.4% and 68.7% decrease in latency to InstructPix2Pix and StableSR, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08792",
        "abstract url": "https://arxiv.org/abs/2403.08792",
        "title": "Realtime Facial Expression Recognition: Neuromorphic Hardware vs. Edge AI Accelerators",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "Facial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The paper focuses on real-time facial expression recognition (FER) systems as an important component in various real-world applications such as social robotics. We investigate two hardware options for the deployment of FER machine learning (ML) models at the edge: neuromorphic hardware versus edge AI accelerators. Our study includes exhaustive experiments providing comparative analyses between the Intel Loihi neuromorphic processor and four distinct edge platforms: Raspberry Pi-4, Intel Neural Compute Stick (NSC), Jetson Nano, and Coral TPU. The results obtained show that Loihi can achieve approximately two orders of magnitude reduction in power dissipation and one order of magnitude energy savings compared to Coral TPU which happens to be the least power-intensive and energy-consuming edge AI accelerator. These reductions in power and energy are achieved while the neuromorphic solution maintains a comparable level of accuracy with the edge accelerators, all within the real-time latency requirements.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.NE",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2404.16839",
        "abstract url": "https://arxiv.org/abs/2404.16839",
        "title": "Immersed in Reality Secured by Design -- A Comprehensive Analysis of Security Measures in AR/VR Environments",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Virtual reality and related technologies such as mixed and augmented reality have received extensive coverage in both mainstream and fringe media outlets. When the subject goes to a new AR headset, another AR device, or AR glasses, the talk swiftly shifts to the technical and design details. Unfortunately, no one seemed to care about security. Data theft and other forms of cyberattack pose serious threats to virtual reality systems. Virtual reality goggles are just specialist versions of computers or Internet of Things devices, whereas virtual reality experiences are software packages. As a result, AR systems are just as vulnerable as any other Internet of Things (IoT) device we use on a daily basis, such as computers, tablets, and phones. Preventing and responding to common cybersecurity threats and assaults is crucial. Cybercriminals can exploit virtual reality headsets just like any other computer system. This paper analysis the data breach induced by these assaults could result in a variety of concerns, including but not limited to identity theft, the unauthorized acquisition of personal information or network credentials, damage to hardware and software, and so on. Augmented reality (AR) allows for real-time monitoring and visualization of network activity, system logs, and security alerts. This allows security professionals to immediately identify threats, monitor suspicious activities, and fix any issues that develop. This data can be displayed in an aesthetically pleasing and intuitively structured format using augmented reality interfaces, enabling for faster analysis and decision-making.",
        "subjects": [
            "cs.CR",
            "cs.IT"
        ],
        "comment": "Cybersecurity. Augmented Reality on, Virtual Reality Implementation errors, Data security and efficiency"
    },
    {
        "paper id": "2401.16800",
        "abstract url": "https://arxiv.org/abs/2401.16800",
        "title": "Online Algorithm for Node Feature Forecasting in Temporal Graphs",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose an online algorithm \"mspace\" for forecasting node features in temporal graphs, which adeptly captures spatial cross-correlation among different nodes as well as the temporal autocorrelation within a node. The algorithm can be used for both probabilistic and deterministic multi-step forecasting, making it applicable for estimation and generation tasks. Comparative evaluations against various baselines, including graph neural network (GNN) based models and classical Kalman filters, demonstrate that mspace performs at par with the state-of-the-art and even surpasses them on some datasets. Importantly, mspace demonstrates consistent robustness across datasets with varying training sizes, a notable advantage over GNN-based methods requiring abundant training samples to learn the spatiotemporal trends in the data effectively. Therefore, employing mspace is advantageous in scenarios where the training sample availability is limited. Additionally, we establish theoretical bounds on multi-step forecasting error of mspace and show that it scales as $O(q)$ for $q$-step forecast.",
        "subjects": [
            "cs.LG",
            "cs.DM",
            "eess.SY"
        ],
        "comment": "19 pages, 25 equations, 9 figures, 13 tables, 3 Algorithms"
    },
    {
        "paper id": "2401.17052",
        "abstract url": "https://arxiv.org/abs/2401.17052",
        "title": "Making Parametric Anomaly Detection on Tabular Data Non-Parametric Again",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning for tabular data has garnered increasing attention in recent years, yet employing deep models for structured data remains challenging. While these models excel with unstructured data, their efficacy with structured data has been limited. Recent research has introduced retrieval-augmented models to address this gap, demonstrating promising results in supervised tasks such as classification and regression. In this work, we investigate using retrieval-augmented models for anomaly detection on tabular data. We propose a reconstruction-based approach in which a transformer model learns to reconstruct masked features of \\textit{normal} samples. We test the effectiveness of KNN-based and attention-based modules to select relevant samples to help in the reconstruction process of the target sample. Our experiments on a benchmark of 31 tabular datasets reveal that augmenting this reconstruction-based anomaly detection (AD) method with non-parametric relationships via retrieval modules may significantly boost performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17116",
        "abstract url": "https://arxiv.org/abs/2401.17116",
        "title": "Quantum error mitigation and correction mediated by Yang-Baxter equation and artificial neural network",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum computing shows great potential, but errors pose a significant challenge. This study explores new strategies for mitigating quantum errors using artificial neural networks (ANN) and the Yang-Baxter equation (YBE). Unlike traditional error correction methods, which are computationally intensive, we investigate artificial error mitigation. The manuscript introduces the basics of quantum error sources and explores the potential of using classical computation for error mitigation. The Yang-Baxter equation plays a crucial role, allowing us to compress time dynamics simulations into constant-depth circuits. By introducing controlled noise through the YBE, we enhance the dataset for error mitigation. We train an ANN model on partial data from quantum simulations, demonstrating its effectiveness in correcting errors in time-evolving quantum states.",
        "subjects": [
            "quant-ph",
            "cond-mat.soft",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17136",
        "abstract url": "https://arxiv.org/abs/2401.17136",
        "title": "Systematically Assessing the Security Risks of AI/ML-enabled Connected Healthcare Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "medical",
                "health",
                "Healthcare"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "The adoption of machine-learning-enabled systems in the healthcare domain is on the rise. While the use of ML in healthcare has several benefits, it also expands the threat surface of medical systems. We show that the use of ML in medical systems, particularly connected systems that involve interfacing the ML engine with multiple peripheral devices, has security risks that might cause life-threatening damage to a patient's health in case of adversarial interventions. These new risks arise due to security vulnerabilities in the peripheral devices and communication channels. We present a case study where we demonstrate an attack on an ML-enabled blood glucose monitoring system by introducing adversarial data points during inference. We show that an adversary can achieve this by exploiting a known vulnerability in the Bluetooth communication channel connecting the glucose meter with the ML-enabled app. We further show that state-of-the-art risk assessment techniques are not adequate for identifying and assessing these new risks. Our study highlights the need for novel risk analysis methods for analyzing the security of AI-enabled connected health devices.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "13 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2401.17457",
        "abstract url": "https://arxiv.org/abs/2401.17457",
        "title": "Socially Aware V2X Localized QoS",
        "rating": "-2.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "5G",
                "IoT"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Vehicle-to-everything (V2X) is a core 5G technology. V2X and its enabler, Device-to-Device (D2D), are essential for the Internet of Things (IoT) and the Internet of Vehicles (IoV). V2X enables vehicles to communicate with other vehicles (V2V), networks (V2N), and infrastructure (V2I). While V2X enables ubiquitous vehicular connectivity, the impact of bursty data on the network's overall Quality of Service (QoS), such as when a vehicle accident occurs, is often ignored. In this work, we study both 4G and 5G V2X utilizing Evolved Universal Terrestrial Radio Access New Radio (E-UTRA-NR) and propose the use of socially aware 5G NR Dual Connectivity (en-DC) for traffic differentiation. We also propose localized QoS, wherein high-priority QoS flows traverse 5G road side units (RSUs) and normal-priority QoS flows traverse 4G Base Station (BS). We formulate a max-min fair QoS-aware Non-Orthogonal Multiple Access (NOMA) resource allocation scheme, QoS reclassify. QoS reclassify enables localized QoS and traffic steering to mitigate bursty network traffic's impact on the network's overall QoS. We then solve QoS reclassify via Integer Linear Programming (ILP) and derive its approximation. We demonstrate that both optimal and approximation QoS reclassify resource allocation schemes in our socially aware QoS management methodology outperform socially unaware legacy 4G V2X algorithms (no localized QoS support, no traffic steering) and socially aware 5G V2X (no localized QoS support, yet utilizes traffic steering). Our proposed QoS reclassify scheme's QoS flow end-to-end latency requires only $\\approx~15\\%$ of the time legacy 4G V2X requires.",
        "subjects": [
            "cs.NI",
            "cs.SI"
        ],
        "comment": "This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Under review by IEEE Internet of Things journal"
    },
    {
        "paper id": "2401.17580",
        "abstract url": "https://arxiv.org/abs/2401.17580",
        "title": "Graph Contrastive Learning with Cohesive Subgraph Awareness",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biomedical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph contrastive learning (GCL) has emerged as a state-of-the-art strategy for learning representations of diverse graphs including social and biomedical networks. GCL widely uses stochastic graph topology augmentation, such as uniform node dropping, to generate augmented graphs. However, such stochastic augmentations may severely damage the intrinsic properties of a graph and deteriorate the following representation learning process. We argue that incorporating an awareness of cohesive subgraphs during the graph augmentation and learning processes has the potential to enhance GCL performance. To this end, we propose a novel unified framework called CTAug, to seamlessly integrate cohesion awareness into various existing GCL mechanisms. In particular, CTAug comprises two specialized modules: topology augmentation enhancement and graph learning enhancement. The former module generates augmented graphs that carefully preserve cohesion properties, while the latter module bolsters the graph encoder's ability to discern subgraph patterns. Theoretical analysis shows that CTAug can strictly improve existing GCL mechanisms. Empirical experiments verify that CTAug can achieve state-of-the-art performance for graph representation learning, especially for graphs with high degrees. The code is available at https://doi.org/10.5281/zenodo.10594093, or https://github.com/wuyucheng2002/CTAug.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16782",
        "abstract url": "https://arxiv.org/abs/2401.16782",
        "title": "A Literature Review on Fetus Brain Motion Correction in MRI",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "MRI"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "This paper provides a comprehensive review of the latest advancements in fetal motion correction in MRI. We delve into various contemporary methodologies and technological advancements aimed at overcoming these challenges. It includes traditional 3D fetal MRI correction methods like Slice to Volume Registration (SVR), deep learning-based techniques such as Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) Networks, Transformers, Generative Adversarial Networks (GANs) and most recent advancements of Diffusion Models. The insights derived from this literature review reflect a thorough understanding of both the technical intricacies and practical implications of fetal motion in MRI studies, offering a reasoned perspective on potential solutions and future improvements in this field.",
        "subjects": [
            "eess.IV",
            "cs.LG"
        ],
        "comment": "8 pages, 2 figures"
    },
    {
        "paper id": "2401.16820",
        "abstract url": "https://arxiv.org/abs/2401.16820",
        "title": "Provably Robust Multi-bit Watermarking for AI-generated Text via Error Correction Code",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "Watermarking"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have been widely deployed for their remarkable capability to generate texts resembling human language. However, they could be misused by criminals to create deceptive content, such as fake news and phishing emails, which raises ethical concerns. Watermarking is a key technique to mitigate the misuse of LLMs, which embeds a watermark (e.g., a bit string) into a text generated by a LLM. Consequently, this enables the detection of texts generated by a LLM as well as the tracing of generated texts to a specific user. The major limitation of existing watermark techniques is that they cannot accurately or efficiently extract the watermark from a text, especially when the watermark is a long bit string. This key limitation impedes their deployment for real-world applications, e.g., tracing generated texts to a specific user. This work introduces a novel watermarking method for LLM-generated text grounded in \\textbf{error-correction codes} to address this challenge. We provide strong theoretical analysis, demonstrating that under bounded adversarial word/token edits (insertion, deletion, and substitution), our method can correctly extract watermarks, offering a provable robustness guarantee. This breakthrough is also evidenced by our extensive experimental results. The experiments show that our method substantially outperforms existing baselines in both accuracy and robustness on benchmark datasets. For instance, when embedding a bit string of length 12 into a 200-token generated text, our approach attains an impressive match rate of $98.4\\%$, surpassing the performance of Yoo et al. (state-of-the-art baseline) at $85.6\\%$. When subjected to a copy-paste attack involving the injection of 50 tokens to generated texts with 200 words, our method maintains a substantial match rate of $90.8\\%$, while the match rate of Yoo et al. diminishes to below $65\\%$.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16827",
        "abstract url": "https://arxiv.org/abs/2401.16827",
        "title": "3D-Printed Hydraulic Fluidic Logic Circuitry for Soft Robots",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "biomedical"
            ]
        ],
        "abstract": "Fluidic logic circuitry analogous to its electric counterpart could potentially provide soft robots with machine intelligence due to its supreme adaptability, dexterity, and seamless compatibility using state-of-the-art additive manufacturing processes. However, conventional microfluidic channel based circuitry suffers from limited driving force, while macroscopic pneumatic logic lacks timely responsivity and desirable accuracy. Producing heavy duty, highly responsive and integrated fluidic soft robotic circuitry for control and actuation purposes for biomedical applications has yet to be accomplished in a hydraulic manner. Here, we present a 3D printed hydraulic fluidic half-adder system, composing of three basic hydraulic fluidic logic building blocks: AND, OR, and NOT gates. Furthermore, a hydraulic soft robotic half-adder system is implemented using an XOR operation and modified dual NOT gate system based on an electrical oscillator structure. This half-adder system possesses binary arithmetic capability as a key component of arithmetic logic unit in modern computers. With slight modifications, it can realize the control over three different directions of deformation of a three degree-of-freedom soft actuation mechanism solely by changing the states of the two fluidic inputs. This hydraulic fluidic system utilizing a small number of inputs to control multiple distinct outputs, can alter the internal state of the circuit solely based on external inputs, holding significant promises for the development of microfluidics, fluidic logic, and intricate internal systems of untethered soft robots with machine intelligence.",
        "subjects": [
            "cs.RO",
            "cond-mat.soft"
        ],
        "comment": "26 pages, 14 figures"
    },
    {
        "paper id": "2401.16847",
        "abstract url": "https://arxiv.org/abs/2401.16847",
        "title": "X-ray Image Generation as a Method of Performance Prediction for Real-Time Inspection: a Case Study",
        "rating": "-3",
        "keywords": [
            [
                "X-ray"
            ],
            [
                "industrial"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "X-ray imaging can be efficiently used for high-throughput in-line inspection of industrial products. However, designing a system that satisfies industrial requirements and achieves high accuracy is a challenging problem. The effect of many system settings is application-specific and difficult to predict in advance. Consequently, the system is often configured using empirical rules and visual observations. The performance of the resulting system is characterized by extensive experimental testing. We propose to use computational methods to substitute real measurements with generated images corresponding to the same experimental settings. With this approach, it is possible to observe the influence of experimental settings on a large amount of data and to make a prediction of the system performance faster than with conventional methods. We argue that a high accuracy of the image generator may be unnecessary for an accurate performance prediction. We propose a quantitative methodology to characterize the quality of the generation model using POD curves. The proposed approach can be adapted to various applications and we demonstrate it on the poultry inspection problem. We show how a calibrated image generation model can be used to quantitatively evaluate the effect of the X-ray exposure time on the performance of the inspection system.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16878",
        "abstract url": "https://arxiv.org/abs/2401.16878",
        "title": "Enhancing EEG Signal-Based Emotion Recognition with Synthetic Data: Diffusion Model Approach",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion",
                "GAN"
            ],
            [
                "EEG"
            ]
        ],
        "abstract": "Emotions are crucial in human life, influencing perceptions, relationships, behaviour, and choices. Emotion recognition using Electroencephalography (EEG) in the Brain-Computer Interface (BCI) domain presents significant challenges, particularly the need for extensive datasets. This study aims to generate synthetic EEG samples that are similar to real samples but are distinct by augmenting noise to a conditional denoising diffusion probabilistic model, thus addressing the prevalent issue of data scarcity in EEG research. The proposed method is tested on the DEAP dataset, showcasing a 1.94% improvement in classification performance when using synthetic data. This is higher compared to the traditional GAN-based and DDPM-based approaches. The proposed diffusion-based approach for EEG data generation appears promising in refining the accuracy of emotion recognition systems and marks a notable contribution to EEG-based emotion recognition. Our research further evaluates the effectiveness of state-of-the-art classifiers on EEG data, employing both real and synthetic data with varying noise levels.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "8 Pages, 3 Figures, 2 Tables"
    },
    {
        "paper id": "2401.16948",
        "abstract url": "https://arxiv.org/abs/2401.16948",
        "title": "An ARGoS plug-in for the Crazyflie drone",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "We present a new plug-in for the ARGoS swarm robotic simulator to implement the Crazyflie drone, including its controllers, sensors, and some expansion decks. We have based our development on the former Spiri drone, upgrading the position controller, adding a new speed controller, LED ring, onboard camera, and battery discharge model. We have compared this new plug-in in terms of accuracy and efficiency with data obtained from real Crazyflie drones. All our experiments showed that the proposed plug-in worked well, presenting high levels of accuracy. We believe that this is an important contribution to robot simulations which will extend ARGoS capabilities through the use of our proposed, open-source plug-in.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 9 figures, 2 tables, 1 algorithm. Source code: https://gitlab.uni.lu/adars/crazyflie"
    },
    {
        "paper id": "2401.17014",
        "abstract url": "https://arxiv.org/abs/2401.17014",
        "title": "Near-Field Fading Channel Modeling for ELAAs: From Communication to ISAC",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "Extremely large aperture array (ELAA) is anticipated to serve as a pivotal feature of future multiple-input multiple-output (MIMO) systems in 6G. Near-field (NF) fading channel models are essential for reliable link-level simulation and ELAA system design. In this article, we propose a framework designed to generate NF fading channels for both communication and integrated sensing and communication (ISAC) applications. The framework allows a mixed of line of sight (LoS) and non-LoS (NLoS) links. It also considers spherical wave model and spatially non-stationary shadow fading. Based on this framework, we propose a three-dimensional (3D) fading channel model for ELAA systems deployed with a uniform rectangular array (URA). It can capture the impact of sensing object for ISAC applications. Moreover, all parameters involved in the framework are based on specifications or measurements from the 3rd Generation Partnership Project (3GPP) documents. Therefore, the proposed framework and channel model have the potential to contribute to the standard in various aspects, including ISAC, extra-large (XL-) MIMO, and reconfigurable intelligent surface (RIS) aided MIMO systems. Finally, future directions for ELAA are presented, including not only NF channel modeling but also the design of next-generation transceivers.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2401.17038",
        "abstract url": "https://arxiv.org/abs/2401.17038",
        "title": "Towards Assessing the Synthetic-to-Measured Adversarial Vulnerability of SAR ATR",
        "rating": "-3",
        "keywords": [
            [
                "radar"
            ],
            [
                "attacks"
            ],
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, there has been increasing concern about the vulnerability of deep neural network (DNN)-based synthetic aperture radar (SAR) automatic target recognition (ATR) to adversarial attacks, where a DNN could be easily deceived by clean input with imperceptible but aggressive perturbations. This paper studies the synthetic-to-measured (S2M) transfer setting, where an attacker generates adversarial perturbation based solely on synthetic data and transfers it against victim models trained with measured data. Compared with the current measured-to-measured (M2M) transfer setting, our approach does not need direct access to the victim model or the measured SAR data. We also propose the transferability estimation attack (TEA) to uncover the adversarial risks in this more challenging and practical scenario. The TEA makes full use of the limited similarity between the synthetic and measured data pairs for blind estimation and optimization of S2M transferability, leading to feasible surrogate model enhancement without mastering the victim model and data. Comprehensive evaluations based on the publicly available synthetic and measured paired labeled experiment (SAMPLE) dataset demonstrate that the TEA outperforms state-of-the-art methods and can significantly enhance various attack algorithms in computer vision and remote sensing applications. Codes and data are available at https://github.com/scenarri/S2M-TEA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17056",
        "abstract url": "https://arxiv.org/abs/2401.17056",
        "title": "Floor extraction and door detection for visually impaired guidance",
        "rating": "-3",
        "keywords": [
            [
                "RGB-D"
            ],
            [
                "navigation"
            ],
            [
                "retina"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Finding obstacle-free paths in unknown environments is a big navigation issue for visually impaired people and autonomous robots. Previous works focus on obstacle avoidance, however they do not have a general view of the environment they are moving in. New devices based on computer vision systems can help impaired people to overcome the difficulties of navigating in unknown environments in safe conditions. In this work it is proposed a combination of sensors and algorithms that can lead to the building of a navigation system for visually impaired people. Based on traditional systems that use RGB-D cameras for obstacle avoidance, it is included and combined the information of a fish-eye camera, which will give a better understanding of the user's surroundings. The combination gives robustness and reliability to the system as well as a wide field of view that allows to obtain many information from the environment. This combination of sensors is inspired by human vision where the center of the retina (fovea) provides more accurate information than the periphery, where humans have a wider field of view. The proposed system is mounted on a wearable device that provides the obstacle-free zones of the scene, allowing the planning of trajectories for people guidance.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17154",
        "abstract url": "https://arxiv.org/abs/2401.17154",
        "title": "Real-time Contact State Estimation in Shape Control of Deformable Linear Objects under Small Environmental Constraints",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Controlling the shape of deformable linear objects using robots and constraints provided by environmental fixtures has diverse industrial applications. In order to establish robust contacts with these fixtures, accurate estimation of the contact state is essential for preventing and rectifying potential anomalies. However, this task is challenging due to the small sizes of fixtures, the requirement for real-time performances, and the infinite degrees of freedom of the deformable linear objects. In this paper, we propose a real-time approach for estimating both contact establishment and subsequent changes by leveraging the dependency between the applied and detected contact force on the deformable linear objects. We seamlessly integrate this method into the robot control loop and achieve an adaptive shape control framework which avoids, detects and corrects anomalies automatically. Real-world experiments validate the robustness and effectiveness of our contact estimation approach across various scenarios, significantly increasing the success rate of shape control processes.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17161",
        "abstract url": "https://arxiv.org/abs/2401.17161",
        "title": "Hybrid Tendon and Ball Chain Continuum Robots for Enhanced Dexterity in Medical Interventions",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Medical"
            ]
        ],
        "abstract": "A hybrid continuum robot design is introduced that combines a proximal tendon-actuated section with a distal telescoping section comprised of permanent-magnet spheres actuated using an external magnet. While, individually, each section can approach a point in its workspace from one or at most several orientations, the two-section combination possesses a dexterous workspace. The paper describes kinematic modeling of the hybrid design and provides a description of the dexterous workspace. We present experimental validation which shows that a simplified kinematic model produces tip position mean and maximum errors of 3% and 7% of total robot length, respectively.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17214",
        "abstract url": "https://arxiv.org/abs/2401.17214",
        "title": "Multi-FLEX: An Automatic Task Sequence Execution Framework to Enable Reactive Motion Planning for Multi-Robot Applications",
        "rating": "-3",
        "keywords": [
            [
                "Robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "In this letter, an integrated task planning and reactive motion planning framework termed Multi-FLEX is presented that targets real-world, industrial multi-robot applications. Reactive motion planning has been attractive for the purposes of collision avoidance, particularly when there are sources of uncertainty and variation. Most industrial applications, though, typically require parts of motion to be at least partially non-reactive in order to achieve functional objectives. Multi-FLEX resolves this dissonance and enables such applications to take advantage of reactive motion planning. The Multi-FLEX framework achieves 1) coordination of motion requests to resolve task-level conflicts and overlaps, 2) incorporation of application-specific task constraints into online motion planning using the new concepts of task dependency accommodation, task decomposition, and task bundling, and 3) online generation of robot trajectories using a custom, online reactive motion planner. This planner combines fast-to-create, sparse dynamic roadmaps (to find a complete path to the goal) with fast-to-execute, short-horizon, online, optimization-based local planning (for collision avoidance and high performance). To demonstrate, we use two six-degree-of-freedom, high-speed industrial robots in a deburring application to show the ability of this approach to not just handle collision avoidance and task variations, but to also achieve industrial applications.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Preprint submitted to IEEE Robotics and Automation Letters"
    },
    {
        "paper id": "2401.17482",
        "abstract url": "https://arxiv.org/abs/2401.17482",
        "title": "Performance Comparison Analysis of ArangoDB, MySQL, and Neo4j: An Experimental Study of Querying Connected Data",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "MySQL"
            ]
        ],
        "abstract": "Choosing and developing performant database solutions helps organizations optimize their operational practices and decision-making. Since graph data is becoming more common, it is crucial to develop and use them in big data with complex relationships with high and consistent performance. However, legacy database technologies such as MySQL are tailored to store relational databases and need to perform more complex queries to retrieve graph data. Previous research has dealt with performance aspects such as CPU and memory usage. In contrast, energy usage and temperature of the servers are lacking. Thus, this paper evaluates and compares state-of-the-art graphs and relational databases from the performance aspects to allow a more informed selection of technologies. Graph-based big data applications benefit from informed selection database technologies for data retrieval and analytics problems. The results show that Neo4j performs faster in querying connected data than MySQL and ArangoDB, and energy, CPU, and memory usage performances are reported in this paper.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "https://hdl.handle.net/10125/107319"
    },
    {
        "paper id": "2401.17593",
        "abstract url": "https://arxiv.org/abs/2401.17593",
        "title": "Head and Neck Tumor Segmentation from [18F]F-FDG PET/CT Images Based on 3D Diffusion Model",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "CT",
                "cancer",
                "Tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Head and neck (H&N) cancers are among the most prevalent types of cancer worldwide, and [18F]F-FDG PET/CT is widely used for H&N cancer management. Recently, the diffusion model has demonstrated remarkable performance in various image-generation tasks. In this work, we proposed a 3D diffusion model to accurately perform H&N tumor segmentation from 3D PET and CT volumes. The 3D diffusion model was developed considering the 3D nature of PET and CT images acquired. During the reverse process, the model utilized a 3D UNet structure and took the concatenation of PET, CT, and Gaussian noise volumes as the network input to generate the tumor mask. Experiments based on the HECKTOR challenge dataset were conducted to evaluate the effectiveness of the proposed diffusion model. Several state-of-the-art techniques based on U-Net and Transformer structures were adopted as the reference methods. Benefits of employing both PET and CT as the network input as well as further extending the diffusion model from 2D to 3D were investigated based on various quantitative metrics and the uncertainty maps generated. Results showed that the proposed 3D diffusion model could generate more accurate segmentation results compared with other methods. Compared to the diffusion model in 2D format, the proposed 3D model yielded superior results. Our experiments also highlighted the advantage of utilizing dual-modality PET and CT data over only single-modality data for H&N tumor segmentation.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": "28 pages, 5 figures"
    },
    {
        "paper id": "2402.00082",
        "abstract url": "https://arxiv.org/abs/2402.00082",
        "title": "Enhancing Grover's Search Algorithm: A Modified Approach to Increase the Probability of Good States",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "This article introduces an enhancement to the Grover search algorithm to speed up computing the probability of finding good states. It suggests incorporating a rotation phase angle determined mathematically from the derivative of the model during the initial iteration. At each iteration, a new phase angle is computed and used in a rotation gate around y+z axis in the diffusion operator. The computed phase angles are optimized through an adaptive adjustment based on the estimated increasing ratio of the consecutive amplitudes. The findings indicate an average decrease of 28% in the required number of iterations resulting in a faster overall process and fewer number of quantum gates. For large search space, this improvement rises to 29.58%. Given the computational capabilities of the computer utilized for the simulation, the approach is applied to instances with up to 12 qubits or 4096 possible combination of search entries.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DB",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17424",
        "abstract url": "https://arxiv.org/abs/2401.17424",
        "title": "Application of Neural Networks for the Reconstruction of Supernova Neutrino Energy Spectra Following Fast Neutrino Flavor Conversions",
        "rating": "-3.5",
        "keywords": [
            [
                "survival"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Neutrinos can undergo fast flavor conversions (FFCs) within extremely dense astrophysical environments such as core-collapse supernovae (CCSNe) and neutron star mergers (NSMs). In this study, we explore FFCs in a \\emph{multi-energy} neutrino gas, revealing that when the FFC growth rate significantly exceeds that of the vacuum Hamiltonian, all neutrinos (regardless of energy) share a common survival probability dictated by the energy-integrated neutrino spectrum. We then employ physics-informed neural networks (PINNs) to predict the asymptotic outcomes of FFCs within such a multi-energy neutrino gas. These predictions are based on the first two moments of neutrino angular distributions for each energy bin, typically available in state-of-the-art CCSN and NSM simulations. Our PINNs achieve errors as low as $\\lesssim6\\%$ and $\\lesssim 18\\%$ for predicting the number of neutrinos in the electron channel and the relative absolute error in the neutrino moments, respectively.",
        "subjects": [
            "astro-ph.HE",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "13 pages, 6 figures, submitted to PRD. arXiv admin note: text overlap with arXiv:2311.15656"
    },
    {
        "paper id": "2402.00068",
        "abstract url": "https://arxiv.org/abs/2402.00068",
        "title": "GPT4Battery: An LLM-driven Framework for Adaptive State of Health Estimation of Raw Li-ion Batteries",
        "rating": "-3.5",
        "keywords": [
            [
                "Health"
            ],
            [
                "chemistry"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "State of health (SOH) is a crucial indicator for assessing the degradation level of batteries that cannot be measured directly but requires estimation. Accurate SOH estimation enhances detection, control, and feedback for Li-ion batteries, allowing for safe and efficient energy management and guiding the development of new-generation batteries. Despite the significant progress in data-driven SOH estimation, the time and resource-consuming degradation experiments for generating lifelong training data pose a challenge in establishing one large model capable of handling diverse types of Li-ion batteries, e.g., cross-chemistry, cross-manufacturer, and cross-capacity. Hence, this paper utilizes the strong generalization capability of large language model (LLM) to proposes a novel framework for adaptable SOH estimation across diverse batteries. To match the real scenario where unlabeled data sequentially arrives in use with distribution shifts, the proposed model is modified by a test-time training technique to ensure estimation accuracy even at the battery's end of life. The validation results demonstrate that the proposed framework achieves state-of-the-art accuracy on four widely recognized datasets collected from 62 batteries. Furthermore, we analyze the theoretical challenges of cross-battery estimation and provide a quantitative explanation of the effectiveness of our method.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.07912",
        "abstract url": "https://arxiv.org/abs/2402.07912",
        "title": "Spatial Computing: Concept, Applications, Challenges and Future Directions",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Spatial computing is a technological advancement that facilitates the seamless integration of devices into the physical environment, resulting in a more natural and intuitive digital world user experience. Spatial computing has the potential to become a significant advancement in the field of computing. From GPS and location-based services to healthcare, spatial computing technologies have influenced and improved our interactions with the digital world. The use of spatial computing in creating interactive digital environments has become increasingly popular and effective. This is explained by its increasing significance among researchers and industrial organisations, which motivated us to conduct this review. This review provides a detailed overview of spatial computing, including its enabling technologies and its impact on various applications. Projects related to spatial computing are also discussed. In this review, we also explored the potential challenges and limitations of spatial computing. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of spatial computing, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Submitted to peer reviewe"
    },
    {
        "paper id": "2401.17149",
        "abstract url": "https://arxiv.org/abs/2401.17149",
        "title": "Optical Tactile Sensing for Aerial Multi-Contact Interaction: Design, Integration, and Evaluation",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "robot"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "Distributed tactile sensing for multi-force detection is crucial for various aerial robot interaction tasks. However, current contact sensing solutions on drones only exploit single end-effector sensors and cannot provide distributed multi-contact sensing. Designed to be easily mounted at the bottom of a drone, we propose an optical tactile sensor that features a large and curved soft sensing surface, a hollow structure and a new illumination system. Even when spaced only 2 cm apart, multiple contacts can be detected simultaneously using our software pipeline, which provides real-world quantities of 3D contact locations (mm) and 3D force vectors (N), with an accuracy of 1.5 mm and 0.17 N respectively. We demonstrate the sensor's applicability and reliability onboard and in real-time with two demos related to i) the estimation of the compliance of different perches and subsequent re-alignment and landing on the stiffer one, and ii) the mapping of sparse obstacles. The implementation of our distributed tactile sensor represents a significant step towards attaining the full potential of drones as versatile robots capable of interacting with and navigating within complex environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2401.17538",
        "abstract url": "https://arxiv.org/abs/2401.17538",
        "title": "Post-Quantum Cryptography for Internet of Things: A Survey on Performance and Optimization",
        "rating": "-4",
        "keywords": [
            [
                "IoT"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Due to recent development in quantum computing, the invention of a large quantum computer is no longer a distant future. Quantum computing severely threatens modern cryptography, as the hard mathematical problems beneath classic public-key cryptosystems can be solved easily by a sufficiently large quantum computer. As such, researchers have proposed PQC based on problems that even quantum computers cannot efficiently solve. Generally, post-quantum encryption and signatures can be hard to compute. This could potentially be a problem for IoT, which usually consist lightweight devices with limited computational power. In this paper, we survey existing literature on the performance for PQC in resource-constrained devices to understand the severeness of this problem. We also review recent proposals to optimize PQC algorithms for resource-constrained devices. Overall, we find that whilst PQC may be feasible for reasonably lightweight IoT, proposals for their optimization seem to lack standardization. As such, we suggest future research to seek coordination, in order to ensure an efficient and safe migration toward IoT for the post-quantum era.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "13 pages, 3 figures and 7 tables. Formatted version submitted to ACM Computer Surveys"
    },
    {
        "paper id": "2403.08791",
        "abstract url": "https://arxiv.org/abs/2403.08791",
        "title": "Gated Chemical Units",
        "rating": "-4",
        "keywords": [
            [
                "biologically-plausible"
            ],
            [
                "Chemical"
            ]
        ],
        "abstract": "We introduce Gated Chemical Units (GCUs), a new type of gated recurrent cells which provide fresh insights into the commonly-used gated recurrent units, and bridge their gap to biologically-plausible neural models. We systematically derive GCUs from Electrical Equivalent Circuits (EECs), a widely adopted ordinary-differential-equations model in neuroscience for biological neurons with both electrical and chemical synapses. We focus on saturated EECs, as they are more stable, and chemical synapses, as they are more expressive. To define GCUs, we introduce a new kind of gate, we call a time gate (TG), in the associated difference-equations model of the EECs. The TG learns for each neuron the optimal time step to be used in a simple Euler integration scheme, and leads to a very efficient gated unit. By observing that the TG corresponds to the forget gate (FG) in traditional gated recurrent units, we provide a new formulation of these units as neural ODEs. We also show that in GCUs, the FG is in fact its liquid time constant. Finally, we demonstrate that GCUs not only explain the elusive nature of gates in traditional recurrent units, but also represent a very competitive alternative to these units.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17388",
        "abstract url": "https://arxiv.org/abs/2401.17388",
        "title": "A Spectral Library and Method for Sparse Unmixing of Hyperspectral Images in Fluorescence Guided Resection of Brain Tumors",
        "rating": "-5",
        "keywords": [
            [
                "surgery",
                "tumor"
            ],
            [
                "Hyperspectral Images"
            ],
            [
                "physics"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Through spectral unmixing, hyperspectral imaging (HSI) in fluorescence-guided brain tumor surgery has enabled detection and classification of tumor regions invisible to the human eye. Prior unmixing work has focused on determining a minimal set of viable fluorophore spectra known to be present in the brain and effectively reconstructing human data without overfitting. With these endmembers, non-negative least squares regression (NNLS) was used to compute the abundances. However, HSI images are heterogeneous, so one small set of endmember spectra may not fit all pixels well. Additionally, NNLS is the maximum likelihood estimator only if the measurement is normally distributed, and it does not enforce sparsity, which leads to overfitting and unphysical results. Here, we analyzed 555666 HSI fluorescence spectra from 891 ex vivo measurements of patients with brain tumors to show that a Poisson distribution models the measured data 82% better than a Gaussian in terms of the Kullback-Leibler divergence and that the endmember abundance vectors are sparse. With this knowledge, we introduce (1) a library of 9 endmember spectra, (2) a sparse, non-negative Poisson regression algorithm to perform physics-informed unmixing with this library without overfitting, and (3) a highly realistic spectral measurement simulation with known endmember abundances. The new unmixing method was then tested on the human and simulated data and compared to four other candidate methods. It outperforms previous methods with 25% lower error in the computed abundances on the simulated data than NNLS, lower reconstruction error on human data, beUer sparsity, and 31 times faster runtime than state-of-the-art Poisson regression. This method and library of endmember spectra can enable more accurate spectral unmixing to beUer aid the surgeon during brain tumor resection.",
        "subjects": [
            "eess.IV",
            "q-bio.QM"
        ],
        "comment": "17 pages, 4 tables, 6 figures; Under review"
    },
    {
        "paper id": "2401.17592",
        "abstract url": "https://arxiv.org/abs/2401.17592",
        "title": "Local Feature Matching Using Deep Learning: A Survey",
        "rating": "-5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "Medical"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Local feature matching enjoys wide-ranging applications in the realm of computer vision, encompassing domains such as image retrieval, 3D reconstruction, and object recognition. However, challenges persist in improving the accuracy and robustness of matching due to factors like viewpoint and lighting variations. In recent years, the introduction of deep learning models has sparked widespread exploration into local feature matching techniques. The objective of this endeavor is to furnish a comprehensive overview of local feature matching methods. These methods are categorized into two key segments based on the presence of detectors. The Detector-based category encompasses models inclusive of Detect-then-Describe, Joint Detection and Description, Describe-then-Detect, as well as Graph Based techniques. In contrast, the Detector-free category comprises CNN Based, Transformer Based, and Patch Based methods. Our study extends beyond methodological analysis, incorporating evaluations of prevalent datasets and metrics to facilitate a quantitative comparison of state-of-the-art techniques. The paper also explores the practical application of local feature matching in diverse domains such as Structure from Motion, Remote Sensing Image Registration, and Medical Image Registration, underscoring its versatility and significance across various fields. Ultimately, we endeavor to outline the current challenges faced in this domain and furnish future research directions, thereby serving as a reference for researchers involved in local feature matching and its interconnected domains. A comprehensive list of studies in this survey is available at https://github.com/vignywang/Awesome-Local-Feature-Matching .",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by Information Fusion 2024. Project page: https://github.com/vignywang/Awesome-Local-Feature-Matching"
    },
    {
        "paper id": "2401.17594",
        "abstract url": "https://arxiv.org/abs/2401.17594",
        "title": "5G NR Positioning Enhancements in 3GPP Release-18",
        "rating": "-5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "5G"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "New radio (NR) positioning in the Third Generation Partnership Project (3GPP) Release 18 (Rel-18) enables 5G-advanced networks to achieve ultra-high accuracy positioning without dependence on global navigation satellite systems (GNSS) with key enablers such as the carrier phase positioning technique, standardized for the first time in a cellular communications standard and setting a new baseline for future generations. In addition, Rel-18 NR supports positioning functionalities for reduced capability (RedCap) user equipment and bandwidth aggregation for positioning measurements. Moreover, the low power solutions are designed for low power high accuracy positioning use cases. Lastly, sidelink-based positioning is introduced in Rel-18. This article constitutes a comprehensive treatment of the Rel-18 NR positioning enhancements crucial for the development of next-generation networks.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16751",
        "abstract url": "https://arxiv.org/abs/2401.16751",
        "title": "Simultaneous Computation and Communication over MAC",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study communication over a Gaussian multiple-access channel (MAC) with two types of transmitters: Digital transmitters hold a message from a discrete set that needs to be communicated to the receiver with vanishing error probability. Analog transmitters hold sequences of analog values, and some functions of these distributed values (but not the values themselves) need to be conveyed to the receiver, subject to a fidelity criterion such as mean squared error (MSE) or a certain maximum error with given confidence. For the case in which the computed function for the analog transmitters is a sum of values in [-1,1], we derive inner and outer bounds for the tradeoff of digital and analog rates of communication under peak and average power constraints for digital transmitters and a peak power constraint for analog transmitters. We then extend the achievability result to a class of functions that includes all linear and some non-linear functions. The practicality of our proposed communication scheme is shown in channel simulations that use a version of the scheme based on low density parity check (LDPC) coding and evaluate the system performance for different block lengths and Gaussian as well as non-Gaussian noise distributions.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16759",
        "abstract url": "https://arxiv.org/abs/2401.16759",
        "title": "Sandi: A System for Accountability and Applications in Direct Communication",
        "rating": "-10",
        "keywords": [],
        "abstract": "We construct a system, Sandi, to bring trust in online communication through accountability. Sandi is based on a unique \"somewhat monotone\" accountability score, with strong privacy and security properties. A registered sender can request from Sandi a cryptographic tag encoding its score. The score measures the sender's trustworthiness based on its previous communications. The tag is sent to a receiver with whom the sender wants to initiate a conversation and signals the sender's \"endorsement\" for the communication channel. Receivers can use the sender's score to decide how to proceed with the sender. If a receiver finds the sender's communication inappropriate, it can use the tag to report the sender to Sandi, thus decreasing the sender's score. Sandi aims to benefit both senders and receivers. Senders benefit, as receivers are more likely to react to communication on an endorsed channel. Receivers benefit, as they can make better choices regarding who they interact with based on indisputable evidence from prior receivers. Receivers do not need registered accounts. Neither senders nor receivers are required to maintain long-term secret keys. Sandi provides a score integrity guarantee for the senders, a full communication privacy guarantee for the senders and receivers, a reporter privacy guarantee to protect reporting receivers, and an unlinkability guarantee to protect senders. The design of Sandi ensures compatibility with any communication system that allows for small binary data transfer. Finally, we provide a game-theoretic analysis for the sender. We prove that Sandi drives rational senders towards a strategy that reduces the amount of inappropriate communication.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16778",
        "abstract url": "https://arxiv.org/abs/2401.16778",
        "title": "Secure ISAC MIMO Systems: Exploiting Interference With Bayesian Cram\u00e9r-Rao Bound Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present a signaling design for secure integrated sensing and communication (ISAC) systems comprising a dual-functional multi-input multi-output (MIMO) base station (BS) that simultaneously communicates with multiple users while detecting targets present in their vicinity, which are regarded as potential eavesdroppers. In particular, assuming that the distribution of each parameter to be estimated is known \\textit{a priori}, we focus on optimizing the targets' sensing performance. To this end, we derive and minimize the Bayesian Cram\u00e9r-Rao bound (BCRB), while ensuring certain communication quality of service (QoS) by exploiting constructive interference (CI). The latter scheme enforces that the received signals at the eavesdropping targets fall into the destructive region of the signal constellation, to deteriorate their decoding probability, thus enhancing the ISAC's system physical-layer security (PLS) capability. To tackle the nonconvexity of the formulated problem, a tailored successive convex approximation method is proposed for its efficient solution. Our extensive numerical results verify the effectiveness of the proposed secure ISAC design showing that the proposed algorithm outperforms block-level precoding techniques.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 4 figures, submitted for journal publication"
    },
    {
        "paper id": "2401.16786",
        "abstract url": "https://arxiv.org/abs/2401.16786",
        "title": "WikiTexVC: MediaWiki's native LaTeX to MathML converter for Wikipedia",
        "rating": "-10",
        "keywords": [],
        "abstract": "MediaWiki and Wikipedia authors usually use LaTeX to define mathematical formulas in the wiki text markup. In the Wikimedia ecosystem, these formulas were processed by a long cascade of web services and finally delivered to users' browsers in rendered form for visually readable representation as SVG. With the latest developments of supporting MathML Core in Chromium-based browsers, MathML continues its path to be a de facto standard markup language for mathematical notation in the web. Conveying formulas in MathML enables semantic annotation and machine readability for extended interpretation of mathematical content, in example for accessibility technologies. With this work, we present WikiTexVC, a novel method for validating LaTeX formulas from wiki texts and converting them to MathML, which is directly integrated into MediaWiki. This mitigates the shortcomings of previously used rendering methods in MediaWiki in terms of robustness, maintainability and performance. In addition, there is no need for a multitude of web services running in the background, but processing takes place directly within MediaWiki instances. We validated this method with an extended dataset of over 300k formulas which have been incorporated as automated tests to the MediaWiki continuous integration instances. Furthermore, we conducted an evaluation with 423 formulas, comparing the tree edit distance for produced parse trees to other MathML renderers. Our method has been made available Open Source and can be used on German Wikipedia and is delivered with recent MediaWiki versions. As a practical example of enabling semantic annotations within our method, we present a new macro that adds content to formula disambiguation to facilitate accessibility for visually impaired people.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2401.16792",
        "abstract url": "https://arxiv.org/abs/2401.16792",
        "title": "WideSA: A High Array Utilization Mapping Scheme for Uniform Recurrences on the Versal ACAP Architecture",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Versal Adaptive Compute Acceleration Platform (ACAP) is a new architecture that combines AI Engines (AIEs) with reconfigurable fabric. This architecture offers significant acceleration potential for uniform recurrences in various domains, such as deep learning, high-performance computation, and signal processing. However, efficiently mapping these computations onto the Versal ACAP architecture while achieving high utilization of AIEs poses a challenge. To address this issue, we propose a mapping scheme called \\fname, which aims to accelerate uniform recurrences on the Versal ACAP architecture by leveraging the features of both the hardware and the computations. Considering the array architecture of AIEs, our approach utilizes space-time transformations based on the polyhedral model to generate legally optimized systolic array mappings. Concurrently, we have developed a routing-aware PLIO assignment algorithm tailored for communication on the AIE array, and the algorithm aims at successful compilation while maximizing array utilization. Furthermore, we introduce an automatic mapping framework. This framework is designed to generate the corresponding executable code for uniform recurrences, which encompasses the AIE kernel program, programmable logic bitstreams, and the host program. The experimental results validate the effectiveness of our mapping scheme. Specifically, when applying our scheme to matrix multiplication computations on the VCK5000 board, we achieve a throughput of 4.15TOPS on float data type, which is 1.11$\\times$ higher compared to the state-of-the-art accelerator on the Versal ACAP architecture.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "DATE24 (To appear)"
    },
    {
        "paper id": "2401.16793",
        "abstract url": "https://arxiv.org/abs/2401.16793",
        "title": "On the Stability of Datatic Control Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The development of feedback controllers is undergoing a paradigm shift from $\\textit{modelic}$ (model-driven) control to $\\textit{datatic}$ (data-driven) control. Stability, as a fundamental property in control, is less well studied in datatic control paradigm. The difficulty is that traditional stability criteria rely on explicit system models, which are not available in those systems with datatic description. Some pioneering works explore stability criteria for datatic systems with special forms such as linear systems, homogeneous systems, and polynomial systems. However, these systems imply too strong assumptions on the inherent connection among data points, which do not hold in general nonlinear systems. This paper proposes a stability verification algorithm for general datatic control systems called $\u03b7$-testing. Our stability criterion only relies on a weak assumption of Lipschitz continuity so as to extend information from known data points to unmeasured regions. This information restricts the time derivative of any unknown state to the intersection of a set of closed balls. Inside the intersection, the worst-case time derivative of Lyapunov function is estimated by solving a quadratically constrained linear program (QCLP). By comparing the optimal values of QCLPs to zero in the whole state space, a sufficient condition of system stability can be checked. We test our algorithm on three datatic control systems, including both linear and nonlinear ones. Results show that our algorithm successfully verifies the stability, instability, and critical stability of tested systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16797",
        "abstract url": "https://arxiv.org/abs/2401.16797",
        "title": "Enhancing Translation Validation of Compiler Transformations with Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a framework that integrates Large Language Models (LLMs) into translation validation, targeting LLVM compiler transformations where formal verification tools fall short. Our framework first utilizes existing formal verification tools for translation validation. In this work, we use Alive2, a well-known tool in LLVM compiler verification, as an example. When formal verification tools are unable to confirm a transformation's soundness, our framework employs fine-tuned LLMs for prediction. It then applies fuzzing to transformations predicted as potentially unsound by the LLMs due to return values or memory inconsistencies, aiming to find counterexamples. In cases where transformations are unsound for other reasons or sound, or if no counterexamples emerge, the framework directly reports these outcomes without further fuzzing. This methodology has shown effectiveness in complex application such as deep-learning accelerator designs, where traditional formal verification tools struggle.",
        "subjects": [
            "cs.PL",
            "cs.SE"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2401.16804",
        "abstract url": "https://arxiv.org/abs/2401.16804",
        "title": "Guessing What, Noise or Codeword?",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we distinguish two guessing algorithms for decoding binary linear codes. One is the guessing noise decoding (GND) algorithm, and the other is the guessing codeword decoding (GCD) algorithm. We prove that the GCD is a maximum likelihood (ML) decoding algorithm and that the GCD is more efficient than GND for most practical applications. We also introduce several variants of ordered statistic decoding (OSD) to trade off the complexity of the Gaussian elimination (GE) and that of the guessing, which may find applications in decoding short block codes in the high signal-to-noise ratio (SNR) region.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2401.16825",
        "abstract url": "https://arxiv.org/abs/2401.16825",
        "title": "Smart Fitting Room: A One-stop Framework for Matching-aware Virtual Try-on",
        "rating": "-10",
        "keywords": [],
        "abstract": "The development of virtual try-on has revolutionized online shopping by allowing customers to visualize themselves in various fashion items, thus extending the in-store try-on experience to the cyber space. Although virtual try-on has attracted considerable research initiatives, existing systems only focus on the quality of image generation, overlooking whether the fashion item is a good match to the given person and clothes. Recognizing this gap, we propose to design a one-stop Smart Fitting Room, with the novel formulation of matching-aware virtual try-on. Following this formulation, we design a Hybrid Matching-aware Virtual Try-On Framework (HMaVTON), which combines retrieval-based and generative methods to foster a more personalized virtual try-on experience. This framework integrates a hybrid mix-and-match module and an enhanced virtual try-on module. The former can recommend fashion items available on the platform to boost sales and generate clothes that meets the diverse tastes of consumers. The latter provides high-quality try-on effects, delivering a one-stop shopping service. To validate the effectiveness of our approach, we enlist the expertise of fashion designers for a professional evaluation, assessing the rationality and diversity of the clothes combinations and conducting an evaluation matrix analysis. Our method significantly enhances the practicality of virtual try-on. The code is available at https://github.com/Yzcreator/HMaVTON.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16826",
        "abstract url": "https://arxiv.org/abs/2401.16826",
        "title": "Design of Linear Precoders for Correlated Sources in MIMO Multiple Access Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work focuses on distributed linear precoding when users transmit correlated information over a fading Multiple-Input and Multiple-Output Multiple Access Channel. Precoders are optimized in order to minimize the sum-Mean Square Error (MSE) between the source and the estimated symbols. When sources are correlated, minimizing the sum-MSE results in a non-convex optimization problem. Precoders for an arbitrary number of users and transmit and receive antennas are thus obtained via a projected steepest-descent algorithm and a low-complexity heuristic approach. For the more restrictive case of two single-antenna users, a closed-form expression for the minimum sum-MSE precoders is derived. Moreover, for the scenario with a single receive antenna and any number of users, a solution is obtained by means of a semidefinite relaxation. Finally, we also consider precoding schemes where the precoders are decomposed into complex scalars and unit norm vectors. Simulation results show a significant improvement when source correlation is exploited at precoding, especially for low SNRs and when the number of receive antennas is lower than the number of transmitting nodes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16833",
        "abstract url": "https://arxiv.org/abs/2401.16833",
        "title": "Strong Polarization for Shortened and Punctured Polar Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Polar codes were originally specified for codelengths that are powers of two. In many applications, it is desired to have a code that is not restricted to such lengths. Two common strategies of modifying the length of a code are shortening and puncturing. Simple and explicit schemes for shortening and puncturing were introduced by Wang and Liu, and by Niu, Chen, and Lin, respectively. In this paper, we prove that both schemes yield polar codes that are capacity achieving. Moreover, the probability of error for both the shortened and the punctured polar codes decreases to zero at the same exponential rate as seminal polar codes. These claims hold for \\emph{all} codelengths large enough.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to ISIT 2024"
    },
    {
        "paper id": "2401.16837",
        "abstract url": "https://arxiv.org/abs/2401.16837",
        "title": "A fully differentiable model for unsupervised singing voice separation",
        "rating": "-10",
        "keywords": [],
        "abstract": "A novel model was recently proposed by Schulze-Forster et al. in [1] for unsupervised music source separation. This model allows to tackle some of the major shortcomings of existing source separation frameworks. Specifically, it eliminates the need for isolated sources during training, performs efficiently with limited data, and can handle homogeneous sources (such as singing voice). But, this model relies on an external multipitch estimator and incorporates an Ad hoc voice assignment procedure. In this paper, we propose to extend this framework and to build a fully differentiable model by integrating a multipitch estimator and a novel differentiable assignment module within the core model. We show the merits of our approach through a set of experiments, and we highlight in particular its potential for processing diverse and unseen data.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16838",
        "abstract url": "https://arxiv.org/abs/2401.16838",
        "title": "A Complete Fragment of LTL(EB)",
        "rating": "-10",
        "keywords": [],
        "abstract": "The verification of liveness conditions is an important aspect of state-based rigorous methods. This article investigates this problem in a fragment $\\square$LTL of the logic LTL(EB), the integration of the UNTIL-fragment of Pnueli's linear time temporal logic (LTL) and the logic of Event-B, in which the most commonly used liveness conditions can be expressed. For this fragment a sound set of derivation rules is developed, which is also complete under mild restrictions for Event-B machines.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2401.16840",
        "abstract url": "https://arxiv.org/abs/2401.16840",
        "title": "Towards Large-scale Network Emulation on Analog Neuromorphic Hardware",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a novel software feature for the BrainScaleS-2 accelerated neuromorphic platform that facilitates the emulation of partitioned large-scale spiking neural networks. This approach is well suited for many deep spiking neural networks, where the constraint of the largest recurrent subnetwork fitting on the substrate or the limited fan-in of neurons is often not a limitation in practice. We demonstrate the training of two deep spiking neural network models, using the MNIST and EuroSAT datasets, that exceed the physical size constraints of a single-chip BrainScaleS-2 system. The ability to emulate and train networks larger than the substrate provides a pathway for accurate performance evaluation in planned or scaled systems, ultimately advancing the development and understanding of large-scale models and neuromorphic computing architectures.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16841",
        "abstract url": "https://arxiv.org/abs/2401.16841",
        "title": "jaxsnn: Event-driven Gradient Estimation for Analog Neuromorphic Hardware",
        "rating": "-10",
        "keywords": [],
        "abstract": "Traditional neuromorphic hardware architectures rely on event-driven computation, where the asynchronous transmission of events, such as spikes, triggers local computations within synapses and neurons. While machine learning frameworks are commonly used for gradient-based training, their emphasis on dense data structures poses challenges for processing asynchronous data such as spike trains. This problem is particularly pronounced for typical tensor data structures. In this context, we present a novel library (jaxsnn) built on top of JAX, that departs from conventional machine learning frameworks by providing flexibility in the data structures used and the handling of time, while maintaining Autograd functionality and composability. Our library facilitates the simulation of spiking neural networks and gradient estimation, with a focus on compatibility with time-continuous neuromorphic backends, such as the BrainScaleS-2 system, during the forward pass. This approach opens avenues for more efficient and flexible training of spiking neural networks, bridging the gap between traditional neuromorphic architectures and contemporary machine learning frameworks.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16845",
        "abstract url": "https://arxiv.org/abs/2401.16845",
        "title": "Reading yesterday's news. Layout recognition by segmentation of historical newspaper pages",
        "rating": "-10",
        "keywords": [],
        "abstract": "Newspapers are important sources for historians interested in past societies' cultural values, social structures, and their changes. Since the 19th century, newspapers have been widely available and spread regionally. Today, historical newspapers are digitized but unavailable in a separate metadata-enhanced form. Machine-readable metadata, however, is a prerequisite for a mass statistical analysis of this source. This paper focuses on parsing the complex layout of historic newspaper pages, which today's machines do not understand well. We argue for using neural networks, which require detailed annotated data in large numbers. Our Bonn newspaper dataset consists of 486 pages of the \\textit{K\u00f6lnische Zeitung} from the years 1866 and 1924. We propose solving the newspaper-understanding problem by training a U-Net on our new dataset, which delivers satisfactory performance.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "Dataset available at: https://gitlab.uni-bonn.de/digital-history/newspaper-dataset . Baseline code: https://github.com/NewspaperSegmentation/NewspaperImageSegmentation/tree/master"
    },
    {
        "paper id": "2401.16853",
        "abstract url": "https://arxiv.org/abs/2401.16853",
        "title": "Transmission of Spatio-Temporal Correlated Sources Over Fading Multiple Access Channels With DQLC Mappings",
        "rating": "-10",
        "keywords": [],
        "abstract": "The design of zero-delay Joint Source-Channel Coding (JSCC) schemes for the transmission of correlated information over fading Multiple Access Channels (MACs) is an interesting problem for many communication scenarios like Wireless Sensor Networks (WSNs). Among the different JSCC schemes so far proposed for this scenario, Distributed Quantizer Linear Coding (DQLC) represents an appealing solution since it is able to outperform uncoded transmissions for any correlation level at high Signal-to-Noise Ratios (SNRs) with a low computational cost. In this paper, we extend the design of DQLC-based schemes for fading MACs considering sphere decoding to make the optimal Minimum Mean Squared Error (MMSE) estimation computationally affordable for an arbitrary number of transmit users. The use of sphere decoding also allows to formulate a practical algorithm for the optimization of DQLC-based systems. Finally, non-linear Kalman Filtering for the DQLC is considered to jointly exploit the temporal and spatial correlation of the source symbols. The results of computer experiments show that the proposed DQLC scheme with the Kalman Filter decoding approach clearly outperforms uncoded transmissions for medium and high SNRs.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16856",
        "abstract url": "https://arxiv.org/abs/2401.16856",
        "title": "BAR Nash Equilibrium and Application to Blockchain Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a novel solution concept, called BAR Nash Equilibrium (BARNE) and apply it to analyse the Verifier's dilemma, a fundamental problem in blockchain. Our solution concept adapts the Nash equilibrium (NE) to accommodate interactions among Byzantine, altruistic and rational agents, which became known as the BAR setting in the literature. We prove the existence of BARNE in a large class of games and introduce two natural refinements, global and local stability. Using this equilibrium and its refinement, we analyse the free-rider problem in the context of byzantine consensus. We demonstrate that by incorporating fines and forced errors into a standard quorum-based blockchain protocol, we can effectively reestablish honest behavior as a globally stable BARNE.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16858",
        "abstract url": "https://arxiv.org/abs/2401.16858",
        "title": "Low-Rate, Low-Distortion Compression with Wasserstein Distortion",
        "rating": "-10",
        "keywords": [],
        "abstract": "Wasserstein distortion is a one-parameter family of distortion measures that was recently proposed to unify fidelity and realism constraints. After establishing continuity results for Wasserstein in the extreme cases of pure fidelity and pure realism, we prove the first coding theorems for compression under Wasserstein distortion focusing on the regime in which both the rate and the distortion are small.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2310.03629"
    },
    {
        "paper id": "2401.16865",
        "abstract url": "https://arxiv.org/abs/2401.16865",
        "title": "Depends-Kotlin: A Cross-Language Kotlin Dependency Extractor",
        "rating": "-10",
        "keywords": [],
        "abstract": "Since Google introduced Kotlin as an official programming language for developing Android apps in 2017, Kotlin has gained widespread adoption in Android development. However, compared to Java, there is limited support for Kotlin code dependency analysis, which is the foundation to software analysis. To bridge this gap, we developed Depends-Kotlin to extract entities and their dependencies in Kotlin source code. Not only does Depends-Kotlin support extracting entities' dependencies in Kotlin code, but it can also extract dependency relations between Kotlin and Java. The extraction of such cross-language dependencies can help developers understand the migration process from Java to Kotlin. Additionally, we used a Java project with confirmed dependencies as a benchmark and converted this project to two projects: Kotlin-only and a combination of Kotlin and Java. The dependencies in these two projects were then extracted using our tool. The consistency observed among dependency relations in all three projects confirms the accuracy of Depends-Kotlin. Furthermore, the performance of Depends-Kotlin was assessed using another three projects of varying sizes. The source code of Depends-Kotlin and the dataset used in this demo paper have been uploaded to https://github.com/XYZboom/depends-kotlin. We also provided a screencast presenting Depends-Kotlin https://youtu.be/daZuXOwn1Ls.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16866",
        "abstract url": "https://arxiv.org/abs/2401.16866",
        "title": "New Centralized MSR Codes With Small Sub-packetization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Centralized repair refers to repairing $h\\geq 2$ node failures using $d$ helper nodes in a centralized way, where the repair bandwidth is counted by the total amount of data downloaded from the helper nodes. A centralized MSR code is an MDS array code with $(h,d)$-optimal repair for some $h$ and $d$. In this paper, we present several classes of centralized MSR codes with small sub-packetization. At first, we construct an alternative MSR code with $(1,d_i)$-optimal repair for multiple repair degrees $d_i$ simultaneously. Based on the code structure, we are able to construct a centralized MSR code with $(h_i,d_i)$-optimal repair property for all possible $(h_i,d_i)$ with $h_i\\mid (d_i-k)$ simultaneously. The sub-packetization is no more than ${\\rm lcm}(1,2,\\ldots,n-k)(n-k)^n$, which is much smaller than a previous work given by Ye and Barg ($({\\rm lcm}(1,2,\\ldots,n-k))^n$). Moreover, for general parameters $2\\leq h\\leq n-k$ and $k\\leq d\\leq n-h$, we further give a centralized MSR code enabling $(h,d)$-optimal repair with sub-packetization smaller than all previous works.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16871",
        "abstract url": "https://arxiv.org/abs/2401.16871",
        "title": "Node Flux-Linkage Synchronizing Control of Power Systems with 100% Wind Power Generation Based on Capacitor Voltage Balancing Scheme",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes a node flux-linkage synchronizing control method (NFSCM) for power systems with 100% wind power generation based on a capacitor voltage balancing scheme (CVBS). Different from the conventional grid-forming controllers, NFSCM is designed to regulate inverters as virtual flux-linkage sources. Auto-synchronization of flux-linkage vectors is achieved through the CVBS-based NFSCM. The mismatch among the angular frequencies of flux-linkage vectors is eliminated by regulating the tracking errors of DC-link voltages, which establishes a negative feedback between the output frequency and active power of the inverter. NFSCM is adaptive to weak and strong grids. It avoids the excitation inrush currents in the step-up transformer of wind power generators. It also eliminates the DC components of the three-phase currents, and avoids low-frequency oscillations in active power. In order to limit the short-circuit current of inverters, a logic-based bang-bang funnel control (LBFC) is designed to control the switches of inverter bridges when over-current is detected. LBFC is able to restrict various fault currents within an acceptable range within the shortest time. LBFC and NFSCM are designed to operate in a switched manner according to a state-dependent switching strategy. Time-domain simulations were conducted on a 100% wind power generation test system, and the performance of NFSCM and LBFC were investigated.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "9 pages, 9 figures"
    },
    {
        "paper id": "2401.16872",
        "abstract url": "https://arxiv.org/abs/2401.16872",
        "title": "A Scalable RISC-V Vector Processor Enabling Efficient Multi-Precision DNN Inference",
        "rating": "-10",
        "keywords": [],
        "abstract": "RISC-V processors encounter substantial challenges in deploying multi-precision deep neural networks (DNNs) due to their restricted precision support, constrained throughput, and suboptimal dataflow design. To tackle these challenges, a scalable RISC-V vector (RVV) processor, namely SPEED, is proposed to enable efficient multi-precision DNN inference by innovations from customized instructions, hardware architecture, and dataflow mapping. Firstly, dedicated customized RISC-V instructions are proposed based on RVV extensions, providing SPEED with fine-grained control over processing precision ranging from 4 to 16 bits. Secondly, a parameterized multi-precision systolic array unit is incorporated within the scalable module to enhance parallel processing capability and data reuse opportunities. Finally, a mixed multi-precision dataflow strategy, compatible with different convolution kernels and data precision, is proposed to effectively improve data utilization and computational efficiency. We perform synthesis of SPEED in TSMC 28nm technology. The experimental results demonstrate that SPEED achieves a peak throughput of 287.41 GOPS and an energy efficiency of 1335.79 GOPS/W at 4-bit precision condition, respectively. Moreover, when compared to the pioneer open-source vector processor Ara, SPEED provides an area efficiency improvement of 2.04$\\times$ and 1.63$\\times$ under 16-bit and 8-bit precision conditions, respectively, which shows SPEED's significant potential for efficient multi-precision DNN inference.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "The work is accepted by 2024 IEEE International Symposium on Circuits and Systems (ISCAS 2024)"
    },
    {
        "paper id": "2401.16879",
        "abstract url": "https://arxiv.org/abs/2401.16879",
        "title": "Optimal Control of a Stochastic Power System -- Algorithms and Mathematical Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "The considered optimal control problem of a stochastic power system, is to select the set of power supply vectors which infimizes the probability that the phase-angle differences of any power flow of the network, endangers the transient stability of the power system by leaving a critical subset. The set of control laws is restricted to be a periodically recomputed set of fixed power supply vectors based on predictions of power demand for the next short horizon. Neither state feedback nor output feedback is used. The associated control objective function is Lipschitz continuous, nondifferentiable, and nonconvex. The results of the paper include that a minimum exists in the value range of the control objective function. Furthermore, it includes a two-step procedure to compute an approximate minimizer based on two key methods: (1) a projected generalized subgradient method for computing an initial vector, and (2) a steepest descent method for approximating a local minimizer. Finally, it includes two convergence theorems that an approximation sequence converges to a local minimum.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "24 pages, 2 figures"
    },
    {
        "paper id": "2401.16888",
        "abstract url": "https://arxiv.org/abs/2401.16888",
        "title": "The Thins Ordering on Relations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Earlier papers \\cite{VB2022,VB2023a} introduced the notions of a core and an index of a relation (an index being a special case of a core). A limited form of the axiom of choice was postulated -- specifically that all partial equivalence relations (pers) have an index -- and the consequences of adding the axiom to axiom systems for point-free reasoning were explored. In this paper, we define a partial ordering on relations, which we call the \\textsf{thins} ordering. We show that our axiom of choice is equivalent to the property that core relations are the minimal elements of the \\textsf{thins} ordering. We also postulate a novel axiom that guarantees that, when \\textsf{thins} is restricted to non-empty pers, equivalence relations are maximal. This and other properties of \\textsf{thins} provide further evidence that our axiom of choice is a desirable means of strengthening point-free reasoning on relations. Although our novel axiom is valid for concrete relations and is a sufficient condition for characterising maximality, we show that it is not a necessary condition in the abstract point-free algebra. This leaves open the problem of deriving a necessary and sufficient condition.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16908",
        "abstract url": "https://arxiv.org/abs/2401.16908",
        "title": "A Rank-Constrained Coordinate Ascent Approach to Hybrid Precoding for the Downlink of Wideband Massive (MIMO) Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "An innovative approach to hybrid analog-digital precoding for the downlink of wideband massive MIMO systems is developed. The proposed solution, termed Rank-Constrained Coordinate Ascent (RCCA), starts seeking the full-digital precoder that maximizes the achievable sum-rate over all the frequency subcarriers while constraining the rank of the overall transmit covariance matrix. The frequency-flat constraint on the analog part of the hybrid precoder and the non-convex nature of the rank constraint are circumvented by transforming the original problem into a more suitable one, where a convenient structure for the transmit covariance matrix is imposed. Such structure makes the resulting full-digital precoder particularly adequate for its posterior analog-digital factorization. An additional problem formulation to determine an appropriate power allocation policy according to the rank constraint is also provided. The numerical results show that the proposed method outperforms baseline solutions even for practical scenarios with high spatial diversity.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16911",
        "abstract url": "https://arxiv.org/abs/2401.16911",
        "title": "Generalized Reed-Muller codes: A new construction of information sets",
        "rating": "-10",
        "keywords": [],
        "abstract": "In [2] we show how to construct information sets for Reed-Muller codes only in terms of their basic parameters. In this work we deal with the corresponding problem for q-ary Generalized Reed-Muller codes of first and second order. We see that for first-order codes the result for binary Reed-Muller codes is also valid, while for second-order codes, with q > 2, we have to manage more complex defining sets and we show that we get different information sets. We also present some examples and associated open problems.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2401.10109"
    },
    {
        "paper id": "2401.16915",
        "abstract url": "https://arxiv.org/abs/2401.16915",
        "title": "Interactive Byzantine-Resilient Gradient Coding for General Data Assignments",
        "rating": "-10",
        "keywords": [],
        "abstract": "We tackle the problem of Byzantine errors in distributed gradient descent within the Byzantine-resilient gradient coding framework. Our proposed solution can recover the exact full gradient in the presence of $s$ malicious workers with a data replication factor of only $s+1$. It generalizes previous solutions to any data assignment scheme that has a regular replication over all data samples. The scheme detects malicious workers through additional interactive communication and a small number of local computations at the main node, leveraging group-wise comparisons between workers with a provably optimal grouping strategy. The scheme requires at most $s$ interactive rounds that incur a total communication cost logarithmic in the number of data samples.",
        "subjects": [
            "cs.IT",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16918",
        "abstract url": "https://arxiv.org/abs/2401.16918",
        "title": "On egalitarian values for cooperative games with a priori unions",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we extend the equal division and the equal surplus division values for transferable utility cooperative games to the more general setup of transferable utility cooperative games with a priori unions. In the case of the equal surplus division value we propose three possible extensions. We provide axiomatic characterizations of the new values. Furthermore, we apply the proposed modifications to a particular cost sharing problem and compare the numerical results with those obtained with the original values.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16926",
        "abstract url": "https://arxiv.org/abs/2401.16926",
        "title": "Coordination Coding with Causal Encoder for Vector-valued Witsenhausen Counterexample",
        "rating": "-10",
        "keywords": [],
        "abstract": "We investigate the Witsenhausen counterexample in a continuous vector-valued context with a causal encoder and noncausal decoder. Our main result is the optimal single-letter condition that characterizes the set of achievable Witsenhausen power costs and estimation costs, leveraging a modified weak typicality approach. In particular, we accommodate our power analysis to the causal encoder constraint, and provide an improved distortion error analysis for the challenging estimation of the interim state. Interestingly, the idea of dual role of control is explicitly captured by the two auxiliary random variables.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "This work has been submitted to 2024 IEEE International Symposium on Information Theory (ISIT 2024)"
    },
    {
        "paper id": "2401.16930",
        "abstract url": "https://arxiv.org/abs/2401.16930",
        "title": "Necessary players and values",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we introduce the $\u0393$ value, a new value for cooperative games with transferable utility. We also provide an axiomatic characterization of the $\u0393$ value based on a property concerning the so-called necessary players. A necessary players of a game is one without which the characteristic function is zero. We illustrate the performance of the $\u0393$ value in a particular cost allocation problem that arises when the owners of the apartments in a building plan to install an elevator and share its installation cost; in the resulting example we compare the proposals of the $\u0393$ value, the equal division value and the Shapley value in two different scenarios. In addition, we propose an extension of the $\u0393$ value for cooperative games with transferable utility and with a coalition structure. Finally, we provide axiomatic characterizations of the coalitional $\u0393$ value and of the Owen and Banzhaf-Owen values using alternative properties concerning necessary players.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16938",
        "abstract url": "https://arxiv.org/abs/2401.16938",
        "title": "On egalitarian values for cooperative games with level structures",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we extend the equal division and the equal surplus division values for transferable utility cooperative games to the more general setup of transferable utility cooperative games with level structures. In the case of the equal surplus division value we propose three possible extensions, one of which has already been described in the literature. We provide axiomatic characterizations of the values considered, apply them to a particular cost sharing problem and compare them in the framework of such an application.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16942",
        "abstract url": "https://arxiv.org/abs/2401.16942",
        "title": "Robust Price Discrimination",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a model of third-degree price discrimination, in which the seller has a valuation for the product which is unknown to the market designer, who aims to maximize the buyers' surplus by revealing information regarding the buyer's valuation to the seller. Our main result shows that the regret is bounded by $U^*(0)/e$, where $U^*(0)$ is the optimal buyer surplus in the case where the seller has zero valuation for the product. This bound is attained by randomly drawing a seller valuation and applying the segmentation of Bergemann et al. (2015) with respect to the drawn valuation. We show that the $U^*(0)/e$ bound is tight in the case of binary buyer valuation.",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16952",
        "abstract url": "https://arxiv.org/abs/2401.16952",
        "title": "Lattice-Based Analog Mappings for Low-Latency Wireless Sensor Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider the transmission of spatially correlated analog information in a wireless sensor network (WSN) through fading single-input and multiple-output (SIMO) multiple access channels (MACs) with low-latency requirements. A lattice-based analog joint source-channel coding (JSCC) approach is considered where vectors of consecutive source symbols are encoded at each sensor using an n-dimensional lattice and then transmitted to a multiantenna central node. We derive a minimum mean square error (MMSE) decoder that accounts for both the multidimensional structure of the encoding lattices and the spatial correlation. In addition, a sphere decoder is considered to simplify the required searches over the multidimensional lattices. Different lattice-based mappings are approached and the impact of their size and density on performance and latency is analyzed. Results show that, while meeting low-latency constraints, lattice-based analog JSCC provides performance gains and higher reliability with respect to the state-of-the-art JSCC schemes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16956",
        "abstract url": "https://arxiv.org/abs/2401.16956",
        "title": "BCM-Broadcast: A Byzantine-Tolerant Causal Broadcast Algorithm for Distributed Mobile Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an algorithm, called BCM-Broadcast, for the implementation of causal broadcast in distributed mobile systems in the presence of Byzantine failures. The BCM-Broadcast algorithm simultaneously focuses on three critical challenges in distributed systems: Byzantine failures, Causality, and Mobility. We first present a hierarchical architecture for BCM-Broadcast. Then, we define twelve properties for BCM-Broadcast, including validity, integrity, termination, and causality. We then show that BCM-Broadcast satisfies all these properties. We also prove the safety of BCM-Broadcast; i.e., no healthy process delivers a message from any Byzantine process, assuming that the number of Byzantine processes is less than a third of the total number of mobile nodes. Subsequently, we show that the message complexity of BCM-Broadcast is linear. Finally, using the Poisson process, we analyze the probability of the violation of the safety condition under different mobility scenarios.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16958",
        "abstract url": "https://arxiv.org/abs/2401.16958",
        "title": "Exact SINR Analysis of Matched-filter Precoder",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper answers a fundamental question about the exact distribution of the signal-to-interference-plus-noise ratio (SINR) under matched-filter (MF) precoding. Specifically, we derive the exact expressions for the cumulative distribution function (CDF) and the probability density function (PDF) of SINR under MF precoding over Rayleigh fading channels. Based on the exact analysis, we then rigorously prove that the SINR converges to some specific distributions separately in high SNR and in massive MIMO. To simplify the exact result in general cases, we develop a good approximation by modelling the interference as a Beta distribution. We then shift to the exact analysis of the transmit rate, and answer the fundamental question: How does the exact rate converge to the well-known asymptotic rate in massive MIMO? After that, we propose a novel approximation for the ergodic rate, which performs better than various existing approximations. Finally, we present some numerical results to demonstrate the accuracy of the derived analytical models.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 3 figures"
    },
    {
        "paper id": "2401.16965",
        "abstract url": "https://arxiv.org/abs/2401.16965",
        "title": "Design of Downlink Hybrid NOMA Transmission",
        "rating": "-10",
        "keywords": [],
        "abstract": "The aim of this paper is to develop hybrid non-orthogonal multiple access (NOMA) assisted downlink transmission. First, for the single-input single-output (SISO) scenario, i.e., each node is equipped with a single antenna, a novel hybrid NOMA scheme is introduced, where NOMA is implemented as an add-on of a legacy time division multiple access (TDMA) network. Because of the simplicity of the SISO scenario, analytical results can be developed to reveal important properties of downlink hybrid NOMA. For example, in the case that the users' channel gains are ordered and the durations of their time slots are the same, downlink hybrid NOMA is shown to always outperform TDMA, which is different from the existing conclusion for uplink hybrid NOMA. Second, the proposed downlink SISO hybrid NOMA scheme is extended to the multiple-input single-output (MISO) scenario, i.e., the base station has multiple antennas. For the MISO scenario, near-field communication is considered to illustrate how NOMA can be used as an add-on in legacy networks based on space division multiple access and TDMA. Simulation results verify the developed analytical results and demonstrate the superior performance of downlink hybrid NOMA compared to conventional orthogonal multiple access.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16969",
        "abstract url": "https://arxiv.org/abs/2401.16969",
        "title": "Taxonomy of Mathematical Plagiarism",
        "rating": "-10",
        "keywords": [],
        "abstract": "Plagiarism is a pressing concern, even more so with the availability of large language models. Existing plagiarism detection systems reliably find copied and moderately reworded text but fail for idea plagiarism, especially in mathematical science, which heavily uses formal mathematical notation. We make two contributions. First, we establish a taxonomy of mathematical content reuse by annotating potentially plagiarised 122 scientific document pairs. Second, we analyze the best-performing approaches to detect plagiarism and mathematical content similarity on the newly established taxonomy. We found that the best-performing methods for plagiarism and math content similarity achieve an overall detection score (PlagDet) of 0.06 and 0.16, respectively. The best-performing methods failed to detect most cases from all seven newly established math similarity types. Outlined contributions will benefit research in plagiarism detection systems, recommender systems, question-answering systems, and search engines. We make our experiment's code and annotated dataset available to the community: https://github.com/gipplab/Taxonomy-of-Mathematical-Plagiarism",
        "subjects": [
            "cs.IR"
        ],
        "comment": "46th European Conference on Information Retrieval (ECIR)"
    },
    {
        "paper id": "2401.16971",
        "abstract url": "https://arxiv.org/abs/2401.16971",
        "title": "Autonomy Loops for Monitoring, Operational Data Analytics, Feedback, and Response in HPC Operations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many High Performance Computing (HPC) facilities have developed and deployed frameworks in support of continuous monitoring and operational data analytics (MODA) to help improve efficiency and throughput. Because of the complexity and scale of systems and workflows and the need for low-latency response to address dynamic circumstances, automated feedback and response have the potential to be more effective than current human-in-the-loop approaches which are laborious and error prone. Progress has been limited, however, by factors such as the lack of infrastructure and feedback hooks, and successful deployment is often site- and case-specific. In this position paper we report on the outcomes and plans from a recent Dagstuhl Seminar, seeking to carve a path for community progress in the development of autonomous feedback loops for MODA, based on the established formalism of similar (MAPE-K) loops in autonomous computing and self-adaptive systems. By defining and developing such loops for significant cases experienced across HPC sites, we seek to extract commonalities and develop conventions that will facilitate interoperability and interchangeability with system hardware, software, and applications across different sites, and will motivate vendors and others to provide telemetry interfaces and feedback hooks to enable community development and pervasive deployment of MODA autonomy loops.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16975",
        "abstract url": "https://arxiv.org/abs/2401.16975",
        "title": "Method for determining the acceleration of a parallel specialised computer system based on Amdahl's law",
        "rating": "-10",
        "keywords": [],
        "abstract": "The modification of Amdahl's law for the case of increment of processor elements in a computer system is considered. The coefficient $k$ linking accelerations of parallel and parallel specialized computer systems is determined. The limiting values of the coefficient are investigated and its theoretical maximum is calculated. It is proved that $k$ > 1 for any positive increment of processor elements. The obtained formulas are combined into a single method allowing to determine the maximum theoretical acceleration of a parallel specialized computer system in comparison with the acceleration of a minimal parallel computer system. The method is tested on Apriori, k-nearest neighbors, CDF 9/7, fast Fourier transform and naive Bayesian classifier algorithms.",
        "subjects": [
            "cs.DC",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.16977",
        "abstract url": "https://arxiv.org/abs/2401.16977",
        "title": "Performance Analysis of Generalized Product Codes with Irregular Degree Distribution",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the theoretical analysis of intrinsic message passing decoding for generalized product codes (GPCs) with irregular degree distributions, a generalization of product codes that allows every code bit to be protected by a minimum of two and potentially more component codes. We derive a random hypergraph-based asymptotic performance analysis for GPCs, extending previous work that considered the case where every bit is protected by exactly two component codes. The analysis offers a new tool to guide the code design of GPCs by providing insights into the influence of degree distributions on the performance of GPCs.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "ISIT 2024 accepted version"
    },
    {
        "paper id": "2401.16979",
        "abstract url": "https://arxiv.org/abs/2401.16979",
        "title": "Re3val: Reinforced and Reranked Generative Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "Generative retrieval models encode pointers to information in a corpus as an index within the model's parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can't be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from the KILT database using the rerank page titles. Upon grounding the top five reranked contexts, Re3val demonstrates the Top 1 KILT scores compared to all other generative retrieval models across five KILT datasets.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "17 pages, 4 figures, Findings of the Association for Computational Linguistics: EACL 2023"
    },
    {
        "paper id": "2401.16997",
        "abstract url": "https://arxiv.org/abs/2401.16997",
        "title": "Spatial Distribution of Data Capacity for the Reduction of Number of Repeaters in Ultra Long-Haul Links",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a novel method to reduce the number of repeaters and amplifiers in trans-oceanic links by distributing a given data capacity in spatial channels. We analytically, numerically and experimentally demonstrate the principle and show that about 40% of the repeaters can be omitted compared to a recently deployed cable. The method predicts that a single-fiber transmission link with 50 km amplifier spacing would be better off, repeater-wise, if the targeted single-fiber capacity is distributed in two fibers, each with an amplifier spacing of 150 km. In this scenario, one would thus only require 2/3 of the original number of amplifiers, and only 1/3 of the number of repeaters, housing the amplifiers. To test the principle of the proposed method, we experimentally and numerically investigate a 6900-km long link with amplifier spacing of 50 and 150 km using a recirculating fiber transmission loop,and find that the result supports the analytical model and thus the proposed method. We then use this concept to analytically investigate a realistic 12-fiber pair cable, and find that the same capacity could be distributed in 16 fiber pairs requiring only about 60% of the original number of repeaters.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to Journal of Lightwave Technology"
    },
    {
        "paper id": "2401.16998",
        "abstract url": "https://arxiv.org/abs/2401.16998",
        "title": "The Sherali-Adams and Weisfeiler-Leman hierarchies in (Promise Valued) Constraint Satisfaction Problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study the interactions between so-called fractional relaxations of the integer programs (IPs) which encode homomorphism and isomorphism of relational structures. We give a combinatorial characterization of a certain natural linear programming (LP) relaxation of homomorphism in terms of fractional isomorphism. As a result, we show that the families of constraint satisfaction problems (CSPs) that are solvable by such linear program are precisely those that are closed under an equivalence relation which we call Weisfeiler-Leman invariance. We also generalize this result to the much broader framework of Promise Valued Constraint Satisfaction Problems, which brings together two well-studied extensions of the CSP framework. Finally, we consider the hierarchies of increasingly tighter relaxations of the homomorphism and isomorphism IPs obtained by applying the Sherali-Adams and Weisfeiler-Leman methods respectively. We extend our combinatorial characterization of the basic LP to higher levels of the Sherali-Adams hierarchy, and we generalize a well-known logical characterization of the Weisfeiler-Leman test from graphs to relational structures.",
        "subjects": [
            "cs.DS",
            "cs.LO"
        ],
        "comment": "A joint extended version of arXiv:2107.02956 and arXiv:2205.04805"
    },
    {
        "paper id": "2401.17005",
        "abstract url": "https://arxiv.org/abs/2401.17005",
        "title": "SAL-PIM: A Subarray-level Processing-in-Memory Architecture with LUT-based Linear Interpolation for Transformer-based Text Generation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Text generation is a compelling sub-field of natural language processing, aiming to generate human-readable text from input words. In particular, the decoder-only generative models, such as generative pre-trained transformer (GPT), are widely used for text generation, with two major computational stages: summarization and generation. Unlike the summarization stage, which can process the input tokens in parallel, the generation stage is difficult to accelerate due to its sequential generation of output tokens through iteration. Moreover, each iteration requires reading a whole model with little data reuse opportunity. Therefore, the workload of transformer-based text generation is severely memory-bound, making the external memory bandwidth system bottleneck. In this paper, we proposed a subarray-level processing-in-memory architecture named SAL-PIM, HBM-based PIM architecture for the end-to-end acceleration of transformer-based text generation. The SAL-PIM architecture includes three architectural features. First, the SAL-PIM architecture utilizes higher internal bandwidth by integrating multiple subarray-level arithmetic logic units with optimized data mapping schemes. Second, the SAL-PIM architecture adopts LUT-based linear interpolation to perform complex non-linear functions in PIM. Third, the SAL-PIM architecture accelerates end-to-end inference on PIM in text generation. Furthermore, to validate the SAL-PIM architecture, we built cycle-accurate simulator and implemented the SAL-PIM's logic units in 28-nm CMOS technology. As a result, when the input size is from 32 to 128 and the output size is from 1 to 256, SAL-PIM achieves a maximum of 4.72 times speedup and an average of 1.83 times speedup for the text generation based on the GPT-2 medium model compared to the server-level GPU.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "14 pages, 15 figures"
    },
    {
        "paper id": "2401.17011",
        "abstract url": "https://arxiv.org/abs/2401.17011",
        "title": "Age of Actuated Information and Age of Actuation in a Data-Caching Energy Harvesting Actuator",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce two metrics, namely, age of actuation (AoA) and age of actuated information (AoAI), within a discrete-time system model that integrates data caching and energy harvesting (EH). AoA evaluates the timeliness of actions irrespective of the age of the information, while AoAI considers the freshness of the utilized data packet. We use Markov Chain analysis to model the system's evolution. Furthermore, we employ three-dimensional Markov Chain analysis to characterize the stationary distributions for AoA and AoAI and calculate their average values. Our findings from the analysis, validated by simulations, show that while AoAI consistently decreases with increased data and energy packet arrival rates, AoA presents a more complex behavior, with potential increases under conditions of limited data or energy resources. These metrics go towards the semantics of information and goal-oriented communications since they consider the timeliness of utilizing the information to perform an action.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17012",
        "abstract url": "https://arxiv.org/abs/2401.17012",
        "title": "On the Algorithmic Verification of Nonlinear Superposition for Systems of First Order Ordinary Differential Equations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper belongs to a group of work in the intersection of symbolic computation and group analysis aiming for the symbolic analysis of differential equations. The goal is to extract important properties without finding the explicit general solution. In this contribution, we introduce the algorithmic verification of nonlinear superposition properties and its implementation. More exactly, for a system of nonlinear ordinary differential equations of first order with a polynomial right-hand side, we check if the differential system admits a general solution by means of a superposition rule and a certain number of particular solutions. It is based on the theory of Newton polytopes and associated symbolic computation. The developed method provides the basis for the identification of nonlinear superpositions within a given system and for the construction of numerical methods which preserve important algebraic properties at the numerical level.",
        "subjects": [
            "cs.SC",
            "math.NA",
            "math.RA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17018",
        "abstract url": "https://arxiv.org/abs/2401.17018",
        "title": "GPU-Accelerated Batch-Dynamic Subgraph Matching",
        "rating": "-10",
        "keywords": [],
        "abstract": "Subgraph matching has garnered increasing attention for its diverse real-world applications. Given the dynamic nature of real-world graphs, addressing evolving scenarios without incurring prohibitive overheads has been a focus of research. However, existing approaches for dynamic subgraph matching often proceed serially, retrieving incremental matches for each updated edge individually. This approach falls short when handling batch data updates, leading to a decrease in system throughput. Leveraging the parallel processing power of GPUs, which can execute a massive number of cores simultaneously, has been widely recognized for performance acceleration in various domains. Surprisingly, systematic exploration of subgraph matching in the context of batch-dynamic graphs, particularly on a GPU platform, remains untouched. In this paper, we bridge this gap by introducing an efficient framework, GAMMA (GPU-Accelerated Batch-Dynamic Subgraph Matching). Our approach features a DFS-based warp-centric batch-dynamic subgraph matching algorithm. To ensure load balance in the DFS-based search, we propose warp-level work stealing via shared memory. Additionally, we introduce coalesced search to reduce redundant computations. Comprehensive experiments demonstrate the superior performance of GAMMA. Compared to state-of-the-art algorithms, GAMMA showcases a performance improvement up to hundreds of times.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "This paper has been accepted by ICDE 2024"
    },
    {
        "paper id": "2401.17019",
        "abstract url": "https://arxiv.org/abs/2401.17019",
        "title": "Towards Generating Executable Metamorphic Relations Using Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Metamorphic testing (MT) has proven to be a successful solution to automating testing and addressing the oracle problem. However, it entails manually deriving metamorphic relations (MRs) and converting them into an executable form; these steps are time-consuming and may prevent the adoption of MT. In this paper, we propose an approach for automatically deriving executable MRs (EMRs) from requirements using large language models (LLMs). Instead of merely asking the LLM to produce EMRs, our approach relies on a few-shot prompting strategy to instruct the LLM to perform activities in the MT process, by providing requirements and API specifications, as one would do with software engineers. To assess the feasibility of our approach, we conducted a questionnaire-based survey in collaboration with Siemens Industry Software, focusing on four of their software applications. Additionally, we evaluated the accuracy of the generated EMRs for a web application. The outcomes of our study are highly promising, as they demonstrate the capability of our approach to generate MRs and EMRs that are both comprehensible and pertinent for testing purposes.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17049",
        "abstract url": "https://arxiv.org/abs/2401.17049",
        "title": "Movable Antenna-Enabled Co-Frequency Co-Time Full-Duplex Wireless Communication",
        "rating": "-10",
        "keywords": [],
        "abstract": "Movable antenna (MA) provides an innovative way to arrange antennas that can contribute to improved signal quality and more effective interference management. This method is especially beneficial for co-frequency co-time full-duplex (CCFD) wireless communication, which struggles with self-interference (SI) that usually overpowers the desired incoming signals. By dynamically repositioning transmit/receive antennas, we can mitigate the SI and enhance the reception of incoming signals. Thus, this paper proposes a novel MA-enabled point-to-point CCFD system and formulates the minimum achievable rate of two CCFD terminals. To maximize the minimum achievable rate and determine the near-optimal positions of the MAs, we introduce a solution based on projected particle swarm optimization (PPSO), which can circumvent common suboptimal positioning issues. Moreover, numerical results reveal that the PPSO method leads to a better performance compared to the conventional alternating position optimization (APO). The results also demonstrate that an MA-enabled CCFD system outperforms the one using fixed-position antennas (FPAs).",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "This paper has been submitted to IEEE Wireless Communications Letters"
    },
    {
        "paper id": "2401.17059",
        "abstract url": "https://arxiv.org/abs/2401.17059",
        "title": "Learning Approximation Sets for Exploratory Queries",
        "rating": "-10",
        "keywords": [],
        "abstract": "In data exploration, executing complex non-aggregate queries over large databases can be time-consuming. Our paper introduces a novel approach to address this challenge, focusing on finding an optimized subset of data, referred to as the approximation set, for query execution. The goal is to maximize query result quality while minimizing execution time. We formalize this problem as Approximate Non-Aggregates Query Processing (ANAQP) and establish its NP-completeness. To tackle this, we propose an approximate solution using advanced Reinforcement Learning architecture, termed ASQP-RL. This approach overcomes challenges related to the large action space and the need for generalization beyond a known query workload. Experimental results on two benchmarks demonstrate the superior performance of ASQP-RL, outperforming baselines by 30% in accuracy and achieving efficiency gains of 10-35X. Our research sheds light on the potential of reinforcement learning techniques for advancing data management tasks. Experimental results on two benchmarks show that ASQP-RL significantly outperforms the baselines both in terms of accuracy (30% better) and efficiency (10-35X). This research provides valuable insights into the potential of RL techniques for future advancements in data management tasks.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17084",
        "abstract url": "https://arxiv.org/abs/2401.17084",
        "title": "On $2 \\times 2$ MIMO Gaussian Channels with a Small Discrete-Time Peak-Power Constraint",
        "rating": "-10",
        "keywords": [],
        "abstract": "A multi-input multi-output (MIMO) Gaussian channel with two transmit antennas and two receive antennas is studied that is subject to an input peak-power constraint. The capacity and the capacity-achieving input distribution are unknown in general. The problem is shown to be equivalent to a channel with an identity matrix but where the input lies inside and on an ellipse with principal axis length $r_p$ and minor axis length $r_m$. If $r_p \\le \\sqrt{2}$, then the capacity-achieving input has support on the ellipse. A sufficient condition is derived under which a two-point distribution is optimal. Finally, if $r_m < r_p \\le \\sqrt{2}$, then the capacity-achieving distribution is discrete.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "8 pages, 1 figure. Submitted to IEEE ISIT 2024"
    },
    {
        "paper id": "2401.17089",
        "abstract url": "https://arxiv.org/abs/2401.17089",
        "title": "Copula-based Estimation of Continuous Sources for a Class of Constrained Rate-Distortion-Functions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a new method to estimate the rate-distortion-perception function in the perfect realism regime (PR-RDPF), for multivariate continuous sources subject to a single-letter average distortion constraint. The proposed approach is not only able to solve the specific problem but also two related problems: the entropic optimal transport (EOT) and the output-constrained rate-distortion function (OC-RDF), of which the PR-RDPF represents a special case. Using copula distributions, we show that the OC-RDF can be cast as an I-projection problem on a convex set, based on which we develop a parametric solution of the optimal projection proving that its parameters can be estimated, up to an arbitrary precision, via the solution of a convex program. Subsequently, we propose an iterative scheme via gradient methods to estimate the convex program. Lastly, we characterize a Shannon lower bound (SLB) for the PR-RDPF under a mean squared error (MSE) distortion constraint. We support our theoretical findings with numerical examples by assessing the estimation performance of our iterative scheme using the PR-RDPF with the obtained SLB for various sources.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17094",
        "abstract url": "https://arxiv.org/abs/2401.17094",
        "title": "Constructing rotatable permutations of $\\mathbb{F}_{2^m}^3$ with $3$-homogeneous functions",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the literature, there are many results about permutation polynomials over finite fields. However, very few permutations of vector spaces are constructed although it has been shown that permutations of vector spaces have many applications in cryptography, especially in constructing permutations with low differential and boomerang uniformities. In this paper, motivated by the butterfly structure \\cite{perrin2016cryptanalysis} and the work of Qu and Li \\cite{qu2023}, we investigate rotatable permutations from $\\gf_{2^m}^3$ to itself with $d$-homogenous functions. Based on the theory of equations of low degree, the resultant of polynomials, and some skills of exponential sums, we construct five infinite classes of $3$-homogeneous rotatable permutations from $\\gf_{2^m}^3$ to itself, where $m$ is odd. Moreover, we demonstrate that the corresponding permutation polynomials of $\\gf_{2^{3m}}$ of our newly constructed permutations of $\\gf_{2^m}^3$ are QM-inequivalent to the known ones.",
        "subjects": [
            "math.CO",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17100",
        "abstract url": "https://arxiv.org/abs/2401.17100",
        "title": "The Influence of Presentation and Performance on User Satisfaction",
        "rating": "-10",
        "keywords": [],
        "abstract": "The effectiveness of an IR system is gauged not just by its ability to retrieve relevant results but also by how it presents these results to users; an engaging presentation often correlates with increased user satisfaction. While existing research has delved into the link between user satisfaction, IR performance metrics, and presentation, these aspects have typically been investigated in isolation. Our research aims to bridge this gap by examining the relationship between query performance, presentation and user satisfaction. For our analysis, we conducted a between-subjects experiment comparing the effectiveness of various result card layouts for an ad-hoc news search interface. Drawing data from the TREC WaPo 2018 collection, we centered our study on four specific topics. Within each of these topics, we assessed six distinct queries with varying nDCG values. Our study involved 164 participants who were exposed to one of five distinct layouts containing result cards, such as \"title'', \"title+image'', or \"title+image+summary''. Our findings indicate that while nDCG is a strong predictor of user satisfaction at the query level, there exists no linear relationship between the performance of the query, presentation of results and user satisfaction. However, when considering the total gain on the initial result page, we observed that presentation does play a significant role in user satisfaction (at the query level) for certain layouts with result cards such as, title+image or title+image+summary. Our results also suggest that the layout differences have complex and multifaceted impacts on satisfaction. We demonstrate the capacity to equalize user satisfaction levels between queries of varying performance by changing how results are presented. This emphasizes the necessity to harmonize both performance and presentation in IR systems, considering users' diverse preferences.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "comment": "To appear as a full paper at CHIIR 2024, Sheffield, UK"
    },
    {
        "paper id": "2401.17112",
        "abstract url": "https://arxiv.org/abs/2401.17112",
        "title": "On the Mod-6 Town Rules",
        "rating": "-10",
        "keywords": [],
        "abstract": "This note presents an upper bound of $1.252 n$ on the size of a set system that satisfies the mod-6 town rules. Under these rules the sizes of the sets are not congruent to $0\\bmod 6$ while the sizes of all pairwise intersections are congruent to $ 0\\bmod 6$.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "Bug. Lemma 1 is incorrect. The lemma needs the sets to be closed under subtraction which they are not"
    },
    {
        "paper id": "2401.17117",
        "abstract url": "https://arxiv.org/abs/2401.17117",
        "title": "A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements",
        "rating": "-10",
        "keywords": [],
        "abstract": "Vision-based estimation of the motion of a moving target is usually formulated as a bearing-only estimation problem where the visual measurement is modeled as a bearing vector. Although the bearing-only approach has been studied for decades, a fundamental limitation of this approach is that it requires extra lateral motion of the observer to enhance the target's observability. Unfortunately, the extra lateral motion conflicts with the desired motion of the observer in many tasks. It is well-known that, once a target has been detected in an image, a bounding box that surrounds the target can be obtained. Surprisingly, this common visual measurement especially its size information has not been well explored up to now. In this paper, we propose a new bearing-angle approach to estimate the motion of a target by modeling its image bounding box as bearing-angle measurements. Both theoretical analysis and experimental results show that this approach can significantly enhance the observability without relying on additional lateral motion of the observer. The benefit of the bearing-angle approach comes with no additional cost because a bounding box is a standard output of object detection algorithms. The approach simply exploits the information that has not been fully exploited in the past. No additional sensing devices or special detection algorithms are required.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17122",
        "abstract url": "https://arxiv.org/abs/2401.17122",
        "title": "Study of Applicability of Simple Closed Loop Input Impedance Model for Grid-Tie Inverters",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years the need for DC distribution buses has increased considerably. As it can be noticed in the transport for example the distribution systems of the more electric aircrafts, ships, or electric cars. Given the complexities of the systems presented above, the need to use more and more switched power converters has arisen. The main problem of the connection of multiple controlled switched converters acting as source and load is the degradation of stability that occurs on the DC distribution bus due to the converter interactions. To study the stability in the distribution bus there are some wellestablished criteria. These criteria require knowledge of the input impedance of the converters that act as load and the output impedance of the equipment that acts as source. In order to reduce the complexity of obtaining the input impedance a model based on a controlled converter acting as a constant power load (CPL) is commonly used. This article studies the accuracy of this model for a commonly used topology in distribution systems nowadays, Two Level Voltage Source Converter (2L-VSC), studying different scenarios that make the model become inaccurate.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17125",
        "abstract url": "https://arxiv.org/abs/2401.17125",
        "title": "Characterising resource management performance in Kubernetes",
        "rating": "-10",
        "keywords": [],
        "abstract": "A key challenge for supporting elastic behaviour in cloud systems is to achieve a good performance in automated (de-)provisioning and scheduling of computing resources. One of the key aspects that can be significant is the overheads associated with deploying, terminating and maintaining resources. Therefore, due to their lower start up and termination overhead, containers are rapidly replacing Virtual Machines (VMs) in many cloud deployments, as the computation instance of choice. In this paper, we analyse the performance of Kubernetes achieved through a Petri net-based performance model. Kubernetes is a container management system for a distributed cluster environment. Our model can be characterised using data from a Kubernetes deployment, and can be exploited for supporting capacity planning and designing Kubernetes-based elastic applications.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2401.17130",
        "abstract url": "https://arxiv.org/abs/2401.17130",
        "title": "Diagonals and Block-Ordered Relations",
        "rating": "-10",
        "keywords": [],
        "abstract": "More than 70 years ago, Jaques Riguet suggested the existence of an ``analogie frappante'' (striking analogy) between so-called ``relations de Ferrers'' and a class of difunctional relations, members of which we call ``diagonals''. Inspired by his suggestion, we formulate an ``analogie frappante'' linking the notion of a block-ordered relation and the notion of the diagonal of a relation. We formulate several novel properties of the core/index of a diagonal, and use these properties to rephrase our ``analogie frappante''. Loosely speaking, we show that a block-ordered relation is a provisional ordering up to isomorphism and reduction to its core. (Our theorems make this informal statement precise.) Unlike Riguet (and others who follow his example), we avoid almost entirely the use of nested complements to express and reason about properties of these notions: we use factors (aka residuals) instead. The only (and inevitable) exception to this is to show that our definition of a ``staircase'' relation is equivalent to Riguet's definition of a ``relation de Ferrers''. Our ``analogie frappante'' also makes it obvious that a ``staircase'' relation is not necessarily block-ordered, in spite of the mental picture of such a relation presented by Riguet.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17134",
        "abstract url": "https://arxiv.org/abs/2401.17134",
        "title": "Wrist movement classification for adaptive mobile phone based rehabilitation of children with motor skill impairments",
        "rating": "-10",
        "keywords": [],
        "abstract": "Rehabilitation exercises performed by children with cerebral palsy are tedious and repetitive. To make them more engaging, we propose to use an exergame approach, where an adaptive application can help the child remain stimulated and interested during exercises. In this paper, we describe how the mobile phone sensors can be used to classify wrist movements of the user during the rehabilitation exercises to detect if the user is performing the correct exercise and illustrate the use of our approach in an actual mobile phone application. We also show how an adaptive difficulty system was added to the application to allow the system to adjust to the user. We present experimental results from a pilot with healthy subjects that were constrained to simulate restricted wrist movements, as well as from tests with a target group of children with cerebral palsy. Our results show that wrist movement classification is successfully achieved and results in improved interactions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "25 pages, 11 figures"
    },
    {
        "paper id": "2401.17150",
        "abstract url": "https://arxiv.org/abs/2401.17150",
        "title": "GAISSALabel: A tool for energy labeling of ML models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Background: The increasing environmental impact of Information Technologies, particularly in Machine Learning (ML), highlights the need for sustainable practices in software engineering. The escalating complexity and energy consumption of ML models need tools for assessing and improving their energy efficiency. Goal: This paper introduces GAISSALabel, a web-based tool designed to evaluate and label the energy efficiency of ML models. Method: GAISSALabel is a technology transfer development from a former research on energy efficiency classification of ML, consisting of a holistic tool for assessing both the training and inference phases of ML models, considering various metrics such as power draw, model size efficiency, CO2e emissions and more. Results: GAISSALabel offers a labeling system for energy efficiency, akin to labels on consumer appliances, making it accessible to ML stakeholders of varying backgrounds. The tool's adaptability allows for customization in the proposed labeling system, ensuring its relevance in the rapidly evolving ML field. Conclusions: GAISSALabel represents a significant step forward in sustainable software engineering, offering a solution for balancing high-performance ML models with environmental impacts. The tool's effectiveness and market relevance will be further assessed through planned evaluations using the Technology Acceptance Model.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "4 pages, 2 figures, 1 table"
    },
    {
        "paper id": "2401.17163",
        "abstract url": "https://arxiv.org/abs/2401.17163",
        "title": "Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Conditionally accepted (with minor revisions) by Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)"
    },
    {
        "paper id": "2401.17168",
        "abstract url": "https://arxiv.org/abs/2401.17168",
        "title": "Stale Profile Matching",
        "rating": "-10",
        "keywords": [],
        "abstract": "Profile-guided optimizations rely on profile data for directing compilers to generate optimized code. To achieve the maximum performance boost, profile data needs to be collected on the same version of the binary that is being optimized. In practice however, there is typically a gap between the profile collection and the release, which makes a portion of the profile invalid for optimizations. This phenomenon is known as profile staleness, and it is a serious practical problem for data-center workloads both for compilers and binary optimizers. In this paper we thoroughly study the staleness problem and propose the first practical solution for utilizing profiles collected on binaries built from several revisions behind the release. Our algorithm is developed and implemented in a mainstream open-source post-link optimizer, BOLT. An extensive evaluation on a variety of standalone benchmarks and production services indicates that the new method recovers up to $0.8$ of the maximum BOLT benefit, even when most of the input profile data is stale and would have been discarded by the optimizer otherwise.",
        "subjects": [
            "cs.PL",
            "cs.SE"
        ],
        "comment": "ACM SIGPLAN 33rd International Conference on Compiler Construction (CC 2024)"
    },
    {
        "paper id": "2401.17175",
        "abstract url": "https://arxiv.org/abs/2401.17175",
        "title": "Integrable Frame Fields using Odeco Tensors",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a method for computing integrable orthogonal frame fields on planar surfaces. Frames and their symmetries are implicitly represented using orthogonally decomposable (odeco) tensors. To formulate an integrability criterion, we express the frame field's Lie bracket solely in terms of the tensor representation; this is made possible by studying the sensitivity of the frame with respect to perturbations in the tensor. We construct an energy formulation that computes smooth and integrable frame fields, in both isotropic and anisotropic settings. The user can prescribe any size and orientation constraints in input, and the solver creates and places the singularities required to fit the constraints with the correct topology. The computed frame field can be integrated to a seamless parametrization that is aligned with the frame field.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "Submitted to the SIAM International Meshing Roundtable Workshop 2024"
    },
    {
        "paper id": "2401.17184",
        "abstract url": "https://arxiv.org/abs/2401.17184",
        "title": "Rigorous Error Analysis for Logarithmic Number Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Logarithmic Number Systems (LNS) hold considerable promise in helping reduce the number of bits needed to represent a high dynamic range of real-numbers with finite precision, and also efficiently support multiplication and division. However, under LNS, addition and subtraction turn into non-linear functions that must be approximated - typically using precomputed table-based functions. Additionally, multiple layers of error correction are typically needed to improve result accuracy. Unfortunately, previous efforts have not characterized the resulting error bound. We provide the first rigorous analysis of LNS, covering detailed techniques such as co-transformation that are crucial to implementing subtraction with reasonable accuracy. We provide theorems capturing the error due to table interpolations, the finite precision of pre-computed values in the tables, and the error introduced by fix-point multiplications involved in LNS implementations. We empirically validate our analysis using a Python implementation, showing that our analytical bounds are tight, and that our testing campaign generates inputs diverse-enough to almost match (but not exceed) the analytical bounds. We close with discussions on how to adapt our analysis to LNS systems with different bases and also discuss many pragmatic ramifications of our work in the broader arena of scientific computing and machine learning.",
        "subjects": [
            "cs.MS",
            "math.NA"
        ],
        "comment": "42 pages, 14 figures, 6 tables"
    },
    {
        "paper id": "2401.17199",
        "abstract url": "https://arxiv.org/abs/2401.17199",
        "title": "A Mixed Linear and Graded Logic: Proofs, Terms, and Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Graded modal logics generalise standard modal logics via families of modalities indexed by an algebraic structure whose operations mediate between the different modalities. The graded \"of-course\" modality $!_r$ captures how many times a proposition is used and has an analogous interpretation to the of-course modality from linear logic; the of-course modality from linear logic can be modelled by a linear exponential comonad and graded of-course can be modelled by a graded linear exponential comonad. Benton showed in his seminal paper on Linear/Non-Linear logic that the of-course modality can be split into two modalities connecting intuitionistic logic with linear logic, forming a symmetric monoidal adjunction. Later, Fujii et al. demonstrated that every graded comonad can be decomposed into an adjunction and a 'strict action'. We give a similar result to Benton, leveraging Fujii et al.'s decomposition, showing that graded modalities can be split into two modalities connecting a graded logic with a graded linear logic. We propose a sequent calculus, its proof theory and categorical model, and a natural deduction system which we show is isomorphic to the sequent calculus. Interestingly, our system can also be understood as Linear/Non-Linear logic composed with an action that adds the grading, further illuminating the shared principles between linear logic and a class of graded modal logics.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2401.17224",
        "abstract url": "https://arxiv.org/abs/2401.17224",
        "title": "Evolvable Agents, a Fine Grained Approach for Distributed Evolutionary Computing: Walking towards the Peer-to-Peer Computing Frontiers",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work we propose a fine grained approach with self-adaptive migration rate for distributed evolutionary computation. Our target is to gain some insights on the effects caused by communication when the algorithm scales. To this end, we consider a set of basic topologies in order to avoid the overlapping of algorithmic effects between communication and topological structures. We analyse the approach viability by comparing how solution quality and algorithm speed change when the number of processors increases and compare it with an Island model based implementation. A finer-grained approach implies a better chance of achieving a larger scalable system; such a feature is crucial concerning large-scale parallel architectures such as Peer-to-Peer systems. In order to check scalability, we perform a threefold experimental evaluation of this model: First, we concentrate on the algorithmic results when the problem scales up to eight nodes in comparison with how it does following the Island model. Second, we analyse the computing time speedup of the approach while scaling. Finally, we analyse the network performance with the proposed self-adaptive migration rate policy that depends on the link latency and bandwidth. With this experimental setup, our approach shows better scalability than the Island model and a equivalent robustness on the average of the three test functions under study.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:cs/0703117"
    },
    {
        "paper id": "2401.17234",
        "abstract url": "https://arxiv.org/abs/2401.17234",
        "title": "Asynchronous Distributed Genetic Algorithms with Javascript and JSON",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a connected world, spare CPU cycles are up for grabs, if you only make its obtention easy enough. In this paper we present a distributed evolutionary computation system that uses the computational capabilities of the ubiquituous web browser. Using Asynchronous Javascript and JSON (Javascript Object Notation, a serialization protocol) allows anybody with a web browser (that is, mostly everybody connected to the Internet) to participate in a genetic algorithm experiment with little effort, or none at all. Since, in this case, computing becomes a social activity and is inherently impredictable, in this paper we will explore the performance of this kind of virtual computer by solving simple problems such as the Royal Road function and analyzing how many machines and evaluations it yields. We will also examine possible performance bottlenecks and how to solve them, and, finally, issue some advice on how to set up this kind of experiments to maximize turnout and, thus, performance.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:cs/0701115"
    },
    {
        "paper id": "2401.17235",
        "abstract url": "https://arxiv.org/abs/2401.17235",
        "title": "Explicit Good Codes Approaching Distance 1 in Ulam Metric",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Ulam distance of two permutations on $[n]$ is $n$ minus the length of their longest common subsequence. In this paper, we show that for every $\\varepsilon>0$, there exists some $\u03b1>0$, and an infinite set $\u0393\\subseteq \\mathbb{N}$, such that for all $n\\in\u0393$, there is an explicit set $C_n$ of $(n!)^\u03b1$ many permutations on $[n]$, such that every pair of permutations in $C_n$ has pairwise Ulam distance at least $(1-\\varepsilon)\\cdot n$. Moreover, we can compute the $i^{\\text{th}}$ permutation in $C_n$ in poly$(n)$ time and can also decode in poly$(n)$ time, a permutation $\u03c0$ on $[n]$ to its closest permutation $\u03c0^*$ in $C_n$, if the Ulam distance of $\u03c0$ and $\u03c0^*$ is less than $ \\frac{(1-\\varepsilon)\\cdot n}{4} $. Previously, it was implicitly known by combining works of Goldreich and Wigderson [Israel Journal of Mathematics'23] and Farnoud, Skachek, and Milenkovic [IEEE Transactions on Information Theory'13] in a black-box manner, that it is possible to explicitly construct $(n!)^{\u03a9(1)}$ many permutations on $[n]$, such that every pair of them have pairwise Ulam distance at least $\\frac{n}{6}\\cdot (1-\\varepsilon)$, for any $\\varepsilon>0$, and the bound on the distance can be improved to $\\frac{n}{4}\\cdot (1-\\varepsilon)$ if the construction of Goldreich and Wigderson is directly analyzed in the Ulam metric.",
        "subjects": [
            "cs.IT",
            "cs.CC",
            "cs.DS",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17247",
        "abstract url": "https://arxiv.org/abs/2401.17247",
        "title": "Semantic Forwarding for Next Generation Relay Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider cooperative semantic text communications facilitated by a relay node. We propose two types of semantic forwarding: semantic lossy forwarding (SLF) and semantic predict-and-forward (SPF). Both are machine learning aided approaches, and, in particular, utilize attention mechanisms at the relay to establish a dynamic semantic state, updated upon receiving a new source signal. In the SLF model, the semantic state is used to decode the received source signal; whereas in the SPF model, it is used to predict the next source signal, enabling proactive forwarding. Our proposed forwarding schemes do not need any channel state information and exhibit consistent performance regardless of the relay's position. Our results demonstrate that the proposed semantic forwarding techniques outperform conventional semantic-agnostic baselines.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)"
    },
    {
        "paper id": "2401.17337",
        "abstract url": "https://arxiv.org/abs/2401.17337",
        "title": "Sharing delay costs in stochastic scheduling problems with delays",
        "rating": "-10",
        "keywords": [],
        "abstract": "An important problem in project management is determining ways to distribute amongst activities the costs that are incurred when a project is delayed because some activities end later than expected. In this study, we address this problem in stochastic projects, where the durations of activities are unknown but their corresponding probability distributions are known. We propose and characterise an allocation rule based on the Shapley value, illustrate its behaviour by using examples, and analyse features of its calculation for large problems.",
        "subjects": [
            "cs.GT",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17338",
        "abstract url": "https://arxiv.org/abs/2401.17338",
        "title": "New results on egalitarian values for games with a priori unions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Several extensions of the equal division value and the equal surplus division value to the family of games with a priori unions are proposed in Alonso-Meijide et al. (2020) ``On egalitarian values for cooperative games with a priori unions.'' TOP 28: 672-688. In this paper we provide new axiomatic characterizations of these values. Furthermore, using the equal surplus division value in two steps, we propose a new coalitional value. The balanced contributions and quotient game properties give rise to a different modification of the equal surplus division value.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17403",
        "abstract url": "https://arxiv.org/abs/2401.17403",
        "title": "Ozone: Fully Out-of-Order Choreographies",
        "rating": "-10",
        "keywords": [],
        "abstract": "Choreographic programming is a paradigm for writing distributed applications. It allows programmers to write a single program, called a choreography, that can be compiled to generate correct implementations of each process in the application. Although choreographies provide good static guarantees, they can exhibit high latency when messages or processes are delayed. This is because processes in a choreography typically execute in a fixed, deterministic order, and cannot adapt to the order that messages arrive at runtime. In non-choreographic code, programmers can address this problem by allowing processes to execute out of order -- for instance by using futures or reactive programming. However, in choreographic code, out-of-order process execution can lead to serious and subtle bugs, called communication integrity violations (CIVs). In this paper, we develop a model of choreographic programming for out-of-order processes that guarantees absence of CIVs and deadlocks. As an application of our approach, we also introduce an API for safe non-blocking communication via futures in the choreographic programming language Choral. The API allows processes to execute out of order, participate in multiple choreographies concurrently, and to handle unordered data messages. We provide an illustrative evaluation of our API, showing that out-of-order execution can reduce latency and increase throughput by overlapping communication with computation.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "25 pages, 22 Figures, 3 pages appendix. Expanded evaluation and revised sections for clarity"
    },
    {
        "paper id": "2401.17419",
        "abstract url": "https://arxiv.org/abs/2401.17419",
        "title": "Few-Shot Channel-Agnostic Analog Coding: A Near-Optimal Scheme",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate the problem of transmitting an analog source to a destination over $N$ uses of an additive-white-Gaussian-noise (AWGN) channel, where $N$ is very small (in the order of 10 or even less). The proposed coding scheme is based on representing the source symbol using a novel progressive expansion technique, partitioning the digits of expansion into $N$ ordered sets, and finally mapping the symbols in each set to a real number by applying the reverse progressive expansion. In the last step, we introduce some gaps between the signal levels to prevent the carry-over of the additive noise from propagation to other levels. This shields the most significant levels of the signal from an additive noise, hitting the signal at a less significant level. The parameters of the progressive expansion and the shielding procedure are opportunistically independent of the $\\SNR$ so that the proposed scheme achieves a distortion $D$, where $-\\log(D)$ is within $O(\\log\\log(\\SNR))$ of the optimal performance for all values of $\\SNR$, leading to a channel-agnostic scheme.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17442",
        "abstract url": "https://arxiv.org/abs/2401.17442",
        "title": "Detection of Signals in Colored Noise: Leading Eigenvalue Test for Non-central $F$-matrices",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the signal detection problem in colored noise with an unknown covariance matrix. In particular, we focus on detecting an unknown non-random signal by capitalizing on the leading eigenvalue of the whitened sample covariance matrix as the test statistic (a.k.a. Roy's largest root test). Since the unknown signal is non-random, the whitened sample covariance matrix turns out to have a non-central $F$-distribution. This distribution assumes a singular or non-singular form depending on whether the number of observations $p\\lessgtr$ the system dimensionality $m$. Therefore, we statistically characterize the leading eigenvalue of the singular and non-singular $F$-matrices by deriving their cumulative distribution functions (c.d.f.). Subsequently, they have been utilized in deriving the corresponding receiver operating characteristic (ROC) profiles. We also extend our analysis into the high dimensional domain. It turns out that, when the signal is sufficiently strong, the maximum eigenvalue can reliably detect it in this regime. Nevertheless, weak signals cannot be detected in the high dimensional regime with the leading eigenvalue.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "6 pages, 2 figures, conference"
    },
    {
        "paper id": "2401.17444",
        "abstract url": "https://arxiv.org/abs/2401.17444",
        "title": "Languages of Higher-Dimensional Timed Automata",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a new language semantics for real-time concurrency. Its operational models are higher-dimensional timed automata (HDTAs), a generalization of both higher-dimensional automata and timed automata. We define languages of HDTAs as sets of interval-timed pomsets with interfaces. As an application, we show that language inclusion of HDTAs is undecidable. On the other hand, using a region construction we can show that untimings of HDTA languages have enough regularity so that untimed language inclusion is decidable.",
        "subjects": [
            "cs.FL",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17474",
        "abstract url": "https://arxiv.org/abs/2401.17474",
        "title": "Parallelization Strategies for the Randomized Kaczmarz Algorithm on Large-Scale Dense Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Kaczmarz algorithm is an iterative technique designed to solve consistent linear systems of equations. It falls within the category of row-action methods, focusing on handling one equation per iteration. This characteristic makes it especially useful in solving very large systems. The recent introduction of a randomized version, the Randomized Kaczmarz method, renewed interest in the algorithm, leading to the development of numerous variations. Subsequently, parallel implementations for both the original and Randomized Kaczmarz method have since then been proposed. However, previous work has addressed sparse linear systems, whereas we focus on solving dense systems. In this paper, we explore in detail approaches to parallelizing the Kaczmarz method for both shared and distributed memory for large dense systems. In particular, we implemented the Randomized Kaczmarz with Averaging (RKA) method that, for inconsistent systems, unlike the standard Randomized Kaczmarz algorithm, reduces the final error of the solution. While efficient parallelization of this algorithm is not achievable, we introduce a block version of the averaging method that can outperform the RKA method.",
        "subjects": [
            "cs.DC",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17483",
        "abstract url": "https://arxiv.org/abs/2401.17483",
        "title": "An Analysis of Symmetry in Quantitative Semantics",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we build on a recent bicategorical model called thin spans of groupoids, introduced by Clairambault and Forest. Notably, thin spans feature a decomposition of symmetry into two sub-groupoids of polarized -- positive and negative -- symmetries. We first construct a variation of the original exponential of thin spans, based on sequences rather than families. Then we give a syntactic characterisation of the interpretation of simply-typed lambda-terms in thin spans, in terms of rigid intersection types and rigid resource terms. Finally, we formally relate thin spans with the weighted relational model and generalized species of structure. This allows us to show how some quantities in those models reflect polarized symmetries: in particular we show that the weighted relational model counts witnesses from generalized species of structure, divided by the cardinal of a group of positive symmetries.",
        "subjects": [
            "cs.LO",
            "math.CT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17486",
        "abstract url": "https://arxiv.org/abs/2401.17486",
        "title": "A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Responsible design of AI systems is a shared goal across HCI and AI communities. Responsible AI (RAI) tools have been developed to support practitioners to identify, assess, and mitigate ethical issues during AI development. These tools take many forms (e.g., design playbooks, software toolkits, documentation protocols). However, research suggests that use of RAI tools is shaped by organizational contexts, raising questions about how effective such tools are in practice. To better understand how RAI tools are -- and might be -- evaluated, we conducted a qualitative analysis of 37 publications that discuss evaluations of RAI tools. We find that most evaluations focus on usability, while questions of tools' effectiveness in changing AI development are sidelined. While usability evaluations are an important approach to evaluate RAI tools, we draw on evaluation approaches from other fields to highlight developer- and community-level steps to support evaluations of RAI tools' effectiveness in shaping AI development practices and outcomes.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted for publication in Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA"
    },
    {
        "paper id": "2401.17519",
        "abstract url": "https://arxiv.org/abs/2401.17519",
        "title": "Modeling and analysis of a flexible spinning Euler-Bernoulli beam with centrifugal stiffening and softening: A Linear Fractional Representation approach with application to spinning spacecraft",
        "rating": "-10",
        "keywords": [],
        "abstract": "The derivation of a linear fractional representation (LFR) model for a flexible, spinning and uniform Euler-Bernoulli beam is accomplished using the {Lagrange} technique, fully capturing the centrifugal force generated by the spinning motion and accounting for its dependence on the angular velocity. This six degrees of freedom (DOF) model accounts for the behavior of deflection in the moving body frame, encompassing the bending, traction and torsion dynamics. The model is also designed to be compliant with the Two-Input-Two-Output Port (TITOP) approach, which offers the possibility to model complex multibody mechanical systems, while keeping the uncertain nature of the plant and condensing all the possible mechanical configurations in a single LFR. To evaluate the effectiveness of the model, various scenarios are considered and their results are tabulated. These scenarios include uniform beams with fixed root boundary conditions for different values of tip mass, root offset and angular velocity. The results from the analysis of the uniform cantilever beam are compared with solutions found in the literature and obtained from a commercial finite element software. Ultimately, this paper presents a multibody model for a spinning spacecraft mission scenario. A comprehensive analysis of the system dynamics is conducted, providing insights into the behavior of the spacecraft under spinning conditions.",
        "subjects": [
            "eess.SY",
            "physics.space-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17522",
        "abstract url": "https://arxiv.org/abs/2401.17522",
        "title": "On the Sum Secrecy Rate Maximisation for Wireless Vehicular Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Wireless communications form the backbone of future vehicular networks, playing a critical role in applications ranging from traffic control to vehicular road safety. However, the dynamic structure of these networks creates security vulnerabilities, making security considerations an integral part of network design. We address these security concerns from a physical layer security aspect by investigating achievable secrecy rates in wireless vehicular networks. Specifically, we aim to maximize the sum secrecy rate from all vehicular pairs subject to bandwidth and power resource constraints. For the considered problem, we first propose a solution based on the successive convex approximation (SCA) method, which has not been applied in this context before. To further reduce the complexity of the SCA-based method, we also propose a low-complexity solution based on a fast iterative shrinkage-thresholding algorithm (FISTA). Our simulation results for SCA and FISTA show a trade-off between convergence and runtime. While the SCA method achieves better convergence, the FISTA-based approach is at least 300 times faster than the SCA method.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17555",
        "abstract url": "https://arxiv.org/abs/2401.17555",
        "title": "opML: Optimistic Machine Learning on Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "The integration of machine learning with blockchain technology has witnessed increasing interest, driven by the vision of decentralized, secure, and transparent AI services. In this context, we introduce opML (Optimistic Machine Learning on chain), an innovative approach that empowers blockchain systems to conduct AI model inference. opML lies a interactive fraud proof protocol, reminiscent of the optimistic rollup systems. This mechanism ensures decentralized and verifiable consensus for ML services, enhancing trust and transparency. Unlike zkML (Zero-Knowledge Machine Learning), opML offers cost-efficient and highly efficient ML services, with minimal participation requirements. Remarkably, opML enables the execution of extensive language models, such as 7B-LLaMA, on standard PCs without GPUs, significantly expanding accessibility. By combining the capabilities of blockchain and AI through opML, we embark on a transformative journey toward accessible, secure, and efficient on-chain machine learning.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17556",
        "abstract url": "https://arxiv.org/abs/2401.17556",
        "title": "Model-Theoretic Logic for Mathematical Theory of Semantic Information and Communication",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose an advancement to Tarskian model-theoretic semantics, leading to a unified quantitative theory of semantic information and communication. We start with description of inductive logic and probabilities, which serve as notable tools in development of the proposed theory. Then, we identify two disparate kinds of uncertainty in semantic communication, that of physical and content, present refined interpretations of semantic information measures, and conclude with proposing a new measure for semantic content-information and entropy. Our proposition standardizes semantic information across different universes and systems, hence bringing measurability and comparability into semantic communication. We then proceed with introducing conditional and mutual semantic cont-information measures and point out to their utility in formulating practical and optimizable lossless and lossy semantic compression objectives. Finally, we experimentally demonstrate the value of our theoretical propositions.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17566",
        "abstract url": "https://arxiv.org/abs/2401.17566",
        "title": "IQ Skew and Imbalance Estimation for Coherent Point-to-Multi-Point Optical Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Coherent point-to-multi-point (PtMP) optical network based on digital subcarrier multiplexing (DSCM) has been a promising technology for metro and access networks to achieve cost savings, low latency, and high flexibility. In-phase and quadrature (IQ) impairments of the coherent transceiver (e.g. IQ skew and power imbalance) cause severe performance degradation. In the DSCM-based coherent PtMP optical networks, it is hard to realize far-end IQ-impairments estimation for the hub transmitter because the leaf on one subcarrier cannot acquire the signal on the symmetrical subcarrier. In this paper, we propose a far-end IQ-impairments estimation based on the specially designed time-and-frequency interleaving tones (TFITs), which can simultaneously estimate IQ skews and power imbalances of the hub transmitter and leaf receiver at an individual leaf. The feasibility of the TFITs-based IQ-impairments estimation has been experimentally verified by setting up $8$Gbaud/SC $\\times$ $4$SCs DSCM-based coherent PtMP optical network. The experimental results depict that the absolute errors in the estimated IQ skew and power imbalance are within $\\pm 0.5$ps and $\\pm 0.2$dB, respectively. In conclusion, TFITs-based IQ-impairments estimation has great potential for DSCM-based coherent PtMP optical networks.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "This paper has been accepted for publication in the Journal of Lightwave Technology"
    },
    {
        "paper id": "2401.17577",
        "abstract url": "https://arxiv.org/abs/2401.17577",
        "title": "Robustness in Wireless Distributed Learning: An Information-Theoretic Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we take an information-theoretic approach to understand the robustness in wireless distributed learning. Upon measuring the difference in loss functions, we provide an upper bound of the performance deterioration due to imperfect wireless channels. Moreover, we characterize the transmission rate under task performance guarantees and propose the channel capacity gain resulting from the inherent robustness in wireless distributed learning. An efficient algorithm for approximating the derived upper bound is established for practical use. The effectiveness of our results is illustrated by the numerical simulations.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17581",
        "abstract url": "https://arxiv.org/abs/2401.17581",
        "title": "Bitcoin Inscriptions: Foundations and Beyond",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bitcoin inscription marks a pivotal moment in blockchain technology. This report presents a primary exploration of Bitcoin inscriptions. We dive into the technological underpinnings and offer a detailed comparative analysis between Bitcoin inscriptions and NFTs on other blockchains. Further, we explore a wide range of use cases and significant opportunities for future innovation, including inscription derivative protocols, Bitcoin Layer2 solutions, and interoperability techniques.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": "25 pages, 6 figures, 4 tables"
    },
    {
        "paper id": "2401.17582",
        "abstract url": "https://arxiv.org/abs/2401.17582",
        "title": "STAR: An Efficient Softmax Engine for Attention Model with RRAM Crossbar",
        "rating": "-10",
        "keywords": [],
        "abstract": "RRAM crossbars have been studied to construct in-memory accelerators for neural network applications due to their in-situ computing capability. However, prior RRAM-based accelerators show efficiency degradation when executing the popular attention models. We observed that the frequent softmax operations arise as the efficiency bottleneck and also are insensitive to computing precision. Thus, we propose STAR, which boosts the computing efficiency with an efficient RRAM-based softmax engine and a fine-grained global pipeline for the attention models. Specifically, STAR exploits the versatility and flexibility of RRAM crossbars to trade off the model accuracy and hardware efficiency. The experimental results evaluated on several datasets show STAR achieves up to 30.63x and 1.31x computing efficiency improvements over the GPU and the state-of-the-art RRAM-based attention accelerators, respectively.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17591",
        "abstract url": "https://arxiv.org/abs/2401.17591",
        "title": "Multi-Agent Phase-Balancing around Polar Curves with Bounded Trajectories: An Experimental Study using Crazyflies and MoCap System",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this experimental work, we implement the control design from our earlier work on a swarm of Crazyflie 2.1 quad-copters by deriving the original control in terms of variables that are available to the user in this practical system. A suitable model is developed using the Crazyswarm2 package within ROS2 to facilitate the execution of the control law. We also discuss various components that are part of this experiment and the challenges we encountered during the experimentation. Extensive experimental results, along with the links to the YouTube videos for actual Crazyflie quad-copters, are provided.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17596",
        "abstract url": "https://arxiv.org/abs/2401.17596",
        "title": "An Interactive Empirical Approach to the Validation of Software Package Specifications",
        "rating": "-10",
        "keywords": [],
        "abstract": "The objective of this research is the development of a practical system to manipulate and validate software package specifications. The validation process developed is based on consistency checks. Furthermore, by means of scenarios, the customer will be able to interactively experience the specified system prior to its implementation. Functions, data, and data types constitute the framework of our validation system. The specification of the Graphical Kernel System (GKS) is a typical example of the target software package specifications to be manipulated.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2401.17599",
        "abstract url": "https://arxiv.org/abs/2401.17599",
        "title": "A Graphics Function Standard Specification Validator",
        "rating": "-10",
        "keywords": [],
        "abstract": "A validation methodology is proposed and implemented for natural language software specifications of standard graphics functions. Checks are made for consistency, completeness, and lack of ambiguity in data element and function descriptions. Functions and data elements are maintained in a relational database representation. The appropriate checks are performed by sequences of database operations. The relational database manager INGRES was used to support a prototype implementation of the proposed technique. The methodology supports the development of a scenario-based prototype from the information available in the specification. This permits various function sequences to be checked without implementation of the environment specified. The application of a prototype implementation of the proposed methodology to the specification of the Graphics Kernel System (GKS) software package demonstrates the practicability of the method. Several inconsistencies in GKS related to the definition of data elements have been identified.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00080",
        "abstract url": "https://arxiv.org/abs/2402.00080",
        "title": "Arithmetic Average Density Fusion -- Part IV: Distributed Heterogeneous Fusion of RFS and LRFS Filters via Variational Approximation",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper, the fourth part of a series of papers on the arithmetic average (AA) density fusion approach and its application for target tracking, addresses the intricate challenge of distributed heterogeneous multisensor multitarget tracking, where each inter-connected sensor operates a probability hypothesis density (PHD) filter, a multiple Bernoulli (MB) filter or a labeled MB (LMB) filter and they cooperate with each other via information fusion. Earlier papers in this series have proven that the proper AA fusion of these filters is all exactly built on averaging their respective unlabeled/labeled PHDs. Based on this finding, two PHD-AA fusion approaches are proposed via variational minimization of the upper bound of the Kullback-Leibler divergence between the local and multi-filter averaged PHDs subject to cardinality consensus based on the Gaussian mixture implementation, enabling heterogeneous filter cooperation. One focuses solely on fitting the weights of the local Gaussian components (L-GCs), while the other simultaneously fits all the parameters of the L-GCs at each sensor, both seeking average consensus on the unlabeled PHD, irrespective of the specific posterior form of the local filters. For the distributed peer-to-peer communication, both the classic consensus and flooding paradigms have been investigated. Simulations have demonstrated the effectiveness and flexibility of the proposed approaches in both homogeneous and heterogeneous scenarios.",
        "subjects": [
            "eess.SY",
            "eess.SP"
        ],
        "comment": "13 pages,14 figures"
    },
    {
        "paper id": "2402.00890",
        "abstract url": "https://arxiv.org/abs/2402.00890",
        "title": "Utilizing Large Language Models to Translate RFC Protocol Specifications to CPSA Definitions",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes the use of Large Language Models (LLMs) for translating Request for Comments (RFC) protocol specifications into a format compatible with the Cryptographic Protocol Shapes Analyzer (CPSA). This novel approach aims to reduce the complexities and efforts involved in protocol analysis, by offering an automated method for translating protocol specifications into structured models suitable for CPSA. In this paper we discuss the implementation of an RFC Protocol Translator, its impact on enhancing the accessibility of formal methods analysis, and its potential for improving the security of internet protocols.",
        "subjects": [
            "cs.CR",
            "cs.NI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.07914",
        "abstract url": "https://arxiv.org/abs/2402.07914",
        "title": "Requirements-Driven Visualizations for Big Data Analytics: a Model-Driven approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Choosing the right Visualization techniques is critical in Big Data Analytics. However, decision makers are not experts on visualization and they face up with enormous difficulties in doing so. There are currently many different (i) Big Data sources and also (ii) many different visual analytics to be chosen. Every visualization technique is not valid for every Big Data source and is not adequate for every context. In order to tackle this problem, we propose an approach, based on the Model Driven Architecture (MDA) to facilitate the selection of the right visual analytics to non-expert users. The approach is based on three different models: (i) a requirements model based on goal-oriented modeling for representing information requirements, (ii) a data representation model for representing data which will be connected to visualizations and, (iii) a visualization model for representing visualization details regardless of their implementation technology. Together with these models, a set of transformations allow us to semi-automatically obtain the corresponding implementation avoiding the intervention of the non-expert users. In this way, the great advantage of our proposal is that users no longer need to focus on the characteristics of the visualization, but rather, they focus on their information requirements and obtain the visualization that is better suited for their needs. We show the applicability of our proposal through a case study focused on a tax collection organization from a real project developed by the Spin-off company Lucentia Lab.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    }
]