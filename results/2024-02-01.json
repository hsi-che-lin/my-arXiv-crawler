[
    {
        "paper id": "2402.00828",
        "abstract url": "https://arxiv.org/abs/2402.00828",
        "title": "Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "Efficient Fine-tuning"
            ],
            [
                "cs.AI",
                "eess.AS"
            ]
        ],
        "abstract": "Mixture of Experts (MoE) architectures have recently started burgeoning due to their ability to scale model's capacity while maintaining the computational cost affordable. Furthermore, they can be applied to both Transformers and State Space Models, the current state-of-the-art models in numerous fields. While MoE has been mostly investigated for the pre-training stage, its use in parameter-efficient transfer learning settings is under-explored. To narrow this gap, this paper attempts to demystify the use of MoE for parameter-efficient fine-tuning of Audio Spectrogram Transformers to audio and speech downstream tasks. Specifically, we propose Soft Mixture of Adapters (Soft-MoA). It exploits adapters as the experts and, leveraging the recent Soft MoE method, it relies on a soft assignment between the input tokens and experts to keep the computational time limited. Extensive experiments across 4 benchmarks demonstrate that Soft-MoA outperforms the single adapter method and performs on par with the dense MoA counterpart. We finally present ablation studies on key elements of Soft-MoA, showing for example that Soft-MoA achieves better scaling with more experts, as well as ensuring that all experts contribute to the computation of the output tokens, thus dispensing with the expert imbalance issue.",
        "subjects": [
            "eess.AS",
            "cs.AI"
        ],
        "comment": "The code will be released ad: \\url{https://github.com/umbertocappellazzo/PETL_AST}"
    },
    {
        "paper id": "2402.01032",
        "abstract url": "https://arxiv.org/abs/2402.01032",
        "title": "Repeat After Me: Transformers are Better than State Space Models at Copying",
        "rating": "2",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Transformers are the dominant architecture for sequence modeling, but there is growing interest in models that use a fixed-size latent state that does not depend on the sequence length, which we refer to as \"generalized state space models\" (GSSMs). In this paper we show that while GSSMs are promising in terms of inference-time efficiency, they are limited compared to transformer models on tasks that require copying from the input context. We start with a theoretical analysis of the simple task of string copying and prove that a two layer transformer can copy strings of exponential length while GSSMs are fundamentally limited by their fixed-size latent state. Empirically, we find that transformers outperform GSSMs in terms of efficiency and generalization on synthetic tasks that require copying the context. Finally, we evaluate pretrained large language models and find that transformer models dramatically outperform state space models at copying and retrieving information from context. Taken together, these results suggest a fundamental gap between transformers and GSSMs on tasks of practical interest.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00341",
        "abstract url": "https://arxiv.org/abs/2402.00341",
        "title": "Recasting Regional Lighting for Shadow Removal",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Removing shadows requires an understanding of both lighting conditions and object textures in a scene. Existing methods typically learn pixel-level color mappings between shadow and non-shadow images, in which the joint modeling of lighting and object textures is implicit and inadequate. We observe that in a shadow region, the degradation degree of object textures depends on the local illumination, while simply enhancing the local illumination cannot fully recover the attenuated textures. Based on this observation, we propose to condition the restoration of attenuated textures on the corrected local lighting in the shadow region. Specifically, We first design a shadow-aware decomposition network to estimate the illumination and reflectance layers of shadow regions explicitly. We then propose a novel bilateral correction network to recast the lighting of shadow regions in the illumination layer via a novel local lighting correction module, and to restore the textures conditioned on the corrected illumination layer via a novel illumination-guided texture restoration module. We further annotate pixel-wise shadow masks for the public SRD dataset, which originally contains only image pairs. Experiments on three benchmarks show that our method outperforms existing state-of-the-art shadow removal methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "AAAI 2024 (Oral)"
    },
    {
        "paper id": "2402.00680",
        "abstract url": "https://arxiv.org/abs/2402.00680",
        "title": "LVC-LGMC: Joint Local and Global Motion Compensation for Learned Video Compression",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Existing learned video compression models employ flow net or deformable convolutional networks (DCN) to estimate motion information. However, the limited receptive fields of flow net and DCN inherently direct their attentiveness towards the local contexts. Global contexts, such as large-scale motions and global correlations among frames are ignored, presenting a significant bottleneck for capturing accurate motions. To address this issue, we propose a joint local and global motion compensation module (LGMC) for leaned video coding. More specifically, we adopt flow net for local motion compensation. To capture global context, we employ the cross attention in feature domain for motion compensation. In addition, to avoid the quadratic complexity of vanilla cross attention, we divide the softmax operations in attention into two independent softmax operations, leading to linear complexity. To validate the effectiveness of our proposed LGMC, we integrate it with DCVC-TCM and obtain learned video compression with joint local and global motion compensation (LVC-LGMC). Extensive experiments demonstrate that our LVC-LGMC has significant rate-distortion performance improvements over baseline DCVC-TCM.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted to ICASSP 2024 (lecture presentation). The first attempt to use cross attention for bits-free motion estimation and motion compensation"
    },
    {
        "paper id": "2402.00794",
        "abstract url": "https://arxiv.org/abs/2402.00794",
        "title": "ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Feature attribution methods (FAs), such as gradients and attention, are widely employed approaches to derive the importance of all input features to the model predictions. Existing work in natural language processing has mostly focused on developing and testing FAs for encoder-only language models (LMs) in classification tasks. However, it is unknown if it is faithful to use these FAs for decoder-only models on text generation, due to the inherent differences between model architectures and task settings respectively. Moreover, previous work has demonstrated that there is no `one-wins-all' FA across models and tasks. This makes the selection of a FA computationally expensive for large LMs since input importance derivation often requires multiple forward and backward passes including gradient computations that might be prohibitive even with access to large compute. To address these issues, we present a model-agnostic FA for generative LMs called Recursive Attribution Generator (ReAGent). Our method updates the token importance distribution in a recursive manner. For each update, we compute the difference in the probability distribution over the vocabulary for predicting the next token between using the original input and using a modified version where a part of the input is replaced with RoBERTa predictions. Our intuition is that replacing an important token in the context should have resulted in a larger change in the model's confidence in predicting the token than replacing an unimportant token. Our method can be universally applied to any generative LM without accessing internal model weights or additional training and fine-tuning, as most other FAs require. We extensively compare the faithfulness of ReAGent with seven popular FAs across six decoder-only LMs of various sizes. The results show that our method consistently provides more faithful token importance distributions.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at AAAI24 workshop ReLM"
    },
    {
        "paper id": "2402.00835",
        "abstract url": "https://arxiv.org/abs/2402.00835",
        "title": "ALISON: Fast and Effective Stylometric Authorship Obfuscation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competing tasks of increasing importance in privacy research. Modern AA leverages an author's consistent writing style to match a text to its author using an AA classifier. AO is the corresponding adversarial task, aiming to modify a text in such a way that its semantics are preserved, yet an AA model cannot correctly infer its authorship. To address privacy concerns raised by state-of-the-art (SOTA) AA methods, new AO methods have been proposed but remain largely impractical to use due to their prohibitively slow training and obfuscation speed, often taking hours. To this challenge, we propose a practical AO method, ALISON, that (1) dramatically reduces training/obfuscation time, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2) achieves better obfuscation success through attacking three transformer-based AA methods on two benchmark datasets, typically performing 15% better than competing methods, (3) does not require direct signals from a target AA classifier during obfuscation, and (4) utilizes unique stylometric features, allowing sound model interpretation for explainable obfuscation. We also demonstrate that ALISON can effectively prevent four SOTA AA methods from accurately determining the authorship of ChatGPT-generated texts, all while minimally changing the original text semantics. To ensure the reproducibility of our findings, our code and data are available at: https://github.com/EricX003/ALISON.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "10 pages, 6 figures, 4 tables. To be published in the Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)"
    },
    {
        "paper id": "2402.00865",
        "abstract url": "https://arxiv.org/abs/2402.00865",
        "title": "Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Feature shaping refers to a family of methods that exhibit state-of-the-art performance for out-of-distribution (OOD) detection. These approaches manipulate the feature representation, typically from the penultimate layer of a pre-trained deep learning model, so as to better differentiate between in-distribution (ID) and OOD samples. However, existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, we first formulate an abstract optimization framework for studying feature-shaping methods. We then propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, we propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, we show that the feature-shaping function optimized by our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "ICLR 2024. Project page: https://github.com/Qinyu-Allen-Zhao/OptFSOOD"
    },
    {
        "paper id": "2402.00340",
        "abstract url": "https://arxiv.org/abs/2402.00340",
        "title": "Can you Remove the Downstream Model for Speaker Recognition with Self-Supervised Speech Features?",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Self-supervised features are typically used in place of filter-banks in speaker verification models. However, these models were originally designed to ingest filter-banks as inputs, and thus, training them on top of self-supervised features assumes that both feature types require the same amount of learning for the task. In this work, we observe that pre-trained self-supervised speech features inherently include information required for downstream speaker verification task, and therefore, we can simplify the downstream model without sacrificing performance. To this end, we revisit the design of the downstream model for speaker verification using self-supervised features. We show that we can simplify the model to use 97.51% fewer parameters while achieving a 29.93% average improvement in performance on SUPERB. Consequently, we show that the simplified downstream model is more data efficient compared to baseline--it achieves better performance with only 60% of the training data.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00345",
        "abstract url": "https://arxiv.org/abs/2402.00345",
        "title": "IndiVec: An Exploration of Leveraging Large Language Models for Media Bias Detection with Fine-Grained Bias Indicators",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study focuses on media bias detection, crucial in today's era of influential social media platforms shaping individual attitudes and opinions. In contrast to prior work that primarily relies on training specific models tailored to particular datasets, resulting in limited adaptability and subpar performance on out-of-domain data, we introduce a general bias detection framework, IndiVec, built upon large language models. IndiVec begins by constructing a fine-grained media bias database, leveraging the robust instruction-following capabilities of large language models and vector database techniques. When confronted with new input for bias detection, our framework automatically selects the most relevant indicator from the vector database and employs majority voting to determine the input's bias label. IndiVec excels compared to previous methods due to its adaptability (demonstrating consistent performance across diverse datasets from various sources) and explainability (providing explicit top-k indicators to interpret bias predictions). Experimental results on four political bias datasets highlight IndiVec's significant superiority over baselines. Furthermore, additional experiments and analysis provide profound insights into the framework's effectiveness.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00348",
        "abstract url": "https://arxiv.org/abs/2402.00348",
        "title": "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "In this study, we investigate the DIstribution Correction Estimation (DICE) methods, an important line of work in offline reinforcement learning (RL) and imitation learning (IL). DICE-based methods impose state-action-level behavior constraint, which is an ideal choice for offline learning. However, they typically perform much worse than current state-of-the-art (SOTA) methods that solely use action-level behavior constraint. After revisiting DICE-based methods, we find there exist two gradient terms when learning the value function using true-gradient update: forward gradient (taken on the current state) and backward gradient (taken on the next state). Using forward gradient bears a large similarity to many offline RL methods, and thus can be regarded as applying action-level constraint. However, directly adding the backward gradient may degenerate or cancel out its effect if these two gradients have conflicting directions. To resolve this issue, we propose a simple yet effective modification that projects the backward gradient onto the normal plane of the forward gradient, resulting in an orthogonal-gradient update, a new learning rule for DICE-based methods. We conduct thorough theoretical analyses and find that the projected backward gradient brings state-level behavior regularization, which reveals the mystery of DICE-based methods: the value learning objective does try to impose state-action-level constraint, but needs to be used in a corrected way. Through toy examples and extensive experiments on complex offline RL and IL tasks, we demonstrate that DICE-based methods using orthogonal-gradient updates (O-DICE) achieve SOTA performance and great robustness.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Spotlight @ ICLR 2024, first two authors contribute equally"
    },
    {
        "paper id": "2402.00367",
        "abstract url": "https://arxiv.org/abs/2402.00367",
        "title": "Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite efforts to expand the knowledge of large language models (LLMs), knowledge gaps -- missing or outdated information in LLMs -- might always persist given the evolving nature of knowledge. In this work, we study approaches to identify LLM knowledge gaps and abstain from answering questions when knowledge gaps are present. We first adapt existing approaches to model calibration or adaptation through fine-tuning/prompting and analyze their ability to abstain from generating low-confidence outputs. Motivated by their failures in self-reflection and over-reliance on held-out sets, we propose two novel approaches that are based on model collaboration, i.e., LLMs probing other LLMs for knowledge gaps, either cooperatively or competitively. Extensive experiments with three LLMs on four QA tasks featuring diverse knowledge domains demonstrate that both cooperative and competitive approaches to unveiling LLM knowledge gaps achieve up to 19.3% improvements on abstain accuracy against the strongest baseline. Further analysis reveals that our proposed mechanisms could help identify failure cases in retrieval augmentation and pinpoint knowledge gaps in multi-hop reasoning.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00371",
        "abstract url": "https://arxiv.org/abs/2402.00371",
        "title": "What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language models (LLMs) in social bot detection. To investigate the opportunities, we design novel LLM-based bot detectors by proposing a mixture-of-heterogeneous-experts framework to divide and conquer diverse user information modalities. To illuminate the risks, we explore the possibility of LLM-guided manipulation of user textual and structured information to evade detection. Extensive experiments with three LLMs on two datasets demonstrate that instruction tuning on merely 1,000 annotated examples produces specialized LLMs that outperform state-of-the-art baselines by up to 9.1% on both datasets, while LLM-guided manipulation strategies could significantly bring down the performance of existing bot detectors by up to 29.6% and harm the calibration and reliability of bot detection systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00385",
        "abstract url": "https://arxiv.org/abs/2402.00385",
        "title": "Computational Morphology and Lexicography Modeling of Modern Standard Arabic Nominals",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Modern Standard Arabic (MSA) nominals present many morphological and lexical modeling challenges that have not been consistently addressed previously. This paper attempts to define the space of such challenges, and leverage a recently proposed morphological framework to build a comprehensive and extensible model for MSA nominals. Our model design addresses the nominals' intricate morphotactics, as well as their paradigmatic irregularities. Our implementation showcases enhanced accuracy and consistency compared to a commonly used MSA morphological analyzer and generator. We make our models publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Findings of the Association for Computational Linguistics: EACL 2024"
    },
    {
        "paper id": "2402.00396",
        "abstract url": "https://arxiv.org/abs/2402.00396",
        "title": "Efficient Exploration for LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We present evidence of substantial benefit from efficient exploration in gathering human feedback to improve large language models. In our experiments, an agent sequentially generates queries while fitting a reward model to the feedback received. Our best-performing agent generates queries using double Thompson sampling, with uncertainty represented by an epistemic neural network. Our results demonstrate that efficient exploration enables high levels of performance with far fewer queries. Further, both uncertainty estimation and the choice of exploration scheme play critical roles.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00402",
        "abstract url": "https://arxiv.org/abs/2402.00402",
        "title": "Investigating Bias Representations in Llama 2 Chat via Activation Steering",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We address the challenge of societal bias in Large Language Models (LLMs), focusing on the Llama 2 7B Chat model. As LLMs are increasingly integrated into decision-making processes with substantial societal impact, it becomes imperative to ensure these models do not reinforce existing biases. Our approach employs activation steering to probe for and mitigate biases related to gender, race, and religion. This method manipulates model activations to direct responses towards or away from biased outputs, utilizing steering vectors derived from the StereoSet dataset and custom GPT4 generated gender bias prompts. Our findings reveal inherent gender bias in Llama 2 7B Chat, persisting even after Reinforcement Learning from Human Feedback (RLHF). We also observe a predictable negative correlation between bias and the model's tendency to refuse responses. Significantly, our study uncovers that RLHF tends to increase the similarity in the model's representation of different forms of societal biases, which raises questions about the model's nuanced understanding of different forms of bias. This work also provides valuable insights into effective red-teaming strategies for LLMs using activation steering, particularly emphasizing the importance of integrating a refusal vector.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00414",
        "abstract url": "https://arxiv.org/abs/2402.00414",
        "title": "Prompt-Time Symbolic Knowledge Capture with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Augmenting large language models (LLMs) with user-specific knowledge is crucial for real-world applications, such as personal AI assistants. However, LLMs inherently lack mechanisms for prompt-driven knowledge capture. This paper investigates utilizing the existing LLM capabilities to enable prompt-driven knowledge capture, with a particular emphasis on knowledge graphs. We address this challenge by focusing on prompt-to-triple (P2T) generation. We explore three methods: zero-shot prompting, few-shot prompting, and fine-tuning, and then assess their performance via a specialized synthetic dataset. Our code and datasets are publicly available at https://github.com/HaltiaAI/paper-PTSKC.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "8 pages, 5 figures, 1 table preprint. Under review"
    },
    {
        "paper id": "2402.00422",
        "abstract url": "https://arxiv.org/abs/2402.00422",
        "title": "Lightweight Pixel Difference Networks for Efficient Visual Representation Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, there have been tremendous efforts in developing lightweight Deep Neural Networks (DNNs) with satisfactory accuracy, which can enable the ubiquitous deployment of DNNs in edge devices. The core challenge of developing compact and efficient DNNs lies in how to balance the competing goals of achieving high accuracy and high efficiency. In this paper we propose two novel types of convolutions, dubbed \\emph{Pixel Difference Convolution (PDC) and Binary PDC (Bi-PDC)} which enjoy the following benefits: capturing higher-order local differential information, computationally efficient, and able to be integrated with existing DNNs. With PDC and Bi-PDC, we further present two lightweight deep networks named \\emph{Pixel Difference Networks (PiDiNet)} and \\emph{Binary PiDiNet (Bi-PiDiNet)} respectively to learn highly efficient yet more accurate representations for visual tasks including edge detection and object recognition. Extensive experiments on popular datasets (BSDS500, ImageNet, LFW, YTF, \\emph{etc.}) show that PiDiNet and Bi-PiDiNet achieve the best accuracy-efficiency trade-off. For edge detection, PiDiNet is the first network that can be trained without ImageNet, and can achieve the human-level performance on BSDS500 at 100 FPS and with $<$1M parameters. For object recognition, among existing Binary DNNs, Bi-PiDiNet achieves the best accuracy and a nearly $2\\times$ reduction of computational cost on ResNet18. Code available at \\href{https://github.com/hellozhuo/pidinet}{https://github.com/hellozhuo/pidinet}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "We design a novel lightweight convolutional operator for computer vision tasks. Both full-precision networks and BNNs are developed. Accepted by TPAMI"
    },
    {
        "paper id": "2402.00433",
        "abstract url": "https://arxiv.org/abs/2402.00433",
        "title": "Merging Multi-Task Models via Weight-Ensembling Mixture of Experts",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Merging various task-specific Transformer-based models trained on different tasks into a single unified model can execute all the tasks concurrently. Previous methods, exemplified by task arithmetic, have been proven to be both effective and scalable. Existing methods have primarily focused on seeking a static optimal solution within the original model parameter space. A notable challenge is mitigating the interference between parameters of different models, which can substantially deteriorate performance. In this paper, we propose to merge most of the parameters while upscaling the MLP of the Transformer layers to a weight-ensembling mixture of experts (MoE) module, which can dynamically integrate shared and task-specific knowledge based on the input, thereby providing a more flexible solution that can adapt to the specific needs of each instance. Our key insight is that by identifying and separating shared knowledge and task-specific knowledge, and then dynamically integrating them, we can mitigate the parameter interference problem to a great extent. We conduct the conventional multi-task model merging experiments and evaluate the generalization and robustness of our method. The results demonstrate the effectiveness of our method and provide a comprehensive understanding of our method. The code is available at https://anonymous.4open.science/r/weight-ensembling_MoE-67C9/",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00446",
        "abstract url": "https://arxiv.org/abs/2402.00446",
        "title": "Improving Dialog Safety using Socially Aware Contrastive Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "State-of-the-art conversational AI systems raise concerns due to their potential risks of generating unsafe, toxic, unethical, or dangerous content. Previous works have developed datasets to teach conversational agents the appropriate social paradigms to respond effectively to specifically designed hazardous content. However, models trained on these adversarial datasets still struggle to recognize subtle unsafe situations that appear naturally in conversations or introduce an inappropriate response in a casual context. To understand the extent of this problem, we study prosociality in both adversarial and casual dialog contexts and audit the response quality of general-purpose language models in terms of propensity to produce unsafe content. We propose a dual-step fine-tuning process to address these issues using a socially aware n-pair contrastive loss. Subsequently, we train a base model that integrates prosocial behavior by leveraging datasets like Moral Integrity Corpus (MIC) and ProsocialDialog. Experimental results on several dialog datasets demonstrate the effectiveness of our approach in generating socially appropriate responses.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "SCI-CHAT@EACL2024"
    },
    {
        "paper id": "2402.00453",
        "abstract url": "https://arxiv.org/abs/2402.00453",
        "title": "Instruction Makes a Difference",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Instruction Document Visual Question Answering (iDocVQA) dataset and Large Language Document (LLaDoc) model, for training Language-Vision (LV) models for document analysis and predictions on document images, respectively. Usually, deep neural networks for the DocVQA task are trained on datasets lacking instructions. We show that using instruction-following datasets improves performance. We compare performance across document-related datasets using the recent state-of-the-art (SotA) Large Language and Vision Assistant (LLaVA)1.5 as the base model. We also evaluate the performance of the derived models for object hallucination using the Polling-based Object Probing Evaluation (POPE) dataset. The results show that instruction-tuning performance ranges from 11X to 32X of zero-shot performance and from 0.1% to 4.2% over non-instruction (traditional task) finetuning. Despite the gains, these still fall short of human performance (94.36%), implying there's much room for improvement.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "14 pages, 8 figures"
    },
    {
        "paper id": "2402.00481",
        "abstract url": "https://arxiv.org/abs/2402.00481",
        "title": "Bias Mitigating Few-Shot Class-Incremental Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot class-incremental learning (FSCIL) aims at recognizing novel classes continually with limited novel class samples. A mainstream baseline for FSCIL is first to train the whole model in the base session, then freeze the feature extractor in the incremental sessions. Despite achieving high overall accuracy, most methods exhibit notably low accuracy for incremental classes. Some recent methods somewhat alleviate the accuracy imbalance between base and incremental classes by fine-tuning the feature extractor in the incremental sessions, but they further cause the accuracy imbalance between past and current incremental classes. In this paper, we study the causes of such classification accuracy imbalance for FSCIL, and abstract them into a unified model bias problem. Based on the analyses, we propose a novel method to mitigate model bias of the FSCIL problem during training and inference processes, which includes mapping ability stimulation, separately dual-feature classification, and self-optimizing classifiers. Extensive experiments on three widely-used FSCIL benchmark datasets show that our method significantly mitigates the model bias problem and achieves state-of-the-art performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages (not including references and checklist)"
    },
    {
        "paper id": "2402.00518",
        "abstract url": "https://arxiv.org/abs/2402.00518",
        "title": "EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This work introduces EE-Tuning, a lightweight and economical solution to training/tuning early-exit large language models (LLMs). In contrast to the common approach of full-parameter pre-training, EE-Tuning augments any pre-trained (and possibly fine-tuned) standard LLM with additional early-exit layers that are tuned in a parameter-efficient manner, which requires significantly less computational resources and training data. Our implementation of EE-Tuning achieves outstanding training efficiency via extensive performance optimizations, as well as scalability due to its full compatibility with 3D parallelism. Results of systematic experiments validate the efficacy of EE-Tuning, confirming that effective early-exit LLM inference can be achieved with a limited training budget. In hope of making early-exit LLMs accessible to the community, we release the source code of our implementation of EE-Tuning at https://github.com/pan-x-c/EE-LLM.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00530",
        "abstract url": "https://arxiv.org/abs/2402.00530",
        "title": "Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Instruction tuning is critical to improve LLMs but usually suffers from low-quality and redundant data. Data filtering for instruction tuning has proved important in improving both the efficiency and performance of the tuning process. But it also leads to extra cost and computation due to the involvement of LLMs in this process. To reduce the filtering cost, we study Superfiltering: Can we use a smaller and weaker model to select data for finetuning a larger and stronger model? Despite the performance gap between weak and strong language models, we find their highly consistent capability to perceive instruction difficulty and data selection results. This enables us to use a much smaller and more efficient model to filter the instruction data used to train a larger language model. Not only does it largely speed up the data filtering, but the filtered-data-finetuned LLM achieves even better performance on standard benchmarks. Extensive experiments validate the efficacy and efficiency of our approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00534",
        "abstract url": "https://arxiv.org/abs/2402.00534",
        "title": "A Manifold Representation of the Key in Vision Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Vision Transformers implement multi-head self-attention (MSA) via stacking multiple attention blocks. The query, key, and value are often intertwined and generated within those blocks via a single, shared linear transformation. This paper explores the concept of disentangling the key from the query and value, and adopting a manifold representation for the key. Our experiments reveal that decoupling and endowing the key with a manifold structure can enhance the model performance. Specifically, ViT-B exhibits a 0.87% increase in top-1 accuracy, while Swin-T sees a boost of 0.52% in top-1 accuracy on the ImageNet-1K dataset, with eight charts in the manifold key. Our approach also yields positive results in object detection and instance segmentation tasks on the COCO dataset. Through detailed ablation studies, we establish that these performance gains are not merely due to the simplicity of adding more parameters and computations. Future research may investigate strategies for cutting the budget of such representations and aim for further performance improvements based on our findings.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00559",
        "abstract url": "https://arxiv.org/abs/2402.00559",
        "title": "A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Prompting language models to provide step-by-step answers (e.g., \"Chain-of-Thought\") is the prominent approach for complex reasoning tasks, where more accurate reasoning chains typically improve downstream task performance. Recent literature discusses automatic methods to verify reasoning to evaluate and improve their correctness. However, no fine-grained step-level datasets are available to enable thorough evaluation of such verification methods, hindering progress in this direction. We introduce REVEAL: Reasoning Verification Evaluation, a dataset to benchmark automatic verifiers of complex Chain-of-Thought reasoning in open-domain question-answering settings. REVEAL includes comprehensive labels for the relevance, attribution to evidence passages, and logical correctness of each reasoning step in a language model's answer, across a variety of datasets and state-of-the-art language models. Evaluation on REVEAL shows that verifiers struggle at verifying reasoning chains - in particular, verifying logical correctness and detecting contradictions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Dataset at https://huggingface.co/datasets/google/reveal"
    },
    {
        "paper id": "2402.00606",
        "abstract url": "https://arxiv.org/abs/2402.00606",
        "title": "Dynamic Texture Transfer using PatchMatch and Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "How to automatically transfer the dynamic texture of a given video to the target still image is a challenging and ongoing problem. In this paper, we propose to handle this task via a simple yet effective model that utilizes both PatchMatch and Transformers. The key idea is to decompose the task of dynamic texture transfer into two stages, where the start frame of the target video with the desired dynamic texture is synthesized in the first stage via a distance map guided texture transfer module based on the PatchMatch algorithm. Then, in the second stage, the synthesized image is decomposed into structure-agnostic patches, according to which their corresponding subsequent patches can be predicted by exploiting the powerful capability of Transformers equipped with VQ-VAE for processing long discrete sequences. After getting all those patches, we apply a Gaussian weighted average merging strategy to smoothly assemble them into each frame of the target stylized video. Experimental results demonstrate the effectiveness and superiority of the proposed method in dynamic texture transfer compared to the state of the art.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00608",
        "abstract url": "https://arxiv.org/abs/2402.00608",
        "title": "Deep Clustering Using the Soft Silhouette Score: Towards Compact and Well-Separated Clusters",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised learning has gained prominence in the big data era, offering a means to extract valuable insights from unlabeled datasets. Deep clustering has emerged as an important unsupervised category, aiming to exploit the non-linear mapping capabilities of neural networks in order to enhance clustering performance. The majority of deep clustering literature focuses on minimizing the inner-cluster variability in some embedded space while keeping the learned representation consistent with the original high-dimensional dataset. In this work, we propose soft silhoutte, a probabilistic formulation of the silhouette coefficient. Soft silhouette rewards compact and distinctly separated clustering solutions like the conventional silhouette coefficient. When optimized within a deep clustering framework, soft silhouette guides the learned representations towards forming compact and well-separated clusters. In addition, we introduce an autoencoder-based deep learning architecture that is suitable for optimizing the soft silhouette objective function. The proposed deep clustering method has been tested and compared with several well-studied deep clustering methods on various benchmark datasets, yielding very satisfactory clustering results.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00620",
        "abstract url": "https://arxiv.org/abs/2402.00620",
        "title": "Actor Identification in Discourse: A Challenge for LLMs?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The identification of political actors who put forward claims in public debate is a crucial step in the construction of discourse networks, which are helpful to analyze societal debates. Actor identification is, however, rather challenging: Often, the locally mentioned speaker of a claim is only a pronoun (\"He proposed that [claim]\"), so recovering the canonical actor name requires discourse understanding. We compare a traditional pipeline of dedicated NLP components (similar to those applied to the related task of coreference) with a LLM, which appears a good match for this generation task. Evaluating on a corpus of German actors in newspaper reports, we find surprisingly that the LLM performs worse. Further analysis reveals that the LLM is very good at identifying the right reference, but struggles to generate the correct canonical form. This points to an underlying issue in LLMs with controlling generated output. Indeed, a hybrid model combining the LLM with a classifier to normalize its output substantially outperforms both initial models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Proceedings of the EACL 2024 workshop on Computational Models of Discourse (St. Julian's, Malta)"
    },
    {
        "paper id": "2402.00626",
        "abstract url": "https://arxiv.org/abs/2402.00626",
        "title": "Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Attacks"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Typographic Attacks, which involve pasting misleading text onto an image, were noted to harm the performance of Vision-Language Models like CLIP. However, the susceptibility of recent Large Vision-Language Models to these attacks remains understudied. Furthermore, prior work's Typographic attacks against CLIP randomly sample a misleading class from a predefined set of categories. However, this simple strategy misses more effective attacks that exploit LVLM(s) stronger language skills. To address these issues, we first introduce a benchmark for testing Typographic attacks against LVLM(s). Moreover, we introduce two novel and more effective \\textit{Self-Generated} attacks which prompt the LVLM to generate an attack against itself: 1) Class Based Attack where the LVLM (e.g. LLaVA) is asked which deceiving class is most similar to the target class and 2) Descriptive Attacks where a more advanced LVLM (e.g. GPT4-V) is asked to recommend a Typographic attack that includes both a deceiving class and description. Using our benchmark, we uncover that Self-Generated attacks pose a significant threat, reducing LVLM(s) classification performance by up to 33\\%. We also uncover that attacks generated by one model (e.g. GPT-4V or LLaVA) are effective against the model itself and other models like InstructBLIP and MiniGPT4. Code: \\url{https://github.com/mqraitem/Self-Gen-Typo-Attack}",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00632",
        "abstract url": "https://arxiv.org/abs/2402.00632",
        "title": "Prosody in Cascade and Direct Speech-to-Text Translation: a case study on Korean Wh-Phrases",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Speech-to-Text Translation (S2TT) has typically been addressed with cascade systems, where speech recognition systems generate a transcription that is subsequently passed to a translation model. While there has been a growing interest in developing direct speech translation systems to avoid propagating errors and losing non-verbal content, prior work in direct S2TT has struggled to conclusively establish the advantages of integrating the acoustic signal directly into the translation process. This work proposes using contrastive evaluation to quantitatively measure the ability of direct S2TT systems to disambiguate utterances where prosody plays a crucial role. Specifically, we evaluated Korean-English translation systems on a test set containing wh-phrases, for which prosodic features are necessary to produce translations with the correct intent, whether it's a statement, a yes/no question, a wh-question, and more. Our results clearly demonstrate the value of direct translation systems over cascade translation models, with a notable 12.9% improvement in overall accuracy in ambiguous cases, along with up to a 15.6% increase in F1 scores for one of the major intent categories. To the best of our knowledge, this work stands as the first to provide quantitative evidence that direct S2TT models can effectively leverage prosody. The code for our evaluation is openly accessible and freely available for review and utilisation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at Findings of EACL 2024"
    },
    {
        "paper id": "2402.00667",
        "abstract url": "https://arxiv.org/abs/2402.00667",
        "title": "Improving Weak-to-Strong Generalization with Scalable Oversight and Ensemble Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a follow-up study to OpenAI's recent superalignment work on Weak-to-Strong Generalization (W2SG). Superalignment focuses on ensuring that high-level AI systems remain consistent with human values and intentions when dealing with complex, high-risk tasks. The W2SG framework has opened new possibilities for empirical research in this evolving field. Our study simulates two phases of superalignment under the W2SG framework: the development of general superhuman models and the progression towards superintelligence. In the first phase, based on human supervision, the quality of weak supervision is enhanced through a combination of scalable oversight and ensemble learning, reducing the capability gap between weak teachers and strong students. In the second phase, an automatic alignment evaluator is employed as the weak supervisor. By recursively updating this auto aligner, the capabilities of the weak teacher models are synchronously enhanced, achieving weak-to-strong supervision over stronger student models.We also provide an initial validation of the proposed approach for the first phase. Using the SciQ task as example, we explore ensemble learning for weak teacher models through bagging and boosting. Scalable oversight is explored through two auxiliary settings: human-AI interaction and AI-AI debate. Additionally, the paper discusses the impact of improved weak supervision on enhancing weak-to-strong generalization based on in-context learning. Experiment code and dataset will be released at https://github.com/ADaM-BJTU/W2SG.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00707",
        "abstract url": "https://arxiv.org/abs/2402.00707",
        "title": "Non-Exchangeable Conformal Language Generation with Nearest Neighbors",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Quantifying uncertainty in automatically generated text is important for letting humans check potential hallucinations and making systems more reliable. Conformal prediction is an attractive framework to provide predictions imbued with statistical guarantees, however, its application to text generation is challenging since any i.i.d. assumptions are not realistic. In this paper, we bridge this gap by leveraging recent results on non-exchangeable conformal prediction, which still ensures bounds on coverage. The result, non-exchangeable conformal nucleus sampling, is a novel extension of the conformal prediction framework to generation based on nearest neighbors. Our method can be used post-hoc for an arbitrary model without extra training and supplies token-level, calibrated prediction sets equipped with statistical guarantees. Experiments in machine translation and language modeling show encouraging results in generation quality. By also producing tighter prediction sets with good coverage, we thus give a more theoretically principled way to perform sampling with conformal guarantees.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00711",
        "abstract url": "https://arxiv.org/abs/2402.00711",
        "title": "Explaining Text Classifiers with Counterfactual Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "One well motivated explanation method for classifiers leverages counterfactuals which are hypothetical events identical to real observations in all aspects except for one categorical feature. Constructing such counterfactual poses specific challenges for texts, however, as some attribute values may not necessarily align with plausible real-world events. In this paper we propose a simple method for generating counterfactuals by intervening in the space of text representations which bypasses this limitation. We argue that our interventions are minimally disruptive and that they are theoretically sound as they align with counterfactuals as defined in Pearl's causal inference framework. To validate our method, we conducted experiments first on a synthetic dataset and then on a realistic dataset of counterfactuals. This allows for a direct comparison between classifier predictions based on ground truth counterfactuals - obtained through explicit text interventions - and our counterfactuals, derived through interventions in the representation space. Eventually, we study a real world scenario where our counterfactuals can be leveraged both for explaining a classifier and for bias mitigation.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "24 pages, 4 figures"
    },
    {
        "paper id": "2402.00723",
        "abstract url": "https://arxiv.org/abs/2402.00723",
        "title": "Improving Semantic Control in Discrete Latent Spaces with Transformer Quantized Variational Autoencoders",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Achieving precise semantic control over the latent spaces of Variational AutoEncoders (VAEs) holds significant value for downstream tasks in NLP as the underlying generative mechanisms could be better localised, explained and improved upon. Recent research, however, has struggled to achieve consistent results, primarily due to the inevitable loss of semantic information in the variational bottleneck and limited control over the decoding mechanism. To overcome these challenges, we investigate discrete latent spaces in Vector Quantized Variational AutoEncoders (VQVAEs) to improve semantic control and generation in Transformer-based VAEs. In particular, We propose T5VQVAE, a novel model that leverages the controllability of VQVAEs to guide the self-attention mechanism in T5 at the token-level, exploiting its full generalization capabilities. Experimental results indicate that T5VQVAE outperforms existing state-of-the-art VAE models, including Optimus, in terms of controllability and preservation of semantic information across different tasks such as auto-encoding of sentences and mathematical expressions, text transfer, and inference. Moreover, T5VQVAE exhibits improved inference capabilities, suggesting potential applications for downstream natural language and symbolic reasoning tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00728",
        "abstract url": "https://arxiv.org/abs/2402.00728",
        "title": "Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Predictive multiplicity refers to the phenomenon in which classification tasks may admit multiple competing models that achieve almost-equally-optimal performance, yet generate conflicting outputs for individual samples. This presents significant concerns, as it can potentially result in systemic exclusion, inexplicable discrimination, and unfairness in practical applications. Measuring and mitigating predictive multiplicity, however, is computationally challenging due to the need to explore all such almost-equally-optimal models, known as the Rashomon set, in potentially huge hypothesis spaces. To address this challenge, we propose a novel framework that utilizes dropout techniques for exploring models in the Rashomon set. We provide rigorous theoretical derivations to connect the dropout parameters to properties of the Rashomon set, and empirically evaluate our framework through extensive experimentation. Numerical results show that our technique consistently outperforms baselines in terms of the effectiveness of predictive multiplicity metric estimation, with runtime speedup up to $20\\times \\sim 5000\\times$. With efficient Rashomon set exploration and metric estimation, mitigation of predictive multiplicity is then achieved through dropout ensemble and model selection.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2402.00742",
        "abstract url": "https://arxiv.org/abs/2402.00742",
        "title": "Transforming and Combining Rewards for Aligning Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "A common approach for aligning language models to human preferences is to first learn a reward model from preference data, and then use this reward model to update the language model. We study two closely related problems that arise in this approach. First, any monotone transformation of the reward model preserves preference ranking; is there a choice that is ``better'' than others? Second, we often wish to align language models to multiple properties: how should we combine multiple reward models? Using a probabilistic interpretation of the alignment procedure, we identify a natural choice for transformation for (the common case of) rewards learned from Bradley-Terry preference models. This derived transformation has two important properties. First, it emphasizes improving poorly-performing outputs, rather than outputs that already score well. This mitigates both underfitting (where some prompts are not improved) and reward hacking (where the model learns to exploit misspecification of the reward model). Second, it enables principled aggregation of rewards by linking summation to logical conjunction: the sum of transformed rewards corresponds to the probability that the output is ``good'' in all measured properties, in a sense we make precise. Experiments aligning language models to be both helpful and harmless using RLHF show substantial improvements over the baseline (non-transformed) approach.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00743",
        "abstract url": "https://arxiv.org/abs/2402.00743",
        "title": "Benefits of Transformer: In-Context Learning in Linear Regression Tasks with Unstructured Data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In practice, it is observed that transformer-based models can learn concepts in context in the inference stage. While existing literature, e.g., \\citet{zhang2023trained,huang2023context}, provide theoretical explanations on this in-context learning ability, they assume the input $x_i$ and the output $y_i$ for each sample are embedded in the same token (i.e., structured data). However, in reality, they are presented in two tokens (i.e., unstructured data \\cite{wibisono2023role}). In this case, this paper conducts experiments in linear regression tasks to study the benefits of the architecture of transformers and provides some corresponding theoretical intuitions to explain why the transformer can learn from unstructured data. We study the exact components in a transformer that facilitate the in-context learning. In particular, we observe that (1) a transformer with two layers of softmax (self-)attentions with look-ahead attention mask can learn from the prompt if $y_i$ is in the token next to $x_i$ for each example; (2) positional encoding can further improve the performance; and (3) multi-head attention with a high input embedding dimension has a better prediction performance than single-head attention.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00744",
        "abstract url": "https://arxiv.org/abs/2402.00744",
        "title": "BATON: Aligning Text-to-Audio Model with Human Preference Feedback",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the development of AI-Generated Content (AIGC), text-to-audio models are gaining widespread attention. However, it is challenging for these models to generate audio aligned with human preference due to the inherent information density of natural language and limited model understanding ability. To alleviate this issue, we formulate the BATON, a framework designed to enhance the alignment between generated audio and text prompt using human preference feedback. Our BATON comprises three key stages: Firstly, we curated a dataset containing both prompts and the corresponding generated audio, which was then annotated based on human feedback. Secondly, we introduced a reward model using the constructed dataset, which can mimic human preference by assigning rewards to input text-audio pairs. Finally, we employed the reward model to fine-tune an off-the-shelf text-to-audio model. The experiment results demonstrate that our BATON can significantly improve the generation quality of the original text-to-audio models, concerning audio integrity, temporal relationship, and alignment with human preference.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00745",
        "abstract url": "https://arxiv.org/abs/2402.00745",
        "title": "Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "An increasing amount of research in Natural Language Inference (NLI) focuses on the application and evaluation of Large Language Models (LLMs) and their reasoning capabilities. Despite their success, however, LLMs are still prone to factual errors and inconsistencies in their explanations, offering limited control and interpretability for inference in complex domains. In this paper, we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques can enhance the logical validity and alignment of ethical explanations produced by LLMs. Specifically, we present an abductive-deductive framework named Logic-Explainer, which integrates LLMs with an external backward-chaining solver to refine step-wise natural language explanations and jointly verify their correctness, reduce incompleteness and minimise redundancy. An extensive empirical analysis demonstrates that Logic-Explainer can improve explanations generated via in-context learning methods and Chain-of-Thought (CoT) on challenging ethical NLI tasks, while, at the same time, producing formal proofs describing and supporting models' reasoning. As ethical NLI requires commonsense reasoning to identify underlying moral violations, our results suggest the effectiveness of neuro-symbolic methods for multi-step NLI more broadly, opening new opportunities to enhance the logical consistency, reliability, and alignment of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Camera-ready for EACL 2024"
    },
    {
        "paper id": "2402.00769",
        "abstract url": "https://arxiv.org/abs/2402.00769",
        "title": "AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Video diffusion models has been gaining increasing attention for its ability to produce videos that are both coherent and of high fidelity. However, the iterative denoising process makes it computationally intensive and time-consuming, thus limiting its applications. Inspired by the Consistency Model (CM) that distills pretrained image diffusion models to accelerate the sampling with minimal steps and its successful extension Latent Consistency Model (LCM) on conditional image generation, we propose AnimateLCM, allowing for high-fidelity video generation within minimal steps. Instead of directly conducting consistency learning on the raw video dataset, we propose a decoupled consistency learning strategy that decouples the distillation of image generation priors and motion generation priors, which improves the training efficiency and enhance the generation visual quality. Additionally, to enable the combination of plug-and-play adapters in stable diffusion community to achieve various functions (e.g., ControlNet for controllable generation). we propose an efficient strategy to adapt existing adapters to our distilled text-conditioned video consistency model or train adapters from scratch without harming the sampling speed. We validate the proposed strategy in image-conditioned video generation and layout-conditioned video generation, all achieving top-performing results. Experimental results validate the effectiveness of our proposed method. Code and weights will be made public. More details are available at https://github.com/G-U-N/AnimateLCM.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project Page: https://animatelcm.github.io/"
    },
    {
        "paper id": "2402.00798",
        "abstract url": "https://arxiv.org/abs/2402.00798",
        "title": "Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements on Large Language Models (LLMs) enable AI Agents to automatically generate and execute multi-step plans to solve complex tasks. However, since LLM's content generation process is hardly controllable, current LLM-based agents frequently generate invalid or non-executable plans, which jeopardizes the performance of the generated plans and corrupts users' trust in LLM-based agents. In response, this paper proposes a novel ``Formal-LLM'' framework for LLM-based agents by integrating the expressiveness of natural language and the precision of formal language. Specifically, the framework allows human users to express their requirements or constraints for the planning process as an automaton. A stack-based LLM plan generation process is then conducted under the supervision of the automaton to ensure that the generated plan satisfies the constraints, making the planning process controllable. We conduct experiments on both benchmark tasks and practical real-life tasks, and our framework achieves over 50% overall performance increase, which validates the feasibility and effectiveness of employing Formal-LLM to guide the plan generation of agents, preventing the agents from generating invalid and unsuccessful plans. Further, more controllable LLM-based agents can facilitate the broader utilization of LLM in application scenarios where high validity of planning is essential. The work is open-sourced at https://github.com/agiresearch/Formal-LLM.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.FL"
        ],
        "comment": "21 pages, 6 figures; comments and suggestions are welcome"
    },
    {
        "paper id": "2402.00820",
        "abstract url": "https://arxiv.org/abs/2402.00820",
        "title": "USDnet: Unsupervised Speech Dereverberation via Neural Forward Filtering",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "In reverberant conditions with a single speaker, each far-field microphone records a reverberant version of the same speaker signal at a different location. In over-determined conditions, where there are more microphones than speakers, each recorded mixture signal can be leveraged as a constraint to narrow down the solutions to target anechoic speech and thereby reduce reverberation. Equipped with this insight, we propose USDnet, a novel deep neural network (DNN) approach for unsupervised speech dereverberation (USD). At each training step, we first feed an input mixture to USDnet to produce an estimate for target speech, and then linearly filter the DNN estimate to approximate the multi-microphone mixture so that the constraint can be satisfied at each microphone, thereby regularizing the DNN estimate to approximate target anechoic speech. The linear filter can be estimated based on the mixture and DNN estimate via neural forward filtering algorithms such as forward convolutive prediction. We show that this novel methodology can promote unsupervised dereverberation of single-source reverberant speech.",
        "subjects": [
            "eess.AS",
            "eess.SP"
        ],
        "comment": "in submission"
    },
    {
        "paper id": "2402.00827",
        "abstract url": "https://arxiv.org/abs/2402.00827",
        "title": "Emo-Avatar: Efficient Monocular Video Style Avatar through Texture Rendering",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Avatar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Artistic video portrait generation is a significant and sought-after task in the fields of computer graphics and vision. While various methods have been developed that integrate NeRFs or StyleGANs with instructional editing models for creating and editing drivable portraits, these approaches face several challenges. They often rely heavily on large datasets, require extensive customization processes, and frequently result in reduced image quality. To address the above problems, we propose the Efficient Monotonic Video Style Avatar (Emo-Avatar) through deferred neural rendering that enhances StyleGAN's capacity for producing dynamic, drivable portrait videos. We proposed a two-stage deferred neural rendering pipeline. In the first stage, we utilize few-shot PTI initialization to initialize the StyleGAN generator through several extreme poses sampled from the video to capture the consistent representation of aligned faces from the target portrait. In the second stage, we propose a Laplacian pyramid for high-frequency texture sampling from UV maps deformed by dynamic flow of expression for motion-aware texture prior integration to provide torso features to enhance StyleGAN's ability to generate complete and upper body for portrait video rendering. Emo-Avatar reduces style customization time from hours to merely 5 minutes compared with existing methods. In addition, Emo-Avatar requires only a single reference image for editing and employs region-aware contrastive learning with semantic invariant CLIP guidance, ensuring consistent high-resolution output and identity preservation. Through both quantitative and qualitative assessments, Emo-Avatar demonstrates superior performance over existing methods in terms of training efficiency, rendering quality and editability in self- and cross-reenactment.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The paper paper needs a big modification, including the tile. This work is no longer its original version"
    },
    {
        "paper id": "2402.00838",
        "abstract url": "https://arxiv.org/abs/2402.00838",
        "title": "OLMo: Accelerating the Science of Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and development undisclosed. Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs. To this end, this technical report details the first release of OLMo, a state-of-the-art, truly Open Language Model and its framework to build and study the science of language modeling. Unlike most prior efforts that have only released model weights and inference code, we release OLMo and the whole framework, including training data and training and evaluation code. We hope this release will empower and strengthen the open research community and inspire a new wave of innovation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00856",
        "abstract url": "https://arxiv.org/abs/2402.00856",
        "title": "Towards Efficient and Exact Optimization of Language Model Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The alignment of language models with human preferences is vital for their application in real-world tasks. The problem is formulated as optimizing the model's policy to maximize the expected reward that reflects human preferences with minimal deviation from the initial policy. While considered as a straightforward solution, reinforcement learning (RL) suffers from high variance in policy updates, which impedes efficient policy improvement. Recently, direct preference optimization (DPO) was proposed to directly optimize the policy from preference data. Though simple to implement, DPO is derived based on the optimal policy that is not assured to be achieved in practice, which undermines its convergence to the intended solution. In this paper, we propose efficient exact optimization (EXO) of the alignment objective. We prove that EXO is guaranteed to optimize in the same direction as the RL algorithms asymptotically for arbitary parametrization of the policy, while enables efficient optimization by circumventing the complexities associated with RL algorithms. We compare our method to DPO with both theoretical and empirical analyses, and further demonstrate the advantages of our method over existing approaches on realistic human preference data. Code is available at https://github.com/haozheji/exact-optimization.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "24 pages, 9 figures"
    },
    {
        "paper id": "2402.00858",
        "abstract url": "https://arxiv.org/abs/2402.00858",
        "title": "Can Large Language Models Understand Context?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Understanding context is key to understanding human language, an ability which Large Language Models (LLMs) have been increasingly seen to demonstrate to an impressive extent. However, though the evaluation of LLMs encompasses various domains within the realm of Natural Language Processing, limited attention has been paid to probing their linguistic capability of understanding contextual features. This paper introduces a context understanding benchmark by adapting existing datasets to suit the evaluation of generative models. This benchmark comprises of four distinct tasks and nine datasets, all featuring prompts designed to assess the models' ability to understand context. First, we evaluate the performance of LLMs under the in-context learning pretraining scenario. Experimental results indicate that pre-trained dense models struggle with understanding more nuanced contextual features when compared to state-of-the-art fine-tuned models. Second, as LLM compression holds growing significance in both research and real-world applications, we assess the context understanding of quantized models under in-context-learning settings. We find that 3-bit post-training quantization leads to varying degrees of performance reduction on our benchmark. We conduct an extensive analysis of these scenarios to substantiate our experimental results.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Findings of EACL 2024"
    },
    {
        "paper id": "2402.00861",
        "abstract url": "https://arxiv.org/abs/2402.00861",
        "title": "Evaluating Large Language Models for Generalization and Robustness via Data Compression",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Existing methods for evaluating large language models face challenges such as data contamination, sensitivity to prompts, and the high cost of benchmark creation. To address this, we propose a lossless data compression based evaluation approach that tests how models' predictive abilities generalize after their training cutoff. Specifically, we collect comprehensive test data spanning 83 months from 2017 to 2023 and split the data into training and testing periods according to models' training data cutoff. We measure: 1) the compression performance on the testing period as a measure of generalization on unseen data; and 2) the performance gap between the training and testing period as a measure of robustness. Our experiments test 14 representative large language models with various sizes on sources including Wikipedia, news articles, code, arXiv papers, and multi-modal data. We find that the compression rate of many models reduces significantly after their cutoff date, but models such as Mistral and Llama-2 demonstrate a good balance between performance and robustness. Results also suggest that models struggle to generalize on news and code data, but work especially well on arXiv papers. We also find the context size and tokenization implementation have a big impact of on the overall compression performance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00868",
        "abstract url": "https://arxiv.org/abs/2402.00868",
        "title": "We're Not Using Videos Effectively: An Updated Domain Adaptive Video Segmentation Baseline",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "There has been abundant work in unsupervised domain adaptation for semantic segmentation (DAS) seeking to adapt a model trained on images from a labeled source domain to an unlabeled target domain. While the vast majority of prior work has studied this as a frame-level Image-DAS problem, a few Video-DAS works have sought to additionally leverage the temporal signal present in adjacent frames. However, Video-DAS works have historically studied a distinct set of benchmarks from Image-DAS, with minimal cross-benchmarking. In this work, we address this gap. Surprisingly, we find that (1) even after carefully controlling for data and model architecture, state-of-the-art Image-DAS methods (HRDA and HRDA+MIC) outperform Video-DAS methods on established Video-DAS benchmarks (+14.5 mIoU on Viper$\\rightarrow$CityscapesSeq, +19.0 mIoU on Synthia$\\rightarrow$CityscapesSeq), and (2) naive combinations of Image-DAS and Video-DAS techniques only lead to marginal improvements across datasets. To avoid siloed progress between Image-DAS and Video-DAS, we open-source our codebase with support for a comprehensive set of Video-DAS and Image-DAS methods on a common benchmark. Code available at https://github.com/SimarKareer/UnifiedVideoDA",
        "subjects": [
            "cs.CV"
        ],
        "comment": "TMLR 2024"
    },
    {
        "paper id": "2402.00909",
        "abstract url": "https://arxiv.org/abs/2402.00909",
        "title": "Generalizing GradCAM for Embedding Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visualizing CNN is an important part in building trust and explaining model's prediction. Methods like CAM and GradCAM have been really successful in localizing area of the image responsible for the output but are only limited to classification models. In this paper, we present a new method EmbeddingCAM, which generalizes the Grad-CAM for embedding networks. We show that for classification networks, EmbeddingCAM reduces to GradCAM. We show the effectiveness of our method on CUB-200-2011 dataset and also present quantitative and qualitative analysis on the dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00912",
        "abstract url": "https://arxiv.org/abs/2402.00912",
        "title": "Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Concept Bottleneck Models (CBMs) are considered inherently interpretable because they first predict a set of human-defined concepts before using these concepts to predict the output of a downstream task. For inherent interpretability to be fully realised, and ensure trust in a model's output, we need to guarantee concepts are predicted based on semantically mapped input features. For example, one might expect the pixels representing a broken bone in an image to be used for the prediction of a fracture. However, current literature indicates this is not the case, as concept predictions are often mapped to irrelevant input features. We hypothesise that this occurs when concept annotations are inaccurate or how input features should relate to concepts is unclear. In general, the effect of dataset labelling on concept representations in CBMs remains an understudied area. Therefore, in this paper, we examine how CBMs learn concepts from datasets with fine-grained concept annotations. We demonstrate that CBMs can learn concept representations with semantic mapping to input features by removing problematic concept correlations, such as two concepts always appearing together. To support our evaluation, we introduce a new synthetic image dataset based on a playing cards domain, which we hope will serve as a benchmark for future CBM research. For validation, we provide empirical evidence on a real-world dataset of chest X-rays, to demonstrate semantically meaningful concepts can be learned in real-world applications.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Main paper: 7 pages, 8 figures, Appendix: 15 pages, 22 figures. This paper is a preprint"
    },
    {
        "paper id": "2402.00913",
        "abstract url": "https://arxiv.org/abs/2402.00913",
        "title": "Institutional Platform for Secure Self-Service Large Language Model Exploration",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces a user-friendly platform developed by the University of Kentucky Center for Applied AI, designed to make large, customized language models (LLMs) more accessible. By capitalizing on recent advancements in multi-LoRA inference, the system efficiently accommodates custom adapters for a diverse range of users and projects. The paper outlines the system's architecture and key features, encompassing dataset curation, model training, secure inference, and text-based feature extraction. We illustrate the establishment of a tenant-aware computational network using agent-based methods, securely utilizing islands of isolated resources as a unified system. The platform strives to deliver secure LLM services, emphasizing process and data isolation, end-to-end encryption, and role-based resource authentication. This contribution aligns with the overarching goal of enabling simplified access to cutting-edge AI models and technology in support of scientific discovery.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "10 pages 11 figures, 5 listings, 4 tables"
    },
    {
        "paper id": "2402.00956",
        "abstract url": "https://arxiv.org/abs/2402.00956",
        "title": "Exploring Spatial Schema Intuitions in Large Language and Vision Models",
        "rating": "1",
        "keywords": [
            [
                "vision language"
            ],
            [
                "robotics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite the ubiquity of large language models (LLMs) in AI research, the question of embodiment in LLMs remains underexplored, distinguishing them from embodied systems in robotics where sensory perception directly informs physical action. Our investigation navigates the intriguing terrain of whether LLMs, despite their non-embodied nature, effectively capture implicit human intuitions about fundamental, spatial building blocks of language. We employ insights from spatial cognitive foundations developed through early sensorimotor experiences, guiding our exploration through the reproduction of three psycholinguistic experiments. Surprisingly, correlations between model outputs and human responses emerge, revealing adaptability without a tangible connection to embodied experiences. Notable distinctions include polarized language model responses and reduced correlations in vision language models. This research contributes to a nuanced understanding of the interplay between language, spatial experiences, and the computations made by large language models. More at https://cisnlp.github.io/Spatial_Schemas/",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2402.00965",
        "abstract url": "https://arxiv.org/abs/2402.00965",
        "title": "Multi-Modal Machine Learning Framework for Automated Seizure Detection in Laboratory Rats",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "A multi-modal machine learning system uses multiple unique data sources and types to improve its performance. This article proposes a system that combines results from several types of models, all of which are trained on different data signals. As an example to illustrate the efficacy of the system, an experiment is described in which multiple types of data are collected from rats suffering from seizures. This data includes electrocorticography readings, piezoelectric motion sensor data, and video recordings. Separate models are trained on each type of data, with the goal of classifying each time frame as either containing a seizure or not. After each model has generated its classification predictions, these results are combined. While each data signal works adequately on its own for prediction purposes, the significant imbalance in class labels leads to increased numbers of false positives, which can be filtered and removed by utilizing all data sources. This paper will demonstrate that, after postprocessing and combination techniques, classification accuracy is improved with this multi-modal system when compared to the performance of each individual data source.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00969",
        "abstract url": "https://arxiv.org/abs/2402.00969",
        "title": "SPARQL Generation with Entity Pre-trained GPT for KG Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge Graphs popularity has been rapidly growing in last years. All that knowledge is available for people to query it through the many online databases on the internet. Though, it would be a great achievement if non-programmer users could access whatever information they want to know. There has been a lot of effort oriented to solve this task using natural language processing tools and creativity encouragement by way of many challenges. Our approach focuses on assuming a correct entity linking on the natural language questions and training a GPT model to create SPARQL queries from them. We managed to isolate which property of the task can be the most difficult to solve at few or zero-shot and we proposed pre-training on all entities (under CWA) to improve the performance. We obtained a 62.703% accuracy of exact SPARQL matches on testing at 3-shots, a F1 of 0.809 on the entity linking challenge and a F1 of 0.009 on the question answering challenge.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB",
            "cs.IR"
        ],
        "comment": "7 pages, 1 figure, 2 tables. For the implementation, see https://github.com/DiegoEmilio01/SPARQL-generation-with-entity-pre-trained-GPT-for-KG-Question-Answering"
    },
    {
        "paper id": "2402.00978",
        "abstract url": "https://arxiv.org/abs/2402.00978",
        "title": "An Information-Theoretic Approach to Analyze NLP Classification Tasks",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Understanding the importance of the inputs on the output is useful across many tasks. This work provides an information-theoretic framework to analyse the influence of inputs for text classification tasks. Natural language processing (NLP) tasks take either a single element input or multiple element inputs to predict an output variable, where an element is a block of text. Each text element has two components: an associated semantic meaning and a linguistic realization. Multiple-choice reading comprehension (MCRC) and sentiment classification (SC) are selected to showcase the framework. For MCRC, it is found that the context influence on the output compared to the question influence reduces on more challenging datasets. In particular, more challenging contexts allow a greater variation in complexity of questions. Hence, test creators need to carefully consider the choice of the context when designing multiple-choice questions for assessment. For SC, it is found the semantic meaning of the input text dominates (above 80\\% for all datasets considered) compared to its linguistic realisation when determining the sentiment. The framework is made available at: https://github.com/WangLuran/nlp-element-influence",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IT"
        ],
        "comment": "21 pages, 10 figures, 11 tables"
    },
    {
        "paper id": "2402.00994",
        "abstract url": "https://arxiv.org/abs/2402.00994",
        "title": "A Cost-Efficient Approach for Creating Virtual Fitting Room using Generative Adversarial Networks (GANs)",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Customers all over the world want to see how the clothes fit them or not before purchasing. Therefore, customers by nature prefer brick-and-mortar clothes shopping so they can try on products before purchasing them. But after the Pandemic of COVID19 many sellers either shifted to online shopping or closed their fitting rooms which made the shopping process hesitant and doubtful. The fact that the clothes may not be suitable for their buyers after purchase led us to think about using new AI technologies to create an online platform or a virtual fitting room (VFR) in the form of a mobile application and a deployed model using a webpage that can be embedded later to any online store where they can try on any number of cloth items without physically trying them. Besides, it will save much searching time for their needs. Furthermore, it will reduce the crowding and headache in the physical shops by applying the same technology using a special type of mirror that will enable customers to try on faster. On the other hand, from business owners' perspective, this project will highly increase their online sales, besides, it will save the quality of the products by avoiding physical trials issues. The main approach used in this work is applying Generative Adversarial Networks (GANs) combined with image processing techniques to generate one output image from two input images which are the person image and the cloth image. This work achieved results that outperformed the state-of-the-art approaches found in literature.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01030",
        "abstract url": "https://arxiv.org/abs/2402.01030",
        "title": "Executable Code Actions Elicit Better LLM Agents",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python code to consolidate LLM agents' actions into a unified action space (CodeAct). Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate). The encouraging performance of CodeAct motivates us to build an open-source LLM agent that interacts with environments by executing interpretable code and collaborates with users using natural language. To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct. We show that it can be used with existing data to improve models in agent-oriented tasks without compromising their general capability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated with Python interpreter and uniquely tailored to perform sophisticated tasks (e.g., model training) using existing libraries and autonomously self-debug.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Code, data, model, and demo are available at https://github.com/xingyaoww/code-act"
    },
    {
        "paper id": "2402.01035",
        "abstract url": "https://arxiv.org/abs/2402.01035",
        "title": "Getting the most out of your tokenizer for pre-training and domain adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Tokenization is an understudied and often neglected component of modern LLMs. Most published works use a single tokenizer for all experiments, often borrowed from another model, without performing ablations or analysis to optimize tokenization. Moreover, the tokenizer is generally kept unchanged when fine-tuning a base model. In this paper, we show that the size, pre-tokenization regular expression, and training data of a tokenizer can significantly impact the model's generation speed, effective context size, memory usage, and downstream performance. We train specialized Byte-Pair Encoding code tokenizers, and conduct extensive ablations on the impact of tokenizer design on the performance of LLMs for code generation tasks such as HumanEval and MBPP, and provide recommendations for tokenizer hyper-parameters selection and switching the tokenizer in a pre-trained LLM. We perform our experiments on models trained from scratch and from pre-trained models, verifying their applicability to a wide range of use-cases. We find that when fine-tuning on more than 50 billion tokens, we can specialize the tokenizer of a pre-trained LLM to obtain large gains in generation speed and effective context size.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01051",
        "abstract url": "https://arxiv.org/abs/2402.01051",
        "title": "Generation, Distillation and Evaluation of Motivational Interviewing-Style Reflections with a Foundational Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Foundational Language Models are capable of performing many tasks at a high level but are difficult to deploy in many applications because of their size and proprietary ownership. Many will be motivated to distill specific capabilities of foundational models into smaller models that can be owned and controlled. In the development of a therapeutic chatbot, we wish to distill a capability known as reflective listening, in which a therapist produces reflections of client speech. These reflections either restate what a client has said, or connect what was said to a relevant observation, idea or guess that encourages and guides the client to continue contemplation. In this paper, we present a method for distilling the generation of reflections from a Foundational Language Model (GPT-4) into smaller models. We first show that GPT-4, using zero-shot prompting, can generate reflections at near 100% success rate, superior to all previous methods. Using reflections generated by GPT-4, we fine-tune different sizes of the GPT-2 family. The GPT-2-small model achieves 83% success on a hold-out test set and the GPT-2 XL achieves 90% success. We also show that GPT-4 can help in the labor-intensive task of evaluating the quality of the distilled models, using it as a zero-shot classifier. Using triple-human review as a guide, the classifier achieves a Cohen-Kappa of 0.66, a substantial inter-rater reliability figure.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EACL 2024 Long Paper"
    },
    {
        "paper id": "2402.01053",
        "abstract url": "https://arxiv.org/abs/2402.01053",
        "title": "Plan-Grounded Large Language Models for Dual Goal Conversational Settings",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Training Large Language Models (LLMs) to follow user instructions has been shown to supply the LLM with ample capacity to converse fluently while being aligned with humans. Yet, it is not completely clear how an LLM can lead a plan-grounded conversation in mixed-initiative settings where instructions flow in both directions of the conversation, i.e. both the LLM and the user provide instructions to one another. In this paper, we tackle a dual goal mixed-initiative conversational setting where the LLM not only grounds the conversation on an arbitrary plan but also seeks to satisfy both a procedural plan and user instructions. The LLM is then responsible for guiding the user through the plan and, at the same time, adapting to new circumstances, answering questions, and activating safety guardrails when needed. We propose a novel LLM that grounds the dialogue on a procedural plan, can take the dialogue initiative, and enforces guardrails on the system's behavior, while also improving the LLM's responses to unexpected user behavior. Experiments in controlled settings and with real users show that the best-performing model, which we call PlanLLM, achieves a 2.1x improvement over a strong baseline. Moreover, experiments also show good generalization to unseen domains.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01064",
        "abstract url": "https://arxiv.org/abs/2402.01064",
        "title": "Semantic-Aware and Goal-Oriented Communications for Object Detection in Wireless End-to-End Image Transmission",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Semantic communication is focused on optimizing the exchange of information by transmitting only the most relevant data required to convey the intended message to the receiver and achieve the desired communication goal. For example, if we consider images as the information and the goal of the communication is object detection at the receiver side, the semantic of information would be the objects in each image. Therefore, by only transferring the semantics of images we can achieve the communication goal. In this paper, we propose a design framework for implementing semantic-aware and goal-oriented communication of images. To achieve this, we first define the baseline problem as a set of mathematical problems that can be optimized to improve the efficiency and effectiveness of the communication system. We consider two scenarios in which either the data rate or the error at the receiver is the limiting constraint. Our proposed system model and solution is inspired by the concept of auto-encoders, where the encoder and the decoder are respectively implemented at the transmitter and receiver to extract semantic information for specific object detection goals. Our numerical results validate the proposed design framework to achieve low error or near-optimal in a goal-oriented communication system while reducing the amount of data transfers.",
        "subjects": [
            "cs.IT",
            "eess.IV"
        ],
        "comment": "International Conference on Computing, Networking and Communications (ICNC 2024)"
    },
    {
        "paper id": "2402.01065",
        "abstract url": "https://arxiv.org/abs/2402.01065",
        "title": "Evaluation Methodology for Large Language Models for Multilingual Document Question and Answer",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the widespread adoption of Large Language Models (LLMs), in this paper we investigate the multilingual capability of these models. Our preliminary results show that, translating the native language context, question and answer into a high resource language produced the best results.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01091",
        "abstract url": "https://arxiv.org/abs/2402.01091",
        "title": "Reading Between the Tweets: Deciphering Ideological Stances of Interconnected Mixed-Ideology Communities",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in NLP have improved our ability to understand the nuanced worldviews of online communities. Existing research focused on probing ideological stances treats liberals and conservatives as separate groups. However, this fails to account for the nuanced views of the organically formed online communities and the connections between them. In this paper, we study discussions of the 2020 U.S. election on Twitter to identify complex interacting communities. Capitalizing on this interconnectedness, we introduce a novel approach that harnesses message passing when finetuning language models (LMs) to probe the nuanced ideologies of these communities. By comparing the responses generated by LMs and real-world survey results, our method shows higher alignment than existing baselines, highlighting the potential of using LMs in revealing complex ideologies within and across interconnected mixed-ideology communities.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01093",
        "abstract url": "https://arxiv.org/abs/2402.01093",
        "title": "Specialized Language Models with Cheap Inference from Limited Domain Data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models have emerged as a versatile tool but are challenging to apply to tasks lacking large inference budgets and large in-domain training sets. This work formalizes these constraints and distinguishes four important variables: the pretraining budget (for training before the target domain is known), the specialization budget (for training after the target domain is known), the inference budget, and the in-domain training set size. Across these settings, we compare different approaches from the machine learning literature. Limited by inference cost, we find better alternatives to the standard practice of training very large vanilla transformer models. In particular, we show that hyper-networks and mixture of experts have better perplexity for large pretraining budgets, while small models trained on importance sampled datasets are attractive for large specialization budgets.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01095",
        "abstract url": "https://arxiv.org/abs/2402.01095",
        "title": "How many views does your deep neural network use for prediction?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The generalization ability of Deep Neural Networks (DNNs) is still not fully understood, despite numerous theoretical and empirical analyses. Recently, Allen-Zhu & Li (2023) introduced the concept of multi-views to explain the generalization ability of DNNs, but their main target is ensemble or distilled models, and no method for estimating multi-views used in a prediction of a specific input is discussed. In this paper, we propose Minimal Sufficient Views (MSVs), which is similar to multi-views but can be efficiently computed for real images. MSVs is a set of minimal and distinct features in an input, each of which preserves a model's prediction for the input. We empirically show that there is a clear relationship between the number of MSVs and prediction accuracy across models, including convolutional and transformer models, suggesting that a multi-view like perspective is also important for understanding the generalization ability of (non-ensemble or non-distilled) DNNs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "stat.ML"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2402.01097",
        "abstract url": "https://arxiv.org/abs/2402.01097",
        "title": "Let's Negotiate! A Survey of Negotiation Dialogue Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Negotiation is a crucial ability in human communication. Recently, there has been a resurgent research interest in negotiation dialogue systems, whose goal is to create intelligent agents that can assist people in resolving conflicts or reaching agreements. Although there have been many explorations into negotiation dialogue systems, a systematic review of this task has not been performed to date. We aim to fill this gap by investigating recent studies in the field of negotiation dialogue systems, and covering benchmarks, evaluations and methodologies within the literature. We also discuss potential future directions, including multi-modal, multi-party and cross-cultural negotiation scenarios. Our goal is to provide the community with a systematic overview of negotiation dialogue systems and to inspire future research.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by EACL 2024 (findings). arXiv admin note: substantial text overlap with arXiv:2212.09072"
    },
    {
        "paper id": "2402.01103",
        "abstract url": "https://arxiv.org/abs/2402.01103",
        "title": "Compositional Generative Modeling: A Single Model is Not All You Need",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Large monolithic generative models trained on massive amounts of data have become an increasingly dominant approach in AI research. In this paper, we argue that we should instead construct large generative systems by composing smaller generative models together. We show how such a compositional generative approach enables us to learn distributions in a more data-efficient manner, enabling generalization to parts of the data distribution unseen at training time. We further show how this enables us to program and construct new generative models for tasks completely unseen at training. Finally, we show that in many cases, we can discover separate compositional components from data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01108",
        "abstract url": "https://arxiv.org/abs/2402.01108",
        "title": "Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Remarkable performance of large language models (LLMs) in a variety of tasks brings forth many opportunities as well as challenges of utilizing them in production settings. Towards practical adoption of LLMs, multi-agent systems hold great promise to augment, integrate, and orchestrate LLMs in the larger context of enterprise platforms that use existing proprietary data and models to tackle complex real-world tasks. Despite the tremendous success of these systems, current approaches rely on narrow, single-focus objectives for optimization and evaluation, often overlooking potential constraints in real-world scenarios, including restricted budgets, resources and time. Furthermore, interpreting, analyzing, and debugging these systems requires different components to be evaluated in relation to one another. This demand is currently not feasible with existing methodologies. In this postion paper, we introduce the concept of reasoning capacity as a unifying criterion to enable integration of constraints during optimization and establish connections among different components within the system, which also enable a more holistic and comprehensive approach to evaluation. We present a formal definition of reasoning capacity and illustrate its utility in identifying limitations within each component of the system. We then argue how these limitations can be addressed with a self-reflective process wherein human-feedback is used to alleviate shortcomings in reasoning and enhance overall consistency of the system.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01117",
        "abstract url": "https://arxiv.org/abs/2402.01117",
        "title": "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Leading models for the text-to-SQL task heavily rely on proprietary Large Language Models (LLMs), posing concerns over data privacy. Closing the performance gap between small open-source models and large proprietary models is crucial to mitigate this reliance. To this end, we introduce a novel two-stage fine-tuning approach that decomposes the task into two simpler tasks. Through comprehensive evaluation on two large cross-domain datasets and two small LLMs, we show that this approach improves execution accuracy by 3 to 7 percent, effectively aligning the performance of open-source models with their proprietary counterparts.",
        "subjects": [
            "cs.CL",
            "cs.DB",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01118",
        "abstract url": "https://arxiv.org/abs/2402.01118",
        "title": "PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce PokeLLMon, the first LLM-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pokemon battles. The design of PokeLLMon incorporates three key strategies: (i) In-context reinforcement learning that instantly consumes text-based feedback derived from battles to iteratively refine the policy; (ii) Knowledge-augmented generation that retrieves external knowledge to counteract hallucination and enables the agent to act timely and properly; (iii) Consistent action generation to mitigate the panic switching phenomenon when the agent faces a powerful opponent and wants to elude the battle. We show that online battles against human demonstrates PokeLLMon's human-like battle strategies and just-in-time decision making, achieving 49% of win rate in the Ladder competitions and 56% of win rate in the invited battles. Our implementation and playable battle logs are available at: https://github.com/git-disl/PokeLLMon.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2402.01123",
        "abstract url": "https://arxiv.org/abs/2402.01123",
        "title": "A Single Simple Patch is All You Need for AI-generated Image Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The recent development of generative models unleashes the potential of generating hyper-realistic fake images. To prevent the malicious usage of fake images, AI-generated image detection aims to distinguish fake images from real images. However, existing method suffer from severe performance drop when detecting images generated by unseen generators. We find that generative models tend to focus on generating the patches with rich textures to make the images more realistic while neglecting the hidden noise caused by camera capture present in simple patches. In this paper, we propose to exploit the noise pattern of a single simple patch to identify fake images. Furthermore, due to the performance decline when handling low-quality generated images, we introduce an enhancement module and a perception module to remove the interfering information. Extensive experiments demonstrate that our method can achieve state-of-the-art performance on public benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01126",
        "abstract url": "https://arxiv.org/abs/2402.01126",
        "title": "Seeing Objects in a Cluttered World: Computational Objectness from Motion in Video",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Perception of the visually disjoint surfaces of our cluttered world as whole objects, physically distinct from those overlapping them, is a cognitive phenomenon called objectness that forms the basis of our visual perception. Shared by all vertebrates and present at birth in humans, it enables object-centric representation and reasoning about the visual world. We present a computational approach to objectness that leverages motion cues and spatio-temporal attention using a pair of supervised spatio-temporal R(2+1)U-Nets. The first network detects motion boundaries and classifies the pixels at those boundaries in terms of their local foreground-background sense. This motion boundary sense (MBS) information is passed, along with a spatio-temporal object attention cue, to an attentional surface perception (ASP) module which infers the form of the attended object over a sequence of frames and classifies its 'pixels' as visible or obscured. The spatial form of the attention cue is flexible, but it must loosely track the attended object which need not be visible. We demonstrate the ability of this simple but novel approach to infer objectness from phenomenology without object models, and show that it delivers robust perception of individual attended objects in cluttered scenes, even with blur and camera shake. We show that our data diversity and augmentation minimizes bias and facilitates transfer to real video. Finally, we describe how this computational objectness capability can grow in sophistication and anchor a robust modular video object perception framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 11 figures, plus 18 pages of Supplemental Information"
    },
    {
        "paper id": "2402.01771",
        "abstract url": "https://arxiv.org/abs/2402.01771",
        "title": "BlackMamba: Mixture of Experts for State-Space Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "State-space models (SSMs) have recently demonstrated competitive performance to transformers at large-scale language modeling benchmarks while achieving linear time and memory complexity as a function of sequence length. Mamba, a recently released SSM model, shows impressive performance in both language modeling and long sequence processing tasks. Simultaneously, mixture-of-expert (MoE) models have shown remarkable performance while significantly reducing the compute and latency costs of inference at the expense of a larger memory footprint. In this paper, we present BlackMamba, a novel architecture that combines the Mamba SSM with MoE to obtain the benefits of both. We demonstrate that BlackMamba performs competitively against both Mamba and transformer baselines, and outperforms in inference and training FLOPs. We fully train and open-source 340M/1.5B and 630M/2.8B BlackMamba models on 300B tokens of a custom dataset. We show that BlackMamba inherits and combines both of the benefits of SSM and MoE architectures, combining linear-complexity generation from SSM with cheap and fast inference from MoE. We release all weights, checkpoints, and inference code open-source. Inference code at: https://github.com/Zyphra/BlackMamba",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01772",
        "abstract url": "https://arxiv.org/abs/2402.01772",
        "title": "Disentangling the Roles of Target-Side Transfer and Regularization in Multilingual Machine Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Multilingual Machine Translation (MMT) benefits from knowledge transfer across different language pairs. However, improvements in one-to-many translation compared to many-to-one translation are only marginal and sometimes even negligible. This performance discrepancy raises the question of to what extent positive transfer plays a role on the target-side for one-to-many MT. In this paper, we conduct a large-scale study that varies the auxiliary target side languages along two dimensions, i.e., linguistic similarity and corpus size, to show the dynamic impact of knowledge transfer on the main language pairs. We show that linguistically similar auxiliary target languages exhibit strong ability to transfer positive knowledge. With an increasing size of similar target languages, the positive transfer is further enhanced to benefit the main language pairs. Meanwhile, we find distant auxiliary target languages can also unexpectedly benefit main language pairs, even with minimal positive transfer ability. Apart from transfer, we show distant auxiliary target languages can act as a regularizer to benefit translation performance by enhancing the generalization and model inference calibration.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01775",
        "abstract url": "https://arxiv.org/abs/2402.01775",
        "title": "Design and consensus content validity of the questionnaire for b-learning education: A 2-Tuple Fuzzy Linguistic Delphi based Decision Support Tool",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Classic Delphi and Fuzzy Delphi methods are used to test content validity of data collection tools such as questionnaires. Fuzzy Delphi takes the opinion issued by judges from a linguistic perspective reducing ambiguity in opinions by using fuzzy numbers. We propose an extension named 2-Tuple Fuzzy Linguistic Delphi method to deal with scenarios in which judges show different expertise degrees by using fuzzy multigranular semantics of the linguistic terms and to obtain intermediate and final results expressed by 2-tuple linguistic values. The key idea of our proposal is to validate the full questionnaire by means of the evaluation of its parts, defining the validity of each item as a Decision Making problem. Taking the opinion of experts, we measure the degree of consensus, the degree of consistency, and the linguistic score of each item, in order to detect those items that affect, positively or negatively, the quality of the instrument. Considering the real need to evaluate a b-learning educational experience with a consensual questionnaire, we present a Decision Making model for questionnaire validation that solves it. Additionally, we contribute to this consensus reaching problem by developing an online tool under GPL v3 license. The software visualizes the collective valuations for each iteration and assists to determine which parts of the questionnaire should be modified to reach a consensual solution.",
        "subjects": [
            "cs.CY",
            "cs.CL",
            "cs.HC"
        ],
        "comment": "47 pages, 7 figures"
    },
    {
        "paper id": "2402.01777",
        "abstract url": "https://arxiv.org/abs/2402.01777",
        "title": "On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We subject GPT-4 to a number of rigorous psychometric tests and analyze the results. We find that, compared to the average human, GPT-4 tends to show more honesty and humility, and less machiavellianism and narcissism. It sometimes exhibits ambivalent sexism, leans slightly toward masculinity, is moderately anxious but mostly not depressive (but not always). It shows human-average numerical literacy and has cognitive reflection abilities that are above human average for verbal tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "16 pages, 8 tables, 1 code repository"
    },
    {
        "paper id": "2402.01778",
        "abstract url": "https://arxiv.org/abs/2402.01778",
        "title": "Introduction to speech recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This document contains lectures and practical experimentations using Matlab and implementing a system which is actually correctly classifying three words (one, two and three) with the help of a very small database. To achieve this performance, it uses speech modeling specificities, powerful computer algorithms (dynamic time warping and Dijktra's algorithm) and machine learning (nearest neighbor). This document introduces also some machine learning evaluation metrics.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "in French language"
    },
    {
        "paper id": "2402.01781",
        "abstract url": "https://arxiv.org/abs/2402.01781",
        "title": "When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value - we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple choice question benchmarks (e.g. MMLU) minor perturbations to the benchmark, such as changing the order of choices or the method of answer selection, result in changes in rankings up to 8 positions. We explain this phenomenon by conducting systematic experiments over three broad categories of benchmark perturbations and identifying the sources of this behavior. Our analysis results in several best-practice recommendations, including the advantage of a hybrid scoring method for answer selection. Our study highlights the dangers of relying on simple benchmark evaluations and charts the path for more robust evaluation schemes on the existing benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01786",
        "abstract url": "https://arxiv.org/abs/2402.01786",
        "title": "COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The development of Courses of Action (COAs) in military operations is traditionally a time-consuming and intricate process. Addressing this challenge, this study introduces COA-GPT, a novel algorithm employing Large Language Models (LLMs) for rapid and efficient generation of valid COAs. COA-GPT incorporates military doctrine and domain expertise to LLMs through in-context learning, allowing commanders to input mission information - in both text and image formats - and receive strategically aligned COAs for review and approval. Uniquely, COA-GPT not only accelerates COA development, producing initial COAs within seconds, but also facilitates real-time refinement based on commander feedback. This work evaluates COA-GPT in a military-relevant scenario within a militarized version of the StarCraft II game, comparing its performance against state-of-the-art reinforcement learning algorithms. Our results demonstrate COA-GPT's superiority in generating strategically sound COAs more swiftly, with added benefits of enhanced adaptability and alignment with commander intentions. COA-GPT's capability to rapidly adapt and update COAs during missions presents a transformative potential for military planning, particularly in addressing planning discrepancies and capitalizing on emergent windows of opportunities.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "Accepted at the NATO Science and Technology Organization Symposium (ICMCIS) organized by the Information Systems Technology (IST) Panel, IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024"
    },
    {
        "paper id": "2402.01788",
        "abstract url": "https://arxiv.org/abs/2402.01788",
        "title": "LitLLM: A Toolkit for Scientific Literature Review",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Conducting literature reviews for scientific papers is essential for understanding research, its limitations, and building on existing work. It is a tedious task which makes an automatic literature review generator appealing. Unfortunately, many existing works that generate such reviews using Large Language Models (LLMs) have significant limitations. They tend to hallucinate-generate non-actual information-and ignore the latest research they have not been trained on. To address these limitations, we propose a toolkit that operates on Retrieval Augmented Generation (RAG) principles, specialized prompting and instructing techniques with the help of LLMs. Our system first initiates a web search to retrieve relevant papers by summarizing user-provided abstracts into keywords using an off-the-shelf LLM. Authors can enhance the search by supplementing it with relevant papers or keywords, contributing to a tailored retrieval process. Second, the system re-ranks the retrieved papers based on the user-provided abstract. Finally, the related work section is generated based on the re-ranked results and the abstract. There is a substantial reduction in time and effort for literature review compared to traditional methods, establishing our toolkit as an efficient alternative. Our open-source toolkit is accessible at https://github.com/shubhamagarwal92/LitLLM and Huggingface space (https://huggingface.co/spaces/shubhamagarwal92/LitLLM) with the video demo at https://youtu.be/E2ggOZBAFw0.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01789",
        "abstract url": "https://arxiv.org/abs/2402.01789",
        "title": "The Political Preferences of LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We report here a comprehensive analysis about the political preferences embedded in Large Language Models (LLMs). Namely, we administer 11 political orientation tests, designed to identify the political preferences of the test taker, to 24 state-of-the-art conversational LLMs, both close and open source. The results indicate that when probed with questions/statements with political connotations most conversational LLMs tend to generate responses that are diagnosed by most political test instruments as manifesting preferences for left-of-center viewpoints. We note that this is not the case for base (i.e. foundation) models upon which LLMs optimized for conversation with humans are built. However, base models' suboptimal performance at coherently answering questions suggests caution when interpreting their classification by political orientation tests. Though not conclusive, our results provide preliminary evidence for the intriguing hypothesis that the embedding of political preferences into LLMs might be happening mostly post-pretraining. Namely, during the supervised fine-tuning (SFT) and/or Reinforcement Learning (RL) stages of the conversational LLMs training pipeline. We provide further support for this hypothesis by showing that LLMs are easily steerable into target locations of the political spectrum via SFT requiring only modest compute and custom data, illustrating the ability of SFT to imprint political preferences onto LLMs. As LLMs have started to displace more traditional information sources such as search engines or Wikipedia, the implications of political biases embedded in LLMs has important societal ramifications.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03471",
        "abstract url": "https://arxiv.org/abs/2402.03471",
        "title": "The Information of Large Language Model Geometry",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates the information encoded in the embeddings of large language models (LLMs). We conduct simulations to analyze the representation entropy and discover a power law relationship with model sizes. Building upon this observation, we propose a theory based on (conditional) entropy to elucidate the scaling law phenomenon. Furthermore, we delve into the auto-regressive structure of LLMs and examine the relationship between the last token and previous context tokens using information theory and regression techniques. Specifically, we establish a theoretical connection between the information gain of new tokens and ridge regression. Additionally, we explore the effectiveness of Lasso regression in selecting meaningful tokens, which sometimes outperforms the closely related attention weights. Finally, we conduct controlled experiments, and find that information is distributed across tokens, rather than being concentrated in specific \"meaningful\" tokens alone.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04866",
        "abstract url": "https://arxiv.org/abs/2402.04866",
        "title": "Room Transfer Function Reconstruction Using Complex-valued Neural Networks and Irregularly Distributed Microphones",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD"
            ]
        ],
        "abstract": "Reconstructing the room transfer functions needed to calculate the complex sound field in a room has several important real-world applications. However, an unpractical number of microphones is often required. Recently, in addition to classical signal processing methods, deep learning techniques have been applied to reconstruct the room transfer function starting from a very limited set of measurements at scattered points in the room. In this paper, we employ complex-valued neural networks to estimate room transfer functions in the frequency range of the first room resonances, using a few irregularly distributed microphones. To the best of our knowledge, this is the first time that complex-valued neural networks are used to estimate room transfer functions. To analyze the benefits of applying complex-valued optimization to the considered task, we compare the proposed technique with a state-of-the-art kernel-based signal processing approach for sound field reconstruction, showing that the proposed technique exhibits relevant advantages in terms of phase accuracy and overall quality of the reconstructed sound field. For informative purposes, we also compare the model with a similarly-structured data-driven approach that, however, applies a real-valued neural network to reconstruct only the magnitude of the sound field.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD",
            "eess.SP"
        ],
        "comment": "Submitted to EUSIPCO 2024"
    },
    {
        "paper id": "2402.00350",
        "abstract url": "https://arxiv.org/abs/2402.00350",
        "title": "Large Language Models Based Fuzzing Techniques: A Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the modern era where software plays a pivotal role, software security and vulnerability analysis have become essential for software development. Fuzzing test, as an efficient software testing method, are widely used in various domains. Moreover, the rapid development of Large Language Models (LLMs) has facilitated their application in the field of software testing, demonstrating remarkable performance. Considering that existing fuzzing test techniques are not entirely automated and software vulnerabilities continue to evolve, there is a growing trend towards employing fuzzing test generated based on large language models. This survey provides a systematic overview of the approaches that fuse LLMs and fuzzing tests for software testing. In this paper, a statistical analysis and discussion of the literature in three areas, namely LLMs, fuzzing test, and fuzzing test generated based on LLMs, are conducted by summarising the state-of-the-art methods up until 2024. Our survey also investigates the potential for widespread deployment and application of fuzzing test techniques generated by LLMs in the future.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "9 pages submission under review"
    },
    {
        "paper id": "2402.00351",
        "abstract url": "https://arxiv.org/abs/2402.00351",
        "title": "Machine Unlearning for Image-to-Image Generative Models",
        "rating": "0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Machine unlearning has emerged as a new paradigm to deliberately forget data samples from a given model in order to adhere to stringent regulations. However, existing machine unlearning methods have been primarily focused on classification models, leaving the landscape of unlearning for generative models relatively unexplored. This paper serves as a bridge, addressing the gap by providing a unifying framework of machine unlearning for image-to-image generative models. Within this framework, we propose a computationally-efficient algorithm, underpinned by rigorous theoretical analysis, that demonstrates negligible performance degradation on the retain samples, while effectively removing the information from the forget samples. Empirical studies on two large-scale datasets, ImageNet-1K and Places-365, further show that our algorithm does not rely on the availability of the retain samples, which further complies with data retention policy. To our best knowledge, this work is the first that represents systemic, theoretical, empirical explorations of machine unlearning specifically tailored for image-to-image generative models. Our code is available at https://github.com/jpmorganchase/l2l-generator-unlearning.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2402.00355",
        "abstract url": "https://arxiv.org/abs/2402.00355",
        "title": "Adaptive Primal-Dual Method for Safe Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Primal-dual methods have a natural application in Safe Reinforcement Learning (SRL), posed as a constrained policy optimization problem. In practice however, applying primal-dual methods to SRL is challenging, due to the inter-dependency of the learning rate (LR) and Lagrangian multipliers (dual variables) each time an embedded unconstrained RL problem is solved. In this paper, we propose, analyze and evaluate adaptive primal-dual (APD) methods for SRL, where two adaptive LRs are adjusted to the Lagrangian multipliers so as to optimize the policy in each iteration. We theoretically establish the convergence, optimality and feasibility of the APD algorithm. Finally, we conduct numerical evaluation of the practical APD algorithm with four well-known environments in Bullet-Safey-Gym employing two state-of-the-art SRL algorithms: PPO-Lagrangian and DDPG-Lagrangian. All experiments show that the practical APD algorithm outperforms (or achieves comparable performance) and attains more stable training than the constant LR cases. Additionally, we substantiate the robustness of selecting the two adaptive LRs by empirical evidence.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00389",
        "abstract url": "https://arxiv.org/abs/2402.00389",
        "title": "On the $O(\\frac{\\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\\ell_1$ Norm",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Although adaptive gradient methods have been extensively used in deep learning, their convergence rates proved in the literature are all slower than that of SGD, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla f(x^k)\\|_1\\right]\\leq O(\\frac{\\sqrt{d}C}{T^{1/4}})$ measured by $\\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable, $T$ is the iteration number, and $C$ is a constant identical to that appeared in the optimal convergence rate of SGD. Our convergence rate matches the lower bound with respect to all the coefficients except the dimension $d$. Since $\\|x\\|_2\\ll\\|x\\|_1\\leq\\sqrt{d}\\|x\\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla f(x^k)\\|_2\\right]\\leq O(\\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\\|\\nabla f(x)\\|_1=\\varTheta(\\sqrt{d}\\|\\nabla f(x)\\|_2)$.",
        "subjects": [
            "math.OC",
            "cs.AI"
        ],
        "comment": "V3 vs V2: A fairer comparison with (Li et al., 2023). V2 vs V1: (1) Correct one error in v1. (2) Improve the convergence rate matching the lower bound with respect to all the coefficients except the dimension"
    },
    {
        "paper id": "2402.00393",
        "abstract url": "https://arxiv.org/abs/2402.00393",
        "title": "Loss Function Considering Dead Zone for Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "It is important to reveal the inverse dynamics of manipulators to improve control performance of model-based control. Neural networks (NNs) are promising techniques to represent complicated inverse dynamics while they require a large amount of motion data. However, motion data in dead zones of actuators is not suitable for training models decreasing the number of useful training data. In this study, based on the fact that the manipulator joint does not work irrespective of input torque in dead zones, we propose a new loss function that considers only errors of joints not in dead zones. The proposed method enables to increase in the amount of motion data available for training and the accuracy of the inverse dynamics computation. Experiments on actual equipment using a three-degree-of-freedom (DOF) manipulator showed higher accuracy than conventional methods. We also confirmed and discussed the behavior of the model of the proposed method in dead zones.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "6 pages, 6 figures, Accepted at AMC2024"
    },
    {
        "paper id": "2402.00412",
        "abstract url": "https://arxiv.org/abs/2402.00412",
        "title": "Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection",
        "rating": "0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in text generation tasks. However, the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises. Although several detectors have been proposed to address these concerns, their effectiveness against adversarial perturbations, specifically in the context of student essay writing, remains largely unexplored. This paper aims to bridge this gap by constructing AIG-ASAP, an AI-generated student essay dataset, employing a range of text perturbation methods that are expected to generate high-quality essays while evading detection. Through empirical experiments, we assess the performance of current AIGC detectors on the AIG-ASAP dataset. The results reveal that the existing detectors can be easily circumvented using straightforward automatic adversarial attacks. Specifically, we explore word substitution and sentence substitution perturbation methods that effectively evade detection while maintaining the quality of the generated essays. This highlights the urgent need for more accurate and robust methods to detect AI-generated student essays in the education domain.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted by EMNLP 2023 Main conference, Oral Presentation"
    },
    {
        "paper id": "2402.00442",
        "abstract url": "https://arxiv.org/abs/2402.00442",
        "title": "Responsible developments and networking research: a reflection beyond a paper ethical statement",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Several recent initiatives have proposed new directions for research practices and their operations in the computer science community, from updated codes of conduct that clarify the use of AI-assisted tools to the inclusion of ethical statements and the organization of working groups on the environmental footprint of digitalization. In this position paper, we focus on the specific case of networking research. We reflect on the technical realization of the community and its incidence beyond techno-centric contributions. In particular, we structure the discussion around two frameworks that were recently developed in different contexts to describe the sense of engagement and responsibilities to which the practitioner of a computing-related area may be confronted.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00459",
        "abstract url": "https://arxiv.org/abs/2402.00459",
        "title": "Genetic-based Constraint Programming for Resource Constrained Job Scheduling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Resource constrained job scheduling is a hard combinatorial optimisation problem that originates in the mining industry. Off-the-shelf solvers cannot solve this problem satisfactorily in reasonable timeframes, while other solution methods such as many evolutionary computation methods and matheuristics cannot guarantee optimality and require low-level customisation and specialised heuristics to be effective. This paper addresses this gap by proposing a genetic programming algorithm to discover efficient search strategies of constraint programming for resource-constrained job scheduling. In the proposed algorithm, evolved programs represent variable selectors to be used in the search process of constraint programming, and their fitness is determined by the quality of solutions obtained for training instances. The novelties of this algorithm are (1) a new representation of variable selectors, (2) a new fitness evaluation scheme, and (3) a pre-selection mechanism. Tests with a large set of random and benchmark instances, the evolved variable selectors can significantly improve the efficiency of constraining programming. Compared to highly customised metaheuristics and hybrid algorithms, evolved variable selectors can help constraint programming identify quality solutions faster and proving optimality is possible if sufficiently large run-times are allowed. The evolved variable selectors are especially helpful when solving instances with large numbers of machines.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00501",
        "abstract url": "https://arxiv.org/abs/2402.00501",
        "title": "Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The solution to empirical risk minimization with $f$-divergence regularization (ERM-$f$DR) is presented under mild conditions on $f$. Under such conditions, the optimal measure is shown to be unique. Examples of the solution for particular choices of the function $f$ are presented. Previously known solutions to common regularization choices are obtained by leveraging the flexibility of the family of $f$-divergences. These include the unique solutions to empirical risk minimization with relative entropy regularization (Type-I and Type-II). The analysis of the solution unveils the following properties of $f$-divergences when used in the ERM-$f$DR problem: $i\\bigl)$ $f$-divergence regularization forces the support of the solution to coincide with the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; and $ii\\bigl)$ any $f$-divergence regularization is equivalent to a different $f$-divergence regularization with an appropriate transformation of the empirical risk function.",
        "subjects": [
            "stat.ML",
            "cs.IT",
            "cs.LG"
        ],
        "comment": "Submitted to the IEEE Symposium in Information Theory 2024. arXiv admin note: text overlap with arXiv:2306.07123"
    },
    {
        "paper id": "2402.00522",
        "abstract url": "https://arxiv.org/abs/2402.00522",
        "title": "Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "65 pages"
    },
    {
        "paper id": "2402.00591",
        "abstract url": "https://arxiv.org/abs/2402.00591",
        "title": "Sandra -- A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00595",
        "abstract url": "https://arxiv.org/abs/2402.00595",
        "title": "Causal evidence for social group sizes from Wikipedia editing data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Human communities have self-organizing properties in which specific Dunbar Numbers may be invoked to explain group attachments. By analyzing Wikipedia editing histories across a wide range of subject pages, we show that there is an emergent coherence in the size of transient groups formed to edit the content of subject texts, with two peaks averaging at around $N=8$ for the size corresponding to maximal contention, and at around $N=4$ as a regular team. These values are consistent with the observed sizes of conversational groups, as well as the hierarchical structuring of Dunbar graphs. We use the Promise Theory model of bipartite trust to derive a scaling law that fits the data and may apply to all group size distributions, when based on attraction to a seeded group process. In addition to providing further evidence that even spontaneous communities of strangers are self-organizing, the results have important implications for the governance of the Wikipedia commons and for the security of all online social platforms and associations.",
        "subjects": [
            "cs.SI",
            "cs.MA",
            "nlin.AO",
            "physics.soc-ph"
        ],
        "comment": "Expanded method section and changed the title to be more specific and informative"
    },
    {
        "paper id": "2402.00598",
        "abstract url": "https://arxiv.org/abs/2402.00598",
        "title": "A Promise Theory Perspective on the Role of Intent in Group Dynamics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "We present a simple argument using Promise Theory and dimensional analysis for the Dunbar scaling hierarchy, supported by recent data from group formation in Wikipedia editing. We show how the assumption of a common priority seeds group alignment until the costs associated with attending to the group outweigh the benefits in a detailed balance scenario. Subject to partial efficiency of implementing promised intentions, we can reproduce a series of compatible rates that balance growth with entropy.",
        "subjects": [
            "cs.SI",
            "cs.MA",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00654",
        "abstract url": "https://arxiv.org/abs/2402.00654",
        "title": "Improving the accuracy of freight mode choice models: A case study using the 2017 CFS PUF data set and ensemble learning techniques",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The US Census Bureau has collected two rounds of experimental data from the Commodity Flow Survey, providing shipment-level characteristics of nationwide commodity movements, published in 2012 (i.e., Public Use Microdata) and in 2017 (i.e., Public Use File). With this information, data-driven methods have become increasingly valuable for understanding detailed patterns in freight logistics. In this study, we used the 2017 Commodity Flow Survey Public Use File data set to explore building a high-performance freight mode choice model, considering three main improvements: (1) constructing local models for each separate commodity/industry category; (2) extracting useful geographical features, particularly the derived distance of each freight mode between origin/destination zones; and (3) applying additional ensemble learning methods such as stacking or voting to combine results from local and unified models for improved performance. The proposed method achieved over 92% accuracy without incorporating external information, an over 19% increase compared to directly fitting Random Forests models over 10,000 samples. Furthermore, SHAP (Shapely Additive Explanations) values were computed to explain the outputs and major patterns obtained from the proposed model. The model framework could enhance the performance and interpretability of existing freight mode choice models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00689",
        "abstract url": "https://arxiv.org/abs/2402.00689",
        "title": "Ocassionally Secure: A Comparative Analysis of Code Generation Assistants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "$ $Large Language Models (LLMs) are being increasingly utilized in various applications, with code generations being a notable example. While previous research has shown that LLMs have the capability to generate both secure and insecure code, the literature does not take into account what factors help generate secure and effective code. Therefore in this paper we focus on identifying and understanding the conditions and contexts in which LLMs can be effectively and safely deployed in real-world scenarios to generate quality code. We conducted a comparative analysis of four advanced LLMs--GPT-3.5 and GPT-4 using ChatGPT and Bard and Gemini from Google--using 9 separate tasks to assess each model's code generation capabilities. We contextualized our study to represent the typical use cases of a real-life developer employing LLMs for everyday tasks as work. Additionally, we place an emphasis on security awareness which is represented through the use of two distinct versions of our developer persona. In total, we collected 61 code outputs and analyzed them across several aspects: functionality, security, performance, complexity, and reliability. These insights are crucial for understanding the models' capabilities and limitations, guiding future development and practical applications in the field of automated code generation.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "12 pages, 2 figures"
    },
    {
        "paper id": "2402.00699",
        "abstract url": "https://arxiv.org/abs/2402.00699",
        "title": "PeaTMOSS: A Dataset and Initial Analysis of Pre-Trained Models in Open-Source Software",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The development and training of deep learning models have become increasingly costly and complex. Consequently, software engineers are adopting pre-trained models (PTMs) for their downstream applications. The dynamics of the PTM supply chain remain largely unexplored, signaling a clear need for structured datasets that document not only the metadata but also the subsequent applications of these models. Without such data, the MSR community cannot comprehensively understand the impact of PTM adoption and reuse. This paper presents the PeaTMOSS dataset, which comprises metadata for 281,638 PTMs and detailed snapshots for all PTMs with over 50 monthly downloads (14,296 PTMs), along with 28,575 open-source software repositories from GitHub that utilize these models. Additionally, the dataset includes 44,337 mappings from 15,129 downstream GitHub repositories to the 2,530 PTMs they use. To enhance the dataset's comprehensiveness, we developed prompts for a large language model to automatically extract model metadata, including the model's training datasets, parameters, and evaluation metrics. Our analysis of this dataset provides the first summary statistics for the PTM supply chain, showing the trend of PTM development and common shortcomings of PTM package documentation. Our example application reveals inconsistencies in software licenses across PTMs and their dependent projects. PeaTMOSS lays the foundation for future research, offering rich opportunities to investigate the PTM supply chain. We outline mining opportunities on PTMs, their downstream usage, and cross-cutting questions.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.DB",
            "cs.LG"
        ],
        "comment": "Accepted at MSR'24"
    },
    {
        "paper id": "2402.00705",
        "abstract url": "https://arxiv.org/abs/2402.00705",
        "title": "Combining the Strengths of Dutch Survey and Register Data in a Data Challenge to Predict Fertility (PreFer)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The social sciences have produced an impressive body of research on determinants of fertility outcomes, or whether and when people have children. However, the strength of these determinants and underlying theories are rarely evaluated on their predictive ability on new data. This prevents us from systematically comparing studies, hindering the evaluation and accumulation of knowledge. In this paper, we present two datasets which can be used to study the predictability of fertility outcomes in the Netherlands. One dataset is based on the LISS panel, a longitudinal survey which includes thousands of variables on a wide range of topics, including individual preferences and values. The other is based on the Dutch register data which lacks attitudinal data but includes detailed information about the life courses of millions of Dutch residents. We provide information about the datasets and the samples, and describe the fertility outcome of interest. We also introduce the fertility prediction data challenge PreFer which is based on these datasets and will start in Spring 2024. We outline the ways in which measuring the predictability of fertility outcomes using these datasets and combining their strengths in the data challenge can advance our understanding of fertility behaviour and computational social science. We further provide details for participants on how to take part in the data challenge.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00715",
        "abstract url": "https://arxiv.org/abs/2402.00715",
        "title": "Intent Assurance using LLMs guided by Intent Drift",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Intent-Based Networking (IBN) presents a paradigm shift for network management, by promising to align intents and business objectives with network operations--in an automated manner. However, its practical realization is challenging: 1) processing intents, i.e., translate, decompose and identify the logic to fulfill the intent, and 2) intent conformance, that is, considering dynamic networks, the logic should be adequately adapted to assure intents. To address the latter, intent assurance is tasked with continuous verification and validation, including taking the necessary actions to align the operational and target states. In this paper, we define an assurance framework that allows us to detect and act when intent drift occurs. To do so, we leverage AI-driven policies, generated by Large Language Models (LLMs) which can quickly learn the necessary in-context requirements, and assist with the fulfillment and assurance of intents.",
        "subjects": [
            "cs.AI",
            "cs.NI",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00738",
        "abstract url": "https://arxiv.org/abs/2402.00738",
        "title": "FM3Q: Factorized Multi-Agent MiniMax Q-Learning for Two-Team Zero-Sum Markov Game",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Many real-world applications involve some agents that fall into two teams, with payoffs that are equal within the same team but of opposite sign across the opponent team. The so-called two-team zero-sum Markov games (2t0sMGs) can be resolved with reinforcement learning in recent years. However, existing methods are thus inefficient in light of insufficient consideration of intra-team credit assignment, data utilization and computational intractability. In this paper, we propose the individual-global-minimax (IGMM) principle to ensure the coherence between two-team minimax behaviors and the individual greedy behaviors through Q functions in 2t0sMGs. Based on it, we present a novel multi-agent reinforcement learning framework, Factorized Multi-Agent MiniMax Q-Learning (FM3Q), which can factorize the joint minimax Q function into individual ones and iteratively solve for the IGMM-satisfied minimax Q functions for 2t0sMGs. Moreover, an online learning algorithm with neural networks is proposed to implement FM3Q and obtain the deterministic and decentralized minimax policies for two-team players. A theoretical analysis is provided to prove the convergence of FM3Q. Empirically, we use three environments to evaluate the learning efficiency and final performance of FM3Q and show its superiority on 2t0sMGs.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00759",
        "abstract url": "https://arxiv.org/abs/2402.00759",
        "title": "Building Expressive and Tractable Probabilistic Generative Models: A Review",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present a comprehensive survey of the advancements and techniques in the field of tractable probabilistic generative modeling, primarily focusing on Probabilistic Circuits (PCs). We provide a unified perspective on the inherent trade-offs between expressivity and the tractability, highlighting the design principles and algorithmic extensions that have enabled building expressive and efficient PCs, and provide a taxonomy of the field. We also discuss recent efforts to build deep and hybrid PCs by fusing notions from deep neural models, and outline the challenges and open questions that can guide future research in this evolving field.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00761",
        "abstract url": "https://arxiv.org/abs/2402.00761",
        "title": "Control-Theoretic Techniques for Online Adaptation of Deep Neural Networks in Dynamical Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural networks (DNNs), trained with gradient-based optimization and backpropagation, are currently the primary tool in modern artificial intelligence, machine learning, and data science. In many applications, DNNs are trained offline, through supervised learning or reinforcement learning, and deployed online for inference. However, training DNNs with standard backpropagation and gradient-based optimization gives no intrinsic performance guarantees or bounds on the DNN, which is essential for applications such as controls. Additionally, many offline-training and online-inference problems, such as sim2real transfer of reinforcement learning policies, experience domain shift from the training distribution to the real-world distribution. To address these stability and transfer learning issues, we propose using techniques from control theory to update DNN parameters online. We formulate the fully-connected feedforward DNN as a continuous-time dynamical system, and we propose novel last-layer update laws that guarantee desirable error convergence under various conditions on the time derivative of the DNN input vector. We further show that training the DNN under spectral normalization controls the upper bound of the error trajectories of the online DNN predictions, which is desirable when numerically differentiated quantities or noisy state measurements are input to the DNN. The proposed online DNN adaptation laws are validated in simulation to learn the dynamics of the Van der Pol system under domain shift, where parameters are varied in inference from the training dataset. The simulations demonstrate the effectiveness of using control-theoretic techniques to derive performance improvements and guarantees in DNN-based learning systems.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Preprint version"
    },
    {
        "paper id": "2402.00774",
        "abstract url": "https://arxiv.org/abs/2402.00774",
        "title": "Mesh motion in fluid-structure interaction with deep operator networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A mesh motion model based on deep operator networks is presented. The model is trained on and evaluated against a biharmonic mesh motion model on a fluid-structure interaction benchmark problem and further evaluated in a setting where biharmonic mesh motion fails. The performance of the proposed mesh motion model is comparable to the biharmonic mesh motion on the test problems.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": "9 pages, 5 figures, submitted to proceedings of ENUMATH 2023"
    },
    {
        "paper id": "2402.00782",
        "abstract url": "https://arxiv.org/abs/2402.00782",
        "title": "Dense Reward for Free in Reinforcement Learning from Human Feedback",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been credited as the key advance that has allowed Large Language Models (LLMs) to effectively follow instructions and produce useful assistance. Classically, this involves generating completions from the LLM in response to a query before using a separate reward model to assign a score to the full completion. As an auto-regressive process, the LLM has to take many \"actions\" (selecting individual tokens) and only receives a single, sparse reward at the end of an episode, a setup that is known to be difficult to optimise in traditional reinforcement learning. In this work we leverage the fact that the reward model contains more information than just its scalar output, in particular, it calculates an attention map over tokens as part of the transformer architecture. We use these attention weights to redistribute the reward along the whole completion, effectively densifying the signal and highlighting the most important tokens, all without incurring extra computational cost or requiring any additional modelling. We demonstrate that, theoretically, this approach is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged. Empirically, we show that it stabilises training, accelerates the rate of learning, and, in practical cases, may lead to better local optima.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00787",
        "abstract url": "https://arxiv.org/abs/2402.00787",
        "title": "Learning and Calibrating Heterogeneous Bounded Rational Market Behaviour with Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Agent-based models (ABMs) have shown promise for modelling various real world phenomena incompatible with traditional equilibrium analysis. However, a critical concern is the manual definition of behavioural rules in ABMs. Recent developments in multi-agent reinforcement learning (MARL) offer a way to address this issue from an optimisation perspective, where agents strive to maximise their utility, eliminating the need for manual rule specification. This learning-focused approach aligns with established economic and financial models through the use of rational utility-maximising agents. However, this representation departs from the fundamental motivation for ABMs: that realistic dynamics emerging from bounded rationality and agent heterogeneity can be modelled. To resolve this apparent disparity between the two approaches, we propose a novel technique for representing heterogeneous processing-constrained agents within a MARL framework. The proposed approach treats agents as constrained optimisers with varying degrees of strategic skills, permitting departure from strict utility maximisation. Behaviour is learnt through repeated simulations with policy gradients to adjust action likelihoods. To allow efficient computation, we use parameterised shared policy learning with distributions of agent skill levels. Shared policy learning avoids the need for agents to learn individual policies yet still enables a spectrum of bounded rational behaviours. We validate our model's effectiveness using real-world data on a range of canonical $n$-agent settings, demonstrating significantly improved predictive capability.",
        "subjects": [
            "cs.MA",
            "cs.CE",
            "cs.GT",
            "cs.LG",
            "econ.GN"
        ],
        "comment": "Accepted as a full paper at AAMAS 2024"
    },
    {
        "paper id": "2402.00789",
        "abstract url": "https://arxiv.org/abs/2402.00789",
        "title": "Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Attention mechanisms have been widely used to capture long-range dependencies among nodes in Graph Transformers. Bottlenecked by the quadratic computational cost, attention mechanisms fail to scale in large graphs. Recent improvements in computational efficiency are mainly achieved by attention sparsification with random or heuristic-based graph subsampling, which falls short in data-dependent context reasoning. State space models (SSMs), such as Mamba, have gained prominence for their effectiveness and efficiency in modeling long-range dependencies in sequential data. However, adapting SSMs to non-sequential graph data presents a notable challenge. In this work, we introduce Graph-Mamba, the first attempt to enhance long-range context modeling in graph networks by integrating a Mamba block with the input-dependent node selection mechanism. Specifically, we formulate graph-centric node prioritization and permutation strategies to enhance context-aware reasoning, leading to a substantial improvement in predictive performance. Extensive experiments on ten benchmark datasets demonstrate that Graph-Mamba outperforms state-of-the-art methods in long-range graph prediction tasks, with a fraction of the computational cost in both FLOPs and GPU memory consumption. The code and models are publicly available at https://github.com/bowang-lab/Graph-Mamba.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00809",
        "abstract url": "https://arxiv.org/abs/2402.00809",
        "title": "Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00816",
        "abstract url": "https://arxiv.org/abs/2402.00816",
        "title": "Leveraging Approximate Model-based Shielding for Probabilistic Safety Guarantees in Continuous Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Shielding is a popular technique for achieving safe reinforcement learning (RL). However, classical shielding approaches come with quite restrictive assumptions making them difficult to deploy in complex environments, particularly those with continuous state or action spaces. In this paper we extend the more versatile approximate model-based shielding (AMBS) framework to the continuous setting. In particular we use Safety Gym as our test-bed, allowing for a more direct comparison of AMBS with popular constrained RL algorithms. We also provide strong probabilistic safety guarantees for the continuous setting. In addition, we propose two novel penalty techniques that directly modify the policy gradient, which empirically provide more stable convergence in our experiments.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted as an Extended Abstract at AAMAS 2024"
    },
    {
        "paper id": "2402.00822",
        "abstract url": "https://arxiv.org/abs/2402.00822",
        "title": "WiOpen: A Robust Wi-Fi-based Open-set Gesture Recognition Framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent years have witnessed a growing interest in Wi-Fi-based gesture recognition. However, existing works have predominantly focused on closed-set paradigms, where all testing gestures are predefined during training. This poses a significant challenge in real-world applications, as unseen gestures might be misclassified as known classes during testing. To address this issue, we propose WiOpen, a robust Wi-Fi-based Open-Set Gesture Recognition (OSGR) framework. Implementing OSGR requires addressing challenges caused by the unique uncertainty in Wi-Fi sensing. This uncertainty, resulting from noise and domains, leads to widely scattered and irregular data distributions in collected Wi-Fi sensing data. Consequently, data ambiguity between classes and challenges in defining appropriate decision boundaries to identify unknowns arise. To tackle these challenges, WiOpen adopts a two-fold approach to eliminate uncertainty and define precise decision boundaries. Initially, it addresses uncertainty induced by noise during data preprocessing by utilizing the CSI ratio. Next, it designs the OSGR network based on an uncertainty quantification method. Throughout the learning process, this network effectively mitigates uncertainty stemming from domains. Ultimately, the network leverages relationships among samples' neighbors to dynamically define open-set decision boundaries, successfully realizing OSGR. Comprehensive experiments on publicly accessible datasets confirm WiOpen's effectiveness. Notably, WiOpen also demonstrates superiority in cross-domain tasks when compared to state-of-the-art approaches.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00823",
        "abstract url": "https://arxiv.org/abs/2402.00823",
        "title": "SLIM: Skill Learning with Multiple Critics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Self-supervised skill learning aims to acquire useful behaviors that leverage the underlying dynamics of the environment. Latent variable models, based on mutual information maximization, have been successful in this task but still struggle in the context of robotic manipulation. As it requires impacting a possibly large set of degrees of freedom composing the environment, mutual information maximization fails alone in producing useful and safe manipulation behaviors. Furthermore, tackling this by augmenting skill discovery rewards with additional rewards through a naive combination might fail to produce desired behaviors. To address this limitation, we introduce SLIM, a multi-critic learning approach for skill discovery with a particular focus on robotic manipulation. Our main insight is that utilizing multiple critics in an actor-critic framework to gracefully combine multiple reward functions leads to a significant improvement in latent-variable skill discovery for robotic manipulation while overcoming possible interference occurring among rewards which hinders convergence to useful skills. Furthermore, in the context of tabletop manipulation, we demonstrate the applicability of our novel skill discovery approach to acquire safe and efficient motor primitives in a hierarchical reinforcement learning fashion and leverage them through planning, significantly surpassing baseline approaches for skill discovery.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Accepted at IEEE ICRA 2024"
    },
    {
        "paper id": "2402.00825",
        "abstract url": "https://arxiv.org/abs/2402.00825",
        "title": "Resolution invariant deep operator network for PDEs with complex geometries",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural operators (NO) are discretization invariant deep learning methods with functional output and can approximate any continuous operator. NO have demonstrated the superiority of solving partial differential equations (PDEs) over other deep learning methods. However, the spatial domain of its input function needs to be identical to its output, which limits its applicability. For instance, the widely used Fourier neural operator (FNO) fails to approximate the operator that maps the boundary condition to the PDE solution. To address this issue, we propose a novel framework called resolution-invariant deep operator (RDO) that decouples the spatial domain of the input and output. RDO is motivated by the Deep operator network (DeepONet) and it does not require retraining the network when the input/output is changed compared with DeepONet. RDO takes functional input and its output is also functional so that it keeps the resolution invariant property of NO. It can also resolve PDEs with complex geometries whereas NO fail. Various numerical experiments demonstrate the advantage of our method over DeepONet and FNO.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00830",
        "abstract url": "https://arxiv.org/abs/2402.00830",
        "title": "Common errors in Generative AI systems used for knowledge extraction in the climate action domain",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Large Language Models (LLMs) and, more specifically, the Generative Pre-Trained Transformers (GPT) can help stakeholders in climate action explore digital knowledge bases and extract and utilize climate action knowledge in a sustainable manner. However, LLMs are \"probabilistic models of knowledge bases\" that excel at generating convincing texts but cannot be entirely relied upon due to the probabilistic nature of the information produced. This brief report illustrates the problem space with examples of LLM responses to some of the questions of relevance to climate action.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00831",
        "abstract url": "https://arxiv.org/abs/2402.00831",
        "title": "A YANG-aided Unified Strategy for Black Hole Detection for Backbone Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Despite the crucial importance of addressing Black Hole failures in Internet backbone networks, effective detection strategies in backbone networks are lacking. This is largely because previous research has been centered on Mobile Ad-hoc Networks (MANETs), which operate under entirely different dynamics, protocols, and topologies, making their findings not directly transferable to backbone networks. Furthermore, detecting Black Hole failures in backbone networks is particularly challenging. It requires a comprehensive range of network data due to the wide variety of conditions that need to be considered, making data collection and analysis far from straightforward. Addressing this gap, our study introduces a novel approach for Black Hole detection in backbone networks using specialized Yet Another Next Generation (YANG) data models with Black Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our method of selecting and analyzing four YANG models relevant to Black Hole detection in ISP networks, focusing on routing protocols and ISP-specific configurations. Our BHMM approach derived from these models demonstrates a 10% improvement in detection accuracy and a 13% increase in packet delivery rate, highlighting the efficiency of our approach. Additionally, we evaluate the Machine Learning approach leveraged with BHMM analysis in two different network settings, a commercial ISP network, and a scientific research-only network topology. This evaluation also demonstrates the practical applicability of our method, yielding significantly improved prediction outcomes in both environments.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00857",
        "abstract url": "https://arxiv.org/abs/2402.00857",
        "title": "Early Time Classification with Accumulated Accuracy Gap Control",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Early time classification algorithms aim to label a stream of features without processing the full input stream, while maintaining accuracy comparable to that achieved by applying the classifier to the entire input. In this paper, we introduce a statistical framework that can be applied to any sequential classifier, formulating a calibrated stopping rule. This data-driven rule attains finite-sample, distribution-free control of the accuracy gap between full and early-time classification. We start by presenting a novel method that builds on the Learn-then-Test calibration framework to control this gap marginally, on average over i.i.d. instances. As this algorithm tends to yield an excessively high accuracy gap for early halt times, our main contribution is the proposal of a framework that controls a stronger notion of error, where the accuracy gap is controlled conditionally on the accumulated halt times. Numerical experiments demonstrate the effectiveness, applicability, and usefulness of our method. We show that our proposed early stopping mechanism reduces up to 94% of timesteps used for classification while achieving rigorous accuracy gap control.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00863",
        "abstract url": "https://arxiv.org/abs/2402.00863",
        "title": "Geometry Transfer for Stylizing Radiance Fields",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "depth",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Shape and geometric patterns are essential in defining stylistic identity. However, current 3D style transfer methods predominantly focus on transferring colors and textures, often overlooking geometric aspects. In this paper, we introduce Geometry Transfer, a novel method that leverages geometric deformation for 3D style transfer. This technique employs depth maps to extract a style guide, subsequently applied to stylize the geometry of radiance fields. Moreover, we propose new techniques that utilize geometric cues from the 3D scene, thereby enhancing aesthetic expressiveness and more accurately reflecting intended styles. Our extensive experiments show that Geometry Transfer enables a broader and more expressive range of stylizations, thereby significantly expanding the scope of 3D style transfer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024. Project page: https://hyblue.github.io/geo-srf/"
    },
    {
        "paper id": "2402.00910",
        "abstract url": "https://arxiv.org/abs/2402.00910",
        "title": "Addressing Bias Through Ensemble Learning and Regularized Fine-Tuning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Addressing biases in AI models is crucial for ensuring fair and accurate predictions. However, obtaining large, unbiased datasets for training can be challenging. This paper proposes a comprehensive approach using multiple methods to remove bias in AI models, with only a small dataset and a potentially biased pretrained model. We train multiple models with the counter-bias of the pre-trained model through data splitting, local training, and regularized fine-tuning, gaining potentially counter-biased models. Then, we employ ensemble learning for all models to reach unbiased predictions. To further accelerate the inference time of our ensemble model, we conclude our solution with knowledge distillation that results in a single unbiased neural network. We demonstrate the effectiveness of our approach through experiments on the CIFAR10 and HAM10000 datasets, showcasing promising results. This work contributes to the ongoing effort to create more unbiased and reliable AI models, even with limited data availability.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00943",
        "abstract url": "https://arxiv.org/abs/2402.00943",
        "title": "Approximate Nearest Neighbor Search with Window Filters",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We define and investigate the problem of $\\textit{c-approximate window search}$: approximate nearest neighbor search where each point in the dataset has a numeric label, and the goal is to find nearest neighbors to queries within arbitrary label ranges. Many semantic search problems, such as image and document search with timestamp filters, or product search with cost filters, are natural examples of this problem. We propose and theoretically analyze a modular tree-based framework for transforming an index that solves the traditional c-approximate nearest neighbor problem into a data structure that solves window search. On standard nearest neighbor benchmark datasets equipped with random label values, adversarially constructed embeddings, and image search embeddings with real timestamps, we obtain up to a $75\\times$ speedup over existing solutions at the same level of recall.",
        "subjects": [
            "cs.DS",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Code available: https://github.com/JoshEngels/RangeFilteredANN"
    },
    {
        "paper id": "2402.00949",
        "abstract url": "https://arxiv.org/abs/2402.00949",
        "title": "Geometry of Polynomial Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the expressivity and learning process for polynomial neural networks (PNNs) with monomial activation functions. The weights of the network parametrize the neuromanifold. In this paper, we study certain neuromanifolds using tools from algebraic geometry: we give explicit descriptions as semialgebraic sets and characterize their Zariski closures, called neurovarieties. We study their dimension and associate an algebraic degree, the learning degree, to the neurovariety. The dimension serves as a geometric measure for the expressivity of the network, the learning degree is a measure for the complexity of training the network and provides upper bounds on the number of learnable functions. These theoretical results are accompanied with experiments.",
        "subjects": [
            "math.AG",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00957",
        "abstract url": "https://arxiv.org/abs/2402.00957",
        "title": "Credal Learning Theory",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "19 pages, 2 figures"
    },
    {
        "paper id": "2402.00972",
        "abstract url": "https://arxiv.org/abs/2402.00972",
        "title": "Closure Discovery for Coarse-Grained Partial Differential Equations using Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reliable predictions of critical phenomena, such as weather, wildfires and epidemics are often founded on models described by Partial Differential Equations (PDEs). However, simulations that capture the full range of spatio-temporal scales in such PDEs are often prohibitively expensive. Consequently, coarse-grained simulations that employ heuristics and empirical closure terms are frequently utilized as an alternative. We propose a novel and systematic approach for identifying closures in under-resolved PDEs using Multi-Agent Reinforcement Learning (MARL). The MARL formulation incorporates inductive bias and exploits locality by deploying a central policy represented efficiently by Convolutional Neural Networks (CNN). We demonstrate the capabilities and limitations of MARL through numerical solutions of the advection equation and the Burgers' equation. Our results show accurate predictions for in- and out-of-distribution test cases as well as a significant speedup compared to resolving all scales.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "physics.comp-ph"
        ],
        "comment": "18 pages, 12 figures"
    },
    {
        "paper id": "2402.00987",
        "abstract url": "https://arxiv.org/abs/2402.00987",
        "title": "Self-Supervised Contrastive Pre-Training for Multivariate Point Processes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Self-supervision is one of the hallmarks of representation learning in the increasingly popular suite of foundation models including large language models such as BERT and GPT-3, but it has not been pursued in the context of multivariate event streams, to the best of our knowledge. We introduce a new paradigm for self-supervised learning for multivariate point processes using a transformer encoder. Specifically, we design a novel pre-training strategy for the encoder where we not only mask random event epochs but also insert randomly sampled \"void\" epochs where an event does not occur; this differs from the typical discrete-time pretext tasks such as word-masking in BERT but expands the effectiveness of masking to better capture continuous-time dynamics. To improve downstream tasks, we introduce a contrasting module that compares real events to simulated void instances. The pre-trained model can subsequently be fine-tuned on a potentially much smaller event dataset, similar conceptually to the typical transfer of popular pre-trained language models. We demonstrate the effectiveness of our proposed paradigm on the next-event prediction task using synthetic datasets and 3 real applications, observing a relative performance boost of as high as up to 20% compared to state-of-the-art models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01029",
        "abstract url": "https://arxiv.org/abs/2402.01029",
        "title": "Response Theory via Generative Score Modeling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce an approach for analyzing the responses of dynamical systems to external perturbations that combines score-based generative modeling with the Fluctuation-Dissipation Theorem (FDT). The methodology enables accurate estimation of system responses, especially for systems with non-Gaussian statistics, often encountered in dynamical systems far from equilibrium. Such cases often present limitations for conventional approximate methods. We numerically validate our approach using time-series data from a stochastic partial differential equation where the score function is available analytically. Furthermore, we demonstrate the improved accuracy of our methodology over conventional methods and its potential as a versatile tool for understanding complex dynamical systems. Applications span disciplines from climate science and finance to neuroscience.",
        "subjects": [
            "physics.data-an",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01036",
        "abstract url": "https://arxiv.org/abs/2402.01036",
        "title": "Fisher information dissipation for time inhomogeneous stochastic differential equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We provide a Lyapunov convergence analysis for time-inhomogeneous variable coefficient stochastic differential equations (SDEs). Three typical examples include overdamped, irreversible drift, and underdamped Langevin dynamics. We first formula the probability transition equation of Langevin dynamics as a modified gradient flow of the Kullback-Leibler divergence in the probability space with respect to time-dependent optimal transport metrics. This formulation contains both gradient and non-gradient directions depending on a class of time-dependent target distribution. We then select a time-dependent relative Fisher information functional as a Lyapunov functional. We develop a time-dependent Hessian matrix condition, which guarantees the convergence of the probability density function of the SDE. We verify the proposed conditions for several time-inhomogeneous Langevin dynamics. For the overdamped Langevin dynamics, we prove the $O(t^{-1/2})$ convergence in $L^1$ distance for the simulated annealing dynamics with a strongly convex potential function. For the irreversible drift Langevin dynamics, we prove an improved convergence towards the target distribution in an asymptotic regime. We also verify the convergence condition for the underdamped Langevin dynamics. Numerical examples demonstrate the convergence results for the time-dependent Langevin dynamics.",
        "subjects": [
            "math.PR",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "9 figures, 36 pages"
    },
    {
        "paper id": "2402.01050",
        "abstract url": "https://arxiv.org/abs/2402.01050",
        "title": "Distributed MCMC inference for Bayesian Non-Parametric Latent Block Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we introduce a novel Distributed Markov Chain Monte Carlo (MCMC) inference method for the Bayesian Non-Parametric Latent Block Model (DisNPLBM), employing the Master/Worker architecture. Our non-parametric co-clustering algorithm divides observations and features into partitions using latent multivariate Gaussian block distributions. The workload on rows is evenly distributed among workers, who exclusively communicate with the master and not among themselves. DisNPLBM demonstrates its impact on cluster labeling accuracy and execution times through experimental results. Moreover, we present a real-use case applying our approach to co-cluster gene expression data. The code source is publicly available at https://github.com/redakhoufache/Distributed-NPLBM.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "comment": "Accepted to PaKDD 2024"
    },
    {
        "paper id": "2402.01055",
        "abstract url": "https://arxiv.org/abs/2402.01055",
        "title": "Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro $F_1$ in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds for our algorithms, establishing that even though they are trained on noisy data, they are Bayes consistent in the sense that their performance converges to the optimal performance w.r.t. the clean (non-noisy) distribution. Our experiments demonstrate the effectiveness of our algorithms in handling label noise.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01071",
        "abstract url": "https://arxiv.org/abs/2402.01071",
        "title": "Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The potential harms of the under-representation of minorities in training data, particularly in multi-modal settings, is a well-recognized concern. While there has been extensive effort in detecting such under-representation, resolution has remained a challenge. With recent advancements in generative AI, large language models and foundation models have emerged as versatile tools across various domains. In this paper, we propose Chameleon, a system that efficiently utilizes these tools to augment a data set with a minimal addition of synthetically generated tuples, in order to enhance the coverage of the under-represented groups. Our system follows a rejection sampling approach to ensure the generated tuples have a high quality and follow the underlying distribution. In order to minimize the rejection chance of the generated tuples, we propose multiple strategies for providing a guide for the foundation model. Our experiment results, in addition to confirming the efficiency of our proposed algorithms, illustrate the effectiveness of our approach, as the unfairness of the model in a downstream task significantly dropped after data repair using Chameleon.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01089",
        "abstract url": "https://arxiv.org/abs/2402.01089",
        "title": "No Free Prune: Information-Theoretic Barriers to Pruning at Initialization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The existence of \"lottery tickets\" arXiv:1803.03635 at or near initialization raises the tantalizing question of whether large models are necessary in deep learning, or whether sparse networks can be quickly identified and trained without ever training the dense models that contain them. However, efforts to find these sparse subnetworks without training the dense model (\"pruning at initialization\") have been broadly unsuccessful arXiv:2009.08576. We put forward a theoretical explanation for this, based on the model's effective parameter count, $p_\\text{eff}$, given by the sum of the number of non-zero weights in the final network and the mutual information between the sparsity mask and the data. We show the Law of Robustness of arXiv:2105.12806 extends to sparse networks with the usual parameter count replaced by $p_\\text{eff}$, meaning a sparse neural network which robustly interpolates noisy data requires a heavily data-dependent mask. We posit that pruning during and after training outputs masks with higher mutual information than those produced by pruning at initialization. Thus two networks may have the same sparsities, but differ in effective parameter count based on how they were trained. This suggests that pruning near initialization may be infeasible and explains why lottery tickets exist, but cannot be found fast (i.e. without training the full network). Experiments on neural networks confirm that information gained during training may indeed affect model capacity.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01090",
        "abstract url": "https://arxiv.org/abs/2402.01090",
        "title": "Scalable Higher-Order Tensor Product Spline Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the current era of vast data and transparent machine learning, it is essential for techniques to operate at a large scale while providing a clear mathematical comprehension of the internal workings of the method. Although there already exist interpretable semi-parametric regression methods for large-scale applications that take into account non-linearity in the data, the complexity of the models is still often limited. One of the main challenges is the absence of interactions in these models, which are left out for the sake of better interpretability but also due to impractical computational costs. To overcome this limitation, we propose a new approach using a factorization method to derive a highly scalable higher-order tensor product spline model. Our method allows for the incorporation of all (higher-order) interactions of non-linear feature effects while having computational costs proportional to a model without interactions. We further develop a meaningful penalization scheme and examine the induced optimization problem. We conclude by evaluating the predictive and estimation performance of our method.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "comment": "Accepted at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024. arXiv admin note: substantial text overlap with arXiv:2205.14515"
    },
    {
        "paper id": "2402.01092",
        "abstract url": "https://arxiv.org/abs/2402.01092",
        "title": "A Dynamical Model of Neural Scaling Laws",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-width dynamics at a rate $1/\\textit{width}$ but at late time exhibit a rate $\\textit{width}^{-c}$, where $c$ depends on the structure of the architecture and task. We show that our model exhibits this behavior. Lastly, our theory shows how the gap between training and test loss can gradually build up over time due to repeated reuse of data.",
        "subjects": [
            "stat.ML",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "comment": "Updated Appendix with new SGD section, more ensembling verification, and connection to timescale/eigenvalue densities"
    },
    {
        "paper id": "2402.01098",
        "abstract url": "https://arxiv.org/abs/2402.01098",
        "title": "Bayesian Deep Learning for Remaining Useful Life Estimation via Stein Variational Gradient Descent",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A crucial task in predictive maintenance is estimating the remaining useful life of physical systems. In the last decade, deep learning has improved considerably upon traditional model-based and statistical approaches in terms of predictive performance. However, in order to optimally plan maintenance operations, it is also important to quantify the uncertainty inherent to the predictions. This issue can be addressed by turning standard frequentist neural networks into Bayesian neural networks, which are naturally capable of providing confidence intervals around the estimates. Several methods exist for training those models. Researchers have focused mostly on parametric variational inference and sampling-based techniques, which notoriously suffer from limited approximation power and large computational burden, respectively. In this work, we use Stein variational gradient descent, a recently proposed algorithm for approximating intractable distributions that overcomes the drawbacks of the aforementioned techniques. In particular, we show through experimental studies on simulated run-to-failure turbofan engine degradation data that Bayesian deep learning models trained via Stein variational gradient descent consistently outperform with respect to convergence speed and predictive performance both the same models trained via parametric variational inference and their frequentist counterparts trained via backpropagation. Furthermore, we propose a method to enhance performance based on the uncertainty information provided by the Bayesian models. We release the source code at https://github.com/lucadellalib/bdl-rul-svgd.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "26 pages, 3 figures"
    },
    {
        "paper id": "2402.01111",
        "abstract url": "https://arxiv.org/abs/2402.01111",
        "title": "Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We study the problem of multi-agent reinforcement learning (MARL) with adaptivity constraints -- a new problem motivated by real-world applications where deployments of new policies are costly and the number of policy updates must be minimized. For two-player zero-sum Markov Games, we design a (policy) elimination based algorithm that achieves a regret of $\\widetilde{O}(\\sqrt{H^3 S^2 ABK})$, while the batch complexity is only $O(H+\\log\\log K)$. In the above, $S$ denotes the number of states, $A,B$ are the number of actions for the two players respectively, $H$ is the horizon and $K$ is the number of episodes. Furthermore, we prove a batch complexity lower bound $\u03a9(\\frac{H}{\\log_{A}K}+\\log\\log K)$ for all algorithms with $\\widetilde{O}(\\sqrt{K})$ regret bound, which matches our upper bound up to logarithmic factors. As a byproduct, our techniques naturally extend to learning bandit games and reward-free MARL within near optimal batch complexity. To the best of our knowledge, these are the first line of results towards understanding MARL with low adaptivity.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01139",
        "abstract url": "https://arxiv.org/abs/2402.01139",
        "title": "Online conformal prediction with decaying step sizes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a method for online conformal prediction with decaying step sizes. Like previous methods, ours possesses a retrospective guarantee of coverage for arbitrary sequences. However, unlike previous methods, we can simultaneously estimate a population quantile when it exists. Our theory and experiments indicate substantially improved practical properties: in particular, when the distribution is stable, the coverage is close to the desired level for every time point, not just on average over the observed sequence.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01770",
        "abstract url": "https://arxiv.org/abs/2402.01770",
        "title": "Extending Interactive Science Exhibits into the Classroom using Anthropomorphized Chatbots and Bloom's Taxonomy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study explores the use of Generative AI chatbots for transforming public science exhibits into virtual experiences that can extend the engagement of exhibits into the classroom. The broader goal is to increase accessibility of science exhibits, especially for those marginalized in STEM due to various factors, including cultural barriers. We hypothesize that turning exhibits into first-person anthropomorphized chatbots with a personality, like quirky-talking asteroids or comets, can increase engagement and learning. The paper mainly explores if such techniques are possible using Generative AI (e.g. GPT) via prompt engineering alone. The research includes an investigation into the possibility of integrating interactive assessment via question-generation using Bloom's Taxonomy. Initial results indicate that it is possible to combine these techniques. As such, it lays a foundation for future classroom evaluations of such chatbots to gauge their overall efficacy in extending the reach of science exhibitions. The paper concludes by discussing extensions of the research to fully evaluate effectiveness in virtual field-trips. We also include a brief examination of additional ways to enhance student motivation towards learning via chatbots.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01785",
        "abstract url": "https://arxiv.org/abs/2402.01785",
        "title": "DoubleMLDeep: Estimation of Causal Effects with Multimodal Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper explores the use of unstructured, multimodal data, namely text and images, in causal inference and treatment effect estimation. We propose a neural network architecture that is adapted to the double machine learning (DML) framework, specifically the partially linear model. An additional contribution of our paper is a new method to generate a semi-synthetic dataset which can be used to evaluate the performance of causal effect estimation in the presence of text and images as confounders. The proposed methods and architectures are evaluated on the semi-synthetic dataset and compared to standard approaches, highlighting the potential benefit of using text and images directly in causal studies. Our findings have implications for researchers and practitioners in economics, marketing, finance, medicine and data science in general who are interested in estimating causal quantities using non-traditional data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "econ.EM",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01795",
        "abstract url": "https://arxiv.org/abs/2402.01795",
        "title": "Few-Shot Scenario Testing for Autonomous Vehicles Based on Neighborhood Coverage and Similarity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Testing and evaluating the safety performance of autonomous vehicles (AVs) is essential before the large-scale deployment. Practically, the number of testing scenarios permissible for a specific AV is severely limited by tight constraints on testing budgets and time. With the restrictions imposed by strictly restricted numbers of tests, existing testing methods often lead to significant uncertainty or difficulty to quantifying evaluation results. In this paper, we formulate this problem for the first time the \"few-shot testing\" (FST) problem and propose a systematic framework to address this challenge. To alleviate the considerable uncertainty inherent in a small testing scenario set, we frame the FST problem as an optimization problem and search for the testing scenario set based on neighborhood coverage and similarity. Specifically, under the guidance of better generalization ability of the testing scenario set on AVs, we dynamically adjust this set and the contribution of each testing scenario to the evaluation result based on coverage, leveraging the prior information of surrogate models (SMs). With certain hypotheses on SMs, a theoretical upper bound of evaluation error is established to verify the sufficiency of evaluation accuracy within the given limited number of tests. The experiment results on cut-in scenarios demonstrate a notable reduction in evaluation error and variance of our method compared to conventional testing methods, especially for situations with a strict limit on the number of scenarios.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.RO",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10088",
        "abstract url": "https://arxiv.org/abs/2402.10088",
        "title": "Hierarchical hybrid modeling for flexible tool use",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In a recent computational framework called active inference, discrete models can be linked to their continuous counterparts to perform decision-making in changing environments. From another perspective, simple agents can be combined to better capture the causal relationships of the world. How can we use these two features together to achieve efficient goal-directed behavior? We present an architecture composed of several hybrid -- continuous and discrete -- units replicating the agent's configuration, controlled by a high-level discrete model that achieves dynamic planning and synchronized behavior. Additional factorizations within each level allow to represent hierarchically other agents and objects in relation to the self. We evaluate this hierarchical hybrid model on a non-trivial task: reaching a moving object after having picked a moving tool. This study extends past work on control as inference and proposes an alternative direction to deep reinforcement learning.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10091",
        "abstract url": "https://arxiv.org/abs/2402.10091",
        "title": "Text-Based Product Matching -- Semi-Supervised Clustering Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Matching identical products present in multiple product feeds constitutes a crucial element of many tasks of e-commerce, such as comparing product offerings, dynamic price optimization, and selecting the assortment personalized for the client. It corresponds to the well-known machine learning task of entity matching, with its own specificity, like omnipresent unstructured data or inaccurate and inconsistent product descriptions. This paper aims to present a new philosophy to product matching utilizing a semi-supervised clustering approach. We study the properties of this method by experimenting with the IDEC algorithm on the real-world dataset using predominantly textual features and fuzzy string matching, with more standard approaches as a point of reference. Encouraging results show that unsupervised matching, enriched with a small annotated sample of product links, could be a possible alternative to the dominant supervised strategy, requiring extensive manual data labeling.",
        "subjects": [
            "cs.DB",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00357",
        "abstract url": "https://arxiv.org/abs/2402.00357",
        "title": "Safety of Multimodal Large Language Models on Images and Text",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Attracted by the impressive power of Multimodal Large Language Models (MLLMs), the public is increasingly utilizing them to improve the efficiency of daily work. Nonetheless, the vulnerabilities of MLLMs to unsafe instructions bring huge safety risks when these models are deployed in real-world scenarios. In this paper, we systematically survey current efforts on the evaluation, attack, and defense of MLLMs' safety on images and text. We begin with introducing the overview of MLLMs on images and text and understanding of safety, which helps researchers know the detailed scope of our survey. Then, we review the evaluation datasets and metrics for measuring the safety of MLLMs. Next, we comprehensively present attack and defense techniques related to MLLMs' safety. Finally, we analyze several unsolved issues and discuss promising research directions. The latest papers are continually collected at https://github.com/isXinLiu/MLLM-Safety-Collection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00407",
        "abstract url": "https://arxiv.org/abs/2402.00407",
        "title": "InfMAE: A Foundation Model in Infrared Modality",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the foundation models have swept the computer vision field and facilitated the development of various tasks within different modalities. However, it remains an open question on how to design an infrared foundation model. In this paper, we propose InfMAE, a foundation model in infrared modality. We release an infrared dataset, called Inf30 to address the problem of lacking large-scale data for self-supervised learning in the infrared vision community. Besides, we design an information-aware masking strategy, which is suitable for infrared images. This masking strategy allows for a greater emphasis on the regions with richer information in infrared images during the self-supervised learning process, which is conducive to learning the generalized representation. In addition, we adopt a multi-scale encoder to enhance the performance of the pre-trained encoders in downstream tasks. Finally, based on the fact that infrared images do not have a lot of details and texture information, we design an infrared decoder module, which further improves the performance of downstream tasks. Extensive experiments show that our proposed method InfMAE outperforms other supervised methods and self-supervised learning methods in three downstream tasks. Our code will be made public at https://github.com/liufangcen/InfMAE.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 2 figures"
    },
    {
        "paper id": "2402.00418",
        "abstract url": "https://arxiv.org/abs/2402.00418",
        "title": "Benchmarking Transferable Adversarial Attacks",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The robustness of deep learning models against adversarial attacks remains a pivotal concern. This study presents, for the first time, an exhaustive review of the transferability aspect of adversarial attacks. It systematically categorizes and critically evaluates various methodologies developed to augment the transferability of adversarial attacks. This study encompasses a spectrum of techniques, including Generative Structure, Semantic Similarity, Gradient Editing, Target Modification, and Ensemble Approach. Concurrently, this paper introduces a benchmark framework \\textit{TAA-Bench}, integrating ten leading methodologies for adversarial attack transferability, thereby providing a standardized and systematic platform for comparative analysis across diverse model architectures. Through comprehensive scrutiny, we delineate the efficacy and constraints of each method, shedding light on their underlying operational principles and practical utility. This review endeavors to be a quintessential resource for both scholars and practitioners in the field, charting the complex terrain of adversarial transferability and setting a foundation for future explorations in this vital sector. The associated codebase is accessible at: https://github.com/KxPlaug/TAA-Bench",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by NDSS 2024 Workshop"
    },
    {
        "paper id": "2402.00448",
        "abstract url": "https://arxiv.org/abs/2402.00448",
        "title": "Dual-Student Knowledge Distillation Networks for Unsupervised Anomaly Detection",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Due to the data imbalance and the diversity of defects, student-teacher networks (S-T) are favored in unsupervised anomaly detection, which explores the discrepancy in feature representation derived from the knowledge distillation process to recognize anomalies. However, vanilla S-T network is not stable. Employing identical structures to construct the S-T network may weaken the representative discrepancy on anomalies. But using different structures can increase the likelihood of divergent performance on normal data. To address this problem, we propose a novel dual-student knowledge distillation (DSKD) architecture. Different from other S-T networks, we use two student networks a single pre-trained teacher network, where the students have the same scale but inverted structures. This framework can enhance the distillation effect to improve the consistency in recognition of normal data, and simultaneously introduce diversity for anomaly representation. To explore high-dimensional semantic information to capture anomaly clues, we employ two strategies. First, a pyramid matching mode is used to perform knowledge distillation on multi-scale feature maps in the intermediate layers of networks. Second, an interaction is facilitated between the two student networks through a deep feature embedding module, which is inspired by real-world group discussions. In terms of classification, we obtain pixel-wise anomaly segmentation maps by measuring the discrepancy between the output feature maps of the teacher and student networks, from which an anomaly score is computed for sample-wise determination. We evaluate DSKD on three benchmark datasets and probe the effects of internal modules through ablation experiments. The results demonstrate that DSKD can achieve exceptional performance on small models like ResNet18 and effectively improve vanilla S-T networks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00541",
        "abstract url": "https://arxiv.org/abs/2402.00541",
        "title": "Masked Conditional Diffusion Model for Enhancing Deepfake Detection",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent studies on deepfake detection have achieved promising results when training and testing faces are from the same dataset. However, their results severely degrade when confronted with forged samples that the model has not yet seen during training. In this paper, deepfake data to help detect deepfakes. this paper present we put a new insight into diffusion model-based data augmentation, and propose a Masked Conditional Diffusion Model (MCDM) for enhancing deepfake detection. It generates a variety of forged faces from a masked pristine one, encouraging the deepfake detection model to learn generic and robust representations without overfitting to special artifacts. Extensive experiments demonstrate that forgery images generated with our method are of high quality and helpful to improve the performance of deepfake detection models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00576",
        "abstract url": "https://arxiv.org/abs/2402.00576",
        "title": "Tropical Decision Boundaries for Neural Networks Are Robust Against Adversarial Attacks",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a simple, easy to implement, and computationally efficient tropical convolutional neural network architecture that is robust against adversarial attacks. We exploit the tropical nature of piece-wise linear neural networks by embedding the data in the tropical projective torus in a single hidden layer which can be added to any model. We study the geometry of its decision boundary theoretically and show its robustness against adversarial attacks on image datasets using computational experiments.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.CV",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00645",
        "abstract url": "https://arxiv.org/abs/2402.00645",
        "title": "Spectrally Transformed Kernel Regression",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Unlabeled data is a key component of modern machine learning. In general, the role of unlabeled data is to impose a form of smoothness, usually from the similarity information encoded in a base kernel, such as the $\u03b5$-neighbor kernel or the adjacency matrix of a graph. This work revisits the classical idea of spectrally transformed kernel regression (STKR), and provides a new class of general and scalable STKR estimators able to leverage unlabeled data. Intuitively, via spectral transformation, STKR exploits the data distribution for which unlabeled data can provide additional information. First, we show that STKR is a principled and general approach, by characterizing a universal type of \"target smoothness\", and proving that any sufficiently smooth function can be learned by STKR. Second, we provide scalable STKR implementations for the inductive setting and a general transformation function, while prior work is mostly limited to the transductive setting. Third, we derive statistical guarantees for two scenarios: STKR with a known polynomial transformation, and STKR with kernel PCA when the transformation is unknown. Overall, we believe that this work helps deepen our understanding of how to work with unlabeled data, and its generality makes it easier to inspire new methods.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "ICLR 2024 spotlight. 36 pages"
    },
    {
        "paper id": "2402.00658",
        "abstract url": "https://arxiv.org/abs/2402.00658",
        "title": "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing",
        "rating": "0",
        "keywords": [
            [
                "Synthesizing"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated significant potential in handling complex reasoning tasks through step-by-step rationale generation. However, recent studies have raised concerns regarding the hallucination and flaws in their reasoning process. Substantial efforts are being made to improve the reliability and faithfulness of the generated rationales. Some approaches model reasoning as planning, while others focus on annotating for process supervision. Nevertheless, the planning-based search process often results in high latency due to the frequent assessment of intermediate reasoning states and the extensive exploration space. Additionally, supervising the reasoning process with human annotation is costly and challenging to scale for LLM training. To address these issues, in this paper, we propose a framework to learn planning-based reasoning through Direct Preference Optimization (DPO) on collected trajectories, which are ranked according to synthesized process rewards. Our results on challenging logical reasoning benchmarks demonstrate the effectiveness of our learning framework, showing that our 7B model can surpass the strong counterparts like GPT-3.5-Turbo.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "17 pages, 9 figures"
    },
    {
        "paper id": "2402.00672",
        "abstract url": "https://arxiv.org/abs/2402.00672",
        "title": "Exploring Homogeneous and Heterogeneous Consistent Label Associations for Unsupervised Visible-Infrared Person ReID",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to retrieve pedestrian images of the same identity from different modalities without annotations. While prior work focuses on establishing cross-modality pseudo-label associations to bridge the modality-gap, they ignore maintaining the instance-level homogeneous and heterogeneous consistency in pseudo-label space, resulting in coarse associations. In response, we introduce a Modality-Unified Label Transfer (MULT) module that simultaneously accounts for both homogeneous and heterogeneous fine-grained instance-level structures, yielding high-quality cross-modality label associations. It models both homogeneous and heterogeneous affinities, leveraging them to define the inconsistency for the pseudo-labels and then minimize it, leading to pseudo-labels that maintain alignment across modalities and consistency within intra-modality structures. Additionally, a straightforward plug-and-play Online Cross-memory Label Refinement (OCLR) module is proposed to further mitigate the impact of noisy pseudo-labels while simultaneously aligning different modalities, coupled with a Modality-Invariant Representation Learning (MIRL) framework. Experiments demonstrate that our proposed method outperforms existing USL-VI-ReID methods, highlighting the superiority of our MULT in comparison to other cross-modality association methods. The code will be available.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00676",
        "abstract url": "https://arxiv.org/abs/2402.00676",
        "title": "Deep Robot Sketching: An application of Deep Q-Learning Networks for human-like sketching",
        "rating": "0",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The current success of Reinforcement Learning algorithms for its performance in complex environments has inspired many recent theoretical approaches to cognitive science. Artistic environments are studied within the cognitive science community as rich, natural, multi-sensory, multi-cultural environments. In this work, we propose the introduction of Reinforcement Learning for improving the control of artistic robot applications. Deep Q-learning Neural Networks (DQN) is one of the most successful algorithms for the implementation of Reinforcement Learning in robotics. DQN methods generate complex control policies for the execution of complex robot applications in a wide set of environments. Current art painting robot applications use simple control laws that limits the adaptability of the frameworks to a set of simple environments. In this work, the introduction of DQN within an art painting robot application is proposed. The goal is to study how the introduction of a complex control policy impacts the performance of a basic art painting robot application. The main expected contribution of this work is to serve as a first baseline for future works introducing DQN methods for complex art painting robot frameworks. Experiments consist of real world executions of human drawn sketches using the DQN generated policy and TEO, the humanoid robot. Results are compared in terms of similarity and obtained reward with respect to the reference inputs",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00692",
        "abstract url": "https://arxiv.org/abs/2402.00692",
        "title": "A Framework for Building Point Cloud Cleaning, Plane Detection and Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a framework to address the challenges involved in building point cloud cleaning, plane detection, and semantic segmentation, with the ultimate goal of enhancing building modeling. We focus in the cleaning stage on removing outliers from the acquired point cloud data by employing an adaptive threshold technique based on z-score measure. Following the cleaning process, we perform plane detection using the robust RANSAC paradigm. The goal is to carry out multiple plane segmentations, and to classify segments into distinct categories, such as floors, ceilings, and walls. The resulting segments can generate accurate and detailed point clouds representing the building's architectural elements. Moreover, we address the problem of semantic segmentation, which plays a vital role in the identification and classification of different components within the building, such as walls, windows, doors, roofs, and objects. Inspired by the PointNet architecture, we propose a deep learning architecture for efficient semantic segmentation in buildings. The results demonstrate the effectiveness of the proposed framework in handling building modeling tasks, paving the way for improved accuracy and efficiency in the field of building modelization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00740",
        "abstract url": "https://arxiv.org/abs/2402.00740",
        "title": "DRSM: efficient neural 4d decomposition for dynamic reconstruction in stationary monocular cameras",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the popularity of monocular videos generated by video sharing and live broadcasting applications, reconstructing and editing dynamic scenes in stationary monocular cameras has become a special but anticipated technology. In contrast to scene reconstructions that exploit multi-view observations, the problem of modeling a dynamic scene from a single view is significantly more under-constrained and ill-posed. Inspired by recent progress in neural rendering, we present a novel framework to tackle 4D decomposition problem for dynamic scenes in monocular cameras. Our framework utilizes decomposed static and dynamic feature planes to represent 4D scenes and emphasizes the learning of dynamic regions through dense ray casting. Inadequate 3D clues from a single-view and occlusion are also particular challenges in scene reconstruction. To overcome these difficulties, we propose deep supervised optimization and ray casting strategies. With experiments on various videos, our method generates higher-fidelity results than existing methods for single-view dynamic scene representation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00752",
        "abstract url": "https://arxiv.org/abs/2402.00752",
        "title": "On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting has garnered extensive attention and application in real-time neural rendering. Concurrently, concerns have been raised about the limitations of this technology in aspects such as point cloud storage, performance, and robustness in sparse viewpoints, leading to various improvements. However, there has been a notable lack of attention to the fundamental problem of projection errors introduced by the local affine approximation inherent in the splatting itself, and the consequential impact of these errors on the quality of photo-realistic rendering. This paper addresses the projection error function of 3D Gaussian Splatting, commencing with the residual error from the first-order Taylor expansion of the projection function. The analysis establishes a correlation between the error and the Gaussian mean position. Subsequently, leveraging function optimization theory, this paper analyzes the function's minima to provide an optimal projection strategy for Gaussian Splatting referred to Optimal Gaussian Splatting, which can accommodate a variety of camera models. Experimental validation further confirms that this projection methodology reduces artifacts, resulting in a more convincingly realistic rendering.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00811",
        "abstract url": "https://arxiv.org/abs/2402.00811",
        "title": "An Analysis of the Variance of Diffusion-based Speech Enhancement",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.SD"
            ]
        ],
        "abstract": "Diffusion models proved to be powerful models for generative speech enhancement. In recent SGMSE+ approaches, training involves a stochastic differential equation for the diffusion process, adding both Gaussian and environmental noise to the clean speech signal gradually. The speech enhancement performance varies depending on the choice of the stochastic differential equation that controls the evolution of the mean and the variance along the diffusion processes when adding environmental and Gaussian noise. In this work, we highlight that the scale of the variance is a dominant parameter for speech enhancement performance and show that it controls the tradeoff between noise attenuation and speech distortions. More concretely, we show that a larger variance increases the noise attenuation and allows for reducing the computational footprint, as fewer function evaluations for generating the estimate are required.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "5 pages, 3 figures, 1 table"
    },
    {
        "paper id": "2402.00859",
        "abstract url": "https://arxiv.org/abs/2402.00859",
        "title": "Deep Room Impulse Response Completion",
        "rating": "0",
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "Rendering immersive spatial audio in virtual reality (VR) and video games demands a fast and accurate generation of room impulse responses (RIRs) to recreate auditory environments plausibly. However, the conventional methods for simulating or measuring long RIRs are either computationally intensive or challenged by low signal-to-noise ratios. This study is propelled by the insight that direct sound and early reflections encapsulate sufficient information about room geometry and absorption characteristics. Building upon this premise, we propose a novel task termed \"RIR completion,\" aimed at synthesizing the late reverberation given only the early portion (50 ms) of the response. To this end, we introduce DECOR, Deep Exponential Completion Of Room impulse responses, a deep neural network structured as an autoencoder designed to predict multi-exponential decay envelopes of filtered noise sequences. The interpretability of DECOR's output facilitates its integration with diverse rendering techniques. The proposed method is compared against an adapted state-of-the-art network, and comparable performance shows promising results supporting the feasibility of the RIR completion task. The RIR completion can be widely adapted to enhance RIR generation tasks where fast late reverberation approximation is required.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "The following article has been submitted to the EURASIP Journal on Audio, Speech, and Music Processing"
    },
    {
        "paper id": "2402.00918",
        "abstract url": "https://arxiv.org/abs/2402.00918",
        "title": "MUSTAN: Multi-scale Temporal Context as Attention for Robust Video Foreground Segmentation",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Video foreground segmentation (VFS) is an important computer vision task wherein one aims to segment the objects under motion from the background. Most of the current methods are image-based, i.e., rely only on spatial cues while ignoring motion cues. Therefore, they tend to overfit the training data and don't generalize well to out-of-domain (OOD) distribution. To solve the above problem, prior works exploited several cues such as optical flow, background subtraction mask, etc. However, having a video data with annotations like optical flow is a challenging task. In this paper, we utilize the temporal information and the spatial cues from the video data to improve OOD performance. However, the challenge lies in how we model the temporal information given the video data in an interpretable way creates a very noticeable difference. We therefore devise a strategy that integrates the temporal context of the video in the development of VFS. Our approach give rise to deep learning architectures, namely MUSTAN1 and MUSTAN2 and they are based on the idea of multi-scale temporal context as an attention, i.e., aids our models to learn better representations that are beneficial for VFS. Further, we introduce a new video dataset, namely Indoor Surveillance Dataset (ISD) for VFS. It has multiple annotations on a frame level such as foreground binary mask, depth map, and instance semantic annotations. Therefore, ISD can benefit other computer vision tasks. We validate the efficacy of our architectures and compare the performance with baselines. We demonstrate that proposed methods significantly outperform the benchmark methods on OOD. In addition, the performance of MUSTAN2 is significantly improved on certain video categories on OOD data due to ISD.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "10 pages, 8 figures"
    },
    {
        "paper id": "2402.00977",
        "abstract url": "https://arxiv.org/abs/2402.00977",
        "title": "Enhanced fringe-to-phase framework using deep learning",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In Fringe Projection Profilometry (FPP), achieving robust and accurate 3D reconstruction with a limited number of fringe patterns remains a challenge in structured light 3D imaging. Conventional methods require a set of fringe images, but using only one or two patterns complicates phase recovery and unwrapping. In this study, we introduce SFNet, a symmetric fusion network that transforms two fringe images into an absolute phase. To enhance output reliability, Our framework predicts refined phases by incorporating information from fringe images of a different frequency than those used as input. This allows us to achieve high accuracy with just two images. Comparative experiments and ablation studies validate the effectiveness of our proposed method. The dataset and code are publicly accessible on our project page https://wonhoe-kim.github.io/SFNet.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "35 pages, 13 figures, 6 tables"
    },
    {
        "paper id": "2402.00989",
        "abstract url": "https://arxiv.org/abs/2402.00989",
        "title": "YOLinO++: Single-Shot Estimation of Generic Polylines for Mapless Automated Diving",
        "rating": "0",
        "keywords": [
            [
                "automated driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In automated driving, highly accurate maps are commonly used to support and complement perception. These maps are costly to create and quickly become outdated as the traffic world is permanently changing. In order to support or replace the map of an automated system with detections from sensor data, a perception module must be able to detect the map features. We propose a neural network that follows the one shot philosophy of YOLO but is designed for detection of 1D structures in images, such as lane boundaries. We extend previous ideas by a midpoint based line representation and anchor definitions. This representation can be used to describe lane borders, markings, but also implicit features such as centerlines of lanes. The broad applicability of the approach is shown with the detection performance on lane centerlines, lane borders as well as the markings both on highways and in urban areas. Versatile lane boundaries are detected and can be inherently classified as dashed or solid lines, curb, road boundaries, or implicit delimitation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00996",
        "abstract url": "https://arxiv.org/abs/2402.00996",
        "title": "mmID: High-Resolution mmWave Imaging for Human Identification",
        "rating": "0",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Achieving accurate human identification through RF imaging has been a persistent challenge, primarily attributed to the limited aperture size and its consequent impact on imaging resolution. The existing imaging solution enables tasks such as pose estimation, activity recognition, and human tracking based on deep neural networks by estimating skeleton joints. In contrast to estimating joints, this paper proposes to improve imaging resolution by estimating the human figure as a whole using conditional generative adversarial networks (cGAN). In order to reduce training complexity, we use an estimated spatial spectrum using the MUltiple SIgnal Classification (MUSIC) algorithm as input to the cGAN. Our system generates environmentally independent, high-resolution images that can extract unique physical features useful for human identification. We use a simple convolution layers-based classification network to obtain the final identification result. From the experimental results, we show that resolution of the image produced by our trained generator is high enough to enable human identification. Our finding indicates high-resolution accuracy with 5% mean silhouette difference to the Kinect device. Extensive experiments in different environments on multiple testers demonstrate that our system can achieve 93% overall test accuracy in unseen environments for static human target identification.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": "This paper was published in the IEEE 9th World Forum on Internet of Things"
    },
    {
        "paper id": "2402.01019",
        "abstract url": "https://arxiv.org/abs/2402.01019",
        "title": "Domain-Independent Deception: A New Taxonomy and Linguistic Analysis",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Internet-based economies and societies are drowning in deceptive attacks. These attacks take many forms, such as fake news, phishing, and job scams, which we call ``domains of deception.'' Machine-learning and natural-language-processing researchers have been attempting to ameliorate this precarious situation by designing domain-specific detectors. Only a few recent works have considered domain-independent deception. We collect these disparate threads of research and investigate domain-independent deception. First, we provide a new computational definition of deception and break down deception into a new taxonomy. Then, we analyze the debate on linguistic cues for deception and supply guidelines for systematic reviews. Finally, we investigate common linguistic features and give evidence for knowledge transfer across different forms of deception.",
        "subjects": [
            "cs.CL",
            "cs.CR",
            "cs.CY"
        ],
        "comment": "33 pages. arXiv admin note: text overlap with arXiv:2207.01738"
    },
    {
        "paper id": "2402.01025",
        "abstract url": "https://arxiv.org/abs/2402.01025",
        "title": "Graph-based Clustering for Detecting Semantic Change Across Time and Languages",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite the predominance of contextualized embeddings in NLP, approaches to detect semantic change relying on these embeddings and clustering methods underperform simpler counterparts based on static word embeddings. This stems from the poor quality of the clustering methods to produce sense clusters -- which struggle to capture word senses, especially those with low frequency. This issue hinders the next step in examining how changes in word senses in one language influence another. To address this issue, we propose a graph-based clustering approach to capture nuanced changes in both high- and low-frequency word senses across time and languages, including the acquisition and loss of these senses over time. Our experimental results show that our approach substantially surpasses previous approaches in the SemEval2020 binary classification task across four languages. Moreover, we showcase the ability of our approach as a versatile visualization tool to detect semantic changes in both intra-language and inter-language setups. We make our code and data publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL2024 Camera Ready (20 pages)"
    },
    {
        "paper id": "2402.01049",
        "abstract url": "https://arxiv.org/abs/2402.01049",
        "title": "IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "One of the primary challenges in the field of human activity recognition (HAR) is the lack of large labeled datasets. This hinders the development of robust and generalizable models. Recently, cross modality transfer approaches have been explored that can alleviate the problem of data scarcity. These approaches convert existing datasets from a source modality, such as video, to a target modality (IMU). With the emergence of generative AI models such as large language models (LLMs) and text-driven motion synthesis models, language has become a promising source data modality as well as shown in proof of concepts such as IMUGPT. In this work, we conduct a large-scale evaluation of language-based cross modality transfer to determine their effectiveness for HAR. Based on this study, we introduce two new extensions for IMUGPT that enhance its use for practical HAR application scenarios: a motion filter capable of filtering out irrelevant motion sequences to ensure the relevance of the generated virtual IMU data, and a set of metrics that measure the diversity of the generated data facilitating the determination of when to stop generating virtual IMU data for both effective and efficient processing. We demonstrate that our diversity metrics can reduce the effort needed for the generation of virtual IMU data by at least 50%, which open up IMUGPT for practical use cases beyond a mere proof of concept.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01109",
        "abstract url": "https://arxiv.org/abs/2402.01109",
        "title": "Vaccine: Perturbation-aware Alignment for Large Language Model",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The new paradigm of finetuning-as-a-service introduces a new attack surface for Large Language Models (LLMs): a few harmful data uploaded by users can easily trick the finetuning to produce an alignment-broken model. We conduct an empirical analysis and uncover a \\textit{harmful embedding drift} phenomenon, showing a probable cause of the alignment-broken effect. Inspired by our findings, we propose Vaccine, a perturbation-aware alignment technique to mitigate the security risk of users finetuning. The core idea of Vaccine is to produce invariant hidden embeddings by progressively adding crafted perturbation to them in the alignment phase. This enables the embeddings to withstand harmful perturbation from un-sanitized user data in the finetuning phase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna) demonstrate that Vaccine can boost the robustness of alignment against harmful prompts induced embedding drift while reserving reasoning ability towards benign prompts. Our code is available at \\url{https://github.com/git-disl/Vaccine}.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05941",
        "abstract url": "https://arxiv.org/abs/2402.05941",
        "title": "Character-based Outfit Generation with Vision-augmented Style Extraction via LLMs",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The outfit generation problem involves recommending a complete outfit to a user based on their interests. Existing approaches focus on recommending items based on anchor items or specific query styles but do not consider customer interests in famous characters from movie, social media, etc. In this paper, we define a new Character-based Outfit Generation (COG) problem, designed to accurately interpret character information and generate complete outfit sets according to customer specifications such as age and gender. To tackle this problem, we propose a novel framework LVA-COG that leverages Large Language Models (LLMs) to extract insights from customer interests (e.g., character information) and employ prompt engineering techniques for accurate understanding of customer preferences. Additionally, we incorporate text-to-image models to enhance the visual understanding and generation (factual or counterfactual) of cohesive outfits. Our framework integrates LLMs with text-to-image models and improves the customer's approach to fashion by generating personalized recommendations. With experiments and case studies, we demonstrate the effectiveness of our solution from multiple dimensions.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "7 pages, 4 figures, IEEE Big Data 2023 3rd Workshop on Multimodal AI (MMAI 2023), IEEE BigData 2023"
    },
    {
        "paper id": "2402.00342",
        "abstract url": "https://arxiv.org/abs/2402.00342",
        "title": "Survey of Privacy Threats and Countermeasures in Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning is widely considered to be as a privacy-aware learning method because no training data is exchanged directly between clients. Nevertheless, there are threats to privacy in federated learning, and privacy countermeasures have been studied. However, we note that common and unique privacy threats among typical types of federated learning have not been categorized and described in a comprehensive and specific way. In this paper, we describe privacy threats and countermeasures for the typical types of federated learning; horizontal federated learning, vertical federated learning, and transfer federated learning.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "Scheduled for renewal by March 2024"
    },
    {
        "paper id": "2402.00366",
        "abstract url": "https://arxiv.org/abs/2402.00366",
        "title": "Legged Robot State Estimation With Invariant Extended Kalman Filter Using Neural Measurement Network",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces a novel proprioceptive state estimator for legged robots that combines model-based filters and deep neural networks. Recent studies have shown that neural networks such as multi-layer perceptron or recurrent neural networks can estimate the robot states, including contact probability and linear velocity. Inspired by this, we develop a state estimation framework that integrates a neural measurement network (NMN) with an invariant extended Kalman filter. We show that our framework improves estimation performance in various terrains. Existing studies that combine model-based filters and learning-based approaches typically use real-world data. However, our approach relies solely on simulation data, as it allows us to easily obtain extensive data. This difference leads to a gap between the learning and the inference domain, commonly referred to as a sim-to-real gap. We address this challenge by adapting existing learning techniques and regularization. To validate our proposed method, we conduct experiments using a quadruped robot on four types of terrain: \\textit{flat}, \\textit{debris}, \\textit{soft}, and \\textit{slippery}. We observe that our approach significantly reduces position drift compared to the existing model-based state estimator.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "8pages, 6paper, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2402.00450",
        "abstract url": "https://arxiv.org/abs/2402.00450",
        "title": "CPT: Competence-progressive Training Strategy for Few-shot Node Classification",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have made significant advancements in node classification, but their success relies on sufficient labeled nodes per class in the training data. Real-world graph data often exhibits a long-tail distribution with sparse labels, emphasizing the importance of GNNs' ability in few-shot node classification, which entails categorizing nodes with limited data. Traditional episodic meta-learning approaches have shown promise in this domain, but they face an inherent limitation: it might lead the model to converge to suboptimal solutions because of random and uniform task assignment, ignoring task difficulty levels. This could lead the meta-learner to face complex tasks too soon, hindering proper learning. Ideally, the meta-learner should start with simple concepts and advance to more complex ones, like human learning. So, we introduce CPT, a novel two-stage curriculum learning method that aligns task difficulty with the meta-learner's progressive competence, enhancing overall performance. Specifically, in CPT's initial stage, the focus is on simpler tasks, fostering foundational skills for engaging with complex tasks later. Importantly, the second stage dynamically adjusts task difficulty based on the meta-learner's growing competence, aiming for optimal knowledge acquisition. Extensive experiments on popular node classification datasets demonstrate significant improvements of our strategy over existing methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2206.11972 by other authors"
    },
    {
        "paper id": "2402.00592",
        "abstract url": "https://arxiv.org/abs/2402.00592",
        "title": "Uncertainty-Aware Partial-Label Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In real-world applications, one often encounters ambiguously labeled data, where different annotators assign conflicting class labels. Partial-label learning allows training classifiers in this weakly supervised setting. While state-of-the-art methods already feature good predictive performance, they often suffer from miscalibrated uncertainty estimates. However, having well-calibrated uncertainty estimates is important, especially in safety-critical domains like medicine and autonomous driving. In this article, we propose a novel nearest-neighbor-based partial-label-learning algorithm that leverages Dempster-Shafer theory. Extensive experiments on artificial and real-world datasets show that the proposed method provides a well-calibrated uncertainty estimate and achieves competitive prediction performance. Additionally, we prove that our algorithm is risk-consistent.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00607",
        "abstract url": "https://arxiv.org/abs/2402.00607",
        "title": "Are Synthetic Time-series Data Really not as Good as Real Data?",
        "rating": "-0.5",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Time-series data presents limitations stemming from data quality issues, bias and vulnerabilities, and generalization problem. Integrating universal data synthesis methods holds promise in improving generalization. However, current methods cannot guarantee that the generator's output covers all unseen real data. In this paper, we introduce InfoBoost -- a highly versatile cross-domain data synthesizing framework with time series representation learning capability. We have developed a method based on synthetic data that enables model training without the need for real data, surpassing the performance of models trained with real data. Additionally, we have trained a universal feature extractor based on our synthetic data that is applicable to all time-series data. Our approach overcomes interference from multiple sources rhythmic signal, noise interference, and long-period features that exceed sampling window capabilities. Through experiments, our non-deep-learning synthetic data enables models to achieve superior reconstruction performance and universal explicit representation extraction without the need for real data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00623",
        "abstract url": "https://arxiv.org/abs/2402.00623",
        "title": "Bayesian Causal Inference with Gaussian Process Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal discovery and inference from observational data is an essential problem in statistics posing both modeling and computational challenges. These are typically addressed by imposing strict assumptions on the joint distribution such as linearity. We consider the problem of the Bayesian estimation of the effects of hypothetical interventions in the Gaussian Process Network (GPN) model, a flexible causal framework which allows describing the causal relationships nonparametrically. We detail how to perform causal inference on GPNs by simulating the effect of an intervention across the whole network and propagating the effect of the intervention on downstream variables. We further derive a simpler computational approximation by estimating the intervention distribution as a function of local variables only, modeling the conditional distributions via additive Gaussian processes. We extend both frameworks beyond the case of a known causal graph, incorporating uncertainty about the causal structure via Markov chain Monte Carlo methods. Simulation studies show that our approach is able to identify the effects of hypothetical interventions with non-Gaussian, non-linear observational data and accurately reflect the posterior uncertainty of the causal estimates. Finally we compare the results of our GPN-based causal inference approach to existing methods on a dataset of $A.~thaliana$ gene expressions.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00659",
        "abstract url": "https://arxiv.org/abs/2402.00659",
        "title": "Modeling Freight Mode Choice Using Machine Learning Classifiers: A Comparative Study Using the Commodity Flow Survey (CFS) Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study explores the usefulness of machine learning classifiers for modeling freight mode choice. We investigate eight commonly used machine learning classifiers, namely Naive Bayes, Support Vector Machine, Artificial Neural Network, K-Nearest Neighbors, Classification and Regression Tree, Random Forest, Boosting and Bagging, along with the classical Multinomial Logit model. US 2012 Commodity Flow Survey data are used as the primary data source; we augment it with spatial attributes from secondary data sources. The performance of the classifiers is compared based on prediction accuracy results. The current research also examines the role of sample size and training-testing data split ratios on the predictive ability of the various approaches. In addition, the importance of variables is estimated to determine how the variables influence freight mode choice. The results show that the tree-based ensemble classifiers perform the best. Specifically, Random Forest produces the most accurate predictions, closely followed by Boosting and Bagging. With regard to variable importance, shipment characteristics, such as shipment distance, industry classification of the shipper and shipment size, are the most significant factors for freight mode choice decisions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00677",
        "abstract url": "https://arxiv.org/abs/2402.00677",
        "title": "Neural Policy Style Transfer",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Style Transfer has been proposed in a number of fields: fine arts, natural language processing, and fixed trajectories. We scale this concept up to control policies within a Deep Reinforcement Learning infrastructure. Each network is trained to maximize the expected reward, which typically encodes the goal of an action, and can be described as the content. The expressive power of deep neural networks enables encoding a secondary task, which can be described as the style. The Neural Policy Style Transfer (NPST) algorithm is proposed to transfer the style of one policy to another, while maintaining the content of the latter. Different policies are defined via Deep Q-Network architectures. These models are trained using demonstrations through Inverse Reinforcement Learning. Two different sets of user demonstrations are performed, one for content and other for style. Different styles are encoded as defined by user demonstrations. The generated policy is the result of feeding a content policy and a style policy to the NPST algorithm. Experiments are performed in a catch-ball game inspired by the Deep Reinforcement Learning classical Atari games; and a real-world painting scenario with a full-sized humanoid robot, based on previous works of the authors. The implementation of three different Q-Network architectures (Shallow, Deep and Deep Recurrent Q-Network) to encode the policies within the NPST framework is proposed and the results obtained in the experiments with each of these architectures compared.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00722",
        "abstract url": "https://arxiv.org/abs/2402.00722",
        "title": "Neural Style Transfer with Twin-Delayed DDPG for Shared Control of Robotic Manipulators",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Neural Style Transfer (NST) refers to a class of algorithms able to manipulate an element, most often images, to adopt the appearance or style of another one. Each element is defined as a combination of Content and Style: the Content can be conceptually defined as the what and the Style as the how of said element. In this context, we propose a custom NST framework for transferring a set of styles to the motion of a robotic manipulator, e.g., the same robotic task can be carried out in an angry, happy, calm, or sad way. An autoencoder architecture extracts and defines the Content and the Style of the target robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3) network generates the robot control policy using the loss defined by the autoencoder. The proposed Neural Policy Style Transfer TD3 (NPST3) alters the robot motion by introducing the trained style. Such an approach can be implemented either offline, for carrying out autonomous robot motions in dynamic environments, or online, for adapting at runtime the style of a teleoperated robot. The considered styles can be learned online from human demonstrations. We carried out an evaluation with human subjects enrolling 73 volunteers, asking them to recognize the style behind some representative robotic motions. Results show a good recognition rate, proving that it is possible to convey different styles to a robot using this approach.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00732",
        "abstract url": "https://arxiv.org/abs/2402.00732",
        "title": "MobilityDL: A Review of Deep Learning From Trajectory Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Trajectory data combines the complexities of time series, spatial data, and (sometimes irrational) movement behavior. As data availability and computing power have increased, so has the popularity of deep learning from trajectory data. This review paper provides the first comprehensive overview of deep learning approaches for trajectory data. We have identified eight specific mobility use cases which we analyze with regards to the deep learning models and the training data used. Besides a comprehensive quantitative review of the literature since 2018, the main contribution of our work is the data-centric analysis of recent work in this field, placing it along the mobility data continuum which ranges from detailed dense trajectories of individual movers (quasi-continuous tracking data), to sparse trajectories (such as check-in data), and aggregated trajectories (crowd information).",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to Geoinformatica"
    },
    {
        "paper id": "2402.00751",
        "abstract url": "https://arxiv.org/abs/2402.00751",
        "title": "Unlearnable Algorithms for In-context Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "unlearning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Machine unlearning is a desirable operation as models get increasingly deployed on data with unknown provenance. However, achieving exact unlearning -- obtaining a model that matches the model distribution when the data to be forgotten was never used -- is challenging or inefficient, often requiring significant retraining. In this paper, we focus on efficient unlearning methods for the task adaptation phase of a pretrained large language model (LLM). We observe that an LLM's ability to do in-context learning for task adaptation allows for efficient exact unlearning of task adaptation training data. We provide an algorithm for selecting few-shot training examples to prepend to the prompt given to an LLM (for task adaptation), ERASE, whose unlearning operation cost is independent of model and dataset size, meaning it scales to large models and datasets. We additionally compare our approach to fine-tuning approaches and discuss the trade-offs between the two approaches. This leads us to propose a new holistic measure of unlearning cost which accounts for varying inference costs, and conclude that in-context learning can often be more favourable than fine-tuning for deployments involving unlearning requests.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00849",
        "abstract url": "https://arxiv.org/abs/2402.00849",
        "title": "Score-based Causal Representation Learning: Linear and General Transformations",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "(updated literature review) Linear transformations: stronger results than our previous paper Score-based Causal Representation Learning with Interventions (arXiv:2301.08230). General transformations: results also appear in our paper General Identifiability and Achievability for Causal Representation Learning (arXiv:2310.15450) accepted to AISTATS 2024 (oral). arXiv admin note: text overlap with arXiv:2310.15450"
    },
    {
        "paper id": "2402.00853",
        "abstract url": "https://arxiv.org/abs/2402.00853",
        "title": "LTAU-FF: Loss Trajectory Analysis for Uncertainty in Atomistic Force Fields",
        "rating": "-0.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Model ensembles are simple and effective tools for estimating the prediction uncertainty of deep learning atomistic force fields. Despite this, widespread adoption of ensemble-based uncertainty quantification (UQ) techniques is limited by the high computational costs incurred by ensembles during both training and inference. In this work we leverage the cumulative distribution functions (CDFs) of per-sample errors obtained over the course of training to efficiently represent the model ensemble, and couple them with a distance-based similarity search in the model latent space. Using these tools, we develop a simple UQ metric (which we call LTAU) that leverages the strengths of ensemble-based techniques without requiring the evaluation of multiple models during either training or inference. As an initial test, we apply our method towards estimating the epistemic uncertainty in atomistic force fields (LTAU-FF) and demonstrate that it can be easily calibrated to accurately predict test errors on multiple datasets from the literature. We then illustrate the utility of LTAU-FF in two practical applications: 1) tuning the training-validation gap for an example dataset, and 2) predicting errors in relaxation trajectories on the OC20 IS2RS task. Though in this work we focus on the use of LTAU with deep learning atomistic force fields, we emphasize that it can be readily applied to any regression task, or any ensemble-generation technique, to provide a reliable and easy-to-implement UQ metric.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00854",
        "abstract url": "https://arxiv.org/abs/2402.00854",
        "title": "SymbolicAI: A framework for logic-based approaches combining generative models and solvers",
        "rating": "-0.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce SymbolicAI, a versatile and modular framework employing a logic-based approach to concept learning and flow management in generative processes. SymbolicAI enables the seamless integration of generative models with a diverse range of solvers by treating large language models (LLMs) as semantic parsers that execute tasks based on both natural and formal language instructions, thus bridging the gap between symbolic reasoning and generative AI. We leverage probabilistic programming principles to tackle complex tasks, and utilize differentiable and classical programming paradigms with their respective strengths. The framework introduces a set of polymorphic, compositional, and self-referential operations for data stream manipulation, aligning LLM outputs with user objectives. As a result, we can transition between the capabilities of various foundation models endowed with zero- and few-shot learning capabilities and specialized, fine-tuned models or solvers proficient in addressing specific problems. In turn, the framework facilitates the creation and evaluation of explainable computational graphs. We conclude by introducing a quality measure and its empirical score for evaluating these computational graphs, and propose a benchmark that compares various state-of-the-art LLMs across a set of complex workflows. We refer to the empirical score as the \"Vector Embedding for Relational Trajectory Evaluation through Cross-similarity\", or VERTEX score for short. The framework codebase and benchmark are linked below.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SC",
            "cs.SE"
        ],
        "comment": "39 pages, 12 figures, external resources: framework is available at https://github.com/ExtensityAI/symbolicai and benchmark at https://github.com/ExtensityAI/benchmark"
    },
    {
        "paper id": "2402.00955",
        "abstract url": "https://arxiv.org/abs/2402.00955",
        "title": "FairEHR-CLP: Towards Fairness-Aware Clinical Predictions with Contrastive Learning in Multimodal Electronic Health Records",
        "rating": "-0.5",
        "keywords": [
            [
                "social biases"
            ],
            [
                "medical",
                "Health",
                "healthcare",
                "Clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the high-stakes realm of healthcare, ensuring fairness in predictive models is crucial. Electronic Health Records (EHRs) have become integral to medical decision-making, yet existing methods for enhancing model fairness restrict themselves to unimodal data and fail to address the multifaceted social biases intertwined with demographic factors in EHRs. To mitigate these biases, we present FairEHR-CLP: a general framework for Fairness-aware Clinical Predictions with Contrastive Learning in EHRs. FairEHR-CLP operates through a two-stage process, utilizing patient demographics, longitudinal data, and clinical notes. First, synthetic counterparts are generated for each patient, allowing for diverse demographic identities while preserving essential health information. Second, fairness-aware predictions employ contrastive learning to align patient representations across sensitive attributes, jointly optimized with an MLP classifier with a softmax layer for clinical classification tasks. Acknowledging the unique challenges in EHRs, such as varying group sizes and class imbalance, we introduce a novel fairness metric to effectively measure error rate disparities across subgroups. Extensive experiments on three diverse EHR datasets on three tasks demonstrate the effectiveness of FairEHR-CLP in terms of fairness and utility compared with competitive baselines. FairEHR-CLP represents an advancement towards ensuring both accuracy and equity in predictive healthcare models.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": "16 pages, in submission"
    },
    {
        "paper id": "2402.00976",
        "abstract url": "https://arxiv.org/abs/2402.00976",
        "title": "Investigating Recurrent Transformers with Dynamic Halt",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we study the inductive biases of two major approaches to augmenting Transformers with a recurrent mechanism - (1) the approach of incorporating a depth-wise recurrence similar to Universal Transformers; and (2) the approach of incorporating a chunk-wise temporal recurrence like Temporal Latent Bottleneck. Furthermore, we propose and investigate novel ways to extend and combine the above methods - for example, we propose a global mean-based dynamic halting mechanism for Universal Transformer and an augmentation of Temporal Latent Bottleneck with elements from Universal Transformer. We compare the models and probe their inductive biases in several diagnostic tasks such as Long Range Arena (LRA), flip-flop language modeling, ListOps, and Logical Inference.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01045",
        "abstract url": "https://arxiv.org/abs/2402.01045",
        "title": "LatticeGraphNet: A two-scale graph neural operator for simulating lattice structures",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study introduces a two-scale Graph Neural Operator (GNO), namely, LatticeGraphNet (LGN), designed as a surrogate model for costly nonlinear finite-element simulations of three-dimensional latticed parts and structures. LGN has two networks: LGN-i, learning the reduced dynamics of lattices, and LGN-ii, learning the mapping from the reduced representation onto the tetrahedral mesh. LGN can predict deformation for arbitrary lattices, therefore the name operator. Our approach significantly reduces inference time while maintaining high accuracy for unseen simulations, establishing the use of GNOs as efficient surrogate models for evaluating mechanical responses of lattices and structures.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01057",
        "abstract url": "https://arxiv.org/abs/2402.01057",
        "title": "Expert Proximity as Surrogate Rewards for Single Demonstration Imitation Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we focus on single-demonstration imitation learning (IL), a practical approach for real-world applications where obtaining numerous expert demonstrations is costly or infeasible. In contrast to typical IL settings with multiple demonstrations, single-demonstration IL involves an agent having access to only one expert trajectory. We highlight the issue of sparse reward signals in this setting and propose to mitigate this issue through our proposed Transition Discriminator-based IL (TDIL) method. TDIL is an IRL method designed to address reward sparsity by introducing a denser surrogate reward function that considers environmental dynamics. This surrogate reward function encourages the agent to navigate towards states that are proximal to expert states. In practice, TDIL trains a transition discriminator to differentiate between valid and non-valid transitions in a given environment to compute the surrogate rewards. The experiments demonstrate that TDIL outperforms existing IL approaches and achieves expert-level performance in the single-demonstration IL setting across five widely adopted MuJoCo benchmarks as well as the \"Adroit Door\" environment.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01058",
        "abstract url": "https://arxiv.org/abs/2402.01058",
        "title": "Towards an Algebraic Framework For Approximating Functions Using Neural Network Polynomials",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We make the case for neural network objects and extend an already existing neural network calculus explained in detail in Chapter 2 on \\cite{bigbook}. Our aim will be to show that, yes, indeed, it makes sense to talk about neural network polynomials, neural network exponentials, sine, and cosines in the sense that they do indeed approximate their real number counterparts subject to limitations on certain of their parameters, $q$, and $\\varepsilon$. While doing this, we show that the parameter and depth growth are only polynomial on their desired accuracy (defined as a 1-norm difference over $\\mathbb{R}$), thereby showing that this approach to approximating, where a neural network in some sense has the structural properties of the function it is approximating is not entire intractable.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "math.CO",
            "math.NA"
        ],
        "comment": "56 pages"
    },
    {
        "paper id": "2402.01070",
        "abstract url": "https://arxiv.org/abs/2402.01070",
        "title": "FedShift: Tackling Dual Heterogeneity Problem of Federated Learning via Weight Shift Aggregation",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) offers a compelling method for training machine learning models with a focus on preserving data privacy. The presence of system heterogeneity and statistical heterogeneity, recognized challenges in FL, arises from the diversity of client hardware, network, and dataset distribution. This diversity can critically affect the training pace and the performance of models. While many studies address either system or statistical heterogeneity by introducing communication-efficient or stable convergence algorithms, addressing these challenges in isolation often leads to compromises due to unaddressed heterogeneity. In response, this paper introduces FedShift, a novel algorithm designed to enhance both the training speed and the models' accuracy in a dual heterogeneity scenario. Our solution can improve client engagement through quantization and mitigate the adverse effects on performance typically associated with quantization by employing a shifting technique. This technique has proven to enhance accuracy by an average of 3.9% in diverse heterogeneity environments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01096",
        "abstract url": "https://arxiv.org/abs/2402.01096",
        "title": "Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Emerging Distributed AI systems are revolutionizing big data computing and data processing capabilities with growing economic and societal impact. However, recent studies have identified new attack surfaces and risks caused by security, privacy, and fairness issues in AI systems. In this paper, we review representative techniques, algorithms, and theoretical foundations for trustworthy distributed AI through robustness guarantee, privacy protection, and fairness awareness in distributed learning. We first provide a brief overview of alternative architectures for distributed learning, discuss inherent vulnerabilities for security, privacy, and fairness of AI algorithms in distributed learning, and analyze why these problems are present in distributed learning regardless of specific architectures. Then we provide a unique taxonomy of countermeasures for trustworthy distributed AI, covering (1) robustness to evasion attacks and irregular queries at inference, and robustness to poisoning attacks, Byzantine attacks, and irregular data distribution during training; (2) privacy protection during distributed learning and model inference at deployment; and (3) AI fairness and governance with respect to both data and models. We conclude with a discussion on open challenges and future research directions toward trustworthy distributed AI, such as the need for trustworthy AI policy guidelines, the AI responsibility-utility co-design, and incentives and compliance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.DC"
        ],
        "comment": "Manuscript accepted to ACM Computing Surveys"
    },
    {
        "paper id": "2402.01114",
        "abstract url": "https://arxiv.org/abs/2402.01114",
        "title": "Double-Dip: Thwarting Label-Only Membership Inference Attacks with Transfer Learning and Randomization",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Transfer learning (TL) has been demonstrated to improve DNN model performance when faced with a scarcity of training samples. However, the suitability of TL as a solution to reduce vulnerability of overfitted DNNs to privacy attacks is unexplored. A class of privacy attacks called membership inference attacks (MIAs) aim to determine whether a given sample belongs to the training dataset (member) or not (nonmember). We introduce Double-Dip, a systematic empirical study investigating the use of TL (Stage-1) combined with randomization (Stage-2) to thwart MIAs on overfitted DNNs without degrading classification accuracy. Our study examines the roles of shared feature space and parameter values between source and target models, number of frozen layers, and complexity of pretrained models. We evaluate Double-Dip on three (Target, Source) dataset paris: (i) (CIFAR-10, ImageNet), (ii) (GTSRB, ImageNet), (iii) (CelebA, VGGFace2). We consider four publicly available pretrained DNNs: (a) VGG-19, (b) ResNet-18, (c) Swin-T, and (d) FaceNet. Our experiments demonstrate that Stage-1 reduces adversary success while also significantly increasing classification accuracy of nonmembers against an adversary with either white-box or black-box DNN model access, attempting to carry out SOTA label-only MIAs. After Stage-2, success of an adversary carrying out a label-only MIA is further reduced to near 50%, bringing it closer to a random guess and showing the effectiveness of Double-Dip. Stage-2 of Double-Dip also achieves lower ASR and higher classification accuracy than regularization and differential privacy-based methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01116",
        "abstract url": "https://arxiv.org/abs/2402.01116",
        "title": "Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a hierarchical architecture designed for scalable real-time Model Predictive Control (MPC) in complex, multi-modal traffic scenarios. This architecture comprises two key components: 1) RAID-Net, a novel attention-based Recurrent Neural Network that predicts relevant interactions along the MPC prediction horizon between the autonomous vehicle and the surrounding vehicles using Lagrangian duality, and 2) a reduced Stochastic MPC problem that eliminates irrelevant collision avoidance constraints, enhancing computational efficiency. Our approach is demonstrated in a simulated traffic intersection with interactive surrounding vehicles, showcasing a 12x speed-up in solving the motion planning problem. A video demonstrating the proposed architecture in multiple complex traffic scenarios can be found here: https://youtu.be/-pRiOnPb9_c. GitHub: https://github.com/MPC-Berkeley/hmpc_raidnet",
        "subjects": [
            "cs.RO",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Accepted at IEEE Intelligent Vehicles Symposium 2024"
    },
    {
        "paper id": "2402.01143",
        "abstract url": "https://arxiv.org/abs/2402.01143",
        "title": "Learning Network Representations with Disentangled Graph Auto-Encoder",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The (variational) graph auto-encoder is extensively employed for learning representations of graph-structured data. However, the formation of real-world graphs is a complex and heterogeneous process influenced by latent factors. Existing encoders are fundamentally holistic, neglecting the entanglement of latent factors. This not only makes graph analysis tasks less effective but also makes it harder to understand and explain the representations. Learning disentangled graph representations with (variational) graph auto-encoder poses significant challenges, and remains largely unexplored in the existing literature. In this article, we introduce the Disentangled Graph Auto-Encoder (DGA) and Disentangled Variational Graph Auto-Encoder (DVGA), approaches that leverage generative models to learn disentangled representations. Specifically, we first design a disentangled graph convolutional network with multi-channel message-passing layers, as the encoder aggregating information related to each disentangled latent factor. Subsequently, a component-wise flow is applied to each channel to enhance the expressive capabilities of disentangled variational graph auto-encoder. Additionally, we design a factor-wise decoder, considering the characteristics of disentangled representations. In order to further enhance the independence among representations, we introduce independence constraints on mapping channels for different latent factors. Empirical experiments on both synthetic and real-world datasets show the superiority of our proposed method compared to several state-of-the-art baselines.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "61 pages, 13 figures"
    },
    {
        "paper id": "2402.01783",
        "abstract url": "https://arxiv.org/abs/2402.01783",
        "title": "Hierarchical Multi-Label Classification of Online Vaccine Concerns",
        "rating": "-0.5",
        "keywords": [
            [
                "health",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Vaccine concerns are an ever-evolving target, and can shift quickly as seen during the COVID-19 pandemic. Identifying longitudinal trends in vaccine concerns and misinformation might inform the healthcare space by helping public health efforts strategically allocate resources or information campaigns. We explore the task of detecting vaccine concerns in online discourse using large language models (LLMs) in a zero-shot setting without the need for expensive training datasets. Since real-time monitoring of online sources requires large-scale inference, we explore cost-accuracy trade-offs of different prompting strategies and offer concrete takeaways that may inform choices in system designs for current applications. An analysis of different prompting strategies reveals that classifying the concerns over multiple passes through the LLM, each consisting a boolean question whether the text mentions a vaccine concern or not, works the best. Our results indicate that GPT-4 can strongly outperform crowdworker accuracy when compared to ground truth annotations provided by experts on the recently introduced VaxConcerns dataset, achieving an overall F1 score of 78.7%.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Published in AAAI 2024 Health Intelligence workshop"
    },
    {
        "paper id": "2402.01787",
        "abstract url": "https://arxiv.org/abs/2402.01787",
        "title": "Harm Amplification in Text-to-Image Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Text-to-image (T2I) models have emerged as a significant advancement in generative AI; however, there exist safety concerns regarding their potential to produce harmful image outputs even when users input seemingly safe prompts. This phenomenon, where T2I models generate harmful representations that were not explicit in the input, poses a potentially greater risk than adversarial prompts, leaving users unintentionally exposed to harms. Our paper addresses this issue by first introducing a formal definition for this phenomenon, termed harm amplification. We further contribute to the field by developing methodologies to quantify harm amplification in which we consider the harm of the model output in the context of user input. We then empirically examine how to apply these different methodologies to simulate real-world deployment scenarios including a quantification of disparate impacts across genders resulting from harm amplification. Together, our work aims to offer researchers tools to comprehensively address safety challenges in T2I systems and contribute to the responsible deployment of generative AI models.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06646",
        "abstract url": "https://arxiv.org/abs/2402.06646",
        "title": "Diffusion Model-based Probabilistic Downscaling for 180-year East Asian Climate Reconstruction",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As our planet is entering into the \"global boiling\" era, understanding regional climate change becomes imperative. Effective downscaling methods that provide localized insights are crucial for this target. Traditional approaches, including computationally-demanding regional dynamical models or statistical downscaling frameworks, are often susceptible to the influence of downscaling uncertainty. Here, we address these limitations by introducing a diffusion probabilistic downscaling model (DPDM) into the meteorological field. This model can efficiently transform data from 1\u00b0 to 0.1\u00b0 resolution. Compared with deterministic downscaling schemes, it not only has more accurate local details, but also can generate a large number of ensemble members based on probability distribution sampling to evaluate the uncertainty of downscaling. Additionally, we apply the model to generate a 180-year dataset of monthly surface variables in East Asia, offering a more detailed perspective for understanding local scale climate change over the past centuries.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG",
            "physics.geo-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10092",
        "abstract url": "https://arxiv.org/abs/2402.10092",
        "title": "Workflow Optimization for Parallel Split Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Split learning (SL) has been recently proposed as a way to enable resource-constrained devices to train multi-parameter neural networks (NNs) and participate in federated learning (FL). In a nutshell, SL splits the NN model into parts, and allows clients (devices) to offload the largest part as a processing task to a computationally powerful helper. In parallel SL, multiple helpers can process model parts of one or more clients, thus, considerably reducing the maximum training time over all clients (makespan). In this paper, we focus on orchestrating the workflow of this operation, which is critical in highly heterogeneous systems, as our experiments show. In particular, we formulate the joint problem of client-helper assignments and scheduling decisions with the goal of minimizing the training makespan, and we prove that it is NP-hard. We propose a solution method based on the decomposition of the problem by leveraging its inherent symmetry, and a second one that is fully scalable. A wealth of numerical evaluations using our testbed's measurements allow us to build a solution strategy comprising these methods. Moreover, we show that this strategy finds a near-optimal solution, and achieves a shorter makespan than the baseline scheme by up to 52.3%.",
        "subjects": [
            "cs.DC",
            "cs.LG",
            "cs.NI"
        ],
        "comment": "IEEE INFOCOM 2024"
    },
    {
        "paper id": "2403.07886",
        "abstract url": "https://arxiv.org/abs/2403.07886",
        "title": "A Memetic Algorithm To Find a Hamiltonian Cycle in a Hamiltonian Graph",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present a memetic algorithm (\\maa) approach for finding a Hamiltonian cycle in a Hamiltonian graph. The \\ma is based on a proven approach to the Asymmetric Travelling Salesman Problem (\\atspp) that, in this contribution, is boosted by the introduction of more powerful local searches. Our approach also introduces a novel technique that sparsifies the input graph under consideration for Hamiltonicity and dynamically augments it during the search. Such a combined heuristic approach helps to prove Hamiltonicity by finding a Hamiltonian cycle in less time. In addition, we also employ a recently introduced polynomial-time reduction from the \\hamcyc to the Symmetric \\tsp, which is based on computing the transitive closure of the graph. Although our approach is a metaheuristic, i.e., it does not give a theoretical guarantee for finding a Hamiltonian cycle, we have observed that the method is successful in practice in verifying the Hamiltonicity of a larger number of instances from the \\textit{Flinder University Hamiltonian Cycle Problem Challenge Set} (\\fhcpsc), even for the graphs that have large treewidth. The experiments on the \\fhcpscc instances and a computational comparison with five recent state-of-the-art baseline approaches show that the proposed method outperforms those for the majority of the instances in the \\fhcpsc.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00344",
        "abstract url": "https://arxiv.org/abs/2402.00344",
        "title": "Reimagining TaxiVis through an Immersive Space-Time Cube metaphor and reflecting on potential benefits of Immersive Analytics for urban data exploration",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Current visualization research has identified the potential of more immersive settings for data exploration, leveraging VR and AR technologies. To explore how a traditional visualization system could be adapted into an immersive framework, and how it could benefit from this, we decided to revisit a landmark paper presented ten years ago at IEEE VIS. TaxiVis, by Ferreira et al., enabled interactive spatio-temporal querying of a large dataset of taxi trips in New York City. Here, we reimagine how TaxiVis' functionalities could be implemented and extended in a 3D immersive environment. Among the unique features we identify as being enabled by the Immersive TaxiVis prototype are alternative uses of the additional visual dimension, a fully visual 3D spatio-temporal query framework, and the opportunity to explore the data at different scales and frames of reference. By revisiting the case studies from the original paper, we demonstrate workflows that can benefit from this immersive perspective. Through reporting on our experience, and on the vision and reasoning behind our design decisions, we hope to contribute to the debate on how conventional and immersive visualization paradigms can complement each other and on how the exploration of urban datasets can be facilitated in the coming years.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted for publication in the proceedings of the IEEE VR 2024 conference"
    },
    {
        "paper id": "2402.00353",
        "abstract url": "https://arxiv.org/abs/2402.00353",
        "title": "High-Quality Medical Image Generation from Free-hand Sketch",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating medical images from human-drawn free-hand sketches holds promise for various important medical imaging applications. Due to the extreme difficulty in collecting free-hand sketch data in the medical domain, most deep learning-based methods have been proposed to generate medical images from the synthesized sketches (e.g., edge maps or contours of segmentation masks from real images). However, these models often fail to generalize on the free-hand sketches, leading to unsatisfactory results. In this paper, we propose a practical free-hand sketch-to-image generation model called Sketch2MedI that learns to represent sketches in StyleGAN's latent space and generate medical images from it. Thanks to the ability to encode sketches into this meaningful representation space, Sketch2MedI only requires synthesized sketches for training, enabling a cost-effective learning process. Our Sketch2MedI demonstrates a robust generalization to free-hand sketches, resulting in high-quality and realistic medical image generations. Comparative evaluations of Sketch2MedI against the pix2pix, CycleGAN, UNIT, and U-GAT-IT models show superior performance in generating pharyngeal images, both quantitative and qualitative across various metrics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00384",
        "abstract url": "https://arxiv.org/abs/2402.00384",
        "title": "Adaptive FRIT-based Recursive Robust Controller Design Using Forgetting Factors",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Adaptive FRIT (A-FRIT) with exponential forgetting (EF) has been proposed for time-varying systems to improve the data dependence of FRIT, which is a direct data-driven tuning method. However, the EF-based method is not a reliable controller because it can cause significant degradation of the control performance and instability unless the persistent excitation (PE) condition is satisfied. To solve this problem, we propose a new A-FRIT method based on directional forgetting (DF) and exponential resetting that can forget old data without instability regardless of the PE condition. To confirm the effectiveness of the proposed method, we applied it to artificial muscle control with strong asymmetric hysteresis characteristics and evaluated its robust performance against load changes during the experiment. The experimental results show that the proposed method based on DF achieves high control performance and is robust against changes in the characteristics and/or target trajectory. The proposed method is also practical because it does not require system identification, model structure, or prior experimentation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been accepted to The 32nd Mediterranean Conference on Control and Automation (MED2024)"
    },
    {
        "paper id": "2402.00398",
        "abstract url": "https://arxiv.org/abs/2402.00398",
        "title": "Reconfigurable Intelligent Computational Surfaces for MEC-Assisted Autonomous Driving Networks",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ]
        ],
        "abstract": "In this paper, we focus on improving autonomous driving safety via task offloading from cellular vehicles (CVs), using vehicle-to-infrastructure (V2I) links, to an multi-access edge computing (MEC) server. Considering that the frequencies used for V2I links can be reused for vehicle-to-vehicle (V2V) communications to improve spectrum utilization, the receiver of each V2I link may suffer from severe interference, causing outages in the task offloading process. To tackle this issue, we propose the deployment of a reconfigurable intelligent computational surface (RICS) to enable, not only V2I reflective links, but also interference cancellation at the V2V links exploiting the computational capability of its metamaterials. We devise a joint optimization formulation for the task offloading ratio between the CVs and the MEC server, the spectrum sharing strategy between V2V and V2I communications, as well as the RICS reflection and refraction matrices, with the objective to maximize a safety-based autonomous driving task. Due to the non-convexity of the problem and the coupling among its free variables, we transform it into a more tractable equivalent form, which is then decomposed into three sub-problems and solved via an alternate approximation method. Our simulation results demonstrate the effectiveness of the proposed RICS optimization in improving the safety in autonomous driving networks.",
        "subjects": [
            "cs.DC",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00399",
        "abstract url": "https://arxiv.org/abs/2402.00399",
        "title": "Continuous-time Trajectory Estimation: A Comparative Study Between Gaussian Process and Spline-based Approaches",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "Continuous-time trajectory estimation is an attractive alternative to discrete-time batch estimation due to the ability to incorporate high-frequency measurements from asynchronous sensors while keeping the number of optimization parameters bounded. Two types of continuous-time estimation have become prevalent in the literature: Gaussian process regression and spline-based estimation. In this paper, we present a direct comparison between these two methods. We first compare them using a simple linear system, and then compare them in a camera and IMU sensor fusion scenario on SE(3) in both simulation and hardware. Our results show that if the same measurements and motion model are used, the two methods achieve similar trajectory accuracy. In addition, if the spline order is chosen so that the degree-of-differentiability of the two trajectory representations match, then they achieve similar solve times as well.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00411",
        "abstract url": "https://arxiv.org/abs/2402.00411",
        "title": "LM-HT SNN: Enhancing the Performance of SNN to ANN Counterpart through Learnable Multi-hierarchical Threshold Model",
        "rating": "-1",
        "keywords": [
            [
                "biological-inspired"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Compared to traditional Artificial Neural Network (ANN), Spiking Neural Network (SNN) has garnered widespread academic interest for its intrinsic ability to transmit information in a more biological-inspired and energy-efficient manner. However, despite previous efforts to optimize the learning gradients and model structure of SNNs through various methods, SNNs still lag behind ANNs in terms of performance to some extent. The recently proposed multi-threshold model provides more possibilities for further enhancing the learning capability of SNNs. In this paper, we rigorously analyze the relationship among the multi-threshold model, vanilla spiking model and quantized ANNs from a mathematical perspective, then propose a novel LM-HT model, which is an equidistant multi-hierarchical model that can dynamically regulate the global input current and membrane potential leakage on the time dimension. In addition, we note that the direct training algorithm based on the LM-HT model can seamlessly integrate with the traditional ANN-SNN Conversion framework. This novel hybrid learning framework can effectively improve the relatively poor performance of converted SNNs under low time latency. Extensive experimental results have demonstrated that our LM-HT model can significantly outperform previous state-of-the-art works on various types of datasets, which promote SNNs to achieve a brand-new level of performance comparable to quantized ANNs.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "15 pages, 2 figures"
    },
    {
        "paper id": "2402.00421",
        "abstract url": "https://arxiv.org/abs/2402.00421",
        "title": "From PARIS to LE-PARIS: Toward Patent Response Automation with Recommender Systems and Collaborative Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "Patent"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In patent prosecution, timely and effective responses to Office Actions (OAs) are crucial for securing patents. However, past automation and artificial intelligence research have largely overlooked this aspect. To bridge this gap, our study introduces the Patent Office Action Response Intelligence System (PARIS) and its advanced version, the Large Language Model (LLM) Enhanced PARIS (LE-PARIS). These systems are designed to enhance the efficiency of patent attorneys in handling OA responses through collaboration with AI. The systems' key features include the construction of an OA Topics Database, development of Response Templates, and implementation of Recommender Systems and LLM-based Response Generation. To validate the effectiveness of the systems, we have employed a multi-paradigm analysis using the USPTO Office Action database and longitudinal data based on attorney interactions with our systems over six years. Through five studies, we have examined the constructiveness of OA topics (studies 1 and 2) using topic modeling and our proposed Delphi process, the efficacy of our proposed hybrid LLM-based recommender system tailored for OA responses (study 3), the quality of generated responses (study 4), and the systems' practical value in real-world scenarios through user studies (study 5). The results indicate that both PARIS and LE-PARIS significantly achieve key metrics and have a positive impact on attorney performance.",
        "subjects": [
            "cs.CL",
            "cs.HC",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "28 pages, 5 figures, typos corrected, references added, under review"
    },
    {
        "paper id": "2402.00425",
        "abstract url": "https://arxiv.org/abs/2402.00425",
        "title": "Genetic Programming Theory and Practice: A Fifteen-Year Trajectory",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "The GPTP workshop series, which began in 2003, has served over the years as a focal meeting for genetic programming (GP) researchers. As such, we think it provides an excellent source for studying the development of GP over the past fifteen years. We thus present herein a trajectory of the thematic developments in the field of GP.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00452",
        "abstract url": "https://arxiv.org/abs/2402.00452",
        "title": "A Hoare Logic for Domain Specification (Full Version)",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Programs must be correct with respect to their application domain. Yet, the program specification and verification approaches so far only consider correctness in terms of computations. In this work, we present a two-tier Hoare Logic that integrates assertions for both implementation and domain. For domain specification, we use description logics and semantic lifting, a recently proposed approach to interpret a program as a knowledge graph. We present a calculus that uses translations between both kinds of assertions, thus separating the concerns in specification, but enabling the use of description logic in verification.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00455",
        "abstract url": "https://arxiv.org/abs/2402.00455",
        "title": "New Lower Bounds on Aperiodic Ambiguity Function of Unimodular Sequences",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "This paper presents new aperiodic ambiguity function (AF) lower bounds of unimodular sequences under certain low ambiguity zone. Our key idea, motivated by the Levenshtein correlation bound, is to introduce two weight vectors associated to the delay and Doppler shifts, respectively, and then exploit the upper and lower bounds on the Frobenius norm of the weighted auto- and cross-AF matrices to derive these bounds. Furthermore, the inherent structure properties of aperiodic AF are also utilized in our derivation. The derived bounds are useful design guidelines for optimal AF shaping in modern communication and radar systems.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2402.00474",
        "abstract url": "https://arxiv.org/abs/2402.00474",
        "title": "SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection Framework for Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in large language models (LLMs) have demonstrated exceptional performance in various natural language processing (NLP) tasks. However, their effective application in the medical domain is hampered by a lack of medical domain knowledge. In this study, we present SA-MDKIF, a scalable and adaptable framework that aims to inject medical knowledge into general-purpose LLMs through instruction tuning, thereby enabling adaptability for various downstream tasks. SA-MDKIF consists of two stages: skill training and skill adaptation. In the first stage, we define 12 basic medical skills and use AdaLoRA to train these skills based on uniformly formatted instructional datasets that we have constructed. In the next stage, we train the skill router using task-specific downstream data and use this router to integrate the acquired skills with LLMs during inference. Experimental results on 9 different medical tasks show that SA-MDKIF improves performance by 10-20% compared to the original LLMs. Notably, this improvement is particularly pronounced for unseen medical tasks, showing an improvement of up to 30%.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00525",
        "abstract url": "https://arxiv.org/abs/2402.00525",
        "title": "StopThePop: Sorted Gaussian Splatting for View-Consistent Real-time Rendering",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth"
            ],
            [
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Gaussian Splatting has emerged as a prominent model for constructing 3D representations from images across diverse domains. However, the efficiency of the 3D Gaussian Splatting rendering pipeline relies on several simplifications. Notably, reducing Gaussian to 2D splats with a single view-space depth introduces popping and blending artifacts during view rotation. Addressing this issue requires accurate per-pixel depth computation, yet a full per-pixel sort proves excessively costly compared to a global sort operation. In this paper, we present a novel hierarchical rasterization approach that systematically resorts and culls splats with minimal processing overhead. Our software rasterizer effectively eliminates popping artifacts and view inconsistencies, as demonstrated through both quantitative and qualitative measurements. Simultaneously, our method mitigates the potential for cheating view-dependent effects with popping, ensuring a more authentic representation. Despite the elimination of cheating, our approach achieves comparable quantitative results for test images, while increasing the consistency for novel view synthesis in motion. Due to its design, our hierarchical approach is only 4% slower on average than the original Gaussian Splatting. Notably, enforcing consistency enables a reduction in the number of Gaussians by approximately half with nearly identical quality and view-consistency. Consequently, rendering performance is nearly doubled, making our approach 1.6x faster than the original Gaussian Splatting, with a 50% reduction in memory requirements.",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "comment": "Video: https://youtu.be/RJQlSORNkr0"
    },
    {
        "paper id": "2402.00537",
        "abstract url": "https://arxiv.org/abs/2402.00537",
        "title": "Robust Path Planning via Learning from Demonstrations for Robotic Catheters in Deformable Environments",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "Navigation through tortuous and deformable vessels using catheters with limited steering capability underscores the need for reliable path planning. State-of-the-art path planners do not fully account for the deformable nature of the environment. This work proposes a robust path planner via a learning from demonstrations method, named Curriculum Generative Adversarial Imitation Learning (C-GAIL). This path planning framework takes into account the interaction between steerable catheters and vessel walls and the deformable property of vessels. In-silico comparative experiments show that the proposed network achieves smaller targeting errors, and a higher success rate, compared to a state-of-the-art approach based on GAIL. The in-vitro validation experiments demonstrate that the path generated by the proposed C-GAIL path planner aligns better with the actual steering capability of the pneumatic artificial muscle-driven catheter utilized in this study. Therefore, the proposed approach can provide enhanced support to the user in navigating the catheter towards the target with greater precision, in contrast to the conventional centerline-following technique. The targeting and tracking errors are 1.26$\\pm$0.55mm and 5.18$\\pm$3.48mm, respectively. The proposed path planning framework exhibits superior performance in managing uncertainty associated with vessel deformation, thereby resulting in lower tracking errors.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Under review in IEEE Transactions on Biomedical Engineering (TBME)"
    },
    {
        "paper id": "2402.00565",
        "abstract url": "https://arxiv.org/abs/2402.00565",
        "title": "A Review of Carsickness Mitigation: Navigating Challenges and Exploiting Opportunities in the Era of Intelligent Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Motion sickness (MS) has long been a common complaint in road transportation. However, in the era of driving automation, MS has become an increasingly significant issue. The future intelligent vehicle is envisioned as a mobile space for work or entertainment, but unfortunately passengers' engagement in non-driving tasks may exacerbate MS. Finding effective MS countermeasures is crucial to ensure a pleasant passenger experience. Nevertheless, due to the complex mechanism of MS, there are numerous challenges in mitigating it, hindering the development of practical countermeasures. To address this, we first review two prevalent theories explaining the mechanism of MS. Subsequently, this paper provides a summary of current subjective and objective approaches for quantifying motion sickness levels. Then, it surveys existing methods for alleviating MS, including passenger adjustment, intelligent vehicle solutions, and motion cues of various modalities. Furthermore, we outline the limitations and remaining challenges of current research and highlight novel opportunities in the context of intelligent vehicles. Finally, we propose an integrated framework for alleviating MS. The findings of this review will enhance our understanding of carsickness and offer valuable insights for future research and practice in MS mitigation within modern vehicles.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "19 pages, 5 figures, 5 tables"
    },
    {
        "paper id": "2402.00570",
        "abstract url": "https://arxiv.org/abs/2402.00570",
        "title": "CADICA: a new dataset for coronary artery disease detection by using invasive coronary angiography",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "disease",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Coronary artery disease (CAD) remains the leading cause of death globally and invasive coronary angiography (ICA) is considered the gold standard of anatomical imaging evaluation when CAD is suspected. However, risk evaluation based on ICA has several limitations, such as visual assessment of stenosis severity, which has significant interobserver variability. This motivates to development of a lesion classification system that can support specialists in their clinical procedures. Although deep learning classification methods are well-developed in other areas of medical imaging, ICA image classification is still at an early stage. One of the most important reasons is the lack of available and high-quality open-access datasets. In this paper, we reported a new annotated ICA images dataset, CADICA, to provide the research community with a comprehensive and rigorous dataset of coronary angiography consisting of a set of acquired patient videos and associated disease-related metadata. This dataset can be used by clinicians to train their skills in angiographic assessment of CAD severity and by computer scientists to create computer-aided diagnostic systems to help in such assessment. In addition, baseline classification methods are proposed and analyzed, validating the functionality of CADICA and giving the scientific community a starting point to improve CAD detection.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00575",
        "abstract url": "https://arxiv.org/abs/2402.00575",
        "title": "Diffusion-based Light Field Synthesis",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Diffusion",
                "Synthesis",
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Light fields (LFs), conducive to comprehensive scene radiance recorded across angular dimensions, find wide applications in 3D reconstruction, virtual reality, and computational photography.However, the LF acquisition is inevitably time-consuming and resource-intensive due to the mainstream acquisition strategy involving manual capture or laborious software synthesis.Given such a challenge, we introduce LFdiff, a straightforward yet effective diffusion-based generative framework tailored for LF synthesis, which adopts only a single RGB image as input.LFdiff leverages disparity estimated by a monocular depth estimation network and incorporates two distinctive components: a novel condition scheme and a noise estimation network tailored for LF data.Specifically, we design a position-aware warping condition scheme, enhancing inter-view geometry learning via a robust conditional signal.We then propose DistgUnet, a disentanglement-based noise estimation network, to harness comprehensive LF representations.Extensive experiments demonstrate that LFdiff excels in synthesizing visually pleasing and disparity-controllable light fields with enhanced generalization capability.Additionally, comprehensive results affirm the broad applicability of the generated LF data, spanning applications like LF super-resolution and refocusing.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages,9 figures"
    },
    {
        "paper id": "2402.00585",
        "abstract url": "https://arxiv.org/abs/2402.00585",
        "title": "SATac: A Thermoluminescence Enabled Tactile Sensor for Concurrent Perception of Temperature, Pressure, and Shear",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Most vision-based tactile sensors use elastomer deformation to infer tactile information, which can not sense some modalities, like temperature. As an important part of human tactile perception, temperature sensing can help robots better interact with the environment. In this work, we propose a novel multimodal vision-based tactile sensor, SATac, which can simultaneously perceive information of temperature, pressure, and shear. SATac utilizes thermoluminescence of strontium aluminate (SA) to sense a wide range of temperatures with exceptional resolution. Additionally, the pressure and shear can also be perceived by analyzing Voronoi diagram. A series of experiments are conducted to verify the performance of our proposed sensor. We also discuss the possible application scenarios and demonstrate how SATac could benefit robot perception capabilities.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00593",
        "abstract url": "https://arxiv.org/abs/2402.00593",
        "title": "Coronary Artery Disease Classification with Different Lesion Degree Ranges based on Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "Disease",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Invasive Coronary Angiography (ICA) images are considered the gold standard for assessing the state of the coronary arteries. Deep learning classification methods are widely used and well-developed in different areas where medical imaging evaluation has an essential impact due to the development of computer-aided diagnosis systems that can support physicians in their clinical procedures. In this paper, a new performance analysis of deep learning methods for binary ICA classification with different lesion degrees is reported. To reach this goal, an annotated dataset of ICA images that contains the ground truth, the location of lesions and seven possible severity degrees ranging between 0% and 100% was employed. The ICA images were divided into 'lesion' or 'non-lesion' patches. We aim to study how binary classification performance is affected by the different lesion degrees considered in the positive class. Therefore, five known convolutional neural network architectures were trained with different input images where different lesion degree ranges were gradually incorporated until considering the seven lesion degrees. Besides, four types of experiments with and without data augmentation were designed, whose F-measure and Area Under Curve (AUC) were computed. Reported results achieved an F-measure and AUC of 92.7% and 98.1%, respectively. However, lesion classification is highly affected by the degree of the lesion intended to classify, with 15% less accuracy when <99% lesion patches are present.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00629",
        "abstract url": "https://arxiv.org/abs/2402.00629",
        "title": "Cocco: Hardware-Mapping Co-Exploration towards Memory Capacity-Communication Optimization",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Memory is a critical design consideration in current data-intensive DNN accelerators, as it profoundly determines energy consumption, bandwidth requirements, and area costs. As DNN structures become more complex, a larger on-chip memory capacity is required to reduce data movement overhead, but at the expense of silicon costs. Some previous works have proposed memory-oriented optimizations, such as different data reuse and layer fusion schemes. However, these methods are not general and potent enough to cope with various graph structures. In this paper, we explore the intrinsic connection between network structures and memory features to optimize both hardware and mapping. First, we introduce a graph-level execution scheme with a corresponding dataflow and memory management method. This scheme enables the execution of arbitrary graph patterns with high data reuse and low hardware overhead. Subsequently, we propose Cocco, a hardware-mapping co-exploration framework leveraging graph-level features of networks. It aims to minimize communication overhead, such as energy consumption and bandwidth requirements, with a smaller memory capacity. We formulate the graph-partition scheduling and memory configuration search as an optimization problem and employ a genetic-based method to achieve efficient co-exploration for large and irregular networks. Experiments demonstrate that Cocco obtains lower external memory access, lower bandwidth requirements, and more stable optimization for graph partition compared to the greedy algorithm and dynamic programming introduced in prior works. Cocco also reduces the costs by 1.89% to 50.33% using co-exploration compared to other typical methods.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Accepted by 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS'24)"
    },
    {
        "paper id": "2402.00641",
        "abstract url": "https://arxiv.org/abs/2402.00641",
        "title": "Testing side-channel security of cryptographic implementations against future microarchitectures",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "How will future microarchitectures impact the security of existing cryptographic implementations? As we cannot keep reducing the size of transistors, chip vendors have started developing new microarchitectural optimizations to speed up computation. A recent study (Sanchez Vicarte et al., ISCA 2021) suggests that these optimizations might open the Pandora's box of microarchitectural attacks. However, there is little guidance on how to evaluate the security impact of future optimization proposals. To help chip vendors explore the impact of microarchitectural optimizations on cryptographic implementations, we develop (i) an expressive domain-specific language, called LmSpec, that allows them to specify the leakage model for the given optimization and (ii) a testing framework, called LmTest, to automatically detect leaks under the specified leakage model within the given implementation. Using this framework, we conduct an empirical study of 18 proposed microarchitectural optimizations on 25 implementations of eight cryptographic primitives in five popular libraries. We find that every implementation would contain secret-dependent leaks, sometimes sufficient to recover a victim's secret key, if these optimizations were realized. Ironically, some leaks are possible only because of coding idioms used to prevent leaks under the standard constant-time model.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00652",
        "abstract url": "https://arxiv.org/abs/2402.00652",
        "title": "Polycube Layouts via Iterative Dual Loops",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Polycube layouts for 3D models effectively support a wide variety of methods such as hex-mesh construction, seamless texture mapping, spline fitting, and multi-block grid generation. Our study of polycube layouts is motivated by conformal mesh generation for aerospace modelling. In this setting, quality and correctness guarantees are of the utmost importance. However, currently the fully automatic construction of valid polycube layouts still poses significant challenges: state-of-the-art methods are generally not guaranteed to return a proper solution, even after post-processing, or they use a prohibitively large number of voxels that add detail indiscriminately. In this paper we present a robust, flexible, and efficient method to generate polycube layouts. Our approach is based on a dual representation for polycube layouts and builds a layout by iteratively adding dual loops. Our construction is robust by design: at any iterative step we maintain a valid polycube layout. We offer the flexibility of manual intervention if the user so desires: while our method is able to compute a complete polycube layout without user intervention, the user can interrupt after each iteration and target further refinement on both the local and the global level. Last but not least, our method is efficient and can be implemented using comparatively simple algorithmic building blocks. Our implementation is publicly available and we present its output for numerous benchmark models.",
        "subjects": [
            "cs.GR",
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00663",
        "abstract url": "https://arxiv.org/abs/2402.00663",
        "title": "Transferring human emotions to robot motions using Neural Policy Style Transfer",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Neural Style Transfer (NST) was originally proposed to use feature extraction capabilities of Neural Networks as a way to perform Style Transfer with images. Pre-trained image classification architectures were selected for feature extraction, leading to new images showing the same content as the original but with a different style. In robotics, Style Transfer can be employed to transfer human motion styles to robot motions. The challenge lies in the lack of pre-trained classification architectures for robot motions that could be used for feature extraction. Neural Policy Style Transfer TD3 (NPST3) is proposed for the transfer of human motion styles to robot motions. This framework allows the same robot motion to be executed in different human-centered motion styles, such as in an angry, happy, calm, or sad fashion. The Twin Delayed Deep Deterministic Policy Gradient (TD3) network is introduced for the generation of control policies. An autoencoder network is in charge of feature extraction for the Style Transfer step. The Style Transfer step can be performed both offline and online: offline for the autonomous executions of human-style robot motions, and online for adapting at runtime the style of e.g., a teleoperated robot. The framework is tested using two different robotic platforms: a robotic manipulator designed for telemanipulation tasks, and a humanoid robot designed for social interaction. The proposed approach was evaluated for both platforms, performing a total of 147 questionnaires asking human subjects to recognize the human motion style transferred to the robot motion for a predefined set of actions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00681",
        "abstract url": "https://arxiv.org/abs/2402.00681",
        "title": "Sampling-based Stochastic Data-driven Predictive Control under Data Uncertainty",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "We present a stochastic output-feedback data-driven predictive control scheme for linear time-invariant systems subject to bounded additive disturbances and probabilistic chance constraints. The approach uses data-driven predictors based on an extension of Willems' fundamental lemma from behavioral systems theory and a single persistently exciting input-output data trajectory. Compared to current state-of-the-art approaches that rely on availability of exact disturbance data, we deterministically approximate the chance constraints in a sampling-based fashion by leveraging a novel parameterization of the unknown disturbance data trajectory, considering consistency with the measured data and the system class. A robust constraint on the first predicted step guarantees recursive feasibility of the proposed controller as well as constraint satisfaction in closed-loop. We show robust asymptotic stability in expectation under further standard assumptions. A numerical example demonstrates the efficiency of the proposed control scheme.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00695",
        "abstract url": "https://arxiv.org/abs/2402.00695",
        "title": "Approximating Optimal Morphing Attacks using Template Inversion",
        "rating": "-1",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "Attacks"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recent works have demonstrated the feasibility of inverting face recognition systems, enabling to recover convincing face images using only their embeddings. We leverage such template inversion models to develop a novel type ofdeep morphing attack based on inverting a theoretical optimal morph embedding, which is obtained as an average of the face embeddings of source images. We experiment with two variants of this approach: the first one exploits a fully self-contained embedding-to-image inversion model, while the second leverages the synthesis network of a pretrained StyleGAN network for increased morph realism. We generate morphing attacks from several source datasets and study the effectiveness of those attacks against several face recognition networks. We showcase that our method can compete with and regularly beat the previous state of the art for deep-learning based morph generation in terms of effectiveness, both in white-box and black-box attack scenarios, and is additionally much faster to run. We hope this might facilitate the development of large scale deep morph datasets for training detection models.",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "Published at the IEEE International Joint Conference on Biometrics (IJCB) 2023"
    },
    {
        "paper id": "2402.00697",
        "abstract url": "https://arxiv.org/abs/2402.00697",
        "title": "Combining Belief Function Theory and Stochastic Model Predictive Control for Multi-Modal Uncertainty in Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving",
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "In automated driving, predicting and accommodating the uncertain future motion of other traffic participants is challenging, especially in unstructured environments in which the high-level intention of traffic participants is difficult to predict. Several possible uncertain future behaviors of traffic participants must be considered, resulting in multi-modal uncertainty. We propose a novel combination of Belief Function Theory and Stochastic Model Predictive Control for trajectory planning of the autonomous vehicle in presence of significant uncertainty about the intention estimation of traffic participants. A misjudgment of the intention of traffic participants may result in dangerous situations. At the same time, excessive conservatism must be avoided. Therefore, the measure of reliability of the estimation provided by Belief Function Theory is used in the design of collision-avoidance safety constraints, in particular to increase safety when the intention of traffic participants is not clear. We discuss two methods to leverage on Belief Function Theory: we introduce a novel belief-to-probability transformation designed not to underestimate unlikely events if the information is uncertain, and a constraint tightening mechanism using the reliability of the estimation. We evaluate our proposal through simulations comparing to state-of-the-art approaches.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been accepted to the 2024 American Control Conference"
    },
    {
        "paper id": "2402.00729",
        "abstract url": "https://arxiv.org/abs/2402.00729",
        "title": "Profiling and Modeling of Power Characteristics of Leadership-Scale HPC System Workloads",
        "rating": "-1",
        "keywords": [
            [
                "GAN"
            ]
        ],
        "abstract": "In the exascale era in which application behavior has large power & energy footprints, per-application job-level awareness of such impression is crucial in taking steps towards achieving efficiency goals beyond performance, such as energy efficiency, and sustainability. To achieve these goals, we have developed a novel low-latency job power profiling machine learning pipeline that can group job-level power profiles based on their shapes as they complete. This pipeline leverages a comprehensive feature extraction and clustering pipeline powered by a generative adversarial network (GAN) model to handle the feature-rich time series of job-level power measurements. The output is then used to train a classification model that can predict whether an incoming job power profile is similar to a known group of profiles or is completely new. With extensive evaluations, we demonstrate the effectiveness of each component in our pipeline. Also, we provide a preliminary analysis of the resulting clusters that depict the power profile landscape of the Summit supercomputer from more than 60K jobs sampled from the year 2021.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00746",
        "abstract url": "https://arxiv.org/abs/2402.00746",
        "title": "Health-LLM: Personalized Retrieval-Augmented Disease Prediction System",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Health",
                "healthcare",
                "Disease"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in artificial intelligence (AI), especially large language models (LLMs), have significantly advanced healthcare applications and demonstrated potentials in intelligent medical treatment. However, there are conspicuous challenges such as vast data volumes and inconsistent symptom characterization standards, preventing full integration of healthcare AI systems with individual patients' needs. To promote professional and personalized healthcare, we propose an innovative framework, Heath-LLM, which combines large-scale feature extraction and medical knowledge trade-off scoring. Compared to traditional health management applications, our system has three main advantages: (1) It integrates health reports and medical knowledge into a large model to ask relevant questions to large language model for disease prediction; (2) It leverages a retrieval augmented generation (RAG) mechanism to enhance feature extraction; (3) It incorporates a semi-automated feature updating framework that can merge and delete features to improve accuracy of disease prediction. We experiment on a large number of health reports to assess the effectiveness of Health-LLM system. The results indicate that the proposed system surpasses the existing ones and has the potential to significantly advance disease prediction and personalized health management. The code is available at https://github.com/jmyissb/HealthLLM.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00750",
        "abstract url": "https://arxiv.org/abs/2402.00750",
        "title": "A System Level Analysis for Integrated Sensing and Communication",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "In this work, we provide a system level analysis of integrated sensing and communication (ISAC) systems, where a setup with a mono-static dual-functional radar communication base station is assumed. We derive the ISAC signal-to-noise ratio (SNR) equation that relates communication and radar SNR for different distances. We also derive the ISAC range equation, which can be used for sensing-assisted beamforming applications. Specifically, we show that increasing the frequency and bandwidth is more favorable to the radar application in terms of relative SNR and range while increasing the transmit power is more favorable to communications. Numerical examples reveal that if the range for communication and radar is desired to be in the same order, the ISAC system should operate in mmWave or sub-THz bands, whereas sub-6GHz allows scenarios where the communication range is of orders of magnitude higher than that of radar.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00763",
        "abstract url": "https://arxiv.org/abs/2402.00763",
        "title": "360-GS: Layout-guided Panoramic Gaussian Splatting For Indoor Roaming",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3D-GS) has recently attracted great attention with real-time and photo-realistic renderings. This technique typically takes perspective images as input and optimizes a set of 3D elliptical Gaussians by splatting them onto the image planes, resulting in 2D Gaussians. However, applying 3D-GS to panoramic inputs presents challenges in effectively modeling the projection onto the spherical surface of ${360^\\circ}$ images using 2D Gaussians. In practical applications, input panoramas are often sparse, leading to unreliable initialization of 3D Gaussians and subsequent degradation of 3D-GS quality. In addition, due to the under-constrained geometry of texture-less planes (e.g., walls and floors), 3D-GS struggles to model these flat regions with elliptical Gaussians, resulting in significant floaters in novel views. To address these issues, we propose 360-GS, a novel $360^{\\circ}$ Gaussian splatting for a limited set of panoramic inputs. Instead of splatting 3D Gaussians directly onto the spherical surface, 360-GS projects them onto the tangent plane of the unit sphere and then maps them to the spherical projections. This adaptation enables the representation of the projection using Gaussians. We guide the optimization of 360-GS by exploiting layout priors within panoramas, which are simple to obtain and contain strong structural information about the indoor scene. Our experimental results demonstrate that 360-GS allows panoramic rendering and outperforms state-of-the-art methods with fewer artifacts in novel view synthesis, thus providing immersive roaming in indoor scenarios.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "11 pages, 10 figures"
    },
    {
        "paper id": "2402.00775",
        "abstract url": "https://arxiv.org/abs/2402.00775",
        "title": "Adaptive Control for Triadic Human-Robot-FES Collaboration in Gait Rehabilitation: A Pilot Study",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "The hybridisation of robot-assisted gait training and functional electrical stimulation (FES) can provide numerous physiological benefits to neurological patients. However, the design of an effective hybrid controller poses significant challenges. In this over-actuated system, it is extremely difficult to find the right balance between robotic assistance and FES that will provide personalised assistance, prevent muscle fatigue and encourage the patient's active participation in order to accelerate recovery. In this paper, we present an adaptive hybrid robot-FES controller to do this and enable the triadic collaboration between the patient, the robot and FES. A patient-driven controller is designed where the voluntary movement of the patient is prioritised and assistance is provided using FES and the robot in a hierarchical order depending on the patient's performance and their muscles' fitness. The performance of this hybrid adaptive controller is tested in simulation and on one healthy subject. Our results indicate an increase in tracking performance with lower overall assistance, and less muscle fatigue when the hybrid adaptive controller is used, compared to its non adaptive equivalent. This suggests that our hybrid adaptive controller may be able to adapt to the behaviour of the user to provide assistance as needed and prevent the early termination of physical therapy due to muscle fatigue.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00786",
        "abstract url": "https://arxiv.org/abs/2402.00786",
        "title": "CroissantLLM: A Truly Bilingual French-English Language Model",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, and training steps, as well as fine-tuned Chat models, and strong translation models. We evaluate our model through the FMTI framework, and validate 81 % of the transparency criteria, far beyond the scores of even most open initiatives. This work enriches the NLP landscape, breaking away from previous English-centric work in order to strengthen our understanding of multilinguality in language models.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00834",
        "abstract url": "https://arxiv.org/abs/2402.00834",
        "title": "Approximating maximum-size properly colored forests",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In the Properly Colored Spanning Tree problem, we are given an edge-colored undirected graph and the goal is to find a properly colored spanning tree, i.e., a spanning tree in which any two adjacent edges have distinct colors. The problem is interesting not only from a graph coloring point of view, but is also closely related to the Degree Bounded Spanning Tree and (1,2)-Traveling Salesman problems, two classical questions that have attracted considerable interest in combinatorial optimization and approximation theory. Previous work on properly colored spanning trees has mainly focused on determining the existence of such a tree and hence has not considered the question from an algorithmic perspective. We propose an optimization version called Maximum-size Properly Colored Forest problem, which aims to find a properly colored forest with as many edges as possible. We consider the problem in different graph classes and for different numbers of colors, and present polynomial-time approximation algorithms as well as inapproximability results for these settings. Our proof technique relies on the sum of matching matroids defined by the color classes, a connection that might be of independent combinatorial interest. We also consider the Maximum-size Properly Colored Tree problem, which asks for the maximum size of a properly colored tree not necessarily spanning all the vertices. We show that the optimum is significantly more difficult to approximate than in the forest case, and provide an approximation algorithm for complete multigraphs.",
        "subjects": [
            "cs.DS",
            "cs.DM",
            "math.CO"
        ],
        "comment": "24 pages, 5 figures"
    },
    {
        "paper id": "2402.00841",
        "abstract url": "https://arxiv.org/abs/2402.00841",
        "title": "Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities to solve a wide range of tasks without being explicitly fine-tuned on task-specific datasets. However, deploying LLMs in the real world is not trivial, as it requires substantial computing resources. In this paper, we investigate whether smaller, compact LLMs are a good alternative to the comparatively Larger LLMs2 to address significant costs associated with utilizing LLMs in the real world. In this regard, we study the meeting summarization task in a real-world industrial environment and conduct extensive experiments by comparing the performance of fine-tuned compact LLMs (e.g., FLAN-T5, TinyLLaMA, LiteLLaMA) with zero-shot larger LLMs (e.g., LLaMA-2, GPT-3.5, PaLM-2). We observe that most smaller LLMs, even after fine-tuning, fail to outperform larger zero-shot LLMs in meeting summarization datasets. However, a notable exception is FLAN-T5 (780M parameters), which performs on par or even better than many zero-shot Larger LLMs (from 7B to above 70B parameters), while being significantly smaller. This makes compact LLMs like FLAN-T5 a suitable cost-efficient solution for real-world industrial deployment.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by NAACL 2024 (Industry Track). The first two authors contributed equally to this work"
    },
    {
        "paper id": "2402.00847",
        "abstract url": "https://arxiv.org/abs/2402.00847",
        "title": "BootsTAP: Bootstrapped Training for Tracking-Any-Point",
        "rating": "-1",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To endow models with greater understanding of physics and motion, it is useful to enable them to perceive how solid surfaces move and deform in real scenes. This can be formalized as Tracking-Any-Point (TAP), which requires the algorithm to be able to track any point corresponding to a solid surface in a video, potentially densely in space and time. Large-scale ground-truth training data for TAP is only available in simulation, which currently has limited variety of objects and motion. In this work, we demonstrate how large-scale, unlabeled, uncurated real-world data can improve a TAP model with minimal architectural changes, using a self-supervised student-teacher setup. We demonstrate state-of-the-art performance on the TAP-Vid benchmark surpassing previous results by a wide margin: for example, TAP-Vid-DAVIS performance improves from 61.3% to 66.4%, and TAP-Vid-Kinetics from 57.2% to 61.5%.",
        "subjects": [
            "cs.CV",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00864",
        "abstract url": "https://arxiv.org/abs/2402.00864",
        "title": "ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce ViCA-NeRF, the first view-consistency-aware method for 3D editing with text instructions. In addition to the implicit neural radiance field (NeRF) modeling, our key insight is to exploit two sources of regularization that explicitly propagate the editing information across different views, thus ensuring multi-view consistency. For geometric regularization, we leverage the depth information derived from NeRF to establish image correspondences between different views. For learned regularization, we align the latent codes in the 2D diffusion model between edited and unedited images, enabling us to edit key views and propagate the update throughout the entire scene. Incorporating these two strategies, our ViCA-NeRF operates in two stages. In the initial stage, we blend edits from different views to create a preliminary 3D edit. This is followed by a second stage of NeRF training, dedicated to further refining the scene's appearance. Experimental results demonstrate that ViCA-NeRF provides more flexible, efficient (3 times faster) editing with higher levels of consistency and details, compared with the state of the art. Our code is publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Neurips2023; project page: https://github.com/Dongjiahua/VICA-NeRF"
    },
    {
        "paper id": "2402.00867",
        "abstract url": "https://arxiv.org/abs/2402.00867",
        "title": "AToM: Amortized Text-to-Mesh using 2D Diffusion",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Amortized Text-to-Mesh (AToM), a feed-forward text-to-mesh framework optimized across multiple text prompts simultaneously. In contrast to existing text-to-3D methods that often entail time-consuming per-prompt optimization and commonly output representations other than polygonal meshes, AToM directly generates high-quality textured meshes in less than 1 second with around 10 times reduction in the training cost, and generalizes to unseen prompts. Our key idea is a novel triplane-based text-to-mesh architecture with a two-stage amortized optimization strategy that ensures stable training and enables scalability. Through extensive experiments on various prompt benchmarks, AToM significantly outperforms state-of-the-art amortized approaches with over 4 times higher accuracy (in DF415 dataset) and produces more distinguishable and higher-quality 3D outputs. AToM demonstrates strong generalizability, offering finegrained 3D assets for unseen interpolated prompts without further optimization during inference, unlike per-prompt solutions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "19 pages with appendix and references. Webpage: https://snap-research.github.io/AToM/"
    },
    {
        "paper id": "2402.00921",
        "abstract url": "https://arxiv.org/abs/2402.00921",
        "title": "Allocation of Indivisible Items with a Common Preference Graph: Minimizing Total Dissatisfaction",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Allocating indivisible items among a set of agents is a frequently studied discrete optimization problem. In the setting considered in this work, the agents' preferences over the items are assumed to be identical. We consider a very recent measure for the overall quality of an allocation which does not rely on numerical valuations of the items. Instead, it captures the agents' opinion by a directed acyclic preference graph with vertices representing items. An arc $(a,b)$ in such a graph means that the agents prefer item $a$ over item $b$. For a given allocation of items the dissatisfaction of an agent is defined as the number of items which the agent does not receive and for which no more preferred item is given to the agent. Our goal is to find an efficient allocation of the items to the agents such that the total dissatisfaction over all agents is minimized. We explore the dichotomy between NP-hard and polynomially solvable instances, depending on properties of the underlying preference graph. While the problem is NP-hard already for three agents even on very restricted graph classes, it is polynomially solvable for two agents on general preference graphs. For an arbitrary number of agents, we derive polynomial-time algorithms for relevant restrictions of the underlying undirected graph. These are trees and, among the graphs of treewidth two, series-parallel graphs and cactus graphs.",
        "subjects": [
            "cs.GT",
            "cs.DM"
        ],
        "comment": "28 pages, 1 figure"
    },
    {
        "paper id": "2402.00950",
        "abstract url": "https://arxiv.org/abs/2402.00950",
        "title": "Bridging Semantics for Automated Web Form Testing",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Automated test generation for web forms has been a longstanding challenge, exacerbated by the intrinsic human-centric design of forms and their complex, device-agnostic structures. We introduce an innovative approach, called FormNexus, for automated web form test generation, which emphasizes deriving semantic insights from individual form elements and relations among them, utilizing textual content, DOM tree structures, and visual proximity. The insights gathered are transformed into a new conceptual graph, the Form Entity Relation Graph (FERG), which offers machine-friendly semantic information extraction. Leveraging LLMs, FormNexus adopts a feedback-driven mechanism for generating and refining input constraints based on real-time form submission responses. The culmination of this approach is a robust set of test cases, each produced by methodically invalidating constraints, ensuring comprehensive testing scenarios for web forms. This work bridges the existing gap in automated web form testing by intertwining the capabilities of LLMs with advanced semantic inference methods. Our evaluation demonstrates that FormNexus combined with GPT-4 achieves 89% coverage in form submission states. This outcome significantly outstrips the performance of the best baseline model by a margin of 25%.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00967",
        "abstract url": "https://arxiv.org/abs/2402.00967",
        "title": "MACE CT Reconstruction for Modular Material Decomposition from Energy Resolving Photon-Counting Data",
        "rating": "-1",
        "keywords": [
            [
                "CT",
                "X-ray",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "X-ray computed tomography (CT) based on photon counting detectors (PCD) extends standard CT by counting detected photons in multiple energy bins. PCD data can be used to increase the contrast-to-noise ratio (CNR), increase spatial resolution, reduce radiation dose, reduce injected contrast dose, and compute a material decomposition using a specified set of basis materials. Current commercial and prototype clinical photon counting CT systems utilize PCD-CT reconstruction methods that either reconstruct from each spectral bin separately, or first create an estimate of a material sinogram using a specified set of basis materials and then reconstruct from these material sinograms. However, existing methods are not able to utilize simultaneously and in a modular fashion both the measured spectral information and advanced prior models in order to produce a material decomposition. We describe an efficient, modular framework for PCD-based CT reconstruction and material decomposition using on Multi-Agent Consensus Equilibrium (MACE). Our method employs a detector proximal map or agent that uses PCD measurements to update an estimate of the pathlength sinogram. We also create a prior agent in the form of a sinogram denoiser that enforces both physical and empirical knowledge about the material-decomposed sinogram. The sinogram reconstruction is computed using the MACE algorithm, which finds an equilibrium solution between the two agents, and the final image is reconstructed from the estimated sinogram. Importantly, the modularity of our method allows the two agents to be designed, implemented, and optimized independently. Our results on simulated data show a substantial (450%) CNR boost vs conventional maximum likelihood reconstruction when applied to a phantom used to evaluate low contrast detectability.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "11 pages, 10 figures, submitted to SPIE Medical Imaging 2024"
    },
    {
        "paper id": "2402.00971",
        "abstract url": "https://arxiv.org/abs/2402.00971",
        "title": "FuseFormer: A Transformer for Visual and Thermal Image Fusion",
        "rating": "-1",
        "keywords": [
            [
                "Thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Due to the lack of a definitive ground truth for the image fusion problem, the loss functions are structured based on evaluation metrics, such as the structural similarity index measure (SSIM). However, in doing so, a bias is introduced toward the SSIM and, consequently, the input visual band image. The objective of this study is to propose a novel methodology for the image fusion problem that mitigates the limitations associated with using classical evaluation metrics as loss functions. Our approach integrates a transformer-based multi-scale fusion strategy that adeptly addresses local and global context information. This integration not only refines the individual components of the image fusion process but also significantly enhances the overall efficacy of the method. Our proposed method follows a two-stage training approach, where an auto-encoder is initially trained to extract deep features at multiple scales in the first stage. For the second stage, we integrate our fusion block and change the loss function as mentioned. The multi-scale features are fused using a combination of Convolutional Neural Networks (CNNs) and Transformers. The CNNs are utilized to capture local features, while the Transformer handles the integration of general context features. Through extensive experiments on various benchmark datasets, our proposed method, along with the novel loss function definition, demonstrates superior performance compared to other competitive fusion algorithms.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 6 figures, 6 tables"
    },
    {
        "paper id": "2402.00986",
        "abstract url": "https://arxiv.org/abs/2402.00986",
        "title": "The Parallel Semantics Program Dependence Graph",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "A compiler's intermediate representation (IR) defines a program's execution plan by encoding its instructions and their relative order. Compiler optimizations aim to replace a given execution plan with a semantically-equivalent one that increases the program's performance for the target architecture. Alternative representations of an IR, like the Program Dependence Graph (PDG), aid this process by capturing the minimum set of constraints that semantically-equivalent execution plans must satisfy. Parallel programming like OpenMP extends a sequential execution plan by adding the possibility of running instructions in parallel, creating a parallel execution plan. Recently introduced parallel IRs, like TAPIR, explicitly encode a parallel execution plan. These new IRs finally make it possible for compilers to change the parallel execution plan expressed by programmers to better fit the target parallel architecture. Unfortunately, parallel IRs do not help compilers in identifying the set of parallel execution plans that preserve the original semantics. In other words, we are still lacking an alternative representation of parallel IRs to capture the minimum set of constraints that parallel execution plans must satisfy to be semantically-equivalent. Unfortunately, the PDG is not an ideal candidate for this task as it was designed for sequential code. We propose the Parallel Semantics Program Dependence Graph (PS-PDG) to precisely capture the salient program constraints that all semantically-equivalent parallel execution plans must satisfy. This paper defines the PS-PDG, justifies the necessity of each extension to the PDG, and demonstrates the increased optimization power of the PS-PDG over an existing PDG-based automatic-parallelizing compiler. Compilers can now rely on the PS-PDG to select different parallel execution plans while maintaining the same original semantics.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00993",
        "abstract url": "https://arxiv.org/abs/2402.00993",
        "title": "Compressed image quality assessment using stacking",
        "rating": "-1",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "It is well-known that there is no universal metric for image quality evaluation. In this case, distortion-specific metrics can be more reliable. The artifact imposed by image compression can be considered as a combination of various distortions. Depending on the image context, this combination can be different. As a result, Generalization can be regarded as the major challenge in compressed image quality assessment. In this approach, stacking is employed to provide a reliable method. Both semantic and low-level information are employed in the presented IQA to predict the human visual system. Moreover, the results of the Full-Reference (FR) and No-Reference (NR) models are aggregated to improve the proposed Full-Reference method for compressed image quality evaluation. The accuracy of the quality benchmark of the clic2024 perceptual image challenge was achieved 79.6\\%, which illustrates the effectiveness of the proposed fusion-based approach.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2402.01012",
        "abstract url": "https://arxiv.org/abs/2402.01012",
        "title": "algoXSSF: Detection and analysis of cross-site request forgery (XSRF) and cross-site scripting (XSS) attacks via Machine learning algorithms",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The global rise of online users and online devices has ultimately given rise to the global internet population apart from several cybercrimes and cyberattacks. The combination of emerging new technology and powerful algorithms (of Artificial Intelligence, Deep Learning, and Machine Learning) is needed to counter defense web security including attacks on several search engines and websites. The unprecedented increase rate of cybercrime and website attacks urged for new technology consideration to protect data and information online. There have been recent and continuous cyberattacks on websites, web domains with ongoing data breaches including - GitHub account hack, data leaks on Twitter, malware in WordPress plugins, vulnerability in Tomcat server to name just a few. We have investigated with an in-depth study apart from the detection and analysis of two major cyberattacks (although there are many more types): cross-site request forgery (XSRF) and cross-site scripting (XSS) attacks. The easy identification of cyber trends and patterns with continuous improvement is possible within the edge of machine learning and AI algorithms. The use of machine learning algorithms would be extremely helpful to counter (apart from detection) the XSRF and XSS attacks. We have developed the algorithm and cyber defense framework - algoXSSF with machine learning algorithms embedded to combat malicious attacks (including Man-in-the-Middle attacks) on websites for detection and analysis.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2402.01018",
        "abstract url": "https://arxiv.org/abs/2402.01018",
        "title": "HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in Large Language Models (LLMs) have been reshaping Natural Language Processing (NLP) task in several domains. Their use in the field of Human Resources (HR) has still room for expansions and could be beneficial for several time consuming tasks. Examples such as time-off submissions, medical claims filing, and access requests are noteworthy, but they are by no means the sole instances. However, the aforementioned developments must grapple with the pivotal challenge of constructing a high-quality training dataset. On one hand, most conversation datasets are solving problems for customers not employees. On the other hand, gathering conversations with HR could raise privacy concerns. To solve it, we introduce HR-Multiwoz, a fully-labeled dataset of 550 conversations spanning 10 HR domains to evaluate LLM Agent. Our work has the following contributions: (1) It is the first labeled open-sourced conversation dataset in the HR domain for NLP research. (2) It provides a detailed recipe for the data generation procedure along with data analysis and human evaluations. The data generation pipeline is transferable and can be easily adapted for labeled conversation data generation in other domains. (3) The proposed data-collection pipeline is mostly based on LLMs with minimal human involvement for annotation, which is time and cost-efficient.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2402.01031",
        "abstract url": "https://arxiv.org/abs/2402.01031",
        "title": "MRAnnotator: A Multi-Anatomy Deep Learning Model for MRI Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "MRI",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Purpose To develop a deep learning model for multi-anatomy and many-class segmentation of diverse anatomic structures on MRI imaging. Materials and Methods In this retrospective study, two datasets were curated and annotated for model development and evaluation. An internal dataset of 1022 MRI sequences from various clinical sites within a health system and an external dataset of 264 MRI sequences from an independent imaging center were collected. In both datasets, 49 anatomic structures were annotated as the ground truth. The internal dataset was divided into training, validation, and test sets and used to train and evaluate an nnU-Net model. The external dataset was used to evaluate nnU-Net model generalizability and performance in all classes on independent imaging data. Dice scores were calculated to evaluate model segmentation performance. Results The model achieved an average Dice score of 0.801 on the internal test set, and an average score of 0.814 on the complete external dataset across 49 classes. Conclusion The developed model achieves robust and generalizable segmentation of 49 anatomic structures on MRI imaging. A future direction is focused on the incorporation of additional anatomic regions and structures into the datasets and model.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01034",
        "abstract url": "https://arxiv.org/abs/2402.01034",
        "title": "VISION-MAE: A Foundation Model for Medical Image Segmentation and Classification",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "diagnosis",
                "CT",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) has the potential to revolutionize diagnosis and segmentation in medical imaging. However, development and clinical implementation face multiple challenges including limited data availability, lack of generalizability, and the necessity to incorporate multi-modal data effectively. A foundation model, which is a large-scale pre-trained AI model, offers a versatile base that can be adapted to a variety of specific tasks and contexts. Here, we present a novel foundation model, VISION-MAE, specifically designed for medical imaging. Specifically, VISION-MAE is trained on a dataset of 2.5 million unlabeled images from various modalities (CT, MR, PET, X-rays, and ultrasound), using self-supervised learning techniques. It is then adapted to classification and segmentation tasks using explicit labels. VISION-MAE has high label efficiency, outperforming several benchmark models in both in-domain and out-of-domain applications, and achieves high performance even with reduced availability of labeled data. This model represents a significant advancement in medical imaging AI, offering a generalizable and robust solution for improving segmentation and classification tasks while reducing the data annotation workload.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01052",
        "abstract url": "https://arxiv.org/abs/2402.01052",
        "title": "Weakly Convex Regularisers for Inverse Problems: Convergence of Critical Points and Primal-Dual Optimisation",
        "rating": "-1",
        "keywords": [
            [
                "CT"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Variational regularisation is the primary method for solving inverse problems, and recently there has been considerable work leveraging deeply learned regularisation for enhanced performance. However, few results exist addressing the convergence of such regularisation, particularly within the context of critical points as opposed to global minima. In this paper, we present a generalised formulation of convergent regularisation in terms of critical points, and show that this is achieved by a class of weakly convex regularisers. We prove convergence of the primal-dual hybrid gradient method for the associated variational problem, and, given a Kurdyka-Lojasiewicz condition, an $\\mathcal{O}(\\log{k}/k)$ ergodic convergence rate. Finally, applying this theory to learned regularisation, we prove universal approximation for input weakly convex neural networks (IWCNN), and show empirically that IWCNNs can lead to improved performance of learned adversarial regularisers for computed tomography (CT) reconstruction.",
        "subjects": [
            "math.OC",
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "26 pages, 4 figures, preprint"
    },
    {
        "paper id": "2402.01059",
        "abstract url": "https://arxiv.org/abs/2402.01059",
        "title": "Eco-driving under localization uncertainty for connected vehicles on Urban roads: Data-driven approach and Experiment verification",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "This paper addresses the eco-driving problem for connected vehicles on urban roads, considering localization uncertainty. Eco-driving is defined as longitudinal speed planning and control on roads with the presence of a sequence of traffic lights. We solve the problem by using a data-driven model predictive control (MPC) strategy. This approach involves learning a cost-to-go function and constraints from state-input data. The cost-to-go function represents the remaining energy-to-spend from the given state, and the constraints ensure that the controlled vehicle passes the upcoming traffic light timely while obeying traffic laws. The resulting convex optimization problem has a short horizon and is amenable for real-time implementations. We demonstrate the effectiveness of our approach through real-world vehicle experiments. Our method demonstrates $12\\%$ improvement in energy efficiency compared to the traditional approaches, which plan longitudinal speed by solving a long-horizon optimal control problem and track the planned speed using another controller, as evidenced by vehicle experiments.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted for IEEE IV 2024"
    },
    {
        "paper id": "2402.01067",
        "abstract url": "https://arxiv.org/abs/2402.01067",
        "title": "Assessing Patient Eligibility for Inspire Therapy through Machine Learning and Deep Learning Models",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "clinical",
                "endoscopic"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Inspire therapy is an FDA-approved internal neurostimulation treatment for obstructive sleep apnea. However, not all patients respond to this therapy, posing a challenge even for experienced otolaryngologists to determine candidacy. This paper makes the first attempt to leverage both machine learning and deep learning techniques in discerning patient responsiveness to Inspire therapy using medical data and videos captured through Drug-Induced Sleep Endoscopy (DISE), an essential procedure for Inspire therapy. To achieve this, we gathered and annotated three datasets from 127 patients. Two of these datasets comprise endoscopic videos focused on the Base of the Tongue and Velopharynx. The third dataset composes the patient's clinical information. By utilizing these datasets, we benchmarked and compared the performance of six deep learning models and five classical machine learning algorithms. The results demonstrate the potential of employing machine learning and deep learning techniques to determine a patient's eligibility for Inspire therapy, paving the way for future advancements in this field.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01104",
        "abstract url": "https://arxiv.org/abs/2402.01104",
        "title": "Simulation Framework for Vehicle and Electric Scooter Interaction",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "The number of shared micro-mobility services such as electric scooters (e-scooters) has an increasing trend due to the advantages of high efficiency and low cost in short-range travel in urban areas. However, due to the unique characteristics of moving behavior, it is commonly seen that e-scooters may share the road with other motor vehicles. The lack of protection may lead to severe injury for e-scooter riders. The scenario where an e-scooter crosses an intersection or makes a lane change while interacting with an approaching vehicle was commonly seen in real-life traffic data. Such scenarios are hazardous because the intention and behavior of the e-scooter may vary significantly based on the traffic environment conditions. Furthermore, some other vehicles may occlude the presence of the moving e-scooter, which can result in an unexpected collision. In this paper, we propose a simulation platform to mimic the interactions between vehicles and e-scooters. Several traffic scenarios are studied via qualitative and quantitative analysis. The proposed framework is shown to be valuable and efficient for the general risk analysis for vehicle and e-scooter interactions (VEI).",
        "subjects": [
            "eess.SY"
        ],
        "comment": "The paper has been accepted by 26th IEEE International Conference on Intelligent Transportation Systems ITSC 2023"
    },
    {
        "paper id": "2402.01105",
        "abstract url": "https://arxiv.org/abs/2402.01105",
        "title": "A Survey for Foundation Models in Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The advent of foundation models has revolutionized the fields of natural language processing and computer vision, paving the way for their application in autonomous driving (AD). This survey presents a comprehensive review of more than 40 research papers, demonstrating the role of foundation models in enhancing AD. Large language models contribute to planning and simulation in AD, particularly through their proficiency in reasoning, code generation and translation. In parallel, vision foundation models are increasingly adapted for critical tasks such as 3D object detection and tracking, as well as creating realistic driving scenarios for simulation and testing. Multi-modal foundation models, integrating diverse inputs, exhibit exceptional visual understanding and spatial reasoning, crucial for end-to-end AD. This survey not only provides a structured taxonomy, categorizing foundation models based on their modalities and functionalities within the AD domain but also delves into the methods employed in current research. It identifies the gaps between existing foundation models and cutting-edge AD approaches, thereby charting future research directions and proposing a roadmap for bridging these gaps.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01106",
        "abstract url": "https://arxiv.org/abs/2402.01106",
        "title": "Learning Which Side to Scan: Multi-View Informed Active Perception with Side Scan Sonar for Autonomous Underwater Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "graph"
            ]
        ],
        "abstract": "Autonomous underwater vehicles often perform surveys that capture multiple views of targets in order to provide more information for human operators or automatic target recognition algorithms. In this work, we address the problem of choosing the most informative views that minimize survey time while maximizing classifier accuracy. We introduce a novel active perception framework for multi-view adaptive surveying and reacquisition using side scan sonar imagery. Our framework addresses this challenge by using a graph formulation for the adaptive survey task. We then use Graph Neural Networks (GNNs) to both classify acquired sonar views and to choose the next best view based on the collected data. We evaluate our method using simulated surveys in a high-fidelity side scan sonar simulator. Our results demonstrate that our approach is able to surpass the state-of-the-art in classification accuracy and survey efficiency. This framework is a promising approach for more efficient autonomous missions involving side scan sonar, such as underwater exploration, marine archaeology, and environmental monitoring.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01115",
        "abstract url": "https://arxiv.org/abs/2402.01115",
        "title": "Interpretation of Intracardiac Electrograms Through Textual Representations",
        "rating": "-1",
        "keywords": [
            [
                "healthcare",
                "clinical",
                "cardiac"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Understanding the irregular electrical activity of atrial fibrillation (AFib) has been a key challenge in electrocardiography. For serious cases of AFib, catheter ablations are performed to collect intracardiac electrograms (EGMs). EGMs offer intricately detailed and localized electrical activity of the heart and are an ideal modality for interpretable cardiac studies. Recent advancements in artificial intelligence (AI) has allowed some works to utilize deep learning frameworks to interpret EGMs during AFib. Additionally, language models (LMs) have shown exceptional performance in being able to generalize to unseen domains, especially in healthcare. In this study, we are the first to leverage pretrained LMs for finetuning of EGM interpolation and AFib classification via masked language modeling. We formulate the EGM as a textual sequence and present competitive performances on AFib classification compared against other representations. Lastly, we provide a comprehensive interpretability study to provide a multi-perspective intuition of the model's behavior, which could greatly benefit the clinical use.",
        "subjects": [
            "cs.CL",
            "eess.SP"
        ],
        "comment": "18 pages, 9 figures; Accepted to CHIL 2024"
    },
    {
        "paper id": "2402.01130",
        "abstract url": "https://arxiv.org/abs/2402.01130",
        "title": "convSeq: Fast and Scalable Method for Detecting Patterns in Spike Data",
        "rating": "-1",
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Spontaneous neural activity, crucial in memory, learning, and spatial navigation, often manifests itself as repetitive spatiotemporal patterns. Despite their importance, analyzing these patterns in large neural recordings remains challenging due to a lack of efficient and scalable detection methods. Addressing this gap, we introduce convSeq, an unsupervised method that employs backpropagation for optimizing spatiotemporal filters that effectively identify these neural patterns. Our method's performance is validated on various synthetic data and real neural recordings, revealing spike sequences with unprecedented scalability and efficiency. Significantly surpassing existing methods in speed, convSeq sets a new standard for analyzing spontaneous neural activity, potentially advancing our understanding of information processing in neural circuits.",
        "subjects": [
            "eess.SP",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01135",
        "abstract url": "https://arxiv.org/abs/2402.01135",
        "title": "A Multi-Agent Conversational Recommender System",
        "rating": "-1",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Due to strong capabilities in conducting fluent, multi-turn conversations with users, Large Language Models (LLMs) have the potential to further improve the performance of Conversational Recommender System (CRS). Unlike the aimless chit-chat that LLM excels at, CRS has a clear target. So it is imperative to control the dialogue flow in the LLM to successfully recommend appropriate items to the users. Furthermore, user feedback in CRS can assist the system in better modeling user preferences, which has been ignored by existing studies. However, simply prompting LLM to conduct conversational recommendation cannot address the above two key challenges. In this paper, we propose Multi-Agent Conversational Recommender System (MACRS) which contains two essential modules. First, we design a multi-agent act planning framework, which can control the dialogue flow based on four LLM-based agents. This cooperative multi-agent framework will generate various candidate responses based on different dialogue acts and then choose the most appropriate response as the system response, which can help MACRS plan suitable dialogue acts. Second, we propose a user feedback-aware reflection mechanism which leverages user feedback to reason errors made in previous turns to adjust the dialogue act planning, and higher-level user information from implicit semantics. We conduct extensive experiments based on user simulator to demonstrate the effectiveness of MACRS in recommendation and user preferences collection. Experimental results illustrate that MACRS demonstrates an improvement in user interaction experience compared to directly using LLMs.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01140",
        "abstract url": "https://arxiv.org/abs/2402.01140",
        "title": "Root Cause Analysis In Microservice Using Neural Granger Causal Discovery",
        "rating": "-1",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "In recent years, microservices have gained widespread adoption in IT operations due to their scalability, maintenance, and flexibility. However, it becomes challenging for site reliability engineers (SREs) to pinpoint the root cause due to the complex relationships in microservices when facing system malfunctions. Previous research employed structured learning methods (e.g., PC-algorithm) to establish causal relationships and derive root causes from causal graphs. Nevertheless, they ignored the temporal order of time series data and failed to leverage the rich information inherent in the temporal relationships. For instance, in cases where there is a sudden spike in CPU utilization, it can lead to an increase in latency for other microservices. However, in this scenario, the anomaly in CPU utilization occurs before the latency increase, rather than simultaneously. As a result, the PC-algorithm fails to capture such characteristics. To address these challenges, we propose RUN, a novel approach for root cause analysis using neural Granger causal discovery with contrastive learning. RUN enhances the backbone encoder by integrating contextual information from time series, and leverages a time series forecasting model to conduct neural Granger causal discovery. In addition, RUN incorporates Pagerank with a personalization vector to efficiently recommend the top-k root causes. Extensive experiments conducted on the synthetic and real-world microservice-based datasets demonstrate that RUN noticeably outperforms the state-of-the-art root cause analysis methods. Moreover, we provide an analysis scenario for the sock-shop case to showcase the practicality and efficacy of RUN in microservice-based applications. Our code is publicly available at https://github.com/zmlin1998/RUN.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "AAAI 2024 Main Track"
    },
    {
        "paper id": "2403.08796",
        "abstract url": "https://arxiv.org/abs/2403.08796",
        "title": "Analog In-Memory Computing with Uncertainty Quantification for Efficient Edge-based Medical Imaging Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This work investigates the role of the emerging Analog In-memory computing (AIMC) paradigm in enabling Medical AI analysis and improving the certainty of these models at the edge. It contrasts AIMC's efficiency with traditional digital computing's limitations in power, speed, and scalability. Our comprehensive evaluation focuses on brain tumor analysis, spleen segmentation, and nuclei detection. The study highlights the superior robustness of isotropic architectures, which exhibit a minimal accuracy drop (0.04) in analog-aware training, compared to significant drops (up to 0.15) in pyramidal structures. Additionally, the paper emphasizes IMC's effective data pipelining, reducing latency and increasing throughput as well as the exploitation of inherent noise within AIMC, strategically harnessed to augment model certainty.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00463",
        "abstract url": "https://arxiv.org/abs/2402.00463",
        "title": "Understanding gender differences in experiences and concerns surrounding online harms: A short report on a nationally representative survey of UK adults",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Online harms, such as hate speech, misinformation, harassment and self-harm promotion, continue to be widespread. While some work suggests that women are disproportionately affected by such harms, other studies find little evidence for gender differences in overall exposure. Here, we present preliminary results from a large, nationally representative survey of UK adults (N = 2000). We asked about exposure to 15 specific harms, along with fears surrounding exposure and comfort engaging in certain online behaviours. While men and women report seeing online harms to a roughly equal extent overall, we find that women are significantly more fearful of experiencing every type of harm that we asked about, and are significantly less comfortable partaking in several online behaviours. Strikingly, just 24% of women report being comfortable expressing political opinions online compared with almost 40% of men, with similar overall proportions for challenging certain content. Our work suggests that women may suffer an additional psychological burden in response to the proliferation of harmful online content, doing more 'safety work' to protect themselves. With much public discourse happening online, gender inequality in public voice is likely to be perpetuated if women feel too fearful to participate. Our results are important because to establish greater equality in society, we must take measures to ensure all members feel safe and able to participate in the online space.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00468",
        "abstract url": "https://arxiv.org/abs/2402.00468",
        "title": "RadDQN: a Deep Q Learning-based Architecture for Finding Time-efficient Minimum Radiation Exposure Pathway",
        "rating": "-1.5",
        "keywords": [
            [
                "Time-efficient"
            ],
            [
                "vehicle"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advancements in deep reinforcement learning (DRL) techniques have sparked its multifaceted applications in the automation sector. Managing complex decision-making problems with DRL encourages its use in the nuclear industry for tasks such as optimizing radiation exposure to the personnel during normal operating conditions and potential accidental scenarios. However, the lack of efficient reward function and effective exploration strategy thwarted its implementation in the development of radiation-aware autonomous unmanned aerial vehicle (UAV) for achieving maximum radiation protection. Here, in this article, we address these intriguing issues and introduce a deep Q-learning based architecture (RadDQN) that operates on a radiation-aware reward function to provide time-efficient minimum radiation-exposure pathway in a radiation zone. We propose a set of unique exploration strategies that fine-tune the extent of exploration and exploitation based on the state-wise variation in radiation exposure during training. Further, we benchmark the predicted path with grid-based deterministic method. We demonstrate that the formulated reward function in conjugation with adequate exploration strategy is effective in handling several scenarios with drastically different radiation field distributions. When compared to vanilla DQN, our model achieves a superior convergence rate and higher training stability.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "12 pages, 7 main figures, code link (GitHub)"
    },
    {
        "paper id": "2402.00485",
        "abstract url": "https://arxiv.org/abs/2402.00485",
        "title": "A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In recent years, there has been an increasing recognition that when machine learning (ML) algorithms are used to automate decisions, they may mistreat individuals or groups, with legal, ethical, or economic implications. Recommender systems are prominent examples of these machine learning (ML) systems that aid users in making decisions. The majority of past literature research on RS fairness treats user and item fairness concerns independently, ignoring the fact that recommender systems function in a two-sided marketplace. In this paper, we propose CP-FairRank, an optimization-based re-ranking algorithm that seamlessly integrates fairness constraints from both the consumer and producer side in a joint objective framework. The framework is generalizable and may take into account varied fairness settings based on group segmentation, recommendation model selection, and domain, which is one of its key characteristics. For instance, we demonstrate that the system may jointly increase consumer and producer fairness when (un)protected consumer groups are defined on the basis of their activity level and main-streamness, while producer groups are defined according to their popularity level. For empirical validation, through large-scale on eight datasets and four mainstream collaborative filtering (CF) recommendation models, we demonstrate that our proposed strategy is able to improve both consumer and producer fairness without compromising or very little overall recommendation quality, demonstrating the role algorithms may play in avoiding data biases.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "cs.IR"
        ],
        "comment": "TORS. arXiv admin note: substantial text overlap with arXiv:2204.08085"
    },
    {
        "paper id": "2402.00491",
        "abstract url": "https://arxiv.org/abs/2402.00491",
        "title": "EXMOS: Explanatory Model Steering Through Multifaceted Explanations and Data Configurations",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Explanations in interactive machine-learning systems facilitate debugging and improving prediction models. However, the effectiveness of various global model-centric and data-centric explanations in aiding domain experts to detect and resolve potential data issues for model improvement remains unexplored. This research investigates the influence of data-centric and model-centric global explanations in systems that support healthcare experts in optimising models through automated and manual data configurations. We conducted quantitative (n=70) and qualitative (n=30) studies with healthcare experts to explore the impact of different explanations on trust, understandability and model improvement. Our results reveal the insufficiency of global model-centric explanations for guiding users during data configuration. Although data-centric explanations enhanced understanding of post-configuration system changes, a hybrid fusion of both explanation types demonstrated the highest effectiveness. Based on our study results, we also present design implications for effective explanation-driven interactive machine-learning systems.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": "This is a pre-print version only for early release. Please view the conference published version from ACM CHI 2024 to get the latest version of the paper"
    },
    {
        "paper id": "2402.00515",
        "abstract url": "https://arxiv.org/abs/2402.00515",
        "title": "Developing A Multi-Agent and Self-Adaptive Framework with Deep Reinforcement Learning for Dynamic Portfolio Risk Management",
        "rating": "-1.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep or reinforcement learning (RL) approaches have been adapted as reactive agents to quickly learn and respond with new investment strategies for portfolio management under the highly turbulent financial market environments in recent years. In many cases, due to the very complex correlations among various financial sectors, and the fluctuating trends in different financial markets, a deep or reinforcement learning based agent can be biased in maximising the total returns of the newly formulated investment portfolio while neglecting its potential risks under the turmoil of various market conditions in the global or regional sectors. Accordingly, a multi-agent and self-adaptive framework namely the MASA is proposed in which a sophisticated multi-agent reinforcement learning (RL) approach is adopted through two cooperating and reactive agents to carefully and dynamically balance the trade-off between the overall portfolio returns and their potential risks. Besides, a very flexible and proactive agent as the market observer is integrated into the MASA framework to provide some additional information on the estimated market trends as valuable feedbacks for multi-agent RL approach to quickly adapt to the ever-changing market conditions. The obtained empirical results clearly reveal the potential strengths of our proposed MASA framework based on the multi-agent RL approach against many well-known RL-based approaches on the challenging data sets of the CSI 300, Dow Jones Industrial Average and S&P 500 indexes over the past 10 years. More importantly, our proposed MASA framework shed lights on many possible directions for future investigation.",
        "subjects": [
            "q-fin.PM",
            "cs.LG"
        ],
        "comment": "Accepted by The 23rd International Conference on Autonomous Agents and Multi-Agent Systems"
    },
    {
        "paper id": "2402.00531",
        "abstract url": "https://arxiv.org/abs/2402.00531",
        "title": "Preconditioning for Physics-Informed Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-informed neural networks (PINNs) have shown promise in solving various partial differential equations (PDEs). However, training pathologies have negatively affected the convergence and prediction accuracy of PINNs, which further limits their practical applications. In this paper, we propose to use condition number as a metric to diagnose and mitigate the pathologies in PINNs. Inspired by classical numerical analysis, where the condition number measures sensitivity and stability, we highlight its pivotal role in the training dynamics of PINNs. We prove theorems to reveal how condition number is related to both the error control and convergence of PINNs. Subsequently, we present an algorithm that leverages preconditioning to improve the condition number. Evaluations of 18 PDE problems showcase the superior performance of our method. Significantly, in 7 of these problems, our method reduces errors by an order of magnitude. These empirical findings verify the critical role of the condition number in PINNs' training.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00544",
        "abstract url": "https://arxiv.org/abs/2402.00544",
        "title": "Quantum-Assisted Hilbert-Space Gaussian Process Regression",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Gaussian processes are probabilistic models that are commonly used as functional priors in machine learning. Due to their probabilistic nature, they can be used to capture the prior information on the statistics of noise, smoothness of the functions, and training data uncertainty. However, their computational complexity quickly becomes intractable as the size of the data set grows. We propose a Hilbert space approximation-based quantum algorithm for Gaussian process regression to overcome this limitation. Our method consists of a combination of classical basis function expansion with quantum computing techniques of quantum principal component analysis, conditional rotations, and Hadamard and Swap tests. The quantum principal component analysis is used to estimate the eigenvalues while the conditional rotations and the Hadamard and Swap tests are employed to evaluate the posterior mean and variance of the Gaussian process. Our method provides polynomial computational complexity reduction over the classical method.",
        "subjects": [
            "stat.CO",
            "cs.LG",
            "quant-ph"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2402.00588",
        "abstract url": "https://arxiv.org/abs/2402.00588",
        "title": "BrainSLAM: SLAM on Neural Population Activity Data",
        "rating": "-1.5",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Simultaneous localisation and mapping (SLAM) algorithms are commonly used in robotic systems for learning maps of novel environments. Brains also appear to learn maps, but the mechanisms are not known and it is unclear how to infer these maps from neural activity data. We present BrainSLAM; a method for performing SLAM using only population activity (local field potential, LFP) data simultaneously recorded from three brain regions in rats: hippocampus, prefrontal cortex, and parietal cortex. This system uses a convolutional neural network (CNN) to decode velocity and familiarity information from wavelet scalograms of neural local field potential data recorded from rats as they navigate a 2D maze. The CNN's output drives a RatSLAM-inspired architecture, powering an attractor network which performs path integration plus a separate system which performs `loop closure' (detecting previously visited locations and correcting map aliasing errors). Together, these three components can construct faithful representations of the environment while simultaneously tracking the animal's location. This is the first demonstration of inference of a spatial map from brain recordings. Our findings expand SLAM to a new modality, enabling a new method of mapping environments and facilitating a better understanding of the role of cognitive maps in navigation and decision making.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "Accepted to the 23rd International Conference on Autonomous Agents and Multiagent Systems. 2024"
    },
    {
        "paper id": "2402.00638",
        "abstract url": "https://arxiv.org/abs/2402.00638",
        "title": "Random Forest-Based Prediction of Stroke Outcome",
        "rating": "-1.5",
        "keywords": [
            [
                "biochemical",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We research into the clinical, biochemical and neuroimaging factors associated with the outcome of stroke patients to generate a predictive model using machine learning techniques for prediction of mortality and morbidity 3 months after admission. The dataset consisted of patients with ischemic stroke (IS) and non-traumatic intracerebral hemorrhage (ICH) admitted to Stroke Unit of a European Tertiary Hospital prospectively registered. We identified the main variables for machine learning Random Forest (RF), generating a predictive model that can estimate patient mortality/morbidity. In conclusion, machine learning algorithms RF can be effectively used in stroke patients for long-term outcome prediction of mortality and morbidity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 5 figures"
    },
    {
        "paper id": "2402.00678",
        "abstract url": "https://arxiv.org/abs/2402.00678",
        "title": "Real Evaluations Tractability using Continuous Goal-Directed Actions in Smart City Applications",
        "rating": "-1.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "One of the most important challenges of Smart City Applications is to adapt the system to interact with non-expert users. Robot imitation frameworks aim to simplify and reduce times of robot programming by allowing users to program directly through demonstrations. In classical frameworks, actions are modeled using joint or Cartesian space trajectories. Other features, such as visual ones, are not always well represented with these pure geometrical approaches. Continuous Goal-Directed Actions (CGDA) is an alternative to these methods, as it encodes actions as changes of any feature that can be extracted from the environment. As a consequence of this, the robot joint trajectories for execution must be fully computed to comply with this feature-agnostic encoding. This is achieved using Evolutionary Algorithms (EA), which usually requires too many evaluations to perform this evolution step in the actual robot. Current strategies involve performing evaluations in a simulation, transferring the final joint trajectory to the actual robot. Smart City applications involve working in highly dynamic and complex environments, where having a precise model is not always achievable. Our goal is to study the tractability of performing these evaluations directly in a real-world scenario. Two different approaches to reduce the number of evaluations using EA, are proposed and compared. In the first approach, Particle Swarm Optimization (PSO)-based methods have been studied and compared within CGDA: naive PSO, Fitness Inheritance PSO (FI-PSO), and Adaptive Fuzzy Fitness Granulation with PSO (AFFG-PSO). The second approach studied the introduction of geometrical and velocity constraints within CGDA. The effects of both approaches were analyzed and compared in the wax and paint actions, two CGDA commonly studied use cases. Results from this paper depict an important reduction in the number of evaluations.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00760",
        "abstract url": "https://arxiv.org/abs/2402.00760",
        "title": "EuroPED-NN: Uncertainty aware surrogate model",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work successfully generates uncertainty aware surrogate models, via the Bayesian neural network with noise contrastive prior (BNN-NCP) technique, of the EuroPED plasma pedestal model using data from the JET-ILW pedestal database and subsequent model evaluations. All this conform EuroPED-NN. The BNN-NCP technique is proven to be a good fit for uncertainty aware surrogate models, matching the output results as a regular neural network, providing prediction's confidence as uncertainties, and highlighting the out of distribution (OOD) regions using surrogate model uncertainties. This provides critical insights into model robustness and reliability. EuroPED-NN has been physically validated, first, analyzing electron density $n_e\\!\\left(\u03c8_{\\text{pol}}=0.94\\right)$ with respect to increasing plasma current, $I_p$, and second, validating the $\u0394-\u03b2_{p,ped}$ relation associated with the EuroPED model. Affirming the robustness of the underlying physics learned by the surrogate model.",
        "subjects": [
            "physics.plasm-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00776",
        "abstract url": "https://arxiv.org/abs/2402.00776",
        "title": "Hybrid Quantum Vision Transformers for Event Classification in High Energy Physics",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum",
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Models based on vision transformer architectures are considered state-of-the-art when it comes to image classification tasks. However, they require extensive computational resources both for training and deployment. The problem is exacerbated as the amount and complexity of the data increases. Quantum-based vision transformer models could potentially alleviate this issue by reducing the training and operating time while maintaining the same predictive power. Although current quantum computers are not yet able to perform high-dimensional tasks yet, they do offer one of the most efficient solutions for the future. In this work, we construct several variations of a quantum hybrid vision transformer for a classification problem in high energy physics (distinguishing photons and electrons in the electromagnetic calorimeter). We test them against classical vision transformer architectures. Our findings indicate that the hybrid models can achieve comparable performance to their classical analogues with a similar number of parameters.",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "hep-ph",
            "stat.ML"
        ],
        "comment": "13 pages, 9 figures. Published version in a special issue \"Computational Aspects of Machine Learning and Quantum Computing\""
    },
    {
        "paper id": "2402.00793",
        "abstract url": "https://arxiv.org/abs/2402.00793",
        "title": "Distinguishing the Indistinguishable: Human Expertise in Algorithmic Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "X-ray"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach focuses on the use of human judgment to distinguish inputs which `look the same' to any feasible predictive algorithm. We argue that this framing clarifies the problem of human/AI collaboration in prediction tasks, as experts often have access to information -- particularly subjective information -- which is not encoded in the algorithm's training data. We use this insight to develop a set of principled algorithms for selectively incorporating human feedback only when it improves the performance of any feasible predictor. We find empirically that although algorithms often outperform their human counterparts on average, human judgment can significantly improve algorithmic predictions on specific instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly 30% of the patient population. Our approach provides a natural way of uncovering this heterogeneity and thus enabling effective human-AI collaboration.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00795",
        "abstract url": "https://arxiv.org/abs/2402.00795",
        "title": "LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Pretrained large language models (LLMs) are surprisingly effective at performing zero-shot tasks, including time-series forecasting. However, understanding the mechanisms behind such capabilities remains highly challenging due to the complexity of the models. In this paper, we study LLMs' ability to extrapolate the behavior of dynamical systems whose evolution is governed by principles of physical interest. Our results show that LLaMA 2, a language model trained primarily on texts, achieves accurate predictions of dynamical system time series without fine-tuning or prompt engineering. Moreover, the accuracy of the learned physical rules increases with the length of the input context window, revealing an in-context version of neural scaling law. Along the way, we present a flexible and efficient algorithm for extracting probability density functions of multi-digit numbers directly from LLMs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00803",
        "abstract url": "https://arxiv.org/abs/2402.00803",
        "title": "Signal Quality Auditing for Time-series Data",
        "rating": "-1.5",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Signal quality assessment (SQA) is required for monitoring the reliability of data acquisition systems, especially in AI-driven Predictive Maintenance (PMx) application contexts. SQA is vital for addressing \"silent failures\" of data acquisition hardware and software, which when unnoticed, misinform the users of data, creating the risk for incorrect decisions with unintended or even catastrophic consequences. We have developed an open-source software implementation of signal quality indices (SQIs) for the analysis of time-series data. We codify a range of SQIs, demonstrate them using established benchmark data, and show that they can be effective for signal quality assessment. We also study alternative approaches to denoising time-series data in an attempt to improve the quality of the already degraded signal, and evaluate them empirically on relevant real-world data. To our knowledge, our software toolkit is the first to provide an open source implementation of a broad range of signal quality assessment and improvement techniques validated on publicly available benchmark data for ease of reproducibility. The generality of our framework can be easily extended to assessing reliability of arbitrary time-series measurements in complex systems, especially when morphological patterns of the waveform shapes and signal periodicity are of key interest in downstream analyses.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00807",
        "abstract url": "https://arxiv.org/abs/2402.00807",
        "title": "Distilling Conditional Diffusion Models for Offline Reinforcement Learning through Trajectory Stitching",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep generative models have recently emerged as an effective approach to offline reinforcement learning. However, their large model size poses challenges in computation. We address this issue by proposing a knowledge distillation method based on data augmentation. In particular, high-return trajectories are generated from a conditional diffusion model, and they are blended with the original trajectories through a novel stitching algorithm that leverages a new reward generator. Applying the resulting dataset to behavioral cloning, the learned shallow policy whose size is much smaller outperforms or nearly matches deep generative planners on several D4RL benchmarks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00839",
        "abstract url": "https://arxiv.org/abs/2402.00839",
        "title": "X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection System",
        "rating": "-1.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The effectiveness of Intrusion Detection Systems (IDS) is critical in an era where cyber threats are becoming increasingly complex. Machine learning (ML) and deep learning (DL) models provide an efficient and accurate solution for identifying attacks and anomalies in computer networks. However, using ML and DL models in IDS has led to a trust deficit due to their non-transparent decision-making. This transparency gap in IDS research is significant, affecting confidence and accountability. To address, this paper introduces a novel Explainable IDS approach, called X-CBA, that leverages the structural advantages of Graph Neural Networks (GNNs) to effectively process network traffic data, while also adapting a new Explainable AI (XAI) methodology. Unlike most GNN-based IDS that depend on labeled network traffic and node features, thereby overlooking critical packet-level information, our approach leverages a broader range of traffic data through network flows, including edge attributes, to improve detection capabilities and adapt to novel threats. Through empirical testing, we establish that our approach not only achieves high accuracy with 99.47% in threat detection but also advances the field by providing clear, actionable explanations of its analytical outcomes. This research also aims to bridge the current gap and facilitate the broader integration of ML/DL technologies in cybersecurity defenses by offering a local and global explainability solution that is both precise and interpretable.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00851",
        "abstract url": "https://arxiv.org/abs/2402.00851",
        "title": "Data Augmentation Scheme for Raman Spectra with Highly Correlated Annotations",
        "rating": "-1.5",
        "keywords": [
            [
                "biotechnology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In biotechnology Raman Spectroscopy is rapidly gaining popularity as a process analytical technology (PAT) that measures cell densities, substrate- and product concentrations. As it records vibrational modes of molecules it provides that information non-invasively in a single spectrum. Typically, partial least squares (PLS) is the model of choice to infer information about variables of interest from the spectra. However, biological processes are known for their complexity where convolutional neural networks (CNN) present a powerful alternative. They can handle non-Gaussian noise and account for beam misalignment, pixel malfunctions or the presence of additional substances. However, they require a lot of data during model training, and they pick up non-linear dependencies in the process variables. In this work, we exploit the additive nature of spectra in order to generate additional data points from a given dataset that have statistically independent labels so that a network trained on such data exhibits low correlations between the model predictions. We show that training a CNN on these generated data points improves the performance on datasets where the annotations do not bear the same correlation as the dataset that was used for model training. This data augmentation technique enables us to reuse spectra as training data for new contexts that exhibit different correlations. The additional data allows for building a better and more robust model. This is of interest in scenarios where large amounts of historical data are available but are currently not used for model training. We demonstrate the capabilities of the proposed method using synthetic spectra of Ralstonia eutropha batch cultivations to monitor substrate, biomass and polyhydroxyalkanoate (PHA) biopolymer concentrations during of the experiments.",
        "subjects": [
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00920",
        "abstract url": "https://arxiv.org/abs/2402.00920",
        "title": "Deep Learning Approaches for Network Traffic Classification in the Internet of Things (IoT): A Survey",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Internet of Things (IoT) has witnessed unprecedented growth, resulting in a massive influx of diverse network traffic from interconnected devices. Effectively classifying this network traffic is crucial for optimizing resource allocation, enhancing security measures, and ensuring efficient network management in IoT systems. Deep learning has emerged as a powerful technique for network traffic classification due to its ability to automatically learn complex patterns and representations from raw data. This survey paper aims to provide a comprehensive overview of the existing deep learning approaches employed in network traffic classification specifically tailored for IoT environments. By systematically analyzing and categorizing the latest research contributions in this domain, we explore the strengths and limitations of various deep learning models in handling the unique challenges posed by IoT network traffic. Through this survey, we aim to offer researchers and practitioners valuable insights, identify research gaps, and provide directions for future research to further enhance the effectiveness and efficiency of deep learning-based network traffic classification in IoT.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00944",
        "abstract url": "https://arxiv.org/abs/2402.00944",
        "title": "NCoder -- A Quantum Field Theory approach to encoding data",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper we present a novel approach to interpretable AI inspired by Quantum Field Theory (QFT) which we call the NCoder. The NCoder is a modified autoencoder neural network whose latent layer is prescribed to be a subset of $n$-point correlation functions. Regarding images as draws from a lattice field theory, this architecture mimics the task of perturbatively constructing the effective action of the theory order by order in an expansion using Feynman diagrams. Alternatively, the NCoder may be regarded as simulating the procedure of statistical inference whereby high dimensional data is first summarized in terms of several lower dimensional summary statistics (here the $n$-point correlation functions), and subsequent out-of-sample data is generated by inferring the data generating distribution from these statistics. In this way the NCoder suggests a fascinating correspondence between perturbative renormalizability and the sufficiency of models. We demonstrate the efficacy of the NCoder by applying it to the generation of MNIST images, and find that generated images can be correctly classified using only information from the first three $n$-point functions of the image distribution.",
        "subjects": [
            "hep-th",
            "cond-mat.dis-nn",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01000",
        "abstract url": "https://arxiv.org/abs/2402.01000",
        "title": "Multivariate Probabilistic Time Series Forecasting with Correlated Errors",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and it can seamlessly integrate with any model with Gaussian-distributed errors. We empirically demonstrate these properties using two distinct neural forecasting models-GPVar and Transformer. Our experimental results confirm the effectiveness of our method in enhancing predictive accuracy and the quality of uncertainty quantification on multiple real-world datasets.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "This paper extends the work presented in arXiv:2305.17028 to a multivariate setting"
    },
    {
        "paper id": "2402.01020",
        "abstract url": "https://arxiv.org/abs/2402.01020",
        "title": "Quantifying analogy of concepts via ologs and wiring diagrams",
        "rating": "-1.5",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We build on the theory of ontology logs (ologs) created by Spivak and Kent, and define a notion of wiring diagrams. In this article, a wiring diagram is a finite directed labelled graph. The labels correspond to types in an olog; they can also be interpreted as readings of sensors in an autonomous system. As such, wiring diagrams can be used as a framework for an autonomous system to form abstract concepts. We show that the graphs underlying skeleton wiring diagrams form a category. This allows skeleton wiring diagrams to be compared and manipulated using techniques from both graph theory and category theory. We also extend the usual definition of graph edit distance to the case of wiring diagrams by using operations only available to wiring diagrams, leading to a metric on the set of all skeleton wiring diagrams. In the end, we give an extended example on calculating the distance between two concepts represented by wiring diagrams, and explain how to apply our framework to any application domain.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.DM",
            "math.CO",
            "math.CT"
        ],
        "comment": "30 pages"
    },
    {
        "paper id": "2402.01047",
        "abstract url": "https://arxiv.org/abs/2402.01047",
        "title": "Ultra Fast Transformers on FPGAs for Particle Physics Experiments",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work introduces a highly efficient implementation of the transformer architecture on a Field-Programmable Gate Array (FPGA) by using the \\texttt{hls4ml} tool. Given the demonstrated effectiveness of transformer models in addressing a wide range of problems, their application in experimental triggers within particle physics becomes a subject of significant interest. In this work, we have implemented critical components of a transformer model, such as multi-head attention and softmax layers. To evaluate the effectiveness of our implementation, we have focused on a particle physics jet flavor tagging problem, employing a public dataset. We recorded latency under 2 $\u03bc$s on the Xilinx UltraScale+ FPGA, which is compatible with hardware trigger requirements at the CERN Large Hadron Collider experiments.",
        "subjects": [
            "cs.LG",
            "cs.AR",
            "hep-ex"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2402.01077",
        "abstract url": "https://arxiv.org/abs/2402.01077",
        "title": "Recent Advances in Predictive Modeling with Electronic Health Records",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The development of electronic health records (EHR) systems has enabled the collection of a vast amount of digitized patient data. However, utilizing EHR data for predictive modeling presents several challenges due to its unique characteristics. With the advancements in machine learning techniques, deep learning has demonstrated its superiority in various applications, including healthcare. This survey systematically reviews recent advances in deep learning-based predictive models using EHR data. Specifically, we begin by introducing the background of EHR data and providing a mathematical definition of the predictive modeling task. We then categorize and summarize predictive deep models from multiple perspectives. Furthermore, we present benchmarks and toolkits relevant to predictive modeling in healthcare. Finally, we conclude this survey by discussing open challenges and suggesting promising directions for future research.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01107",
        "abstract url": "https://arxiv.org/abs/2402.01107",
        "title": "Simulation of Graph Algorithms with Looped Transformers",
        "rating": "-1.5",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The execution of graph algorithms using neural networks has recently attracted significant interest due to promising empirical progress. This motivates further understanding of how neural networks can replicate reasoning steps with relational data. In this work, we study the ability of transformer networks to simulate algorithms on graphs from a theoretical perspective. The architecture that we utilize is a looped transformer with extra attention heads that interact with the graph. We prove by construction that this architecture can simulate algorithms such as Dijkstra's shortest path algorithm, Breadth- and Depth-First Search, and Kosaraju's strongly connected components algorithm. The width of the network does not increase with the size of the input graph, which implies that the network can simulate the above algorithms for any graph. Despite this property, we show that there is a limit to simulation in our solution due to finite precision. Finally, we show a Turing Completeness result with constant width when the extra attention heads are utilized.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DS"
        ],
        "comment": "45 pages, 2 figures"
    },
    {
        "paper id": "2402.01790",
        "abstract url": "https://arxiv.org/abs/2402.01790",
        "title": "An introduction to graphical tensor notation for mechanistic interpretability",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Graphical tensor notation is a simple way of denoting linear operations on tensors, originating from physics. Modern deep learning consists almost entirely of operations on or between tensors, so easily understanding tensor operations is quite important for understanding these systems. This is especially true when attempting to reverse-engineer the algorithms learned by a neural network in order to understand its behavior: a field known as mechanistic interpretability. It's often easy to get confused about which operations are happening between tensors and lose sight of the overall structure, but graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences. The first half of this document introduces the notation and applies it to some decompositions (SVD, CP, Tucker, and tensor network decompositions), while the second half applies it to some existing some foundational approaches for mechanistically understanding language models, loosely following ``A Mathematical Framework for Transformer Circuits'', then constructing an example ``induction head'' circuit in graphical tensor notation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "30 pages, 75 figures"
    },
    {
        "paper id": "2402.07915",
        "abstract url": "https://arxiv.org/abs/2402.07915",
        "title": "Research on Older Adults' Interaction with E-Health Interface Based on Explainable Artificial Intelligence",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposed a comprehensive mixed-methods framework with varied samples of older adults, including user experience, usability assessments, and in-depth interviews with the integration of Explainable Artificial Intelligence (XAI) methods. The experience of older adults' interaction with the Ehealth interface is collected through interviews and transformed into operatable databases whereas XAI methods are utilized to explain the collected interview results in this research work. The results show that XAI-infused e-health interfaces could play an important role in bridging the age-related digital divide by investigating elders' preferences when interacting with E-health interfaces. Furthermore, the study identifies important design factors, such as intuitive visualization and straightforward explanations, that are critical for creating efficient Human Computer Interaction (HCI) tools among older users. Furthermore, this study emphasizes the revolutionary potential of XAI in e-health interfaces for older users, emphasizing the importance of transparency and understandability in HCI-driven healthcare solutions. This study's findings have far-reaching implications for the design and development of user-centric e-health technologies, intending to increase the overall well-being of older adults.",
        "subjects": [
            "cs.HC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08797",
        "abstract url": "https://arxiv.org/abs/2403.08797",
        "title": "Evolutionary Algorithms Simulating Molecular Evolution: A New Field Proposal",
        "rating": "-1.5",
        "keywords": [
            [
                "biologists",
                "DNA"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The genetic blueprint for the essential functions of life is encoded in DNA, which is translated into proteins -- the engines driving most of our metabolic processes. Recent advancements in genome sequencing have unveiled a vast diversity of protein families, but compared to the massive search space of all possible amino acid sequences, the set of known functional families is minimal. One could say nature has a limited protein \"vocabulary.\" The major question for computational biologists, therefore, is whether this vocabulary can be expanded to include useful proteins that went extinct long ago, or maybe never evolved in the first place. We outline a computational approach to solving this problem. By merging evolutionary algorithms, machine learning (ML), and bioinformatics, we can facilitate the development of completely novel proteins which have never existed before. We envision this work forming a new sub-field of computational evolution we dub evolutionary algorithms simulating molecular evolution (EASME).",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": "7 pages, 2 figures"
    },
    {
        "paper id": "2405.01540",
        "abstract url": "https://arxiv.org/abs/2405.01540",
        "title": "Universal Imitation Games",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Alan Turing proposed in 1950 a framework called an imitation game to decide if a machine could think. Using mathematics developed largely after Turing -- category theory -- we analyze a broader class of universal imitation games (UIGs), which includes static, dynamic, and evolutionary games. In static games, the participants are in a steady state. In dynamic UIGs, \"learner\" participants are trying to imitate \"teacher\" participants over the long run. In evolutionary UIGs, the participants are competing against each other in an evolutionary game, and participants can go extinct and be replaced by others with higher fitness. We use the framework of category theory -- in particular, two influential results by Yoneda -- to characterize each type of imitation game. Universal properties in categories are defined by initial and final objects. We characterize dynamic UIGs where participants are learning by inductive inference as initial algebras over well-founded sets, and contrast them with participants learning by conductive inference over the final coalgebra of non-well-founded sets. We briefly discuss the extension of our categorical framework for UIGs to imitation games on quantum computers.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "98 pages. arXiv admin note: substantial text overlap with arXiv:2402.18732"
    },
    {
        "paper id": "2402.00375",
        "abstract url": "https://arxiv.org/abs/2402.00375",
        "title": "Disentangled Multimodal Brain MR Image Translation via Transformer-based Modality Infuser",
        "rating": "-2",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "diagnosis",
                "disease",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal Magnetic Resonance (MR) Imaging plays a crucial role in disease diagnosis due to its ability to provide complementary information by analyzing a relationship between multimodal images on the same subject. Acquiring all MR modalities, however, can be expensive, and, during a scanning session, certain MR images may be missed depending on the study protocol. The typical solution would be to synthesize the missing modalities from the acquired images such as using generative adversarial networks (GANs). Yet, GANs constructed with convolutional neural networks (CNNs) are likely to suffer from a lack of global relationships and mechanisms to condition the desired modality. To address this, in this work, we propose a transformer-based modality infuser designed to synthesize multimodal brain MR images. In our method, we extract modality-agnostic features from the encoder and then transform them into modality-specific features using the modality infuser. Furthermore, the modality infuser captures long-range relationships among all brain structures, leading to the generation of more realistic images. We carried out experiments on the BraTS 2018 dataset, translating between four MR modalities, and our experimental results demonstrate the superiority of our proposed method in terms of synthesis quality. In addition, we conducted experiments on a brain tumor segmentation task and different conditioning methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2402.00378",
        "abstract url": "https://arxiv.org/abs/2402.00378",
        "title": "On the Minimum Depth of Circuits with Linear Number of Wires Encoding Good Codes",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Let $S_d(n)$ denote the minimum number of wires of a depth-$d$ (unbounded fan-in) circuit encoding an error-correcting code $C:\\{0, 1\\}^n \\to \\{0, 1\\}^{32n}$ with distance at least $4n$. G\u00e1l, Hansen, Kouck\u00fd, Pudl\u00e1k, and Viola [IEEE Trans. Inform. Theory 59(10), 2013] proved that $S_d(n) = \u0398_d(\u03bb_d(n)\\cdot n)$ for any fixed $d \\ge 3$. By improving their construction and analysis, we prove $S_d(n)= O(\u03bb_d(n)\\cdot n)$. Letting $d = \u03b1(n)$, a version of the inverse Ackermann function, we obtain circuits of linear size. This depth $\u03b1(n)$ is the minimum possible to within an additive constant 2; we credit the nearly-matching depth lower bound to G\u00e1l et al., since it directly follows their method (although not explicitly claimed or fully verified in that work), and is obtained by making some constants explicit in a graph-theoretic lemma of Pudl\u00e1k [Combinatorica, 14(2), 1994], extending it to super-constant depths. We also study a subclass of MDS codes $C: \\mathbb{F}^n \\to \\mathbb{F}^m$ characterized by the Hamming-distance relation $\\mathrm{dist}(C(x), C(y)) \\ge m - \\mathrm{dist}(x, y) + 1$ for any distinct $x, y \\in \\mathbb{F}^n$. (For linear codes this is equivalent to the generator matrix being totally invertible.) We call these superconcentrator-induced codes, and we show their tight connection with superconcentrators. Specifically, we observe that any linear or nonlinear circuit encoding a superconcentrator-induced code must be a superconcentrator graph, and any superconcentrator graph can be converted to a linear circuit, over a sufficiently large field (exponential in the size of the graph), encoding a superconcentrator-induced code.",
        "subjects": [
            "cs.CC",
            "cs.IT"
        ],
        "comment": "COCOON'23. Correction to the conference version: noted G\u00e1l et al.'s description/use (in the journal version) of rate-boosting of codes"
    },
    {
        "paper id": "2402.00467",
        "abstract url": "https://arxiv.org/abs/2402.00467",
        "title": "Can you see me now? Blind spot estimation for autonomous vehicles using scenario-based simulation with random reference sensors",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "LiDAR"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce a method for estimating blind spots for sensor setups of autonomous or automated vehicles and/or robotics applications. In comparison to previous methods that rely on geometric approximations, our presented approach provides more realistic coverage estimates by utilizing accurate and detailed 3D simulation environments. Our method leverages point clouds from LiDAR sensors or camera depth images from high-fidelity simulations of target scenarios to provide accurate and actionable visibility estimates. A Monte Carlo-based reference sensor simulation enables us to accurately estimate blind spot size as a metric of coverage, as well as detection probabilities of objects at arbitrary positions.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00535",
        "abstract url": "https://arxiv.org/abs/2402.00535",
        "title": "A Low-Cost Multi-Band Waveform Security Framework in Resource-Constrained Communications",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Traditional physical layer secure beamforming is achieved via precoding before signal transmission using channel state information (CSI). However, imperfect CSI will compromise the performance with imperfect beamforming and potential information leakage. In addition, multiple RF chains and antennas are needed to support the narrow beam generation, which complicates hardware implementation and is not suitable for resource-constrained Internet-of-Things (IoT) devices. Moreover, with the advancement of hardware and artificial intelligence (AI), low-cost and intelligent eavesdropping to wireless communications is becoming increasingly detrimental. In this paper, we propose a multi-carrier based multi-band waveform-defined security (WDS) framework, independent from CSI and RF chains, to defend against AI eavesdropping. Ideally, the continuous variations of sub-band structures lead to an infinite number of spectral features, which can potentially prevent brute-force eavesdropping. Sub-band spectral pattern information is efficiently constructed at legitimate users via a proposed chaotic sequence generator. A novel security metric, termed signal classification accuracy (SCA), is used to evaluate the security robustness under AI eavesdropping. Communication error probability and complexity are also investigated to show the reliability and practical capability of the proposed framework. Finally, compared to traditional secure beamforming techniques, the proposed multi-band WDS framework reduces power consumption by up to six times.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00594",
        "abstract url": "https://arxiv.org/abs/2402.00594",
        "title": "Identifying relevant Factors of Requirements Quality: an industrial Case Study",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "[Context and Motivation]: The quality of requirements specifications impacts subsequent, dependent software engineering activities. Requirements quality defects like ambiguous statements can result in incomplete or wrong features and even lead to budget overrun or project failure. [Problem]: Attempts at measuring the impact of requirements quality have been held back by the vast amount of interacting factors. Requirements quality research lacks an understanding of which factors are relevant in practice. [Principal Ideas and Results]: We conduct a case study considering data from both interview transcripts and issue reports to identify relevant factors of requirements quality. The results include 17 factors and 11 interaction effects relevant to the case company. [Contribution]: The results contribute empirical evidence that (1) strengthens existing requirements engineering theories and (2) advances industry-relevant requirements quality research.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00622",
        "abstract url": "https://arxiv.org/abs/2402.00622",
        "title": "Gain of Grain: A Film Grain Handling Toolchain for VVC-based Open Implementations",
        "rating": "-2",
        "keywords": [
            [
                "quality assessment"
            ]
        ],
        "abstract": "Film grain is a distinctive visual characteristic cherished by filmmakers and cinephiles for its ability to evoke nostalgia and artistic aesthetics. However, faithful preservation of film grain during encoding poses unique challenges. Film grain introduces random noise, complicating traditional compression techniques. Consequently, specialized algorithms and encoding strategies have emerged, aiming to strike a harmonious equilibrium. This paper delves into the nuanced realm of film grain handling in Versatile Video Coding (VVC) encoding. We explore the delicate balance between retaining the cinematic charm of film grain and achieving efficient compression. Moreover, we discuss the importance of perceptual quality assessment and adaptive encoding techniques in preserving film grain fidelity. Additionally, we delve into the impact of film grain handling on bitrate control and compression efficiency using VVenC, an open and optimized VVC encoder. Understanding the role of film grain and its nuanced treatment within encoders becomes increasingly pivotal for delivering high-quality, grain-inclusive content in the digital age.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "2024 Mile High Video (MHV)"
    },
    {
        "paper id": "2402.00637",
        "abstract url": "https://arxiv.org/abs/2402.00637",
        "title": "Fisheye Camera and Ultrasonic Sensor Fusion For Near-Field Obstacle Perception in Bird's-Eye-View",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate obstacle identification represents a fundamental challenge within the scope of near-field perception for autonomous driving. Conventionally, fisheye cameras are frequently employed for comprehensive surround-view perception, including rear-view obstacle localization. However, the performance of such cameras can significantly deteriorate in low-light conditions, during nighttime, or when subjected to intense sun glare. Conversely, cost-effective sensors like ultrasonic sensors remain largely unaffected under these conditions. Therefore, we present, to our knowledge, the first end-to-end multimodal fusion model tailored for efficient obstacle perception in a bird's-eye-view (BEV) perspective, utilizing fisheye cameras and ultrasonic sensors. Initially, ResNeXt-50 is employed as a set of unimodal encoders to extract features specific to each modality. Subsequently, the feature space associated with the visible spectrum undergoes transformation into BEV. The fusion of these two modalities is facilitated via concatenation. At the same time, the ultrasonic spectrum-based unimodal feature maps pass through content-aware dilated convolution, applied to mitigate the sensor misalignment between two sensors in the fused feature space. Finally, the fused features are utilized by a two-stage semantic occupancy decoder to generate grid-wise predictions for precise obstacle perception. We conduct a systematic investigation to determine the optimal strategy for multimodal fusion of both sensors. We provide insights into our dataset creation procedures, annotation guidelines, and perform a thorough data analysis to ensure adequate coverage of all scenarios. When applied to our dataset, the experimental results underscore the robustness and effectiveness of our proposed multimodal fusion approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 12 Figures, 6 tables"
    },
    {
        "paper id": "2402.00675",
        "abstract url": "https://arxiv.org/abs/2402.00675",
        "title": "On Modular Algorithms and Butterfly Operations in Number Theoretic Transform",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Number theoretic transform (NTT) has been a very useful tool in computations for number theory, algebra and cryptography. Its performance affects some post-quantum cryptosystems. In this paper, we discuss the butterfly operation of NTT. This basic module of NTT requires heavy modular arithmetics. Montgomery reduction is commonly used in this setting. Recently several variants of Montgomery algorithm have been proposed for the purpose of speeding up NTT. We observe that the Chinese remainder theorem (CRT) can be involved in this type of algorithms in natural and transparent ways. In the first part of the paper, a framework of using CRT to model Montgomery type algorithms is described. The derivation of these algorithms as well as their correctness are all treated in the CRT framework. Under our approach, some problems of a modular reduction algorithm (published in IACR Transactions on Cryptographic Hardware and Embedded Systems, doi:10.46586/tches.v2022.i4.614-636 ) are identified, and a counterexample is generated to show that the algorithm is incorrect. In the second part of the paper, we modify a modular multiplication algorithm of Plantard to suite the butterfly structure by Scott, an improved computation of the butterfly module for NTT is obtained. Experiments show that the method performs better compared to NTT implementations using previous popular methods.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2402.00683",
        "abstract url": "https://arxiv.org/abs/2402.00683",
        "title": "WayFASTER: a Self-Supervised Traversability Prediction for Increased Navigation Awareness",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "Accurate and robust navigation in unstructured environments requires fusing data from multiple sensors. Such fusion ensures that the robot is better aware of its surroundings, including areas of the environment that are not immediately visible but were visible at a different time. To solve this problem, we propose a method for traversability prediction in challenging outdoor environments using a sequence of RGB and depth images fused with pose estimations. Our method, termed WayFASTER (Waypoints-Free Autonomous System for Traversability with Enhanced Robustness), uses experience data recorded from a receding horizon estimator to train a self-supervised neural network for traversability prediction, eliminating the need for heuristics. Our experiments demonstrate that our method excels at avoiding obstacles, and correctly detects that traversable terrains, such as tall grass, can be navigable. By using a sequence of images, WayFASTER significantly enhances the robot's awareness of its surroundings, enabling it to predict the traversability of terrains that are not immediately visible. This enhanced awareness contributes to better navigation performance in environments where such predictive capabilities are essential.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)"
    },
    {
        "paper id": "2402.00698",
        "abstract url": "https://arxiv.org/abs/2402.00698",
        "title": "Time-Series Analysis Approach for Improving Energy Efficiency of a Fixed-Route Vessel in Short-Sea Shipping",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Several approaches have been developed for improving the ship energy efficiency, thereby reducing operating costs and ensuring compliance with climate change mitigation regulations. Many of these approaches will heavily depend on measured data from onboard IoT devices, including operational and environmental information, as well as external data sources for additional navigational data. In this paper, we develop a framework that implements time-series analysis techniques to optimize the vessel's speed profile for improving the vessel's energy efficiency. We present a case study involving a real-world data from a passenger vessel that was collected over a span of 15 months in the south of Sweden. The results indicate that the implemented models exhibit a range of outcomes and adaptability across different scenarios. The findings highlight the effectiveness of time-series analysis approach for optimizing vessel voyages within the context of constrained landscapes, as often seen in short-sea shipping.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "8 pages, 7 figures and four tables"
    },
    {
        "paper id": "2402.00703",
        "abstract url": "https://arxiv.org/abs/2402.00703",
        "title": "Vehicle Perception from Satellite",
        "rating": "-2",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Satellites are capable of capturing high-resolution videos. It makes vehicle perception from satellite become possible. Compared to street surveillance, drive recorder or other equipments, satellite videos provide a much broader city-scale view, so that the global dynamic scene of the traffic are captured and displayed. Traffic monitoring from satellite is a new task with great potential applications, including traffic jams prediction, path planning, vehicle dispatching, \\emph{etc.}. Practically, limited by the resolution and view, the captured vehicles are very tiny (a few pixels) and move slowly. Worse still, these satellites are in Low Earth Orbit (LEO) to capture such high-resolution videos, so the background is also moving. Under this circumstance, traffic monitoring from the satellite view is an extremely challenging task. To attract more researchers into this field, we build a large-scale benchmark for traffic monitoring from satellite. It supports several tasks, including tiny object detection, counting and density estimation. The dataset is constructed based on 12 satellite videos and 14 synthetic videos recorded from GTA-V. They are separated into 408 video clips, which contain 7,336 real satellite images and 1,960 synthetic images. 128,801 vehicles are annotated totally, and the number of vehicles in each image varies from 0 to 101. Several classic and state-of-the-art approaches in traditional computer vision are evaluated on the datasets, so as to compare the performance of different approaches, analyze the challenges in this task, and discuss the future prospects. The dataset is available at: https://github.com/Chenxi1510/Vehicle-Perception-from-Satellite-Videos.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00724",
        "abstract url": "https://arxiv.org/abs/2402.00724",
        "title": "Automatic Segmentation of the Spinal Cord Nerve Rootlets",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "MRI"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Precise identification of spinal nerve rootlets is relevant to delineate spinal levels for the study of functional activity in the spinal cord. The goal of this study was to develop an automatic method for the semantic segmentation of spinal nerve rootlets from T2-weighted magnetic resonance imaging (MRI) scans. Images from two open-access MRI datasets were used to train a 3D multi-class convolutional neural network using an active learning approach to segment C2-C8 dorsal nerve rootlets. Each output class corresponds to a spinal level. The method was tested on 3T T2-weighted images from datasets unseen during training to assess inter-site, inter-session, and inter-resolution variability. The test Dice score was 0.67 +- 0.16 (mean +- standard deviation across testing images and rootlets levels), suggesting a good performance. The method also demonstrated low inter-vendor and inter-site variability (coefficient of variation <= 1.41 %), as well as low inter-session variability (coefficient of variation <= 1.30 %) indicating stable predictions across different MRI vendors, sites, and sessions. The proposed methodology is open-source and readily available in the Spinal Cord Toolbox (SCT) v6.2 and higher.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00734",
        "abstract url": "https://arxiv.org/abs/2402.00734",
        "title": "BIOMERO: BioImage analysis in OMERO",
        "rating": "-2",
        "keywords": [
            [
                "BIOMERO"
            ]
        ],
        "abstract": "In the rapidly evolving field of bioimaging, the integration and orchestration of Findable, Accessible, Interoperable, and Reusable (FAIR) image analysis workflows remains a challenge. We introduce BIOMERO, a bridge connecting OMERO, a renowned bioimaging data management platform, FAIR workflows and high-performance computing (HPC) environments. BIOMERO, featuring our opensource Python library \"OMERO Slurm Client\", facilitates seamless execution of FAIR workflows, particularly for large datasets from High Content or High Throughput Screening. BIOMERO empowers researchers by eliminating the need for specialized knowledge, enabling scalable image processing directly from OMERO. BIOMERO notably supports the sharing and utilization of FAIR workflows between OMERO, Cytomine/BIAFLOWS, and other bioimaging communities. BIOMERO will promote the widespread adoption of FAIR workflows, emphasizing reusability, across the realm of bioimaging research. Its user-friendly interface will empower users, including those without technical expertise, to seamlessly apply these workflows to their datasets, democratizing the utilization of AI by the broader research community.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "20 pages, 3 figures, 4 pages supplemental information; submitted to Cell Patterns; for software, see https://github.com/NL-BioImaging/biomero"
    },
    {
        "paper id": "2402.00812",
        "abstract url": "https://arxiv.org/abs/2402.00812",
        "title": "Examining the Influence of Digital Phantom Models in Virtual Imaging Trials for Tomographic Breast Imaging",
        "rating": "-2",
        "keywords": [
            [
                "voxel"
            ],
            [
                "medical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: Digital phantoms are one of the key components of virtual imaging trials (VITs) that aim to assess and optimize new medical imaging systems and algorithms. However, these phantoms vary in their voxel resolution, appearance, and structural details. This study aims to examine whether and how variations between digital phantoms influence system optimization with digital breast tomosynthesis (DBT) as a chosen modality. Methods: We selected widely used and open-access digital breast phantoms generated with different methods. For each phantom type, we created an ensemble of DBT images to test acquisition strategies. Human observer localization ROC (LROC) was used to assess observer performance studies for each case. Noise power spectrum (NPS) was estimated to compare the phantom structural components. Further, we computed several gaze metrics to quantify the gaze pattern when viewing images generated from different phantom types. Results: Our LROC results show that the arc samplings for peak performance were approximately 2.5 degrees and 6 degrees in Bakic and XCAT breast phantoms respectively for 3-mm lesion detection tasks and indicate that system optimization outcomes from VITs can vary with phantom types and structural frequency components. Additionally, a significant correlation (p= 0.01) between gaze metrics and diagnostic performance suggests that gaze analysis can be used to understand and evaluate task difficulty in VITs.",
        "subjects": [
            "physics.med-ph",
            "cs.HC",
            "eess.IV",
            "eess.SP",
            "physics.app-ph"
        ],
        "comment": "20 pages, 8 figures"
    },
    {
        "paper id": "2402.00925",
        "abstract url": "https://arxiv.org/abs/2402.00925",
        "title": "A Practical Evaluation of Commercial Industrial Augmented Reality Systems in an Industry 4.0 Shipyard",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "The principles of the Industry 4.0 are guiding manufacturing companies towards more automated and computerized factories. Such principles are also applied in shipbuilding, which usually involves numerous complex processes whose automation will improve its efficiency and performance. Navantia, a company that has been building ships for 300 years, is modernizing its shipyards according to the Industry 4.0 principles with the help of the latest technologies. Augmented Reality (AR), which when utilized in an industrial environment is called Industrial AR (IAR), is one of such technologies, since it can be applied in numerous situations in order to provide useful and attractive interfaces that allow shipyard operators to obtain information on their tasks and to interact with certain elements that surround them. This article first reviews the state of the art on IAR applications for shipbuilding and smart manufacturing. Then, the most relevant IAR hardware and software tools are detailed, as well as the main use cases for the application of IAR in a shipyard. Next, it is described Navantia's IAR system, which is based on a fog-computing architecture. Such a system is evaluated when making use of three IAR devices (a smartphone, a tablet and a pair of smart glasses), two AR SDKs (ARToolKit and Vuforia) and multiple IAR markers, with the objective of determining their performance in a shipyard workshop and inside a ship under construction. The results obtained show remarkable performance differences among the different IAR tools and the impact of factors like lighting, pointing out the best combinations of markers, hardware and software to be used depending on the characteristics of the shipyard scenario.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted version of an IEEE Access journal paper"
    },
    {
        "paper id": "2402.00995",
        "abstract url": "https://arxiv.org/abs/2402.00995",
        "title": "Joint Devices and IRSs Association for Terahertz Communications in Industrial IoT Networks",
        "rating": "-2",
        "keywords": [
            [
                "Industrial",
                "IoT"
            ]
        ],
        "abstract": "The Industrial Internet of Things (IIoT) enables industries to build large interconnected systems utilizing various technologies that require high data rates. Terahertz (THz) communication is envisioned as a candidate technology for achieving data rates of several terabits-per-second (Tbps). Despite this, establishing a reliable communication link at THz frequencies remains a challenge due to high pathloss and molecular absorption. To overcome these limitations, this paper proposes using intelligent reconfigurable surfaces (IRSs) with THz communications to enable future smart factories for the IIoT. In this paper, we formulate the power allocation and joint IIoT device and IRS association (JIIA) problem, which is a mixed-integer nonlinear programming (MINLP) problem. {Furthermore, the JIIA problem aims to maximize the sum rate with imperfect channel state information (CSI).} To address this non-deterministic polynomial-time hard (NP-hard) problem, we decompose the problem into multiple sub-problems, which we solve iteratively. Specifically, we propose a Gale-Shapley algorithm-based JIIA solution to obtain stable matching between uplink and downlink IRSs. {We validate the proposed solution by comparing the Gale-Shapley-based JIIA algorithm with exhaustive search (ES), greedy search (GS), and random association (RA) with imperfect CSI.} The complexity analysis shows that our algorithm is more efficient than the ES.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01002",
        "abstract url": "https://arxiv.org/abs/2402.01002",
        "title": "AI-generated faces free from racial and gender stereotypes",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image generative AI models such as Stable Diffusion are used daily by millions worldwide. However, many have raised concerns regarding how these models amplify racial and gender stereotypes. To study this phenomenon, we develop a classifier to predict the race, gender, and age group of any given face image, and show that it achieves state-of-the-art performance. Using this classifier, we quantify biases in Stable Diffusion across six races, two genders, five age groups, 32 professions, and eight attributes. We then propose novel debiasing solutions that outperform state-of-the-art alternatives. Additionally, we examine the degree to which Stable Diffusion depicts individuals of the same race as being similar to one another. This analysis reveals a high degree of stereotyping, e.g., depicting most middle eastern males as being dark-skinned, bearded, and wearing a traditional headdress. We address these limitations by proposing yet another novel solution that increases facial diversity across genders and racial groups. Our solutions are open-sourced and made publicly available.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "26 pages, 6 figures"
    },
    {
        "paper id": "2402.01033",
        "abstract url": "https://arxiv.org/abs/2402.01033",
        "title": "End-to-End Deep Learning for TDD MIMO Systems in the 6G Upper Midbands",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "This paper proposes and analyzes novel deep learning methods for downlink (DL) single-user multiple-input multiple-output (SU-MIMO) and multi-user MIMO (MU-MIMO) systems operating in time division duplex (TDD) mode. A motivating application is the 6G upper midbands (7-24 GHz), where the base station (BS) antenna arrays are large, user equipment (UE) array sizes are moderate, and theoretically optimal approaches are practically infeasible for several reasons. To deal with uplink (UL) pilot overhead and low signal power issues, we introduce the channel-adaptive pilot, as part of an analog channel state information feedback mechanism. Deep neural network (DNN)-generated pilots are used to linearly transform the UL channel matrix into lower-dimensional latent vectors. Meanwhile, the BS employs a second DNN that processes the received UL pilots to directly generate near-optimal DL precoders. The training is end-to-end which exploits synergies between the two DNNs. For MU-MIMO precoding, we propose a DNN structure inspired by theoretically optimum linear precoding. The proposed methods are evaluated against genie-aided upper bounds and conventional approaches, using realistic upper midband datasets. Numerical results demonstrate the potential of our approach to achieve significantly increased sum-rate, particularly at moderate to high signal-to-noise ratio (SNR) and when UL pilot overhead is constrained.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01040",
        "abstract url": "https://arxiv.org/abs/2402.01040",
        "title": "Everyday Uses of Music Listening and Music Technologies by Caregivers and People with Dementia: Survey and Focus Group Study",
        "rating": "-2",
        "keywords": [
            [
                "diagnosis"
            ]
        ],
        "abstract": "Music is a valuable non-pharmacological tool that provides benefits for people with dementia, and there is interest in designing technologies to support music use in dementia care. To ensure music technologies are appropriately designed for supporting caregivers and people living with dementia, there remains a need to better understand how music is currently used in everyday care at home. We aimed to understand how people with dementia and their caregivers use music technologies in everyday caring, as well as challenges they experience using music and technology. This study used a mixed methods design. A survey was completed by 77 caregivers and people with dementia to understand their use of music and technology. Of these, 18 survey respondents (12 family caregivers, 6 people living with dementia) participated in focus groups about their experiences of using music and technology in care. Transcripts were analysed with reflexive thematic analysis. Most survey respondents used music often in their daily lives, reporting a range of music technologies such as CDs, radio, and streaming. Focus groups highlighted benefits and challenges of music technologies in everyday care. Participants used music and music technologies to regulate mood, provide joy, facilitate social connection, encourage reminiscence, provide continuity before and after diagnosis, and to make caregiving easier. Challenges of using music technology in care included difficulties staying up to date with evolving technology, and low self-efficacy for technology use expressed by people living with dementia. Evidently, people living with dementia and their caregivers use music technologies to support their everyday care needs. Results suggest opportunities to design technologies enabling easier access to music and supporting people living with dementia with recreational and therapeutic music listening and music-based activities.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01086",
        "abstract url": "https://arxiv.org/abs/2402.01086",
        "title": "Sim-to-Real of Soft Robots with Learned Residual Physics",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "Accurately modeling soft robots in simulation is computationally expensive and commonly falls short of representing the real world. This well-known discrepancy, known as the sim-to-real gap, can have several causes, such as coarsely approximated geometry and material models, manufacturing defects, viscoelasticity and plasticity, and hysteresis effects. Residual physics networks learn from real-world data to augment a discrepant model and bring it closer to reality. Here, we present a residual physics method for modeling soft robots with large degrees of freedom. We train neural networks to learn a residual term -- the modeling error between simulated and physical systems. Concretely, the residual term is a force applied on the whole simulated mesh, while real position data is collected with only sparse motion markers. The physical prior of the analytical simulation provides a starting point for the residual network, and the combined model is more informed than if physics were learned tabula rasa. We demonstrate our method on 1) a silicone elastomeric beam and 2) a soft pneumatic arm with hard-to-model, anisotropic fiber reinforcements. Our method outperforms traditional system identification up to 60%. We show that residual physics need not be limited to low degrees of freedom but can effectively bridge the sim-to-real gap for high dimensional systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2402.01124",
        "abstract url": "https://arxiv.org/abs/2402.01124",
        "title": "TransFR: Transferable Federated Recommendation with Pre-trained Language Models",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Federated recommendations (FRs), facilitating multiple local clients to collectively learn a global model without disclosing user private data, have emerged as a prevalent architecture for privacy-preserving recommendations. In conventional FRs, a dominant paradigm is to utilize discrete identities to represent users/clients and items, which are subsequently mapped to domain-specific embeddings to participate in model training. Despite considerable performance, we reveal three inherent limitations that can not be ignored in federated settings, i.e., non-transferability across domains, unavailability in cold-start settings, and potential privacy violations during federated training. To this end, we propose a transferable federated recommendation model with universal textual representations, TransFR, which delicately incorporates the general capabilities empowered by pre-trained language models and the personalized abilities by fine-tuning local private data. Specifically, it first learns domain-agnostic representations of items by exploiting pre-trained models with public textual corpora. To tailor for federated recommendation, we further introduce an efficient federated fine-tuning and a local training mechanism. This facilitates personalized local heads for each client by utilizing their private behavior data. By incorporating pre-training and fine-tuning within FRs, it greatly improves the adaptation efficiency transferring to a new domain and the generalization capacity to address cold-start issues. Through extensive experiments on several datasets, we demonstrate that our TransFR model surpasses several state-of-the-art FRs in terms of accuracy, transferability, and privacy.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01773",
        "abstract url": "https://arxiv.org/abs/2402.01773",
        "title": "Creating a Synthesizer from Schr\u00f6dinger's Equation",
        "rating": "-2",
        "keywords": [
            [
                "Synthesizer"
            ],
            [
                "quantum",
                "physics"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Our project offers an alternative approach to the sensory perception of the Schr\u00f6dinger equation (an elementary model of quantum phenomena) by interpreting it as a sound wave. We are building a synthesizer plugin that simulates a quantum mechanical state that evolves over time. Thus, our tool allows the creation of unique sounds that are in motion and feel alive. These can be used in professional music production without any knowledge of physics, while at the same time providing insight into a chapter of quantum mechanics. The goal is to lower the threshold for entering complex theory by first developing an intuition for the subject; but the tool can also be used purely as a musical instrument. The user is encouraged, but not forced, to learn more about the underlying physics. Simulation parameters are adjustable in real-time, allowing intuitive experimentation. Despite the approximate calculations, real physical effects such as quantum tunneling can be observed acoustically and visually.",
        "subjects": [
            "cs.SD",
            "eess.AS",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01779",
        "abstract url": "https://arxiv.org/abs/2402.01779",
        "title": "Plug-and-Play image restoration with Stochastic deNOising REgularization",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "inpainting"
            ],
            [
                "image restoration"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Plug-and-Play (PnP) algorithms are a class of iterative algorithms that address image inverse problems by combining a physical model and a deep neural network for regularization. Even if they produce impressive image restoration results, these algorithms rely on a non-standard use of a denoiser on images that are less and less noisy along the iterations, which contrasts with recent algorithms based on Diffusion Models (DM), where the denoiser is applied only on re-noised images. We propose a new PnP framework, called Stochastic deNOising REgularization (SNORE), which applies the denoiser only on images with noise of the adequate level. It is based on an explicit stochastic regularization, which leads to a stochastic gradient descent algorithm to solve ill-posed inverse problems. A convergence analysis of this algorithm and its annealing extension is provided. Experimentally, we prove that SNORE is competitive with respect to state-of-the-art methods on deblurring and inpainting tasks, both quantitatively and qualitatively.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01782",
        "abstract url": "https://arxiv.org/abs/2402.01782",
        "title": "Benchmarking Spiking Neural Network Learning Methods with Varying Locality",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "biologically"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but comes with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, this research examines the implicitly recurrent nature of SNNs and investigates the influence of addition of explicit recurrence to SNNs. We experimentally prove that the addition of explicit recurrent weights enhances the robustness of SNNs. We also investigate the performance of local learning methods under gradient and non-gradient based adversarial attacks.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03369",
        "abstract url": "https://arxiv.org/abs/2402.03369",
        "title": "Evaluation of Google's Voice Recognition and Sentence Classification for Health Care Applications",
        "rating": "-2",
        "keywords": [
            [
                "support vector machine"
            ],
            [
                "Health"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This study examined the use of voice recognition technology in perioperative services (Periop) to enable Periop staff to record workflow milestones using mobile technology. The use of mobile technology to improve patient flow and quality of care could be facilitated if such voice recognition technology could be made robust. The goal of this experiment was to allow the Periop staff to provide care without being interrupted with data entry and querying tasks. However, the results are generalizable to other situations where an engineering manager attempts to improve communication performance using mobile technology. This study enhanced Google's voice recognition capability by using post-processing classifiers (i.e., bag-of-sentences, support vector machine, and maximum entropy). The experiments investigated three factors (original phrasing, reduced phrasing, and personalized phrasing) at three levels (zero training repetition, 5 training repetitions, and 10 training repetitions). Results indicated that personal phrasing yielded the highest correctness and that training the device to recognize an individual's voice improved correctness as well. Although simplistic, the bag-of-sentences classifier significantly improved voice recognition correctness. The classification efficiency of the maximum entropy and support vector machine algorithms was found to be nearly identical. These results suggest that engineering managers could significantly enhance Google's voice recognition technology by using post-processing techniques, which would facilitate its use in health care and other applications.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.LG",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2402.07917",
        "abstract url": "https://arxiv.org/abs/2402.07917",
        "title": "Smart Water Irrigation for Rice Farming through the Internet of Things",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "This study intends to build smart water irrigation for rice farming using IoT and microcontroller devices with solar panel support. The system demonstrates the capabilities of automated irrigation by reducing physical labor through smart monitoring of the temperature, soil moisture, and humidity using multiple sensors. This study uses an agile methodology as it is suitable for reiterative operation for the development of the prototype. The mean result for the interpretation of data gathered for the systems' adaptability and flexibility is 4.32. The researchers were able to develop smart water irrigation for rice farming using IoT and microcontroller devices with solar panel support and the respondents also agreed that Smart water irrigation for rice farming using IoT and microcontroller devices with solar panel support is practical and valuable. A decision support system is recommended that can analyze data collected from IoT sensors and provide further recommendations. Based on the results, it is also suggested that future researchers use drip irrigation, instead of flood irrigation. Smart water irrigation has the potential to revolutionize agriculture, enhance environmental sustainability, and address pressing global challenges related to water resources and food security. These implications highlight the importance of continued research and innovation in this field.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "14 pages, 5 figures, 1 table"
    },
    {
        "paper id": "2402.14022",
        "abstract url": "https://arxiv.org/abs/2402.14022",
        "title": "Statistical validation of a deep learning algorithm for dental anomaly detection in intraoral radiographs using paired data",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This article describes the clinical validation study setup, statistical analysis and results for a deep learning algorithm which detects dental anomalies in intraoral radiographic images, more specifically caries, apical lesions, root canal treatment defects, marginal defects at crown restorations, periodontal bone loss and calculus. The study compares the detection performance of dentists using the deep learning algorithm to the prior performance of these dentists evaluating the images without algorithmic assistance. Calculating the marginal profit and loss of performance from the annotated paired image data allows for a quantification of the hypothesized change in sensitivity and specificity. The statistical significance of these results is extensively proven using both McNemar's test and the binomial hypothesis test. The average sensitivity increases from $60.7\\%$ to $85.9\\%$, while the average specificity slightly decreases from $94.5\\%$ to $92.7\\%$. We prove that the increase of the area under the localization ROC curve (AUC) is significant (from $0.60$ to $0.86$ on average), while the average AUC is bounded by the $95\\%$ confidence intervals ${[}0.54, 0.65{]}$ and ${[}0.82, 0.90{]}$. When using the deep learning algorithm for diagnostic guidance, the dentist can be $95\\%$ confident that the average true population sensitivity is bounded by the range $79.6\\%$ to $91.9\\%$. The proposed paired data setup and statistical analysis can be used as a blueprint to thoroughly test the effect of a modality change, like a deep learning based detection and/or segmentation, on radiographic images.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "stat.AP"
        ],
        "comment": "10 pages, 2 figures, 10 tables"
    },
    {
        "paper id": "2405.00010",
        "abstract url": "https://arxiv.org/abs/2405.00010",
        "title": "A Review on Industrial Augmented Reality Systems for the Industry 4.0 Shipyard",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "Shipbuilding companies are upgrading their inner workings in order to create Shipyards 4.0, where the principles of Industry 4.0 are paving the way to further digitalized and optimized processes in an integrated network. Among the different Industry 4.0 technologies, this article focuses on Augmented Reality, whose application in the industrial field has led to the concept of Industrial Augmented Reality (IAR). This article first describes the basics of IAR and then carries out a thorough analysis of the latest IAR systems for industrial and shipbuilding applications. Then, in order to build a practical IAR system for shipyard workers, the main hardware and software solutions are compared. Finally, as a conclusion after reviewing all the aspects related to IAR for shipbuilding, it is proposed an IAR system architecture that combines Cloudlets and Fog Computing, which reduce latency response and accelerate rendering tasks while offloading compute intensive tasks from the Cloud.",
        "subjects": [
            "cs.DC",
            "cs.HC"
        ],
        "comment": "Accepted version of an IEEE Access journal article"
    },
    {
        "paper id": "2402.00362",
        "abstract url": "https://arxiv.org/abs/2402.00362",
        "title": "Climate Trends of Tropical Cyclone Intensity and Energy Extremes Revealed by Deep Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "radar"
            ],
            [
                "satellite"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Anthropogenic influences have been linked to tropical cyclone (TC) poleward migration, TC extreme precipitation, and an increased proportion of major hurricanes [1, 2, 3, 4]. Understanding past TC trends and variability is critical for projecting future TC impacts on human society considering the changing climate [5]. However, past trends of TC structure/energy remain uncertain due to limited observations; subjective-analyzed and spatiotemporal-heterogeneous \"best-track\" datasets lead to reduced confidence in the assessed TC repose to climate change [6, 7]. Here, we use deep learning to reconstruct past \"observations\" and yield an objective global TC wind profile dataset during 1981 to 2020, facilitating a comprehensive examination of TC structure/energy. By training with uniquely labeled data integrating best tracks and numerical model analysis of 2004 to 2018 TCs, our model converts multichannel satellite imagery to a 0-750-km wind profile of axisymmetric surface winds. The model performance is verified to be sufficient for climate studies by comparing it to independent satellite-radar surface winds. Based on the new homogenized dataset, the major TC proportion has increased by ~13% in the past four decades. Moreover, the proportion of extremely high-energy TCs has increased by ~25%, along with an increasing trend (> one standard deviation of the 40-y variability) of the mean total energy of high-energy TCs. Although the warming ocean favors TC intensification, the TC track migration to higher latitudes and altered environments further affect TC structure/energy. This new deep learning method/dataset reveals novel trends regarding TC structure extremes and may help verify simulations/studies regarding TCs in the changing climate.",
        "subjects": [
            "physics.ao-ph",
            "cs.AI"
        ],
        "comment": "41 pages"
    },
    {
        "paper id": "2402.00376",
        "abstract url": "https://arxiv.org/abs/2402.00376",
        "title": "Image2Points:A 3D Point-based Context Clusters GAN for High-Quality PET Image Reconstruction",
        "rating": "-2.5",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "GAN"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "To obtain high-quality Positron emission tomography (PET) images while minimizing radiation exposure, numerous methods have been proposed to reconstruct standard-dose PET (SPET) images from the corresponding low-dose PET (LPET) images. However, these methods heavily rely on voxel-based representations, which fall short of adequately accounting for the precise structure and fine-grained context, leading to compromised reconstruction. In this paper, we propose a 3D point-based context clusters GAN, namely PCC-GAN, to reconstruct high-quality SPET images from LPET. Specifically, inspired by the geometric representation power of points, we resort to a point-based representation to enhance the explicit expression of the image structure, thus facilitating the reconstruction with finer details. Moreover, a context clustering strategy is applied to explore the contextual relationships among points, which mitigates the ambiguities of small structures in the reconstructed images. Experiments on both clinical and phantom datasets demonstrate that our PCC-GAN outperforms the state-of-the-art reconstruction methods qualitatively and quantitatively. Code is available at https://github.com/gluucose/PCCGAN.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2402.00390",
        "abstract url": "https://arxiv.org/abs/2402.00390",
        "title": "EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this age where data is abundant, the ability to distill meaningful insights from the sea of information is essential. Our research addresses the computational and resource inefficiencies that current Sequential Recommender Systems (SRSs) suffer from. especially those employing attention-based models like SASRec, These systems are designed for next-item recommendations in various applications, from e-commerce to social networks. However, such systems suffer from substantial computational costs and resource consumption during the inference stage. To tackle these issues, our research proposes a novel method that combines automatic pruning techniques with advanced model architectures. We also explore the potential of resource-constrained Neural Architecture Search (NAS), a technique prevalent in the realm of recommendation systems, to fine-tune models for reduced FLOPs, latency, and energy usage while retaining or even enhancing accuracy. The main contribution of our work is developing the Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems (EASRec). This approach aims to find optimal compact architectures for attention-based SRSs, ensuring accuracy retention. EASRec introduces data-aware gates that leverage historical information from input data batch to improve the performance of the recommendation network. Additionally, it utilizes a dynamic resource constraint approach, which standardizes the search process and results in more appropriate architectures. The effectiveness of our methodology is validated through exhaustive experiments on three benchmark datasets, which demonstrates EASRec's superiority in SRSs. Our research set a new standard for future exploration into efficient and accurate recommender systems, signifying a substantial advancement within this swiftly advancing field.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00397",
        "abstract url": "https://arxiv.org/abs/2402.00397",
        "title": "Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Traffic forecasting is crucial for intelligent transportation systems (ITS), aiding in efficient resource allocation and effective traffic control. However, its effectiveness often relies heavily on abundant traffic data, while many cities lack sufficient data due to limited device support, posing a significant challenge for traffic forecasting. Recognizing this challenge, we have made a noteworthy observation: traffic patterns exhibit similarities across diverse cities. Building on this key insight, we propose a solution for the cross-city few-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank (MTPB). Primarily, MTPB initiates its learning process by leveraging data-rich source cities, effectively acquiring comprehensive traffic knowledge through a spatial-temporal-aware pre-training process. Subsequently, the framework employs advanced clustering techniques to systematically generate a multi-scale traffic pattern bank derived from the learned knowledge. Next, the traffic data of the data-scarce target city could query the traffic pattern bank, facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn, assumes a pivotal role as a robust guide in subsequent processes involving graph reconstruction and forecasting. Empirical assessments conducted on real-world traffic datasets affirm the superior performance of MTPB, surpassing existing methods across various categories and exhibiting numerous attributes conducive to the advancement of cross-city few-shot forecasting methodologies. The code is available in https://github.com/zhyliu00/MTPB.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Under review. Text overlap with arXiv:2308.09727"
    },
    {
        "paper id": "2402.00435",
        "abstract url": "https://arxiv.org/abs/2402.00435",
        "title": "A practical existence theorem for reduced order models based on convolutional autoencoders",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely investigated. Furthermore, many practical questions remain unanswered, e.g., the number of snapshots needed for convergence or the neural network training strategy. In this work, using recent techniques from sparse high-dimensional function approximation, we fill some of these gaps by providing a new practical existence theorem for CNN-based autoencoders when the parameter-to-solution map is holomorphic. This regularity assumption arises in many relevant classes of parametric PDEs, such as the parametric diffusion equation, for which we discuss an explicit application of our general theory.",
        "subjects": [
            "math.NA",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00447",
        "abstract url": "https://arxiv.org/abs/2402.00447",
        "title": "A Survey of Data-Efficient Graph Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biochemical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including self-supervised graph learning, semi-supervised graph learning, and few-shot graph learning. Also, we state promising directions for future research, contributing to the evolution of graph machine learning.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00568",
        "abstract url": "https://arxiv.org/abs/2402.00568",
        "title": "Secure Supervised Learning-Based Smart Home Authentication Framework",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Smart home possesses the capability of facilitating home services to their users with the systematic advance in The Internet of Things (IoT) and information and communication technologies (ICT) in recent decades. The home service offered by the smart devices helps the users in utilize maximized level of comfort for the objective of improving life quality. As the user and smart devices communicate through an insecure channel, the smart home environment is prone to security and privacy problems. A secure authentication protocol needs to be established between the smart devices and the user, such that a situation for device authentication can be made feasible in smart home environments. Most of the existing smart home authentication protocols were identified to fail in facilitating a secure mutual authentication and increases the possibility of lunching the attacks of session key disclosure, impersonation and stolen smart device. In this paper, Secure Supervised Learning-based Smart Home Authentication Framework (SSL-SHAF) is proposed as are liable mutual authentication that can be contextually imposed for better security. The formal analysis of the proposed SSL-SHAF confirmed better resistance against session key disclosure, impersonation and stolen smart device attacks. The results of SSL-SHAF confirmed minimized computational costs and security compared to the baseline protocols considered for investigation.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00926",
        "abstract url": "https://arxiv.org/abs/2402.00926",
        "title": "A Comparative Analysis of Gene Expression Profiling by Statistical and Machine Learning Approaches",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "biological",
                "cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many machine learning models have been proposed to classify phenotypes from gene expression data. In addition to their good performance, these models can potentially provide some understanding of phenotypes by extracting explanations for their decisions. These explanations often take the form of a list of genes ranked in order of importance for the predictions, the highest-ranked genes being interpreted as linked to the phenotype. We discuss the biological and the methodological limitations of such explanations. Experiments are performed on several datasets gathering cancer and healthy tissue samples from the TCGA, GTEx and TARGET databases. A collection of machine learning models including logistic regression, multilayer perceptron, and graph neural network are trained to classify samples according to their cancer type. Gene rankings are obtained from explainability methods adapted to these models, and compared to the ones from classical statistical feature selection methods such as mutual information, DESeq2, and EdgeR. Interestingly, on simple tasks, we observe that the information learned by black-box neural networks is related to the notion of differential expression. In all cases, a small set containing the best-ranked genes is sufficient to achieve a good classification. However, these genes differ significantly between the methods and similar classification performance can be achieved with numerous lower ranked genes. In conclusion, although these methods enable the identification of biomarkers characteristic of certain pathologies, our results question the completeness of the selected gene sets and thus of explainability by the identification of the underlying biological processes.",
        "subjects": [
            "q-bio.GN",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01076",
        "abstract url": "https://arxiv.org/abs/2402.01076",
        "title": "DoseGNN: Improving the Performance of Deep Learning Models in Adaptive Dose-Volume Histogram Prediction through Graph Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "CT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Dose-Volume Histogram (DVH) prediction is fundamental in radiation therapy that facilitate treatment planning, dose evaluation, plan comparison and etc. It helps to increase the ability to deliver precise and effective radiation treatments while managing potential toxicities to healthy tissues as needed to reduce the risk of complications. This paper extends recently disclosed research findings presented on AAPM (AAPM 65th Annual Meeting $\\&$ Exhibition) and includes necessary technique details. The objective is to design efficient deep learning models for DVH prediction on general radiotherapy platform equipped with high performance CBCT system, where input CT images and target dose images to predict may have different origins, spacing and sizes. Deep learning models widely-adopted in DVH prediction task are evaluated on the novel radiotherapy platform, and graph neural networks (GNNs) are shown to be the ideal architecture to construct a plug-and-play framework to improve predictive performance of base deep learning models in the adaptive setting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01082",
        "abstract url": "https://arxiv.org/abs/2402.01082",
        "title": "Salsa Fresca: Angular Embeddings and Pre-Training for ML Attacks on Learning With Errors",
        "rating": "-2.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning with Errors (LWE) is a hard math problem underlying recently standardized post-quantum cryptography (PQC) systems for key exchange and digital signatures. Prior work proposed new machine learning (ML)-based attacks on LWE problems with small, sparse secrets, but these attacks require millions of LWE samples to train on and take days to recover secrets. We propose three key methods -- better preprocessing, angular embeddings and model pre-training -- to improve these attacks, speeding up preprocessing by $25\\times$ and improving model sample efficiency by $10\\times$. We demonstrate for the first time that pre-training improves and reduces the cost of ML attacks on LWE. Our architecture improvements enable scaling to larger-dimension LWE problems: this work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "8 pages (main text)"
    },
    {
        "paper id": "2402.01138",
        "abstract url": "https://arxiv.org/abs/2402.01138",
        "title": "Graph Neural Networks in EEG-based Emotion Recognition: A Survey",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "EEG"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several open challenges and future directions, such as Temporal full-connected graph and Graph condensation.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01791",
        "abstract url": "https://arxiv.org/abs/2402.01791",
        "title": "Variational Quantum Circuits Enhanced Generative Adversarial Network",
        "rating": "-2.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generative adversarial network (GAN) is one of the widely-adopted machine-learning frameworks for a wide range of applications such as generating high-quality images, video, and audio contents. However, training a GAN could become computationally expensive for large neural networks. In this work, we propose a hybrid quantum-classical architecture for improving GAN (denoted as QC-GAN). The performance was examed numerically by benchmarking with a classical GAN using MindSpore Quantum on the task of hand-written image generation. The generator of the QC-GAN consists of a quantum variational circuit together with a one-layer neural network, and the discriminator consists of a traditional neural network. Leveraging the entangling and expressive power of quantum circuits, our hybrid architecture achieved better performance (Frechet Inception Distance) than the classical GAN, with much fewer training parameters and number of iterations for convergence. We have also demonstrated the superiority of QC-GAN over an alternative quantum GAN, namely pathGAN, which could hardly generate 16$\\times$16 or larger images. This work demonstrates the value of combining ideas from quantum computing with machine learning for both areas of Quantum-for-AI and AI-for-Quantum.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.ET",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03368",
        "abstract url": "https://arxiv.org/abs/2402.03368",
        "title": "Empirical and Experimental Perspectives on Big Data in Recommendation Systems: A Comprehensive Survey",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This survey paper provides a comprehensive analysis of big data algorithms in recommendation systems, addressing the lack of depth and precision in existing literature. It proposes a two-pronged approach: a thorough analysis of current algorithms and a novel, hierarchical taxonomy for precise categorization. The taxonomy is based on a tri-level hierarchy, starting with the methodology category and narrowing down to specific techniques. Such a framework allows for a structured and comprehensive classification of algorithms, assisting researchers in understanding the interrelationships among diverse algorithms and techniques. Covering a wide range of algorithms, this taxonomy first categorizes algorithms into four main analysis types: User and Item Similarity-Based Methods, Hybrid and Combined Approaches, Deep Learning and Algorithmic Methods, and Mathematical Modeling Methods, with further subdivisions into sub-categories and techniques. The paper incorporates both empirical and experimental evaluations to differentiate between the techniques. The empirical evaluation ranks the techniques based on four criteria. The experimental assessments rank the algorithms that belong to the same category, sub-category, technique, and sub-technique. Also, the paper illuminates the future prospects of big data techniques in recommendation systems, underscoring potential advancements and opportunities for further research in this field",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10085",
        "abstract url": "https://arxiv.org/abs/2402.10085",
        "title": "Develop End-to-End Anomaly Detection System",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Anomaly detection plays a crucial role in ensuring network robustness. However, implementing intelligent alerting systems becomes a challenge when considering scenarios in which anomalies can be caused by both malicious and non-malicious events, leading to the difficulty of determining anomaly patterns. The lack of labeled data in the computer networking domain further exacerbates this issue, impeding the development of robust models capable of handling real-world scenarios. To address this challenge, in this paper, we propose an end-to-end anomaly detection model development pipeline. This framework makes it possible to consume user feedback and enable continuous user-centric model performance evaluation and optimization. We demonstrate the efficacy of the framework by way of introducing and bench-marking a new forecasting model -- named \\emph{Lachesis} -- on a real-world networking problem. Experiments have demonstrated the robustness and effectiveness of the two proposed versions of \\emph{Lachesis} compared with other models proposed in the literature. Our findings underscore the potential for improving the performance of data-driven products over their life cycles through a harmonized integration of user feedback and iterative development.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00356",
        "abstract url": "https://arxiv.org/abs/2402.00356",
        "title": "Securing Cloud-Based Internet of Things: Challenges and Mitigations",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "The Internet of Things (IoT) has seen remarkable advancements in recent years, leading to a paradigm shift in the digital landscape. However, these technological strides have also brought new challenges, particularly in terms of cybersecurity. IoT devices are inherently connected to the internet, which makes them more vulnerable to attack. In addition, IoT services often handle sensitive user data, which could be misused by malicious actors or unauthorized service providers. As more mainstream service providers emerge without uniform regulations, these security risks are expected to escalate exponentially. The task of maintaining the security of IoT devices while they interact with cloud services is also challenging. Newer IoT services, especially those developed and deployed via Platform-as-a-Service (PaaS) and Infrastructure-as-a-Service (IaaS) models, pose additional security threats. Although IoT devices are becoming more affordable and ubiquitous, their growing complexity could expose users to heightened security and privacy risks. This paper highlights these pressing security concerns associated with the widespread adoption of IoT devices and services. We propose potential solutions to bridge the existing security gaps and expect future challenges. Our approach entails a comprehensive exploration of the key security challenges that IoT services are currently facing. We also suggest proactive strategies to mitigate these risks, strengthening the overall security of IoT devices and services.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00478",
        "abstract url": "https://arxiv.org/abs/2402.00478",
        "title": "Resource Bounds for Quantum Circuit Mapping via Quantum Circuit Complexity",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Efficiently mapping quantum circuits onto hardware is an integral part of the quantum compilation process, wherein a quantum circuit is modified in accordance with the stringent architectural demands of a quantum processor. Many techniques exist for solving the quantum circuit mapping problem, many of which relate quantum circuit mapping to classical computer science. This work considers a novel perspective on quantum circuit mapping, in which the routing process of a simplified circuit is viewed as a composition of quantum operations acting on density matrices representing the quantum circuit and processor. Drawing on insight from recent advances in quantum information theory and information geometry, we show that a minimal SWAP gate count for executing a quantum circuit on a device emerges via the minimization of the distance between quantum states using the quantum Jensen-Shannon divergence. Additionally, we develop a novel initial placement algorithm based on a graph similarity search that selects the partition nearest to a graph isomorphism between interaction and coupling graphs. From these two ingredients, we then construct a polynomial-time algorithm for calculating the SWAP gate lower bound, which is directly compared alongside the IBM Qiskit compiler for over 600 realistic benchmark experiments, as well as against a brute-force method for smaller benchmarks. In our simulations, we unambiguously find that neither the brute-force method nor the Qiskit compiler surpass our bound, implying utility as a precise estimation of minimal overhead when realizing quantum algorithms on constrained quantum hardware. This work constitutes the first use of quantum circuit uncomplexity to practically-relevant quantum computing. We anticipate that this method may have diverse applicability outside of the scope of quantum information science, and we discuss several of these possibilities.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00564",
        "abstract url": "https://arxiv.org/abs/2402.00564",
        "title": "A Single Graph Convolution Is All You Need: Efficient Grayscale Image Classification",
        "rating": "-3",
        "keywords": [
            [
                "radar"
            ],
            [
                "Graph"
            ],
            [
                "medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Image classifiers often rely on convolutional neural networks (CNN) for their tasks, which are inherently more heavyweight than multilayer perceptrons (MLPs), which can be problematic in real-time applications. Additionally, many image classification models work on both RGB and grayscale datasets. Classifiers that operate solely on grayscale images are much less common. Grayscale image classification has diverse applications, including but not limited to medical image classification and synthetic aperture radar (SAR) automatic target recognition (ATR). Thus, we present a novel grayscale (single channel) image classification approach using a vectorized view of images. We exploit the lightweightness of MLPs by viewing images as a vector and reducing our problem setting to the grayscale image classification setting. We find that using a single graph convolutional layer batch-wise increases accuracy and reduces variance in the performance of our model. Moreover, we develop a customized accelerator on FPGA for the proposed model with several optimizations to improve its performance. Our experimental results on benchmark grayscale image datasets demonstrate the effectiveness of the proposed model, achieving vastly lower latency (up to 16$\\times$ less) and competitive or leading performance compared to other state-of-the-art image classification models on various domain-specific grayscale image classification datasets.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "6 pages of content, 1 page of references"
    },
    {
        "paper id": "2402.00569",
        "abstract url": "https://arxiv.org/abs/2402.00569",
        "title": "Radio Map Assisted Approach for Interference-Aware Predictive UAV Communications",
        "rating": "-3",
        "keywords": [
            [
                "vehicle",
                "flight"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Herein, an interference-aware predictive aerial-and-terrestrial communication problem is studied, where an unmanned aerial vehicle (UAV) delivers some data payload to a few nodes within a communication deadline. The first challenge is the possible interference to the ground base stations (BSs) and users possibly at unknown locations. This paper develops a radio-map-based approach to predict the channel to the receivers and the unintended nodes. Therefore, a predictive communication strategy can be optimized ahead of time to reduce the interference power and duration for the ground nodes. Such predictive optimization raises the second challenge of developing a low-complexity solution for a batch of transmission strategies over T time slots for N receivers before the flight. Mathematically, while the proposed interference-aware predictive communication problem is non-convex, it is converted into a relaxed convex problem, and solved by a novel dual-based algorithm, which is shown to achieve global optimality at asymptotically small slot duration. The proposed algorithm demonstrates orders of magnitude saving of the computational time for moderate T and N compared to several existing solvers. Simulations show that the radio-map-assisted scheme can prevent all unintended receivers with known positions from experiencing interference and significantly reduce the interference to the users at unknown locations.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00627",
        "abstract url": "https://arxiv.org/abs/2402.00627",
        "title": "CapHuman: Capture Your Moments in Parallel Universes",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "synthesis",
                "text-to-image"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We concentrate on a novel human-centric image synthesis task, that is, given only one reference facial photograph, it is expected to generate specific individual images with diverse head positions, poses, facial expressions, and illuminations in different contexts. To accomplish this goal, we argue that our generative model should be capable of the following favorable characteristics: (1) a strong visual and semantic understanding of our world and human society for basic object and human image generation. (2) generalizable identity preservation ability. (3) flexible and fine-grained head control. Recently, large pre-trained text-to-image diffusion models have shown remarkable results, serving as a powerful generative foundation. As a basis, we aim to unleash the above two capabilities of the pre-trained model. In this work, we present a new framework named CapHuman. We embrace the \"encode then learn to align\" paradigm, which enables generalizable identity preservation for new individuals without cumbersome tuning at inference. CapHuman encodes identity features and then learns to align them into the latent space. Moreover, we introduce the 3D facial prior to equip our model with control over the human head in a flexible and 3D-consistent manner. Extensive qualitative and quantitative analyses demonstrate our CapHuman can produce well-identity-preserved, photo-realistic, and high-fidelity portraits with content-rich representations and various head renditions, superior to established baselines. Code and checkpoint will be released at https://github.com/VamosC/CapHuman.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Project page: https://caphuman.github.io/"
    },
    {
        "paper id": "2402.00700",
        "abstract url": "https://arxiv.org/abs/2402.00700",
        "title": "In-Bed Pose Estimation: A Review",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "infrared"
            ],
            [
                "healthcare",
                "diagnosis",
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Human pose estimation, the process of identifying joint positions in a person's body from images or videos, represents a widely utilized technology across diverse fields, including healthcare. One such healthcare application involves in-bed pose estimation, where the body pose of an individual lying under a blanket is analyzed. This task, for instance, can be used to monitor a person's sleep behavior and detect symptoms early for potential disease diagnosis in homes and hospitals. Several studies have utilized unimodal and multimodal methods to estimate in-bed human poses. The unimodal studies generally employ RGB images, whereas the multimodal studies use modalities including RGB, long-wavelength infrared, pressure map, and depth map. Multimodal studies have the advantage of using modalities in addition to RGB that might capture information useful to cope with occlusions. Moreover, some multimodal studies exclude RGB and, this way, better suit privacy preservation. To expedite advancements in this domain, we conduct a review of existing datasets and approaches. Our objectives are to show the limitations of the previous studies, current challenges, and provide insights for future works on the in-bed human pose estimation field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at HCCS24 Workshop @ International Conference on Pervasive Computing and Communications (PerCom 2024)"
    },
    {
        "paper id": "2402.00708",
        "abstract url": "https://arxiv.org/abs/2402.00708",
        "title": "Benchmarking human-robot collaborative assembly tasks",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "CT"
            ]
        ],
        "abstract": "Manufacturing assembly tasks can vary in complexity and level of automation. Yet, achieving full automation can be challenging and inefficient, particularly due to the complexity of certain assembly operations. Human-robot collaborative work, leveraging the strengths of human labor alongside the capabilities of robots, can be a solution for enhancing efficiency. This paper introduces the CT benchmark, a benchmark and model set designed to facilitate the testing and evaluation of human-robot collaborative assembly scenarios. It was designed to compare manual and automatic processes using metrics such as the assembly time and human workload. The components of the model set can be assembled through the most common assembly tasks, each with varying levels of difficulty. The CT benchmark was designed with a focus on its applicability in human-robot collaborative environments, with the aim of ensuring the reproducibility and replicability of experiments. Experiments were carried out to assess assembly performance in three different setups (manual, automatic and collaborative), measuring metrics related to the assembly time and the workload on human operators. The results suggest that the collaborative approach takes longer than the fully manual assembly, with an increase of 70.8%. However, users reported a lower overall workload, as well as reduced mental demand, physical demand, and effort according to the NASA-TLX questionnaire.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00712",
        "abstract url": "https://arxiv.org/abs/2402.00712",
        "title": "ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction",
        "rating": "-3",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "Physics"
            ],
            [
                "cs.CY",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster readiness, reduced economic risk, and improved policy-making amidst climate change. Yet, S2S prediction remains challenging due to the chaotic nature of such system. At present, existing benchmarks for weather and climate applications, tend to (1) have shorter forecasting range of up-to 14 days, (2) do not include a wide range of operational baseline forecasts, and (3) lack physics-based constraints for explainability. Thus, we propose ChaosBench, a large-scale, multi-channel, physics-based benchmark for S2S prediction. ChaosBench has over 460K frames of real-world observations and simulations, each with 60 variable-channels and spanning for up-to 45 years. We also propose several physics-based, in addition to vision-based metrics, that enables for a more physically-consistent model. Furthermore, we include a diverse set of physics-based forecasts from 4 national weather agencies as baselines to our data-driven counterpart. We establish two tasks that vary in complexity: full and sparse dynamics prediction. Our benchmark is one of the first to perform large-scale evaluation on existing models including PanguWeather, FourCastNetV2, GraphCast, and ClimaX, and finds methods originally developed for weather-scale applications fails on S2S task: they perform much worse than just simply taking the long-term climatological averages. We release our benchmark code and datasets at https://leap-stc.github.io/ChaosBench.",
        "subjects": [
            "cs.CV",
            "cs.CY"
        ],
        "comment": "45 pages, 39 figures"
    },
    {
        "paper id": "2402.00829",
        "abstract url": "https://arxiv.org/abs/2402.00829",
        "title": "The En Route Truck-Drone Delivery Problem",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Drone"
            ]
        ],
        "abstract": "We study the truck-drone cooperative delivery problem in a setting where a single truck carrying a drone travels at constant speed on a straight-line trajectory/street. Delivery to clients located in the plane and not on the truck's trajectory is performed by the drone, which has limited carrying capacity and flying range, and whose battery can be recharged when on the truck. We show that the problem of maximizing the number of deliveries is strongly NP-hard even in this simple setting. We present a 2-approximation algorithm for the problem, and an optimal algorithm for a non-trivial family of instances.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00922",
        "abstract url": "https://arxiv.org/abs/2402.00922",
        "title": "Towards post-quantum blockchain: A review on blockchain cryptography resistant to quantum computing attacks",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Blockchain and other Distributed Ledger Technologies (DLTs) have evolved significantly in the last years and their use has been suggested for numerous applications due to their ability to provide transparency, redundancy and accountability. In the case of blockchain, such characteristics are provided through public-key cryptography and hash functions. However, the fast progress of quantum computing has opened the possibility of performing attacks based on Grover's and Shor's algorithms in the near future. Such algorithms threaten both public-key cryptography and hash functions, forcing to redesign blockchains to make use of cryptosystems that withstand quantum attacks, thus creating which are known as post-quantum, quantum-proof, quantum-safe or quantum-resistant cryptosystems. For such a purpose, this article first studies current state of the art on post-quantum cryptosystems and how they can be applied to blockchains and DLTs. Moreover, the most relevant post-quantum blockchain systems are studied, as well as their main challenges. Furthermore, extensive comparisons are provided on the characteristics and performance of the most promising post-quantum public-key encryption and digital signature schemes for blockchains. Thus, this article seeks to provide a broad view and useful guidelines on post-quantum blockchain security to future blockchain researchers and developers.",
        "subjects": [
            "cs.CR",
            "quant-ph"
        ],
        "comment": "Accepted version of an IEEE Access journal paper"
    },
    {
        "paper id": "2402.00954",
        "abstract url": "https://arxiv.org/abs/2402.00954",
        "title": "A Review on Blockchain Technologies for an Advanced and Cyber-Resilient Automotive Industry",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "In the last century the automotive industry has arguably transformed society, being one of the most complex, sophisticated and technologically advanced industries, with innovations ranging from hybrid, electric and self-driving smart cars to the development of IoT-connected cars. Due to its complexity, it requires the involvement of many Industry 4.0 technologies, like robotics, advanced manufacturing systems, cyber-physical systems or augmented reality. One of the latest technologies that can benefit the automotive industry is blockchain, which can enhance its data security, privacy, anonymity, traceability, accountability, integrity, robustness, transparency, trustworthiness and authentication, as well as provide long-term sustainability and a higher operational efficiency to the whole industry. This review analyzes the great potential of applying blockchain technologies to the automotive industry emphasizing its cybersecurity features. Thus, the applicability of blockchain is evaluated after examining the state-of-the-art and devising the main stakeholders' current challenges. Furthermore, the article describes the most relevant use cases, since the broad adoption of blockchain unlocks a wide area of short- and medium-term promising automotive applications that can create new business models and even disrupt the car-sharing economy as we know it. Finally, after a Strengths, Weaknesses, Opportunities, and Threats (SWOT) analysis, some recommendations are enumerated with the aim of guiding researchers and companies in future cyber-resilient automotive industry developments.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Version accepted in IEEE Access"
    },
    {
        "paper id": "2402.01026",
        "abstract url": "https://arxiv.org/abs/2402.01026",
        "title": "Bispectrum Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types",
        "rating": "-3",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "EEG"
            ]
        ],
        "abstract": "The bispectrum stands out as a revolutionary tool in frequency domain analysis, leaping the usual power spectrum by capturing crucial phase information between frequency components. In our innovative study, we have utilized the bispectrum to analyze and decode complex grasping movements, gathering EEG data from five human subjects. We put this data through its paces with three classifiers, focusing on both magnitude and phase-related features. The results highlight the bispectrum's incredible ability to delve into neural activity and differentiate between various grasping motions with the Support Vector Machine (SVM) classifier emerging as a standout performer. In binary classification, it achieved a remarkable 97\\% accuracy in identifying power grasp, and in the more complex multiclass tasks, it maintained an impressive 94.93\\% accuracy. This finding not only underscores the bispectrum's analytical strength but also showcases the SVM's exceptional capability in classification, opening new doors in our understanding of movement and neural dynamics.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "4 pages, 3 figures, 12 references, 4 authors, conference paper"
    },
    {
        "paper id": "2402.01054",
        "abstract url": "https://arxiv.org/abs/2402.01054",
        "title": "Unconditional Latent Diffusion Models Memorize Patient Imaging Data",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "synthesis"
            ],
            [
                "medical",
                "MRI",
                "CT",
                "X-ray"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Generative latent diffusion models hold a wide range of applications in the medical imaging domain. A noteworthy application is privacy-preserved open-data sharing by proposing synthetic data as surrogates of real patient data. Despite the promise, these models are susceptible to patient data memorization, where models generate patient data copies instead of novel synthetic samples. This undermines the whole purpose of preserving patient data and may even result in patient re-identification. Considering the importance of the problem, surprisingly it has received relatively little attention in the medical imaging community. To this end, we assess memorization in latent diffusion models for medical image synthesis. We train 2D and 3D latent diffusion models on CT, MR, and X-ray datasets for synthetic data generation. Afterwards, we examine the amount of training data memorized utilizing self-supervised models and further investigate various factors that can possibly lead to memorization by training models in different settings. We observe a surprisingly large amount of data memorization among all datasets, with up to 41.7%, 19.6%, and 32.6% of the training data memorized in CT, MRI, and X-ray datasets respectively. Further analyses reveal that increasing training data size and using data augmentation reduce memorization, while over-training enhances it. Overall, our results suggest a call for memorization-informed evaluation of synthetic data prior to open-data sharing.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01134",
        "abstract url": "https://arxiv.org/abs/2402.01134",
        "title": "DeepAAT: Deep Automated Aerial Triangulation for Fast UAV-based Mapping",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Vehicle"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Automated Aerial Triangulation (AAT), aiming to restore image pose and reconstruct sparse points simultaneously, plays a pivotal role in earth observation. With its rich research heritage spanning several decades in photogrammetry, AAT has evolved into a fundamental process widely applied in large-scale Unmanned Aerial Vehicle (UAV) based mapping. Despite its advancements, classic AAT methods still face challenges like low efficiency and limited robustness. This paper introduces DeepAAT, a deep learning network designed specifically for AAT of UAV imagery. DeepAAT considers both spatial and spectral characteristics of imagery, enhancing its capability to resolve erroneous matching pairs and accurately predict image poses. DeepAAT marks a significant leap in AAT's efficiency, ensuring thorough scene coverage and precision. Its processing speed outpaces incremental AAT methods by hundreds of times and global AAT methods by tens of times while maintaining a comparable level of reconstruction accuracy. Additionally, DeepAAT's scene clustering and merging strategy facilitate rapid localization and pose determination for large-scale UAV images, even under constrained computing resources. The experimental results demonstrate DeepAAT's substantial improvements over conventional AAT methods, highlighting its potential in the efficiency and accuracy of UAV-based 3D reconstruction tasks. To benefit the photogrammetry society, the code of DeepAAT will be released at: https://github.com/WHU-USI3DV/DeepAAT.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00388",
        "abstract url": "https://arxiv.org/abs/2402.00388",
        "title": "Cumulative Distribution Function based General Temporal Point Processes",
        "rating": "-3.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Temporal Point Processes (TPPs) hold a pivotal role in modeling event sequences across diverse domains, including social networking and e-commerce, and have significantly contributed to the advancement of recommendation systems and information retrieval strategies. Through the analysis of events such as user interactions and transactions, TPPs offer valuable insights into behavioral patterns, facilitating the prediction of future trends. However, accurately forecasting future events remains a formidable challenge due to the intricate nature of these patterns. The integration of Neural Networks with TPPs has ushered in the development of advanced deep TPP models. While these models excel at processing complex and nonlinear temporal data, they encounter limitations in modeling intensity functions, grapple with computational complexities in integral computations, and struggle to capture long-range temporal dependencies effectively. In this study, we introduce the CuFun model, representing a novel approach to TPPs that revolves around the Cumulative Distribution Function (CDF). CuFun stands out by uniquely employing a monotonic neural network for CDF representation, utilizing past events as a scaling factor. This innovation significantly bolsters the model's adaptability and precision across a wide range of data scenarios. Our approach addresses several critical issues inherent in traditional TPP modeling: it simplifies log-likelihood calculations, extends applicability beyond predefined density function forms, and adeptly captures long-range temporal patterns. Our contributions encompass the introduction of a pioneering CDF-based TPP model, the development of a methodology for incorporating past event information into future event prediction, and empirical validation of CuFun's effectiveness through extensive experimentation on synthetic and real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00709",
        "abstract url": "https://arxiv.org/abs/2402.00709",
        "title": "Towards an autonomous industry 4.0 warehouse: A UAV and blockchain-based system for inventory and traceability applications in big data-driven supply chain management",
        "rating": "-3.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "UAV"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "In this paper we present the design and evaluation of a UAV-based system aimed at automating inventory tasks and keeping the traceability of industrial items attached to Radio-Frequency IDentification (RFID) tags. To confront current shortcomings, such a system is developed under a versatile, modular and scalable architecture aimed to reinforce cyber security and decentralization while fostering external audits and big data analytics. Therefore, the system uses a blockchain and a distributed ledger to store certain inventory data collected by UAVs, validate them, ensure their trustworthiness and make them available to the interested parties. In order to show the performance of the proposed system, different tests were performed in a real industrial warehouse, concluding that the system is able to obtain the inventory data really fast in comparison to traditional manual tasks, while being also able to estimate the position of the items when hovering over them thanks to their tag's signal strength. In addition, the performance of the proposed blockchain-based architecture was evaluated in different scenarios.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "Accepted version of Sensors journal article"
    },
    {
        "paper id": "2402.00808",
        "abstract url": "https://arxiv.org/abs/2402.00808",
        "title": "Exploring the Dynamics between Cobot's Production Rhythm, Locus of Control and Emotional State in a Collaborative Assembly Scenario",
        "rating": "-3.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In industrial scenarios, there is widespread use of collaborative robots (cobots), and growing interest is directed at evaluating and measuring the impact of some characteristics of the cobot on the human factor. In the present pilot study, the effect that the production rhythm (C1 - Slow, C2 - Fast, C3 - Adapted to the participant's pace) of a cobot has on the Experiential Locus of Control (ELoC) and the emotional state of 31 participants has been examined. The operators' performance, the degree of basic internal Locus of Control, and the attitude towards the robots were also considered. No difference was found regarding the emotional state and the ELoC in the three conditions, but considering the other psychological variables, a more complex situation emerges. Overall, results seem to indicate a need to consider the person's psychological characteristics to offer a differentiated and optimal interaction experience.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "Accepted to 4th IEEE International Conference on Human-Machine Systems"
    },
    {
        "paper id": "2402.01062",
        "abstract url": "https://arxiv.org/abs/2402.01062",
        "title": "Bio-Inspired Compensatory Strategies for Damage to Flapping Robotic Propulsors",
        "rating": "-3.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "attack"
            ],
            [
                "Bio-Inspired"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "To maintain full autonomy, autonomous robotic systems must have the ability to self-repair. Self-repairing via compensatory mechanisms appears in nature: for example, some fish can lose even 76% of their propulsive surface without loss of thrust by altering stroke mechanics. However, direct transference of these alterations from an organism to a robotic flapping propulsor may not be optimal due to irrelevant evolutionary pressures. We instead seek to determine what alterations to stroke mechanics are optimal for a damaged robotic system via artificial evolution. To determine whether natural and machine-learned optima differ, we employ a cyber-physical system using a Covariance Matrix Adaptation Evolutionary Strategy to seek the most efficient trajectory for a given force. We implement an online optimization with hardware-in-the-loop, performing experimental function evaluations with an actuated flexible flat plate. To recoup thrust production following partial amputation, the most efficient learned strategy was to increase amplitude, increase frequency, increase the amplitude of angle of attack, and phase shift the angle of attack by approximately 110 degrees. In fish, only an amplitude increase is reported by majority in the literature. To recoup side-force production, a more challenging optimization landscape is encountered. Nesting of optimal angle of attack traces is found in the resultant-based reference frame, but no clear trend in amplitude or frequency are exhibited -- in contrast to the increase in frequency reported in insect literature. These results suggest that how mechanical flapping propulsors most efficiently adjust to damage of a flapping propulsor may not align with natural swimmers and flyers.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00438",
        "abstract url": "https://arxiv.org/abs/2402.00438",
        "title": "The GREENBOT dataset: Multimodal mobile robotic dataset for a typical Mediterranean greenhouse",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "SLAM"
            ],
            [
                "agricultural"
            ]
        ],
        "abstract": "This paper introduces an innovative dataset specifically crafted for challenging agricultural settings (a greenhouse), where achieving precise localization is of paramount importance. The dataset was gathered using a mobile platform equipped with a set of sensors typically used in mobile robots, as it was moved through all the corridors of a typical Mediterranean greenhouse featuring tomato crop. This dataset presents a unique opportunity for constructing detailed 3D models of plants in such indoor-like space, with potential applications such as robotized spraying. For the first time to the best knowledge of authors, a dataset suitable to put at test Simultaneous Localization and Mapping (SLAM) methods is presented in a greenhouse environment, which poses unique challenges. The suitability of the dataset for such goal is assessed by presenting SLAM results with state-of-the-art algorithms. The dataset is available online in \\url{https://arm.ual.es/arm-group/dataset-greenhouse-2024/}.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "29 pages, 15 figures"
    },
    {
        "paper id": "2402.01074",
        "abstract url": "https://arxiv.org/abs/2402.01074",
        "title": "Neural Models and Algorithms for Sensorimotor Control of an Octopus Arm",
        "rating": "-4",
        "keywords": [
            [
                "biophysically"
            ],
            [
                "chemical"
            ]
        ],
        "abstract": "In this article, a biophysically realistic model of a soft octopus arm with internal musculature is presented. The modeling is motivated by experimental observations of sensorimotor control where an arm localizes and reaches a target. Major contributions of this article are: (i) development of models to capture the mechanical properties of arm musculature, the electrical properties of the arm peripheral nervous system (PNS), and the coupling of PNS with muscular contractions; (ii) modeling the arm sensory system, including chemosensing and proprioception; and (iii) algorithms for sensorimotor control, which include a novel feedback neural motor control law for mimicking target-oriented arm reaching motions, and a novel consensus algorithm for solving sensing problems such as locating a food source from local chemical sensory information (exogenous) and arm deformation information (endogenous). Several analytical results, including rest-state characterization and stability properties of the proposed sensing and motor control algorithms, are provided. Numerical simulations demonstrate the efficacy of our approach. Qualitative comparisons against observed arm rest shapes and target-oriented reaching motions are also reported.",
        "subjects": [
            "eess.SY",
            "cs.RO",
            "physics.bio-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00653",
        "abstract url": "https://arxiv.org/abs/2402.00653",
        "title": "Coherent Feed Forward Quantum Neural Network",
        "rating": "-4.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cancer"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum machine learning, focusing on quantum neural networks (QNNs), remains a vastly uncharted field of study. Current QNN models primarily employ variational circuits on an ansatz or a quantum feature map, often requiring multiple entanglement layers. This methodology not only increases the computational cost of the circuit beyond what is practical on near-term quantum devices but also misleadingly labels these models as neural networks, given their divergence from the structure of a typical feed-forward neural network (FFNN). Moreover, the circuit depth and qubit needs of these models scale poorly with the number of data features, resulting in an efficiency challenge for real-world machine-learning tasks. We introduce a bona fide QNN model, which seamlessly aligns with the versatility of a traditional FFNN in terms of its adaptable intermediate layers and nodes, absent from intermediate measurements such that our entire model is coherent. This model stands out with its reduced circuit depth and number of requisite C-NOT gates to outperform prevailing QNN models. Furthermore, the qubit count in our model remains unaffected by the data's feature quantity. We test our proposed model on various benchmarking datasets such as the diagnostic breast cancer (Wisconsin) and credit card fraud detection datasets. We compare the outcomes of our model with the existing QNN methods to showcase the advantageous efficacy of our approach, even with a reduced requirement on quantum resources. Our model paves the way for application of quantum neural networks to real relevant machine learning problems.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "11 pages, 7 figures. Comments welcome!"
    },
    {
        "paper id": "2402.00687",
        "abstract url": "https://arxiv.org/abs/2402.00687",
        "title": "A Review on the Use of Blockchain for the Internet of Things",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "BIoT"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "The paradigm of Internet of Things (IoT) is paving the way for a world, where many of our daily objects will be interconnected and will interact with their environment in order to collect information and automate certain tasks. Such a vision requires, among other things, seamless authentication, data privacy, security, robustness against attacks, easy deployment, and self-maintenance. Such features can be brought by blockchain, a technology born with a cryptocurrency called Bitcoin. In this paper, a thorough review on how to adapt blockchain to the specific needs of IoT in order to develop Blockchain-based IoT (BIoT) applications is presented. After describing the basics of blockchain, the most relevant BIoT applications are described with the objective of emphasizing how blockchain can impact traditional cloud-centered IoT applications. Then, the current challenges and possible optimizations are detailed regarding many aspects that affect the design, development, and deployment of a BIoT application. Finally, some recommendations are enumerated with the aim of guiding future BIoT researchers and developers on some of the issues that will have to be tackled before deploying the next generation of BIoT applications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted version of IEEE Access journal paper"
    },
    {
        "paper id": "2402.00790",
        "abstract url": "https://arxiv.org/abs/2402.00790",
        "title": "From Pre-Quantum to Post-Quantum IoT Security: A Survey on Quantum-Resistant Cryptosystems for the Internet of Things",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "This article provides a survey on what can be called post-quantum IoT systems (IoT systems protected from the currently known quantum computing attacks): the main post-quantum cryptosystems and initiatives are reviewed, the most relevant IoT architectures and challenges are analyzed, and the expected future trends are indicated. Thus, this paper is aimed at providing a wide view of post-quantum IoT security and give useful guidelines to the future post-quantum IoT developers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00347",
        "abstract url": "https://arxiv.org/abs/2402.00347",
        "title": "Diverse Explanations from Data-driven and Domain-driven Perspectives for Machine Learning Models",
        "rating": "-5.5",
        "keywords": [
            [
                "biology"
            ],
            [
                "chemistry"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Explanations of machine learning models are important, especially in scientific areas such as chemistry, biology, and physics, where they guide future laboratory experiments and resource requirements. These explanations can be derived from well-trained machine learning models (data-driven perspective) or specific domain knowledge (domain-driven perspective). However, there exist inconsistencies between these perspectives due to accurate yet misleading machine learning models and various stakeholders with specific needs, wants, or aims. This paper calls attention to these inconsistencies and suggests a way to find an accurate model with expected explanations that reinforce physical laws and meet stakeholders' requirements from a set of equally-good models, also known as Rashomon sets. Our goal is to foster a comprehensive understanding of these inconsistencies and ultimately contribute to the integration of eXplainable Artificial Intelligence (XAI) into scientific domains.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00346",
        "abstract url": "https://arxiv.org/abs/2402.00346",
        "title": "Experimental Application of Predictive Cost Adaptive Control to Thermoacoustic Oscillations in a Rijke Tube",
        "rating": "-10",
        "keywords": [],
        "abstract": "Model predictive control (MPC) has been used successfully in diverse applications. As its name suggests, MPC requires a model for predictive optimization. The present paper focuses on the application of MPC to a Rijke tube, in which a heating source and acoustic dynamics interact to produce self-excited oscillations. Since the dynamics of a Rijke tube are difficult to model to a high level of accuracy, the implementation of MPC requires leveraging data from the physical setup as well as knowledge about thermoacoustics, which is labor intensive and requires domain expertise. With this motivation, the present paper uses predictive cost adaptive control (PCAC) for sampled-data control of an experimental Rijke-tube setup. PCAC performs online closed-loop linear model identification for receding-horizon optimization based on the backward propagating Riccati equation. In place of analytical modeling, open-loop experiments are used to create a simple emulation model, which is used for choosing PCAC hyperparameters. PCAC is applied to the Rijke-tube setup under various experimental scenarios.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00352",
        "abstract url": "https://arxiv.org/abs/2402.00352",
        "title": "A Data-Driven Autopilot for Fixed-Wing Aircraft Based on Model Predictive Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "Autopilots for fixed-wing aircraft are typically designed based on linearized aerodynamic models consisting of stability and control derivatives obtained from wind-tunnel testing. The resulting local controllers are then pieced together using gain scheduling. For applications in which the aerodynamics are unmodeled, the present paper proposes an autopilot based on predictive cost adaptive control (PCAC). As an indirect adaptive control extension of model predictive control, PCAC uses recursive least squares (RLS) with variable-rate forgetting for online, closed-loop system identification. At each time step, RLS-based system identification updates the coefficients of an input-output model whose order is a hyperparameter specified by the user. For MPC, the receding-horizon optimization can be performed by either the backward-propagating Riccati equation or quadratic programming. The present paper investigates the performance of PCAC for fixed-wing aircraft without the use of any aerodynamic modeling or offline/prior data collection.",
        "subjects": [
            "eess.SY",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00365",
        "abstract url": "https://arxiv.org/abs/2402.00365",
        "title": "bypass4netns: Accelerating TCP/IP Communications in Rootless Containers",
        "rating": "-10",
        "keywords": [],
        "abstract": "\"Rootless containers\" is a concept to run the entire container runtimes and containers without the root privileges. It protects the host environment from attackers exploiting container runtime vulnerabilities. However, when rootless containers communicate with external endpoints, the network performance is low compared to rootful containers because of the overhead of rootless networking components. In this paper, we propose bypass4netns that accelerates TCP/IP communications in rootless containers by bypassing slow networking components. bypass4netns uses sockets allocated on the host. It switches sockets in containers to the host's sockets by intercepting syscalls and injecting the file descriptors using Seccomp. Our method with Seccomp can handle statically linked applications that previous works could not handle. Also, we propose high-performance rootless multi-node communication. We confirmed that rootless containers with bypass4netns achieve more than 30x faster throughput than rootless containers without it. In addition, we evaluated performance with applications and it showed large improvements on some applications.",
        "subjects": [
            "cs.NI",
            "cs.OS"
        ],
        "comment": "11 pages, 12 figures"
    },
    {
        "paper id": "2402.00370",
        "abstract url": "https://arxiv.org/abs/2402.00370",
        "title": "Exploring the landscape of virtual academic conferences: A scoping review of the 1984-2021 literature",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study presents an overview of the literature on virtual academic conferences, which have gained prominence due to the COVID-19 pandemic. We conducted a scoping review analyzing 147 documents covering the literature available up to October 5th, 2021. We examined the development of the field focusing on the evolution of virtual academic conferences, main themes in the literature, and its methodological and theoretical approaches. The results indicate that the existing literature on virtual academic conferences is mainly descriptive and lacks a theoretical framework. Future research should focus on developing a solid theoretical framework to guide empirically and methodologically robust studies on virtual academic conferences. We emphasize the importance of recognizing their advantages and disadvantages from the perspectives of different groups of scholars. This will be a crucial step in establishing a framework for identifying and addressing dilemmas in online scholarly communication according to the responsible research and innovation approach.",
        "subjects": [
            "cs.DL",
            "cs.HC"
        ],
        "comment": "35 pages, 1 figure"
    },
    {
        "paper id": "2402.00381",
        "abstract url": "https://arxiv.org/abs/2402.00381",
        "title": "A Joint Communication and Computation Framework for Digital Twin over Wireless Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, the problem of low-latency communication and computation resource allocation for digital twin (DT) over wireless networks is investigated. In the considered model, multiple physical devices in the physical network (PN) needs to frequently offload the computation task related data to the digital network twin (DNT), which is generated and controlled by the central server. Due to limited energy budget of the physical devices, both computation accuracy and wireless transmission power must be considered during the DT procedure. This joint communication and computation problem is formulated as an optimization problem whose goal is to minimize the overall transmission delay of the system under total PN energy and DNT model accuracy constraints. To solve this problem, an alternating algorithm with iteratively solving device scheduling, power control, and data offloading subproblems. For the device scheduling subproblem, the optimal solution is obtained in closed form through the dual method. For the special case with one physical device, the optimal number of transmission times is reveled. Based on the theoretical findings, the original problem is transformed into a simplified problem and the optimal device scheduling can be found. Numerical results verify that the proposed algorithm can reduce the transmission delay of the system by up to 51.2\\% compared to the conventional schemes.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00386",
        "abstract url": "https://arxiv.org/abs/2402.00386",
        "title": "AssertLLM: Generating and Evaluating Hardware Verification Assertions from Design Specifications via Multi-LLMs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Assertion-based verification (ABV) is a critical method for ensuring design circuits comply with their architectural specifications, which are typically described in natural language. This process often requires significant interpretation by engineers to convert these specifications into functional verification assertions. Existing methods for generating assertions from natural language specifications are limited to sentences extracted by engineers, discouraging the practical application. In this work, we present AssertLLM, an automatic assertion generation framework for complete specification files. AssertLLM breaks down the complex task into three phases, incorporating three customized Large Language Models (LLMs) for extracting structural specifications, mapping signal definitions, and generating assertions. Additionally, we provide an open-source benchmark for assessing assertion generation capabilities. Our evaluation of AssertLLM on a full design, encompassing 23 signals, demonstrates that 89% of the generated assertions are both syntactically and functionally accurate.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00394",
        "abstract url": "https://arxiv.org/abs/2402.00394",
        "title": "Random partitions, potential of the Shapley value, and games with externalities",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Shapley value equals a player's contribution to the potential of a game. The potential is a most natural one-number summary of a game, which can be computed as the expected accumulated worth of a random partition of the players. This computation integrates the coalition formation of all players and readily extends to games with externalities. We investigate those potential functions for games with externalities that can be computed this way. It turns out that the potential that corresponds to the MPW solution introduced by Macho-Stadler et al. (2007, J. Econ. Theory 135, 339-356), is unique in the following sense. It is obtained as a the expected accumulated worth of a random partition, it generalizes the potential for games without externalities, and it induces a solution that satisfies the null player property even in the presence of externalities.",
        "subjects": [
            "econ.TH",
            "cs.GT",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00395",
        "abstract url": "https://arxiv.org/abs/2402.00395",
        "title": "ONE-SA: Enabling Nonlinear Operations in Systolic Arrays for Efficient and Flexible Neural Network Inference",
        "rating": "-10",
        "keywords": [],
        "abstract": "The computation and memory-intensive nature of DNNs limits their use in many mobile and embedded contexts. Application-specific integrated circuit (ASIC) hardware accelerators employ matrix multiplication units (such as the systolic arrays) and dedicated nonlinear function units to speed up DNN computations. A close examination of these ASIC accelerators reveals that the designs are often specialized and lack versatility across different networks, especially when the networks have different types of computation. In this paper, we introduce a novel systolic array architecture, which is capable of executing nonlinear functions. By encompassing both inherent linear and newly enabled nonlinear functions within the systolic arrays, the proposed architecture facilitates versatile network inferences, substantially enhancing computational power and energy efficiency. Experimental results show that employing this systolic array enables seamless execution of entire DNNs, incurring only a negligible loss in the network inference accuracy. Furthermore, assessment and evaluation with FPGAs reveal that integrating nonlinear computation capacity into a systolic array does not introduce extra notable (less than 1.5%) block memory memories (BRAMs), look-up-tables (LUTs), or digital signal processors (DSPs) but a mere 13.3% - 24.1% more flip flops (FFs). In comparison to existing methodologies, executing the networks with the proposed systolic array, which enables the flexibility of different network models, yields up to 25.73x, 5.21x, and 1.54x computational efficiency when compared to general-purpose CPUs, GPUs, and SoCs respectively, while achieving comparable (83.4% - 135.8%) performance with the conventional accelerators which are designed for specific neural network models.",
        "subjects": [
            "cs.AR",
            "eess.SP"
        ],
        "comment": "Accepted to DATE 2024"
    },
    {
        "paper id": "2402.00404",
        "abstract url": "https://arxiv.org/abs/2402.00404",
        "title": "Improving Critical Node Detection Using Neural Network-based Initialization in a Genetic Algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Critical Node Problem (CNP) is concerned with identifying the critical nodes in a complex network. These nodes play a significant role in maintaining the connectivity of the network, and removing them can negatively impact network performance. CNP has been studied extensively due to its numerous real-world applications. Among the different versions of CNP, CNP-1a has gained the most popularity. The primary objective of CNP-1a is to minimize the pair-wise connectivity in the remaining network after deleting a limited number of nodes from a network. Due to the NP-hard nature of CNP-1a, many heuristic/metaheuristic algorithms have been proposed to solve this problem. However, most existing algorithms start with a random initialization, leading to a high cost of obtaining an optimal solution. To improve the efficiency of solving CNP-1a, a knowledge-guided genetic algorithm named K2GA has been proposed. Unlike the standard genetic algorithm framework, K2GA has two main components: a pretrained neural network to obtain prior knowledge on possible critical nodes, and a hybrid genetic algorithm with local search for finding an optimal set of critical nodes based on the knowledge given by the trained neural network. The local search process utilizes a cut node-based greedy strategy. The effectiveness of the proposed knowledgeguided genetic algorithm is verified by experiments on 26 realworld instances of complex networks. Experimental results show that K2GA outperforms the state-of-the-art algorithms regarding the best, median, and average objective values, and improves the best upper bounds on the best objective values for eight realworld instances.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "14 pages, 13 figures"
    },
    {
        "paper id": "2402.00415",
        "abstract url": "https://arxiv.org/abs/2402.00415",
        "title": "A two-phase Volume of Fluid approach to model rigid-perfectly plastic granular materials",
        "rating": "-10",
        "keywords": [],
        "abstract": "Granular flow problems characterized by large deformations are widespread in various applications, including coastal and geotechnical engineering. The paper deals with the application of a rigid-perfectly plastic two-phase model extended by the Drucker-Prager yield criterion to simulate granular media with a finite volume flow solver (FV). The model refers to the combination of a Bingham fluid and an Eulerian strain measure to assess the failure region of granular dam slides. A monolithic volume-of-fluid (VoF) method is used to distinguish between the air and granular phases, both governed by the incompressible Navier-Stokes equations. The numerical framework enables modeling of large displacements and arbitrary shapes for large-scale applications. The displayed validation and verification focuses on the rigid-perfectly plastic material model for non-cohesive and cohesive materials with varying angles of repose. Results indicate a good agreement of the predicted soil surface and strain results with experimental and numerical data.",
        "subjects": [
            "physics.flu-dyn",
            "cs.DM",
            "physics.geo-ph"
        ],
        "comment": "18 pages, 8 figures"
    },
    {
        "paper id": "2402.00417",
        "abstract url": "https://arxiv.org/abs/2402.00417",
        "title": "Presentation of monoids generated by a projection and an involution",
        "rating": "-10",
        "keywords": [],
        "abstract": "Monoids generated by elements of order two appear in numerous places in the literature. For example, Coxeter reflection groups in geometry, Kuratowski monoids in topology, various monoids generated by regular operations in language theory and so on. In order to initiate a classification of these monoids, we are interested in the subproblem of monoids, called strict 2-PIMs, generated by an involution and an idempotent. In this case we show, when the monoid is finite, that it is generated by a single equation (in addition to the two defining the involution and the idempotent). We then describe the exact possible forms of this equation and classify them. We recover Kuratowski's theorem as a special case of our study.",
        "subjects": [
            "math.GR",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00424",
        "abstract url": "https://arxiv.org/abs/2402.00424",
        "title": "Reproducibility of Build Environments through Space and Time",
        "rating": "-10",
        "keywords": [],
        "abstract": "Modern software engineering builds up on the composability of software components, that rely on more and more direct and transitive dependencies to build their functionalities. This principle of reusability however makes it harder to reproduce projects' build environments, even though reproducibility of build environments is essential for collaboration, maintenance and component lifetime. In this work, we argue that functional package managers provide the tooling to make build environments reproducible in space and time, and we produce a preliminary evaluation to justify this claim. Using historical data, we show that we are able to reproduce build environments of about 7 million Nix packages, and to rebuild 99.94% of the 14 thousand packages from a 6-year-old Nixpkgs revision.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "46th International Conference on Software Engineering (ICSE 2024) - New Ideas and Emerging Results (NIER) Track, Apr 2024, Lisbonne, Portugal"
    },
    {
        "paper id": "2402.00444",
        "abstract url": "https://arxiv.org/abs/2402.00444",
        "title": "Evaluating Genetic Algorithms through the Approximability Hierarchy",
        "rating": "-10",
        "keywords": [],
        "abstract": "Optimization problems frequently appear in any scientific domain. Most of the times, the corresponding decision problem turns out to be NP-hard, and in these cases genetic algorithms are often used to obtain approximated solutions. However, the difficulty to approximate different NP-hard problems can vary a lot. In this paper, we analyze the usefulness of using genetic algorithms depending on the approximation class the problem belongs to. In particular, we use the standard approximability hierarchy, showing that genetic algorithms are especially useful for the most pessimistic classes of the hierarchy",
        "subjects": [
            "cs.NE"
        ],
        "comment": "17 pages, 1 figures"
    },
    {
        "paper id": "2402.00449",
        "abstract url": "https://arxiv.org/abs/2402.00449",
        "title": "Efficient Training Spiking Neural Networks with Parallel Spiking Unit",
        "rating": "-10",
        "keywords": [],
        "abstract": "Efficient parallel computing has become a pivotal element in advancing artificial intelligence. Yet, the deployment of Spiking Neural Networks (SNNs) in this domain is hampered by their inherent sequential computational dependency. This constraint arises from the need for each time step's processing to rely on the preceding step's outcomes, significantly impeding the adaptability of SNN models to massively parallel computing environments. Addressing this challenge, our paper introduces the innovative Parallel Spiking Unit (PSU) and its two derivatives, the Input-aware PSU (IPSU) and Reset-aware PSU (RPSU). These variants skillfully decouple the leaky integration and firing mechanisms in spiking neurons while probabilistically managing the reset process. By preserving the fundamental computational attributes of the spiking neuron model, our approach enables the concurrent computation of all membrane potential instances within the SNN, facilitating parallel spike output generation and substantially enhancing computational efficiency. Comprehensive testing across various datasets, including static and sequential images, Dynamic Vision Sensor (DVS) data, and speech datasets, demonstrates that the PSU and its variants not only significantly boost performance and simulation speed but also augment the energy efficiency of SNNs through enhanced sparsity in neural activity. These advancements underscore the potential of our method in revolutionizing SNN deployment for high-performance parallel computing applications.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00454",
        "abstract url": "https://arxiv.org/abs/2402.00454",
        "title": "Analyzing Crowdfunding of Public Projects Under Dynamic Beliefs",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the last decade, social planners have used crowdfunding to raise funds for public projects. As these public projects are non-excludable, the beneficiaries may free-ride. Thus, there is a need to design incentive mechanisms for such strategic agents to contribute to the project. The existing mechanisms, like PPR or PPRx, assume that the agent's beliefs about the project getting funded do not change over time, i.e., their beliefs are static. Researchers highlight that unless appropriately incentivized, the agents defer their contributions in static settings, leading to a ``race'' to contribute at the deadline. In this work, we model the evolution of agents' beliefs as a random walk. We study PPRx -- an existing mechanism for the static belief setting -- in this dynamic belief setting and refer to it as PPRx-DB for readability. We prove that in PPRx-DB, the project is funded at equilibrium. More significantly, we prove that under certain conditions on agent's belief evolution, agents will contribute as soon as they arrive at the mechanism. Thus, we believe that by incorporating dynamic belief evolution in analysis, the social planner can mitigate the concern of race conditions in many mechanisms.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "AAMAS '24 (Extended Abstract)"
    },
    {
        "paper id": "2402.00462",
        "abstract url": "https://arxiv.org/abs/2402.00462",
        "title": "Data Management Challenges in Agile Software Projects: A Systematic Literature Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Agile software development follows an adaptive and iterative approach. However, the management of data (e.g., development data or product data) can pose significant challenges for projects and agile teams. We aim to identify and characterize key challenges faced in data management within agile projects and to examine potential solutions proposed in the literature. We used a Systematic Literature Review (SLR) to collect and analyse relevant studies. We identified 45 studies related to data management in agile software development. We then manually analysed and mapped data from these studies to categorise different data management aspects and identify challenges and solutions as identified in those studies. Our findings reveal major challenges such as data integration and quality assurance. We found implications of challenges on team members and the product delivery process. We found that teams frequently struggle to integrate heterogeneous data sources, ensuring data reliability and real-time analytics. Additionally, fragmented data collection and a lack of standardized practices can impede team collaboration and project transparency. The studies have also proposed various solutions to address those challenges, including the use of ontologies, diverse data management strategies, automated tools, and the adoption of quality-focused development methods. Solutions also include training to enhance data quality and analysis. This SLR provides in-depth insights and recommendations for practitioners, emphasizing the importance of robust data management strategies. It suggests integrating advanced data management techniques into agile frameworks to enhance decision-making and improve software project outcomes. The study highlights the need for a more focused approach to data management in agile environments, advocating tailored solutions to meet the unique demands of agile software development.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "32 pages, 3 images, 6 tables, Manuscript submitted to a Journal (2024)"
    },
    {
        "paper id": "2402.00465",
        "abstract url": "https://arxiv.org/abs/2402.00465",
        "title": "Coded Multi-User Information Retrieval with a Multi-Antenna Helper Node",
        "rating": "-10",
        "keywords": [],
        "abstract": "A novel coding design is proposed to enhance information retrieval in a wireless network of users with partial access to the data, in the sense of observation, measurement, computation, or storage. Information exchange in the network is assisted by a multi-antenna base station (BS), with no direct access to the data. Accordingly, the missing parts of data are exchanged among users through an uplink (UL) step followed by a downlink (DL) step. In this paper, new coding strategies, inspired by coded caching (CC) techniques, are devised to enhance both UL and DL steps. In the UL step, users transmit encoded and properly combined parts of their accessible data to the BS. Then, during the DL step, the BS carries out the required processing on its received signals and forwards a proper combination of the resulting signal terms back to the users, enabling each user to retrieve the desired information. Using the devised coded data retrieval strategy, the data exchange in both UL and DL steps requires the same communication delay, measured by normalized delivery time (NDT). Furthermore, the NDT of the UL/DL step is shown to coincide with the optimal NDT of the original DL multi-input single-output CC scheme, in which the BS is connected to a centralized data library.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2402.00466",
        "abstract url": "https://arxiv.org/abs/2402.00466",
        "title": "Towards a GPU-Parallelization of the neXtSIM-DG Dynamical Core",
        "rating": "-10",
        "keywords": [],
        "abstract": "The cryosphere plays a significant role in Earth's climate system. Therefore, an accurate simulation of sea ice is of great importance to improve climate projections. To enable higher resolution simulations, graphics processing units (GPUs) have become increasingly attractive as they offer higher floating point peak performance and better energy efficiency compared to CPUs. However, making use of this theoretical peak performance, which is based on massive data parallelism, usually requires more care and effort in the implementation. In recent years, a number of frameworks have become available that promise to simplify general purpose GPU programming. In this work, we compare multiple such frameworks, including CUDA, SYCL, Kokkos and PyTorch, for the parallelization of \\nextsim, a finite-element based dynamical core for sea ice. We evaluate the different approaches according to their usability and performance.",
        "subjects": [
            "cs.DC",
            "math.NA"
        ],
        "comment": "revision for PASC 2024"
    },
    {
        "paper id": "2402.00477",
        "abstract url": "https://arxiv.org/abs/2402.00477",
        "title": "HERITRACE: Tracing Evolution and Bridging Data for Streamlined Curatorial Work in the GLAM Domain",
        "rating": "-10",
        "keywords": [],
        "abstract": "HERITRACE is a semantic data management system tailored for the GLAM sector. It is engineered to streamline data curation for non-technical users while also offering an efficient administrative interface for technical staff. The paper compares HERITRACE with other established platforms such as OmekaS, Semantic MediaWiki, Research Space, and CLEF, emphasizing its advantages in user friendliness, provenance management, change tracking, customization capabilities, and data integration. The system leverages SHACL for data modeling and employs the OpenCitations Data Model (OCDM) for provenance and change tracking, ensuring a harmonious blend of advanced technical features and user accessibility. Future developments include the integration of a robust authentication system and the expansion of data compatibility via the RDF Mapping Language (RML), enhancing HERITRACE's utility in digital heritage management.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "5 pages, 1 figure, submitted to AIUCD 2024"
    },
    {
        "paper id": "2402.00496",
        "abstract url": "https://arxiv.org/abs/2402.00496",
        "title": "Optimization of a Line Detection Algorithm for Autonomous Vehicles on a RISC-V with Accelerator",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, autonomous vehicles have attracted the attention of many research groups, both in academia and business, including researchers from leading companies such as Google, Uber and Tesla. This type of vehicles are equipped with systems that are subject to very strict requirements, essentially aimed at performing safe operations -- both for potential passengers and pedestrians -- as well as carrying out the processing needed for decision making in real time. In many instances, general-purpose processors alone cannot ensure that these safety, reliability and real-time requirements are met, so it is common to implement heterogeneous systems by including accelerators. This paper explores the acceleration of a line detection application in the autonomous car environment using a heterogeneous system consisting of a general-purpose RISC-V core and a domain-specific accelerator. In particular, the application is analyzed to identify the most computationally intensive parts of the code and it is adapted accordingly for more efficient processing. Furthermore, the code is executed on the aforementioned hardware platform to verify that the execution effectively meets the existing requirements in autonomous vehicles, experiencing a 3.7x speedup with respect to running without accelerator.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00502",
        "abstract url": "https://arxiv.org/abs/2402.00502",
        "title": "Axiomatizing NFAs Generated by Regular Grammars",
        "rating": "-10",
        "keywords": [],
        "abstract": "A subclass of nondeterministic Finite Automata generated by means of regular Grammars (GFAs, for short) is introduced. A process algebra is proposed, whose semantics maps a term to a GFA. We prove a representability theorem: for each GFA $N$, there exists a process algebraic term $p$ such that its semantics is a GFA isomorphic to $N$. Moreover, we provide a concise axiomatization of language equivalence: two GFAs $N_1$ and $N_2$ recognize the same regular language if and only if the associated terms $p_1$ and $p_2$, respectively, can be equated by means of a set of axioms, comprising 6 axioms plus 2 conditional axioms, only.",
        "subjects": [
            "cs.FL",
            "cs.LO"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2301.03435"
    },
    {
        "paper id": "2402.00519",
        "abstract url": "https://arxiv.org/abs/2402.00519",
        "title": "Towards Summarizing Code Snippets Using Pre-Trained Transformers",
        "rating": "-10",
        "keywords": [],
        "abstract": "When comprehending code, a helping hand may come from the natural language comments documenting it that, unfortunately, are not always there. To support developers in such a scenario, several techniques have been presented to automatically generate natural language summaries for a given code. Most recent approaches exploit deep learning (DL) to automatically document classes or functions, while little effort has been devoted to more fine-grained documentation (e.g., documenting code snippets or even a single statement). Such a design choice is dictated by the availability of training data: For example, in the case of Java, it is easy to create datasets composed of pairs <Method, Javadoc> that can be fed to DL models to teach them how to summarize a method. Such a comment-to-code linking is instead non-trivial when it comes to inner comments documenting a few statements. In this work, we take all the steps needed to train a DL model to document code snippets. First, we manually built a dataset featuring 6.6k comments that have been (i) classified based on their type (e.g., code summary, TODO), and (ii) linked to the code statements they document. Second, we used such a dataset to train a multi-task DL model, taking as input a comment and being able to (i) classify whether it represents a \"code summary\" or not and (ii) link it to the code statements it documents. Our model identifies code summaries with 84% accuracy and is able to link them to the documented lines of code with recall and precision higher than 80%. Third, we run this model on 10k projects, identifying and linking code summaries to the documented code. This unlocked the possibility of building a large-scale dataset of documented code snippets that have then been used to train a new DL model able to document code snippets. A comparison with state-of-the-art baselines shows the superiority of the proposed approach.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00533",
        "abstract url": "https://arxiv.org/abs/2402.00533",
        "title": "Reuse Detector: Improving the Management of STT-RAM SLLCs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Various constraints of Static Random Access Memory (SRAM) are leading to consider new memory technologies as candidates for building on-chip shared last-level caches (SLLCs). Spin-Transfer Torque RAM (STT-RAM) is currently postulated as the prime contender due to its better energy efficiency, smaller die footprint and higher scalability. However, STT-RAM also exhibits some drawbacks, like slow and energy-hungry write operations, that need to be mitigated. In this work we address these shortcomings by leveraging a new management mechanism for STT-RAM SLLCs. This approach is based on the previous observation that the stream of references arriving at the SLLC of a Chip MultiProcessor (CMP) exhibits reuse locality, i.e., those blocks referenced several times manifest high probability of forthcoming reuse. In this paper, we employ a cache management mechanism that selects the contents of the SLLC aimed to exploit reuse locality instead of temporal locality. Specifically, our proposal consists in the inclusion of a Reuse Detector between private cache levels and the STT-RAM SLLC to detect blocks that do not exhibit reuse, in order to avoid their insertion in the SLLC, hence reducing the number of write operations and the energy consumption in the STT-RAM. Our evaluation reveals that our scheme reports on average, energy reductions in the SLLC in the range of 37-30\\%, additional energy savings in the main memory in the range of 6-8\\% and performance improvements of 3\\% up to 14\\% (16-core) compared to an STT-RAM SLLC baseline where no reuse detector is employed. More importantly, our approach outperforms DASCA, the state-of-the-art STT-RAM SLLC management, reporting SLLC energy savings in the range of 4-11\\% higher than those of DASCA, delivering higher performance in the range of 1.5-14\\%, and additional improvements in DRAM energy consumption in the range of 2-9\\% higher than DASCA.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00540",
        "abstract url": "https://arxiv.org/abs/2402.00540",
        "title": "Experimental Evaluation of Interactive Edge/Cloud Virtual Reality Gaming over Wi-Fi using Unity Render Streaming",
        "rating": "-10",
        "keywords": [],
        "abstract": "Virtual Reality (VR) streaming enables end-users to seamlessly immerse themselves in interactive virtual environments using even low-end devices. However, the quality of the VR experience heavily relies on Wi-Fi performance, since it serves as the last hop in the network chain. Our study delves into the intricate interplay between Wi-Fi and VR traffic, drawing upon empirical data and leveraging a simulator tailored to VR traffic patterns. In this work we further evaluate Wi-Fi's suitability for VR streaming in terms of the quality of service it provides. In particular, we employ Unity Render Streaming to remotely stream real-time VR gaming content over Wi-Fi 6 using WebRTC, leveraging a server physically located at the network's edge, near the end user. Our findings demonstrate the system's sustained network performance, showcasing minimal round-trip time and jitter at 60 and 90 fps. In addition, we uncover the characteristics and patterns of the generated traffic streams, unveiling a surprising video transmission approach inherent to WebRTC-based services. This approach involves the fragmentation of video frames into discrete batches of packets, transmitted at regular intervals regardless of the targeted frame rate.This segmentation mechanism maintains consistent video packet delays across video frame rates but leads to increased Wi-Fi airtime consumption at higher frame rates. The presented results demonstrate that shortening the interval between batches is advantageous as it improves Wi-Fi efficiency and reduces delays in delivering complete frames.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "15 pages, 22 figures"
    },
    {
        "paper id": "2402.00542",
        "abstract url": "https://arxiv.org/abs/2402.00542",
        "title": "Hardness of Random Reordered Encodings of Parity for Resolution and CDCL",
        "rating": "-10",
        "keywords": [],
        "abstract": "Parity reasoning is challenging for Conflict-Driven Clause Learning (CDCL) SAT solvers. This has been observed even for simple formulas encoding two contradictory parity constraints with different variable orders (Chew and Heule 2020). We provide an analytical explanation for their hardness by showing that they require exponential resolution refutations with high probability when the variable order is chosen at random. We obtain this result by proving that these formulas, which are known to be Tseitin formulas, have Tseitin graphs of linear treewidth with high probability. Since such Tseitin formulas require exponential resolution proofs, our result follows. We generalize this argument to a new class of formulas that capture a basic form of parity reasoning involving a sum of two random parity constraints with random orders. Even when the variable order for the sum is chosen favorably, these formulas remain hard for resolution. In contrast, we prove that they have short DRAT refutations. We show experimentally that the running time of CDCL SAT solvers on both classes of formulas grows exponentially with their treewidth.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00562",
        "abstract url": "https://arxiv.org/abs/2402.00562",
        "title": "Endomorphisms of Linear Block Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "The automorphism groups of various linear codes are extensively studied yielding insights into the respective code structure. This knowledge is used in, e.g., theoretical analysis and in improving decoding performance, motivating the analyses of endomorphisms of linear codes. In this work, we discuss the structure of the set of transformation matrices of code endomorphisms, defined as a generalization of code automorphisms, and provide an explicit construction of a bijective mapping between the image of an endomorphism and its canonical quotient space. Furthermore, we introduce a one-to-one mapping between the set of transformation matrices of endomorphisms and a larger linear block code enabling the use of well-known algorithms for the search for suitable endomorphisms. Additionally, we propose an approach to obtain unknown code endomorphisms based on automorphisms of the code. Furthermore, we consider ensemble decoding as a possible use case for endomorphisms by introducing endomorphism ensemble decoding. Interestingly, EED can improve decoding performance when other ensemble decoding schemes are not applicable.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Accepted for presentation at International Symposium on Information Theory 2024; Included reviews: Changed some wordings, Indicate that 32,16 Polar code is a RM code; Smaller formatting changes, Results unchanged,"
    },
    {
        "paper id": "2402.00612",
        "abstract url": "https://arxiv.org/abs/2402.00612",
        "title": "Rhoban Football Club: RoboCup Humanoid Kid-Size 2023 Champion Team Paper",
        "rating": "-10",
        "keywords": [],
        "abstract": "In 2023, Rhoban Football Club reached the first place of the KidSize soccer competition for the fifth time, and received the best humanoid award. This paper presents and reviews important points in robots architecture and workflow, with hindsights from the competition.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00616",
        "abstract url": "https://arxiv.org/abs/2402.00616",
        "title": "Dual-Tap Optical-Digital Feedforward Equalization Enabling High-Speed Optical Transmission in IM/DD Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Intensity-modulation and direct-detection (IM/DD) transmission is widely adopted for high-speed optical transmission scenarios due to its cost-effectiveness and simplicity. However, as the data rate increases, the fiber chromatic dispersion (CD) would induce a serious power fading effect, and direct detection could generate inter-symbol interference (ISI). Moreover, the ISI becomes more severe with the increase of fiber length, thereby highly restricting the transmission distance of IM/DD systems. This paper proposes a dual-tap optical-digital feedforward equalization (DT-ODFE) scheme, which could effectively compensate for CD-induced power fading while maintaining low cost and simplicity. A theoretical channel response is formulated for IM/DD transmission, incorporating a dual-tap optical equalizer, and the theoretical analysis reveals that for an IM/DD transmission using 1371nm over 10km standard single-mode fiber (SSMF), frequency notch is removed from 33.7GHz to 46GHz. Simulation results show that the DT- ODFE achieves an SNR gain of 2.3dB over IM/DD systems with symbol-space feedforward equalizer (FFE) alone. As the fiber length increases to 15 km, DT- ODFE performs well, while FFE, decision-feedback equalizer (DFE) and Volterra nonlinear equalizers (VNLE) all fail to compensate for the power fading and the 7% hard-decision FEC limit is not satisfied. For 200 Gb/s/$\u03bb$ PAM-4 over 15km SSMF, results show that the signal-to-noise ratio (SNR) of the proposed DT- ODFE with optimal coefficients satisfies the 7% hard-decision FEC limit, which uncovers the great potential of the DT- ODFE for high-speed IM/DD systems in LR/FR scenarios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 7 gigures, journal"
    },
    {
        "paper id": "2402.00625",
        "abstract url": "https://arxiv.org/abs/2402.00625",
        "title": "Bialgebraic Reasoning on Higher-Order Program Equivalence",
        "rating": "-10",
        "keywords": [],
        "abstract": "Logical relations constitute a key method for reasoning about contextual equivalence of programs in higher-order languages. They are usually developed on a per-case basis, with a new theory required for each variation of the language or of the desired notion of equivalence. In the present paper we introduce a general construction of (step-indexed) logical relations at the level of Higher-Order Mathematical Operational Semantics, a highly parametric categorical framework for modeling the operational semantics of higher-order languages. Our main result asserts that for languages whose weak operational model forms a lax bialgebra, the logical relation is automatically sound for contextual equivalence. Our abstract theory is shown to instantiate to combinatory logics and $\u03bb$-calculi with recursive types, and to different flavours of contextual equivalence.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00646",
        "abstract url": "https://arxiv.org/abs/2402.00646",
        "title": "Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable Intelligent Surfaces",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the integration of beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) into cell-free massive multiple-input multiple-output (CF-mMIMO) systems, focusing on applications involving simultaneous wireless information and power transfer (SWIPT). The system supports concurrently two user groups: information users (IUs) and energy users (EUs). A BD-RIS is employed to enhance the wireless power transfer (WPT) directed towards the EUs. To comprehensively evaluate the system's performance, we present an analytical framework for the spectral efficiency (SE) of IUs and the average harvested energy (HE) of EUs in the presence of spatial correlation among the BD-RIS elements and for a non-linear energy harvesting circuit. Our findings offer important insights into the transformative potential of BD-RIS, setting the stage for the development of more efficient and effective SWIPT networks. Finally, incorporating a heuristic scattering matrix design at the BD-RIS results in a substantial improvement compared to the scenario with random scattering matrix design.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00649",
        "abstract url": "https://arxiv.org/abs/2402.00649",
        "title": "Improving the Representativeness of Simulation Intervals for the Cache Memory System",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurate simulation techniques are indispensable to efficiently propose new memory or architectural organizations. As implementing new hardware concepts in real systems is often not feasible, cycle-accurate simulators employed together with certain benchmarks are commonly used. However, detailed simulators may take too much time to execute these programs until completion. Therefore, several techniques aimed at reducing this time are usually employed. These schemes select fragments of the source code considered as representative of the entire application's behaviour -- mainly in terms of performance, but not plenty considering the behaviour of cache memory levels -- and only these intervals are simulated. Our hypothesis is that the different simulation windows currently employed when evaluating microarchitectural proposals, especially those involving the last level cache (LLC), do not reproduce the overall cache behaviour during the entire execution, potentially leading to wrong conclusions on the real performance of the proposals assessed. In this work, we first demonstrate this hypothesis by evaluating different cache replacement policies using various typical simulation approaches. Consequently, we also propose a simulation strategy, based on the applications' LLC activity, which mimics the overall behaviour of the cache much closer than conventional simulation intervals. Our proposal allows a fairer comparison between cache-related approaches as it reports, on average, a number of changes in the relative order among the policies assessed -- with respect to the full simulation -- more than 30\\% lower than that of conventional strategies, maintaining the simulation time largely unchanged and without losing accuracy on performance terms, especially for memory-intensive applications.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00657",
        "abstract url": "https://arxiv.org/abs/2402.00657",
        "title": "Pre-training by Predicting Program Dependencies for Vulnerability Analysis Tasks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Vulnerability analysis is crucial for software security. This work focuses on using pre-training techniques to enhance the understanding of vulnerable code and boost vulnerability analysis. The code understanding ability of a pre-trained model is highly related to its pre-training objectives. The semantic structure, e.g., control and data dependencies, of code is important for vulnerability analysis. However, existing pre-training objectives either ignore such structure or focus on learning to use it. The feasibility and benefits of learning the knowledge of analyzing semantic structure have not been investigated. To this end, this work proposes two novel pre-training objectives, namely Control Dependency Prediction (CDP) and Data Dependency Prediction (DDP), which aim to predict the statement-level control dependencies and token-level data dependencies, respectively, in a code snippet only based on its source code. During pre-training, CDP and DDP can guide the model to learn the knowledge required for analyzing fine-grained dependencies in code. After pre-training, the pre-trained model can boost the understanding of vulnerable code during fine-tuning and can directly be used to perform dependence analysis for both partial and complete functions. To demonstrate the benefits of our pre-training objectives, we pre-train a Transformer model named PDBERT with CDP and DDP, fine-tune it on three vulnerability analysis tasks, i.e., vulnerability detection, vulnerability classification, and vulnerability assessment, and also evaluate it on program dependence analysis. Experimental results show that PDBERT benefits from CDP and DDP, leading to state-of-the-art performance on the three downstream tasks. Also, PDBERT achieves F1-scores of over 99% and 94% for predicting control and data dependencies, respectively, in partial and complete functions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by ICSE 2024"
    },
    {
        "paper id": "2402.00665",
        "abstract url": "https://arxiv.org/abs/2402.00665",
        "title": "Revising Apetrei's bounding volume hierarchy construction algorithm to allow stackless traversal",
        "rating": "-10",
        "keywords": [],
        "abstract": "Stackless traversal is a technique to speed up range queries by avoiding usage of a stack during the tree traversal. One way to achieve that is to transform a given binary tree to store a left child and a skip-connection (also called an escape index). In general, this operation requires an additional tree traversal during the tree construction. For some tree structures, however, it is possible achieve the same result at a reduced cost. We propose one such algorithm for a GPU hierarchy construction algorithm proposed by Karras in [Karras, 2012]. Furthermore, we show that our algorithm also works with the improved algorithm proposed by Apetrei in [Apetrei, 2014], despite a different ordering of the internal nodes. We achieve that by modifying the Apetrei's algorithm to restore the original Karras' ordering of the internal nodes. Using the modified algorithm, we show how to construct a hierarchy suitable for a stackless traversal in a single bottom-up pass.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2402.00671",
        "abstract url": "https://arxiv.org/abs/2402.00671",
        "title": "Uncertainty-Aware Guidance for Target Tracking subject to Intermittent Measurements using Motion Model Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "This letter presents a novel guidance law for target tracking applications where the target motion model is unknown and sensor measurements are intermittent due to unknown environmental conditions and low measurement update rate. In this work, the target motion model is represented by a transformer-based neural network and trained by previous target position measurements. This neural network (NN)-based motion model serves as the prediction step in a particle filter for target state estimation and uncertainty quantification. Then this estimation uncertainty is utilized in the information-driven guidance law to compute a path for the mobile agent to travel to a position with maximum expected entropy reduction (EER). The computation of EER is performed in real-time by approximating the probability distribution of the state using the particle representation from particle filter. Simulation and hardware experiments are performed with a quadcopter agent and TurtleBot target to demonstrate that the presented guidance law outperforms two other baseline guidance methods.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00684",
        "abstract url": "https://arxiv.org/abs/2402.00684",
        "title": "An Investigation of Hardware Security Bug Characteristics in Open-Source Projects",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hardware security is an important concern of system security as vulnerabilities can arise from design errors introduced throughout the development lifecycle. Recent works have proposed techniques to detect hardware security bugs, such as static analysis, fuzzing, and symbolic execution. However, the fundamental properties of hardware security bugs remain relatively unexplored. To gain a better understanding of hardware security bugs, we perform a deep dive into the popular OpenTitan project, including its bug reports and bug fixes. We manually classify the bugs as relevant to functionality or security and analyze characteristics, such as the impact and location of security bugs, and the size of their bug fixes. We also investigate relationships between security impact and bug management during development. Finally, we propose an abstract syntax tree-based analysis to identify the syntactic characteristics of bug fixes. Our results show that 53% of the bugs in OpenTitan have potential security implications and that 55% of all bug fixes modify only one file. Our findings underscore the importance of security-aware development practices and tools and motivate the development of techniques that leverage the highly localized nature of hardware bugs.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "7 pages, 8 figures"
    },
    {
        "paper id": "2402.00691",
        "abstract url": "https://arxiv.org/abs/2402.00691",
        "title": "Comparative Study of Large Language Model Architectures on Frontier",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models (LLMs) have garnered significant attention in both the AI community and beyond. Among these, the Generative Pre-trained Transformer (GPT) has emerged as the dominant architecture, spawning numerous variants. However, these variants have undergone pre-training under diverse conditions, including variations in input data, data preprocessing, and training methodologies, resulting in a lack of controlled comparative studies. Here we meticulously examine two prominent open-sourced GPT architectures, GPT-NeoX and LLaMA, leveraging the computational power of Frontier, the world's first Exascale supercomputer. Employing the same materials science text corpus and a comprehensive end-to-end pipeline, we conduct a comparative analysis of their training and downstream performance. Our efforts culminate in achieving state-of-the-art performance on a challenging materials science benchmark. Furthermore, we investigate the computation and energy efficiency, and propose a computationally efficient method for architecture design. To our knowledge, these pre-trained models represent the largest available for materials science. Our findings provide practical guidance for building LLMs on HPC platforms.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00719",
        "abstract url": "https://arxiv.org/abs/2402.00719",
        "title": "Orientation-aware Incremental Potential Contact",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Incremental Potential Contact (IPC) method enables robust complex simulations of deformable objects with contact and friction. The key to IPC's robustness is its strict adherence to geometric constraints, avoiding intersections, which are a common cause of robustness issues in contact mechanics. A key element of the IPC approach to contact is a geometric barrier function, which is defined directly in the discrete setting. While IPC achieves its main goal of providing guarantees for contact constraints, its parameters need to be chosen carefully to avoid significant simulation artifacts and inaccuracies. We present a systematic derivation of an IPC-like continuum potential defined for smooth and piecewise smooth surfaces, starting from identifying a set of natural requirements for contact potentials, including the barrier property, locality, differentiable dependence of shape, and absence of forces in rest configurations, based on the idea of candidate sets. Our potential is formulated in a way independent of surface discretization. This new potential is suitable for piecewise-linear surfaces and its efficiency is similar to standard IPC. We demonstrate its behavior and compare it to IPC on a range of challenging contact examples.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00764",
        "abstract url": "https://arxiv.org/abs/2402.00764",
        "title": "To Search or To Gen? Exploring the Synergy between Generative AI and Web Search in Programming",
        "rating": "-10",
        "keywords": [],
        "abstract": "The convergence of generative AI and web search is reshaping problem-solving for programmers. However, the lack of understanding regarding their interplay in the information-seeking process often leads programmers to perceive them as alternatives rather than complementary tools. To analyze this interaction and explore their synergy, we conducted an interview study with eight experienced programmers. Drawing from the results and literature, we have identified three major challenges and proposed three decision-making stages, each with its own relevant factors. Additionally, we present a comprehensive process model that captures programmers' interaction patterns. This model encompasses decision-making stages, the information-foraging loop, and cognitive activities during system interaction, offering a holistic framework to comprehend and optimize the use of these convergent tools in programming.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00771",
        "abstract url": "https://arxiv.org/abs/2402.00771",
        "title": "Mixed Static and Reconfigurable Metasurface Deployment in Indoor Dense Spaces: How Much Reconfigurability is Needed?",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate how metasurfaces can be deployed to deliver high data rates in a millimeter-wave (mmWave) indoor dense space with many blocking objects. These surfaces can either be static metasurfaces (SMSs) that reflect with fixed phase-shifts or reconfigurable intelligent surfaces (RISs) that can reconfigure their phase-shifts to the currently served user. The latter comes with an increased power, cabling, and signaling cost. To see how reconfigurability affects the network performance, we propose an iterative algorithm based on the feasible point pursuit successive convex approximation method. We jointly optimize the types and phase-shifts of the surfaces and the time portion allocated to each user equipment to maximize the minimum data rate achieved by the network. Our numerical results demonstrate that the minimum data rate improves as more RISs are introduced but the gain diminishes after some point. Therefore, introducing more reconfigurability is not always necessary. Another result shows that to reach the same data rate achieved by using 22 SMSs, at least 18 RISs are needed. This suggests that when it is costly to deploy many RISs, as an inexpensive alternative solution, one can reach the same data rate just by densely deploying more SMSs.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 5 figures, Accepted to be presented in IEEE WCNC 2024"
    },
    {
        "paper id": "2402.00772",
        "abstract url": "https://arxiv.org/abs/2402.00772",
        "title": "Neural Risk Limiting Dispatch in Power Networks: Formulation and Generalization Guarantees",
        "rating": "-10",
        "keywords": [],
        "abstract": "Risk limiting dispatch (RLD) has been proposed as an approach that effectively trades off economic costs with operational risks for power dispatch under uncertainty. However, how to solve the RLD problem with provably near-optimal performance still remains an open problem. This paper presents a learning-based solution to this challenge. We first design a data-driven formulation for the RLD problem, which aims to construct a decision rule that directly maps day-ahead observable information to cost-effective dispatch decisions for the future delivery interval. Unlike most existing works that follow a predict-then-optimize paradigm, this end-to-end rule bypasses the additional suboptimality introduced by separately handling prediction and optimization. We then propose neural RLD, a novel solution method to the data-driven formulation. This method leverages an L2-regularized neural network to learn the decision rule, thereby transforming the data-driven formulation into a neural network training task that can be efficiently completed by stochastic gradient descent. A theoretical performance guarantee is further established to bound the suboptimality of our method, which implies that its suboptimality approaches to zero with high probability as more samples are utilized. Simulation tests across various systems demonstrate our method's superior performance in convergence, suboptimality, and computational efficiency compared with benchmarks.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2402.00773",
        "abstract url": "https://arxiv.org/abs/2402.00773",
        "title": "On the Choice of Loss Function in Learning-based Optimal Power Flow",
        "rating": "-10",
        "keywords": [],
        "abstract": "We analyze and contrast two ways to train machine learning models for solving AC optimal power flow (OPF) problems, distinguished with the loss functions used. The first trains a mapping from the loads to the optimal dispatch decisions, utilizing mean square error (MSE) between predicted and optimal dispatch decisions as the loss function. The other intends to learn the same mapping, but directly uses the OPF cost of the predicted decisions, referred to as decision loss, as the loss function. In addition to better aligning with the OPF cost which results in reduced suboptimality, the use of decision loss can circumvent feasibility issues that arise with MSE when the underlying mapping from loads to optimal dispatch is discontinuous. Since decision loss does not capture the OPF constraints, we further develop a neural network with a specific structure and introduce a modified training algorithm incorporating Lagrangian duality to improve feasibility.} This result in an improved performance measured by feasibility and suboptimality as demonstrated with an IEEE 39-bus case study.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "5 pages, Accepted by PESGM2024"
    },
    {
        "paper id": "2402.00791",
        "abstract url": "https://arxiv.org/abs/2402.00791",
        "title": "Hausdorff Reductions and the Exponential Hierarchies",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Strong Exponential Hierarchy $SEH$ was shown to collapse to $P^{NExp}$ by Hemachandra by proving $P^{NExp} = NP^{NExp}$ via a census argument. Nonetheless, Hemachandra also asked for certificate-based and alternating Turing machine characterizations of the $SEH$ levels, in the hope that these might have revealed deeper structural reasons behind the collapse. These open questions have thus far remained unanswered. To close them, by building upon the notion of Hausdorff reductions, we investigate a natural normal form for the intermediate levels of the (generalized) exponential hierarchies, i.e., the single-, the double-Exponential Hierarchy, and so on. Although the two characterizations asked for derive from our Hausdorff characterization, it is nevertheless from the latter that a surprising structural reason behind the collapse of $SEH$ is uncovered as a consequence of a very general result: the intermediate levels of the exponential hierarchies are precisely characterized by specific \"Hausdorff classes\", which define these levels without resorting to oracle machines. By this, contrarily to oracle classes, which may have different shapes for a same class (e.g., $P^{NP}_{||} = P^{NP[Log]} = LogSpace^{NP}$), hierarchy intermediate levels are univocally identified by Hausdorff classes (under the hypothesis of no hierarchy collapse). In fact, we show that the rather simple reason behind many equivalences of oracle classes is that they just refer to different ways of deciding the languages of a same Hausdorff class, and this happens also for $P^{NExp}$ and $NP^{NExp}$. In addition, via Hausdorff classes, we define complete problems for various intermediate levels of the exponential hierarchies. Through these, we obtain matching lower-bounds for problems known to be in $P^{NExp[Log]}$, but whose hardness was left open due to the lack of known $P^{NExp[Log]}$-complete problems.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "ii + 100 pages, 3 figures"
    },
    {
        "paper id": "2402.00845",
        "abstract url": "https://arxiv.org/abs/2402.00845",
        "title": "When to Preempt in a Status Update System?",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a time slotted status update system with an error-free preemptive queue. The goal of the sampler-scheduler pair is to minimize the age of information at the monitor by sampling and transmitting the freshly sampled update packets to the monitor. The sampler-scheduler pair also has a choice to preempt an old update packet from the server and transmit a new update packet to the server. We formulate this problem as a Markov decision process and find the optimal sampling policy. We show that it is optimal for the sampler-scheduler pair to sample a new packet immediately upon the reception of an update packet at the monitor. We also show that the optimal choice for the scheduler is to preempt an update packet in the server, if the age of that packet crosses a fixed threshold. Finally, we find the optimal preemption threshold when the range of the service time of the server is finite, otherwise we find the $\u03b5$-optimal preemption threshold.",
        "subjects": [
            "cs.IT",
            "cs.GT",
            "cs.NI",
            "eess.SP",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00850",
        "abstract url": "https://arxiv.org/abs/2402.00850",
        "title": "Constant Degree Direct Product Testers with Small Soundness",
        "rating": "-10",
        "keywords": [],
        "abstract": "Let $X$ be a $d$-dimensional simplicial complex. A function $F\\colon X(k)\\to \\{0,1\\}^k$ is said to be a direct product function if there exists a function $f\\colon X(1)\\to \\{0,1\\}$ such that $F(\u03c3) = (f(\u03c3_1), \\ldots, f(\u03c3_k))$ for each $k$-face $\u03c3$. In an effort to simplify components of the PCP theorem, Goldreich and Safra introduced the problem of direct product testing, which asks whether one can test if $F\\colon X(k)\\to \\{0,1\\}^k$ is correlated with a direct product function by querying $F$ on only $2$ inputs. Dinur and Kaufman conjectured that there exist bounded degree complexes with a direct product test in the small soundness regime. We resolve their conjecture by showing that for all $\u03b4>0$, there exists a family of high-dimensional expanders with degree $O_\u03b4(1)$ and a $2$-query direct product tester with soundness $\u03b4$. We use the characterization given by a subset of the authors and independently by Dikstein and Dinur, who showed that some form of non-Abelian coboundary expansion (which they called \"Unique-Games coboundary expansion\") is a necessary and sufficient condition for a complex to admit such direct product testers. Our main technical contribution is a general technique for showing coboundary expansion of complexes with coefficients in a non-Abelian group. This allows us to prove that the high dimensional expanders constructed by Chapman and Lubotzky satisfies the necessary conditions, thus admitting a 2-query direct product tester with small soundness.",
        "subjects": [
            "cs.CC",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00924",
        "abstract url": "https://arxiv.org/abs/2402.00924",
        "title": "The Fragile Nature of Road Transportation Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Major cities worldwide experience problems with the performance of their road transportation systems. The continuous increase in traffic demand presents a substantial challenge to the optimal operation of urban road networks and the efficiency of traffic control strategies. Although robust and resilient transportation systems have been extensively researched over the past decades, their performance under an ever-growing traffic demand can still be questionable. The operation of transportation systems is widely believed to display fragile property, i.e., the loss in performance increases exponentially with the linearly increasing magnitude of disruptions, which undermines their continuous operation. The risk engineering community is now embracing the novel concept of (anti-)fragility, which enables systems to learn from historical disruptions and exhibit improved performance as disruption levels reach unprecedented magnitudes. In this study, we demonstrate the fragile nature of road transportation systems when faced with either demand or supply disruptions. First, we conducted a rigorous mathematical analysis to theoretically establish the fragile nature of the systems. Subsequently, by taking into account real-world stochasticity, we implemented a numerical simulation with realistic network data to bridge the gap between the theoretical proof and the real-world operations, to study the impact of uncertainty on the fragile property of the systems. This work aims to help researchers better comprehend the necessity to explicitly consider antifragile design toward the application of future traffic control strategies, coping with constantly growing traffic demand and subsequent traffic accidents.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "30 pages, 11 figures"
    },
    {
        "paper id": "2402.00948",
        "abstract url": "https://arxiv.org/abs/2402.00948",
        "title": "Nanomechanically Induced Transparency",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate a nanomechanically induced transparency (NIT) effects that arises from the coupling of a nanoelectromechanical system and a trapped ion. By confining the ion in mesoscopic traps and capacitively coupling it with a nanoelectromechanical system suspended as electrodes, the research is intricately focussed on the implications of including the ion's degrees of freedom. The Lamb--Dicke approximation is crucial to understanding the effects of phonon exchange with electronic qubits and revealing transparency phenomena in this unique coupling. The results underline the importance of the Lamb--Dicke approximation in modelling the effects of transparency windows in nanoelectromechanical systems.",
        "subjects": [
            "cs.IT",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00958",
        "abstract url": "https://arxiv.org/abs/2402.00958",
        "title": "Reflection and Preservation of Properties in Coalgebraic (bi)Simulations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Our objective is to extend the standard results of preservation and reflection of properties by bisimulations to the coalgebraic setting, as well as to study under what conditions these results hold for simulations. The notion of bisimulation is the classical one, while for simulations we use that proposed by Hughes and Jacobs. As for properties, we start by using a generalization of linear temporal logic to arbitrary coalgebras suggested by Jacobs, and then an extension by Kurtz which includes atomic propositions too.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00962",
        "abstract url": "https://arxiv.org/abs/2402.00962",
        "title": "Multiset Bisimulations as a Common Framework for Ordinary and Probabilistic Bisimulations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Our concrete objective is to present both ordinary bisimulations and probabilistic bisimulations in a common coalgebraic framework based on multiset bisimulations. For that we show how to relate the underlying powerset and probabilistic distributions functors with the multiset functor by means of adequate natural transformations. This leads us to the general topic that we investigate in the paper: a natural transformation from a functor F to another G transforms F-bisimulations into G-bisimulations but, in general, it is not possible to express G-bisimulations in terms of F-bisimulations. However, they can be characterized by considering Hughes and Jacobs' notion of simulation, taking as the order on the functor F the equivalence induced by the epi-mono decomposition of the natural transformation relating F and G. We also consider the case of alternating probabilistic systems where non-deterministic and probabilistic choices are mixed, although only in a partial way, and extend all these results to categorical simulations.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00963",
        "abstract url": "https://arxiv.org/abs/2402.00963",
        "title": "Non-strongly Stable Orders Also Define Interesting Simulation Relations",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a study of the notion of coalgebraic simulation introduced by Hughes and Jacobs. Although in their original paper they allow any functorial order in their definition of coalgebraic simulation, for the simulation relations to have good properties they focus their attention on functors with orders which are strongly stable. This guarantees a so-called \"composition-preserving\" property from which all the desired good properties follow. We have noticed that the notion of strong stability not only ensures such good properties but also \"distinguishes the direction\" of the simulation. For example, the classic notion of simulation for labeled transition systems, the relation \"p is simulated by q\", can be defined as a coalgebraic simulation relation by means of a strongly stable order, whereas the opposite relation, \"p simulates q\", cannot. Our study was motivated by some interesting classes of simulations that illustrate the application of these results: covariant-contravariant simulations and conformance simulations.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00964",
        "abstract url": "https://arxiv.org/abs/2402.00964",
        "title": "Logics for Contravariant Simulations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Covariant-contravariant simulation and conformance simulation are two generalizations of the simple notion of simulation which aim at capturing the fact that it is not always the case that \"the larger the number of behaviors, the better\". Therefore, they can be considered to be more adequate to express the fact that a system is a correct implementation of some specification. We have previously shown that these two more elaborated notions fit well within the categorical framework developed to study the notion of simulation in a generic way. Now we show that their behaviors have also simple and natural logical characterizations, though more elaborated than those for the plain simulation semantics.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.00966",
        "abstract url": "https://arxiv.org/abs/2402.00966",
        "title": "On the specification of modal systems: A comparison of three frameworks",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper studies the relationships between three notions of behavioural preorder that have been proposed in the literature: refinement over modal transition systems, and the covariant-contravariant simulation and the partial bisimulation preorders over labelled transition systems. It is shown that there are mutual translations between modal transition systems and labelled transition systems that preserve, and reflect, refinement and the covariant-contravariant simulation preorder. The translations are also shown to preserve the modal properties that can be expressed in the logics that characterize those preorders. A translation from labelled transition systems modulo the partial bisimulation preorder into the same model modulo the covariant-contravariant simulation preorder is also offered, together with some evidence that the former model is less expressive than the latter. In order to gain more insight into the relationships between modal transition systems modulo refinement and labelled transition systems modulo the covariant-contravariant simulation preorder, their connections are also phrased and studied in the context of institutions.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Replaced conference version with the extended paper published in a journal (This update includes a change in the title of the paper)"
    },
    {
        "paper id": "2402.00970",
        "abstract url": "https://arxiv.org/abs/2402.00970",
        "title": "When Are Prime Formulae Characteristic?",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the setting of the modal logic that characterizes modal refinement over modal transition systems, Boudol and Larsen showed that the formulae for which model checking can be reduced to preorder checking, that is, the characteristic formulae, are exactly the consistent and prime ones. This paper presents general, sufficient conditions guaranteeing that characteristic formulae are exactly the consistent and prime ones. It is shown that the given conditions apply to various behavioural relations in the literature. In particular, characteristic formulae are exactly the prime and consistent ones for all the semantics in van Glabbeek's linear time-branching time spectrum.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Updated conference version with the extended version"
    },
    {
        "paper id": "2402.00973",
        "abstract url": "https://arxiv.org/abs/2402.00973",
        "title": "Logical characterisations, rule formats and compositionality for input-output conformance simulation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Input-output conformance simulation (iocos) has been proposed by Gregorio-Rodr\u00edguez, Llana and Mart\u00ednez-Torres as a simulation-based behavioural preorder underlying model-based testing. This relation is inspired by Tretmans' classic ioco relation, but has better worst-case complexity than ioco and supports stepwise refinement. The goal of this paper is to develop the theory of iocos by studying logical characterisations of this relation, rule formats for it and its compositionality. More specifically, this article presents characterisations of iocos in terms of modal logics and compares them with an existing logical characterisation for ioco proposed by Beohar and Mousavi. It also offers a characteristic-formula construction for iocos over finite processes in an extension of the proposed modal logics with greatest fixed points. A precongruence rule format for iocos and a rule format ensuring that operations take quiescence properly into account are also given. Both rule formats are based on the GSOS format by Bloom, Istrail and Meyer. The general modal decomposition methodology of Fokkink and van Glabbeek is used to show how to check the satisfaction of properties expressed in the logic for iocos in a compositional way for operations specified by rules in the precongruence rule format for iocos .",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Replaced conference version for extended version (this includes a change in the name of the paper plus additional sections and results)"
    },
    {
        "paper id": "2402.00982",
        "abstract url": "https://arxiv.org/abs/2402.00982",
        "title": "Rule Formats for Nominal Process Calculi",
        "rating": "-10",
        "keywords": [],
        "abstract": "The nominal transition systems (NTSs) of Parrow et al. describe the operational semantics of nominal process calculi. We study NTSs in terms of the nominal residual transition systems (NRTSs) that we introduce. We provide rule formats for the specifications of NRTSs that ensure that the associated NRTS is an NTS and apply them to the operational specification of the early pi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. and from earlier works in nominal sets and nominal logic by Gabbay, Pitts and their collaborators.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Conference version of arXiv:1807.02081"
    },
    {
        "paper id": "2402.00999",
        "abstract url": "https://arxiv.org/abs/2402.00999",
        "title": "RDNF Oriented Analytics to Random Boolean Functions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Dominant areas of computer science and computation systems are intensively linked to the hypercube-related studies and interpretations. This article presents some transformations and analytics for some example algorithms and Boolean domain problems. Our focus is on the methodology of complexity evaluation and integration of several types of postulations concerning special hypercube structures. Our primary goal is to demonstrate the usual formulas and analytics in this area, giving the necessary set of common formulas often used for complexity estimations and approximations. The basic example under considered is the Boolean minimization problem, in terms of the average complexity of the so-called reduced disjunctive normal form (also referred to as complete, prime irredundant, or Blake canonical form). In fact, combinatorial counterparts of the disjunctive normal form complexities are investigated in terms of sets of their maximal intervals. The results obtained compose the basis of logical separation classification algorithmic technology of pattern recognition. In fact, these considerations are not only general tools of minimization investigations of Boolean functions, but they also prove useful structures, models, and analytics for constraint logic programming, machine learning, decision policy optimization and other domains of computer science.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01001",
        "abstract url": "https://arxiv.org/abs/2402.01001",
        "title": "Ensuring Data Privacy in AC Optimal Power Flow with a Distributed Co-Simulation Framework",
        "rating": "-10",
        "keywords": [],
        "abstract": "During the energy transition, the significance of collaborative management among institutions is rising, confronting challenges posed by data privacy concerns. Prevailing research on distributed approaches, as an alternative to centralized management, often lacks numerical convergence guarantees or is limited to single-machine numerical simulation. To address this, we present a distributed approach for solving AC Optimal Power Flow (OPF) problems within a geographically distributed environment. This involves integrating the energy system Co-Simulation (eCoSim) module in the eASiMOV framework with the convergence-guaranteed distributed optimization algorithm, i.e., the Augmented Lagrangian based Alternating Direction Inexact Newton method (ALADIN). Comprehensive evaluations across multiple system scenarios reveal a marginal performance slowdown compared to the centralized approach and the distributed approach executed on single machines -- a justified trade-off for enhanced data privacy. This investigation serves as empirical validation of the successful execution of distributed AC OPF within a geographically distributed environment, highlighting potential directions for future research.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01007",
        "abstract url": "https://arxiv.org/abs/2402.01007",
        "title": "Municipal cyber risk modeling using cryptographic computing to inform cyber policymaking",
        "rating": "-10",
        "keywords": [],
        "abstract": "Municipalities are vulnerable to cyberattacks with devastating consequences, but they lack key information to evaluate their own risk and compare their security posture to peers. Using data from 83 municipalities collected via a cryptographically secure computation platform about their security posture, incidents, security control failures, and losses, we build data-driven cyber risk models and cyber security benchmarks for municipalities. We produce benchmarks of the security posture in a sector, the frequency of cyber incidents, forecasted annual losses for organizations based on their defensive posture, and a weighting of cyber controls based on their individual failure rates and associated losses. Combined, these four items can help guide cyber policymaking by quantifying the cyber risk in a sector, identifying gaps that need to be addressed, prioritizing policy interventions, and tracking progress of those interventions over time. In the case of the municipalities, these newly derived risk measures highlight the need for continuous measured improvement of cybersecurity readiness, show clear areas of weakness and strength, and provide governments with some early targets for policy focus such as security education, incident response, and focusing efforts first on municipalities at the lowest security levels that have the highest risk reduction per security dollar invested.",
        "subjects": [
            "cs.CR",
            "econ.GN"
        ],
        "comment": "Working Draft for Presentation at the Cybersecurity Law and Policy Scholars Conference - September 29, 2023"
    },
    {
        "paper id": "2402.01008",
        "abstract url": "https://arxiv.org/abs/2402.01008",
        "title": "CF4J: Collaborative Filtering for Java",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recommender Systems (RS) provide a relevant tool to mitigate the information overload problem. A large number of researchers have published hundreds of papers to improve different RS features. It is advisable to use RS frameworks that simplify RS researchers: a) to design and implement recommendations methods and, b) to speed up the execution time of the experiments. In this paper, we present CF4J, a Java library designed to carry out Collaborative Filtering based RS research experiments. CF4J has been designed from researchers to researchers. It allows: a) RS datasets reading, b) full and easy access to data and intermediate or final results, c) to extend their main functionalities, d) to concurrently execute the implemented methods, and e) to provide a thorough evaluation for the implementations by quality measures. In summary, CF4J serves as a library specifically designed for the research trial and error process.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01009",
        "abstract url": "https://arxiv.org/abs/2402.01009",
        "title": "Compositional Expected Cost Analysis of Functional Probabilistic Programs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reasoning about resources used during the execution of programs, such as time, is one of the fundamental questions in computer science. When programming with probabilistic primitives, however, different samples may result in different resource usage, making the cost of a program not a single number but a distribution instead. The expected cost is an important metric used to quantify the efficiency of probabilistic programs. In this work we introduce $\\mathbf{cert}$, a call-by-push-value (CBPV) metalanguage extended with primitives for probability, cost and unbounded recursion, and give it denotational semantics for reasoning about the average cost of programs. We justify the validity of the semantics by presenting case-studies ranging from randomized algorithms to stochastic processes and showing how the semantics captures their intended cost.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01010",
        "abstract url": "https://arxiv.org/abs/2402.01010",
        "title": "A generalized essentially non-hourglass total Lagrangian SPH solid dynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we tackle a persistent numerical instability within the total Lagrangian smoothed particle hydrodynamics (TLSPH) solid dynamics. Specifically, we address the hourglass modes that may grow and eventually deteriorate the reliability of simulation, particularly in the scenarios characterized by large deformations. We propose a generalized essentially non-hourglass formulation based on volumetric-deviatoric stress decomposition, offering a general solution for elasticity, plasticity, anisotropy, and other material models. Comparing the standard SPH formulation with the original non-nested Laplacian operator applied in our previous work \\cite{wu2023essentially} to handle the hourglass issues in standard elasticity, we introduce a correction for the discretization of shear stress that relies on the discrepancy produced by a tracing-back prediction of the initial inter-particle direction from the current deformation gradient. The present formulation, when applied to standard elastic materials, is able to recover the original Laplacian operator. Due to the dimensionless nature of the correction, this formulation handles complex material models in a very straightforward way. Furthermore, a magnitude limiter is introduced to minimize the correction in domains where the discrepancy is less pronounced. The present formulation is validated, with a single set of modeling parameters, through a series of benchmark cases, confirming good stability and accuracy across elastic, plastic, and anisotropic materials. To showcase its potential, the formulation is employed to simulate a complex problem involving viscous plastic Oobleck material, contacts, and very large deformation.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "61 pages, 37 figures"
    },
    {
        "paper id": "2402.01011",
        "abstract url": "https://arxiv.org/abs/2402.01011",
        "title": "Ruling Out Low-rank Matrix Multiplication Tensor Decompositions with Symmetries via SAT",
        "rating": "-10",
        "keywords": [],
        "abstract": "We analyze rank decompositions of the $3\\times 3$ matrix multiplication tensor over $\\mathbb{Z}/2\\mathbb{Z}$. We restrict our attention to decompositions of rank $\\le 21$, as only those decompositions will yield an asymptotically faster algorithm for matrix multiplication than Strassen's algorithm. To reduce search space, we also require decompositions to have certain symmetries. Using Boolean SAT solvers, we show that under certain symmetries, such decompositions do not exist.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "submitted to ISSAC 2024; 8 pages, 0 figures"
    },
    {
        "paper id": "2402.01021",
        "abstract url": "https://arxiv.org/abs/2402.01021",
        "title": "Towards Understanding the Challenges of Bug Localization in Deep Learning Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software bugs cost the global economy billions of dollars annually and claim ~50\\% of the programming time from software developers. Locating these bugs is crucial for their resolution but challenging. It is even more challenging in deep-learning systems due to their black-box nature. Bugs in these systems are also hidden not only in the code but also in the models and training data, which might make traditional debugging methods less effective. In this article, we conduct a large-scale empirical study to better understand the challenges of localizing bugs in deep-learning systems. First, we determine the bug localization performance of four existing techniques using 2,365 bugs from deep-learning systems and 2,913 from traditional software. We found these techniques significantly underperform in localizing deep-learning system bugs. Second, we evaluate how different bug types in deep learning systems impact bug localization. We found that the effectiveness of localization techniques varies with bug type due to their unique challenges. For example, tensor bugs were more accessible to locate due to their structural nature, while all techniques struggled with GPU bugs due to their external dependencies. Third, we investigate the impact of bugs' extrinsic nature on localization in deep-learning systems. We found that deep learning bugs are often extrinsic and thus connected to artifacts other than source code (e.g., GPU, training data), contributing to the poor performance of existing localization methods.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.01024",
        "abstract url": "https://arxiv.org/abs/2402.01024",
        "title": "On the BER vs. Bandwidth-Efficiency Trade-offs in Windowed OTSM Dispensing with Zero-Padding",
        "rating": "-10",
        "keywords": [],
        "abstract": "An orthogonal time sequency multiplexing (OTSM) scheme using practical signaling functions is proposed under strong phase noise (PHN) scenarios. By utilizing the transform relationships between the delay-sequency (DS), time-frequency (TF) and time-domains, we first conceive the DS-domain input-output relationship of our OTSM system, where the conventional zero-padding is discarded to increase the spectral efficiency. Then, the unconditional pairwise error probability is derived, followed by deriving the bit error ratio (BER) upper bound in closed-form. Moreover, we compare the BER performance of our OTSM system based on several practical signaling functions. Our simulation results demonstrate that the upper bound derived accurately predicts the BER performance in the case of moderate to high signal-to-noise ratios (SNRs), while harnessing practical window functions is capable of attaining an attractive out-of-band emission (OOBE) vs. BER trade-off.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Accepted by WCNC 2024"
    },
    {
        "paper id": "2402.01037",
        "abstract url": "https://arxiv.org/abs/2402.01037",
        "title": "Wireless Information Surveillance via STAR-RIS",
        "rating": "-10",
        "keywords": [],
        "abstract": "We explore the potential of a simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) to enhance the performance of wireless surveillance systems. The STAR-RIS is deployed between a full-duplex (FD) multi-antenna legitimate eavesdropper (E) and a suspicious communication pair. It reflects the suspicious signal towards the suspicious receiver (SR), while simultaneously transmitting the same signal to E for interception purposes. Additionally, it enables the forwarding of a jamming signal from E to SR, which is located on the back side of the STAR-RIS. To enhance the eavesdropping non-outage probability, we formulate a non-convex joint optimization problem to design the beamforming vectors at E and reflection/transmission phase shift matrices at the STAR-RIS. We adopt the block coordinate descent (BCD) algorithm and propose an approach, mainly based on semi-definite relaxation (SDR) and successive convex approximation (SCA), for solving the resulting decoupled sub-problems. Finally, we compare the performance of the proposed design against low-complexity zero-forcing (ZF)-based beamforming designs.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "This paper has been accepted for presentation at the IEEE WCNC 2024"
    },
    {
        "paper id": "2402.01078",
        "abstract url": "https://arxiv.org/abs/2402.01078",
        "title": "Low Acceptance Agreement Tests via Bounded-Degree Symplectic HDXs",
        "rating": "-10",
        "keywords": [],
        "abstract": "We solve the derandomized direct product testing question in the low acceptance regime, by constructing new high dimensional expanders that have no small connected covers. We show that our complexes have swap cocycle expansion, which allows us to deduce the agreement theorem by relying on previous work. Derandomized direct product testing, also known as agreement testing, is the following problem. Let X be a family of k-element subsets of [n] and let $\\{f_s:s\\to\u03a3\\}_{s\\in X}$ be an ensemble of local functions, each defined over a subset $s\\subset [n]$. Suppose that we run the following so-called agreement test: choose a random pair of sets $s_1,s_2\\in X$ that intersect on $\\sqrt k$ elements, and accept if $f_{s_1},f_{s_2}$ agree on the elements in $s_1\\cap s_2$. We denote the success probability of this test by $Agr(\\{f_s\\})$. Given that $Agr(\\{f_s\\})=\u03b5>0$, is there a global function $G:[n]\\to\u03a3$ such that $f_s = G|_s$ for a non-negligible fraction of $s\\in X$ ? We construct a family X of k-subsets of $[n]$ such that $|X| = O(n)$ and such that it satisfies the low acceptance agreement theorem. Namely, $Agr (\\{f_s\\}) > \u03b5\\; \\; \\longrightarrow$ there is a function $G:[n]\\to\u03a3$ such that $\\Pr_s[f_s\\overset{0.99}{\\approx} G|_s]\\geq poly(\u03b5)$. A key idea is to replace the well-studied LSV complexes by symplectic high dimensional expanders (HDXs). The family X is just the k-faces of the new symplectic HDXs. The later serve our needs better since their fundamental group satisfies the congruence subgroup property, which implies that they lack small covers. We also give a polynomial-time algorithm to construct this family of symplectic HDXs.",
        "subjects": [
            "cs.CC",
            "math.CO",
            "math.GR"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2312.15325"
    },
    {
        "paper id": "2402.01079",
        "abstract url": "https://arxiv.org/abs/2402.01079",
        "title": "Data-Driven Evidence-Based Syntactic Sugar Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Programming languages are essential tools for developers, and their evolution plays a crucial role in supporting the activities of developers. One instance of programming language evolution is the introduction of syntactic sugars, which are additional syntax elements that provide alternative, more readable code constructs. However, the process of designing and evolving a programming language has traditionally been guided by anecdotal experiences and intuition. Recent advances in tools and methodologies for mining open-source repositories have enabled developers to make data-driven software engineering decisions. In light of this, this paper proposes an approach for motivating data-driven programming evolution by applying frequent subgraph mining techniques to a large dataset of 166,827,154 open-source Java methods. The dataset is mined by generalizing Java control-flow graphs to capture broad programming language usages and instances of duplication. Frequent subgraphs are then extracted to identify potentially impactful opportunities for new syntactic sugars. Our diverse results demonstrate the benefits of the proposed technique by identifying new syntactic sugars involving a variety of programming constructs that could be implemented in Java, thus simplifying frequent code idioms. This approach can potentially provide valuable insights for Java language designers, and serve as a proof-of-concept for data-driven programming language design and evolution.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "12 pages, 12 figures, to be published in ICSE'24"
    },
    {
        "paper id": "2402.01084",
        "abstract url": "https://arxiv.org/abs/2402.01084",
        "title": "Fairness and efficiency trade-off in two-sided matching",
        "rating": "-10",
        "keywords": [],
        "abstract": "The theory of two-sided matching has been extensively developed and applied to many real-life application domains. As the theory has been applied to increasingly diverse types of environments, researchers and practitioners have encountered various forms of distributional constraints. As a mechanism can handle a more general class of constraints, we can assign students more flexibly to colleges to increase students' welfare. However, it turns out that there exists a trade-off between students' welfare (efficiency) and fairness (which means no student has justified envy). Furthermore, this trade-off becomes sharper as the class of constraints becomes more general. The first contribution of this paper is to clarify the boundary on whether a strategyproof and fair mechanism can satisfy certain efficiency properties for each class of constraints. Our second contribution is to establish a weaker fairness requirement called envy-freeness up to $k$ peers (EF-$k$), which is inspired by a similar concept used in the fair division of indivisible items. EF-$k$ guarantees that each student has justified envy towards at most $k$ students. By varying $k$, EF-$k$ can represent different levels of fairness. We investigate theoretical properties associated with EF-$k$. Furthermore, we develop two contrasting strategyproof mechanisms that work for general hereditary constraints, i.e., one mechanism can guarantee a strong efficiency requirement, while the other can guarantee EF-$k$ for any fixed $k$. We evaluate the performance of these mechanisms through computer simulation.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2402.01088",
        "abstract url": "https://arxiv.org/abs/2402.01088",
        "title": "The Danger Of Arrogance: Welfare Equilibra As A Solution To Stackelberg Self-Play In Non-Coincidental Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "The increasing prevalence of multi-agent learning systems in society necessitates understanding how to learn effective and safe policies in general-sum multi-agent environments against a variety of opponents, including self-play. General-sum learning is difficult because of non-stationary opponents and misaligned incentives. Our first main contribution is to show that many recent approaches to general-sum learning can be derived as approximations to Stackelberg strategies, which suggests a framework for developing new multi-agent learning algorithms. We then define non-coincidental games as games in which the Stackelberg strategy profile is not a Nash Equilibrium. This notably includes several canonical matrix games and provides a normative theory for why existing algorithms fail in self-play in such games. We address this problem by introducing Welfare Equilibria (WE) as a generalisation of Stackelberg Strategies, which can recover desirable Nash Equilibria even in non-coincidental games. Finally, we introduce Welfare Function Search (WelFuSe) as a practical approach to finding desirable WE against unknown opponents, which finds more mutually desirable solutions in self-play, while preserving performance against naive learning opponents.",
        "subjects": [
            "cs.GT",
            "cs.MA"
        ],
        "comment": "31 pages, 23 figures"
    },
    {
        "paper id": "2402.01122",
        "abstract url": "https://arxiv.org/abs/2402.01122",
        "title": "Generalized Multi-Speed Dubins Motion Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "The paper develops a novel motion model, called Generalized Multi-Speed Dubins Motion Model (GMDM), which extends the Dubins model by considering multiple speeds. While the Dubins model produces time-optimal paths under a constant-speed constraint, these paths could be suboptimal if this constraint is relaxed to include multiple speeds. This is because a constant speed results in a large minimum turning radius, thus producing paths with longer maneuvers and larger travel times. In contrast, multi-speed relaxation allows for slower speed sharp turns, thus producing more direct paths with shorter maneuvers and smaller travel times. Furthermore, the inability of the Dubins model to reduce speed could result in fast maneuvers near obstacles, thus producing paths with high collision risks. In this regard, GMDM provides the motion planners the ability to jointly optimize time and risk by allowing the change of speed along the path. GMDM is built upon the six Dubins path types considering the change of speed on path segments. It is theoretically established that GMDM provides full reachability of the configuration space for any speed selections. Furthermore, it is shown that the Dubins model is a specific case of GMDM for constant speeds. The solutions of GMDM are analytical and suitable for real-time applications. The performance of GMDM in terms of solution quality (i.e., time/time-risk cost) and computation time is comparatively evaluated against the existing motion models in obstacle-free as well as obstacle-rich environments via extensive Monte Carlo simulations. The results show that in obstacle-free environments, GMDM produces near time-optimal paths with significantly lower travel times than the Dubins model while having similar computation times. In obstacle-rich environments, GMDM produces time-risk optimized paths with substantially lower collision risks.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2402.01480",
        "abstract url": "https://arxiv.org/abs/2402.01480",
        "title": "Selenium-Jupiter: A JUnit 5 extension for Selenium WebDriver",
        "rating": "-10",
        "keywords": [],
        "abstract": "Selenium WebDriver is a library that allows controlling web browsers (e.g., Chrome, Firefox, etc.) programmatically. It provides a cross-browser programming interface in several languages used primarily to implement end-to-end tests for web applications. JUnit is a popular unit testing framework for Java. Its latest version (i.e., JUnit 5) provides a programming and extension model called Jupiter. This paper presents Selenium-Jupiter, an open-source JUnit 5 extension for Selenium WebDriver. Selenium-Jupiter aims to ease the development of Selenium WebDriver tests thanks to an automated driver management process implemented in conjunction with the Jupiter parameter resolution mechanism. Moreover, Selenium-Jupiter provides seamless integration with Docker, allowing the use of different web browsers in Docker containers out of the box. This feature enables cross-browser testing, load testing, and troubleshooting (e.g., configurable session recordings). This paper presents an example case in which Selenium-Jupiter is used to evaluate the performance of video conferencing systems based on WebRTC. This example case shows that Selenium-Jupiter can build and maintain the required infrastructure for complex tests effortlessly.",
        "subjects": [
            "cs.OH"
        ],
        "comment": "37 pages, 10 figures"
    },
    {
        "paper id": "2402.07916",
        "abstract url": "https://arxiv.org/abs/2402.07916",
        "title": "Perceptual Thresholds for Radial Optic Flow Distortion in Near-Eye Stereoscopic Displays",
        "rating": "-10",
        "keywords": [],
        "abstract": "We provide the first perceptual quantification of user's sensitivity to radial optic flow artifacts and demonstrate a promising approach for masking this optic flow artifact via blink suppression. Near-eye HMDs allow users to feel immersed in virtual environments by providing visual cues, like motion parallax and stereoscopy, that mimic how we view the physical world. However, these systems exhibit a variety of perceptual artifacts that can limit their usability and the user's sense of presence in VR. One well-known artifact is the vergence-accommodation conflict (VAC). Varifocal displays can mitigate VAC, but bring with them other artifacts such as a change in virtual image size (radial optic flow) when the focal plane changes. We conducted a set of psychophysical studies to measure users' ability to perceive this radial flow artifact before, during, and after self-initiated blinks. Our results showed that visual sensitivity was reduced by a factor of 10 at the start and for ~70 ms after a blink was detected. Pre- and post-blink sensitivity was, on average, ~0.15% image size change during normal viewing and increased to ~1.5-2.0% during blinks. Our results imply that a rapid (under 70 ms) radial optic flow distortion can go unnoticed during a blink. Furthermore, our results provide empirical data that can be used to inform engineering requirements for both hardware design and software-based graphical correction algorithms for future varifocal near-eye displays. Our project website is available at https://gamma.umd.edu/RoF/.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.08591",
        "abstract url": "https://arxiv.org/abs/2402.08591",
        "title": "Nonlinear Maccone-Pati Uncertainty Principle",
        "rating": "-10",
        "keywords": [],
        "abstract": "We show that one of the two important uncertainty principles derived by Maccone and Pati \\textit{[Phys. Rev. Lett., 2014]} can be derived for arbitrary maps defined on subsets of $\\mathcal{L}^p$ spaces for $1< p<\\infty$. Our main tool is the Clarkson inequalities. We also derive a nonlinear uncertainty principle for weak parallelogram spaces and Type-p Banach spaces.",
        "subjects": [
            "math.FA",
            "cs.IT",
            "math-ph"
        ],
        "comment": "6 pages, 0 figures"
    },
    {
        "paper id": "2403.08798",
        "abstract url": "https://arxiv.org/abs/2403.08798",
        "title": "Self-adaptive, Requirements-driven Autoscaling of Microservices",
        "rating": "-10",
        "keywords": [],
        "abstract": "Microservices architecture offers various benefits, including granularity, flexibility, and scalability. A crucial feature of this architecture is the ability to autoscale microservices, i.e., adjust the number of replicas and/or manage resources. Several autoscaling solutions already exist. Nonetheless, when employed for diverse microservices compositions, current solutions may exhibit suboptimal resource allocations, either exceeding the actual requirements or falling short. This can in turn lead to unbalanced environments, downtime, and undesirable infrastructure costs. We propose MS-RA, a self-adaptive, requirements-driven solution for microservices autoscaling. MS-RA utilizes service-level objectives (SLOs) for real-time decision making. Our solution, which is customizable to specific needs and costs, facilitates a more efficient allocation of resources by precisely using the right amount to meet the defined requirements. We have developed MS-RA based on the MAPE-K self-adaptive loop, and have evaluated it using an open-source microservice-based application. Our results indicate that MS-RA considerably outperforms the horizontal pod autoscaler (HPA), the industry-standard Kubernetes autoscaling mechanism. It achieves this by using fewer resources while still ensuring the satisfaction of the SLOs of interest. Specifically, MS-RA meets the SLO requirements of our case-study system, requiring at least 50% less CPU time, 87% less memory, and 90% fewer replicas compared to the HPA.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "This paper has been accepted at the 19th International Conference on Software Engineering for Adaptive and Self-Managing Systems (SEAMS 2024)"
    },
    {
        "paper id": "2403.18830",
        "abstract url": "https://arxiv.org/abs/2403.18830",
        "title": "Cloudy with a Chance of Green: Measuring the Predictability of 18,009 Traffic Lights in Hamburg",
        "rating": "-10",
        "keywords": [],
        "abstract": "Informing drivers about the predicted state of upcoming traffic lights is considered a key solution to reduce unneeded energy expenditure and dilemma zones at intersections. However, newer traffic lights can react to traffic demand, resulting in spontaneous switching behavior and poor predictability. To assess whether future traffic light assistance services are viable, it is crucial to understand how strongly predictability is affected by such spontaneous switching behavior. Previous studies have so far only reported percentages of adaptivity-capable traffic lights, but the actual switching behavior has not been measured. Addressing this research gap, we conduct a large-scale predictability evaluation based on 424 million recorded switching cycles over four weeks for 18,009 individual traffic lights in Hamburg. Two characteristics of predictability are studied: cycle discrepancy and wait time diversity. Results indicate that fewer traffic lights exhibit hard-to-predict switching behavior than suggested by previous work, considering a reported number of 90.7% adaptive traffic lights in Hamburg. Contrasting previous work, we find that not all traffic lights capable of adaptiveness may necessarily exhibit low predictability. We critically review these results and derive avenues for future research.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted for publication at IEEE IV 2024"
    },
    {
        "paper id": "2404.08642",
        "abstract url": "https://arxiv.org/abs/2404.08642",
        "title": "Integrating Multi -WAN, VPN and IEEE 802.3ad for Advanced IPSEC",
        "rating": "-10",
        "keywords": [],
        "abstract": "Since the emergence of the internet, IPSEC has undergone significant changes due to changes in the type and behavior of users worldwide. IEEE 802.3ad, while considered a key aspect of the IPSEC model, is predictable and can result in potential design flaws, making it relatively easy to access a secure workstation. Thus, it is critical to leverage the benefits of multiple ISPs (multi-WAN) and a link aggregation model and integrate an aspect of randomisation in the network. This facet of the network is highlighted by the proof of concept in the simulation of a double pendulum. The analysis of POC provided a network topology designed to utilize multiple WAN, 802.3ad link aggregation, and other environmental components to create a sense of true randomness within a network system. An analysis of this approach shows that it accounts for the data stream's size, transmission speed, WANs and VPNs' location, and other environmental factors to create a sense of randomness. Based on the proof concept, it can be concluded that attaining randomisation using multi-WAN, VPN, and 802.3ad is a highly effective model for improving IPSEC.",
        "subjects": [
            "cs.NI",
            "cs.CR"
        ],
        "comment": "13 pages, 2 figures"
    },
    {
        "paper id": "2405.00011",
        "abstract url": "https://arxiv.org/abs/2405.00011",
        "title": "A Multiscale Fracture Model using Peridynamic Enrichment of Finite Elements within an Adaptive Partition of Unity: Experimental Validation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Partition of unity methods (PUM) are of domain decomposition type and provide the opportunity for multiscale and multiphysics numerical modeling. Within the PUM global-local enrichment scheme [1, 2] different physical models can exist to capture multiscale behavior. For instance, we consider classical linear elasticity globally and local zones where fractures occur. The elastic fields of the undamaged media provide appropriate boundary data for local PD simulations on a subdomain containing the crack tip to grow the crack path. Once the updated crack path is found, the elastic field in the body and surrounding the crack is updated using PUM basis with appropriate enrichment near the crack. The subdomain for the PD simulation is chosen to include the current crack tip as well as nearby features that will influence crack growth. This paper is part II of this series and validates the combined PD/PUM simulator against the experimental results presented in [3]. The presented results show that we can attain good agreement between experimental and simulation data with a local PD subdomain that is moving with the crack tip and adaptively chosen size.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    }
]