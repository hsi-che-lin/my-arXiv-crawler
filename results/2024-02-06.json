[
    {
        "paper id": "2402.04050",
        "abstract url": "https://arxiv.org/abs/2402.04050",
        "title": "Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models",
        "rating": 2.5,
        "keywords": [
            [
                "efficient fine-tuning"
            ],
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the emergence of pretrained vision-language models (VLMs), considerable efforts have been devoted to fine-tuning them for downstream tasks. Despite the progress made in designing efficient fine-tuning methods, such methods require access to the model's parameters, which can be challenging as model owners often opt to provide their models as a black box to safeguard model ownership. This paper proposes a \\textbf{C}ollabo\\textbf{ra}tive \\textbf{F}ine-\\textbf{T}uning (\\textbf{CraFT}) approach for fine-tuning black-box VLMs to downstream tasks, where one only has access to the input prompts and the output predictions of the model. CraFT comprises two modules, a prompt generation module for learning text prompts and a prediction refinement module for enhancing output predictions in residual style. Additionally, we introduce an auxiliary prediction-consistent loss to promote consistent optimization across these modules. These modules are optimized by a novel collaborative training algorithm. Extensive experiments on few-shot classification over 15 datasets demonstrate the superiority of CraFT. The results show that CraFT achieves a decent gain of about 12\\% with 16-shot datasets and only 8,000 queries. Moreover, CraFT trains faster and uses only about 1/80 of the memory footprint for deployment, while sacrificing only 1.62\\% compared to the white-box method.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04087",
        "abstract url": "https://arxiv.org/abs/2402.04087",
        "title": "A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation",
        "rating": 2.5,
        "keywords": [
            [
                "efficient fine-tuning"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Contrastive Language-Image Pretraining (CLIP) has gained popularity for its remarkable zero-shot capacity. Recent research has focused on developing efficient fine-tuning methods, such as prompt learning and adapter, to enhance CLIP's performance in downstream tasks. However, these methods still require additional training time and computational resources, which is undesirable for devices with limited resources. In this paper, we revisit a classical algorithm, Gaussian Discriminant Analysis (GDA), and apply it to the downstream classification of CLIP. Typically, GDA assumes that features of each class follow Gaussian distributions with identical covariance. By leveraging Bayes' formula, the classifier can be expressed in terms of the class means and covariance, which can be estimated from the data without the need for training. To integrate knowledge from both visual and textual modalities, we ensemble it with the original zero-shot classifier within CLIP. Extensive results on 17 datasets validate that our method surpasses or achieves comparable results with state-of-the-art methods on few-shot classification, imbalanced learning, and out-of-distribution generalization. In addition, we extend our method to base-to-new generalization and unsupervised learning, once again demonstrating its superiority over competing approaches. Our code is publicly available at \\url{https://github.com/mrflogs/ICLR24}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2024"
    },
    {
        "paper id": "2402.03746",
        "abstract url": "https://arxiv.org/abs/2402.03746",
        "title": "Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback",
        "rating": 2,
        "keywords": [
            [
                "VLM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). The previous approaches for VLMMs involved Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and adding additional learnable modules. Video and text multimodal alignment remains challenging, primarily due to the deficient volume and quality of multimodal instruction-tune data compared to text-only data. We present a novel alignment strategy that employs multimodal AI system to oversee itself called Reinforcement Learning from AI Feedback (RLAIF), providing self-preference feedback to refine itself and facilitating the alignment of video and text modalities. In specific, we propose context-aware reward modeling by providing detailed video descriptions as context during the generation of preference feedback in order to enrich the understanding of video content. Demonstrating enhanced performance across diverse video benchmarks, our multimodal RLAIF approach, VLM-RLAIF, outperforms existing approaches, including the SFT model. We commit to open-sourcing our code, models, and datasets to foster further research in this area.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Technical report"
    },
    {
        "paper id": "2402.03766",
        "abstract url": "https://arxiv.org/abs/2402.03766",
        "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model",
        "rating": 2,
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce MobileVLM V2, a family of significantly improved vision language models upon MobileVLM, which proves that a delicate orchestration of novel architectural design, an improved training scheme tailored for mobile VLMs, and rich high-quality dataset curation can substantially benefit VLMs' performance. Specifically, MobileVLM V2 1.7B achieves better or on-par performance on standard VLM benchmarks compared with much larger VLMs at the 3B scale. Notably, our 3B model outperforms a large variety of VLMs at the 7B+ scale. Our models will be released at https://github.com/Meituan-AutoML/MobileVLM .",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03782",
        "abstract url": "https://arxiv.org/abs/2402.03782",
        "title": "Soft Prompt Tuning for Cross-Lingual Transfer: When Less is More",
        "rating": 2,
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Soft Prompt Tuning (SPT) is a parameter-efficient method for adapting pre-trained language models (PLMs) to specific tasks by inserting learnable embeddings, or soft prompts, at the input layer of the PLM, without modifying its parameters. This paper investigates the potential of SPT for cross-lingual transfer. Unlike previous studies on SPT for cross-lingual transfer that often fine-tune both the soft prompt and the model parameters, we adhere to the original intent of SPT by keeping the model parameters frozen and only training the soft prompt. This does not only reduce the computational cost and storage overhead of full-model fine-tuning, but we also demonstrate that this very parameter efficiency intrinsic to SPT can enhance cross-lingual transfer performance to linguistically distant languages. Moreover, we explore how different factors related to the prompt, such as the length or its reparameterization, affect cross-lingual transfer performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at the 1st Workshop on Modular and Open Multilingual NLP (co-located with EACL 2024)"
    },
    {
        "paper id": "2402.04009",
        "abstract url": "https://arxiv.org/abs/2402.04009",
        "title": "Low-rank Attention Side-Tuning for Parameter-Efficient Fine-Tuning",
        "rating": 2,
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In finetuning a large pretrained model to downstream tasks, parameter-efficient fine-tuning (PEFT) methods can effectively finetune pretrained models with few trainable parameters, but suffer from high GPU memory consumption and slow training speed. Because learnable parameters from these methods are entangled with the pretrained model, gradients related to the frozen pretrained model's parameters have to be computed and stored during finetuning. We propose Low-rank Attention Side-Tuning (LAST), which disentangles the trainable module from the pretrained model by freezing not only parameters but also outputs of the pretrained network. LAST trains a side-network composed of only low-rank self-attention modules. By viewing the pretrained model as a frozen feature extractor, the side-network takes intermediate output from the pretrained model and focus on learning task-specific knowledge. We also show that LAST can be highly parallel across multiple optimization objectives, making it very efficient in downstream task adaptation, for example, in finding optimal hyperparameters. LAST outperforms previous state-of-the-art methods on VTAB-1K and other visual adaptation tasks with roughly only 30\\% of GPU memory footprint and 60\\% of training time compared to existing PEFT methods, but achieves significantly higher accuracy.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04049",
        "abstract url": "https://arxiv.org/abs/2402.04049",
        "title": "Systematic Biases in LLM Simulations of Debates",
        "rating": 2,
        "keywords": [
            [
                "social biases"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in natural language processing, especially the emergence of Large Language Models (LLMs), have opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. However, LLMs are complex statistical learners without straightforward deductive rules, making them prone to unexpected behaviors. In this study, we highlight the limitations of LLMs in simulating human interactions, particularly focusing on LLMs' ability to simulate political debates. Our findings indicate a tendency for LLM agents to conform to the model's inherent social biases despite being directed to debate from certain political perspectives. This tendency results in behavioral patterns that seem to deviate from well-established social dynamics among humans. We reinforce these observations using an automatic self-fine-tuning method, which enables us to manipulate the biases within the LLM and demonstrate that agents subsequently align with the altered biases. These results underscore the need for further research to develop methods that help agents overcome these biases, a critical step toward creating more realistic simulations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04236",
        "abstract url": "https://arxiv.org/abs/2402.04236",
        "title": "CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations",
        "rating": 2,
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-Language Models (VLMs) have demonstrated their widespread viability thanks to extensive training in aligning visual instructions to answers. However, this conclusive alignment leads models to ignore critical visual reasoning, and further result in failures on meticulous visual problems and unfaithful responses. In this paper, we propose Chain of Manipulations, a mechanism that enables VLMs to solve problems with a series of manipulations, where each manipulation refers to an operation on the visual input, either from intrinsic abilities (e.g., grounding) acquired through prior training or from imitating human-like behaviors (e.g., zoom in). This mechanism encourages VLMs to generate faithful responses with evidential visual reasoning, and permits users to trace error causes in the interpretable paths. We thus train CogCoM, a general 17B VLM with a memory-based compatible architecture endowed this reasoning mechanism. Experiments show that our model achieves the state-of-the-art performance across 8 benchmarks from 3 categories, and a limited number of training steps with the data swiftly gains a competitive performance. The code and data are publicly available at https://github.com/THUDM/CogCoM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "17 pages, 7 figures"
    },
    {
        "paper id": "2402.04416",
        "abstract url": "https://arxiv.org/abs/2402.04416",
        "title": "A Data Centric Approach for Unsupervised Domain Generalization via Retrieval from Web Scale Multimodal Data",
        "rating": 2,
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Domain generalization (DG) is an important problem that learns a model that can generalize to unseen test domains leveraging one or more source domains, under the assumption of shared label spaces. However, most DG methods assume access to abundant source data in the target label space, a requirement that proves overly stringent for numerous real-world applications, where acquiring the same label space as the target task is prohibitively expensive. For this setting, we tackle the multimodal version of the unsupervised domain generalization (UDG) problem, which uses a large task-agnostic unlabeled source dataset, such as LAION-2B during finetuning. Our framework does not explicitly assume any relationship between the source dataset and target task. Instead, it relies only on the premise that the source dataset can be efficiently searched in a joint vision-language space. For this multimodal UDG setting, we propose a novel method to build a small ($<$100K) subset of the source data in three simple steps: (1) diversified retrieval using label names as queries, (2) rank pseudo-labeling, and (3) clustering to find representative samples. To demonstrate the value of studying the multimodal UDG problem, we compare our results against state-of-the-art source-free DG and zero-shot (ZS) methods on their respective benchmarks and show up to 10% improvement in accuracy on 20 diverse target datasets. Additionally, our multi-stage dataset construction method achieves 3% improvement on average over nearest neighbors retrieval. Code is available: https://github.com/Chris210634/mudg",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04492",
        "abstract url": "https://arxiv.org/abs/2402.04492",
        "title": "ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation",
        "rating": 2,
        "keywords": [
            [
                "visual language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces the ColorSwap dataset, designed to assess and improve the proficiency of multimodal models in matching objects with their colors. The dataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000 examples. Each example includes a caption-image pair, along with a ``color-swapped'' pair. We follow the Winoground schema: the two captions in an example have the same words, but the color words have been rearranged to modify different objects. The dataset was created through a novel blend of automated caption and image generation with humans in the loop. We evaluate image-text matching (ITM) and visual language models (VLMs) and find that even the latest ones are still not robust at this task. GPT-4V and LLaVA score 72% and 42% on our main VLM metric, although they may improve with more advanced prompting techniques. On the main ITM metric, contrastive models such as CLIP and SigLIP perform close to chance (at 12% and 30%, respectively), although the non-contrastive BLIP ITM model is stronger (87%). We also find that finetuning on fewer than 2,000 examples yields significant performance gains on this out-of-distribution word-order understanding task. The dataset is here: https://github.com/Top34051/colorswap.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03744",
        "abstract url": "https://arxiv.org/abs/2402.03744",
        "title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \\textbf{IN}ternal \\textbf{S}tates for halluc\\textbf{I}nation \\textbf{DE}tection (\\textbf{INSIDE}). In particular, a simple yet effective \\textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident generations and potentially benefits the detection of overconfident hallucinations. Extensive experiments and ablation studies are performed on several popular LLMs and question-answering (QA) benchmarks, showing the effectiveness of our proposal.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ICLR-2024"
    },
    {
        "paper id": "2402.03917",
        "abstract url": "https://arxiv.org/abs/2402.03917",
        "title": "Elastic Feature Consolidation for Cold Start Exemplar-free Incremental Learning",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Exemplar-Free Class Incremental Learning (EFCIL) aims to learn from a sequence of tasks without having access to previous task data. In this paper, we consider the challenging Cold Start scenario in which insufficient data is available in the first task to learn a high-quality backbone. This is especially challenging for EFCIL since it requires high plasticity, which results in feature drift which is difficult to compensate for in the exemplar-free setting. To address this problem, we propose a simple and effective approach that consolidates feature representations by regularizing drift in directions highly relevant to previous tasks and employs prototypes to reduce task-recency bias. Our method, called Elastic Feature Consolidation (EFC), exploits a tractable second-order approximation of feature drift based on an Empirical Feature Matrix (EFM). The EFM induces a pseudo-metric in feature space which we use to regularize feature drift in important directions and to update Gaussian prototypes used in a novel asymmetric cross entropy loss which effectively balances prototype rehearsal with data from new tasks. Experimental results on CIFAR-100, Tiny-ImageNet, ImageNet-Subset and ImageNet-1K demonstrate that Elastic Feature Consolidation is better able to learn new tasks by maintaining model plasticity and significantly outperform the state-of-the-art.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at Twelfth International Conference on Learning Representations (ICLR 2024)"
    },
    {
        "paper id": "2402.04160",
        "abstract url": "https://arxiv.org/abs/2402.04160",
        "title": "Harnessing the Plug-and-Play Controller by Prompting",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Controllable text generation is a growing field within natural language generation (NLG) that focuses on producing text that meets specific constraints in real-world applications. Previous approaches, such as plug-and-play controllers (PPCs), aimed to steer the properties of generated text in a flexible manner. However, these methods often compromised the integrity of the language model's decoding process, resulting in less smooth text generation. Alternatively, other techniques utilized multiple attribute prompts to align the generated text with desired attributes, but this approach required prompt design for each attribute and was dependent on the size of the language model. This paper introduces a novel method for flexible attribute control in text generation using pre-trained language models (PLMs). The proposed approach aims to enhance the fluency of generated text by guiding the generation process with PPCs. The key idea is to dynamically adjust the distribution of generated text by modifying prompts, effectively constraining the output space of the language model and influencing the desired attribute. To enable smooth cooperation between the PLM and the PPC, our work innovatively proposes a new model fine-tuning method: Reinforcement Learning with Dynamic Adjust Feedback (RLDAF).This fine-tuning process adapts a small subset of the language model's parameters based on the generating actions taken during the PPC control process. The resulting harmonious collaboration between the PLM and PPC leads to improved smoothness in text generation during inference. Extensive experiments were conducted on the SST2 dataset, and the proposed method outperformed previous approaches in various evaluation metrics, including text fluency and attribute consistency.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "The Third Version of the Generation, Evaluation & Metrics (GEM) Workshop in EMNLP 2023"
    },
    {
        "paper id": "2402.04291",
        "abstract url": "https://arxiv.org/abs/2402.04291",
        "title": "BiLLM: Pushing the Limit of Post-Training Quantization for LLMs",
        "rating": 1.5,
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Pretrained large language models (LLMs) exhibit exceptional general language processing capabilities but come with significant demands on memory and computational resources. As a powerful compression technology, binarization can extremely reduce model weights to a mere 1 bit, lowering the expensive computation and memory requirements. However, existing quantization techniques fall short of maintaining LLM performance under ultra-low bit-widths. In response to this challenge, we present BiLLM, a groundbreaking 1-bit post-training quantization scheme tailored for pretrained LLMs. Based on the weight distribution of LLMs, BiLLM first identifies and structurally selects salient weights, and minimizes the compression loss through an effective binary residual approximation strategy. Moreover, considering the bell-shaped distribution of the non-salient weights, we propose an optimal splitting search to group and binarize them accurately. BiLLM achieving for the first time high-accuracy inference (e.g. 8.41 perplexity on LLaMA2-70B) with only 1.08-bit weights across various LLMs families and evaluation metrics, outperforms SOTA quantization methods of LLM by significant margins. Moreover, BiLLM enables the binarization process of the LLM with 7 billion weights within 0.5 hours on a single GPU, demonstrating satisfactory time efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "19 pages"
    },
    {
        "paper id": "2402.04563",
        "abstract url": "https://arxiv.org/abs/2402.04563",
        "title": "Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Vision Transformer(ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected by the self-attention mechanism. This approach of our method provides elaborate high-level semantic explanations with great localization performance only with the class labels. As a result, our method outperforms the previous leading explainability methods of ViT in the weakly-supervised localization task and presents great capability in capturing the full instances of the target class object. Meanwhile, our method provides a visualization that faithfully explains the model, which is demonstrated in the perturbation comparison test.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "AAAI2024. Code available at https://github.com/LeemSaebom/Attention-Guided-CAM-Visual-Explanations-of-Vision-Transformer-Guided-by-Self-Attention.git"
    },
    {
        "paper id": "2402.03710",
        "abstract url": "https://arxiv.org/abs/2402.03710",
        "title": "Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced Auditory Experience",
        "rating": 1,
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "In daily life, we encounter a variety of sounds, both desirable and undesirable, with limited control over their presence and volume. Our work introduces \"Listen, Chat, and Edit\" (LCE), a novel multimodal sound mixture editor that modifies each sound source in a mixture based on user-provided text instructions. LCE distinguishes itself with a user-friendly chat interface and its unique ability to edit multiple sound sources simultaneously within a mixture, without needing to separate them. Users input open-vocabulary text prompts, which are interpreted by a large language model to create a semantic filter for editing the sound mixture. The system then decomposes the mixture into its components, applies the semantic filter, and reassembles it into the desired output. We developed a 160-hour dataset with over 100k mixtures, including speech and various audio sources, along with text prompts for diverse editing tasks like extraction, removal, and volume control. Our experiments demonstrate significant improvements in signal quality across all editing tasks and robust performance in zero-shot scenarios with varying numbers and types of sound sources.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "preprint"
    },
    {
        "paper id": "2402.03719",
        "abstract url": "https://arxiv.org/abs/2402.03719",
        "title": "Empowering Language Models with Active Inquiry for Deeper Understanding",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The rise of large language models (LLMs) has revolutionized the way that we interact with artificial intelligence systems through natural language. However, LLMs often misinterpret user queries because of their uncertain intention, leading to less helpful responses. In natural human interactions, clarification is sought through targeted questioning to uncover obscure information. Thus, in this paper, we introduce LaMAI (Language Model with Active Inquiry), designed to endow LLMs with this same level of interactive engagement. LaMAI leverages active learning techniques to raise the most informative questions, fostering a dynamic bidirectional dialogue. This approach not only narrows the contextual gap but also refines the output of the LLMs, aligning it more closely with user expectations. Our empirical studies, across a variety of complex datasets where LLMs have limited conversational context, demonstrate the effectiveness of LaMAI. The method improves answer accuracy from 31.9% to 50.9%, outperforming other leading question-answering frameworks. Moreover, in scenarios involving human participants, LaMAI consistently generates responses that are superior or comparable to baseline methods in more than 82% of the cases. The applicability of LaMAI is further evidenced by its successful integration with various LLMs, highlighting its potential for the future of interactive language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03749",
        "abstract url": "https://arxiv.org/abs/2402.03749",
        "title": "Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in large language models have sparked interest in their extraordinary and near-superhuman capabilities, leading researchers to explore methods for evaluating and optimizing these abilities, which is called superalignment. In this context, our paper delves into the realm of vision foundation models, focusing on the concept of weak-to-strong generalization, which involves using a weaker model to supervise a stronger one, aiming to enhance the latter's capabilities beyond the former's limits. We introduce a novel and adaptively adjustable loss function for weak-to-strong supervision. Our comprehensive experiments span various scenarios, including few-shot learning, transfer learning, noisy label learning, and common knowledge distillation settings. The results are striking: our approach not only exceeds the performance benchmarks set by strong-to-strong generalization but also surpasses the outcomes of fine-tuning strong models with whole datasets. This compelling evidence underscores the significant potential of weak-to-strong generalization, showcasing its capability to substantially elevate the performance of vision foundation models. The code is available at https://github.com/ggjy/vision_weak_to_strong.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2402.03752",
        "abstract url": "https://arxiv.org/abs/2402.03752",
        "title": "Pre-training of Lightweight Vision Transformers on Small Datasets with Minimally Scaled Images",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Can a lightweight Vision Transformer (ViT) match or exceed the performance of Convolutional Neural Networks (CNNs) like ResNet on small datasets with small image resolutions? This report demonstrates that a pure ViT can indeed achieve superior performance through pre-training, using a masked auto-encoder technique with minimal image scaling. Our experiments on the CIFAR-10 and CIFAR-100 datasets involved ViT models with fewer than 3.65 million parameters and a multiply-accumulate (MAC) count below 0.27G, qualifying them as 'lightweight' models. Unlike previous approaches, our method attains state-of-the-art performance among similar lightweight transformer-based architectures without significantly scaling up images from CIFAR-10 and CIFAR-100. This achievement underscores the efficiency of our model, not only in handling small datasets but also in effectively processing images close to their original scale.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2402.03757",
        "abstract url": "https://arxiv.org/abs/2402.03757",
        "title": "The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large language models (LLMs) have recently experienced remarkable progress, where the advent of multi-modal large language models (MLLMs) has endowed LLMs with visual capabilities, leading to impressive performances in various multi-modal tasks. However, those powerful MLLMs such as GPT-4V still fail spectacularly when presented with certain image and text inputs. In this paper, we identify a typical class of inputs that baffles MLLMs, which consist of images that are highly relevant but inconsistent with answers, causing MLLMs to suffer from hallucination. To quantify the effect, we propose CorrelationQA, the first benchmark that assesses the hallucination level given spurious images. This benchmark contains 7,308 text-image pairs across 13 categories. Based on the proposed CorrelationQA, we conduct a thorough analysis on 9 mainstream MLLMs, illustrating that they universally suffer from this instinctive bias to varying degrees. We hope that our curated benchmark and evaluation results aid in better assessments of the MLLMs' robustness in the presence of misleading images. The resource is available in https://github.com/MasaiahHan/CorrelationQA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03758",
        "abstract url": "https://arxiv.org/abs/2402.03758",
        "title": "Virtual Classification: Modulating Domain-Specific Knowledge for Multidomain Crowd Counting",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multidomain crowd counting aims to learn a general model for multiple diverse datasets. However, deep networks prefer modeling distributions of the dominant domains instead of all domains, which is known as domain bias. In this study, we propose a simple-yet-effective Modulating Domain-specific Knowledge Network (MDKNet) to handle the domain bias issue in multidomain crowd counting. MDKNet is achieved by employing the idea of `modulating', enabling deep network balancing and modeling different distributions of diverse datasets with little bias. Specifically, we propose an Instance-specific Batch Normalization (IsBN) module, which serves as a base modulator to refine the information flow to be adaptive to domain distributions. To precisely modulating the domain-specific information, the Domain-guided Virtual Classifier (DVC) is then introduced to learn a domain-separable latent space. This space is employed as an input guidance for the IsBN modulator, such that the mixture distributions of multiple datasets can be well treated. Extensive experiments performed on popular benchmarks, including Shanghai-tech A/B, QNRF and NWPU, validate the superiority of MDKNet in tackling multidomain crowd counting and the effectiveness for multidomain learning. Code is available at \\url{https://github.com/csguomy/MDKNet}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Multidomain learning; Domain-guided virtual classifier; Instance-specific batch normalization"
    },
    {
        "paper id": "2402.03776",
        "abstract url": "https://arxiv.org/abs/2402.03776",
        "title": "Large Language Models As MOOCs Graders",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Massive open online courses (MOOCs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. Despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (LLMs) to replace peer grading in MOOCs. Specifically, we focus on two state-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. To instruct LLMs, we use three different prompts based on a variant of the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique: Zero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoT in conjunction with both instructor-formulated answers and rubrics; and Zero-shot-CoT with instructor-offered correct answers and LLM-generated rubrics. Our results show that Zero-shot-CoT, when integrated with instructor-provided answers and rubrics, produces grades that are more aligned with those assigned by instructors compared to peer grading. However, the History and Philosophy of Astronomy course proves to be more challenging in terms of grading as opposed to other courses. Finally, our study reveals a promising direction for automating grading systems for MOOCs, especially in subjects with well-defined rubrics.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "v1.3 preprint"
    },
    {
        "paper id": "2402.03780",
        "abstract url": "https://arxiv.org/abs/2402.03780",
        "title": "Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates the language of propaganda and its stylistic features. It presents the PPN dataset, standing for Propagandist Pseudo-News, a multisource, multilingual, multimodal dataset composed of news articles extracted from websites identified as propaganda sources by expert agencies. A limited sample from this set was randomly mixed with papers from the regular French press, and their URL masked, to conduct an annotation-experiment by humans, using 11 distinct labels. The results show that human annotators were able to reliably discriminate between the two types of press across each of the labels. We propose different NLP techniques to identify the cues used by the annotators, and to compare them with machine classification. They include the analyzer VAGO to measure discourse vagueness and subjectivity, a TF-IDF to serve as a baseline, and four different classifiers: two RoBERTa-based models, CATS using syntax, and one XGBoost combining syntactic and semantic features.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Paper to appear in the EACL 2024 Proceedings of the Third Workshop on Understanding Implicit and Underspecified Language (UnImplicit 2024)"
    },
    {
        "paper id": "2402.03833",
        "abstract url": "https://arxiv.org/abs/2402.03833",
        "title": "An SVD-free Approach to Nonlinear Dictionary Learning based on RVFL",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel nonlinear dictionary learning algorithm leveraging the theory of a feed-forward neural network called Random Vector Functional Link (RVFL). The proposed RVFL-based nonlinear Dictionary Learning (RVFLDL) learns a dictionary as a sparse-to-dense feature map from nonlinear sparse coefficients to the dense input features. Kernel-based nonlinear dictionary learning methods operate in a feature space obtained by an implicit feature map, and they are not independent of computationally expensive operations like Singular Value Decomposition (SVD). Training the RVFL-based dictionary is free from SVD computation as RVFL generates weights from the input to the output layer analytically. Sparsity-inducing Horse-shoe prior is assumed on the coefficients to generate a sparse coefficient matrix w.r.t an initial random dictionary. Higher-order dependencies between the input sparse coefficients and the dictionary atoms are incorporated into the training process by nonlinearly transforming the sparse coefficients and adding them as enhanced features. Thus the method projects sparse coefficients to a higher dimensional space while inducing nonlinearities into the dictionary. For classification using RVFL-net, a classifier matrix is learned as a transform that maps nonlinear sparse coefficients to the labels. The performance of the method illustrated in image classification and reconstruction applications is comparable to that of other nonlinear dictionary learning methods. Experiments show that RVFLDL is scalable and provides a solution better than those obtained using other nonlinear dictionary learning methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03835",
        "abstract url": "https://arxiv.org/abs/2402.03835",
        "title": "Transformer based Endmember Fusion with Spatial Context for Hyperspectral Unmixing",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, transformer-based deep learning networks have gained popularity in Hyperspectral (HS) unmixing applications due to their superior performance. The attention mechanism within transformers facilitates input-dependent weighting and enhances contextual awareness during training. Drawing inspiration from this, we propose a novel attention based Hyperspectral Unmixing algorithm called Transformer based Endmember Fusion with Spatial Context for Hyperspectral Unmixing (FusionNet). This algorithm can effectively fuse endmember signatures obtained from different endmember extraction algorithms, as opposed to the classical HS unmixing approaches that rely on a single Endmember Extraction Algorithm (EEA). The FusionNet incorporates an Approximation Network (AN), introducing contextual awareness into abundance prediction by considering neighborhood pixels. Unlike Convolutional Neural Networks (CNNs), which are constrained by specific kernel shapes, the Fusion network offers flexibility in choosing any arbitrary configuration of the neighborhood. We conducted a comparative analysis between the FusionNet algorithm and state-of-the-art algorithms using two popular datasets. Remarkably, FusionNet outperformed other algorithms, achieving the lowest Root Mean Square Error (RMSE) for abundance predictions and competitive Spectral Angle Distance (SAD) for signatures associated with each endmember for both datasets.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03848",
        "abstract url": "https://arxiv.org/abs/2402.03848",
        "title": "ANLS* -- A Universal Document Processing Metric for Generative Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs. This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and is still compatible with previously reported ANLS scores. An evaluation of 7 different datasets, 6 different GLLMs and 3 different prompting methods using the ANLS* metric is also provided, demonstrating the importance of the proposed metric. We also benchmark a novel approach to generate prompts for documents, called SFT, against other prompting techniques such as LATIN. In 27 out of 35 cases, SFT outperforms other techniques and improves the state-of-the-art, sometimes by as much as $18$ percentage points. Sources are available at https://github.com/deepopinion/anls_star_metric",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03870",
        "abstract url": "https://arxiv.org/abs/2402.03870",
        "title": "Less than one percent of words would be affected by gender-inclusive language in German press texts",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Research on gender and language is tightly knitted to social debates on gender equality and non-discriminatory language use. Psycholinguistic scholars have made significant contributions in this field. However, corpus-based studies that investigate these matters within the context of language use are still rare. In our study, we address the question of how much textual material would actually have to be changed if non-gender-inclusive texts were rewritten to be gender-inclusive. This quantitative measure is an important empirical insight, as a recurring argument against the use of gender-inclusive German is that it supposedly makes written texts too long and complicated. It is also argued that gender-inclusive language has negative effects on language learners. However, such effects are only likely if gender-inclusive texts are very different from those that are not gender-inclusive. In our corpus-linguistic study, we manually annotated German press texts to identify the parts that would have to be changed. Our results show that, on average, less than 1% of all tokens would be affected by gender-inclusive language. This small proportion calls into question whether gender-inclusive German presents a substantial barrier to understanding and learning the language, particularly when we take into account the potential complexities of interpreting masculine generics.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "27 pages, 7 figures, 2 tables"
    },
    {
        "paper id": "2402.03887",
        "abstract url": "https://arxiv.org/abs/2402.03887",
        "title": "Shifting social norms as a driving force for linguistic change: Struggles about language and gender in the German Bundestag",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper focuses on language change based on shifting social norms, in particular with regard to the debate on language and gender. It is a recurring argument in this debate that language develops \"naturally\" and that \"severe interventions\" - such as gender-inclusive language is often claimed to be - in the allegedly \"organic\" language system are inappropriate and even \"dangerous\". Such interventions are, however, not unprecedented. Socially motivated processes of language change are neither unusual nor new. We focus in our contribution on one important political-social space in Germany, the German Bundestag. Taking other struggles about language and gender in the plenaries of the Bundestag as a starting point, our article illustrates that language and gender has been a recurring issue in the German Bundestag since the 1980s. We demonstrate how this is reflected in linguistic practices of the Bundestag, by the use of a) designations for gays and lesbians; b) pair forms such as B\u00fcrgerinnen und B\u00fcrger (female and male citizens); and c) female forms of addresses and personal nouns ('Pr\u00e4sidentin' in addition to 'Pr\u00e4sident'). Lastly, we will discuss implications of these earlier language battles for the currently very heated debate about gender-inclusive language, especially regarding new forms with gender symbols like the asterisk or the colon (Lehrer*innen, Lehrer:innen; male*female teachers) which are intended to encompass all gender identities.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "40 pages, 9 figures"
    },
    {
        "paper id": "2402.03896",
        "abstract url": "https://arxiv.org/abs/2402.03896",
        "title": "Convincing Rationales for Visual Question Answering Reasoning",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual Question Answering (VQA) is a challenging task of predicting the answer to a question about the content of an image. It requires deep understanding of both the textual question and visual image. Prior works directly evaluate the answering models by simply calculating the accuracy of the predicted answers. However, the inner reasoning behind the prediction is disregarded in such a \"black box\" system, and we do not even know if one can trust the predictions. In some cases, the models still get the correct answers even when they focus on irrelevant visual regions or textual tokens, which makes the models unreliable and illogical. To generate both visual and textual rationales next to the predicted answer to the given image/question pair, we propose Convincing Rationales for VQA, CRVQA. Considering the extra annotations brought by the new outputs, {CRVQA} is trained and evaluated by samples converted from some existing VQA datasets and their visual labels. The extensive experiments demonstrate that the visual and textual rationales support the prediction of the answers, and further improve the accuracy. Furthermore, {CRVQA} achieves competitive performance on generic VQA datatsets in the zero-shot evaluation setting. The dataset and source code will be released under https://github.com/lik1996/CRVQA2024.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2402.03898",
        "abstract url": "https://arxiv.org/abs/2402.03898",
        "title": "DistiLLM: Towards Streamlined Distillation for Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge distillation (KD) is widely used for compressing a teacher model to a smaller student model, reducing its inference cost and memory footprint while preserving model capabilities. However, current KD methods for auto-regressive sequence models (e.g., large language models) suffer from missing a standardized objective function. Moreover, the recent use of student-generated outputs to address training-inference mismatches has significantly escalated computational costs. To tackle these issues, we introduce DistiLLM, a more effective and efficient KD framework for auto-regressive language models. DistiLLM comprises two components: (1) a novel skew Kullback-Leibler divergence loss, where we unveil and leverage its theoretical properties, and (2) an adaptive off-policy approach designed to enhance the efficiency in utilizing student-generated outputs. Extensive experiments, including instruction-following tasks, demonstrate the effectiveness of DistiLLM in building high-performing student models while achieving up to 4.3$\\times$ speedup compared to recent KD methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Code is available at https://github.com/jongwooko/distillm"
    },
    {
        "paper id": "2402.03904",
        "abstract url": "https://arxiv.org/abs/2402.03904",
        "title": "Deep MSFOP: Multiple Spectral filter Operators Preservation in Deep Functional Maps for Unsupervised Shape Matching",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose a novel constraint called Multiple Spectral filter Operators Preservation (MSFOR) to compute functional maps and based on it, develop an efficient deep functional map architecture called Deep MSFOP for shape matching. The core idea is that, instead of using the general descriptor preservation constraint, we require our maps to preserve multiple spectral filter operators. This allows us to incorporate more informative geometrical information, contained in different frequency bands of functions, into the functional map computing. This can be confirmed by that some previous techniques like wavelet preservation and LBO commutativity are actually our special cases. Moreover, we also develop a very efficient way to compute the maps with MSFOP constraint, which can be conveniently embedded into the deep learning, especially having learnable filter operators. Utilizing the above results, we finally design our Deep MSFOP pipeline, equipped with a suitable unsupervised loss jointly penalizing the functional map and the underlying pointwise map. Our deep functional map has notable advantages, including that the functional map is more geometrically informative and guaranteed to be proper, and the computing is numerically stable. Extensive experimental results on different datasets demonstrate that our approach outperforms the existing state-of-the-art methods, especially in challenging settings like non-isometric and inconsistent topology datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03921",
        "abstract url": "https://arxiv.org/abs/2402.03921",
        "title": "Large Language Models to Enhance Bayesian Optimization",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Bayesian optimization (BO) is a powerful approach for optimizing complex and expensive-to-evaluate black-box functions. Its importance is underscored in many applications, notably including hyperparameter tuning, but its efficacy depends on efficiently balancing exploration and exploitation. While there has been substantial progress in BO methods, striking this balance remains a delicate process. In this light, we present LLAMBO, a novel approach that integrates the capabilities of Large Language Models (LLM) within BO. At a high level, we frame the BO problem in natural language, enabling LLMs to iteratively propose and evaluate promising solutions conditioned on historical evaluations. More specifically, we explore how combining contextual understanding, few-shot learning proficiency, and domain knowledge of LLMs can improve model-based BO. Our findings illustrate that LLAMBO is effective at zero-shot warmstarting, and enhances surrogate modeling and candidate sampling, especially in the early stages of search when observations are sparse. Our approach is performed in context and does not require LLM finetuning. Additionally, it is modular by design, allowing individual components to be integrated into existing BO frameworks, or function cohesively as an end-to-end method. We empirically validate LLAMBO's efficacy on the problem of hyperparameter tuning, highlighting strong empirical performance across a range of diverse benchmarks, proprietary, and synthetic tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted as Poster at ICLR2024"
    },
    {
        "paper id": "2402.03927",
        "abstract url": "https://arxiv.org/abs/2402.03927",
        "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of \\emph{indirect} data leaking, where models are iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI's GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI's data usage policy, we extensively document the amount of data leaked to these models during the first year after the model's release. We report that these models have been globally exposed to $\\sim$4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at EACL 2024 - main conference"
    },
    {
        "paper id": "2402.03973",
        "abstract url": "https://arxiv.org/abs/2402.03973",
        "title": "Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given Enough Time",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning is closing the gap with humans on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen from unusual viewpoints. We find that humans excel at recognizing objects in unusual poses, in contrast with state-of-the-art pretrained networks (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) which are systematically brittle in this condition. Remarkably, as we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) take place when humans identify objects in unusual poses. Finally, our analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. We conclude that more work is needed to bring computer vision systems to the level of robustness of the human visual system. Understanding the nature of the mental processes taking place during extra viewing time may be key to attain such robustness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03988",
        "abstract url": "https://arxiv.org/abs/2402.03988",
        "title": "REBORN: Reinforcement-Learned Boundary Segmentation with Iterative Training for Unsupervised ASR",
        "rating": 1,
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Unsupervised automatic speech recognition (ASR) aims to learn the mapping between the speech signal and its corresponding textual transcription without the supervision of paired speech-text data. A word/phoneme in the speech signal is represented by a segment of speech signal with variable length and unknown boundary, and this segmental structure makes learning the mapping between speech and text challenging, especially without paired data. In this paper, we propose REBORN, Reinforcement-Learned Boundary Segmentation with Iterative Training for Unsupervised ASR. REBORN alternates between (1) training a segmentation model that predicts the boundaries of the segmental structures in speech signals and (2) training the phoneme prediction model, whose input is a segmental structure segmented by the segmentation model, to predict a phoneme transcription. Since supervised data for training the segmentation model is not available, we use reinforcement learning to train the segmentation model to favor segmentations that yield phoneme sequence predictions with a lower perplexity. We conduct extensive experiments and find that under the same setting, REBORN outperforms all prior unsupervised ASR models on LibriSpeech, TIMIT, and five non-English languages in Multilingual LibriSpeech. We comprehensively analyze why the boundaries learned by REBORN improve the unsupervised ASR performance.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04028",
        "abstract url": "https://arxiv.org/abs/2402.04028",
        "title": "AlbNews: A Corpus of Headlines for Topic Modeling in Albanian",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The scarcity of available text corpora for low-resource languages like Albanian is a serious hurdle for research in natural language processing tasks. This paper introduces AlbNews, a collection of 600 topically labeled news headlines and 2600 unlabeled ones in Albanian. The data can be freely used for conducting topic modeling research. We report the initial classification scores of some traditional machine learning classifiers trained with the AlbNews samples. These results show that basic models outrun the ensemble learning ones and can serve as a baseline for future experiments.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04129",
        "abstract url": "https://arxiv.org/abs/2402.04129",
        "title": "OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Recent works have shown that by using large pre-trained models along with learnable prompts, rehearsal-free methods for class-incremental learning (CIL) settings can achieve superior performance to prominent rehearsal-based ones. Rehearsal-free CIL methods struggle with distinguishing classes from different tasks, as those are not trained together. In this work we propose a regularization method based on virtual outliers to tighten decision boundaries of the classifier, such that confusion of classes among different tasks is mitigated. Recent prompt-based methods often require a pool of task-specific prompts, in order to prevent overwriting knowledge of previous tasks with that of the new task, leading to extra computation in querying and composing an appropriate prompt from the pool. This additional cost can be eliminated, without sacrificing accuracy, as we reveal in the paper. We illustrate that a simplified prompt-based method can achieve results comparable to previous state-of-the-art (SOTA) methods equipped with a prompt pool, using much less learnable parameters and lower inference cost. Our regularization method has demonstrated its compatibility with different prompt-based methods, boosting those previous SOTA rehearsal-free CIL methods' accuracy on the ImageNet-R and CIFAR-100 benchmarks. Our source code is available at https://github.com/jpmorganchase/ovor.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by ICLR 2024"
    },
    {
        "paper id": "2402.04177",
        "abstract url": "https://arxiv.org/abs/2402.04177",
        "title": "Scaling Laws for Downstream Task Performance of Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with more pretraining data. In such cases, we show that it is possible to predict the downstream BLEU score with good accuracy using a log-law. However, there are also cases where moderate misalignment causes the BLEU score to fluctuate or get worse with more pretraining, whereas downstream cross-entropy monotonically improves. By analyzing these observations, we provide new practical insights for choosing appropriate pretraining data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04222",
        "abstract url": "https://arxiv.org/abs/2402.04222",
        "title": "What is 'Typological Diversity' in NLP?",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The NLP research community has devoted increased attention to languages beyond English, resulting in considerable improvements for multilingual NLP. However, these improvements only apply to a small subset of the world's languages. Aiming to extend this, an increasing number of papers aspires to enhance generalizable multilingual performance across languages. To this end, linguistic typology is commonly used to motivate language selection, on the basis that a broad typological sample ought to imply generalization across a broad range of languages. These selections are often described as being 'typologically diverse'. In this work, we systematically investigate NLP research that includes claims regarding 'typological diversity'. We find there are no set definitions or criteria for such claims. We introduce metrics to approximate the diversity of language selection along several axes and find that the results vary considerably across papers. Crucially, we show that skewed language selection can lead to overestimated multilingual performance. We recommend future work to include an operationalization of 'typological diversity' that empirically justifies the diversity of language samples.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04251",
        "abstract url": "https://arxiv.org/abs/2402.04251",
        "title": "Linear-time Minimum Bayes Risk Decoding with Reference Aggregation",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Minimum Bayes Risk (MBR) decoding is a text generation technique that has been shown to improve the quality of machine translations, but is expensive, even if a sampling-based approximation is used. Besides requiring a large number of sampled sequences, it requires the pairwise calculation of a utility metric, which has quadratic complexity. In this paper, we propose to approximate pairwise metric scores with scores calculated against aggregated reference representations. This changes the complexity of utility estimation from $O(n^2)$ to $O(n)$, while empirically preserving most of the quality gains of MBR decoding. We release our source code at https://github.com/ZurichNLP/mbr",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04252",
        "abstract url": "https://arxiv.org/abs/2402.04252",
        "title": "EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Scaling up contrastive language-image pretraining (CLIP) is critical for empowering both vision and multimodal models. We present EVA-CLIP-18B, the largest and most powerful open-source CLIP model to date, with 18-billion parameters. With only 6-billion training samples seen, EVA-CLIP-18B achieves an exceptional 80.7% zero-shot top-1 accuracy averaged across 27 widely recognized image classification benchmarks, outperforming its forerunner EVA-CLIP (5-billion parameters) and other open-source CLIP models by a large margin. Remarkably, we observe a consistent performance improvement with the model size scaling of EVA-CLIP, despite maintaining a constant training dataset of 2-billion image-text pairs from LAION-2B and COYO-700M. This dataset is openly available and much smaller than the in-house datasets (e.g., DFN-5B, WebLI-10B) employed in other state-of-the-art CLIP models. EVA-CLIP-18B demonstrates the potential of EVA-style weak-to-strong visual model scaling. With our model weights made publicly available, we hope to facilitate future research in vision and multimodal foundation models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04253",
        "abstract url": "https://arxiv.org/abs/2402.04253",
        "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries. We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries. AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable. AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules. We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. By revising the evaluation protocol to better reflect practical application scenarios, we introduce an additional benchmark, termed AnyToolBench. Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. For instance, AnyTool outperforms ToolLLM by +35.4% in terms of average pass rate on ToolBench. Code will be available at https://github.com/dyabel/AnyTool.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04315",
        "abstract url": "https://arxiv.org/abs/2402.04315",
        "title": "Training Language Models to Generate Text with Citations via Fine-grained Rewards",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "While recent Large Language Models (LLMs) have proven useful in answering user queries, they are prone to hallucination, and their responses often lack credibility due to missing references to reliable sources. An intuitive solution to these issues would be to include in-text citations referring to external documents as evidence. While previous works have directly prompted LLMs to generate in-text citations, their performances are far from satisfactory, especially when it comes to smaller LLMs. In this work, we propose an effective training framework using fine-grained rewards to teach LLMs to generate highly supportive and relevant citations, while ensuring the correctness of their responses. We also conduct a systematic analysis of applying these fine-grained rewards to common LLM training strategies, demonstrating its advantage over conventional practices. We conduct extensive experiments on Question Answering (QA) datasets taken from the ALCE benchmark and validate the model's generalizability using EXPERTQA. On LLaMA-2-7B, the incorporation of fine-grained rewards achieves the best performance among the baselines, even surpassing that of GPT-3.5-turbo.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04333",
        "abstract url": "https://arxiv.org/abs/2402.04333",
        "title": "LESS: Selecting Influential Data for Targeted Instruction Tuning",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots. However, real-world applications often require a specialized suite of skills (e.g., reasoning). The challenge lies in identifying the most relevant data from these extensive datasets to effectively develop specific capabilities, a setting we frame as targeted instruction tuning. We propose LESS, an optimizer-aware and practically efficient algorithm to effectively estimate data influences and perform Low-rank gradiEnt Similarity Search for instruction data selection. Crucially, LESS adapts existing influence formulations to work with the Adam optimizer and variable-length instruction data. LESS first constructs a highly reusable and transferable gradient datastore with low-dimensional gradient features and then selects examples based on their similarity to few-shot examples embodying a specific capability. Experiments show that training on a LESS-selected 5% of the data can often outperform training on the full dataset across diverse downstream tasks. Furthermore, the selected data is highly transferable: smaller models can be leveraged to select useful data for larger models and models from different families. Our qualitative analysis shows that our method goes beyond surface form cues to identify data that exemplifies the necessary reasoning skills for the intended downstream application.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Code and data are available at https://github.com/princeton-nlp/LESS"
    },
    {
        "paper id": "2402.04335",
        "abstract url": "https://arxiv.org/abs/2402.04335",
        "title": "LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we focus on two main tasks, the first for detecting legal violations within unstructured textual data, and the second for associating these violations with potentially affected individuals. We constructed two datasets using Large Language Models (LLMs) which were subsequently validated by domain expert annotators. Both tasks were designed specifically for the context of class-action cases. The experimental design incorporated fine-tuning models from the BERT family and open-source LLMs, and conducting few-shot experiments using closed-source LLMs. Our results, with an F1-score of 62.69\\% (violation identification) and 81.02\\% (associating victims), show that our datasets and setups can be used for both tasks. Finally, we publicly release the datasets and the code used for the experiments in order to advance further research in the area of legal natural language processing (NLP).",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04347",
        "abstract url": "https://arxiv.org/abs/2402.04347",
        "title": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Linear attentions have shown potential for improving Transformer efficiency, reducing attention's quadratic complexity to linear in sequence length. This holds exciting promise for (1) training linear Transformers from scratch, (2) \"finetuned-conversion\" of task-specific Transformers into linear versions that recover task performance, and (3) \"pretrained-conversion\" of Transformers such as large language models into linear versions finetunable on downstream tasks. However, linear attentions often underperform standard softmax attention in quality. To close this performance gap, we find prior linear attentions lack key properties of softmax attention tied to good performance: low-entropy (or \"spiky\") weights and dot-product monotonicity. We further observe surprisingly simple feature maps that retain these properties and match softmax performance, but are inefficient to compute in linear attention. We thus propose Hedgehog, a learnable linear attention that retains the spiky and monotonic properties of softmax attention while maintaining linear complexity. Hedgehog uses simple trainable MLPs to produce attention weights mimicking softmax attention. Experiments show Hedgehog recovers over 99% of standard Transformer quality in train-from-scratch and finetuned-conversion settings, outperforming prior linear attentions up to 6 perplexity points on WikiText-103 with causal GPTs, and up to 8.7 GLUE score points on finetuned bidirectional BERTs. Hedgehog also enables pretrained-conversion. Converting a pretrained GPT-2 into a linear attention variant achieves state-of-the-art 16.7 perplexity on WikiText-103 for 125M subquadratic decoder models. We finally turn a pretrained Llama-2 7B into a viable linear attention Llama. With low-rank adaptation, Hedgehog-Llama2 7B achieves 28.1 higher ROUGE-1 points over the base standard attention model, where prior linear attentions lead to 16.5 point drops.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "30 pages, 20 figures, 15 tables, ICLR 2024"
    },
    {
        "paper id": "2402.04401",
        "abstract url": "https://arxiv.org/abs/2402.04401",
        "title": "Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning",
        "rating": 1,
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-tuning"
            ],
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Personalization in large language models (LLMs) is increasingly important, aiming to align LLM's interactions, content, and recommendations with individual user preferences. Recent advances in LLM personalization have spotlighted effective prompt design, by enriching user queries with non-parametric knowledge through behavior history retrieval and textual profiles. However, these approaches were limited due to a lack of model ownership, resulting in constrained customization and privacy issues. Moreover, they often failed to accurately capture user behavior patterns, especially in cases where user data were complex and dynamic. To address these shortcomings, we introduce One PEFT Per User (OPPU), which employs personalized parameter-efficient fine-tuning (PEFT) modules, to store user-specific behavior patterns and preferences. By plugging in users' personal PEFT parameters, they can own and use their LLMs personally. OPPU integrates parametric user knowledge in the personal PEFT parameters with the non-parametric knowledge acquired through retrieval and profile. This integration adapts individual LLMs to user behavior shifts. Experimental results demonstrate that OPPU significantly outperforms existing prompt-based methods across seven diverse tasks in the LaMP benchmark. Further in-depth studies reveal OPPU's enhanced capabilities in handling user behavior shifts, modeling users at different active levels, maintaining robustness across various user history formats, and displaying versatility with different PEFT methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04437",
        "abstract url": "https://arxiv.org/abs/2402.04437",
        "title": "Structured Entity Extraction Using Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in machine learning have significantly impacted the field of information extraction, with Large Language Models (LLMs) playing a pivotal role in extracting structured information from unstructured text. Prior works typically represent information extraction as triplet-centric and use classical metrics such as precision and recall for evaluation. We reformulate the task to be entity-centric, enabling the use of diverse metrics that can provide more insights from various perspectives. We contribute to the field by introducing Structured Entity Extraction (SEE) and proposing the Approximate Entity Set OverlaP (AESOP) metric, designed to appropriately assess model performance. Later, we introduce a new model that harnesses the power of LLMs for enhanced effectiveness and efficiency by decomposing the extraction task into multiple stages. Quantitative and human side-by-side evaluations confirm that our model outperforms baselines, offering promising directions for future advancements in structured entity extraction.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04477",
        "abstract url": "https://arxiv.org/abs/2402.04477",
        "title": "Detecting Mode Collapse in Language Models via Narration",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "No two authors write alike. Personal flourishes invoked in written narratives, from lexicon to rhetorical devices, imply a particular author--what literary theorists label the implied or virtual author; distinct from the real author or narrator of a text. Early large language models trained on unfiltered training sets drawn from a variety of discordant sources yielded incoherent personalities, problematic for conversational tasks but proving useful for sampling literature from multiple perspectives. Successes in alignment research in recent years have allowed researchers to impose subjectively consistent personae on language models via instruction tuning and reinforcement learning from human feedback (RLHF), but whether aligned models retain the ability to model an arbitrary virtual author has received little scrutiny. By studying 4,374 stories sampled from three OpenAI language models, we show successive versions of GPT-3 suffer from increasing degrees of \"mode collapse\" whereby overfitting the model during alignment constrains it from generalizing over authorship: models suffering from mode collapse become unable to assume a multiplicity of perspectives. Our method and results are significant for researchers seeking to employ language models in sociological simulations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "To appear in the proceedings of the first Workshop on the Scaling Behavior of Large Language Models (EACL 2024)"
    },
    {
        "paper id": "2402.04482",
        "abstract url": "https://arxiv.org/abs/2402.04482",
        "title": "BEBLID: Boosted efficient binary local image descriptor",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Efficient matching of local image features is a fundamental task in many computer vision applications. However, the real-time performance of top matching algorithms is compromised in computationally limited devices, such as mobile phones or drones, due to the simplicity of their hardware and their finite energy supply. In this paper we introduce BEBLID, an efficient learned binary image descriptor. It improves our previous real-valued descriptor, BELID, making it both more efficient for matching and more accurate. To this end we use AdaBoost with an improved weak-learner training scheme that produces better local descriptions. Further, we binarize our descriptor by forcing all weak-learners to have the same weight in the strong learner combination and train it in an unbalanced data set to address the asymmetries arising in matching and retrieval tasks. In our experiments BEBLID achieves an accuracy close to SIFT and better computational efficiency than ORB, the fastest algorithm in the literature.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04485",
        "abstract url": "https://arxiv.org/abs/2402.04485",
        "title": "Incentivized Truthful Communication for Federated Bandits",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "To enhance the efficiency and practicality of federated bandit learning, recent advances have introduced incentives to motivate communication among clients, where a client participates only when the incentive offered by the server outweighs its participation cost. However, existing incentive mechanisms naively assume the clients are truthful: they all report their true cost and thus the higher cost one participating client claims, the more the server has to pay. Therefore, such mechanisms are vulnerable to strategic clients aiming to optimize their own utility by misreporting. To address this issue, we propose an incentive compatible (i.e., truthful) communication protocol, named Truth-FedBan, where the incentive for each participant is independent of its self-reported cost, and reporting the true cost is the only way to achieve the best utility. More importantly, Truth-FedBan still guarantees the sub-linear regret and communication cost without any overheads. In other words, the core conceptual contribution of this paper is, for the first time, demonstrating the possibility of simultaneously achieving incentive compatibility and nearly optimal regret in federated bandit learning. Extensive numerical studies further validate the effectiveness of our proposed solution.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "20 pages, 2 figures. Accepted at ICLR 2024"
    },
    {
        "paper id": "2402.04505",
        "abstract url": "https://arxiv.org/abs/2402.04505",
        "title": "Developments in Sheaf-Theoretic Models of Natural Language Ambiguities",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Sheaves are mathematical objects consisting of a base which constitutes a topological space and the data associated with each open set thereof, e.g. continuous functions defined on the open sets. Sheaves have originally been used in algebraic topology and logic. Recently, they have also modelled events such as physical experiments and natural language disambiguation processes. We extend the latter models from lexical ambiguities to discourse ambiguities arising from anaphora. To begin, we calculated a new measure of contextuality for a dataset of basic anaphoric discourses, resulting in a higher proportion of contextual models--82.9%--compared to previous work which only yielded 3.17% contextual models. Then, we show how an extension of the natural language processing challenge, known as the Winograd Schema, which involves anaphoric ambiguities can be modelled on the Bell-CHSH scenario with a contextual fraction of 0.096.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2308.16498"
    },
    {
        "paper id": "2402.04542",
        "abstract url": "https://arxiv.org/abs/2402.04542",
        "title": "Share What You Already Know: Cross-Language-Script Transfer and Alignment for Sentiment Detection in Code-Mixed Data",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Code-switching entails mixing multiple languages. It is an increasingly occurring phenomenon in social media texts. Usually, code-mixed texts are written in a single script, even though the languages involved have different scripts. Pre-trained multilingual models primarily utilize the data in the native script of the language. In existing studies, the code-switched texts are utilized as they are. However, using the native script for each language can generate better representations of the text owing to the pre-trained knowledge. Therefore, a cross-language-script knowledge sharing architecture utilizing the cross attention and alignment of the representations of text in individual language scripts was proposed in this study. Experimental results on two different datasets containing Nepali-English and Hindi-English code-switched texts, demonstrate the effectiveness of the proposed method. The interpretation of the model using model explainability technique illustrates the sharing of language-specific knowledge between language-specific representations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04555",
        "abstract url": "https://arxiv.org/abs/2402.04555",
        "title": "FM-Fusion: Instance-aware Semantic Mapping Boosted by Vision-Language Foundation Models",
        "rating": 1,
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "RGB-D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semantic mapping based on the supervised object detectors is sensitive to image distribution. In real-world environments, the object detection and segmentation performance can lead to a major drop, preventing the use of semantic mapping in a wider domain. On the other hand, the development of vision-language foundation models demonstrates a strong zero-shot transferability across data distribution. It provides an opportunity to construct generalizable instance-aware semantic maps. Hence, this work explores how to boost instance-aware semantic mapping from object detection generated from foundation models. We propose a probabilistic label fusion method to predict close-set semantic classes from open-set label measurements. An instance refinement module merges the over-segmented instances caused by inconsistent segmentation. We integrate all the modules into a unified semantic mapping system. Reading a sequence of RGB-D input, our work incrementally reconstructs an instance-aware semantic map. We evaluate the zero-shot performance of our method in ScanNet and SceneNN datasets. Our method achieves 40.3 mean average precision (mAP) on the ScanNet semantic instance segmentation task. It outperforms the traditional semantic mapping method significantly.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE RA-L"
    },
    {
        "paper id": "2402.04558",
        "abstract url": "https://arxiv.org/abs/2402.04558",
        "title": "DMAT: A Dynamic Mask-Aware Transformer for Human De-occlusion",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Human de-occlusion, which aims to infer the appearance of invisible human parts from an occluded image, has great value in many human-related tasks, such as person re-id, and intention inference. To address this task, this paper proposes a dynamic mask-aware transformer (DMAT), which dynamically augments information from human regions and weakens that from occlusion. First, to enhance token representation, we design an expanded convolution head with enlarged kernels, which captures more local valid context and mitigates the influence of surrounding occlusion. To concentrate on the visible human parts, we propose a novel dynamic multi-head human-mask guided attention mechanism through integrating multiple masks, which can prevent the de-occluded regions from assimilating to the background. Besides, a region upsampling strategy is utilized to alleviate the impact of occlusion on interpolated images. During model learning, an amodal loss is developed to further emphasize the recovery effect of human regions, which also refines the model's convergence. Extensive experiments on the AHP dataset demonstrate its superior performance compared to recent state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04573",
        "abstract url": "https://arxiv.org/abs/2402.04573",
        "title": "Progressive Conservative Adaptation for Evolving Target Domains",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Conventional domain adaptation typically transfers knowledge from a source domain to a stationary target domain. However, in many real-world cases, target data usually emerge sequentially and have continuously evolving distributions. Restoring and adapting to such target data results in escalating computational and resource consumption over time. Hence, it is vital to devise algorithms to address the evolving domain adaptation (EDA) problem, \\emph{i.e.,} adapting models to evolving target domains without access to historic target domains. To achieve this goal, we propose a simple yet effective approach, termed progressive conservative adaptation (PCAda). To manage new target data that diverges from previous distributions, we fine-tune the classifier head based on the progressively updated class prototypes. Moreover, as adjusting to the most recent target domain can interfere with the features learned from previous target domains, we develop a conservative sparse attention mechanism. This mechanism restricts feature adaptation within essential dimensions, thus easing the inference related to historical knowledge. The proposed PCAda is implemented with a meta-learning framework, which achieves the fast adaptation of the classifier with the help of the progressively updated class prototypes in the inner loop and learns a generalized feature without severely interfering with the historic knowledge via the conservative sparse attention in the outer loop. Experiments on Rotated MNIST, Caltran, and Portraits datasets demonstrate the effectiveness of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2402.05136",
        "abstract url": "https://arxiv.org/abs/2402.05136",
        "title": "LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "State-of-the-art large language models (LLMs) are now claiming remarkable supported context lengths of 256k or even more. In contrast, the average context lengths of mainstream benchmarks are insufficient (5k-21k), and they suffer from potential knowledge leakage and inaccurate metrics, resulting in biased evaluation. This paper introduces LV-Eval, a challenging long-context benchmark with five length levels (16k, 32k, 64k, 128k, and 256k) reaching up to 256k words. LV-Eval features two main tasks, single-hop QA and multi-hop QA, comprising 11 bilingual datasets. The design of LV-Eval has incorporated three key techniques, namely confusing facts insertion, keyword and phrase replacement, and keyword-recall-based metric design. The advantages of LV-Eval include controllable evaluation across different context lengths, challenging test instances with confusing facts, mitigated knowledge leakage, and more objective evaluations. We evaluate 10 LLMs on LV-Eval and conduct ablation studies on the techniques used in LV-Eval construction. The results reveal that: (i) Commercial LLMs generally outperform open-source LLMs when evaluated within length levels shorter than their claimed context length. However, their overall performance is surpassed by open-source LLMs with longer context lengths. (ii) Extremely long-context LLMs, such as Yi-6B-200k, exhibit a relatively gentle degradation of performance, but their absolute performances may not necessarily be higher than those of LLMs with shorter context lengths. (iii) LLMs' performances can significantly degrade in the presence of confusing information, especially in the pressure test of \"needle in a haystack\". (iv) Issues related to knowledge leakage and inaccurate metrics introduce bias in evaluation, and these concerns are alleviated in LV-Eval. All datasets and evaluation codes are released at: https://github.com/infinigence/LVEval.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.09676",
        "abstract url": "https://arxiv.org/abs/2403.09676",
        "title": "Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This research critically navigates the intricate landscape of AI deception, concentrating on deceptive behaviours of Large Language Models (LLMs). My objective is to elucidate this issue, examine the discourse surrounding it, and subsequently delve into its categorization and ramifications. The essay initiates with an evaluation of the AI Safety Summit 2023 (ASS) and introduction of LLMs, emphasising multidimensional biases that underlie their deceptive behaviours.The literature review covers four types of deception categorised: Strategic deception, Imitation, Sycophancy, and Unfaithful Reasoning, along with the social implications and risks they entail. Lastly, I take an evaluative stance on various aspects related to navigating the persistent challenges of the deceptive AI. This encompasses considerations of international collaborative governance, the reconfigured engagement of individuals with AI, proposal of practical adjustments, and specific elements of digital education.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "AI deception, Large Language Models, ChatGPT"
    },
    {
        "paper id": "2402.03715",
        "abstract url": "https://arxiv.org/abs/2402.03715",
        "title": "Clarify: Improving Model Robustness With Natural Language Corrections",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In supervised learning, models are trained to extract correlations from a static dataset. This often leads to models that rely on high-level misconceptions. To prevent such misconceptions, we must necessarily provide additional information beyond the training data. Existing methods incorporate forms of additional instance-level supervision, such as labels for spurious features or additional labeled data from a balanced distribution. Such strategies can become prohibitively costly for large-scale datasets since they require additional annotation at a scale close to the original training data. We hypothesize that targeted natural language feedback about a model's misconceptions is a more efficient form of additional supervision. We introduce Clarify, a novel interface and method for interactively correcting model misconceptions. Through Clarify, users need only provide a short text description to describe a model's consistent failure patterns. Then, in an entirely automated way, we use such descriptions to improve the training process by reweighting the training data or gathering additional targeted data. Our user studies show that non-expert users can successfully describe model misconceptions via Clarify, improving worst-group accuracy by an average of 17.1% in two datasets. Additionally, we use Clarify to find and rectify 31 novel hard subpopulations in the ImageNet dataset, improving minority-split accuracy from 21.1% to 28.7%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03726",
        "abstract url": "https://arxiv.org/abs/2402.03726",
        "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03728",
        "abstract url": "https://arxiv.org/abs/2402.03728",
        "title": "Consistent Joint Decision-Making with Heterogeneous Learning Models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces a novel decision-making framework that promotes consistency among decisions made by diverse models while utilizing external knowledge. Leveraging the Integer Linear Programming (ILP) framework, we map predictions from various models into globally normalized and comparable values by incorporating information about decisions' prior probability, confidence (uncertainty), and the models' expected accuracy. Our empirical study demonstrates the superiority of our approach over conventional baselines on multiple datasets.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "EACL 2024 Findings - Short Paper"
    },
    {
        "paper id": "2402.03737",
        "abstract url": "https://arxiv.org/abs/2402.03737",
        "title": "Differentially Private High Dimensional Bandits",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider a high-dimensional stochastic contextual linear bandit problem when the parameter vector is $s_{0}$-sparse and the decision maker is subject to privacy constraints under both central and local models of differential privacy. We present PrivateLASSO, a differentially private LASSO bandit algorithm. PrivateLASSO is based on two sub-routines: (i) a sparse hard-thresholding-based privacy mechanism and (ii) an episodic thresholding rule for identifying the support of the parameter $\u03b8$. We prove minimax private lower bounds and establish privacy and utility guarantees for PrivateLASSO for the central model under standard assumptions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03740",
        "abstract url": "https://arxiv.org/abs/2402.03740",
        "title": "BotSSCL: Social Bot Detection with Self-Supervised Contrastive Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The detection of automated accounts, also known as \"social bots\", has been an increasingly important concern for online social networks (OSNs). While several methods have been proposed for detecting social bots, significant research gaps remain. First, current models exhibit limitations in detecting sophisticated bots that aim to mimic genuine OSN users. Second, these methods often rely on simplistic profile features, which are susceptible to manipulation. In addition to their vulnerability to adversarial manipulations, these models lack generalizability, resulting in subpar performance when trained on one dataset and tested on another. To address these challenges, we propose a novel framework for social Bot detection with Self-Supervised Contrastive Learning (BotSSCL). Our framework leverages contrastive learning to distinguish between social bots and humans in the embedding space to improve linear separability. The high-level representations derived by BotSSCL enhance its resilience to variations in data distribution and ensure generalizability. We evaluate BotSSCL's robustness against adversarial attempts to manipulate bot accounts to evade detection. Experiments on two datasets featuring sophisticated bots demonstrate that BotSSCL outperforms other supervised, unsupervised, and self-supervised baseline methods. We achieve approx. 6% and approx. 8% higher (F1) performance than SOTA on both datasets. In addition, BotSSCL also achieves 67% F1 when trained on one dataset and tested with another, demonstrating its generalizability. Lastly, BotSSCL increases adversarial complexity and only allows 4% success to the adversary in evading detection.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03753",
        "abstract url": "https://arxiv.org/abs/2402.03753",
        "title": "Enhanced sampling of robust molecular datasets with uncertainty-based collective variables",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generating a data set that is representative of the accessible configuration space of a molecular system is crucial for the robustness of machine learned interatomic potentials (MLIP). However, the complexity of molecular systems, characterized by intricate potential energy surfaces (PESs) with numerous local minima and energy barriers, presents a significant challenge. Traditional methods of data generation, such as random sampling or exhaustive exploration, are either intractable or may not capture rare, but highly informative configurations. In this study, we propose a method that leverages uncertainty as the collective variable (CV) to guide the acquisition of chemically-relevant data points, focusing on regions of the configuration space where ML model predictions are most uncertain. This approach employs a Gaussian Mixture Model-based uncertainty metric from a single model as the CV for biased molecular dynamics simulations. The effectiveness of our approach in overcoming energy barriers and exploring unseen energy minima, thereby enhancing the data set in an active learning framework, is demonstrated on the alanine dipeptide benchmark system.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "13 pages, 4 figures, 10 pages of Supplementary Information"
    },
    {
        "paper id": "2402.03755",
        "abstract url": "https://arxiv.org/abs/2402.03755",
        "title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autonomous agents based on Large Language Models (LLMs) that devise plans and tackle real-world challenges have gained prominence.However, tailoring these agents for specialized domains like quantitative investment remains a formidable task. The core challenge involves efficiently building and integrating a domain-specific knowledge base for the agent's learning process. This paper introduces a principled framework to address this challenge, comprising a two-layer loop.In the inner loop, the agent refines its responses by drawing from its knowledge base, while in the outer loop, these responses are tested in real-world scenarios to automatically enhance the knowledge base with new insights.We demonstrate that our approach enables the agent to progressively approximate optimal behavior with provable efficiency.Furthermore, we instantiate this framework through an autonomous agent for mining trading signals named QuantAgent. Empirical results showcase QuantAgent's capability in uncovering viable financial signals and enhancing the accuracy of financial forecasts.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03763",
        "abstract url": "https://arxiv.org/abs/2402.03763",
        "title": "Misinformation and Polarization around COVID-19 vaccines in France, Germany, and Italy",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The kick-off of vaccination campaigns in Europe, starting in late December 2020, has been followed by the online spread of controversies and conspiracies surrounding vaccine validity and efficacy. We study Twitter discussions in three major European languages (Italian, German, and French) during the vaccination campaign. Moving beyond content analysis to explore the structural aspects of online discussions, our investigation includes an analysis of polarization and the potential formation of echo chambers, revealing nuanced behavioral and topical differences in user interactions across the analyzed countries. Notably, we identify strong anti- and pro-vaccine factions exhibiting heterogeneous temporal polarization patterns in different countries. Through a detailed examination of news-sharing sources, we uncover the widespread use of other media platforms like Telegram and YouTube for disseminating low-credibility information, indicating a concerning trend of diminishing news credibility over time. Our findings on Twitter discussions during the COVID-19 vaccination campaign in major European languages expose nuanced behavioral distinctions, revealing the profound impact of polarization and the emergence of distinct anti-vaccine and pro-vaccine advocates over time.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "17 pages (including references), 14 figures, 1 table, to be published at 16th ACM Web Science Conference 2024"
    },
    {
        "paper id": "2402.03774",
        "abstract url": "https://arxiv.org/abs/2402.03774",
        "title": "Learning a Decision Tree Algorithm with Transformers",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Decision trees are renowned for their interpretability capability to achieve high predictive performance, especially on tabular data. Traditionally, they are constructed through recursive algorithms, where they partition the data at every node in a tree. However, identifying the best partition is challenging, as decision trees optimized for local segments may not bring global generalization. To address this, we introduce MetaTree, which trains a transformer-based model on filtered outputs from classical algorithms to produce strong decision trees for classification. Specifically, we fit both greedy decision trees and optimized decision trees on a large number of datasets. We then train MetaTree to produce the trees that achieve strong generalization performance. This training enables MetaTree to not only emulate these algorithms, but also to intelligently adapt its strategy according to the context, thereby achieving superior generalization performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03804",
        "abstract url": "https://arxiv.org/abs/2402.03804",
        "title": "ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse LLMs",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sparse computation offers a compelling solution for the inference of Large Language Models (LLMs) in low-resource scenarios by dynamically skipping the computation of inactive neurons. While traditional approaches focus on ReLU-based LLMs, leveraging zeros in activation values, we broaden the scope of sparse LLMs beyond zero activation values. We introduce a general method that defines neuron activation through neuron output magnitudes and a tailored magnitude threshold, demonstrating that non-ReLU LLMs also exhibit sparse activation. To find the most efficient activation function for sparse computation, we propose a systematic framework to examine the sparsity of LLMs from three aspects: the trade-off between sparsity and performance, the predictivity of sparsity, and the hardware affinity. We conduct thorough experiments on LLMs utilizing different activation functions, including ReLU, SwiGLU, ReGLU, and ReLU$^2$. The results indicate that models employing ReLU$^2$ excel across all three evaluation aspects, highlighting its potential as an efficient activation function for sparse LLMs. We will release the code to facilitate future research.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03822",
        "abstract url": "https://arxiv.org/abs/2402.03822",
        "title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks. Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to $\\mathcal{O}(1)$, a new metric we introduce to assess equation complexity. Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle. Implementation of RevOrder is cost-effective for both training and inference phases. Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03828",
        "abstract url": "https://arxiv.org/abs/2402.03828",
        "title": "Estimating Barycenters of Distributions with Neural Optimal Transport",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Given a collection of probability measures, a practitioner sometimes needs to find an \"average\" distribution which adequately aggregates reference distributions. A theoretically appealing notion of such an average is the Wasserstein barycenter, which is the primal focus of our work. By building upon the dual formulation of Optimal Transport (OT), we propose a new scalable approach for solving the Wasserstein barycenter problem. Our methodology is based on the recent Neural OT solver: it has bi-level adversarial learning objective and works for general cost functions. These are key advantages of our method, since the typical adversarial algorithms leveraging barycenter tasks utilize tri-level optimization and focus mostly on quadratic cost. We also establish theoretical error bounds for our proposed approach and showcase its applicability and effectiveness on illustrative scenarios and image data setups.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03846",
        "abstract url": "https://arxiv.org/abs/2402.03846",
        "title": "Efficient Generation of Hidden Outliers for Improved Outlier Detection",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Outlier generation is a popular technique used for solving important outlier detection tasks. Generating outliers with realistic behavior is challenging. Popular existing methods tend to disregard the 'multiple views' property of outliers in high-dimensional spaces. The only existing method accounting for this property falls short in efficiency and effectiveness. We propose BISECT, a new outlier generation method that creates realistic outliers mimicking said property. To do so, BISECT employs a novel proposition introduced in this article stating how to efficiently generate said realistic outliers. Our method has better guarantees and complexity than the current methodology for recreating 'multiple views'. We use the synthetic outliers generated by BISECT to effectively enhance outlier detection in diverse datasets, for multiple use cases. For instance, oversampling with BISECT reduced the error by up to 3 times when compared with the baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03855",
        "abstract url": "https://arxiv.org/abs/2402.03855",
        "title": "Position Paper: Toward New Frameworks for Studying Model Representations",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mechanistic interpretability (MI) aims to understand AI models by reverse-engineering the exact algorithms neural networks learn. Most works in MI so far have studied behaviors and capabilities that are trivial and token-aligned. However, most capabilities are not that trivial, which advocates for the study of hidden representations inside these networks as the unit of analysis. We do a literature review, formalize representations for features and behaviors, highlight their importance and evaluation, and perform some basic exploration in the mechanistic interpretability of representations. With discussion and exploratory results, we justify our position that studying representations is an important and under-studied field, and that currently established methods in MI are not sufficient to understand representations, thus pushing for the research community to work toward new frameworks for studying representations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03885",
        "abstract url": "https://arxiv.org/abs/2402.03885",
        "title": "MOMENT: A Family of Open Time-series Foundation Models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce MOMENT, a family of open-source foundation models for general-purpose time-series analysis. Pre-training large models on time-series data is challenging due to (1) the absence of a large and cohesive public time-series repository, and (2) diverse time-series characteristics which make multi-dataset training onerous. Additionally, (3) experimental benchmarks to evaluate these models, especially in scenarios with limited resources, time, and supervision, are still in their nascent stages. To address these challenges, we compile a large and diverse collection of public time-series, called the Time-series Pile, and systematically tackle time-series-specific challenges to unlock large-scale multi-dataset pre-training. Finally, we build on recent work to design a benchmark to evaluate time-series foundation models on diverse tasks and datasets in limited supervision settings. Experiments on this benchmark demonstrate the effectiveness of our pre-trained models with minimal data and task-specific fine-tuning. Finally, we present several interesting empirical observations about large pre-trained time-series models. Our code is available anonymously at anonymous.4open.science/r/BETT-773F/.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03900",
        "abstract url": "https://arxiv.org/abs/2402.03900",
        "title": "Pro-HAN: A Heterogeneous Graph Attention Network for Profile-Based Spoken Language Understanding",
        "rating": 0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Recently, Profile-based Spoken Language Understanding (SLU) has gained increasing attention, which aims to incorporate various types of supplementary profile information (i.e., Knowledge Graph, User Profile, Context Awareness) to eliminate the prevalent ambiguities in user utterances. However, existing approaches can only separately model different profile information, without considering their interrelationships or excluding irrelevant and conflicting information within them. To address the above issues, we introduce a Heterogeneous Graph Attention Network to perform reasoning across multiple Profile information, called Pro-HAN. Specifically, we design three types of edges, denoted as intra-Pro, inter-Pro, and utterance-Pro, to capture interrelationships among multiple Pros. We establish a new state-of-the-art on the ProSLU dataset, with an improvement of approximately 8% across all three metrics. Further analysis experiments also confirm the effectiveness of our method in modeling multi-source profile information.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at ICASSP 2024"
    },
    {
        "paper id": "2402.03902",
        "abstract url": "https://arxiv.org/abs/2402.03902",
        "title": "A phase transition between positional and semantic learning in a solvable model of dot-product attention",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate how a dot-product attention layer learns a positional attention matrix (with tokens attending to each other based on their respective positions) and a semantic attention matrix (with tokens attending to each other based on their meaning). For an algorithmic task, we experimentally show how the same simple architecture can learn to implement a solution using either the positional or semantic mechanism. On the theoretical side, we study the learning of a non-linear self-attention layer with trainable tied and low-rank query and key matrices. In the asymptotic limit of high-dimensional data and a comparably large number of training samples, we provide a closed-form characterization of the global minimum of the non-convex empirical loss landscape. We show that this minimum corresponds to either a positional or a semantic mechanism and evidence an emergent phase transition from the former to the latter with increasing sample complexity. Finally, we compare the dot-product attention layer to linear positional baseline, and show that it outperforms the latter using the semantic mechanism provided it has access to sufficient data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03903",
        "abstract url": "https://arxiv.org/abs/2402.03903",
        "title": "Compound Returns Reduce Variance in Reinforcement Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multistep returns, such as $n$-step returns and $\u03bb$-returns, are commonly used to improve the sample efficiency of reinforcement learning (RL) methods. The variance of the multistep returns becomes the limiting factor in their length; looking too far into the future increases variance and reverses the benefits of multistep learning. In our work, we demonstrate the ability of compound returns -- weighted averages of $n$-step returns -- to reduce variance. We prove for the first time that any compound return with the same contraction modulus as a given $n$-step return has strictly lower variance. We additionally prove that this variance-reduction property improves the finite-sample complexity of temporal-difference learning under linear function approximation. Because general compound returns can be expensive to implement, we introduce two-bootstrap returns which reduce variance while remaining efficient, even when using minibatched experience replay. We conduct experiments showing that two-bootstrap returns can improve the sample efficiency of $n$-step deep RL agents, with little additional computational cost.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preprint. 8 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2402.03910",
        "abstract url": "https://arxiv.org/abs/2402.03910",
        "title": "Understanding Trends, Patterns, and Dynamics in Global Acquisitions: A Network Perspective",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Studying acquisitions offers invaluable insights into startup trends, aiding informed investment decisions for businesses. However, the scarcity of studies in this domain prompts our focus on shedding light in this area. Employing Crunchbase data, our study delves into the global network of company acquisitions using diverse network analysis techniques. Our findings unveil an acquisition network characterized by a primarily sparse structure comprising localized dense connections. We reveal a prevalent tendency among organizations to acquire companies within their own country and industry. Furthermore, our temporal analysis indicates a growth in network communities over time, accompanied by a trend toward a sparser network. Through centrality metrics computation in the cross-city acquisition network, we identify New York, London, and San Francisco as pivotal and central hubs in the global economic landscape. Finally, we show that the United States, United Kingdom, and Germany are predominant countries in international acquisitions.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03915",
        "abstract url": "https://arxiv.org/abs/2402.03915",
        "title": "Learning Metrics that Maximise Power for Accelerated A/B-Tests",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent. We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the $p$-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with over 160 million Monthly Active Users each, totalling over 153 A/B-pairs. Empirical results show that we are able to increase statistical power by up to 78% when using our learnt metrics stand-alone, and by up to 210% when used in tandem with the North Star. Alternatively, we can obtain constant statistical power at a sample size that is down to 12% of what the North Star requires, significantly reducing the cost of experimentation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03923",
        "abstract url": "https://arxiv.org/abs/2402.03923",
        "title": "Return-Aligned Decision Transformer",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional approaches in offline reinforcement learning aim to learn the optimal policy that maximizes the cumulative reward, also known as return. However, as applications broaden, it becomes increasingly crucial to train agents that not only maximize the returns, but align the actual return with a specified target return, giving control over the agent's performance. Decision Transformer (DT) optimizes a policy that generates actions conditioned on the target return through supervised learning and is equipped with a mechanism to control the agent using the target return. Despite being designed to align the actual return with the target return, we have empirically identified a discrepancy between the actual return and the target return in DT. In this paper, we propose Return-Aligned Decision Transformer (RADT), designed to effectively align the actual return with the target return. Our model decouples returns from the conventional input sequence, which typically consists of returns, states, and actions, to enhance the relationships between returns and states, as well as returns and actions. Extensive experiments show that RADT reduces the discrepancies between the actual return and the target return of DT-based methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03951",
        "abstract url": "https://arxiv.org/abs/2402.03951",
        "title": "Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping",
        "rating": 0.5,
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Adversarial examples generated by a surrogate model typically exhibit limited transferability to unknown target systems. To address this problem, many transferability enhancement approaches (e.g., input transformation and model augmentation) have been proposed. However, they show poor performances in attacking systems having different model genera from the surrogate model. In this paper, we propose a novel and generic attacking strategy, called Deformation-Constrained Warping Attack (DeCoWA), that can be effectively applied to cross model genus attack. Specifically, DeCoWA firstly augments input examples via an elastic deformation, namely Deformation-Constrained Warping (DeCoW), to obtain rich local details of the augmented input. To avoid severe distortion of global semantics led by random deformation, DeCoW further constrains the strength and direction of the warping transformation by a novel adaptive control strategy. Extensive experiments demonstrate that the transferable examples crafted by our DeCoWA on CNN surrogates can significantly hinder the performance of Transformers (and vice versa) on various tasks, including image classification, video action recognition, and audio recognition. Code is made available at https://github.com/LinQinLiang/DeCoWA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "AAAI 2024"
    },
    {
        "paper id": "2402.03962",
        "abstract url": "https://arxiv.org/abs/2402.03962",
        "title": "Position Paper: Against Spurious Sparks $-$ Dovelating Inflated AI Claims",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Humans have a tendency to see 'human'-like qualities in objects around them. We name our cars, and talk to pets and even household appliances, as if they could understand us as other humans do. This behavior, called anthropomorphism, is also seeing traction in Machine Learning (ML), where human-like intelligence is claimed to be perceived in Large Language Models (LLMs). In this position paper, considering professional incentives, human biases, and general methodological setups, we discuss how the current search for Artificial General Intelligence (AGI) is a perfect storm for over-attributing human-like qualities to LLMs. In several experiments, we demonstrate that the discovery of human-interpretable patterns in latent spaces should not be a surprising outcome. Also in consideration of common AI portrayal in the media, we call for the academic community to exercise extra caution, and to be extra aware of principles of academic integrity, in interpreting and communicating about AI research outcomes.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "20 pages, 15 figures. Preliminary work. Under review by the International Conference on Machine Learning (ICML)"
    },
    {
        "paper id": "2402.03969",
        "abstract url": "https://arxiv.org/abs/2402.03969",
        "title": "In-context learning agents are asymmetric belief updaters",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the in-context learning dynamics of large language models (LLMs) using three instrumental learning tasks adapted from cognitive psychology. We find that LLMs update their beliefs in an asymmetric manner and learn more from better-than-expected outcomes than from worse-than-expected ones. Furthermore, we show that this effect reverses when learning about counterfactual feedback and disappears when no agency is implied. We corroborate these findings by investigating idealized in-context learning agents derived through meta-reinforcement learning, where we observe similar patterns. Taken together, our results contribute to our understanding of how in-context learning works by highlighting that the framing of a problem significantly influences how learning occurs, a phenomenon also observed in human cognition.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03970",
        "abstract url": "https://arxiv.org/abs/2402.03970",
        "title": "Tabular Data: Is Attention All You Need?",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Learning has revolutionized the field of AI and led to remarkable achievements in applications involving image and text data. Unfortunately, there is inconclusive evidence on the merits of neural networks for structured tabular data. In this paper, we introduce a large-scale empirical study comparing neural networks against gradient-boosted decision trees on tabular data, but also transformer-based architectures against traditional multi-layer perceptrons (MLP) with residual connections. In contrast to prior work, our empirical findings indicate that neural networks are competitive against decision trees. Furthermore, we assess that transformer-based architectures do not outperform simpler variants of traditional MLP architectures on tabular datasets. As a result, this paper helps the research and practitioner communities make informed choices on deploying neural networks on future tabular data applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03979",
        "abstract url": "https://arxiv.org/abs/2402.03979",
        "title": "Cross Entropy versus Label Smoothing: A Neural Collapse Perspective",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Label smoothing loss is a widely adopted technique to mitigate overfitting in deep neural networks. This paper studies label smoothing from the perspective of Neural Collapse (NC), a powerful empirical and theoretical framework which characterizes model behavior during the terminal phase of training. We first show empirically that models trained with label smoothing converge faster to neural collapse solutions and attain a stronger level of neural collapse. Additionally, we show that at the same level of NC1, models under label smoothing loss exhibit intensified NC2. These findings provide valuable insights into the performance benefits and enhanced model calibration under label smoothing loss. We then leverage the unconstrained feature model to derive closed-form solutions for the global minimizers for both loss functions and further demonstrate that models under label smoothing have a lower conditioning number and, therefore, theoretically converge faster. Our study, combining empirical evidence and theoretical results, not only provides nuanced insights into the differences between label smoothing and cross-entropy losses, but also serves as an example of how the powerful neural collapse framework can be used to improve our understanding of DNNs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03985",
        "abstract url": "https://arxiv.org/abs/2402.03985",
        "title": "A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03991",
        "abstract url": "https://arxiv.org/abs/2402.03991",
        "title": "Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent work in deep learning has shown strong empirical and theoretical evidence of an implicit low-rank bias: weight matrices in deep networks tend to be approximately low-rank and removing relatively small singular values during training or from available trained models may significantly reduce model size while maintaining or even improving model performance. However, the majority of the theoretical investigations around low-rank bias in neural networks deal with oversimplified deep linear networks. In this work, we consider general networks with nonlinear activations and the weight decay parameter, and we show the presence of an intriguing neural rank collapse phenomenon, connecting the low-rank bias of trained networks with networks' neural collapse properties: as the weight decay parameter grows, the rank of each layer in the network decreases proportionally to the within-class variability of the hidden-space embeddings of the previous layers. Our theoretical findings are supported by a range of experimental evaluations illustrating the phenomenon.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03994",
        "abstract url": "https://arxiv.org/abs/2402.03994",
        "title": "Gradient Sketches for Training Data Attribution and Studying the Loss Landscape",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Random projections or sketches of gradients and Hessian vector products play an essential role in applications where one needs to store many such vectors while retaining accurate information about their relative geometry. Two important scenarios are training data attribution (tracing a model's behavior to the training data), where one needs to store a gradient for each training example, and the study of the spectrum of the Hessian (to analyze the training dynamics), where one needs to store multiple Hessian vector products. While sketches that use dense matrices are easy to implement, they are memory bound and cannot be scaled to modern neural networks. Motivated by work on the intrinsic dimension of neural networks, we propose and study a design space for scalable sketching algorithms. We demonstrate the efficacy of our approach in three applications: training data attribution, the analysis of the Hessian spectrum and the computation of the intrinsic dimension when fine-tuning pre-trained language models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04004",
        "abstract url": "https://arxiv.org/abs/2402.04004",
        "title": "Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "During both pretraining and fine-tuning, Large Language Models (\\textbf{LLMs}) are trained on trillions of tokens of text of widely varying quality. Both phases of training typically involve heuristically filtering out ``low-quality'' or \\textit{noisy} training samples, yet little is known quantitatively about how the type or intensity of noise affects downstream performance. In this work, we study how noise in chain of thought (\\textbf{CoT}) impacts task performance in the highly-controlled setting of algorithmically solvable tasks. First, we develop the Traced Integer (\\textbf{TInt}) framework to generate highly customizable noised execution traces for any arithmetic function on lists of integers. We then define two types of noise: \\textit{static} noise, a local form of noise which is applied after the CoT trace is computed, and \\textit{dynamic} noise, a global form of noise which propagates errors in the trace as it is computed. We then evaluate the test performance of pretrained models both prompted and fine-tuned on noised datasets with varying levels of dataset contamination and intensity. We find fine-tuned models are extremely robust to high levels of static noise but struggle significantly more with lower levels of dynamic noise. In contrast, few-shot prompted models appear more sensitive to even static noise. We conclude with a discussion of how our findings impact noise filtering best-practices, in particular emphasizing the importance of removing samples containing destructive dynamic noise with global errors.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04005",
        "abstract url": "https://arxiv.org/abs/2402.04005",
        "title": "Bayesian Uncertainty for Gradient Aggregation in Multi-Task Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As machine learning becomes more prominent there is a growing demand to perform several inference tasks in parallel. Running a dedicated model for each task is computationally expensive and therefore there is a great interest in multi-task learning (MTL). MTL aims at learning a single model that solves several tasks efficiently. Optimizing MTL models is often achieved by computing a single gradient per task and aggregating them for obtaining a combined update direction. However, these approaches do not consider an important aspect, the sensitivity in the gradient dimensions. Here, we introduce a novel gradient aggregation approach using Bayesian inference. We place a probability distribution over the task-specific parameters, which in turn induce a distribution over the gradients of the tasks. This additional valuable information allows us to quantify the uncertainty in each of the gradients dimensions, which can then be factored in when aggregating them. We empirically demonstrate the benefits of our approach in a variety of datasets, achieving state-of-the-art performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04029",
        "abstract url": "https://arxiv.org/abs/2402.04029",
        "title": "Positive concave deep equilibrium models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep equilibrium (DEQ) models are widely recognized as a memory efficient alternative to standard neural networks, achieving state-of-the-art performance in language modeling and computer vision tasks. These models solve a fixed point equation instead of explicitly computing the output, which sets them apart from standard neural networks. However, existing DEQ models often lack formal guarantees of the existence and uniqueness of the fixed point, and the convergence of the numerical scheme used for computing the fixed point is not formally established. As a result, DEQ models are potentially unstable in practice. To address these drawbacks, we introduce a novel class of DEQ models called positive concave deep equilibrium (pcDEQ) models. Our approach, which is based on nonlinear Perron-Frobenius theory, enforces nonnegative weights and activation functions that are concave on the positive orthant. By imposing these constraints, we can easily ensure the existence and uniqueness of the fixed point without relying on additional complex assumptions commonly found in the DEQ literature, such as those based on monotone operator theory in convex analysis. Furthermore, the fixed point can be computed with the standard fixed point algorithm, and we provide theoretical guarantees of geometric convergence, which, in particular, simplifies the training process. Experiments demonstrate the competitiveness of our pcDEQ models against other implicit models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04035",
        "abstract url": "https://arxiv.org/abs/2402.04035",
        "title": "Low-Distortion Clustering with Ordinal and Limited Cardinal Information",
        "rating": 0.5,
        "keywords": [
            [
                "AAAI"
            ]
        ],
        "abstract": "Motivated by recent work in computational social choice, we extend the metric distortion framework to clustering problems. Given a set of $n$ agents located in an underlying metric space, our goal is to partition them into $k$ clusters, optimizing some social cost objective. The metric space is defined by a distance function $d$ between the agent locations. Information about $d$ is available only implicitly via $n$ rankings, through which each agent ranks all other agents in terms of their distance from her. Still, we would like to evaluate clustering algorithms in terms of social cost objectives that are defined using $d$. This is done using the notion of distortion, which measures how far from optimality a clustering can be, taking into account all underlying metrics that are consistent with the ordinal information available. Unfortunately, the most important clustering objectives do not admit algorithms with finite distortion. To sidestep this disappointing fact, we follow two alternative approaches: We first explore whether resource augmentation can be beneficial. We consider algorithms that use more than $k$ clusters but compare their social cost to that of the optimal $k$-clusterings. We show that using exponentially (in terms of $k$) many clusters, we can get low (constant or logarithmic) distortion for the $k$-center and $k$-median objectives. Interestingly, such an exponential blowup is shown to be necessary. More importantly, we explore whether limited cardinal information can be used to obtain better results. Somewhat surprisingly, for $k$-median and $k$-center, we show that a number of queries that is polynomial in $k$ and only logarithmic in $n$ (i.e., only sublinear in the number of agents for the most relevant scenarios in practice) is enough to get constant distortion.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "to appear in AAAI 2024"
    },
    {
        "paper id": "2402.04051",
        "abstract url": "https://arxiv.org/abs/2402.04051",
        "title": "Analysis of Linear Mode Connectivity via Permutation-Based Weight Matching",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, Ainsworth et al. showed that using weight matching (WM) to minimize the $L_2$ distance in a permutation search of model parameters effectively identifies permutations that satisfy linear mode connectivity (LMC), in which the loss along a linear path between two independently trained models with different seeds remains nearly constant. This paper provides a theoretical analysis of LMC using WM, which is crucial for understanding stochastic gradient descent's effectiveness and its application in areas like model merging. We first experimentally and theoretically show that permutations found by WM do not significantly reduce the $L_2$ distance between two models and the occurrence of LMC is not merely due to distance reduction by WM in itself. We then provide theoretical insights showing that permutations can change the directions of the singular vectors, but not the singular values, of the weight matrices in each layer. This finding shows that permutations found by WM mainly align the directions of singular vectors associated with large singular values across models. This alignment brings the singular vectors with large singular values, which determine the model functionality, closer between pre-merged and post-merged models, so that the post-merged model retains functionality similar to the pre-merged models, making it easy to satisfy LMC. Finally, we analyze the difference between WM and straight-through estimator (STE), a dataset-dependent permutation search method, and show that WM outperforms STE, especially when merging three or more models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2402.04054",
        "abstract url": "https://arxiv.org/abs/2402.04054",
        "title": "More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04059",
        "abstract url": "https://arxiv.org/abs/2402.04059",
        "title": "Deep Learning for Multivariate Time Series Imputation: A Survey",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The ubiquitous missing values cause the multivariate time series data to be partially observed, destroying the integrity of time series and hindering the effective time series data analysis. Recently deep learning imputation methods have demonstrated remarkable success in elevating the quality of corrupted time series data, subsequently enhancing performance in downstream tasks. In this paper, we conduct a comprehensive survey on the recently proposed deep learning imputation methods. First, we propose a taxonomy for the reviewed methods, and then provide a structured review of these methods by highlighting their strengths and limitations. We also conduct empirical experiments to study different methods and compare their enhancement for downstream tasks. Finally, the open issues for future research on multivariate time series imputation are pointed out. All code and configurations of this work, including a regularly maintained multivariate time series imputation paper list, can be found in the GitHub repository~\\url{https://github.com/WenjieDu/Awesome\\_Imputation}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 1 figure, 5 tables, 58 referred papers"
    },
    {
        "paper id": "2402.04082",
        "abstract url": "https://arxiv.org/abs/2402.04082",
        "title": "An Optimal House Price Prediction Algorithm: XGBoost",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "An accurate prediction of house prices is a fundamental requirement for various sectors including real estate and mortgage lending. It is widely recognized that a property value is not solely determined by its physical attributes but is significantly influenced by its surrounding neighbourhood. Meeting the diverse housing needs of individuals while balancing budget constraints is a primary concern for real estate developers. To this end, we addressed the house price prediction problem as a regression task and thus employed various machine learning techniques capable of expressing the significance of independent variables. We made use of the housing dataset of Ames City in Iowa, USA to compare support vector regressor, random forest regressor, XGBoost, multilayer perceptron and multiple linear regression algorithms for house price prediction. Afterwards, we identified the key factors that influence housing costs. Our results show that XGBoost is the best performing model for house price prediction.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, Journal of Analytics"
    },
    {
        "paper id": "2402.04084",
        "abstract url": "https://arxiv.org/abs/2402.04084",
        "title": "Provably learning a multi-head attention layer",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The multi-head attention layer is one of the key components of the transformer architecture that sets it apart from traditional feed-forward models. Given a sequence length $k$, attention matrices $\\mathbf\u0398_1,\\ldots,\\mathbf\u0398_m\\in\\mathbb{R}^{d\\times d}$, and projection matrices $\\mathbf{W}_1,\\ldots,\\mathbf{W}_m\\in\\mathbb{R}^{d\\times d}$, the corresponding multi-head attention layer $F: \\mathbb{R}^{k\\times d}\\to \\mathbb{R}^{k\\times d}$ transforms length-$k$ sequences of $d$-dimensional tokens $\\mathbf{X}\\in\\mathbb{R}^{k\\times d}$ via $F(\\mathbf{X}) \\triangleq \\sum^m_{i=1} \\mathrm{softmax}(\\mathbf{X}\\mathbf\u0398_i\\mathbf{X}^\\top)\\mathbf{X}\\mathbf{W}_i$. In this work, we initiate the study of provably learning a multi-head attention layer from random examples and give the first nontrivial upper and lower bounds for this problem: - Provided $\\{\\mathbf{W}_i, \\mathbf\u0398_i\\}$ satisfy certain non-degeneracy conditions, we give a $(dk)^{O(m^3)}$-time algorithm that learns $F$ to small error given random labeled examples drawn uniformly from $\\{\\pm 1\\}^{k\\times d}$. - We prove computational lower bounds showing that in the worst case, exponential dependence on $m$ is unavoidable. We focus on Boolean $\\mathbf{X}$ to mimic the discrete nature of tokens in large language models, though our techniques naturally extend to standard continuous settings, e.g. Gaussian. Our algorithm, which is centered around using examples to sculpt a convex body containing the unknown parameters, is a significant departure from existing provable algorithms for learning feedforward networks, which predominantly exploit algebraic and rotation invariance properties of the Gaussian distribution. In contrast, our analysis is more flexible as it primarily relies on various upper and lower tail bounds for the input distribution and \"slices\" thereof.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "105 pages, comments welcome"
    },
    {
        "paper id": "2402.04103",
        "abstract url": "https://arxiv.org/abs/2402.04103",
        "title": "An Exploration of Clustering Algorithms for Customer Segmentation in the UK Retail Market",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, peoples awareness of online purchases has significantly risen. This has given rise to online retail platforms and the need for a better understanding of customer purchasing behaviour. Retail companies are pressed with the need to deal with a high volume of customer purchases, which requires sophisticated approaches to perform more accurate and efficient customer segmentation. Customer segmentation is a marketing analytical tool that aids customer-centric service and thus enhances profitability. In this paper, we aim to develop a customer segmentation model to improve decision-making processes in the retail market industry. To achieve this, we employed a UK-based online retail dataset obtained from the UCI machine learning repository. The retail dataset consists of 541,909 customer records and eight features. Our study adopted the RFM (recency, frequency, and monetary) framework to quantify customer values. Thereafter, we compared several state-of-the-art (SOTA) clustering algorithms, namely, K-means clustering, the Gaussian mixture model (GMM), density-based spatial clustering of applications with noise (DBSCAN), agglomerative clustering, and balanced iterative reducing and clustering using hierarchies (BIRCH). The results showed the GMM outperformed other approaches, with a Silhouette Score of 0.80.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, Journal of Analytics"
    },
    {
        "paper id": "2402.04111",
        "abstract url": "https://arxiv.org/abs/2402.04111",
        "title": "Vector Approximate Message Passing With Arbitrary I.I.D. Noise Priors",
        "rating": 0.5,
        "keywords": [
            [
                "ICASSP"
            ]
        ],
        "abstract": "Approximate message passing (AMP) algorithms are devised under the Gaussianity assumption of the measurement noise vector. In this work, we relax this assumption within the vector AMP (VAMP) framework to arbitrary independent and identically distributed (i.i.d.) noise priors. We do so by rederiving the linear minimum mean square error (LMMSE) to accommodate both the noise and signal estimations within the message passing steps of VAMP. Numerical results demonstrate how our proposed algorithm handles non-Gaussian noise models as compared to VAMP. This extension to general noise priors enables the use of AMP algorithms in a wider range of engineering applications where non-Gaussian noise models are more appropriate.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Accepted to the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
        "paper id": "2402.04119",
        "abstract url": "https://arxiv.org/abs/2402.04119",
        "title": "Scientific Language Modeling: A Quantitative Review of Large Language Models in Molecular Science",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Efficient molecular modeling and design are crucial for the discovery and exploration of novel molecules, and the incorporation of deep learning methods has revolutionized this field. In particular, large language models (LLMs) offer a fresh approach to tackle scientific problems from a natural language processing (NLP) perspective, introducing a research paradigm called scientific language modeling (SLM). However, two key issues remain: how to quantify the match between model and data modalities and how to identify the knowledge-learning preferences of models. To address these challenges, we propose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263 experiments to assess the model's compatibility with data modalities and knowledge acquisition. Through the modal transition probability matrix, we provide insights into the most suitable modalities for tasks. Furthermore, we introduce a statistically interpretable approach to discover context-specific knowledge mapping by localized feature filtering. Our pioneering analysis offers an exploration of the learning mechanism and paves the way for advancing SLM in molecular science.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04140",
        "abstract url": "https://arxiv.org/abs/2402.04140",
        "title": "Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study consists of a novel approach toward the analysis of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (AI) and legal analysis, emphasizing the role of AI (specifically generative AI) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-AI collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT technology), focusing on detecting logical inconsistencies and biases across various legal decisions. SHIRLEY analysis is aggregated and is accompanied by a comparison-oriented AI-based application called SAM (also an ALM) to identify relative deviations in SHIRLEY bias detections. Further, a CRITIC is generated within semi-autonomous arbitration process via the ALM, SARA. A novel approach is introduced in the utilization of an AI arbitrator to critically evaluate biases and qualitative-in-nature nuances identified by the aforementioned AI applications (SAM in concert with SHIRLEY), based on the Hague Rules on Business and Human Rights Arbitration. This Semi-Automated Arbitration Process (SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring a nuanced debate-resultant \"understanding\" through a hybrid system of AI and human-based collaborative analysis.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04161",
        "abstract url": "https://arxiv.org/abs/2402.04161",
        "title": "Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data characteristics and the transformer architecture. Backed by experiments, we demonstrate that our theoretical findings are in congruence with the empirical results. We further investigate these findings in the broader context of higher order Markov chains and deeper architectures, and outline open problems in this arena. Code is available at \\url{https://github.com/Bond1995/Markov}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04163",
        "abstract url": "https://arxiv.org/abs/2402.04163",
        "title": "Tempered Calculus for ML: Application to Hyperbolic Model Embedding",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Most mathematical distortions used in ML are fundamentally integral in nature: $f$-divergences, Bregman divergences, (regularized) optimal transport distances, integral probability metrics, geodesic distances, etc. In this paper, we unveil a grounded theory and tools which can help improve these distortions to better cope with ML requirements. We start with a generalization of Riemann integration that also encapsulates functions that are not strictly additive but are, more generally, $t$-additive, as in nonextensive statistical mechanics. Notably, this recovers Volterra's product integral as a special case. We then generalize the Fundamental Theorem of calculus using an extension of the (Euclidean) derivative. This, along with a series of more specific Theorems, serves as a basis for results showing how one can specifically design, alter, or change fundamental properties of distortion measures in a simple way, with a special emphasis on geometric- and ML-related properties that are the metricity, hyperbolicity, and encoding. We show how to apply it to a problem that has recently gained traction in ML: hyperbolic embeddings with a \"cheap\" and accurate encoding along the hyperbolic vs Euclidean scale. We unveil a new application for which the Poincar\u00e9 disk model has very appealing features, and our theory comes in handy: \\textit{model} embeddings for boosted combinations of decision trees, trained using the log-loss (trees) and logistic loss (combinations).",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04182",
        "abstract url": "https://arxiv.org/abs/2402.04182",
        "title": "Reinforcement Learning with Ensemble Model Predictive Safety Certification",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning algorithms need exploration to learn. However, unsupervised exploration prevents the deployment of such algorithms on safety-critical tasks and limits real-world deployment. In this paper, we propose a new algorithm called Ensemble Model Predictive Safety Certification that combines model-based deep reinforcement learning with tube-based model predictive control to correct the actions taken by a learning agent, keeping safety constraint violations at a minimum through planning. Our approach aims to reduce the amount of prior knowledge about the actual system by requiring only offline data generated by a safe controller. Our results show that we can achieve significantly fewer constraint violations than comparable reinforcement learning methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Published in: Proc. of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)"
    },
    {
        "paper id": "2402.04193",
        "abstract url": "https://arxiv.org/abs/2402.04193",
        "title": "Gradient Coding in Decentralized Learning for Evading Stragglers",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we consider a decentralized learning problem in the presence of stragglers. Although gradient coding techniques have been developed for distributed learning to evade stragglers, where the devices send encoded gradients with redundant training data, it is difficult to apply those techniques directly to decentralized learning scenarios. To deal with this problem, we propose a new gossip-based decentralized learning method with gradient coding (GOCO). In the proposed method, to avoid the negative impact of stragglers, the parameter vectors are updated locally using encoded gradients based on the framework of stochastic gradient coding and then averaged in a gossip-based manner. We analyze the convergence performance of GOCO for strongly convex loss functions. And we also provide simulation results to demonstrate the superiority of the proposed method in terms of learning performance compared with the baseline methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04203",
        "abstract url": "https://arxiv.org/abs/2402.04203",
        "title": "Human-Like Geometric Abstraction in Large Pre-trained Neural Networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Humans possess a remarkable capacity to recognize and manipulate abstract structure, which is especially apparent in the domain of geometry. Recent research in cognitive science suggests neural networks do not share this capacity, concluding that human geometric abilities come from discrete symbolic structure in human mental representations. However, progress in artificial intelligence (AI) suggests that neural networks begin to demonstrate more human-like reasoning after scaling up standard architectures in both model size and amount of training data. In this study, we revisit empirical results in cognitive science on geometric visual processing and identify three key biases in geometric visual processing: a sensitivity towards complexity, regularity, and the perception of parts and relations. We test tasks from the literature that probe these biases in humans and find that large pre-trained neural network models used in AI demonstrate more human-like abstract geometric processing.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04210",
        "abstract url": "https://arxiv.org/abs/2402.04210",
        "title": "\"Task Success\" is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors",
        "rating": 0.5,
        "keywords": [
            [
                "VLMs"
            ],
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large-scale generative models are shown to be useful for sampling meaningful candidate solutions, yet they often overlook task constraints and user preferences. Their full power is better harnessed when the models are coupled with external verifiers and the final solutions are derived iteratively or progressively according to the verification feedback. In the context of embodied AI, verification often solely involves assessing whether goal conditions specified in the instructions have been met. Nonetheless, for these agents to be seamlessly integrated into daily life, it is crucial to account for a broader range of constraints and preferences beyond bare task success (e.g., a robot should grasp bread with care to avoid significant deformations). However, given the unbounded scope of robot tasks, it is infeasible to construct scripted verifiers akin to those used for explicit-knowledge tasks like the game of Go and theorem proving. This begs the question: when no sound verifier is available, can we use large vision and language models (VLMs), which are approximately omniscient, as scalable Behavior Critics to catch undesirable robot behaviors in videos? To answer this, we first construct a benchmark that contains diverse cases of goal-reaching yet undesirable robot policies. Then, we comprehensively evaluate VLM critics to gain a deeper understanding of their strengths and failure modes. Based on the evaluation, we provide guidelines on how to effectively utilize VLM critiques and showcase a practical way to integrate the feedback into an iterative process of policy refinement. The dataset and codebase are released at: https://guansuns.github.io/pages/vlm-critic.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04211",
        "abstract url": "https://arxiv.org/abs/2402.04211",
        "title": "Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a novel masked neural network architecture. Evaluations on simulated and real datasets underscore our technique's robust predictive and explanatory performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04229",
        "abstract url": "https://arxiv.org/abs/2402.04229",
        "title": "MusicRL: Aligning Music Generation to Human Preferences",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose MusicRL, the first music generation system finetuned from human feedback. Appreciation of text-to-music models is particularly subjective since the concept of musicality as well as the specific intention behind a caption are user-dependent (e.g. a caption such as \"upbeat work-out music\" can map to a retro guitar solo or a techno pop beat). Not only this makes supervised training of such models challenging, but it also calls for integrating continuous human feedback in their post-deployment finetuning. MusicRL is a pretrained autoregressive MusicLM (Agostinelli et al., 2023) model of discrete audio tokens finetuned with reinforcement learning to maximise sequence-level rewards. We design reward functions related specifically to text-adherence and audio quality with the help from selected raters, and use those to finetune MusicLM into MusicRL-R. We deploy MusicLM to users and collect a substantial dataset comprising 300,000 pairwise preferences. Using Reinforcement Learning from Human Feedback (RLHF), we train MusicRL-U, the first text-to-music model that incorporates human feedback at scale. Human evaluations show that both MusicRL-R and MusicRL-U are preferred to the baseline. Ultimately, MusicRL-RU combines the two approaches and results in the best model according to human raters. Ablation studies shed light on the musical attributes influencing human preferences, indicating that text adherence and quality only account for a part of it. This underscores the prevalence of subjectivity in musical appreciation and calls for further involvement of human listeners in the finetuning of music generation models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04232",
        "abstract url": "https://arxiv.org/abs/2402.04232",
        "title": "Can Generative Agents Predict Emotion?",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated a number of human-like abilities, however the empathic understanding and emotional state of LLMs is yet to be aligned to that of humans. In this work, we investigate how the emotional state of generative LLM agents evolves as they perceive new events, introducing a novel architecture in which new experiences are compared to past memories. Through this comparison, the agent gains the ability to understand new experiences in context, which according to the appraisal theory of emotion is vital in emotion creation. First, the agent perceives new experiences as time series text data. After perceiving each new input, the agent generates a summary of past relevant memories, referred to as the norm, and compares the new experience to this norm. Through this comparison we can analyse how the agent reacts to the new experience in context. The PANAS, a test of affect, is administered to the agent, capturing the emotional state of the agent after the perception of the new event. Finally, the new experience is then added to the agents memory to be used in the creation of future norms. By creating multiple experiences in natural language from emotionally charged situations, we test the proposed architecture on a wide range of scenarios. The mixed results suggests that introducing context can occasionally improve the emotional alignment of the agent, but further study and comparison with human evaluators is necessary. We hope that this paper is another step towards the alignment of generative agents.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "14 pages, 6 figures"
    },
    {
        "paper id": "2402.04239",
        "abstract url": "https://arxiv.org/abs/2402.04239",
        "title": "CAST: Clustering Self-Attention using Surrogate Tokens for Efficient Transformers",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Transformer architecture has shown to be a powerful tool for a wide range of tasks. It is based on the self-attention mechanism, which is an inherently computationally expensive operation with quadratic computational complexity: memory usage and compute time increase quadratically with the length of the input sequences, thus limiting the application of Transformers. In this work, we propose a novel Clustering self-Attention mechanism using Surrogate Tokens (CAST), to optimize the attention computation and achieve efficient transformers. CAST utilizes learnable surrogate tokens to construct a cluster affinity matrix, used to cluster the input sequence and generate novel cluster summaries. The self-attention from within each cluster is then combined with the cluster summaries of other clusters, enabling information flow across the entire input sequence. CAST improves efficiency by reducing the complexity from $O(N^2)$ to $O(\u03b1N)$ where N is the sequence length, and \u03b1 is constant according to the number of clusters and samples per cluster. We show that CAST performs better than or comparable to the baseline Transformers on long-range sequence modeling tasks, while also achieving higher results on time and memory efficiency than other efficient transformers.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04247",
        "abstract url": "https://arxiv.org/abs/2402.04247",
        "title": "Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Intelligent agents powered by large language models (LLMs) have demonstrated substantial promise in autonomously conducting experiments and facilitating scientific discoveries across various disciplines. While their capabilities are promising, they also introduce novel vulnerabilities that demand careful consideration for safety. However, there exists a notable gap in the literature, as there has been no comprehensive exploration of these vulnerabilities. This position paper fills this gap by conducting a thorough examination of vulnerabilities in LLM-based agents within scientific domains, shedding light on potential risks associated with their misuse and emphasizing the need for safety measures. We begin by providing a comprehensive overview of the potential risks inherent to scientific LLM agents, taking into account user intent, the specific scientific domain, and their potential impact on the external environment. Then, we delve into the origins of these vulnerabilities and provide a scoping review of the limited existing works. Based on our analysis, we propose a triadic framework involving human regulation, agent alignment, and an understanding of environmental feedback (agent regulation) to mitigate these identified risks. Furthermore, we highlight the limitations and challenges associated with safeguarding scientific agents and advocate for the development of improved models, robust benchmarks, and comprehensive regulations to address these issues effectively.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04248",
        "abstract url": "https://arxiv.org/abs/2402.04248",
        "title": "Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "State-space models (SSMs), such as Mamba Gu & Dao (2034), have been proposed as alternatives to Transformer networks in language modeling, by incorporating gating, convolutions, and input-dependent token selection to mitigate the quadratic cost of multi-head attention. Although SSMs exhibit competitive performance, their in-context learning (ICL) capabilities, a remarkable emergent property of modern language models that enables task execution without parameter optimization, remain underexplored compared to Transformers. In this study, we evaluate the ICL performance of SSMs, focusing on Mamba, against Transformer models across various tasks. Our results show that SSMs perform comparably to Transformers in standard regression ICL tasks, while outperforming them in tasks like sparse parity learning. However, SSMs fall short in tasks involving non-standard retrieval functionality. To address these limitations, we introduce a hybrid model, \\variant, that combines Mamba with attention blocks, surpassing individual models in tasks where they struggle independently. Our findings suggest that hybrid architectures offer promising avenues for enhancing ICL in language models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 6 figures"
    },
    {
        "paper id": "2402.04298",
        "abstract url": "https://arxiv.org/abs/2402.04298",
        "title": "Multi-View Symbolic Regression",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Symbolic regression (SR) searches for analytical expressions representing the relationship between a set of explanatory and response variables. Current SR methods assume a single dataset extracted from a single experiment. Nevertheless, frequently, the researcher is confronted with multiple sets of results obtained from experiments conducted with different setups. Traditional SR methods may fail to find the underlying expression since the parameters of each experiment can be different. In this work we present Multi-View Symbolic Regression (MvSR), which takes into account multiple datasets simultaneously, mimicking experimental environments, and outputs a general parametric solution. This approach fits the evaluated expression to each independent dataset and returns a parametric family of functions f(x; \u03b8) simultaneously capable of accurately fitting all datasets. We demonstrate the effectiveness of MvSR using data generated from known expressions, as well as real-world data from astronomy, chemistry and economy, for which an a priori analytical expression is not available. Results show that MvSR obtains the correct expression more frequently and is robust to hyperparameters change. In real-world data, it is able to grasp the group behaviour, recovering known expressions from the literature as well as promising alternatives, thus enabling the use SR to a large range of experimental scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to GECCO-2024. 10 pages, 6 figures"
    },
    {
        "paper id": "2402.04344",
        "abstract url": "https://arxiv.org/abs/2402.04344",
        "title": "Does Confidence Calibration Help Conformal Prediction?",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Conformal prediction, as an emerging uncertainty qualification technique, constructs prediction sets that are guaranteed to contain the true label with high probability. Previous works usually employ temperature scaling to calibrate the classifier, assuming that confidence calibration can benefit conformal prediction. In this work, we first show that post-hoc calibration methods surprisingly lead to larger prediction sets with improved calibration, while over-confidence with small temperatures benefits the conformal prediction performance instead. Theoretically, we prove that high confidence reduces the probability of appending a new class in the prediction set. Inspired by the analysis, we propose a novel method, $\\textbf{Conformal Temperature Scaling}$ (ConfTS), which rectifies the objective through the gap between the threshold and the non-conformity score of the ground-truth label. In this way, the new objective of ConfTS will optimize the temperature value toward an optimal set that satisfies the $\\textit{marginal coverage}$. Experiments demonstrate that our method can effectively improve widely-used conformal prediction methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04359",
        "abstract url": "https://arxiv.org/abs/2402.04359",
        "title": "Adaptive Inference: Theoretical Limits and Unexplored Opportunities",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces the first theoretical framework for quantifying the efficiency and performance gain opportunity size of adaptive inference algorithms. We provide new approximate and exact bounds for the achievable efficiency and performance gains, supported by empirical evidence demonstrating the potential for 10-100x efficiency improvements in both Computer Vision and Natural Language Processing tasks without incurring any performance penalties. Additionally, we offer insights on improving achievable efficiency gains through the optimal selection and design of adaptive inference state spaces.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04362",
        "abstract url": "https://arxiv.org/abs/2402.04362",
        "title": "Neural Networks Learn Statistics of Increasing Complexity",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The distributional simplicity bias (DSB) posits that neural networks learn low-order moments of the data distribution first, before moving on to higher-order correlations. In this work, we present compelling new evidence for the DSB by showing that networks automatically learn to perform well on maximum-entropy distributions whose low-order statistics match those of the training set early in training, then lose this ability later. We also extend the DSB to discrete domains by proving an equivalence between token $n$-gram frequencies and the moments of embedding vectors, and by finding empirical evidence for the bias in LLMs. Finally we use optimal transport methods to surgically edit the low-order statistics of one class to match those of another, and show that early-training networks treat the edited samples as if they were drawn from the target class. Code is available at https://github.com/EleutherAI/features-across-time.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04373",
        "abstract url": "https://arxiv.org/abs/2402.04373",
        "title": "The World of Generative AI: Deepfakes and Large Language Models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "We live in the era of Generative Artificial Intelligence (GenAI). Deepfakes and Large Language Models (LLMs) are two examples of GenAI. Deepfakes, in particular, pose an alarming threat to society as they are capable of spreading misinformation and changing the truth. LLMs are powerful language models that generate general-purpose language. However due to its generative aspect, it can also be a risk for people if used with ill intentions. The ethical use of these technologies is a big concern. This short article tries to find out the interrelationship between them.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04375",
        "abstract url": "https://arxiv.org/abs/2402.04375",
        "title": "Bounding the Excess Risk for Linear Models Trained on Marginal-Preserving, Differentially-Private, Synthetic Data",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The growing use of machine learning (ML) has raised concerns that an ML model may reveal private information about an individual who has contributed to the training dataset. To prevent leakage of sensitive data, we consider using differentially-private (DP), synthetic training data instead of real training data to train an ML model. A key desirable property of synthetic data is its ability to preserve the low-order marginals of the original distribution. Our main contribution comprises novel upper and lower bounds on the excess empirical risk of linear models trained on such synthetic data, for continuous and Lipschitz loss functions. We perform extensive experimentation alongside our theoretical results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04376",
        "abstract url": "https://arxiv.org/abs/2402.04376",
        "title": "Scaling laws for learning with real and surrogate data",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Collecting large quantities of high-quality data is often prohibitively expensive or impractical, and a crucial bottleneck in machine learning. One may instead augment a small set of $n$ data points from the target distribution with data from more accessible sources like public datasets, data collected under different circumstances, or synthesized by generative models. Blurring distinctions, we refer to such data as `surrogate data'. We define a simple scheme for integrating surrogate data into training and use both theoretical models and empirical studies to explore its behavior. Our main findings are: $(i)$ Integrating surrogate data can significantly reduce the test error on the original distribution; $(ii)$ In order to reap this benefit, it is crucial to use optimally weighted empirical risk minimization; $(iii)$ The test error of models trained on mixtures of real and surrogate data is well described by a scaling law. This can be used to predict the optimal weighting and the gain from surrogate data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04377",
        "abstract url": "https://arxiv.org/abs/2402.04377",
        "title": "NeRCC: Nested-Regression Coded Computing for Resilient Distributed Prediction Serving Systems",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Resilience against stragglers is a critical element of prediction serving systems, tasked with executing inferences on input data for a pre-trained machine-learning model. In this paper, we propose NeRCC, as a general straggler-resistant framework for approximate coded computing. NeRCC includes three layers: (1) encoding regression and sampling, which generates coded data points, as a combination of original data points, (2) computing, in which a cluster of workers run inference on the coded data points, (3) decoding regression and sampling, which approximately recovers the predictions of the original data points from the available predictions on the coded data points. We argue that the overall objective of the framework reveals an underlying interconnection between two regression models in the encoding and decoding layers. We propose a solution to the nested regressions problem by summarizing their dependence on two regularization terms that are jointly optimized. Our extensive experiments on different datasets and various machine learning models, including LeNet5, RepVGG, and Vision Transformer (ViT), demonstrate that NeRCC accurately approximates the original predictions in a wide range of stragglers, outperforming the state-of-the-art by up to 23%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04382",
        "abstract url": "https://arxiv.org/abs/2402.04382",
        "title": "Counterfactual Generation with Answer Set Programming",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Machine learning models that automate decision-making are increasingly being used in consequential areas such as loan approvals, pretrial bail approval, hiring, and many more. Unfortunately, most of these models are black-boxes, i.e., they are unable to reveal how they reach these prediction decisions. A need for transparency demands justification for such predictions. An affected individual might also desire explanations to understand why a decision was made. Ethical and legal considerations may further require informing the individual of changes in the input attribute that could be made to produce a desirable outcome. This paper focuses on the latter problem of automatically generating counterfactual explanations. We propose a framework Counterfactual Generation with s(CASP) (CFGS) that utilizes answer set programming (ASP) and the s(CASP) goal-directed ASP system to automatically generate counterfactual explanations from rules generated by rule-based machine learning (RBML) algorithms. In our framework, we show how counterfactual explanations are computed and justified by imagining worlds where some or all factual assumptions are altered/changed. More importantly, we show how we can navigate between these worlds, namely, go from our original world/scenario where we obtain an undesired outcome to the imagined world/scenario where we obtain a desired/favourable outcome.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "16 Pages"
    },
    {
        "paper id": "2402.04396",
        "abstract url": "https://arxiv.org/abs/2402.04396",
        "title": "QuIP#: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Post-training quantization (PTQ) reduces the memory footprint of LLMs by quantizing their weights to low-precision. In this work, we introduce QuIP#, a weight-only PTQ method that achieves state-of-the-art results in extreme compression regimes ($\\le$ 4 bits per weight) using three novel techniques. First, QuIP# improves the incoherence processing from QuIP by using the randomized Hadamard transform, which is faster and has better theoretical properties. Second, QuIP# uses vector quantization techniques to take advantage of the ball-shaped sub-Gaussian distribution that incoherent weights possess: specifically, we introduce a set of hardware-efficient codebooks based on the highly symmetric $E_8$ lattice, which achieves the optimal 8-dimension unit ball packing. Third, QuIP# uses fine-tuning to improve fidelity to the original model. Our experiments show that QuIP# outperforms existing PTQ methods, enables new behaviors in PTQ scaling, and supports fast inference.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2402.04398",
        "abstract url": "https://arxiv.org/abs/2402.04398",
        "title": "Learning from Time Series under Temporal Label Noise",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many sequential classification tasks are affected by label noise that varies over time. Such noise can cause label quality to improve, worsen, or periodically change over time. We first propose and formalize temporal label noise, an unstudied problem for sequential classification of time series. In this setting, multiple labels are recorded in sequence while being corrupted by a time-dependent noise function. We first demonstrate the importance of modelling the temporal nature of the label noise function and how existing methods will consistently underperform. We then propose methods that can train noise-tolerant classifiers by estimating the temporal label noise function directly from data. We show that our methods lead to state-of-the-art performance in the presence of diverse temporal label noise functions using real and synthetic data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04440",
        "abstract url": "https://arxiv.org/abs/2402.04440",
        "title": "Exploring higher-order neural network node interactions with total correlation",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In domains such as ecological systems, collaborations, and the human brain the variables interact in complex ways. Yet accurately characterizing higher-order variable interactions (HOIs) is a difficult problem that is further exacerbated when the HOIs change across the data. To solve this problem we propose a new method called Local Correlation Explanation (CorEx) to capture HOIs at a local scale by first clustering data points based on their proximity on the data manifold. We then use a multivariate version of the mutual information called the total correlation, to construct a latent factor representation of the data within each cluster to learn the local HOIs. We use Local CorEx to explore HOIs in synthetic and real world data to extract hidden insights about the data structure. Lastly, we demonstrate Local CorEx's suitability to explore and interpret the inner workings of trained neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04464",
        "abstract url": "https://arxiv.org/abs/2402.04464",
        "title": "Ten Hard Problems in Artificial Intelligence We Must Get Right",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We explore the AI2050 \"hard problems\" that block the promise of AI and cause AI risks: (1) developing general capabilities of the systems; (2) assuring the performance of AI systems and their training processes; (3) aligning system goals with human goals; (4) enabling great applications of AI in real life; (5) addressing economic disruptions; (6) ensuring the participation of all; (7) at the same time ensuring socially responsible deployment; (8) addressing any geopolitical disruptions that AI causes; (9) promoting sound governance of the technology; and (10) managing the philosophical disruptions for humans living in the age of AI. For each problem, we outline the area, identify significant recent work, and suggest ways forward. [Note: this paper reviews literature through January 2023.]",
        "subjects": [
            "cs.AI"
        ],
        "comment": "75 + 19 pages"
    },
    {
        "paper id": "2402.04467",
        "abstract url": "https://arxiv.org/abs/2402.04467",
        "title": "DySLIM: Dynamics Stable Learning by Invariant Measure for Chaotic Systems",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning dynamics from dissipative chaotic systems is notoriously difficult due to their inherent instability, as formalized by their positive Lyapunov exponents, which exponentially amplify errors in the learned dynamics. However, many of these systems exhibit ergodicity and an attractor: a compact and highly complex manifold, to which trajectories converge in finite-time, that supports an invariant measure, i.e., a probability distribution that is invariant under the action of the dynamics, which dictates the long-term statistical behavior of the system. In this work, we leverage this structure to propose a new framework that targets learning the invariant measure as well as the dynamics, in contrast with typical methods that only target the misfit between trajectories, which often leads to divergence as the trajectories' length increases. We use our framework to propose a tractable and sample efficient objective that can be used with any existing learning objectives. Our Dynamics Stable Learning by Invariant Measures (DySLIM) objective enables model training that achieves better point-wise tracking and long-term statistical accuracy relative to other learning objectives. By targeting the distribution with a scalable regularization term, we hope that this approach can be extended to more complex systems exhibiting slowly-variant distributions, such as weather and climate models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04476",
        "abstract url": "https://arxiv.org/abs/2402.04476",
        "title": "Dual-View Visual Contextualization for Web Navigation",
        "rating": 0.5,
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Automatic web navigation aims to build a web agent that can follow language instructions to execute complex and diverse tasks on real-world websites. Existing work primarily takes HTML documents as input, which define the contents and action spaces (i.e., actionable elements and operations) of webpages. Nevertheless, HTML documents may not provide a clear task-related context for each element, making it hard to select the right (sequence of) actions. In this paper, we propose to contextualize HTML elements through their \"dual views\" in webpage screenshots: each HTML element has its corresponding bounding box and visual content in the screenshot. We build upon the insight -- web developers tend to arrange task-related elements nearby on webpages to enhance user experiences -- and propose to contextualize each element with its neighbor elements, using both textual and visual features. The resulting representations of HTML elements are more informative for the agent to take action. We validate our method on the recently released Mind2Web dataset, which features diverse navigation domains and tasks on real-world websites. Our method consistently outperforms the baseline in all the scenarios, including cross-task, cross-website, and cross-domain ones.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to CVPR 2024"
    },
    {
        "paper id": "2402.04489",
        "abstract url": "https://arxiv.org/abs/2402.04489",
        "title": "De-amplifying Bias from Differential Privacy in Language Model Fine-tuning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fairness and privacy are two important values machine learning (ML) practitioners often seek to operationalize in models. Fairness aims to reduce model bias for social/demographic sub-groups. Privacy via differential privacy (DP) mechanisms, on the other hand, limits the impact of any individual's training data on the resulting model. The trade-offs between privacy and fairness goals of trustworthy ML pose a challenge to those wishing to address both. We show that DP amplifies gender, racial, and religious bias when fine-tuning large language models (LLMs), producing models more biased than ones fine-tuned without DP. We find the cause of the amplification to be a disparity in convergence of gradients across sub-groups. Through the case of binary gender bias, we demonstrate that Counterfactual Data Augmentation (CDA), a known method for addressing bias, also mitigates bias amplification by DP. As a consequence, DP and CDA together can be used to fine-tune models while maintaining both fairness and privacy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04494",
        "abstract url": "https://arxiv.org/abs/2402.04494",
        "title": "Grandmaster-Level Chess Without Search",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The recent breakthrough successes in machine learning are mainly attributed to scale: namely large-scale attention-based architectures and datasets of unprecedented scale. This paper investigates the impact of training at scale for chess. Unlike traditional chess engines that rely on complex heuristics, explicit search, or a combination of both, we train a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games. We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points. Our largest model reaches a Lichess blitz Elo of 2895 against humans, and successfully solves a series of challenging chess puzzles, without any domain-specific tweaks or explicit search algorithms. We also show that our model outperforms AlphaZero's policy and value networks (without MCTS) and GPT-3.5-turbo-instruct. A systematic investigation of model and dataset size shows that strong chess performance only arises at sufficient scale. To validate our results, we perform an extensive series of ablations of design choices and hyperparameters.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04497",
        "abstract url": "https://arxiv.org/abs/2402.04497",
        "title": "The Fine-Grained Complexity of Gradient Computation for Training Large Language Models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) have made fundamental contributions over the last a few years. To train an LLM, one needs to alternatingly run `forward' computations and `backward' computations. The forward computation can be viewed as attention function evaluation, and the backward computation can be viewed as a gradient computation. In previous work by [Alman and Song, NeurIPS 2023], it was proved that the forward step can be performed in almost-linear time in certain parameter regimes, but that there is no truly sub-quadratic time algorithm in the remaining parameter regimes unless the popular hypothesis SETH is false. In this work, we show nearly identical results for the harder-seeming problem of computing the gradient of loss function of one layer attention network, and thus for the entire process of LLM training. This completely characterizes the fine-grained complexity of every step of LLM training.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04513",
        "abstract url": "https://arxiv.org/abs/2402.04513",
        "title": "Online Cascade Learning for Efficient Inference over Streams",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have a natural role in answering complex queries about data streams, but the high computational cost of LLM inference makes them infeasible in many such tasks. We propose online cascade learning, the first approach to addressing this challenge. The objective here is to learn a \"cascade\" of models, starting with lower-capacity models (such as logistic regressors) and ending with a powerful LLM, along with a deferral policy that determines the model that is used on a given input. We formulate the task of learning cascades online as an imitation-learning problem and give a no-regret algorithm for the problem. Experimental results across four benchmarks show that our method parallels LLMs in accuracy while cutting down inference costs by as much as 90%, underscoring its efficacy and adaptability in stream processing.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04520",
        "abstract url": "https://arxiv.org/abs/2402.04520",
        "title": "On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the computational limits of the memory retrieval dynamics of modern Hopfield models from the fine-grained complexity analysis. Our key contribution is the characterization of a phase transition behavior in the efficiency of all possible modern Hopfield models based on the norm of patterns. Specifically, we establish an upper bound criterion for the norm of input query patterns and memory patterns. Only below this criterion, sub-quadratic (efficient) variants of the modern Hopfield model exist, assuming the Strong Exponential Time Hypothesis (SETH). To showcase our theory, we provide a formal example of efficient constructions of modern Hopfield models using low-rank approximation when the efficient criterion holds. This includes a derivation of a lower bound on the computational time, scaling linearly with $\\max\\{$\\# of stored memory patterns, length of input query sequence$\\}$. In addition, we prove its memory retrieval error bound and exponential memory capacity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "31 pages; v2: fix typos; v3: fix typos, add clarifications, add references"
    },
    {
        "paper id": "2402.04538",
        "abstract url": "https://arxiv.org/abs/2402.04538",
        "title": "Triplet Interaction Improves Graph Transformers: Accurate Molecular Graph Learning with Triplet Graph Transformers",
        "rating": 0.5,
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph transformers typically lack direct pair-to-pair communication, instead forcing neighboring pairs to exchange information via a common node. We propose the Triplet Graph Transformer (TGT) that enables direct communication between two neighboring pairs in a graph via novel triplet attention and aggregation mechanisms. TGT is applied to molecular property prediction by first predicting interatomic distances from 2D graphs and then using these distances for downstream tasks. A novel three-stage training procedure and stochastic inference further improve training efficiency and model performance. Our model achieves new state-of-the-art (SOTA) results on open challenge benchmarks PCQM4Mv2 and OC20 IS2RE. We also obtain SOTA results on QM9, MOLPCBA, and LIT-PCBA molecular property prediction benchmarks via transfer learning. We also demonstrate the generality of TGT with SOTA results on the traveling salesman problem (TSP).",
        "subjects": [
            "cs.LG"
        ],
        "comment": "First preprint, 24 pages, 10 figures, 18 tables"
    },
    {
        "paper id": "2402.04539",
        "abstract url": "https://arxiv.org/abs/2402.04539",
        "title": "Learning Diverse Policies with Soft Self-Generated Guidance",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning (RL) with sparse and deceptive rewards is challenging because non-zero rewards are rarely obtained. Hence, the gradient calculated by the agent can be stochastic and without valid information. Recent studies that utilize memory buffers of previous experiences can lead to a more efficient learning process. However, existing methods often require these experiences to be successful and may overly exploit them, which can cause the agent to adopt suboptimal behaviors. This paper develops an approach that uses diverse past trajectories for faster and more efficient online RL, even if these trajectories are suboptimal or not highly rewarded. The proposed algorithm combines a policy improvement step with an additional exploration step using offline demonstration data. The main contribution of this paper is that by regarding diverse past trajectories as guidance, instead of imitating them, our method directs its policy to follow and expand past trajectories while still being able to learn without rewards and approach optimality. Furthermore, a novel diversity measurement is introduced to maintain the team's diversity and regulate exploration. The proposed algorithm is evaluated on discrete and continuous control tasks with sparse and deceptive rewards. Compared with the existing RL methods, the experimental results indicate that our proposed algorithm is significantly better than the baseline methods regarding diverse exploration and avoiding local optima.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "23 pages, 19 figures"
    },
    {
        "paper id": "2402.04553",
        "abstract url": "https://arxiv.org/abs/2402.04553",
        "title": "Curvature-Informed SGD via General Purpose Lie-Group Preconditioners",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a novel approach to accelerate stochastic gradient descent (SGD) by utilizing curvature information obtained from Hessian-vector products or finite differences of parameters and gradients, similar to the BFGS algorithm. Our approach involves two preconditioners: a matrix-free preconditioner and a low-rank approximation preconditioner. We update both preconditioners online using a criterion that is robust to stochastic gradient noise and does not require line search or damping. To preserve the corresponding symmetry or invariance, our preconditioners are constrained to certain connected Lie groups. The Lie group's equivariance property simplifies the preconditioner fitting process, while its invariance property eliminates the need for damping, which is commonly required in second-order optimizers. As a result, the learning rate for parameter updating and the step size for preconditioner fitting are naturally normalized, and their default values work well in most scenarios. Our proposed approach offers a promising direction for improving the convergence of SGD with low computational overhead. We demonstrate that Preconditioned SGD (PSGD) outperforms SoTA on Vision, NLP, and RL tasks across multiple modern deep-learning architectures. We have provided code for reproducing toy and large scale experiments in this paper.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04559",
        "abstract url": "https://arxiv.org/abs/2402.04559",
        "title": "Can Large Language Model Agents Simulate Human Trust Behaviors?",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, particularly for GPT-4, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strategies and external manipulations. We further offer important implications of our discoveries for various scenarios where trust is paramount. Our study provides new insights into the behaviors of LLM agents and the fundamental analogy between LLMs and humans.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "The first two authors contributed equally. Project website: https://www.camel-ai.org/research/agent-trust"
    },
    {
        "paper id": "2402.04578",
        "abstract url": "https://arxiv.org/abs/2402.04578",
        "title": "S-Agents: Self-organizing Agents in Open-ended Environments",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Leveraging large language models (LLMs), autonomous agents have significantly improved, gaining the ability to handle a variety of tasks. In open-ended settings, optimizing collaboration for efficiency and effectiveness demands flexible adjustments. Despite this, current research mainly emphasizes fixed, task-oriented workflows and overlooks agent-centric organizational structures. Drawing inspiration from human organizational behavior, we introduce a self-organizing agent system (S-Agents) with a \"tree of agents\" structure for dynamic workflow, an \"hourglass agent architecture\" for balancing information priorities, and a \"non-obstructive collaboration\" method to allow asynchronous task execution among agents. This structure can autonomously coordinate a group of agents, efficiently addressing the challenges of open and dynamic environments without human intervention. Our experiments demonstrate that S-Agents proficiently execute collaborative building tasks and resource collection in the Minecraft environment, validating their effectiveness.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Preview, 15 pages, 12 figure"
    },
    {
        "paper id": "2402.04579",
        "abstract url": "https://arxiv.org/abs/2402.04579",
        "title": "Collective Counterfactual Explanations via Optimal Transport",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Counterfactual explanations provide individuals with cost-optimal actions that can alter their labels to desired classes. However, if substantial instances seek state modification, such individual-centric methods can lead to new competitions and unanticipated costs. Furthermore, these recommendations, disregarding the underlying data distribution, may suggest actions that users perceive as outliers. To address these issues, our work proposes a collective approach for formulating counterfactual explanations, with an emphasis on utilizing the current density of the individuals to inform the recommended actions. Our problem naturally casts as an optimal transport problem. Leveraging the extensive literature on optimal transport, we illustrate how this collective method improves upon the desiderata of classical counterfactual explanations. We support our proposal with numerical simulations, illustrating the effectiveness of the proposed approach and its relation to classic methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05970",
        "abstract url": "https://arxiv.org/abs/2402.05970",
        "title": "Modeling Spatio-temporal Dynamical Systems with Neural Discrete Learning and Levels-of-Experts",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we address the issue of modeling and estimating changes in the state of the spatio-temporal dynamical systems based on a sequence of observations like video frames. Traditional numerical simulation systems depend largely on the initial settings and correctness of the constructed partial differential equations (PDEs). Despite recent efforts yielding significant success in discovering data-driven PDEs with neural networks, the limitations posed by singular scenarios and the absence of local insights prevent them from performing effectively in a broader real-world context. To this end, this paper propose the universal expert module -- that is, optical flow estimation component, to capture the evolution laws of general physical processes in a data-driven fashion. To enhance local insight, we painstakingly design a finer-grained physical pipeline, since local characteristics may be influenced by various internal contextual information, which may contradict the macroscopic properties of the whole system. Further, we harness currently popular neural discrete learning to unveil the underlying important features in its latent space, this process better injects interpretability, which can help us obtain a powerful prior over these discrete random variables. We conduct extensive experiments and ablations to demonstrate that the proposed framework achieves large performance margins, compared with the existing SOTA baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06665",
        "abstract url": "https://arxiv.org/abs/2402.06665",
        "title": "The Essential Role of Causality in Foundation World Models for Embodied AI",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advances in foundation models, especially in large multi-modal models and conversational agents, have ignited interest in the potential of generally capable embodied agents. Such agents would require the ability to perform new tasks in many different real-world environments. However, current foundation models fail to accurately model physical interactions with the real world thus not sufficient for Embodied AI. The study of causality lends itself to the construction of veridical world models, which are crucial for accurately predicting the outcomes of possible interactions. This paper focuses on the prospects of building foundation world models for the upcoming generation of embodied agents and presents a novel viewpoint on the significance of causality within these. We posit that integrating causal considerations is vital to facilitate meaningful physical interactions with the world. Finally, we demystify misconceptions about causality in this context and present our outlook for future research.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05545",
        "abstract url": "https://arxiv.org/abs/2403.05545",
        "title": "Unveiling the influence of behavioural, built environment and socio-economic features on the spatial and temporal variability of bus use using explainable machine learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Understanding the variability of people's travel patterns is key to transport planning and policy-making. However, to what extent daily transit use displays geographic and temporal variabilities, and what are the contributing factors have not been fully addressed. Drawing on smart card data in Beijing, China, this study seeks to address these deficits by adopting new indices to capture the spatial and temporal variability of bus use during peak hours and investigate their associations with relevant contextual features. Using explainable machine learning, our findings reveal non-linear interaction between spatial and temporal variability and trip frequency. Furthermore, greater distance to the urban centres (>10 kilometres) is associated with increased spatial variability of bus use, while greater separation of trip origins and destinations from the subcentres reduces both spatial and temporal variability. Higher availability of bus routes is linked to higher spatial variability but lower temporal variability. Meanwhile, both lower and higher road density is associated with higher spatial variability of bus use especially in morning times. These findings indicate that different built environment features moderate the flexibility of travel time and locations. Implications are derived to inform more responsive and reliable operation and planning of transit systems.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "58 pages including supplementary material"
    },
    {
        "paper id": "2403.05546",
        "abstract url": "https://arxiv.org/abs/2403.05546",
        "title": "Unified Occupancy on a Public Transport Network through Combination of AFC and APC Data",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "In a transport network, the onboard occupancy is key for gaining insights into travelers' habits and adjusting the offer. Traditionally, operators have relied on field studies to evaluate ridership of a typical workday. However, automated fare collection (AFC) and automatic passenger counting (APC) data, which provide complete temporal coverage, are often available but underexploited. It should be noted, however, that each data source comes with its own biases: AFC data may not account for fraud, while not all vehicles are equipped with APC systems. This paper introduces the unified occupancy method, a geostatistical model to extrapolate occupancy to every course of a public transportation network by combining AFC and APC data with partial coverage. Unified occupancy completes missing APC information for courses on lines where other courses have APC measures, as well as for courses on lines where no APC data is available at all. The accuracy of this method is evaluated on real data from several public transportation networks in France.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Accepted in this version to ITSC 2023"
    },
    {
        "paper id": "2403.05547",
        "abstract url": "https://arxiv.org/abs/2403.05547",
        "title": "AI for non-programmers: Applied AI in the lectures for students without programming skills",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Applications such as ChatGPT and WOMBO Dream make it easy to inspire students without programming knowledge to use artificial intelligence (AI). Therefore, given the increasing importance of AI in all disciplines, innovative strategies are needed to educate students in AI without programming knowledge so that AI can be integrated into their study modules as a future skill. This work presents a didactic planning script for applied AI. The didactic planning script is based on the AI application pipeline and links AI concepts with study-relevant topics. These linkages open up a new solution space and promote students' interest in and understanding of the potentials and risks of AI. An example lecture series for master students in energy management shows how AI can be seamlessly integrated into discipline-specific lectures. To this end, the planning script for applied AI is adapted to fit the study programs' topic. This specific teaching scenario enables students to solve a discipline-specific task step by step using the AI application pipeline. Thus, the application of the didactic planning script for applied AI shows the practical implementation of the theoretical concepts of AI. In addition, a checklist is presented that can be used to assess whether AI can be used in the discipline-specific lecture. AI as a future skill must be learned by students based on use cases that are relevant to the course of studies. For this reason, AI education should fit seamlessly into various curricula, even if the students do not have a programming background due to their field of study.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "10 pages, 6 figures, Translated from the German of \"KI f\u00fcr Nicht-Programmierer*innen: Angewandte KI im H\u00f6rsaal f\u00fcr Studierende ohne Programmierkenntnisse\". Translated from the German of https://nbn-resolving.org/urn:nbn:de:bsz:959-opus-52866"
    },
    {
        "paper id": "2403.05548",
        "abstract url": "https://arxiv.org/abs/2403.05548",
        "title": "Monitoring the evolution of antisemitic discourse on extremist social media using BERT",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Racism and intolerance on social media contribute to a toxic online environment which may spill offline to foster hatred, and eventually lead to physical violence. That is the case with online antisemitism, the specific category of hatred considered in this study. Tracking antisemitic themes and their associated terminology over time in online discussions could help monitor the sentiments of their participants and their evolution, and possibly offer avenues for intervention that may prevent the escalation of hatred. Due to the large volume and constant evolution of online traffic, monitoring conversations manually is impractical. Instead, we propose an automated method that extracts antisemitic themes and terminology from extremist social media over time and captures their evolution. Since supervised learning would be too limited for such a task, we created an unsupervised online machine learning approach that uses large language models to assess the contextual similarity of posts. The method clusters similar posts together, dividing, and creating additional clusters over time when sub-themes emerge from existing ones or new themes appear. The antisemitic terminology used within each theme is extracted from the posts in each cluster. Our experiments show that our methodology outperforms existing baselines and demonstrates the kind of themes and sub-themes it discovers within antisemitic discourse along with their associated terminology. We believe that our approach will be useful for monitoring the evolution of all kinds of hatred beyond antisemitism on social platforms.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "11 pages; 4 figures; 4 pages"
    },
    {
        "paper id": "2402.03783",
        "abstract url": "https://arxiv.org/abs/2402.03783",
        "title": "Exploring Low-Resource Medical Image Classification with Weakly Supervised Prompt Learning",
        "rating": 0,
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Medical",
                "diagnosis",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most advances in medical image recognition supporting clinical auxiliary diagnosis meet challenges due to the low-resource situation in the medical field, where annotations are highly expensive and professional. This low-resource problem can be alleviated by leveraging the transferable representations of large-scale pre-trained vision-language models via relevant medical text prompts. However, existing pre-trained vision-language models require domain experts to carefully design the medical prompts, which greatly increases the burden on clinicians. To address this problem, we propose a weakly supervised prompt learning method MedPrompt to automatically generate medical prompts, which includes an unsupervised pre-trained vision-language model and a weakly supervised prompt learning model. The unsupervised pre-trained vision-language model utilizes the natural correlation between medical images and corresponding medical texts for pre-training, without any manual annotations. The weakly supervised prompt learning model only utilizes the classes of images in the dataset to guide the learning of the specific class vector in the prompt, while the learning of other context vectors in the prompt requires no manual annotations for guidance. To the best of our knowledge, this is the first model to automatically generate medical prompts. With these prompts, the pre-trained vision-language model can be freed from the strong expert dependency of manual annotation and manual prompt design. Experimental results show that the model using our automatically generated prompts outperforms its full-shot learning hand-crafted prompts counterparts with only a minimal number of labeled samples for few-shot learning, and reaches superior or comparable accuracy on zero-shot image classification. The proposed prompt generator is lightweight and therefore can be embedded into any network architecture.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by Pattern Recognition"
    },
    {
        "paper id": "2402.03795",
        "abstract url": "https://arxiv.org/abs/2402.03795",
        "title": "Energy-based Domain-Adaptive Segmentation with Depth Guidance",
        "rating": 0,
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent endeavors have been made to leverage self-supervised depth estimation as guidance in unsupervised domain adaptation (UDA) for semantic segmentation. Prior arts, however, overlook the discrepancy between semantic and depth features, as well as the reliability of feature fusion, thus leading to suboptimal segmentation performance. To address this issue, we propose a novel UDA framework called SMART (croSs doMain semAntic segmentation based on eneRgy esTimation) that utilizes Energy-Based Models (EBMs) to obtain task-adaptive features and achieve reliable feature fusion for semantic segmentation with self-supervised depth estimates. Our framework incorporates two novel components: energy-based feature fusion (EB2F) and energy-based reliable fusion Assessment (RFA) modules. The EB2F module produces task-adaptive semantic and depth features by explicitly measuring and reducing their discrepancy using Hopfield energy for better feature fusion. The RFA module evaluates the reliability of the feature fusion using an energy score to improve the effectiveness of depth guidance. Extensive experiments on two datasets demonstrate that our method achieves significant performance gains over prior works, validating the effectiveness of our energy-based learning approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03807",
        "abstract url": "https://arxiv.org/abs/2402.03807",
        "title": "SEABO: A Simple Search-Based Method for Offline Imitation Learning",
        "rating": 0.0,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Offline reinforcement learning (RL) has attracted much attention due to its ability in learning from static offline datasets and eliminating the need of interacting with the environment. Nevertheless, the success of offline RL relies heavily on the offline transitions annotated with reward labels. In practice, we often need to hand-craft the reward function, which is sometimes difficult, labor-intensive, or inefficient. To tackle this challenge, we set our focus on the offline imitation learning (IL) setting, and aim at getting a reward function based on the expert data and unlabeled data. To that end, we propose a simple yet effective search-based offline IL method, tagged SEABO. SEABO allocates a larger reward to the transition that is close to its closest neighbor in the expert demonstration, and a smaller reward otherwise, all in an unsupervised learning manner. Experimental results on a variety of D4RL datasets indicate that SEABO can achieve competitive performance to offline RL algorithms with ground-truth rewards, given only a single expert trajectory, and can outperform prior reward learning and offline IL methods across many tasks. Moreover, we demonstrate that SEABO also works well if the expert demonstrations contain only observations. Our code is publicly available at https://github.com/dmksjfl/SEABO.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "To appear in ICLR2024"
    },
    {
        "paper id": "2402.03843",
        "abstract url": "https://arxiv.org/abs/2402.03843",
        "title": "A new method for optical steel rope non-destructive damage detection",
        "rating": 0,
        "keywords": [
            [
                "RGBD",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel algorithm for non-destructive damage detection for steel ropes in high-altitude environments (aerial ropeway). The algorithm comprises two key components: First, a segmentation model named RGBD-UNet is designed to accurately extract steel ropes from complex backgrounds. This model is equipped with the capability to process and combine color and depth information through the proposed CMA module. Second, a detection model named VovNetV3.5 is developed to differentiate between normal and abnormal steel ropes. It integrates the VovNet architecture with a DBB module to enhance performance. Besides, a novel background augmentation method is proposed to enhance the generalization ability of the segmentation model. Datasets containing images of steel ropes in different scenarios are created for the training and testing of both the segmentation and detection models. Experiments demonstrate a significant improvement over baseline models. On the proposed dataset, the highest accuracy achieved by the detection model reached 0.975, and the maximum F-measure achieved by the segmentation model reached 0.948.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03867",
        "abstract url": "https://arxiv.org/abs/2402.03867",
        "title": "Binaural sound source localization using a hybrid time and frequency domain model",
        "rating": 0,
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "This paper introduces a new approach to sound source localization using head-related transfer function (HRTF) characteristics, which enable precise full-sphere localization from raw data. While previous research focused primarily on using extensive microphone arrays in the frontal plane, this arrangement often encountered limitations in accuracy and robustness when dealing with smaller microphone arrays. Our model proposes using both time and frequency domain for sound source localization while utilizing Deep Learning (DL) approach. The performance of our proposed model, surpasses the current state-of-the-art results. Specifically, it boasts an average angular error of $0.24 degrees and an average Euclidean distance of 0.01 meters, while the known state-of-the-art gives average angular error of 19.07 degrees and average Euclidean distance of 1.08 meters. This level of accuracy is of paramount importance for a wide range of applications, including robotics, virtual reality, and aiding individuals with cochlear implants (CI).",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03966",
        "abstract url": "https://arxiv.org/abs/2402.03966",
        "title": "On dimensionality of feature vectors in MPNNs",
        "rating": 0.0,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We revisit the classical result of Morris et al.~(AAAI'19) that message-passing graphs neural networks (MPNNs) are equal in their distinguishing power to the Weisfeiler--Leman (WL) isomorphism test. Morris et al.~show their simulation result with ReLU activation function and $O(n)$-dimensional feature vectors, where $n$ is the number of nodes of the graph. By introducing randomness into the architecture, Aamand et al.~(NeurIPS'22) were able to improve this bound to $O(\\log n)$-dimensional feature vectors, again for ReLU activation, although at the expense of guaranteeing perfect simulation only with high probability. Recently, Amir et al.~(NeurIPS'23) have shown that for any non-polynomial analytic activation function, it is enough to use just 1-dimensional feature vectors. In this paper, we give a simple proof of the result of Amit et al.~and provide an independent experimental validation of it.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, 2 figures. Changes to the previous version: added reference to Amir et al.~(NeurIPS'23)"
    },
    {
        "paper id": "2402.03989",
        "abstract url": "https://arxiv.org/abs/2402.03989",
        "title": "YOLOPoint Joint Keypoint and Object Detection",
        "rating": 0,
        "keywords": [
            [
                "vehicle",
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Intelligent vehicles of the future must be capable of understanding and navigating safely through their surroundings. Camera-based vehicle systems can use keypoints as well as objects as low- and high-level landmarks for GNSS-independent SLAM and visual odometry. To this end we propose YOLOPoint, a convolutional neural network model that simultaneously detects keypoints and objects in an image by combining YOLOv5 and SuperPoint to create a single forward-pass network that is both real-time capable and accurate. By using a shared backbone and a light-weight network structure, YOLOPoint is able to perform competitively on both the HPatches and KITTI benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 5 figures"
    },
    {
        "paper id": "2402.04013",
        "abstract url": "https://arxiv.org/abs/2402.04013",
        "title": "Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and Defenses",
        "rating": 0,
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Model Inversion (MI) attacks aim to disclose private information about the training data by abusing access to the pre-trained models. These attacks enable adversaries to reconstruct high-fidelity data that closely aligns with the private training data, which has raised significant privacy concerns. Despite the rapid advances in the field, we lack a comprehensive overview of existing MI attacks and defenses. To fill this gap, this paper thoroughly investigates this field and presents a holistic survey. Firstly, our work briefly reviews the traditional MI on machine learning scenarios. We then elaborately analyze and compare numerous recent attacks and defenses on \\textbf{D}eep \\textbf{N}eural \\textbf{N}etworks (DNNs) across multiple modalities and learning tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04064",
        "abstract url": "https://arxiv.org/abs/2402.04064",
        "title": "Multi-class Road Defect Detection and Segmentation using Spatial and Channel-wise Attention for Autonomous Road Repairing",
        "rating": 0,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Road pavement detection and segmentation are critical for developing autonomous road repair systems. However, developing an instance segmentation method that simultaneously performs multi-class defect detection and segmentation is challenging due to the textural simplicity of road pavement image, the diversity of defect geometries, and the morphological ambiguity between classes. We propose a novel end-to-end method for multi-class road defect detection and segmentation. The proposed method comprises multiple spatial and channel-wise attention blocks available to learn global representations across spatial and channel-wise dimensions. Through these attention blocks, more globally generalised representations of morphological information (spatial characteristics) of road defects and colour and depth information of images can be learned. To demonstrate the effectiveness of our framework, we conducted various ablation studies and comparisons with prior methods on a newly collected dataset annotated with nine road defect classes. The experiments show that our proposed method outperforms existing state-of-the-art methods for multi-class road defect detection and segmentation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to the ICRA 2024"
    },
    {
        "paper id": "2402.04066",
        "abstract url": "https://arxiv.org/abs/2402.04066",
        "title": "On the Modelling of Ship Wakes in S-Band SAR Images and an Application to Ship Identification",
        "rating": 0,
        "keywords": [
            [
                "Radar"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "We present a novel ship wake simulation system for generating S-band Synthetic Aperture Radar (SAR) images, and demonstrate the use of such imagery for the classification of ships based on their wake signatures via a deep learning approach. Ship wakes are modeled through the linear superposition of wind-induced sea elevation and the Kelvin wakes model of a moving ship. Our SAR imaging simulation takes into account frequency-dependent radar parameters, i.e., the complex dielectric constant ($\\varepsilon$) and the relaxation rate ($\u03bc$) of seawater. The former was determined through the Debye model while the latter was estimated for S-band SAR based on pre-existing values for the L, C, and X-bands. The results show good agreement between simulated and real imagery upon visual inspection. The results of implementing different training strategies are also reported, showcasing a notable improvement in accuracy of classifier achieved by integrating real and simulated SAR images during the training.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04273",
        "abstract url": "https://arxiv.org/abs/2402.04273",
        "title": "Breaking Data Silos: Cross-Domain Learning for Multi-Agent Perception from Independent Private Sources",
        "rating": 0,
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The diverse agents in multi-agent perception systems may be from different companies. Each company might use the identical classic neural network architecture based encoder for feature extraction. However, the data source to train the various agents is independent and private in each company, leading to the Distribution Gap of different private data for training distinct agents in multi-agent perception system. The data silos by the above Distribution Gap could result in a significant performance decline in multi-agent perception. In this paper, we thoroughly examine the impact of the distribution gap on existing multi-agent perception systems. To break the data silos, we introduce the Feature Distribution-aware Aggregation (FDA) framework for cross-domain learning to mitigate the above Distribution Gap in multi-agent perception. FDA comprises two key components: Learnable Feature Compensation Module and Distribution-aware Statistical Consistency Module, both aimed at enhancing intermediate features to minimize the distribution gap among multi-agent features. Intensive experiments on the public OPV2V and V2XSet datasets underscore FDA's effectiveness in point cloud-based 3D object detection, presenting it as an invaluable augmentation to existing multi-agent perception systems.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by the 2024 IEEE International Conference on Robotics and Automation (ICRA)"
    },
    {
        "paper id": "2402.04297",
        "abstract url": "https://arxiv.org/abs/2402.04297",
        "title": "Road Surface Defect Detection -- From Image-based to Non-image-based: A Survey",
        "rating": 0,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Ensuring traffic safety is crucial, which necessitates the detection and prevention of road surface defects. As a result, there has been a growing interest in the literature on the subject, leading to the development of various road surface defect detection methods. The methods for detecting road defects can be categorised in various ways depending on the input data types or training methodologies. The predominant approach involves image-based methods, which analyse pixel intensities and surface textures to identify defects. Despite their popularity, image-based methods share the distinct limitation of vulnerability to weather and lighting changes. To address this issue, researchers have explored the use of additional sensors, such as laser scanners or LiDARs, providing explicit depth information to enable the detection of defects in terms of scale and volume. However, the exploration of data beyond images has not been sufficiently investigated. In this survey paper, we provide a comprehensive review of road surface defect detection studies, categorising them based on input data types and methodologies used. Additionally, we review recently proposed non-image-based methods and discuss several challenges and open problems associated with these techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Survey papers"
    },
    {
        "paper id": "2402.04324",
        "abstract url": "https://arxiv.org/abs/2402.04324",
        "title": "ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation",
        "rating": 0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image-to-video (I2V) generation aims to use the initial frame (alongside a text prompt) to create a video sequence. A grand challenge in I2V generation is to maintain visual consistency throughout the video: existing methods often struggle to preserve the integrity of the subject, background, and style from the first frame, as well as ensure a fluid and logical progression within the video narrative. To mitigate these issues, we propose ConsistI2V, a diffusion-based method to enhance visual consistency for I2V generation. Specifically, we introduce (1) spatiotemporal attention over the first frame to maintain spatial and motion consistency, (2) noise initialization from the low-frequency band of the first frame to enhance layout consistency. These two approaches enable ConsistI2V to generate highly consistent videos. We also extend the proposed approaches to show their potential to improve consistency in auto-regressive long video generation and camera motion control. To verify the effectiveness of our method, we propose I2V-Bench, a comprehensive evaluation benchmark for I2V generation. Our automatic and human evaluation results demonstrate the superiority of ConsistI2V over existing methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://tiger-ai-lab.github.io/ConsistI2V/"
    },
    {
        "paper id": "2402.04356",
        "abstract url": "https://arxiv.org/abs/2402.04356",
        "title": "Bidirectional Autoregressive Diffusion Model for Dance Generation",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Dance serves as a powerful medium for expressing human emotions, but the lifelike generation of dance is still a considerable challenge. Recently, diffusion models have showcased remarkable generative abilities across various domains. They hold promise for human motion generation due to their adaptable many-to-many nature. Nonetheless, current diffusion-based motion generation models often create entire motion sequences directly and unidirectionally, lacking focus on the motion with local and bidirectional enhancement. When choreographing high-quality dance movements, people need to take into account not only the musical context but also the nearby music-aligned dance motions. To authentically capture human behavior, we propose a Bidirectional Autoregressive Diffusion Model (BADM) for music-to-dance generation, where a bidirectional encoder is built to enforce that the generated dance is harmonious in both the forward and backward directions. To make the generated dance motion smoother, a local information decoder is built for local motion enhancement. The proposed framework is able to generate new motions based on the input conditions and nearby motions, which foresees individual motion slices iteratively and consolidates all predictions. To further refine the synchronicity between the generated dance and the beat, the beat information is incorporated as an input to generate better music-aligned dance movements. Experimental results demonstrate that the proposed model achieves state-of-the-art performance compared to existing unidirectional approaches on the prominent benchmark for music-to-dance generation.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04379",
        "abstract url": "https://arxiv.org/abs/2402.04379",
        "title": "Fine-Tuned Language Models Generate Stable Inorganic Materials as Text",
        "rating": 0.0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "We propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints on atom positions and charges. Using energy above hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text prompting's inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models' ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR 2024. Code available at: https://github.com/facebookresearch/crystal-llm"
    },
    {
        "paper id": "2402.04408",
        "abstract url": "https://arxiv.org/abs/2402.04408",
        "title": "Detection Transformer for Teeth Detection, Segmentation, and Numbering in Oral Rare Diseases: Focus on Data Augmentation and Inpainting Techniques",
        "rating": 0,
        "keywords": [
            [
                "diffusion",
                "Inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we focused on deep learning image processing in the context of oral rare diseases, which pose challenges due to limited data availability. A crucial step involves teeth detection, segmentation and numbering in panoramic radiographs. To this end, we used a dataset consisting of 156 panoramic radiographs from individuals with rare oral diseases and labeled by experts. We trained the Detection Transformer (DETR) neural network for teeth detection, segmentation, and numbering the 52 teeth classes. In addition, we used data augmentation techniques, including geometric transformations. Finally, we generated new panoramic images using inpainting techniques with stable diffusion, by removing teeth from a panoramic radiograph and integrating teeth into it. The results showed a mAP exceeding 0,69 for DETR without data augmentation. The mAP was improved to 0,82 when data augmentation techniques are used. Furthermore, we observed promising performances when using new panoramic radiographs generated with inpainting technique, with mAP of 0,76.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04504",
        "abstract url": "https://arxiv.org/abs/2402.04504",
        "title": "Text2Street: Controllable Text-to-image Generation for Street Views",
        "rating": 0,
        "keywords": [
            [
                "diffusion",
                "Text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image generation has made remarkable progress with the emergence of diffusion models. However, it is still a difficult task to generate images for street views based on text, mainly because the road topology of street scenes is complex, the traffic status is diverse and the weather condition is various, which makes conventional text-to-image models difficult to deal with. To address these challenges, we propose a novel controllable text-to-image framework, named \\textbf{Text2Street}. In the framework, we first introduce the lane-aware road topology generator, which achieves text-to-map generation with the accurate road structure and lane lines armed with the counting adapter, realizing the controllable road topology generation. Then, the position-based object layout generator is proposed to obtain text-to-layout generation through an object-level bounding box diffusion strategy, realizing the controllable traffic object layout generation. Finally, the multiple control image generator is designed to integrate the road topology, object layout and weather description to realize controllable street-view image generation. Extensive experiments show that the proposed approach achieves controllable street-view text-to-image generation and validates the effectiveness of the Text2Street framework for street views.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04541",
        "abstract url": "https://arxiv.org/abs/2402.04541",
        "title": "BRI3L: A Brightness Illusion Image Dataset for Identification and Localization of Regions of Illusory Perception",
        "rating": 0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual illusions play a significant role in understanding visual perception. Current methods in understanding and evaluating visual illusions are mostly deterministic filtering based approach and they evaluate on a handful of visual illusions, and the conclusions therefore, are not generic. To this end, we generate a large-scale dataset of 22,366 images (BRI3L: BRightness Illusion Image dataset for Identification and Localization of illusory perception) of the five types of brightness illusions and benchmark the dataset using data-driven neural network based approaches. The dataset contains label information - (1) whether a particular image is illusory/nonillusory, (2) the segmentation mask of the illusory region of the image. Hence, both the classification and segmentation task can be evaluated using this dataset. We follow the standard psychophysical experiments involving human subjects to validate the dataset. To the best of our knowledge, this is the first attempt to develop a dataset of visual illusions and benchmark using data-driven approach for illusion classification and localization. We consider five well-studied types of brightness illusions: 1) Hermann grid, 2) Simultaneous Brightness Contrast, 3) White illusion, 4) Grid illusion, and 5) Induced Grating illusion. Benchmarking on the dataset achieves 99.56% accuracy in illusion identification and 84.37% pixel accuracy in illusion localization. The application of deep learning model, it is shown, also generalizes over unseen brightness illusions like brightness assimilation to contrast transitions. We also test the ability of state-of-theart diffusion models to generate brightness illusions. We have provided all the code, dataset, instructions etc in the github repo: https://github.com/aniket004/BRI3L",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08806",
        "abstract url": "https://arxiv.org/abs/2403.08806",
        "title": "Adversarially Robust Deepfake Detection via Adversarial Feature Similarity Learning",
        "rating": 0,
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deepfake technology has raised concerns about the authenticity of digital content, necessitating the development of effective detection methods. However, the widespread availability of deepfakes has given rise to a new challenge in the form of adversarial attacks. Adversaries can manipulate deepfake videos with small, imperceptible perturbations that can deceive the detection models into producing incorrect outputs. To tackle this critical issue, we introduce Adversarial Feature Similarity Learning (AFSL), which integrates three fundamental deep feature learning paradigms. By optimizing the similarity between samples and weight vectors, our approach aims to distinguish between real and fake instances. Additionally, we aim to maximize the similarity between both adversarially perturbed examples and unperturbed examples, regardless of their real or fake nature. Moreover, we introduce a regularization technique that maximizes the dissimilarity between real and fake samples, ensuring a clear separation between these two categories. With extensive experiments on popular deepfake datasets, including FaceForensics++, FaceShifter, and DeeperForensics, the proposed method outperforms other standard adversarial training-based defense methods significantly. This further demonstrates the effectiveness of our approach to protecting deepfake detectors from adversarial attacks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "MMM 2024 Accepted"
    },
    {
        "paper id": "2402.03720",
        "abstract url": "https://arxiv.org/abs/2402.03720",
        "title": "Similarity-based Neighbor Selection for Graph LLMs",
        "rating": -0.5,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Text-attributed graphs (TAGs) present unique challenges for direct processing by Language Learning Models (LLMs), yet their extensive commonsense knowledge and robust reasoning capabilities offer great promise for node classification in TAGs. Prior research in this field has grappled with issues such as over-squashing, heterophily, and ineffective graph information integration, further compounded by inconsistencies in dataset partitioning and underutilization of advanced LLMs. To address these challenges, we introduce Similarity-based Neighbor Selection (SNS). Using SimCSE and advanced neighbor selection techniques, SNS effectively improves the quality of selected neighbors, thereby improving graph representation and alleviating issues like over-squashing and heterophily. Besides, as an inductive and training-free approach, SNS demonstrates superior generalization and scalability over traditional GNN methods. Our comprehensive experiments, adhering to standard dataset partitioning practices, demonstrate that SNS, through simple prompt interactions with LLMs, consistently outperforms vanilla GNNs and achieves state-of-the-art results on datasets like PubMed in node classification, showcasing LLMs' potential in graph structure understanding. Our research further underscores the significance of graph structure integration in LLM applications and identifies key factors for their success in node classification. Code is available at https://github.com/ruili33/SNS.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03732",
        "abstract url": "https://arxiv.org/abs/2402.03732",
        "title": "Deep Outdated Fact Detection in Knowledge Graphs",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Knowledge graphs (KGs) have garnered significant attention for their vast potential across diverse domains. However, the issue of outdated facts poses a challenge to KGs, affecting their overall quality as real-world information evolves. Existing solutions for outdated fact detection often rely on manual recognition. In response, this paper presents DEAN (Deep outdatEd fAct detectioN), a novel deep learning-based framework designed to identify outdated facts within KGs. DEAN distinguishes itself by capturing implicit structural information among facts through comprehensive modeling of both entities and relations. To effectively uncover latent out-of-date information, DEAN employs a contrastive approach based on a pre-defined Relations-to-Nodes (R2N) graph, weighted by the number of entities. Experimental results demonstrate the effectiveness and superiority of DEAN over state-of-the-art baseline methods.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2402.03741",
        "abstract url": "https://arxiv.org/abs/2402.03741",
        "title": "SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems",
        "rating": -0.5,
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in multi-agent reinforcement learning (MARL) have opened up vast application prospects, including swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent researches reveal that an attacker can rapidly exploit the victim's vulnerabilities and generate adversarial policies, leading to the victim's failure in specific tasks. For example, reducing the winning rate of a superhuman-level Go AI to around 20%. They predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation. In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY), which incorporates the concept of constructing multiple subgames to mitigate the impact of partial observability and suggests the sharing of transitions among subpolicies to improve the exploitative ability of attackers. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under three typical partial observability limitations. Visualization results indicate that adversarial policies induce significantly different activations of the victims' policy networks. Furthermore, we evaluate three potential defenses aimed at exploring ways to mitigate security threats posed by adversarial policies, providing constructive recommendations for deploying MARL in competitive environments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03747",
        "abstract url": "https://arxiv.org/abs/2402.03747",
        "title": "An invariance constrained deep learning network for PDE discovery",
        "rating": -0.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The discovery of partial differential equations (PDEs) from datasets has attracted increased attention. However, the discovery of governing equations from sparse data with high noise is still very challenging due to the difficulty of derivatives computation and the disturbance of noise. Moreover, the selection principles for the candidate library to meet physical laws need to be further studied. The invariance is one of the fundamental laws for governing equations. In this study, we propose an invariance constrained deep learning network (ICNet) for the discovery of PDEs. Considering that temporal and spatial translation invariance (Galilean invariance) is a fundamental property of physical laws, we filter the candidates that cannot meet the requirement of the Galilean transformations. Subsequently, we embedded the fixed and possible terms into the loss function of neural network, significantly countering the effect of sparse data with high noise. Then, by filtering out redundant terms without fixing learnable parameters during the training process, the governing equations discovered by the ICNet method can effectively approximate the real governing equations. We select the 2D Burgers equation, the equation of 2D channel flow over an obstacle, and the equation of 3D intracranial aneurysm as examples to verify the superiority of the ICNet for fluid mechanics. Furthermore, we extend similar invariance methods to the discovery of wave equation (Lorentz Invariance) and verify it through Single and Coupled Klein-Gordon equation. The results show that the ICNet method with physical constraints exhibits excellent performance in governing equations discovery from sparse and noisy data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03750",
        "abstract url": "https://arxiv.org/abs/2402.03750",
        "title": "Digital Twin Mobility Profiling: A Spatio-Temporal Graph Learning Approach",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the arrival of the big data era, mobility profiling has become a viable method of utilizing enormous amounts of mobility data to create an intelligent transportation system. Mobility profiling can extract potential patterns in urban traffic from mobility data and is critical for a variety of traffic-related applications. However, due to the high level of complexity and the huge amount of data, mobility profiling faces huge challenges. Digital Twin (DT) technology paves the way for cost-effective and performance-optimised management by digitally creating a virtual representation of the network to simulate its behaviour. In order to capture the complex spatio-temporal features in traffic scenario, we construct alignment diagrams to assist in completing the spatio-temporal correlation representation and design dilated alignment convolution network (DACN) to learn the fine-grained correlations, i.e., spatio-temporal interactions. We propose a digital twin mobility profiling (DTMP) framework to learn node profiles on a mobility network DT model. Extensive experiments have been conducted upon three real-world datasets. Experimental results demonstrate the effectiveness of DTMP.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 7 figures"
    },
    {
        "paper id": "2402.03770",
        "abstract url": "https://arxiv.org/abs/2402.03770",
        "title": "Fed-CVLC: Compressing Federated Learning Communications with Variable-Length Codes",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In Federated Learning (FL) paradigm, a parameter server (PS) concurrently communicates with distributed participating clients for model collection, update aggregation, and model distribution over multiple rounds, without touching private data owned by individual clients. FL is appealing in preserving data privacy; yet the communication between the PS and scattered clients can be a severe bottleneck. Model compression algorithms, such as quantization and sparsification, have been suggested but they generally assume a fixed code length, which does not reflect the heterogeneity and variability of model updates. In this paper, through both analysis and experiments, we show strong evidences that variable-length is beneficial for compression in FL. We accordingly present Fed-CVLC (Federated Learning Compression with Variable-Length Codes), which fine-tunes the code length in response of the dynamics of model updates. We develop optimal tuning strategy that minimizes the loss function (equivalent to maximizing the model utility) subject to the budget for communication. We further demonstrate that Fed-CVLC is indeed a general compression design that bridges quantization and sparsification, with greater flexibility. Extensive experiments have been conducted with public datasets to demonstrate that Fed-CVLC remarkably outperforms state-of-the-art baselines, improving model utility by 1.50%-5.44%, or shrinking communication traffic by 16.67%-41.61%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "To appear in 2024 IEEE International Conference on Computer Communications(INFOCOM 2024)"
    },
    {
        "paper id": "2402.03785",
        "abstract url": "https://arxiv.org/abs/2402.03785",
        "title": "Weakly Supervised Anomaly Detection via Knowledge-Data Alignment",
        "rating": -0.5,
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Anomaly detection (AD) plays a pivotal role in numerous web-based applications, including malware detection, anti-money laundering, device failure detection, and network fault analysis. Most methods, which rely on unsupervised learning, are hard to reach satisfactory detection accuracy due to the lack of labels. Weakly Supervised Anomaly Detection (WSAD) has been introduced with a limited number of labeled anomaly samples to enhance model performance. Nevertheless, it is still challenging for models, trained on an inadequate amount of labeled data, to generalize to unseen anomalies. In this paper, we introduce a novel framework Knowledge-Data Alignment (KDAlign) to integrate rule knowledge, typically summarized by human experts, to supplement the limited labeled data. Specifically, we transpose these rules into the knowledge space and subsequently recast the incorporation of knowledge as the alignment of knowledge and data. To facilitate this alignment, we employ the Optimal Transport (OT) technique. We then incorporate the OT distance as an additional loss term to the original objective function of WSAD methodologies. Comprehensive experimental results on five real-world datasets demonstrate that our proposed KDAlign framework markedly surpasses its state-of-the-art counterparts, achieving superior performance across various anomaly types.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by WWW 2024"
    },
    {
        "paper id": "2402.03808",
        "abstract url": "https://arxiv.org/abs/2402.03808",
        "title": "SDEMG: Score-based Diffusion Model for Surface Electromyographic Signal Denoising",
        "rating": -0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Surface electromyography (sEMG) recordings can be influenced by electrocardiogram (ECG) signals when the muscle being monitored is close to the heart. Several existing methods use signal-processing-based approaches, such as high-pass filter and template subtraction, while some derive mapping functions to restore clean sEMG signals from noisy sEMG (sEMG with ECG interference). Recently, the score-based diffusion model, a renowned generative model, has been introduced to generate high-quality and accurate samples with noisy input data. In this study, we proposed a novel approach, termed SDEMG, as a score-based diffusion model for sEMG signal denoising. To evaluate the proposed SDEMG approach, we conduct experiments to reduce noise in sEMG signals, employing data from an openly accessible source, the Non-Invasive Adaptive Prosthetics database, along with ECG signals from the MIT-BIH Normal Sinus Rhythm Database. The experiment result indicates that SDEMG outperformed comparative methods and produced high-quality sEMG samples. The source code of SDEMG the framework is available at: https://github.com/tonyliu0910/SDEMG",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This paper is accepted by ICASSP 2024"
    },
    {
        "paper id": "2402.03814",
        "abstract url": "https://arxiv.org/abs/2402.03814",
        "title": "Masked Graph Autoencoder with Non-discrete Bandwidths",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Masked graph autoencoders have emerged as a powerful graph self-supervised learning method that has yet to be fully explored. In this paper, we unveil that the existing discrete edge masking and binary link reconstruction strategies are insufficient to learn topologically informative representations, from the perspective of message propagation on graph neural networks. These limitations include blocking message flows, vulnerability to over-smoothness, and suboptimal neighborhood discriminability. Inspired by these understandings, we explore non-discrete edge masks, which are sampled from a continuous and dispersive probability distribution instead of the discrete Bernoulli distribution. These masks restrict the amount of output messages for each edge, referred to as \"bandwidths\". We propose a novel, informative, and effective topological masked graph autoencoder using bandwidth masking and a layer-wise bandwidth prediction objective. We demonstrate its powerful graph topological learning ability both theoretically and empirically. Our proposed framework outperforms representative baselines in both self-supervised link prediction (improving the discrete edge reconstructors by at most 20%) and node classification on numerous datasets, solely with a structure-learning pretext. Our implementation is available at https://github.com/Newiz430/Bandana.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Full version (17 pages, 8 figures, 12 tables), accepted by TheWebConf 2024 (WWW 2024)"
    },
    {
        "paper id": "2402.03815",
        "abstract url": "https://arxiv.org/abs/2402.03815",
        "title": "Expediting In-Network Federated Learning by Voting-Based Consensus Model Compression",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, federated learning (FL) has gained momentum because of its capability in preserving data privacy. To conduct model training by FL, multiple clients exchange model updates with a parameter server via Internet. To accelerate the communication speed, it has been explored to deploy a programmable switch (PS) in lieu of the parameter server to coordinate clients. The challenge to deploy the PS in FL lies in its scarce memory space, prohibiting running memory consuming aggregation algorithms on the PS. To overcome this challenge, we propose Federated Learning in-network Aggregation with Compression (FediAC) algorithm, consisting of two phases: client voting and model aggregating. In the former phase, clients report their significant model update indices to the PS to estimate global significant model updates. In the latter phase, clients upload global significant model updates to the PS for aggregation. FediAC consumes much less memory space and communication traffic than existing works because the first phase can guarantee consensus compression across clients. The PS easily aligns model update indices to swiftly complete aggregation in the second phase. Finally, we conduct extensive experiments by using public datasets to demonstrate that FediAC remarkably surpasses the state-of-the-art baselines in terms of model accuracy and communication traffic.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "To appear in 2024 IEEE International Conference on Computer Communications(INFOCOM 2024)"
    },
    {
        "paper id": "2402.03818",
        "abstract url": "https://arxiv.org/abs/2402.03818",
        "title": "Asymptotic generalization error of a single-layer graph convolutional network",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "While graph convolutional networks show great practical promises, the theoretical understanding of their generalization properties as a function of the number of samples is still in its infancy compared to the more broadly studied case of supervised fully connected neural networks. In this article, we predict the performances of a single-layer graph convolutional network (GCN) trained on data produced by attributed stochastic block models (SBMs) in the high-dimensional limit. Previously, only ridge regression on contextual-SBM (CSBM) has been considered in Shi et al. 2022; we generalize the analysis to arbitrary convex loss and regularization for the CSBM and add the analysis for another data model, the neural-prior SBM. We also study the high signal-to-noise ratio limit, detail the convergence rates of the GCN and show that, while consistent, it does not reach the Bayes-optimal rate for any of the considered cases.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03824",
        "abstract url": "https://arxiv.org/abs/2402.03824",
        "title": "A call for embodied AI",
        "rating": -0.5,
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We propose Embodied AI as the next fundamental step in the pursuit of Artificial General Intelligence, juxtaposing it against current AI advancements, particularly Large Language Models. We traverse the evolution of the embodiment concept across diverse fields - philosophy, psychology, neuroscience, and robotics - to highlight how EAI distinguishes itself from the classical paradigm of static learning. By broadening the scope of Embodied AI, we introduce a theoretical framework based on cognitive architectures, emphasizing perception, action, memory, and learning as essential components of an embodied agent. This framework is aligned with Friston's active inference principle, offering a comprehensive approach to EAI development. Despite the progress made in the field of AI, substantial challenges, such as the formulation of a novel AI learning theory and the innovation of advanced hardware, persist. Our discussion lays down a foundational guideline for future Embodied AI research. Highlighting the importance of creating Embodied AI agents capable of seamless communication, collaboration, and coexistence with humans and other intelligent entities within real-world environments, we aim to steer the AI community towards addressing the multifaceted challenges and seizing the opportunities that lie ahead in the quest for AGI.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Submitted to ICML 2024 Position paper track"
    },
    {
        "paper id": "2402.03845",
        "abstract url": "https://arxiv.org/abs/2402.03845",
        "title": "On gauge freedom, conservativity and intrinsic dimensionality estimation in diffusion models",
        "rating": -0.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models are generative models that have recently demonstrated impressive performances in terms of sampling quality and density estimation in high dimensions. They rely on a forward continuous diffusion process and a backward continuous denoising process, which can be described by a time-dependent vector field and is used as a generative model. In the original formulation of the diffusion model, this vector field is assumed to be the score function (i.e. it is the gradient of the log-probability at a given time in the diffusion process). Curiously, on the practical side, most studies on diffusion models implement this vector field as a neural network function and do not constrain it be the gradient of some energy function (that is, most studies do not constrain the vector field to be conservative). Even though some studies investigated empirically whether such a constraint will lead to a performance gain, they lead to contradicting results and failed to provide analytical results. Here, we provide three analytical results regarding the extent of the modeling freedom of this vector field. {Firstly, we propose a novel decomposition of vector fields into a conservative component and an orthogonal component which satisfies a given (gauge) freedom. Secondly, from this orthogonal decomposition, we show that exact density estimation and exact sampling is achieved when the conservative component is exactly equals to the true score and therefore conservativity is neither necessary nor sufficient to obtain exact density estimation and exact sampling. Finally, we show that when it comes to inferring local information of the data manifold, constraining the vector field to be conservative is desirable.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03905",
        "abstract url": "https://arxiv.org/abs/2402.03905",
        "title": "Employee Turnover Analysis Using Machine Learning Algorithms",
        "rating": -0.5,
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Employee's knowledge is an organization asset. Turnover may impose apparent and hidden costs and irreparable damages. To overcome and mitigate this risk, employee's condition should be monitored. Due to high complexity of analyzing well-being features, employee's turnover predicting can be delegated to machine learning techniques. In this paper, we discuss employee's attrition rate. Three different supervised learning algorithms comprising AdaBoost, SVM and RandomForest are used to benchmark employee attrition accuracy. Attained models can help out at establishing predictive analytics.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "6 pages, 11 feagures, 2 tables"
    },
    {
        "paper id": "2402.03908",
        "abstract url": "https://arxiv.org/abs/2402.03908",
        "title": "EscherNet: A Generative Model for Scalable View Synthesis",
        "rating": -0.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "Synthesis"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We introduce EscherNet, a multi-view conditioned diffusion model for view synthesis. EscherNet learns implicit and generative 3D representations coupled with a specialised camera positional encoding, allowing precise and continuous relative control of the camera transformation between an arbitrary number of reference and target views. EscherNet offers exceptional generality, flexibility, and scalability in view synthesis -- it can generate more than 100 consistent target views simultaneously on a single consumer-grade GPU, despite being trained with a fixed number of 3 reference views to 3 target views. As a result, EscherNet not only addresses zero-shot novel view synthesis, but also naturally unifies single- and multi-image 3D reconstruction, combining these diverse tasks into a single, cohesive framework. Our extensive experiments demonstrate that EscherNet achieves state-of-the-art performance in multiple benchmarks, even when compared to methods specifically tailored for each individual problem. This remarkable versatility opens up new directions for designing scalable neural architectures for 3D vision. Project page: https://kxhit.github.io/EscherNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR2024 Project Page: https://kxhit.github.io/EscherNet"
    },
    {
        "paper id": "2402.04010",
        "abstract url": "https://arxiv.org/abs/2402.04010",
        "title": "Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously",
        "rating": -0.5,
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in real-world applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04062",
        "abstract url": "https://arxiv.org/abs/2402.04062",
        "title": "Link Prediction with Relational Hypergraphs",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Link prediction with knowledge graphs has been thoroughly studied in graph machine learning, leading to a rich landscape of graph neural network architectures with successful applications. Nonetheless, it remains challenging to transfer the success of these architectures to link prediction with relational hypergraphs. The presence of relational hyperedges makes link prediction a task between $k$ nodes for varying choices of $k$, which is substantially harder than link prediction with knowledge graphs, where every relation is binary ($k=2$). In this paper, we propose two frameworks for link prediction with relational hypergraphs and conduct a thorough analysis of the expressive power of the resulting model architectures via corresponding relational Weisfeiler-Leman algorithms, and also via some natural logical formalisms. Through extensive empirical analysis, we validate the power of the proposed model architectures on various relational hypergraph benchmarks. The resulting model architectures substantially outperform every baseline for inductive link prediction, and lead to state-of-the-art results for transductive link prediction. Our study therefore unlocks applications of graph neural networks to fully relational structures.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04080",
        "abstract url": "https://arxiv.org/abs/2402.04080",
        "title": "Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning",
        "rating": -0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents advanced techniques of training diffusion policies for offline reinforcement learning (RL). At the core is a mean-reverting stochastic differential equation (SDE) that transfers a complex action distribution into a standard Gaussian and then samples actions conditioned on the environment state with a corresponding reverse-time SDE, like a typical diffusion policy. We show that such an SDE has a solution that we can use to calculate the log probability of the policy, yielding an entropy regularizer that improves the exploration of offline datasets. To mitigate the impact of inaccurate value functions from out-of-distribution data points, we further propose to learn the lower confidence bound of Q-ensembles for more robust policy improvement. By combining the entropy-regularized diffusion policy with Q-ensembles in offline RL, our method achieves state-of-the-art performance on most tasks in D4RL benchmarks. Code is available at \\href{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04081",
        "abstract url": "https://arxiv.org/abs/2402.04081",
        "title": "Improved Generalization of Weight Space Networks via Augmentations",
        "rating": -0.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning in deep weight spaces (DWS), where neural networks process the weights of other neural networks, is an emerging research direction, with applications to 2D and 3D neural fields (INRs, NeRFs), as well as making inferences about other types of neural networks. Unfortunately, weight space models tend to suffer from substantial overfitting. We empirically analyze the reasons for this overfitting and find that a key reason is the lack of diversity in DWS datasets. While a given object can be represented by many different weight configurations, typical INR training sets fail to capture variability across INRs that represent the same object. To address this, we explore strategies for data augmentation in weight spaces and propose a MixUp method adapted for weight spaces. We demonstrate the effectiveness of these methods in two setups. In classification, they improve performance similarly to having up to 10 times more data. In self-supervised contrastive learning, they yield substantial 5-10% gains in downstream classification.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2402.04108",
        "abstract url": "https://arxiv.org/abs/2402.04108",
        "title": "Hierarchical Delay Attribution Classification using Unstructured Text in Train Management Systems",
        "rating": -0.5,
        "keywords": [
            [
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "EU directives stipulate a systematic follow-up of train delays. In Sweden, the Swedish Transport Administration registers and assigns an appropriate delay attribution code. However, this delay attribution code is assigned manually, which is a complex task. In this paper, a machine learning-based decision support for assigning delay attribution codes based on event descriptions is investigated. The text is transformed using TF-IDF, and two models, Random Forest and Support Vector Machine, are evaluated against a random uniform classifier and the classification performance of the Swedish Transport Administration. Further, the problem is modeled as both a hierarchical and flat approach. The results indicate that a hierarchical approach performs better than a flat approach. Both approaches perform better than the random uniform classifier but perform worse than the manual classification.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "22 pages, 7 figures"
    },
    {
        "paper id": "2402.04154",
        "abstract url": "https://arxiv.org/abs/2402.04154",
        "title": "Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction",
        "rating": -0.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning. However, these works encounter challenges in extending their capabilities to new tasks. Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction. However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks. This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a \"read-to-play\" capability. Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set of multimodal game instructions to incorporate instruction tuning into a decision transformer. Experimental results demonstrate that incorporating multimodal game instructions significantly enhances the decision transformer's multitasking and generalization capabilities.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04168",
        "abstract url": "https://arxiv.org/abs/2402.04168",
        "title": "Informed Reinforcement Learning for Situation-Aware Traffic Rule Exceptions",
        "rating": -0.5,
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning is a highly active research field with promising advancements. In the field of autonomous driving, however, often very simple scenarios are being examined. Common approaches use non-interpretable control commands as the action space and unstructured reward designs which lack structure. In this work, we introduce Informed Reinforcement Learning, where a structured rulebook is integrated as a knowledge source. We learn trajectories and asses them with a situation-aware reward design, leading to a dynamic reward which allows the agent to learn situations which require controlled traffic rule exceptions. Our method is applicable to arbitrary RL models. We successfully demonstrate high completion rates of complex scenarios with recent model-based agents.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Daniel Bogdoll and Jing Qin contributed equally. Accepted for publication at ICRA 2024"
    },
    {
        "paper id": "2402.04249",
        "abstract url": "https://arxiv.org/abs/2402.04249",
        "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
        "rating": -0.5,
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Automated red teaming holds substantial promise for uncovering and mitigating the risks associated with the malicious use of large language models (LLMs), yet the field lacks a standardized evaluation framework to rigorously assess new methods. To address this issue, we introduce HarmBench, a standardized evaluation framework for automated red teaming. We identify several desirable properties previously unaccounted for in red teaming evaluations and systematically design HarmBench to meet these criteria. Using HarmBench, we conduct a large-scale comparison of 18 red teaming methods and 33 target LLMs and defenses, yielding novel insights. We also introduce a highly efficient adversarial training method that greatly enhances LLM robustness across a wide range of attacks, demonstrating how HarmBench enables codevelopment of attacks and defenses. We open source HarmBench at https://github.com/centerforaisafety/HarmBench.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Website: https://www.harmbench.org"
    },
    {
        "paper id": "2402.04292",
        "abstract url": "https://arxiv.org/abs/2402.04292",
        "title": "AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies",
        "rating": -0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion-based imitation learning improves Behavioral Cloning (BC) on multi-modal decision-making, but comes at the cost of significantly slower inference due to the recursion in the diffusion process. It urges us to design efficient policy generators while keeping the ability to generate diverse actions. To address this challenge, we propose AdaFlow, an imitation learning framework based on flow-based generative modeling. AdaFlow represents the policy with state-conditioned ordinary differential equations (ODEs), which are known as probability flows. We reveal an intriguing connection between the conditional variance of their training loss and the discretization error of the ODEs. With this insight, we propose a variance-adaptive ODE solver that can adjust its step size in the inference stage, making AdaFlow an adaptive decision-maker, offering rapid inference without sacrificing diversity. Interestingly, it automatically reduces to a one-step generator when the action distribution is uni-modal. Our comprehensive empirical evaluation shows that AdaFlow achieves high performance across all dimensions, including success rate, behavioral diversity, and inference speed. The code is available at https://github.com/hxixixh/AdaFlow",
        "subjects": [
            "cs.LG"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2402.04370",
        "abstract url": "https://arxiv.org/abs/2402.04370",
        "title": "Pedestrian crossing decisions can be explained by bounded optimal decision-making under noisy visual perception",
        "rating": -0.5,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents a model of pedestrian crossing decisions, based on the theory of computational rationality. It is assumed that crossing decisions are boundedly optimal, with bounds on optimality arising from human cognitive limitations. While previous models of pedestrian behaviour have been either 'black-box' machine learning models or mechanistic models with explicit assumptions about cognitive factors, we combine both approaches. Specifically, we model mechanistically noisy human visual perception and assumed rewards in crossing, but we use reinforcement learning to learn bounded optimal behaviour policy. The model reproduces a larger number of known empirical phenomena than previous models, in particular: (1) the effect of the time to arrival of an approaching vehicle on whether the pedestrian accepts the gap, the effect of the vehicle's speed on both (2) gap acceptance and (3) pedestrian timing of crossing in front of yielding vehicles, and (4) the effect on this crossing timing of the stopping distance of the yielding vehicle. Notably, our findings suggest that behaviours previously framed as 'biases' in decision-making, such as speed-dependent gap acceptance, might instead be a product of rational adaptation to the constraints of visual perception. Our approach also permits fitting the parameters of cognitive constraints and rewards per individual, to better account for individual differences. To conclude, by leveraging both RL and mechanistic modelling, our model offers novel insights about pedestrian behaviour, and may provide a useful foundation for more accurate and scalable pedestrian models.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04383",
        "abstract url": "https://arxiv.org/abs/2402.04383",
        "title": "FairWire: Fair Graph Generation",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning over graphs has recently attracted growing attention due to its ability to analyze and learn complex relations within critical interconnected systems. However, the disparate impact that is amplified by the use of biased graph structures in these algorithms has raised significant concerns for the deployment of them in real-world decision systems. In addition, while synthetic graph generation has become pivotal for privacy and scalability considerations, the impact of generative learning algorithms on the structural bias has not yet been investigated. Motivated by this, this work focuses on the analysis and mitigation of structural bias for both real and synthetic graphs. Specifically, we first theoretically analyze the sources of structural bias that result in disparity for the predictions of dyadic relations. To alleviate the identified bias factors, we design a novel fairness regularizer that offers a versatile use. Faced with the bias amplification in graph generation models that is brought to light in this work, we further propose a fair graph generation framework, FairWire, by leveraging our fair regularizer design in a generative model. Experimental results on real-world networks validate that the proposed tools herein deliver effective structural bias mitigation for both real and synthetic graphs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 1 figure, 7 tables"
    },
    {
        "paper id": "2402.04435",
        "abstract url": "https://arxiv.org/abs/2402.04435",
        "title": "PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection",
        "rating": -0.5,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Pretraining on Graph Neural Networks (GNNs) has shown great power in facilitating various downstream tasks. As pretraining generally requires huge amount of data and computational resources, the pretrained GNNs are high-value Intellectual Properties (IP) of the legitimate owner. However, adversaries may illegally copy and deploy the pretrained GNN models for their downstream tasks. Though initial efforts have been made to watermark GNN classifiers for IP protection, these methods require the target classification task for watermarking, and thus are not applicable to self-supervised pretraining of GNN models. Hence, in this work, we propose a novel framework named PreGIP to watermark the pretraining of GNN encoder for IP protection while maintain the high-quality of the embedding space. PreGIP incorporates a task-free watermarking loss to watermark the embedding space of pretrained GNN encoder. A finetuning-resistant watermark injection is further deployed. Theoretical analysis and extensive experiments show the effectiveness of {\\method} in IP protection and maintaining high-performance for downstream tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04567",
        "abstract url": "https://arxiv.org/abs/2402.04567",
        "title": "OIL-AD: An Anomaly Detection Framework for Sequential Decision Sequences",
        "rating": -0.5,
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Anomaly detection in decision-making sequences is a challenging problem due to the complexity of normality representation learning and the sequential nature of the task. Most existing methods based on Reinforcement Learning (RL) are difficult to implement in the real world due to unrealistic assumptions, such as having access to environment dynamics, reward signals, and online interactions with the environment. To address these limitations, we propose an unsupervised method named Offline Imitation Learning based Anomaly Detection (OIL-AD), which detects anomalies in decision-making sequences using two extracted behaviour features: action optimality and sequential association. Our offline learning model is an adaptation of behavioural cloning with a transformer policy network, where we modify the training process to learn a Q function and a state value function from normal trajectories. We propose that the Q function and the state value function can provide sufficient information about agents' behavioural data, from which we derive two features for anomaly detection. The intuition behind our method is that the action optimality feature derived from the Q function can differentiate the optimal action from others at each local state, and the sequential association feature derived from the state value function has the potential to maintain the temporal correlations between decisions (state-action pairs). Our experiments show that OIL-AD can achieve outstanding online anomaly detection performance with up to 34.8% improvement in F1 score over comparable baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04870",
        "abstract url": "https://arxiv.org/abs/2402.04870",
        "title": "Embedding Knowledge Graphs in Degenerate Clifford Algebras",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Clifford algebras are a natural generalization of the real numbers, the complex numbers, and the quaternions. So far, solely Clifford algebras of the form $Cl_{p,q}$ (i.e., algebras without nilpotent base vectors) have been studied in the context of knowledge graph embeddings. We propose to consider nilpotent base vectors with a nilpotency index of two. In these spaces, denoted $Cl_{p,q,r}$, allows generalizing over approaches based on dual numbers (which cannot be modelled using $Cl_{p,q}$) and capturing patterns that emanate from the absence of higher-order interactions between real and complex parts of entity embeddings. We design two new models for the discovery of the parameters $p$, $q$, and $r$. The first model uses a greedy search to optimize $p$, $q$, and $r$. The second predicts $(p, q,r)$ based on an embedding of the input knowledge graph computed using neural networks. The results of our evaluation on seven benchmark datasets suggest that nilpotent vectors can help capture embeddings better. Our comparison against the state of the art suggests that our approach generalizes better than other approaches on all datasets w.r.t. the MRR it achieves on validation data. We also show that a greedy search suffices to discover values of $p$, $q$ and $r$ that are close to optimal.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05135",
        "abstract url": "https://arxiv.org/abs/2402.05135",
        "title": "CADReN: Contextual Anchor-Driven Relational Network for Controllable Cross-Graphs Node Importance Estimation",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Node Importance Estimation (NIE) is crucial for integrating external information into Large Language Models through Retriever-Augmented Generation. Traditional methods, focusing on static, single-graph characteristics, lack adaptability to new graphs and user-specific requirements. CADReN, our proposed method, addresses these limitations by introducing a Contextual Anchor (CA) mechanism. This approach enables the network to assess node importance relative to the CA, considering both structural and semantic features within Knowledge Graphs (KGs). Extensive experiments show that CADReN achieves better performance in cross-graph NIE task, with zero-shot prediction ability. CADReN is also proven to match the performance of previous models on single-graph NIE task. Additionally, we introduce and opensource two new datasets, RIC200 and WK1K, specifically designed for cross-graph NIE research, providing a valuable resource for future developments in this domain.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2402.03708",
        "abstract url": "https://arxiv.org/abs/2402.03708",
        "title": "SISP: A Benchmark Dataset for Fine-grained Ship Instance Segmentation in Panchromatic Satellite Images",
        "rating": -1,
        "keywords": [
            [
                "Satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fine-grained ship instance segmentation in satellite images holds considerable significance for monitoring maritime activities at sea. However, existing datasets often suffer from the scarcity of fine-grained information or pixel-wise localization annotations, as well as the insufficient image diversity and variations, thus limiting the research of this task. To this end, we propose a benchmark dataset for fine-grained Ship Instance Segmentation in Panchromatic satellite images, namely SISP, which contains 56,693 well-annotated ship instances with four fine-grained categories across 10,000 sliced images, and all the images are collected from SuperView-1 satellite with the resolution of 0.5m. Targets in the proposed SISP dataset have characteristics that are consistent with real satellite scenes, such as high class imbalance, various scenes, large variations in target densities and scales, and high inter-class similarity and intra-class diversity, all of which make the SISP dataset more suitable for real-world applications. In addition, we introduce a Dynamic Feature Refinement-assist Instance segmentation network, namely DFRInst, as the benchmark method for ship instance segmentation in satellite images, which can fortify the explicit representation of crucial features, thus improving the performance of ship instance segmentation. Experiments and analysis are performed on the proposed SISP dataset to evaluate the benchmark method and several state-of-the-art methods to establish baselines for facilitating future research. The proposed dataset and source codes will be available at: https://github.com/Justlovesmile/SISP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 9 figures"
    },
    {
        "paper id": "2402.03716",
        "abstract url": "https://arxiv.org/abs/2402.03716",
        "title": "Attention-based Shape and Gait Representations Learning for Video-based Cloth-Changing Person Re-Identification",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current state-of-the-art Video-based Person Re-Identification (Re-ID) primarily relies on appearance features extracted by deep learning models. These methods are not applicable for long-term analysis in real-world scenarios where persons have changed clothes, making appearance information unreliable. In this work, we deal with the practical problem of Video-based Cloth-Changing Person Re-ID (VCCRe-ID) by proposing \"Attention-based Shape and Gait Representations Learning\" (ASGL) for VCCRe-ID. Our ASGL framework improves Re-ID performance under clothing variations by learning clothing-invariant gait cues using a Spatial-Temporal Graph Attention Network (ST-GAT). Given the 3D-skeleton-based spatial-temporal graph, our proposed ST-GAT comprises multi-head attention modules, which are able to enhance the robustness of gait embeddings under viewpoint changes and occlusions. The ST-GAT amplifies the important motion ranges and reduces the influence of noisy poses. Then, the multi-head learning module effectively reserves beneficial local temporal dynamics of movement. We also boost discriminative power of person representations by learning body shape cues using a GAT. Experiments on two large-scale VCCRe-ID datasets demonstrate that our proposed framework outperforms state-of-the-art methods by 12.2% in rank-1 accuracy and 7.0% in mAP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03736",
        "abstract url": "https://arxiv.org/abs/2402.03736",
        "title": "An Effective Branch-and-Bound Algorithm with New Bounding Methods for the Maximum $s$-Bundle Problem",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The Maximum s-Bundle Problem (MBP) addresses the task of identifying a maximum s-bundle in a given graph. A graph G=(V, E) is called an s-bundle if its vertex connectivity is at least |V|-s, where the vertex connectivity equals the minimum number of vertices whose deletion yields a disconnected or trivial graph. MBP is NP-hard and holds relevance in numerous realworld scenarios emphasizing the vertex connectivity. Exact algorithms for MBP mainly follow the branch-and-bound (BnB) framework, whose performance heavily depends on the quality of the upper bound on the cardinality of a maximum s-bundle and the initial lower bound with graph reduction. In this work, we introduce a novel Partition-based Upper Bound (PUB) that leverages the graph partitioning technique to achieve a tighter upper bound compared to existing ones. To increase the lower bound, we propose to do short random walks on a clique to generate larger initial solutions. Then, we propose a new BnB algorithm that uses the initial lower bound and PUB in preprocessing for graph reduction, and uses PUB in the BnB search process for branch pruning. Extensive experiments with diverse s values demonstrate the significant progress of our algorithm over state-of-the-art BnB MBP algorithms. Moreover, our initial lower bound can also be generalized to other relaxation clique problems.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "10 pages, 2 figures, 5 tables"
    },
    {
        "paper id": "2402.03738",
        "abstract url": "https://arxiv.org/abs/2402.03738",
        "title": "AoSRNet: All-in-One Scene Recovery Networks via Multi-knowledge Integration",
        "rating": -1,
        "keywords": [
            [
                "haze"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Scattering and attenuation of light in no-homogeneous imaging media or inconsistent light intensity will cause insufficient contrast and color distortion in the collected images, which limits the developments such as vision-driven smart urban, autonomous vehicles, and intelligent robots. In this paper, we propose an all-in-one scene recovery network via multi-knowledge integration (termed AoSRNet) to improve the visibility of imaging devices in typical low-visibility imaging scenes (e.g., haze, sand dust, and low light). It combines gamma correction (GC) and optimized linear stretching (OLS) to create the detail enhancement module (DEM) and color restoration module (CRM). Additionally, we suggest a multi-receptive field extraction module (MEM) to attenuate the loss of image texture details caused by GC nonlinear and OLS linear transformations. Finally, we refine the coarse features generated by DEM, CRM, and MEM through Encoder-Decoder to generate the final restored image. Comprehensive experimental results demonstrate the effectiveness and stability of AoSRNet compared to other state-of-the-art methods. The source code is available at \\url{https://github.com/LouisYuxuLu/AoSRNet}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03748",
        "abstract url": "https://arxiv.org/abs/2402.03748",
        "title": "Succinct Data Structure for Chordal Graphs with Bounded Vertex Leafage",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We improve the worst-case information theoretic lower bound of Munro and Wu (ISAAC 2018) for $n-$vertex unlabeled chordal graphs when vertex leafage is bounded and leafage is unbounded. The class of unlabeled $k-$vertex leafage chordal graphs that consists of all chordal graphs with vertex leafage at most $k$ and unbounded leafage, denoted $\\mathcal{G}_k$, is introduced for the first time. For $k>0$ in $o(n/\\log n)$, we obtain a lower bound of $((k-1)n \\log n -kn \\log k - O(\\log n))-$bits on the size of any data structure that encodes a graph in $\\mathcal{G}_k$. Further, for every $k-$vertex leafage chordal graph $G$ such that for $k>1$ in $o(n^c), c >0$, we present a $((k-1)n \\log n + o(kn \\log n))-$bit succinct data structure, constructed using the succinct data structure for path graphs with $kn/2$ vertices. Our data structure supports adjacency query in $O(k \\log n)$ time and using additional $2n \\log n$ bits, an $O(k^2 d_v \\log n + \\log^2 n)$ time neighbourhood query where $d_v$ is degree of $v \\in V$.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "19 pages, 2 figure"
    },
    {
        "paper id": "2402.03760",
        "abstract url": "https://arxiv.org/abs/2402.03760",
        "title": "DeMarking: A Defense for Network Flow Watermarking in Real-Time",
        "rating": -1,
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The network flow watermarking technique associates the two communicating parties by actively modifying certain characteristics of the stream generated by the sender so that it covertly carries some special marking information. Some curious users communicating with the hidden server as a Tor client may attempt de-anonymization attacks to uncover the real identity of the hidden server by using this technique. This compromises the privacy of the anonymized communication system. Therefore, we propose a defense scheme against flow watermarking. The scheme is based on deep neural networks and utilizes generative adversarial networks to convert the original Inter-Packet Delays (IPD) into new IPDs generated by the model. We also adopt the concept of adversarial attacks to ensure that the detector will produce an incorrect classification when detecting these new IPDs. This approach ensures that these IPDs are considered \"clean\", effectively covering the potential watermarks. This scheme is effective against time-based flow watermarking techniques.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03762",
        "abstract url": "https://arxiv.org/abs/2402.03762",
        "title": "MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction",
        "rating": -1,
        "keywords": [
            [
                "3D",
                "depth",
                "NeRF"
            ],
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular SLAM has received a lot of attention due to its simple RGB inputs and the lifting of complex sensor constraints. However, existing monocular SLAM systems are designed for bounded scenes, restricting the applicability of SLAM systems. To address this limitation, we propose MoD-SLAM, the first monocular NeRF-based dense mapping method that allows 3D reconstruction in real-time in unbounded scenes. Specifically, we introduce a Gaussian-based unbounded scene representation approach to solve the challenge of mapping scenes without boundaries. This strategy is essential to extend the SLAM application. Moreover, a depth estimation module in the front-end is designed to extract accurate priori depth values to supervise mapping and tracking processes. By introducing a robust depth loss term into the tracking process, our SLAM system achieves more precise pose estimation in large-scale scenes. Our experiments on two standard datasets show that MoD-SLAM achieves competitive performance, improving the accuracy of the 3D reconstruction and localization by up to 30% and 15% respectively compared with existing state-of-the-art monocular SLAM systems.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03796",
        "abstract url": "https://arxiv.org/abs/2402.03796",
        "title": "Face Detection: Present State and Research Directions",
        "rating": -1,
        "keywords": [
            [
                "Face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The majority of computer vision applications that handle images featuring humans use face detection as a core component. Face detection still has issues, despite much research on the topic. Face detection's accuracy and speed might yet be increased. This review paper shows the progress made in this area as well as the substantial issues that still need to be tackled. The paper provides research directions that can be taken up as research projects in the field of face detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03803",
        "abstract url": "https://arxiv.org/abs/2402.03803",
        "title": "Robot voice a voice controlled robot using arduino",
        "rating": -1,
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Robotic assistants reduce the manual efforts being put in by humans in their day-to-day tasks. In this paper, we develop a voice-controlled personal assistant robot. The robot takes the human voice commands by its own built-in microphone. This robot not only takes the commands and executes them but also acknowledges them through speech output. This robot can perform different movements, turns, wakeup/shutdown operations, relocate an object from one place to another, and can also develop a conversation with humans. The voice commands are processed in real time using an offline server. The speech signal commands are directly communicated to the server using a USB cable. The personal assistant robot is developed on a microcontroller-based platform. Performance evaluation is carried out with encouraging results of the initial experiments. Possible improvements for applications in homes, hospitals, car systems, and industries are also discussed.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03811",
        "abstract url": "https://arxiv.org/abs/2402.03811",
        "title": "Using Perspective-n-Point Algorithms for a Local Positioning System Based on LEDs and a QADA Receiver",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The research interest on location-based services has increased during the last years ever since 3D centimetre accuracy inside intelligent environments could be confronted with. This work proposes an indoor local positioning system based on LED lighting, transmitted from a set of beacons to a receiver.The receiver is based on a quadrant photodiode angular diversity aperture (QADA) plus an aperture placed over it.This configuration can be modelled as a perspective camera, where the image position of the transmitters can be used to recover the receiver's 3D pose. This process is known as the perspective-n-point (PnP) problem, which is well known in computer vision and photogrammetry. This work investigates the use of different state-of-the-art PnP algorithms to localize the receiver in a large space based on four co-planar transmitters and with a distance from transmitters to receiver of 3.4 m. Encoding techniques are used to permit the simultaneous emission of all the transmitted signals and their processing in the receiver. In addition, correlation techniques are used to determine the image points projected from each emitter on the QADA. This work uses Monte Carlo simulations to characterize the absolute errors for a grid of test points under noisy measurements, as well as the robustness of the system when varying the 3D location of one transmitter. The IPPE algorithm obtained the best performance in this configuration. The proposal has also been experimentally evaluated in a real setup. The estimation of the receiver's position at three points using the IPPE algorithm achieves average absolute errors of 4.33cm, 3.51cm and 28.90cm in the coordinates x, y and z, respectively. These positioning results are in line with those obtained in previous work using triangulation techniques but with the addition that the complete pose of the receiver is obtained in this proposal.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03830",
        "abstract url": "https://arxiv.org/abs/2402.03830",
        "title": "OASim: an Open and Adaptive Simulator based on Neural Rendering for Autonomous Driving",
        "rating": -1,
        "keywords": [
            [
                "depth"
            ],
            [
                "Autonomous Driving",
                "Trajectory",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With deep learning and computer vision technology development, autonomous driving provides new solutions to improve traffic safety and efficiency. The importance of building high-quality datasets is self-evident, especially with the rise of end-to-end autonomous driving algorithms in recent years. Data plays a core role in the algorithm closed-loop system. However, collecting real-world data is expensive, time-consuming, and unsafe. With the development of implicit rendering technology and in-depth research on using generative models to produce data at scale, we propose OASim, an open and adaptive simulator and autonomous driving data generator based on implicit neural rendering. It has the following characteristics: (1) High-quality scene reconstruction through neural implicit surface reconstruction technology. (2) Trajectory editing of the ego vehicle and participating vehicles. (3) Rich vehicle model library that can be freely selected and inserted into the scene. (4) Rich sensors model library where you can select specified sensors to generate data. (5) A highly customizable data generation system can generate data according to user needs. We demonstrate the high quality and fidelity of the generated data through perception performance evaluation on the Carla simulator and real-world data acquisition. Code is available at https://github.com/PJLab-ADG/OASim.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 9 figures"
    },
    {
        "paper id": "2402.03832",
        "abstract url": "https://arxiv.org/abs/2402.03832",
        "title": "Rethinking Skill Extraction in the Job Market Domain using Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "BIO"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Skill Extraction involves identifying skills and qualifications mentioned in documents such as job postings and resumes. The task is commonly tackled by training supervised models using a sequence labeling approach with BIO tags. However, the reliance on manually annotated data limits the generalizability of such approaches. Moreover, the common BIO setting limits the ability of the models to capture complex skill patterns and handle ambiguous mentions. In this paper, we explore the use of in-context learning to overcome these challenges, on a benchmark of 6 uniformized skill extraction datasets. Our approach leverages the few-shot learning capabilities of large language models (LLMs) to identify and extract skills from sentences. We show that LLMs, despite not being on par with traditional supervised models in terms of performance, can better handle syntactically complex skill mentions in skill extraction tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Published at NLP4HR 2024 (EACL Workshop)"
    },
    {
        "paper id": "2402.03849",
        "abstract url": "https://arxiv.org/abs/2402.03849",
        "title": "Global certification via perfect hashing",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this work, we provide an upper bound for global certification of graph homomorphism, a generalization of graph coloring. In certification, the nodes of a network should decide if the network satisfies a given property, thanks to small pieces of information called certificates. Here, there is only one global certificate which is shared by all the nodes, and the property we want to certify is the existence of a graph homomorphism to a given graph. For bipartiteness, a special case of graph homomorphism, Feuilloley and Hirvonen proved in~\\cite{FeuilloleyH18} some upper and lower bounds on the size of the optimal certificate, and made the conjecture that their lower bound could be improved to match their upper bound. We prove that this conjecture is false: their lower bound was in fact optimal, and we prove it by providing the matching upper bound using a known result of perfect hashing.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03877",
        "abstract url": "https://arxiv.org/abs/2402.03877",
        "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs' abilities in constructive geometric problem-solving one of the most fundamental steps in the development of human mathematical reasoning. Our work reveals notable challenges that the state-of-the-art LLMs face in this domain despite many successes in similar areas. LLMs exhibit biases in target variable selection and struggle with 2D spatial relationships, often misrepresenting and hallucinating objects and their placements. To this end, we introduce a framework that formulates an LLMs-based multi-agents system that enhances their existing reasoning potential by conducting an internal dialogue. This work underscores LLMs' current limitations in geometric reasoning and improves geometric reasoning capabilities through self-correction, collaboration, and diverse role specializations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint. Work in progress"
    },
    {
        "paper id": "2402.03893",
        "abstract url": "https://arxiv.org/abs/2402.03893",
        "title": "Prediction Horizon Requirements for Automated Driving: Optimizing Safety, Comfort, and Efficiency",
        "rating": -1,
        "keywords": [
            [
                "Automated Driving",
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "Predicting the movement of other road users is beneficial for improving automated vehicle (AV) performance. However, the relationship between the time horizon associated with these predictions and AV performance remains unclear. Despite the existence of numerous trajectory prediction algorithms, no studies have been conducted on how varying prediction lengths affect AV safety and other vehicle performance metrics, resulting in undefined horizon requirements for prediction methods. Our study addresses this gap by examining the effects of different prediction horizons on AV performance, focusing on safety, comfort, and efficiency. Through multiple experiments using a state-of-the-art, risk-based predictive trajectory planner, we simulated predictions with horizons up to 20 seconds. Based on our simulations, we propose a framework for specifying the minimum required and optimal prediction horizons based on specific AV performance criteria and application needs. Our results indicate that a horizon of 1.6 seconds is required to prevent collisions with crossing pedestrians, horizons of 7-8 seconds yield the best efficiency, and horizons up to 15 seconds improve passenger comfort. We conclude that prediction horizon requirements are application-dependent, and recommend aiming for a prediction horizon of 11.8 seconds as a general guideline for applications involving crossing pedestrians.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to IEEE Intelligent Vehicles Symposium. 9 pages. 10 figures. 6 tables"
    },
    {
        "paper id": "2402.03919",
        "abstract url": "https://arxiv.org/abs/2402.03919",
        "title": "Sensing Mutual Information with Random Signals in Gaussian Channels: Bridging Sensing and Communication Metrics",
        "rating": -1,
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Sensing performance is typically evaluated by classical radar metrics, such as Cramer-Rao bound and signal-to-clutter-plus-noise ratio. The recent development of the integrated sensing and communication (ISAC) framework motivated the efforts to unify the performance metric for sensing and communication, where mutual information (MI) was proposed as a sensing performance metric with deterministic signals. However, the need of communication in ISAC systems necessitates the transmission of random signals for sensing applications, whereas an explicit evaluation for the sensing mutual information (SMI) with random signals is not yet available in the literature. This paper aims to fill the research gap and investigate the unification of sensing and communication performance metrics. For that purpose, we first derive the explicit expression for the SMI with random signals utilizing random matrix theory. On top of that, we further build up the connections between SMI and traditional sensing metrics, such as ergodic minimum mean square error (EMMSE), ergodic linear minimum mean square error (ELMMSE), and ergodic Bayesian Cram\u00e9r-Rao bound (EBCRB). Such connections open up the opportunity to unify sensing and communication performance metrics, which facilitates the analysis and design for ISAC systems. Finally, SMI is utilized to optimize the precoder for both sensing-only and ISAC applications. Simulation results validate the accuracy of the theoretical results and the effectiveness of the proposed precoding designs.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2311.07081"
    },
    {
        "paper id": "2402.04023",
        "abstract url": "https://arxiv.org/abs/2402.04023",
        "title": "Google Translate Error Analysis for Mental Healthcare Information: Evaluating Accuracy, Comprehensibility, and Implications for Multilingual Healthcare Communication",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "Health",
                "Healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the use of Google Translate (GT) for translating mental healthcare (MHealth) information and evaluates its accuracy, comprehensibility, and implications for multilingual healthcare communication through analysing GT output in the MHealth domain from English to Persian, Arabic, Turkish, Romanian, and Spanish. Two datasets comprising MHealth information from the UK National Health Service website and information leaflets from The Royal College of Psychiatrists were used. Native speakers of the target languages manually assessed the GT translations, focusing on medical terminology accuracy, comprehensibility, and critical syntactic/semantic errors. GT output analysis revealed challenges in accurately translating medical terminology, particularly in Arabic, Romanian, and Persian. Fluency issues were prevalent across various languages, affecting comprehension, mainly in Arabic and Spanish. Critical errors arose in specific contexts, such as bullet-point formatting, specifically in Persian, Turkish, and Romanian. Although improvements are seen in longer-text translations, there remains a need to enhance accuracy in medical and mental health terminology and fluency, whilst also addressing formatting issues for a more seamless user experience. The findings highlight the need to use customised translation engines for Mhealth translation and the challenges when relying solely on machine-translated medical content, emphasising the crucial role of human reviewers in multilingual healthcare communication.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04075",
        "abstract url": "https://arxiv.org/abs/2402.04075",
        "title": "Iterative Prompt Refinement for Radiation Oncology Symptom Extraction Using Teacher-Student Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "cancer",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces a novel teacher-student architecture utilizing Large Language Models (LLMs) to improve prostate cancer radiotherapy symptom extraction from clinical notes. Mixtral, the student model, initially extracts symptoms, followed by GPT-4, the teacher model, which refines prompts based on Mixtral's performance. This iterative process involved 294 single symptom clinical notes across 12 symptoms, with up to 16 rounds of refinement per epoch. Results showed significant improvements in extracting symptoms from both single and multi-symptom notes. For 59 single symptom notes, accuracy increased from 0.51 to 0.71, precision from 0.52 to 0.82, recall from 0.52 to 0.72, and F1 score from 0.49 to 0.73. In 375 multi-symptom notes, accuracy rose from 0.24 to 0.43, precision from 0.6 to 0.76, recall from 0.24 to 0.43, and F1 score from 0.20 to 0.44. These results demonstrate the effectiveness of advanced prompt engineering in LLMs for radiation oncology use.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04088",
        "abstract url": "https://arxiv.org/abs/2402.04088",
        "title": "The Use of a Large Language Model for Cyberbullying Detection",
        "rating": -1,
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The dominance of social media has added to the channels of bullying for perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent phenomenon in todays cyber world, and is a severe threat to the mental and physical health of citizens. This opens the need to develop a robust system to prevent bullying content from online forums, blogs, and social media platforms to manage the impact in our society. Several machine learning (ML) algorithms have been proposed for this purpose. However, their performances are not consistent due to high class imbalance and generalisation issues. In recent years, large language models (LLMs) like BERT and RoBERTa have achieved state-of-the-art (SOTA) results in several natural language processing (NLP) tasks. Unfortunately, the LLMs have not been applied extensively for CB detection. In our paper, we explored the use of these models for cyberbullying (CB) detection. We have prepared a new dataset (D2) from existing studies (Formspring and Twitter). Our experimental results for dataset D1 and D2 showed that RoBERTa outperformed other models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "14 pages, Journal of Analytics"
    },
    {
        "paper id": "2402.04139",
        "abstract url": "https://arxiv.org/abs/2402.04139",
        "title": "U-shaped Vision Mamba for Single Image Dehazing",
        "rating": -1,
        "keywords": [
            [
                "image restoration",
                "Dehazing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Currently, Transformer is the most popular architecture for image dehazing, but due to its large computational complexity, its ability to handle long-range dependency is limited on resource-constrained devices. To tackle this challenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficient single-image dehazing network. Inspired by the State Space Sequence Models (SSMs), a new deep sequence model known for its power to handle long sequences, we design a Bi-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. Extensive experimental results demonstrate the effectiveness of our method. Our method provides a more highly efficient idea of long-range dependency modeling for image dehazing as well as other image restoration tasks. The URL of the code is \\url{https://github.com/zzr-idam/UVM-Net}. Our method takes only \\textbf{0.009} seconds to infer a $325 \\times 325$ resolution image (100FPS) without I/O handling time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04157",
        "abstract url": "https://arxiv.org/abs/2402.04157",
        "title": "Controller synthesis for input-state data with measurement errors",
        "rating": -1,
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "We consider the problem of designing a state-feedback controller for a linear system, based only on noisy input-state data. We focus on input-state data corrupted by additive measurement errors, which, albeit less investigated, are as relevant as process disturbances in applications. For energy and instantaneous bounds on these measurement errors, we derive linear matrix inequalities for controller design where the one for the energy bound is actually equivalent to robust stabilization of all systems consistent with the noisy data points.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04173",
        "abstract url": "https://arxiv.org/abs/2402.04173",
        "title": "COPS: A Compact On-device Pipeline for real-time Smishing detection",
        "rating": -1,
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Smartphones have become indispensable in our daily lives and can do almost everything, from communication to online shopping. However, with the increased usage, cybercrime aimed at mobile devices is rocketing. Smishing attacks, in particular, have observed a significant upsurge in recent years. This problem is further exacerbated by the perpetrator creating new deceptive websites daily, with an average life cycle of under 15 hours. This renders the standard practice of keeping a database of malicious URLs ineffective. To this end, we propose a novel on-device pipeline: COPS that intelligently identifies features of fraudulent messages and URLs to alert the user in real-time. COPS is a lightweight pipeline with a detection module based on the Disentangled Variational Autoencoder of size 3.46MB for smishing and URL phishing detection, and we benchmark it on open datasets. We achieve an accuracy of 98.15% and 99.5%, respectively, for both tasks, with a false negative and false positive rate of a mere 0.037 and 0.015, outperforming previous works with the added advantage of ensuring real-time alerts on resource-constrained devices.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Published at IEEE Consumer Communications & Networking Conference (CCNC) 2024"
    },
    {
        "paper id": "2402.04195",
        "abstract url": "https://arxiv.org/abs/2402.04195",
        "title": "Instance by Instance: An Iterative Framework for Multi-instance 3D Registration",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-instance registration is a challenging problem in computer vision and robotics, where multiple instances of an object need to be registered in a standard coordinate system. In this work, we propose the first iterative framework called instance-by-instance (IBI) for multi-instance 3D registration (MI-3DReg). It successively registers all instances in a given scenario, starting from the easiest and progressing to more challenging ones. Throughout the iterative process, outliers are eliminated continuously, leading to an increasing inlier rate for the remaining and more challenging instances. Under the IBI framework, we further propose a sparse-to-dense-correspondence-based multi-instance registration method (IBI-S2DC) to achieve robust MI-3DReg. Experiments on the synthetic and real datasets have demonstrated the effectiveness of IBI and suggested the new state-of-the-art performance of IBI-S2DC, e.g., our MHF1 is 12.02%/12.35% higher than the existing state-of-the-art method ECC on the synthetic/real datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 12 figures, 10 tables"
    },
    {
        "paper id": "2402.04206",
        "abstract url": "https://arxiv.org/abs/2402.04206",
        "title": "Explaining Autonomy: Enhancing Human-Robot Interaction through Explanation Generation with Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "robotics",
                "Robot",
                "navigation"
            ]
        ],
        "abstract": "This paper introduces a system designed to generate explanations for the actions performed by an autonomous robot in Human-Robot Interaction (HRI). Explainability in robotics, encapsulated within the concept of an eXplainable Autonomous Robot (XAR), is a growing research area. The work described in this paper aims to take advantage of the capabilities of Large Language Models (LLMs) in performing natural language processing tasks. This study focuses on the possibility of generating explanations using such models in combination with a Retrieval Augmented Generation (RAG) method to interpret data gathered from the logs of autonomous systems. In addition, this work also presents a formalization of the proposed explanation system. It has been evaluated through a navigation test from the European Robotics League (ERL), a Europe-wide social robotics competition. Regarding the obtained results, a validation questionnaire has been conducted to measure the quality of the explanations from the perspective of technical users. The results obtained during the experiment highlight the potential utility of LLMs in achieving explanatory capabilities in robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "26 pages, 15 Figures, 11 Tables. This paper is a preprint of an article submitted to the International Journal of Social Robotics"
    },
    {
        "paper id": "2402.04216",
        "abstract url": "https://arxiv.org/abs/2402.04216",
        "title": "Resource-Aware Hierarchical Federated Learning in Wireless Video Caching Networks",
        "rating": -1,
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Backhaul traffic congestion caused by the video traffic of a few popular files can be alleviated by storing the to-be-requested content at various levels in wireless video caching networks. Typically, content service providers (CSPs) own the content, and the users request their preferred content from the CSPs using their (wireless) internet service providers (ISPs). As these parties do not reveal their private information and business secrets, traditional techniques may not be readily used to predict the dynamic changes in users' future demands. Motivated by this, we propose a novel resource-aware hierarchical federated learning (RawHFL) solution for predicting user's future content requests. A practical data acquisition technique is used that allows the user to update its local training dataset based on its requested content. Besides, since networking and other computational resources are limited, considering that only a subset of the users participate in the model training, we derive the convergence bound of the proposed algorithm. Based on this bound, we minimize a weighted utility function for jointly configuring the controllable parameters to train the RawHFL energy efficiently under practical resource constraints. Our extensive simulation results validate the proposed algorithm's superiority, in terms of test accuracy and energy cost, over existing baselines.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Under review for possible publication in IEEE TWC"
    },
    {
        "paper id": "2402.04301",
        "abstract url": "https://arxiv.org/abs/2402.04301",
        "title": "Deep PCCT: Photon Counting Computed Tomography Deep Learning Applications Review",
        "rating": -1,
        "keywords": [
            [
                "Medical",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Medical imaging faces challenges such as limited spatial resolution, interference from electronic noise and poor contrast-to-noise ratios. Photon Counting Computed Tomography (PCCT) has emerged as a solution, addressing these issues with its innovative technology. This review delves into the recent developments and applications of PCCT in pre-clinical research, emphasizing its potential to overcome traditional imaging limitations. For example PCCT has demonstrated remarkable efficacy in improving the detection of subtle abnormalities in breast, providing a level of detail previously unattainable. Examining the current literature on PCCT, it presents a comprehensive analysis of the technology, highlighting the main features of scanners and their varied applications. In addition, it explores the integration of deep learning into PCCT, along with the study of radiomic features, presenting successful applications in data processing. While acknowledging these advances, it also discusses the existing challenges in this field, paving the way for future research and improvements in medical imaging technologies. Despite the limited number of articles on this subject, due to the recent integration of PCCT at a clinical level, its potential benefits extend to various diagnostic applications.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04353",
        "abstract url": "https://arxiv.org/abs/2402.04353",
        "title": "Fair Interval Scheduling of Indivisible Chores",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We study the problem of fairly assigning a set of discrete tasks (or chores) among a set of agents with additive valuations. Each chore is associated with a start and finish time, and each agent can perform at most one chore at any given time. The goal is to find a fair and efficient schedule of the chores, where fairness pertains to satisfying envy-freeness up to one chore (EF1) and efficiency pertains to maximality (i.e., no unallocated chore can be feasibly assigned to any agent). Our main result is a polynomial-time algorithm for computing an EF1 and maximal schedule for two agents under monotone valuations when the conflict constraints constitute an arbitrary interval graph. The algorithm uses a coloring technique in interval graphs that may be of independent interest. For an arbitrary number of agents, we provide an algorithm for finding a fair schedule under identical dichotomous valuations when the constraints constitute a path graph. We also show that stronger fairness and efficiency properties, including envy-freeness up to any chore (EFX) along with maximality and EF1 along with Pareto optimality, cannot be achieved.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04367",
        "abstract url": "https://arxiv.org/abs/2402.04367",
        "title": "Merkle Trees in Blockchain: A Study of Collision Probability and Security Implications",
        "rating": -1,
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of blockchain technology, ensuring the integrity and security of data is paramount. This study delves into the security aspects of Merkle Trees, a fundamental component in blockchain architectures, such as Ethereum. We critically examine the susceptibility of Merkle Trees to hash collisions, a potential vulnerability that poses significant risks to data security within blockchain systems. Despite their widespread application, the collision resistance of Merkle Trees and their robustness against preimage attacks have not been thoroughly investigated, leading to a notable gap in the comprehensive understanding of blockchain security mechanisms. Our research endeavors to bridge this gap through a meticulous blend of theoretical analysis and empirical validation. We scrutinize the probability of root collisions in Merkle Trees, considering various factors such as hash length and path length within the tree. Our findings reveal a direct correlation between the increase in path length and the heightened probability of root collisions, thereby underscoring potential security vulnerabilities. Conversely, we observe that an increase in hash length significantly reduces the likelihood of collisions, highlighting its critical role in fortifying security. The insights garnered from our research offer valuable guidance for blockchain developers and researchers, aiming to bolster the security and operational efficacy of blockchain-based systems.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "4 figures"
    },
    {
        "paper id": "2402.04403",
        "abstract url": "https://arxiv.org/abs/2402.04403",
        "title": "Edge-Parallel Graph Encoder Embedding",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "New algorithms for embedding graphs have reduced the asymptotic complexity of finding low-dimensional representations. One-Hot Graph Encoder Embedding (GEE) uses a single, linear pass over edges and produces an embedding that converges asymptotically to the spectral embedding. The scaling and performance benefits of this approach have been limited by a serial implementation in an interpreted language. We refactor GEE into a parallel program in the Ligra graph engine that maps functions over the edges of the graph and uses lock-free atomic instrutions to prevent data races. On a graph with 1.8B edges, this results in a 500 times speedup over the original implementation and a 17 times speedup over a just-in-time compiled version.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "4 pages, 4 figures"
    },
    {
        "paper id": "2402.04411",
        "abstract url": "https://arxiv.org/abs/2402.04411",
        "title": "Chatbot Meets Pipeline: Augment Large Language Model with Definite Finite Automaton",
        "rating": -1,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces the Definite Finite Automaton augmented large language model (DFA-LLM), a novel framework designed to enhance the capabilities of conversational agents using large language models (LLMs). Traditional LLMs face challenges in generating regulated and compliant responses in special scenarios with predetermined response guidelines, like emotional support and customer service. Our framework addresses these challenges by embedding a Definite Finite Automaton (DFA), learned from training dialogues, within the LLM. This structured approach enables the LLM to adhere to a deterministic response pathway, guided by the DFA. The advantages of DFA-LLM include an interpretable structure through human-readable DFA, context-aware retrieval for responses in conversations, and plug-and-play compatibility with existing LLMs. Extensive benchmarks validate DFA-LLM's effectiveness, indicating its potential as a valuable contribution to the conversational agent.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "21 pages, 11 figures"
    },
    {
        "paper id": "2402.04419",
        "abstract url": "https://arxiv.org/abs/2402.04419",
        "title": "What limits performance of weakly supervised deep learning for chest CT classification?",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "CT",
                "disease"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Weakly supervised learning with noisy data has drawn attention in the medical imaging community due to the sparsity of high-quality disease labels. However, little is known about the limitations of such weakly supervised learning and the effect of these constraints on disease classification performance. In this paper, we test the effects of such weak supervision by examining model tolerance for three conditions. First, we examined model tolerance for noisy data by incrementally increasing error in the labels within the training data. Second, we assessed the impact of dataset size by varying the amount of training data. Third, we compared performance differences between binary and multi-label classification. Results demonstrated that the model could endure up to 10% added label error before experiencing a decline in disease classification performance. Disease classification performance steadily rose as the amount of training data was increased for all disease classes, before experiencing a plateau in performance at 75% of training data. Last, the binary model outperformed the multilabel model in every disease category. However, such interpretations may be misleading, as the binary model was heavily influenced by co-occurring diseases and may not have learned the specific features of the disease in the image. In conclusion, this study may help the medical imaging community understand the benefits and risks of weak supervision with noisy labels. Such studies demonstrate the need to build diverse, large-scale datasets and to develop explainable and responsible AI.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "16 pages , 8 figures. arXiv admin note: text overlap with arXiv:2202.11709"
    },
    {
        "paper id": "2402.04421",
        "abstract url": "https://arxiv.org/abs/2402.04421",
        "title": "Studying Vulnerable Code Entities in R",
        "rating": -1,
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Pre-trained Code Language Models (Code-PLMs) have shown many advancements and achieved state-of-the-art results for many software engineering tasks in the past few years. These models are mainly targeted for popular programming languages such as Java and Python, leaving out many other ones like R. Though R has a wide community of developers and users, there is little known about the applicability of Code-PLMs for R. In this preliminary study, we aim to investigate the vulnerability of Code-PLMs for code entities in R. For this purpose, we use an R dataset of code and comment pairs and then apply CodeAttack, a black-box attack model that uses the structure of code to generate adversarial code samples. We investigate how the model can attack different entities in R. This is the first step towards understanding the importance of R token types, compared to popular programming languages (e.g., Java). We limit our study to code summarization. Our results show that the most vulnerable code entity is the identifier, followed by some syntax tokens specific to R. The results can shed light on the importance of token types and help in developing models for code summarization and method name prediction for the R language.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "5 pages, 3 figures, and 2 tables. to be published in ICPC 2024"
    },
    {
        "paper id": "2402.04442",
        "abstract url": "https://arxiv.org/abs/2402.04442",
        "title": "Evaluating Embeddings for One-Shot Classification of Doctor-AI Consultations",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "health",
                "healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Effective communication between healthcare providers and patients is crucial to providing high-quality patient care. In this work, we investigate how Doctor-written and AI-generated texts in healthcare consultations can be classified using state-of-the-art embeddings and one-shot classification systems. By analyzing embeddings such as bag-of-words, character n-grams, Word2Vec, GloVe, fastText, and GPT2 embeddings, we examine how well our one-shot classification systems capture semantic information within medical consultations. Results show that the embeddings are capable of capturing semantic features from text in a reliable and adaptable manner. Overall, Word2Vec, GloVe and Character n-grams embeddings performed well, indicating their suitability for modeling targeted to this task. GPT2 embedding also shows notable performance, indicating its suitability for models tailored to this task as well. Our machine learning architectures significantly improved the quality of health conversations when training data are scarce, improving communication between patients and healthcare providers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04446",
        "abstract url": "https://arxiv.org/abs/2402.04446",
        "title": "Pushing the limits of cell segmentation models for imaging mass cytometry",
        "rating": -1,
        "keywords": [
            [
                "biological"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Imaging mass cytometry (IMC) is a relatively new technique for imaging biological tissue at subcellular resolution. In recent years, learning-based segmentation methods have enabled precise quantification of cell type and morphology, but typically rely on large datasets with fully annotated ground truth (GT) labels. This paper explores the effects of imperfect labels on learning-based segmentation models and evaluates the generalisability of these models to different tissue types. Our results show that removing 50% of cell annotations from GT masks only reduces the dice similarity coefficient (DSC) score to 0.874 (from 0.889 achieved by a model trained on fully annotated GT masks). This implies that annotation time can in fact be reduced by at least half without detrimentally affecting performance. Furthermore, training our single-tissue model on imperfect labels only decreases DSC by 0.031 on an unseen tissue type compared to its multi-tissue counterpart, with negligible qualitative differences in segmentation. Additionally, bootstrapping the worst-performing model (with 5% of cell annotations) a total of ten times improves its original DSC score of 0.720 to 0.829. These findings imply that less time and work can be put into the process of producing comparable segmentation models; this includes eliminating the need for multiple IMC tissue types during training, whilst also providing the potential for models with very few labels to improve on themselves. Source code is available on GitHub: https://github.com/kimberley/ISBI2024.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "International Symposium on Biomedical Imaging (ISBI) 2024 Submission"
    },
    {
        "paper id": "2402.04451",
        "abstract url": "https://arxiv.org/abs/2402.04451",
        "title": "Human-guided Swarms: Impedance Control-inspired Influence in Virtual Reality Environments",
        "rating": -1,
        "keywords": [
            [
                "flight"
            ]
        ],
        "abstract": "Prior works in human-swarm interaction (HSI) have sought to guide swarm behavior towards established objectives, but may be unable to handle specific scenarios that require finer human supervision, variable autonomy, or application to large-scale swarms. In this paper, we present an approach that enables human supervisors to tune the level of swarm control, and guide a large swarm using an assistive control mechanism that does not significantly restrict emergent swarm behaviors. We develop this approach in a virtual reality (VR) environment, using the HTC Vive and Unreal Engine 4 with AirSim plugin. The novel combination of an impedance control-inspired influence mechanism and a VR test bed enables and facilitates the rapid design and test iterations to examine trade-offs between swarming behavior and macroscopic-scale human influence, while circumventing flight duration limitations associated with battery-powered small unmanned aerial system (sUAS) systems. The impedance control-inspired mechanism was tested by a human supervisor to guide a virtual swarm consisting of 16 sUAS agents. Each test involved moving the swarm's center of mass through narrow canyons, which were not feasible for a swarm to traverse autonomously. Results demonstrate that integration of the influence mechanism enabled the successful manipulation of the macro-scale behavior of the swarm towards task completion, while maintaining the innate swarming behavior.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "11 pages, 5 figures, preprint"
    },
    {
        "paper id": "2402.04465",
        "abstract url": "https://arxiv.org/abs/2402.04465",
        "title": "BAdaCost: Multi-class Boosting with Costs",
        "rating": -1,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present BAdaCost, a multi-class cost-sensitive classification algorithm. It combines a set of cost-sensitive multi-class weak learners to obtain a strong classification rule within the Boosting framework. To derive the algorithm we introduce CMEL, a Cost-sensitive Multi-class Exponential Loss that generalizes the losses optimized in various classification algorithms such as AdaBoost, SAMME, Cost-sensitive AdaBoost and PIBoost. Hence unifying them under a common theoretical framework. In the experiments performed we prove that BAdaCost achieves significant gains in performance when compared to previous multi-class cost-sensitive approaches. The advantages of the proposed algorithm in asymmetric multi-class classification are also evaluated in practical multi-view face and car detection problems.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04515",
        "abstract url": "https://arxiv.org/abs/2402.04515",
        "title": "A Deep Reinforcement Learning Approach for Adaptive Traffic Routing in Next-gen Networks",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Next-gen networks require significant evolution of management to enable automation and adaptively adjust network configuration based on traffic dynamics. The advent of software-defined networking (SDN) and programmable switches enables flexibility and programmability. However, traditional techniques that decide traffic policies are usually based on hand-crafted programming optimization and heuristic algorithms. These techniques make non-realistic assumptions, e.g., considering static network load and topology, to obtain tractable solutions, which are inadequate for next-gen networks. In this paper, we design and develop a deep reinforcement learning (DRL) approach for adaptive traffic routing. We design a deep graph convolutional neural network (DGCNN) integrated into the DRL framework to learn the traffic behavior from not only the network topology but also link and node attributes. We adopt the Deep Q-Learning technique to train the DGCNN model in the DRL framework without the need for a labeled training dataset, enabling the framework to quickly adapt to traffic dynamics. The model leverages q-value estimates to select the routing path for every traffic flow request, balancing exploration and exploitation. We perform extensive experiments with various traffic patterns and compare the performance of the proposed approach with the Open Shortest Path First (OSPF) protocol. The experimental results show the effectiveness and adaptiveness of the proposed framework by increasing the network throughput by up to 7.8% and reducing the traffic delay by up to 16.1% compared to OSPF.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted for publication in the Proceedings of the IEEE International Conference on Communications (IEEE ICC 2024)"
    },
    {
        "paper id": "2402.04516",
        "abstract url": "https://arxiv.org/abs/2402.04516",
        "title": "Generalized Sobolev Transport for Probability Measures on a Graph",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "We study the optimal transport (OT) problem for measures supported on a graph metric space. Recently, Le et al. (2022) leverage the graph structure and propose a variant of OT, namely Sobolev transport (ST), which yields a closed-form expression for a fast computation. However, ST is essentially coupled with the $L^p$ geometric structure within its definition which makes it nontrivial to utilize ST for other prior structures. In contrast, the classic OT has the flexibility to adapt to various geometric structures by modifying the underlying cost function. An important instance is the Orlicz-Wasserstein (OW) which moves beyond the $L^p$ structure by leveraging the \\emph{Orlicz geometric structure}. Comparing to the usage of standard $p$-order Wasserstein, OW remarkably helps to advance certain machine learning approaches. Nevertheless, OW brings up a new challenge on its computation due to its two-level optimization formulation. In this work, we leverage a specific class of convex functions for Orlicz structure to propose the generalized Sobolev transport (GST). GST encompasses the ST as its special case, and can be utilized for prior structures beyond the $L^p$ geometry. In connection with the OW, we show that one only needs to simply solve a univariate optimization problem to compute the GST, unlike the complex two-level optimization problem in OW. We empirically illustrate that GST is several-order faster than the OW. Moreover, we provide preliminary evidences on the advantages of GST for document classification and for several tasks in topological data analysis.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04522",
        "abstract url": "https://arxiv.org/abs/2402.04522",
        "title": "H-EYE: Holistic Resource Modeling and Management for Diversely Scaled Edge-Cloud Systems",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Computing systems have been evolving to be more pervasive, heterogeneous, and dynamic. An increasing number of emerging domains now rely on diverse edge to cloud continuum where the execution of applications often spans various tiers of systems with significantly heterogeneous computational capabilities. Resources in each tier are often handled in isolation due to scalability and privacy concerns. However, better overall resource utilization could be achieved if different tiers of systems had the means to communicate their computational capabilities. In this paper, we propose H-EYE, a universal approach to holistically capture diverse computational characteristics of edge-cloud systems with arbitrary topologies and to manage the assignment of tasks to the computational resources with the whole continuum in the scope. Our proposed work introduces two significant innovations: (1) We present a multi-layer, graph-based hardware (HW) representation and a modular performance modeling interface that could capture interactions and inference between different computing and communication resources in the system at desired level of detail. (2) We introduce a novel orchestrator mechanism that leverages the graph-based HW representation to hierarchically locate target devices that a given set of tasks could be mapped to. Orchestrator provides isolation for various device groups and allows hierarchical abstraction to scalably find mappings that satisfy system deadlines. The orchestrator internally relies on a novel traverser that takes shared resource slowdown into account. We demonstrate the utility and flexibility of H-EYE on edge-server systems that are deployed on the field in two different disciplines, improving up to 47% latency over baselines with less than 2% scheduling overhead",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04532",
        "abstract url": "https://arxiv.org/abs/2402.04532",
        "title": "Joint Beamforming Design for Double Active RIS-assisted Radar-Communication Coexistence Systems",
        "rating": -1,
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "Integrated sensing and communication (ISAC) technology has been considered as one of the key candidate technologies in the next-generation wireless communication systems. However, when radar and communication equipment coexist in the same system, i.e. radar-communication coexistence (RCC), the interference from communication systems to radar can be large and cannot be ignored. Recently, reconfigurable intelligent surface (RIS) has been introduced into RCC systems to reduce the interference. However, the \"multiplicative fading\" effect introduced by passive RIS limits its performance. To tackle this issue, we consider a double active RIS-assisted RCC system, which focuses on the design of the radar's beamforming vector and the active RISs' reflecting coefficient matrices, to maximize the achievable data rate of the communication system. The considered system needs to meet the radar detection constraint and the power budgets at the radar and the RISs. Since the problem is non-convex, we propose an algorithm based on the penalty dual decomposition (PDD) framework. Specifically, we initially introduce auxiliary variables to reformulate the coupled variables into equation constraints and incorporate these constraints into the objective function through the PDD framework. Then, we decouple the equivalent problem into several subproblems by invoking the block coordinate descent (BCD) method. Furthermore, we employ the Lagrange dual method to alternately optimize these subproblems. Simulation results verify the effectiveness of the proposed algorithm. Furthermore, the results also show that under the same power budget, deploying double active RISs in RCC systems can achieve higher data rate than those with single active RIS and double passive RISs.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04557",
        "abstract url": "https://arxiv.org/abs/2402.04557",
        "title": "An Artificial Intelligence (AI) workflow for catalyst design and optimization",
        "rating": -1,
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "In the pursuit of novel catalyst development to address pressing environmental concerns and energy demand, conventional design and optimization methods often fall short due to the complexity and vastness of the catalyst parameter space. The advent of Machine Learning (ML) has ushered in a new era in the field of catalyst optimization, offering potential solutions to the shortcomings of traditional techniques. However, existing methods fail to effectively harness the wealth of information contained within the burgeoning body of scientific literature on catalyst synthesis. To address this gap, this study proposes an innovative Artificial Intelligence (AI) workflow that integrates Large Language Models (LLMs), Bayesian optimization, and an active learning loop to expedite and enhance catalyst optimization. Our methodology combines advanced language understanding with robust optimization strategies, effectively translating knowledge extracted from diverse literature into actionable parameters for practical experimentation and optimization. In this article, we demonstrate the application of this AI workflow in the optimization of catalyst synthesis for ammonia production. The results underscore the workflow's ability to streamline the catalyst development process, offering a swift, resource-efficient, and high-precision alternative to conventional methods.",
        "subjects": [
            "physics.chem-ph"
        ],
        "comment": "31 pages, 7 figures"
    },
    {
        "paper id": "2402.04566",
        "abstract url": "https://arxiv.org/abs/2402.04566",
        "title": "Triplet-constraint Transformer with Multi-scale Refinement for Dose Prediction in Radiotherapy",
        "rating": -1,
        "keywords": [
            [
                "cancer",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Radiotherapy is a primary treatment for cancers with the aim of applying sufficient radiation dose to the planning target volume (PTV) while minimizing dose hazards to the organs at risk (OARs). Convolutional neural networks (CNNs) have automated the radiotherapy plan-making by predicting the dose maps. However, current CNN-based methods ignore the remarkable dose difference in the dose map, i.e., high dose value in the interior PTV while low value in the exterior PTV, leading to a suboptimal prediction. In this paper, we propose a triplet-constraint transformer (TCtrans) with multi-scale refinement to predict the high-quality dose distribution. Concretely, a novel PTV-guided triplet constraint is designed to refine dose feature representations in the interior and exterior PTV by utilizing the explicit geometry of PTV. Furthermore, we introduce a multi-scale refinement (MSR) module to effectively fulfill the triplet constraint in different decoding layers with multiple scales. Besides, a transformer encoder is devised to learn the important global dosimetric knowledge. Experiments on a clinical cervical cancer dataset demonstrate the superiority of our method.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "accepted by 2024 IEEE ISBI"
    },
    {
        "paper id": "2402.04580",
        "abstract url": "https://arxiv.org/abs/2402.04580",
        "title": "A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "The burgeoning fields of robot learning and embodied AI have triggered an increasing demand for large quantities of data. However, collecting sufficient unbiased data from the target domain remains a challenge due to costly data collection processes and stringent safety requirements. Consequently, researchers often resort to data from easily accessible source domains, such as simulation and laboratory environments, for cost-effective data acquisition and rapid model iteration. Nevertheless, the environments and embodiments of these source domains can be quite different from their target domain counterparts, underscoring the need for effective cross-domain policy transfer approaches. In this paper, we conduct a systematic review of existing cross-domain policy transfer methods. Through a nuanced categorization of domain gaps, we encapsulate the overarching insights and design considerations of each problem setting. We also provide a high-level discussion about the key methodologies used in cross-domain policy transfer problems. Lastly, we summarize the open challenges that lie beyond the capabilities of current paradigms and discuss potential future directions in this field.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04583",
        "abstract url": "https://arxiv.org/abs/2402.04583",
        "title": "A Psychological Study: Importance of Contrast and Luminance in Color to Grayscale Mapping",
        "rating": -1,
        "keywords": [
            [
                "Psychological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Grayscale images are essential in image processing and computer vision tasks. They effectively emphasize luminance and contrast, highlighting important visual features, while also being easily compatible with other algorithms. Moreover, their simplified representation makes them efficient for storage and transmission purposes. While preserving contrast is important for maintaining visual quality, other factors such as preserving information relevant to the specific application or task at hand may be more critical for achieving optimal performance. To evaluate and compare different decolorization algorithms, we designed a psychological experiment. During the experiment, participants were instructed to imagine color images in a hypothetical \"colorless world\" and select the grayscale image that best resembled their mental visualization. We conducted a comparison between two types of algorithms: (i) perceptual-based simple color space conversion algorithms, and (ii) spatial contrast-based algorithms, including iteration-based methods. Our experimental findings indicate that CIELAB exhibited superior performance on average, providing further evidence for the effectiveness of perception-based decolorization algorithms. On the other hand, the spatial contrast-based algorithms showed relatively poorer performance, possibly due to factors such as DC-offset and artificial contrast generation. However, these algorithms demonstrated shorter selection times. Notably, no single algorithm consistently outperformed the others across all test images. In this paper, we will delve into a comprehensive discussion on the significance of contrast and luminance in color-to-grayscale mapping based on our experimental results and analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04584",
        "abstract url": "https://arxiv.org/abs/2402.04584",
        "title": "Troublemaker Learning for Low-Light Image Enhancement",
        "rating": -1,
        "keywords": [
            [
                "Image Enhancement"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Low-light image enhancement (LLIE) restores the color and brightness of underexposed images. Supervised methods suffer from high costs in collecting low/normal-light image pairs. Unsupervised methods invest substantial effort in crafting complex loss functions. We address these two challenges through the proposed TroubleMaker Learning (TML) strategy, which employs normal-light images as inputs for training. TML is simple: we first dim the input and then increase its brightness. TML is based on two core components. First, the troublemaker model (TM) constructs pseudo low-light images from normal images to relieve the cost of pairwise data. Second, the predicting model (PM) enhances the brightness of pseudo low-light images. Additionally, we incorporate an enhancing model (EM) to further improve the visual performance of PM outputs. Moreover, in LLIE tasks, characterizing global element correlations is important because more information on the same object can be captured. CNN cannot achieve this well, and self-attention has high time complexity. Accordingly, we propose Global Dynamic Convolution (GDC) with O(n) time complexity, which essentially imitates the partial calculation process of self-attention to formulate elementwise correlations. Based on the GDC module, we build the UGDC model. Extensive quantitative and qualitative experiments demonstrate that UGDC trained with TML can achieve competitive performance against state-of-the-art approaches on public datasets. The code is available at https://github.com/Rainbowman0/TML_LLIE.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.08688",
        "abstract url": "https://arxiv.org/abs/2402.08688",
        "title": "Context-Aware Automated Passenger Counting Data Denoising",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "A reliable and accurate knowledge of the ridership in public transportation networks is crucial for public transport operators and public authorities to be aware of their network's use and optimize transport offering. Several techniques to estimate ridership exist nowadays, some of them in an automated manner. Among them, Automatic Passenger Counting (APC) systems detect passengers entering and leaving the vehicle at each station of its course. However, data resulting from these systems are often noisy or even biased, resulting in under or overestimation of onboard occupancy. In this work, we propose a denoising algorithm for APC data to improve their robustness and ease their analyzes. The proposed approach consists in a constrained integer linear optimization, taking advantage of ticketing data and historical ridership data to further constrain and guide the optimization. The performances are assessed and compared to other denoising methods on several public transportation networks in France, to manual counts available on one of these networks, and on simulated data.",
        "subjects": [
            "stat.AP"
        ],
        "comment": "Accepted in this version to ITSC 2023"
    },
    {
        "paper id": "2402.03792",
        "abstract url": "https://arxiv.org/abs/2402.03792",
        "title": "No-Regret Reinforcement Learning in Smooth MDPs",
        "rating": -1.5,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Obtaining no-regret guarantees for reinforcement learning (RL) in the case of problems with continuous state and/or action spaces is still one of the major open challenges in the field. Recently, a variety of solutions have been proposed, but besides very specific settings, the general problem remains unsolved. In this paper, we introduce a novel structural assumption on the Markov decision processes (MDPs), namely $\u03bd-$smoothness, that generalizes most of the settings proposed so far (e.g., linear MDPs and Lipschitz MDPs). To face this challenging scenario, we propose two algorithms for regret minimization in $\u03bd-$smooth MDPs. Both algorithms build upon the idea of constructing an MDP representation through an orthogonal feature map based on Legendre polynomials. The first algorithm, \\textsc{Legendre-Eleanor}, archives the no-regret property under weaker assumptions but is computationally inefficient, whereas the second one, \\textsc{Legendre-LSVI}, runs in polynomial time, although for a smaller class of problems. After analyzing their regret properties, we compare our results with state-of-the-art ones from RL theory, showing that our algorithms achieve the best guarantees.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03864",
        "abstract url": "https://arxiv.org/abs/2402.03864",
        "title": "The Challenges of the Nonlinear Regime for Physics-Informed Neural Networks",
        "rating": -1.5,
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Neural Tangent Kernel (NTK) viewpoint represents a valuable approach to examine the training dynamics of Physics-Informed Neural Networks (PINNs) in the infinite width limit. We leverage this perspective and focus on the case of nonlinear Partial Differential Equations (PDEs) solved by PINNs. We provide theoretical results on the different behaviors of the NTK depending on the linearity of the differential operator. Moreover, inspired by our theoretical results, we emphasize the advantage of employing second-order methods for training PINNs. Additionally, we explore the convergence capabilities of second-order methods and address the challenges of spectral bias and slow convergence. Every theoretical result is supported by numerical examples with both linear and nonlinear PDEs, and we validate our training method on benchmark test cases.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 10 figures, appendix of 10 additional pages"
    },
    {
        "paper id": "2402.03924",
        "abstract url": "https://arxiv.org/abs/2402.03924",
        "title": "Network Analysis of U.S. Non-Fatal Opioid-Involved Overdose Journeys, 2018-2023",
        "rating": -1.5,
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "We present a nation-wide network analysis of non-fatal opioid-involved overdose journeys in the United States. Leveraging a unique proprietary dataset of Emergency Medical Services incidents, we construct a journey-to-overdose geospatial network capturing nearly half a million opioid-involved overdose events spanning 2018-2023. We analyze the structure and sociological profile of the nodes, which are counties or their equivalents, characterize the distribution of overdose journey lengths, and investigate changes in the journey network between 2018 and 2023. Our findings include that authority and hub nodes identified by the HITS algorithm tend to be located in urban areas and involved in overdose journeys with particularly long geographical distances.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03941",
        "abstract url": "https://arxiv.org/abs/2402.03941",
        "title": "Discovery of the Hidden World with Large Language Models",
        "rating": -1.5,
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Science originates with discovering new causal knowledge from a combination of known facts and observations. Traditional causal discovery approaches mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. However, the causal variables are usually unavailable in a wide range of real-world applications. The rise of large language models (LLMs) that are trained to learn rich knowledge from the massive observations of the world, provides a new opportunity to assist with discovering high-level hidden variables from the raw observational data. Therefore, we introduce COAT: Causal representatiOn AssistanT. COAT incorporates LLMs as a factor proposer that extracts the potential causal factors from unstructured data. Moreover, LLMs can also be instructed to provide additional information used to collect data values (e.g., annotation criteria) and to further parse the raw unstructured data into structured data. The annotated data will be fed to a causal learning module (e.g., the FCI algorithm) that provides both rigorous explanations of the data, as well as useful feedback to further improve the extraction of causal factors by LLMs. We verify the effectiveness of COAT in uncovering the underlying causal system with two case studies of review rating analysis and neuropathic diagnosis.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preliminary version of an ongoing project; Chenxi and Yongqiang contributed equally; 26 pages, 41 figures; Project page: https://causalcoat.github.io/"
    },
    {
        "paper id": "2402.04033",
        "abstract url": "https://arxiv.org/abs/2402.04033",
        "title": "On provable privacy vulnerabilities of graph representations",
        "rating": -1.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph representation learning (GRL) is critical for extracting insights from complex network structures, but it also raises security concerns due to potential privacy vulnerabilities in these representations. This paper investigates the structural vulnerabilities in graph neural models where sensitive topological information can be inferred through edge reconstruction attacks. Our research primarily addresses the theoretical underpinnings of cosine-similarity-based edge reconstruction attacks (COSERA), providing theoretical and empirical evidence that such attacks can perfectly reconstruct sparse Erdos Renyi graphs with independent random features as graph size increases. Conversely, we establish that sparsity is a critical factor for COSERA's effectiveness, as demonstrated through analysis and experiments on stochastic block models. Finally, we explore the resilience of (provably) private graph representations produced via noisy aggregation (NAG) mechanism against COSERA. We empirically delineate instances wherein COSERA demonstrates both efficacy and deficiency in its capacity to function as an instrument for elucidating the trade-off between privacy and utility.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04046",
        "abstract url": "https://arxiv.org/abs/2402.04046",
        "title": "Generative Modeling of Graphs via Joint Diffusion of Node and Edge Attributes",
        "rating": -1.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Graph generation is integral to various engineering and scientific disciplines. Nevertheless, existing methodologies tend to overlook the generation of edge attributes. However, we identify critical applications where edge attributes are essential, making prior methods potentially unsuitable in such contexts. Moreover, while trivial adaptations are available, empirical investigations reveal their limited efficacy as they do not properly model the interplay among graph components. To address this, we propose a joint score-based model of nodes and edges for graph generation that considers all graph components. Our approach offers two key novelties: (i) node and edge attributes are combined in an attention module that generates samples based on the two ingredients; and (ii) node, edge and adjacency information are mutually dependent during the graph diffusion process. We evaluate our method on challenging benchmarks involving real-world and synthetic datasets in which edge features are crucial. Additionally, we introduce a new synthetic dataset that incorporates edge values. Furthermore, we propose a novel application that greatly benefits from the method due to its nature: the generation of traffic scenes represented as graphs. Our method outperforms other graph generation methods, demonstrating a significant advantage in edge-related measures.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04068",
        "abstract url": "https://arxiv.org/abs/2402.04068",
        "title": "Retrieve to Explain: Evidence-driven Predictions with Language Models",
        "rating": -1.5,
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models, particularly language models, are notoriously difficult to introspect. Black-box models can mask both issues in model training and harmful biases. For human-in-the-loop processes, opaque predictions can drive lack of trust, limiting a model's impact even when it performs effectively. To address these issues, we introduce Retrieve to Explain (R2E). R2E is a retrieval-based language model that prioritizes amongst a pre-defined set of possible answers to a research question based on the evidence in a document corpus, using Shapley values to identify the relative importance of pieces of evidence to the final prediction. R2E can adapt to new evidence without retraining, and incorporate structured data through templating into natural language. We assess on the use case of drug target identification from published scientific literature, where we show that the model outperforms an industry-standard genetics-based approach on predicting clinical trial outcomes.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04105",
        "abstract url": "https://arxiv.org/abs/2402.04105",
        "title": "Measuring Implicit Bias in Explicitly Unbiased Large Language Models",
        "rating": -1.5,
        "keywords": [
            [
                "health",
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Large language models (LLMs) can pass explicit bias tests but still harbor implicit biases, similar to humans who endorse egalitarian beliefs yet exhibit subtle biases. Measuring such implicit biases can be a challenge: as LLMs become increasingly proprietary, it may not be possible to access their embeddings and apply existing bias measures; furthermore, implicit biases are primarily a concern if they affect the actual decisions that these systems make. We address both of these challenges by introducing two measures of bias inspired by psychology: LLM Implicit Association Test (IAT) Bias, which is a prompt-based method for revealing implicit bias; and LLM Decision Bias for detecting subtle discrimination in decision-making tasks. Using these measures, we found pervasive human-like stereotype biases in 6 LLMs across 4 social domains (race, gender, religion, health) and 21 categories (weapons, guilt, science, career among others). Our prompt-based measure of implicit bias correlates with embedding-based methods but better predicts downstream behaviors measured by LLM Decision Bias. This measure is based on asking the LLM to decide between individuals, motivated by psychological results indicating that relative not absolute evaluations are more related to implicit biases. Using prompt-based measures informed by psychology allows us to effectively expose nuanced biases and subtle discrimination in proprietary LLMs that do not show explicit bias on standard benchmarks.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04209",
        "abstract url": "https://arxiv.org/abs/2402.04209",
        "title": "Acute kidney injury prediction for non-critical care patients: a retrospective external and internal validation study",
        "rating": -1.5,
        "keywords": [
            [
                "Medical",
                "Health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Background: Acute kidney injury (AKI), the decline of kidney excretory function, occurs in up to 18% of hospitalized admissions. Progression of AKI may lead to irreversible kidney damage. Methods: This retrospective cohort study includes adult patients admitted to a non-intensive care unit at the University of Pittsburgh Medical Center (UPMC) (n = 46,815) and University of Florida Health (UFH) (n = 127,202). We developed and compared deep learning and conventional machine learning models to predict progression to Stage 2 or higher AKI within the next 48 hours. We trained local models for each site (UFH Model trained on UFH, UPMC Model trained on UPMC) and a separate model with a development cohort of patients from both sites (UFH-UPMC Model). We internally and externally validated the models on each site and performed subgroup analyses across sex and race. Results: Stage 2 or higher AKI occurred in 3% (n=3,257) and 8% (n=2,296) of UFH and UPMC patients, respectively. Area under the receiver operating curve values (AUROC) for the UFH test cohort ranged between 0.77 (UPMC Model) and 0.81 (UFH Model), while AUROC values ranged between 0.79 (UFH Model) and 0.83 (UPMC Model) for the UPMC test cohort. UFH-UPMC Model achieved an AUROC of 0.81 (95% confidence interval [CI] [0.80, 0.83]) for UFH and 0.82 (95% CI [0.81,0.84]) for UPMC test cohorts; an area under the precision recall curve values (AUPRC) of 0.6 (95% CI, [0.05, 0.06]) for UFH and 0.13 (95% CI, [0.11,0.15]) for UPMC test cohorts. Kinetic estimated glomerular filtration rate, nephrotoxic drug burden and blood urea nitrogen remained the top three features with the highest influence across the models and health centers. Conclusion: Locally developed models displayed marginally reduced discrimination when tested on another institution, while the top set of influencing features remained the same across the models and sites.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04290",
        "abstract url": "https://arxiv.org/abs/2402.04290",
        "title": "CasCast: Skillful High-resolution Precipitation Nowcasting via Cascaded Modelling",
        "rating": -1.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "radar"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Precipitation nowcasting based on radar data plays a crucial role in extreme weather prediction and has broad implications for disaster management. Despite progresses have been made based on deep learning, two key challenges of precipitation nowcasting are not well-solved: (i) the modeling of complex precipitation system evolutions with different scales, and (ii) accurate forecasts for extreme precipitation. In this work, we propose CasCast, a cascaded framework composed of a deterministic and a probabilistic part to decouple the predictions for mesoscale precipitation distributions and small-scale patterns. Then, we explore training the cascaded framework at the high resolution and conducting the probabilistic modeling in a low dimensional latent space with a frame-wise-guided diffusion transformer for enhancing the optimization of extreme events while reducing computational costs. Extensive experiments on three benchmark radar precipitation datasets show that CasCast achieves competitive performance. Especially, CasCast significantly surpasses the baseline (up to +91.8%) for regional extreme-precipitation nowcasting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04338",
        "abstract url": "https://arxiv.org/abs/2402.04338",
        "title": "Logical recognition method for solving the problem of identification in the Internet of Things",
        "rating": -1.5,
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "A new area of application of methods of algebra of logic and to valued logic, which has emerged recently, is the problem of recognizing a variety of objects and phenomena, medical or technical diagnostics, constructing modern machines, checking test problems, etc., which can be reduced to constructing an optimal extension of the logical function to the entire feature space. For example, in logical recognition systems, logical methods based on discrete analysis and propositional calculus based on it are used to build their own recognition algorithms. In the general case, the use of a logical recognition method provides for the presence of logical connections expressed by the optimal continuation of a k-valued function over the entire feature space, in which the variables are the logical features of the objects or phenomena being recognized. The goal of this work is to develop a logical method for object recognition consisting of a reference table with logical features and classes of non-intersecting objects, which are specified as vectors from a given feature space. The method consists of considering the reference table as a logical function that is not defined everywhere and constructing an optimal continuation of the logical function to the entire feature space, which determines the extension of classes to the entire space.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "I will rework and improve it and post it again"
    },
    {
        "paper id": "2402.04340",
        "abstract url": "https://arxiv.org/abs/2402.04340",
        "title": "Skills in computational thinking of engineering students of the first school year",
        "rating": -1.5,
        "keywords": [
            [
                "CT"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "In this world of the digital era, in which we are living, one of the fundamental competences that students must acquire is the competence in Computational Thinking (CT). Although there is no general consensus on a formal definition, there is a general understanding of it as a set of skills and attitudes necessary for the resolution, with or without a computer, of problems that may arise in any area of life. Measuring and evaluating which of the CT skills students have acquired is fundamental, and for this purpose, previously validated measuring instruments must be used. In this study, a previously validated instrument is applied to know if the new students in the Engineering Degrees of the University of the Basque Country have the following skills in CT: Critical Thinking, Algorithmic Thinking, Problem Solving, Cooperativity and Creativity.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04390",
        "abstract url": "https://arxiv.org/abs/2402.04390",
        "title": "Densely Multiplied Physics Informed Neural Networks",
        "rating": -1.5,
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although physics-informed neural networks (PINNs) have shown great potential in dealing with nonlinear partial differential equations (PDEs), it is common that PINNs will suffer from the problem of insufficient precision or obtaining incorrect outcomes. Unlike most of the existing solutions trying to enhance the ability of PINN by optimizing the training process, this paper improved the neural network architecture to improve the performance of PINN. We propose a densely multiply PINN (DM-PINN) architecture, which multiplies the output of a hidden layer with the outputs of all the behind hidden layers. Without introducing more trainable parameters, this effective mechanism can significantly improve the accuracy of PINNs. The proposed architecture is evaluated on four benchmark examples (Allan-Cahn equation, Helmholtz equation, Burgers equation and 1D convection equation). Comparisons between the proposed architecture and different PINN structures demonstrate the superior performance of the DM-PINN in both accuracy and efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, 9 figures"
    },
    {
        "paper id": "2402.04400",
        "abstract url": "https://arxiv.org/abs/2402.04400",
        "title": "CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines",
        "rating": -1.5,
        "keywords": [
            [
                "Medical",
                "Health",
                "healthcare",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in advancing healthcare applications and machine learning models, particularly for researchers without direct access to healthcare data. Although existing methods, like rule-based approaches and generative adversarial networks (GANs), generate synthetic data that resembles real-world EHR data, these methods often use a tabular format, disregarding temporal dependencies in patient histories and limiting data replication. Recently, there has been a growing interest in leveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables applications like disease progression analysis, population estimation, counterfactual reasoning, and synthetic data generation. In this work, we focus on synthetic data generation and demonstrate the capability of training a GPT model using a particular patient representation derived from CEHR-BERT, enabling us to generate patient sequences that can be seamlessly converted to the Observational Medical Outcomes Partnership (OMOP) data format.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04409",
        "abstract url": "https://arxiv.org/abs/2402.04409",
        "title": "Towards Fair, Robust and Efficient Client Contribution Evaluation in Federated Learning",
        "rating": -1.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The performance of clients in Federated Learning (FL) can vary due to various reasons. Assessing the contributions of each client is crucial for client selection and compensation. It is challenging because clients often have non-independent and identically distributed (non-iid) data, leading to potentially noisy or divergent updates. The risk of malicious clients amplifies the challenge especially when there's no access to clients' local data or a benchmark root dataset. In this paper, we introduce a novel method called Fair, Robust, and Efficient Client Assessment (FRECA) for quantifying client contributions in FL. FRECA employs a framework called FedTruth to estimate the global model's ground truth update, balancing contributions from all clients while filtering out impacts from malicious ones. This approach is robust against Byzantine attacks and incorporates a Byzantine-resilient aggregation algorithm. FRECA is also efficient, as it operates solely on local model updates and requires no validation operations or datasets. Our experimental results show that FRECA can accurately and efficiently quantify client contributions in a robust manner.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04412",
        "abstract url": "https://arxiv.org/abs/2402.04412",
        "title": "The VampPrior Mixture Model",
        "rating": -1.5,
        "keywords": [
            [
                "biologically"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Current clustering priors for deep latent variable models (DLVMs) require defining the number of clusters a-priori and are susceptible to poor initializations. Addressing these deficiencies could greatly benefit deep learning-based scRNA-seq analysis by performing integration and clustering simultaneously. We adapt the VampPrior (Tomczak & Welling, 2018) into a Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture Model (VMM), a novel prior for DLVMs. We propose an inference procedure that alternates between variational inference and Empirical Bayes to cleanly distinguish variational and prior parameters. Using the VMM in a Variational Autoencoder attains highly competitive clustering performance on benchmark datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration method, with the VMM significantly improves its performance and automatically arranges cells into biologically meaningful clusters.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04417",
        "abstract url": "https://arxiv.org/abs/2402.04417",
        "title": "Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit",
        "rating": -1.5,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study a robust multi-agent multi-armed bandit problem where multiple clients or participants are distributed on a fully decentralized blockchain, with the possibility of some being malicious. The rewards of arms are homogeneous among the clients, following time-invariant stochastic distributions that are revealed to the participants only when the system is secure enough. The system's objective is to efficiently ensure the cumulative rewards gained by the honest participants. To this end and to the best of our knowledge, we are the first to incorporate advanced techniques from blockchains, as well as novel mechanisms, into the system to design optimal strategies for honest participants. This allows various malicious behaviors and the maintenance of participant privacy. More specifically, we randomly select a pool of validators who have access to all participants, design a brand-new consensus mechanism based on digital signatures for these validators, invent a UCB-based strategy that requires less information from participants through secure multi-party computation, and design the chain-participant interaction and an incentive mechanism to encourage participants' participation. Notably, we are the first to prove the theoretical guarantee of the proposed algorithms by regret analyses in the context of optimality in blockchains. Unlike existing work that integrates blockchains with learning problems such as federated learning which mainly focuses on numerical optimality, we demonstrate that the regret of honest participants is upper bounded by $log{T}$. This is consistent with the multi-agent multi-armed bandit problem without malicious participants and the robust multi-agent multi-armed bandit problem with purely Byzantine attacks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2402.04420",
        "abstract url": "https://arxiv.org/abs/2402.04420",
        "title": "Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways",
        "rating": -1.5,
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "As machine learning applications proliferate, we need an understanding of their potential for harm. However, current fairness metrics are rarely grounded in human psychological experiences of harm. Drawing on the social psychology of stereotypes, we use a case study of gender stereotypes in image search to examine how people react to machine learning errors. First, we use survey studies to show that not all machine learning errors reflect stereotypes nor are equally harmful. Then, in experimental studies we randomly expose participants to stereotype-reinforcing, -violating, and -neutral machine learning errors. We find stereotype-reinforcing errors induce more experientially (i.e., subjectively) harmful experiences, while having minimal changes to cognitive beliefs, attitudes, or behaviors. This experiential harm impacts women more than men. However, certain stereotype-violating errors are more experientially harmful for men, potentially due to perceived threats to masculinity. We conclude that harm cannot be the sole guide in fairness mitigation, and propose a nuanced perspective depending on who is experiencing what harm and why.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "earlier draft non-archival at EAAMO 2023"
    },
    {
        "paper id": "2402.04470",
        "abstract url": "https://arxiv.org/abs/2402.04470",
        "title": "Large language models as probes into latent psychology",
        "rating": -1.5,
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Advances in AI invite the misuse of language models as stand-ins for human minds or participants, which fundamentally mischaracterizes these statistical algorithms. We argue that language models should be embraced as flexible simulation tools, able to mimic a wide range of behaviors, perspectives, and psychological attributes evident in human language data, but the models themselves should not be equated to or anthropomorphized as human minds.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "8 pages, 1 table"
    },
    {
        "paper id": "2402.04523",
        "abstract url": "https://arxiv.org/abs/2402.04523",
        "title": "SumRec: A Framework for Recommendation using Open-Domain Dialogue",
        "rating": -1.5,
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Chat dialogues contain considerable useful information about a speaker's interests, preferences, and experiences.Thus, knowledge from open-domain chat dialogue can be used to personalize various systems and offer recommendations for advanced information.This study proposed a novel framework SumRec for recommending information from open-domain chat dialogue.The study also examined the framework using ChatRec, a newly constructed dataset for training and evaluation. To extract the speaker and item characteristics, the SumRec framework employs a large language model (LLM) to generate a summary of the speaker information from a dialogue and to recommend information about an item according to the type of user.The speaker and item information are then input into a score estimation model, generating a recommendation score.Experimental results show that the SumRec framework provides better recommendations than the baseline method of using dialogues and item descriptions in their original form. Our dataset and code is publicly available at https://github.com/Ryutaro-A/SumRec",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to PACLIC 2023"
    },
    {
        "paper id": "2402.03721",
        "abstract url": "https://arxiv.org/abs/2402.03721",
        "title": "Enhancing Embodied Object Detection through Language-Image Pre-training and Implicit Object Memory",
        "rating": -2,
        "keywords": [
            [
                "depth"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Deep-learning and large scale language-image training have produced image object detectors that generalise well to diverse environments and semantic classes. However, single-image object detectors trained on internet data are not optimally tailored for the embodied conditions inherent in robotics. Instead, robots must detect objects from complex multi-modal data streams involving depth, localisation and temporal correlation, a task termed embodied object detection. Paradigms such as Video Object Detection (VOD) and Semantic Mapping have been proposed to leverage such embodied data streams, but existing work fails to enhance performance using language-image training. In response, we investigate how an image object detector pre-trained using language-image data can be extended to perform embodied object detection. We propose a novel implicit object memory that uses projective geometry to aggregate the features of detected objects across long temporal horizons. The spatial and temporal information accumulated in memory is then used to enhance the image features of the base detector. When tested on embodied data streams sampled from diverse indoor scenes, our approach improves the base object detector by 3.09 mAP, outperforming alternative external memories designed for VOD and Semantic Mapping. Our method also shows a significant improvement of 16.90 mAP relative to baselines that perform embodied object detection without first training on language-image data, and is robust to sensor noise and domain shift experienced in real-world deployment.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03723",
        "abstract url": "https://arxiv.org/abs/2402.03723",
        "title": "Rig3DGS: Creating Controllable Portraits from Casual Monocular Videos",
        "rating": -2,
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "synthesis"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Creating controllable 3D human portraits from casual smartphone videos is highly desirable due to their immense value in AR/VR applications. The recent development of 3D Gaussian Splatting (3DGS) has shown improvements in rendering quality and training efficiency. However, it still remains a challenge to accurately model and disentangle head movements and facial expressions from a single-view capture to achieve high-quality renderings. In this paper, we introduce Rig3DGS to address this challenge. We represent the entire scene, including the dynamic subject, using a set of 3D Gaussians in a canonical space. Using a set of control signals, such as head pose and expressions, we transform them to the 3D space with learned deformations to generate the desired rendering. Our key innovation is a carefully designed deformation method which is guided by a learnable prior derived from a 3D morphable model. This approach is highly efficient in training and effective in controlling facial expressions, head positions, and view synthesis across various captures. We demonstrate the effectiveness of our learned deformation through extensive quantitative and qualitative experiments. The project page can be found at http://shahrukhathar.github.io/2024/02/05/Rig3DGS.html",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03754",
        "abstract url": "https://arxiv.org/abs/2402.03754",
        "title": "Intensive Vision-guided Network for Radiology Report Generation",
        "rating": -2,
        "keywords": [
            [
                "depth"
            ],
            [
                "medical",
                "healthcare",
                "diagnosis",
                "X-Ray",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic radiology report generation is booming due to its huge application potential for the healthcare industry. However, existing computer vision and natural language processing approaches to tackle this problem are limited in two aspects. First, when extracting image features, most of them neglect multi-view reasoning in vision and model single-view structure of medical images, such as space-view or channel-view. However, clinicians rely on multi-view imaging information for comprehensive judgment in daily clinical diagnosis. Second, when generating reports, they overlook context reasoning with multi-modal information and focus on pure textual optimization utilizing retrieval-based methods. We aim to address these two issues by proposing a model that better simulates clinicians' perspectives and generates more accurate reports. Given the above limitation in feature extraction, we propose a Globally-intensive Attention (GIA) module in the medical image encoder to simulate and integrate multi-view vision perception. GIA aims to learn three types of vision perception: depth view, space view, and pixel view. On the other hand, to address the above problem in report generation, we explore how to involve multi-modal signals to generate precisely matched reports, i.e., how to integrate previously predicted words with region-aware visual content in next word prediction. Specifically, we design a Visual Knowledge-guided Decoder (VKGD), which can adaptively consider how much the model needs to rely on visual information and previously predicted text to assist next word prediction. Hence, our final Intensive Vision-guided Network (IVGN) framework includes a GIA-guided Visual Encoder and the VKGD. Experiments on two commonly-used datasets IU X-Ray and MIMIC-CXR demonstrate the superior ability of our method compared with other state-of-the-art approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by Physics in Medicine & Biology"
    },
    {
        "paper id": "2402.03769",
        "abstract url": "https://arxiv.org/abs/2402.03769",
        "title": "AttackNet: Enhancing Biometric Security via Tailored Convolutional Neural Network Architectures for Liveness Detection",
        "rating": -2,
        "keywords": [
            [
                "attacks"
            ],
            [
                "Biometric"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Biometric security is the cornerstone of modern identity verification and authentication systems, where the integrity and reliability of biometric samples is of paramount importance. This paper introduces AttackNet, a bespoke Convolutional Neural Network architecture, meticulously designed to combat spoofing threats in biometric systems. Rooted in deep learning methodologies, this model offers a layered defense mechanism, seamlessly transitioning from low-level feature extraction to high-level pattern discernment. Three distinctive architectural phases form the crux of the model, each underpinned by judiciously chosen activation functions, normalization techniques, and dropout layers to ensure robustness and resilience against adversarial attacks. Benchmarking our model across diverse datasets affirms its prowess, showcasing superior performance metrics in comparison to contemporary models. Furthermore, a detailed comparative analysis accentuates the model's efficacy, drawing parallels with prevailing state-of-the-art methodologies. Through iterative refinement and an informed architectural strategy, AttackNet underscores the potential of deep learning in safeguarding the future of biometric security.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03801",
        "abstract url": "https://arxiv.org/abs/2402.03801",
        "title": "On Practical Diversified Recommendation with Controllable Category Diversity Framework",
        "rating": -2,
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recommender systems have made significant strides in various industries, primarily driven by extensive efforts to enhance recommendation accuracy. However, this pursuit of accuracy has inadvertently given rise to echo chamber/filter bubble effects. Especially in industry, it could impair user's experiences and prevent user from accessing a wider range of items. One of the solutions is to take diversity into account. However, most of existing works focus on user's explicit preferences, while rarely exploring user's non-interaction preferences. These neglected non-interaction preferences are especially important for broadening user's interests in alleviating echo chamber/filter bubble effects.Therefore, in this paper, we first define diversity as two distinct definitions, i.e., user-explicit diversity (U-diversity) and user-item non-interaction diversity (N-diversity) based on user historical behaviors. Then, we propose a succinct and effective method, named as Controllable Category Diversity Framework (CCDF) to achieve both high U-diversity and N-diversity simultaneously.Specifically, CCDF consists of two stages, User-Category Matching and Constrained Item Matching. The User-Category Matching utilizes the DeepU2C model and a combined loss to capture user's preferences in categories, and then selects the top-$K$ categories with a controllable parameter $K$.These top-$K$ categories will be used as trigger information in Constrained Item Matching. Offline experimental results show that our proposed DeepU2C outperforms state-of-the-art diversity-oriented methods, especially on N-diversity task. The whole framework is validated in a real-world production environment by conducting online A/B testing.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "A Two-stage Controllable Category Diversity Framework for Recommendation"
    },
    {
        "paper id": "2402.03834",
        "abstract url": "https://arxiv.org/abs/2402.03834",
        "title": "Enhanced Security and Efficiency in Blockchain with Aggregated Zero-Knowledge Proof Mechanisms",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "Blockchain technology has emerged as a revolutionary tool in ensuring data integrity and security in digital transactions. However, the current approaches to data verification in blockchain systems, particularly in Ethereum, face challenges in terms of efficiency and computational overhead. The traditional use of Merkle Trees and cryptographic hash functions, while effective, leads to significant resource consumption, especially for large datasets. This highlights a gap in existing research: the need for more efficient methods of data verification in blockchain networks. Our study addresses this gap by proposing an innovative aggregation scheme for Zero-Knowledge Proofs within the structure of Merkle Trees. We develop a system that significantly reduces the size of the proof and the computational resources needed for its generation and verification. Our approach represents a paradigm shift in blockchain data verification, balancing security with efficiency. We conducted extensive experimental evaluations using real Ethereum block data to validate the effectiveness of our proposed scheme. The results demonstrate a drastic reduction in proof size and computational requirements compared to traditional methods, making the verification process more efficient and economically viable. Our contribution fills a critical research void, offering a scalable and secure solution for blockchain data verification. The implications of our work are far-reaching, enhancing the overall performance and adaptability of blockchain technology in various applications, from financial transactions to supply chain management.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages, 7 figures"
    },
    {
        "paper id": "2402.03865",
        "abstract url": "https://arxiv.org/abs/2402.03865",
        "title": "Design and implementation of multiprotocol framework for residential prosumer incorporation in flexibility markets",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The growth of distributed renewable energy in the electrical grid presents challenges to its stability and quality. To address this at the local level, flexibility energy strategies emerge as an innovative technique. However, managing these strategies in residential areas becomes complex due to the unique characteristics of each prosumer. A major challenge lies in managing communication among diverse devices with different protocols. To address these issues, a comprehensive framework is designed and implemented to facilitate prosumers' integration in flexibility strategies, addressing communication at various levels. The effectiveness of the proposed framework is demonstrated through its implementation in a real smart home environment with diverse devices. The framework enables seamless integration and communication between IoT devices and IEC 61,850-compliant power devices. This research presents a novel approach to address the challenges of managing flexibility strategies in residential areas, providing a practical solution for prosumers to actively participate in optimizing energy consumption and enhancing the stability and quality of the electricity system amidst the growing integration of distributed renewable energy.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03907",
        "abstract url": "https://arxiv.org/abs/2402.03907",
        "title": "Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy",
        "rating": -2,
        "keywords": [
            [
                "biometric"
            ]
        ],
        "abstract": "Recent developments in computer graphics, hardware, artificial intelligence (AI), and human-computer interaction likely lead to extended reality (XR) devices and setups being more pervasive. While these devices and setups provide users with interactive, engaging, and immersive experiences with different sensing modalities, such as eye and hand trackers, many non-player characters are utilized in a pre-scripted way or by conventional AI techniques. In this paper, we argue for using large language models (LLMs) in XR by embedding them in virtual avatars or as narratives to facilitate more inclusive experiences through prompt engineering according to user profiles and fine-tuning the LLMs for particular purposes. We argue that such inclusion will facilitate diversity for XR use. In addition, we believe that with the versatile conversational capabilities of LLMs, users will engage more with XR environments, which might help XR be more used in everyday life. Lastly, we speculate that combining the information provided to LLM-powered environments by the users and the biometric data obtained through the sensors might lead to novel privacy invasions. While studying such possible privacy invasions, user privacy concerns and preferences should also be investigated. In summary, despite some challenges, embedding LLMs into XR is a promising and novel research area with several opportunities.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03918",
        "abstract url": "https://arxiv.org/abs/2402.03918",
        "title": "Dynastic Potential Crossover Operator",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "An optimal recombination operator for two parent solutions provides the best solution among those that take the value for each variable from one of the parents (gene transmission property). If the solutions are bit strings, the offspring of an optimal recombination operator is optimal in the smallest hyperplane containing the two parent solutions. Exploring this hyperplane is computationally costly, in general, requiring exponential time in the worst case. However, when the variable interaction graph of the objective function is sparse, exploration can be done in polynomial time. In this paper, we present a recombination operator, called Dynastic Potential Crossover (DPX), that runs in polynomial time and behaves like an optimal recombination operator for low-epistasis combinatorial problems. We compare this operator, both theoretically and experimentally, with traditional crossover operators, like uniform crossover and network crossover, and with two recently defined efficient recombination operators: partition crossover and articulation points partition crossover. The empirical comparison uses NKQ Landscapes and MAX-SAT instances. DPX outperforms the other crossover operators in terms of quality of the offspring and provides better results included in a trajectory and a population-based metaheuristic, but it requires more time and memory to compute the offspring.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03922",
        "abstract url": "https://arxiv.org/abs/2402.03922",
        "title": "Competitive advantage of URLLC vs. eMBB for supporting timeliness-relevant services",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "5G specifications promise a common and flexible-enough network infrastructure capable of satisfying diverse requirements of both current and future use cases. Two service types standardized in 5G are eMBB, without stringent delay guarantee, and URLLC, with stringent delay guarantee. We focus on a use case where data timeliness is the relevant quality parameter. We provide an economic rationale for the support of data-based services, that is, from the point of view of the profits attained by the service providers and operators (SP). More specifically, we focus on data-based services the quality of which is related to the Age of Information, and we assess two alternatives for the support of this sort of services by means of a 5G network: one that is based on the eMBB service type, and one that is based on the URLLC service type. These assessment is conducted in a duopoly scenario. We conclude that URLLC support provides a competitive advantage to an SP against a competitor SP that supports its service offering on eMBB. And that there is a slightly better situation for the users when the URLLC QoS constraint is stringent.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03931",
        "abstract url": "https://arxiv.org/abs/2402.03931",
        "title": "Fully autonomous tuning of a spin qubit",
        "rating": -2,
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Spanning over two decades, the study of qubits in semiconductors for quantum computing has yielded significant breakthroughs. However, the development of large-scale semiconductor quantum circuits is still limited by challenges in efficiently tuning and operating these circuits. Identifying optimal operating conditions for these qubits is complex, involving the exploration of vast parameter spaces. This presents a real 'needle in the haystack' problem, which, until now, has resisted complete automation due to device variability and fabrication imperfections. In this study, we present the first fully autonomous tuning of a semiconductor qubit, from a grounded device to Rabi oscillations, a clear indication of successful qubit operation. We demonstrate this automation, achieved without human intervention, in a Ge/Si core/shell nanowire device. Our approach integrates deep learning, Bayesian optimization, and computer vision techniques. We expect this automation algorithm to apply to a wide range of semiconductor qubit devices, allowing for statistical studies of qubit quality metrics. As a demonstration of the potential of full automation, we characterise how the Rabi frequency and g-factor depend on barrier gate voltages for one of the qubits found by the algorithm. Twenty years after the initial demonstrations of spin qubit operation, this significant advancement is poised to finally catalyze the operation of large, previously unexplored quantum circuits.",
        "subjects": [
            "cond-mat.mes-hall"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03957",
        "abstract url": "https://arxiv.org/abs/2402.03957",
        "title": "Sparse Graph Representations for Procedural Instructional Documents",
        "rating": -2,
        "keywords": [
            [
                "Graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Computation of document similarity is a critical task in various NLP domains that has applications in deduplication, matching, and recommendation. Traditional approaches for document similarity computation include learning representations of documents and employing a similarity or a distance function over the embeddings. However, pairwise similarities and differences are not efficiently captured by individual representations. Graph representations such as Joint Concept Interaction Graph (JCIG) represent a pair of documents as a joint undirected weighted graph. JCIGs facilitate an interpretable representation of document pairs as a graph. However, JCIGs are undirected, and don't consider the sequential flow of sentences in documents. We propose two approaches to model document similarity by representing document pairs as a directed and sparse JCIG that incorporates sequential information. We propose two algorithms inspired by Supergenome Sorting and Hamiltonian Path that replace the undirected edges with directed edges. Our approach also sparsifies the graph to $O(n)$ edges from JCIG's worst case of $O(n^2)$. We show that our sparse directed graph model architecture consisting of a Siamese encoder and GCN achieves comparable results to the baseline on datasets not containing sequential information and beats the baseline by ten points on an instructional documents dataset containing sequential information.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03963",
        "abstract url": "https://arxiv.org/abs/2402.03963",
        "title": "A Novel Local and Hyper-Local Multicast Services Transmission Scheme for Beyond 5G Networks",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "The efficiency of the broadcast network is impacted by the different types of services that may be transmitted over it. Global services serve users across the entire network, while local services cater to specific regions, and hyper-local services have even narrower coverage. Multimedia Broadcast over a Single-Frequency Network (MBSFN) is typically used for global service transmission while existing literature extensively discusses schemes for transmitting local or hyper-local services with or without Single Frequency Network (SFN) gain. However, these schemes fall short when network-wide requests for only local and hyper-local services are made, leading operators to scale down to either Single Cell-Point to Multipoint (SCPtM) or Multi-Frequency Network (MFN). SCPtM is highly susceptible to interference, and MFN requires substantial amounts of valuable spectrum. They both employ the Least Channel Gain (LCG) strategy for transmitting hyper-local services without SFN gain. Our proposed Local and Hyper-Local Services (LHS) transmission scheme utilizes the knowledge of user distribution and their corresponding radio link channel quality to schedule single or multi-resolution, local or hyper-local services within a three-cell cluster and aims to enhance spectral efficiency and maximize system throughput. It leverages Scalable Video Coding (SVC) in conjunction with Hierarchical Modulation (HM) for transmitting multi-resolution multimedia content to address the problem of heterogeneity amongst the multicast group users. The proposed scheme also employs macro-diversity combining with optimal HM parameters for each gNB catering to a local service area in order to minimize the service outage. System-level simulation results testify to the better performance achieved by the proposed LHS transmission scheme with respect to SCPtM.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "12 pages, 18 figures, 2 tables, 3 algorithms"
    },
    {
        "paper id": "2402.03992",
        "abstract url": "https://arxiv.org/abs/2402.03992",
        "title": "Space Group Constrained Crystal Generation",
        "rating": -2.0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Crystals are the foundation of numerous scientific and industrial applications. While various learning-based approaches have been proposed for crystal generation, existing methods seldom consider the space group constraint which is crucial in describing the geometry of crystals and closely relevant to many desirable properties. However, considering space group constraint is challenging owing to its diverse and nontrivial forms. In this paper, we reduce the space group constraint into an equivalent formulation that is more tractable to be handcrafted into the generation process. In particular, we translate the space group constraint into two parts: the basis constraint of the invariant logarithmic space of the lattice matrix and the Wyckoff position constraint of the fractional coordinates. Upon the derived constraints, we then propose DiffCSP++, a novel diffusion model that has enhanced a previous work DiffCSP by further taking space group constraint into account. Experiments on several popular datasets verify the benefit of the involvement of the space group constraint, and show that our DiffCSP++ achieves promising performance on crystal structure prediction, ab initio crystal generation and controllable generation with customized space groups.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR 2024 poster"
    },
    {
        "paper id": "2402.04031",
        "abstract url": "https://arxiv.org/abs/2402.04031",
        "title": "Polyp-DDPM: Diffusion-Based Semantic Polyp Synthesis for Enhanced Segmentation",
        "rating": -2,
        "keywords": [
            [
                "Diffusion",
                "Synthesis"
            ],
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study introduces Polyp-DDPM, a diffusion-based method for generating realistic images of polyps conditioned on masks, aimed at enhancing the segmentation of gastrointestinal (GI) tract polyps. Our approach addresses the challenges of data limitations, high annotation costs, and privacy concerns associated with medical images. By conditioning the diffusion model on segmentation masks-binary masks that represent abnormal areas-Polyp-DDPM outperforms state-of-the-art methods in terms of image quality (achieving a Frechet Inception Distance (FID) score of 78.47, compared to scores above 83.79) and segmentation performance (achieving an Intersection over Union (IoU) of 0.7156, versus less than 0.6694 for synthetic images from baseline models and 0.7067 for real data). Our method generates a high-quality, diverse synthetic dataset for training, thereby enhancing polyp segmentation models to be comparable with real images and offering greater data augmentation capabilities to improve segmentation models. The source code and pretrained weights for Polyp-DDPM are made publicly available at https://github.com/mobaidoctor/polyp-ddpm.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2402.04045",
        "abstract url": "https://arxiv.org/abs/2402.04045",
        "title": "Mission Planning and Safety Assessment for Pipeline Inspection Using Autonomous Underwater Vehicles: A Framework based on Behavior Trees",
        "rating": -2,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "The recent advance in autonomous underwater robotics facilitates autonomous inspection tasks of offshore infrastructure. However, current inspection missions rely on predefined plans created offline, hampering the flexibility and autonomy of the inspection vehicle and the mission's success in case of unexpected events. In this work, we address these challenges by proposing a framework encompassing the modeling and verification of mission plans through Behavior Trees (BTs). This framework leverages the modularity of BTs to model onboard reactive behaviors, thus enabling autonomous plan executions, and uses BehaVerify to verify the mission's safety. Moreover, as a use case of this framework, we present a novel AI-enabled algorithm that aims for efficient, autonomous pipeline camera data collection. In a simulated environment, we demonstrate the framework's application to our proposed pipeline inspection algorithm. Our framework marks a significant step forward in the field of autonomous underwater robotics, promising to enhance the safety and success of underwater missions in practical, real-world applications. https://github.com/remaro-network/pipe_inspection_mission",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04079",
        "abstract url": "https://arxiv.org/abs/2402.04079",
        "title": "Design and implementation of a real-time onboard system for a stratospheric balloon mission using commercial off-the-self components and a model-based approach",
        "rating": -2,
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "Stratospheric balloons have emerged as an affordable and flexible alternative to traditional spacecrafts as they are implemented using commercial off-the-shelf (COTS) equipment without following strict methodologies. HERCCULES is a stratospheric balloon mission that aims to characterize the convective heat and radiative environment in the stratosphere. The purpose of this article is to present the HERCCULES onboard software (OBSW) whose design and complexity is comparable to that of satellite systems, since it must control about sixty COTS equipment using a single Raspberry Pi 4B as onboard computer and ensure the real-time requirements. Compared to similar systems, novel contributions are presented as the OBSW is developed following modelbased and component-based approaches using the TASTE toolchain from the European Space Agency (ESA) for automatic code generation. Besides, the OBSW is verified and validated following the ESA standards and the results obtained demonstrate the suitability and efficiency of the solution and the selected methodologies.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04090",
        "abstract url": "https://arxiv.org/abs/2402.04090",
        "title": "Acceleration and energy consumption optimization in cascading classifiers for face detection on low-cost ARM big.LITTLE asymmetric architectures",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "This paper proposes a mechanism to accelerate and optimize the energy consumption of a face detection software based on Haar-like cascading classifiers, taking advantage of the features of low-cost Asymmetric Multicore Processors (AMPs) with limited power budget. A modelling and task scheduling/allocation is proposed in order to efficiently make use of the existing features on big.LITTLE ARM processors, including: (I) source-code adaptation for parallel computing, which enables code acceleration by applying the OmpSs programming model, a task-based programming model that handles data-dependencies between tasks in a transparent fashion; (II) different OmpSs task allocation policies which take into account the processor asymmetry and can dynamically set processing resources in a more efficient way based on their particular features. The proposed mechanism can be efficiently applied to take advantage of the processing elements existing on low-cost and low-energy multi-core embedded devices executing object detection algorithms based on cascading classifiers. Although these classifiers yield the best results for detection algorithms in the field of computer vision, their high computational requirements prevent them from being used on these devices under real-time requirements. Finally, we compare the energy efficiency of a heterogeneous architecture based on asymmetric multicore processors with a suitable task scheduling, with that of a homogeneous symmetric architecture.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04100",
        "abstract url": "https://arxiv.org/abs/2402.04100",
        "title": "A programmable photonic memory",
        "rating": -2,
        "keywords": [
            [
                "medical",
                "diagnosis"
            ]
        ],
        "abstract": "The significant advancements in integrated photonics have enabled high-speed and energy efficient systems for various applications from data communications and high-performance computing, to medical diagnosis, sensing and ranging. However, data storage in these systems has been dominated by electronic memories which necessitates signal conversion between optical and electrical as well as analog and digital domains, and data movement between processor and memory that reduce the speed and energy efficiency. To date, a scalable optical memory with optical control has remained an open problem. Here we report an integrated photonic set-reset latch as a fundamental optical static memory unit based on universal optical logic gates. While the proposed memory is compatible with different photonic platforms, its functionality is demonstrated on a programmable silicon photonic chip as a proof of concept. Optical set, reset, and complementary outputs, scalability to a large number of memory units via the independent latch supply light, and compatibility with different photonic platforms enable more efficient and lower latency optical processing systems.",
        "subjects": [
            "physics.optics"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04101",
        "abstract url": "https://arxiv.org/abs/2402.04101",
        "title": "VRMM: A Volumetric Relightable Morphable Head Model",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "facial",
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce the Volumetric Relightable Morphable Model (VRMM), a novel volumetric and parametric facial prior for 3D face modeling. While recent volumetric prior models offer improvements over traditional methods like 3D Morphable Models (3DMMs), they face challenges in model learning and personalized reconstructions. Our VRMM overcomes these by employing a novel training framework that efficiently disentangles and encodes latent spaces of identity, expression, and lighting into low-dimensional representations. This framework, designed with self-supervised learning, significantly reduces the constraints for training data, making it more feasible in practice. The learned VRMM offers relighting capabilities and encompasses a comprehensive range of expressions. We demonstrate the versatility and effectiveness of VRMM through various applications like avatar generation, facial reconstruction, and animation. Additionally, we address the common issue of overfitting in generative volumetric models with a novel prior-preserving personalization framework based on VRMM. Such an approach enables accurate 3D face reconstruction from even a single portrait input. Our experiments showcase the potential of VRMM to significantly enhance the field of 3D face modeling.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04110",
        "abstract url": "https://arxiv.org/abs/2402.04110",
        "title": "Behind the Screen: Investigating ChatGPT's Dark Personality Traits and Conspiracy Beliefs",
        "rating": -2,
        "keywords": [
            [
                "depth"
            ],
            [
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "ChatGPT is notorious for its intransparent behavior. This paper tries to shed light on this, providing an in-depth analysis of the dark personality traits and conspiracy beliefs of GPT-3.5 and GPT-4. Different psychological tests and questionnaires were employed, including the Dark Factor Test, the Mach-IV Scale, the Generic Conspiracy Belief Scale, and the Conspiracy Mentality Scale. The responses were analyzed computing average scores, standard deviations, and significance tests to investigate differences between GPT-3.5 and GPT-4. For traits that have shown to be interdependent in human studies, correlations were considered. Additionally, system roles corresponding to groups that have shown distinct answering behavior in the corresponding questionnaires were applied to examine the models' ability to reflect characteristics associated with these roles in their responses. Dark personality traits and conspiracy beliefs were not particularly pronounced in either model with little differences between GPT-3.5 and GPT-4. However, GPT-4 showed a pronounced tendency to believe in information withholding. This is particularly intriguing given that GPT-4 is trained on a significantly larger dataset than GPT-3.5. Apparently, in this case an increased data exposure correlates with a greater belief in the control of information. An assignment of extreme political affiliations increased the belief in conspiracy theories. Test sequencing affected the models' responses and the observed correlations, indicating a form of contextual memory.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "15 pages, 5 figures"
    },
    {
        "paper id": "2402.04146",
        "abstract url": "https://arxiv.org/abs/2402.04146",
        "title": "Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process",
        "rating": -2,
        "keywords": [
            [
                "alloys"
            ]
        ],
        "abstract": "With the advent of artificial intelligence (AI) and machine learning (ML), various domains of science and engineering communites has leveraged data-driven surrogates to model complex systems from numerous sources of information (data). The proliferation has led to significant reduction in cost and time involved in development of superior systems designed to perform specific functionalities. A high proposition of such surrogates are built extensively fusing multiple sources of data, may it be published papers, patents, open repositories, or other resources. However, not much attention has been paid to the differences in quality and comprehensiveness of the known and unknown underlying physical parameters of the information sources that could have downstream implications during system optimization. Towards resolving this issue, a multi-source data fusion framework based on Latent Variable Gaussian Process (LVGP) is proposed. The individual data sources are tagged as a characteristic categorical variable that are mapped into a physically interpretable latent space, allowing the development of source-aware data fusion modeling. Additionally, a dissimilarity metric based on the latent variables of LVGP is introduced to study and understand the differences in the sources of data. The proposed approach is demonstrated on and analyzed through two mathematical (representative parabola problem, 2D Ackley function) and two materials science (design of FeCrAl and SmCoFe alloys) case studies. From the case studies, it is observed that compared to using single-source and source unaware ML models, the proposed multi-source data fusion framework can provide better predictions for sparse-data problems, interpretability regarding the sources, and enhanced modeling capabilities by taking advantage of the correlations and relationships among different sources.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "27 Pages,9 Figures, 3 Supplementary Figures, 2 Supplementary Tables"
    },
    {
        "paper id": "2402.04166",
        "abstract url": "https://arxiv.org/abs/2402.04166",
        "title": "Mind the Gap: Securely modeling cyber risk based on security deviations from a peer group",
        "rating": -2,
        "keywords": [
            [
                "forecast"
            ]
        ],
        "abstract": "There are two strategic and longstanding questions about cyber risk that organizations largely have been unable to answer: What is an organization's estimated risk exposure and how does its security compare with peers? Answering both requires industry-wide data on security posture, incidents, and losses that, until recently, have been too sensitive for organizations to share. Now, privacy enhancing technologies (PETs) such as cryptographic computing can enable the secure computation of aggregate cyber risk metrics from a peer group of organizations while leaving sensitive input data undisclosed. As these new aggregate data become available, analysts need ways to integrate them into cyber risk models that can produce more reliable risk assessments and allow comparison to a peer group. This paper proposes a new framework for benchmarking cyber posture against peers and estimating cyber risk within specific economic sectors using the new variables emerging from secure computations. We introduce a new top-line variable called the Defense Gap Index representing the weighted security gap between an organization and its peers that can be used to forecast an organization's own security risk based on historical industry data. We apply this approach in a specific sector using data collected from 25 large firms, in partnership with an industry ISAO, to build an industry risk model and provide tools back to participants to estimate their own risk exposure and privately compare their security posture with their peers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04187",
        "abstract url": "https://arxiv.org/abs/2402.04187",
        "title": "Start Stop Bit Method for Efficient Data Communication in 6G Mobile Radio Systems",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "In this article, a novel approach for mobile radio communications is proposed and analysed, which is promising for future 6G cooperative distributed MIMO systems. The fundamental idea is a new mechanism namely start stop bit method, which transmits bit sequences as the start/stop bits of a synchronized counter instead of transmitting the full encoded bit sequence itself. In that way, theoretically, we can transmit infinitely long data messages with only one bit for starting and one bit for stopping the counter. The value of the counter, as identified by the stop bit, is then used to reconstruct and remap the one and unique transmitted bit sequence. The start stop bit method is characterized by a high signal sparsity as only two bits are transmitted, independently of the bit sequence length for the message. Among the benefits of the start stop bit method are energy efficient data transmission, and effective distributed MIMO systems, which exploit the sparse inter cooperation area interference as well as the low processing complexity for the sparse precoder calculation. Moreover, for the next mobile wireless generation, we propose an advanced scheme of the start stop bit method which enhances its resource usage. We call the resulting method a sparse dMIMO system.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "7 pages, 8 figures"
    },
    {
        "paper id": "2402.04235",
        "abstract url": "https://arxiv.org/abs/2402.04235",
        "title": "LIPSTICK: Corruptibility-Aware and Explainable Graph Neural Network-based Oracle-Less Attack on Logic Locking",
        "rating": -2,
        "keywords": [
            [
                "Graph"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "In a zero-trust fabless paradigm, designers are increasingly concerned about hardware-based attacks on the semiconductor supply chain. Logic locking is a design-for-trust method that adds extra key-controlled gates in the circuits to prevent hardware intellectual property theft and overproduction. While attackers have traditionally relied on an oracle to attack logic-locked circuits, machine learning attacks have shown the ability to retrieve the secret key even without access to an oracle. In this paper, we first examine the limitations of state-of-the-art machine learning attacks and argue that the use of key hamming distance as the sole model-guiding structural metric is not always useful. Then, we develop, train, and test a corruptibility-aware graph neural network-based oracle-less attack on logic locking that takes into consideration both the structure and the behavior of the circuits. Our model is explainable in the sense that we analyze what the machine learning model has interpreted in the training process and how it can perform a successful attack. Chip designers may find this information beneficial in securing their designs while avoiding incremental fixes.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Proceedings of 29th Asia and South Pacific Design Automation Conference (ASP-DAC 2024)"
    },
    {
        "paper id": "2402.04318",
        "abstract url": "https://arxiv.org/abs/2402.04318",
        "title": "Human Observation-Inspired Trajectory Prediction for Autonomous Driving in Mixed-Autonomy Traffic Environments",
        "rating": -2,
        "keywords": [
            [
                "Autonomous Driving",
                "Trajectory"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "In the burgeoning field of autonomous vehicles (AVs), trajectory prediction remains a formidable challenge, especially in mixed autonomy environments. Traditional approaches often rely on computational methods such as time-series analysis. Our research diverges significantly by adopting an interdisciplinary approach that integrates principles of human cognition and observational behavior into trajectory prediction models for AVs. We introduce a novel \"adaptive visual sector\" mechanism that mimics the dynamic allocation of attention human drivers exhibit based on factors like spatial orientation, proximity, and driving speed. Additionally, we develop a \"dynamic traffic graph\" using Convolutional Neural Networks (CNN) and Graph Attention Networks (GAT) to capture spatio-temporal dependencies among agents. Benchmark tests on the NGSIM, HighD, and MoCAD datasets reveal that our model (GAVA) outperforms state-of-the-art baselines by at least 15.2%, 19.4%, and 12.0%, respectively. Our findings underscore the potential of leveraging human cognition principles to enhance the proficiency and adaptability of trajectory prediction algorithms in AVs. The code for the proposed model is available at our Github.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04350",
        "abstract url": "https://arxiv.org/abs/2402.04350",
        "title": "Education and Sustainability: a model for different Engineering degrees",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Technologies related to the Internet of Things (IoT) have seen remarkable growth in recent years. This has facilitated, among many other reasons, that monitoring systems have spread in many everyday areas, including both industry and the services and systems of the so-called smart home. These systems can also be applied in Engineering and in Education for the different existing engineering degrees; and one of the fields is sustainability. A project related to sustainability and student practices has been launched at our university. In this way, several objectives are achieved at the same time, such as the transfer of knowledge from universities to society, and also the development of sustainable education, in line with the sustainable development goals. In this framework, we want to apply the ideas of monitoring through IoT applications, by means of the measurement of certain environmental factors that occur both in an urban garden and in a composting process. Only open hardware-based devices have been used in the project. The proposed model can be applied in other areas of knowledge, having considered different alternatives and having chosen the best elements, based on sustainability criteria, for each section of the project. Specifically, in the system that has been created, the environmental factors of a small urban garden and also of a composting box can be measured. Both sections of the project, garden and composting, are located at the university. The factors to be measured are the following: air temperature, air humidity, soil moisture, ultraviolet radiation and amount of light (luminosity) received in the urban garden; and temperature and humidity in the composting process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04374",
        "abstract url": "https://arxiv.org/abs/2402.04374",
        "title": "SKOOTR: A SKating, Omni-Oriented, Tripedal Robot",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "In both animals and robots, locomotion capabilities are determined by the physical structure of the system. The majority of legged animals and robots are bilaterally symmetric, which facilitates locomotion with consistent headings and obstacle traversal, but leads to constraints in their turning ability. On the other hand, radially symmetric animals have demonstrated rapid turning abilities enabled by their omni-directional body plans. Radially symmetric tripedal robots are able to turn instantaneously, but are commonly constrained by needing to change direction with every step, resulting in inefficient and less stable locomotion. We address these challenges by introducing a novel design for a tripedal robot that has both frictional and rolling contacts. Additionally, a freely rotating central sphere provides an added contact point so the robot can retain a stable tripod base of support while lifting and pushing with any one of its legs. The SKating, Omni-Oriented, Tripedal Robot (SKOOTR) is more versatile and stable than other existing tripedal robots. It is capable of multiple forward gaits, multiple turning maneuvers, obstacle traversal, and stair climbing. SKOOTR has been designed to facilitate customization for diverse applications: it is fully open-source, is constructed with 3D printed or off-the-shelf parts, and costs approximately $500 USD to build.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04386",
        "abstract url": "https://arxiv.org/abs/2402.04386",
        "title": "Novel Methods for Load Estimation in Cell Switching in HAPS-Assisted Sustainable 6G Networks",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "In the evolving landscape of vertical heterogeneous networks, the practice of cell switching particularly for small base stations faces a significant challenge due to the lack of accurate data on the traffic load of sleeping SBSs. This information gap is crucial as it hinders the feasibility and applicability of existing power consumption optimization methods; however, the studies in the literature predominantly assume perfect knowledge about the traffic load of sleeping SBSs. Addressing this critical issue, our study introduces innovative methodologies for estimating the traffic load of sleeping SBSs in a vHetNet including the integration of a high altitude platform as a super macro base station into the terrestrial network. We propose three distinct spatial interpolation-based estimation schemes: clustering-based, distance based, and random neighboring selection. Employing a real data set for empirical validations, we compare the estimation performance of the developed traffic load estimation schemes and assess the impact of estimation errors. Our findings demonstrate that accurate estimation of sleeping SBSs' traffic loads is essential for making network power consumption optimization methods both feasible and applicable in vHetNets.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "6 pages, 5 figures, ICC Conference"
    },
    {
        "paper id": "2402.04418",
        "abstract url": "https://arxiv.org/abs/2402.04418",
        "title": "A Survey of Offline and Online Learning-Based Algorithms for Multirotor UAVs",
        "rating": -2,
        "keywords": [
            [
                "flight"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Multirotor UAVs are used for a wide spectrum of civilian and public domain applications. Navigation controllers endowed with different attributes and onboard sensor suites enable multirotor autonomous or semi-autonomous, safe flight, operation, and functionality under nominal and detrimental conditions and external disturbances, even when flying in uncertain and dynamically changing environments. During the last decade, given the faster-than-exponential increase of available computational power, different learning-based algorithms have been derived, implemented, and tested to navigate and control, among other systems, multirotor UAVs. Learning algorithms have been, and are used to derive data-driven based models, to identify parameters, to track objects, to develop navigation controllers, and to learn the environment in which multirotors operate. Learning algorithms combined with model-based control techniques have been proven beneficial when applied to multirotors. This survey summarizes published research since 2015, dividing algorithms, techniques, and methodologies into offline and online learning categories, and then, further classifying them into machine learning, deep learning, and reinforcement learning sub-categories. An integral part and focus of this survey are on online learning algorithms as applied to multirotors with the aim to register the type of learning techniques that are either hard or almost hard real-time implementable, as well as to understand what information is learned, why, and how, and how fast. The outcome of the survey offers a clear understanding of the recent state-of-the-art and of the type and kind of learning-based algorithms that may be implemented, tested, and executed in real-time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "26 pages, 6 figures, 4 tables, Survey Paper"
    },
    {
        "paper id": "2402.04423",
        "abstract url": "https://arxiv.org/abs/2402.04423",
        "title": "Smart Pipe System for a Shipyard 4.0",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "As a result of the progressive implantation of the Industry 4.0 paradigm, many industries are experimenting a revolution that shipyards cannot ignore. Therefore, the application of the principles of Industry 4.0 to shipyards are leading to the creation of Shipyards 4.0. Due to this, Navantia, one of the 10 largest shipbuilders in the world, is updating its whole inner workings to keep up with the near-future challenges that a Shipyard 4.0 will have to face. Such challenges can be divided into three groups: the vertical integration of production systems, the horizontal integration of a new generation of value creation networks, and the re-engineering of the entire production chain, making changes that affect the entire life cycle of each piece of a ship. Pipes, which exist in a huge number and varied typology on a ship, are one of the key pieces, and its monitoring constitutes a prospective cyber-physical system. Their improved identification, traceability, and indoor location, from production and through their life, can enhance shipyard productivity and safety. In order to perform such tasks, this article first conducts a thorough analysis of the shipyard environment. From this analysis, the essential hardware and software technical requirements are determined. Next, the concept of smart pipe is presented and defined as an object able to transmit signals periodically that allows for providing enhanced services in a shipyard. In order to build a smart pipe system, different technologies are selected and evaluated, concluding that passive and active RFID are currently the most appropriate technologies to create it. Furthermore, some promising indoor positioning results obtained in a pipe workshop are presented, showing that multi-antenna algorithms and Kalman filtering can help to stabilize Received Signal Strength (RSS) and improve the overall accuracy of the system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "43 pages, 25 figures, accepted version of Sensors journal article"
    },
    {
        "paper id": "2402.04448",
        "abstract url": "https://arxiv.org/abs/2402.04448",
        "title": "Failure Analysis in Next-Generation Critical Cellular Communication Infrastructures",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "The advent of communication technologies marks a transformative phase in critical infrastructure construction, where the meticulous analysis of failures becomes paramount in achieving the fundamental objectives of continuity, security, and availability. This survey enriches the discourse on failures, failure analysis, and countermeasures in the context of the next-generation critical communication infrastructures. Through an exhaustive examination of existing literature, we discern and categorize prominent research orientations with focuses on, namely resource depletion, security vulnerabilities, and system availability concerns. We also analyze constructive countermeasures tailored to address identified failure scenarios and their prevention. Furthermore, the survey emphasizes the imperative for standardization in addressing failures related to Artificial Intelligence (AI) within the ambit of the sixth-generation (6G) networks, accounting for the forward-looking perspective for the envisioned intelligence of 6G network architecture. By identifying new challenges and delineating future research directions, this survey can help guide stakeholders toward unexplored territories, fostering innovation and resilience in critical communication infrastructure development and failure prevention.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04454",
        "abstract url": "https://arxiv.org/abs/2402.04454",
        "title": "Evolving Mobile Cloud Gaming with 5G Standalone Network Telemetry",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Mobile cloud gaming places the simultaneous demands of high capacity and low latency on the wireless network, demands that Private and Metropolitan-Area Standalone 5G networks are poised to meet. However, lacking introspection into the 5G Radio Access Network (RAN), cloud gaming servers are ill-poised to cope with the vagaries of the wireless last hop to a mobile client, while 5G network operators run mostly closed networks, limiting their potential for co-design with the wider internet and user applications. This paper presents Telesa, a passive, incrementally-deployable, and independently-deployable Standalone 5G network telemetry system that streams fine-grained RAN capacity, latency, and retransmission information to application servers to enable better millisecond scale, application-level decisions on offered load and bit rate adaptation than end-to-end latency measurements or end-to-end packet losses currently permit. We design, implement, and evaluate a Telesa telemetry-enhanced game streaming platform, demonstrating exact congestion-control that can better adapt game video bitrate while simultaneously controlling end-to-end latency, thus maximizing game quality of experience. Our experimental evaluation on a production 5G Standalone network demonstrates a 178-249% Quality of Experience improvement versus two state-of-the-art cloud gaming applications.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04457",
        "abstract url": "https://arxiv.org/abs/2402.04457",
        "title": "Reliability quality measures for recommender systems",
        "rating": -2,
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Users want to know the reliability of the recommendations; they do not accept high predictions if there is no reliability evidence. Recommender systems should provide reliability values associated with the predictions. Research into reliability measures requires the existence of simple, plausible and universal reliability quality measures. Research into recommender system quality measures has focused on accuracy. Moreover, novelty, serendipity and diversity have been studied; nevertheless there is an important lack of research into reliability/confidence quality measures. This paper proposes a reliability quality prediction measure (RPI) and a reliability quality recommendation measure (RRI). Both quality measures are based on the hypothesis that the more suitable a reliability measure is, the better accuracy results it will provide when applied. These reliability quality measures show accuracy improvements when appropriated reliability values are associated with their predictions (i.e. high reliability values associated with correct predictions or low reliability values associated with incorrect predictions). The proposed reliability quality metrics will lead to the design of brand new recommender system reliability measures. These measures could be applied to different matrix factorization techniques and to content-based, context-aware and social recommendation approaches. The recommender system reliability measures designed could be tested, compared and improved using the proposed reliability quality metrics.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04466",
        "abstract url": "https://arxiv.org/abs/2402.04466",
        "title": "Towards Deterministic End-to-end Latency for Medical AI Systems in NVIDIA Holoscan",
        "rating": -2,
        "keywords": [
            [
                "Medical",
                "healthcare"
            ]
        ],
        "abstract": "The introduction of AI and ML technologies into medical devices has revolutionized healthcare diagnostics and treatments. Medical device manufacturers are keen to maximize the advantages afforded by AI and ML by consolidating multiple applications onto a single platform. However, concurrent execution of several AI applications, each with its own visualization components, leads to unpredictable end-to-end latency, primarily due to GPU resource contentions. To mitigate this, manufacturers typically deploy separate workstations for distinct AI applications, thereby increasing financial, energy, and maintenance costs. This paper addresses these challenges within the context of NVIDIA's Holoscan platform, a real-time AI system for streaming sensor data and images. We propose a system design optimized for heterogeneous GPU workloads, encompassing both compute and graphics tasks. Our design leverages CUDA MPS for spatial partitioning of compute workloads and isolates compute and graphics processing onto separate GPUs. We demonstrate significant performance improvements across various end-to-end latency determinism metrics through empirical evaluation with real-world Holoscan medical device applications. For instance, the proposed design reduces maximum latency by 21-30% and improves latency distribution flatness by 17-25% for up to five concurrent endoscopy tool tracking AI applications, compared to a single-GPU baseline. Against a default multi-GPU setup, our optimizations decrease maximum latency by 35% for up to six concurrent applications by improving GPU utilization by 42%. This paper provides clear design insights for AI applications in the edge-computing domain including medical systems, where performance predictability of concurrent and heterogeneous GPU workloads is a critical requirement.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04471",
        "abstract url": "https://arxiv.org/abs/2402.04471",
        "title": "Reductive Quantum Phase Estimation",
        "rating": -2,
        "keywords": [
            [
                "Quantum",
                "physics"
            ]
        ],
        "abstract": "Estimating a quantum phase is a necessary task in a wide range of fields of quantum science. To accomplish this task, two well-known methods have been developed in distinct contexts, namely, Ramsey interferometry (RI) in atomic and molecular physics and quantum phase estimation (QPE) in quantum computing. We demonstrate that these canonical examples are instances of a larger class of phase estimation protocols, which we call reductive quantum phase estimation (RQPE) circuits. Here we present an explicit algorithm that allows one to create an RQPE circuit. This circuit distinguishes an arbitrary set of phases with a fewer number of qubits and unitary applications, thereby solving a general class of quantum hypothesis testing to which RI and QPE belong. We further demonstrate a trade-off between measurement precision and phase distinguishability, which allows one to tune the circuit to be optimal for a specific application.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "12 pages, 6 figures, submitted to Physical Review Research"
    },
    {
        "paper id": "2402.04480",
        "abstract url": "https://arxiv.org/abs/2402.04480",
        "title": "MIRT: a simultaneous reconstruction and affine motion compensation technique for four dimensional computed tomography (4DCT)",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "CT"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "In four-dimensional computed tomography (4DCT), 3D images of moving or deforming samples are reconstructed from a set of 2D projection images. Recent techniques for iterative motion-compensated reconstruction either necessitate a reference acquisition or alternate image reconstruction and motion estimation steps. In these methods, the motion estimation step involves the estimation of either complete deformation vector fields (DVFs) or a limited set of parameters corresponding to the affine motion, including rigid motion or scaling. The majority of these approaches rely on nested iterations, incurring significant computational expenses. Notably, despite the direct benefits of an analytical formulation and a substantial reduction in computational complexity, there has been no exploration into parameterizing DVFs for general affine motion in CT imaging. In this work, we propose the Motion-compensated Iterative Reconstruction Technique (MIRT)- an efficient iterative reconstruction scheme that combines image reconstruction and affine motion estimation in a single update step, based on the analytical gradients of the motion towards both the reconstruction and the affine motion parameters. When most of the state-of-the-art 4DCT methods have not attempted to be tested on real data, results from simulation and real experiments show that our method outperforms the state-of-the-art CT reconstruction with affine motion correction methods in computational feasibility and projection distance. In particular, this allows accurate reconstruction for a proper microscale diamond in the appearance of motion from the practically acquired projection radiographs, which leads to a novel application of 4DCT.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Submitted to the SIAM Journal on Imaging Sciences (SIIMS)"
    },
    {
        "paper id": "2402.04527",
        "abstract url": "https://arxiv.org/abs/2402.04527",
        "title": "RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation",
        "rating": -2,
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Large language models (LLM) have recently emerged as a powerful tool for a variety of natural language processing tasks, bringing a new surge of combining LLM with recommendation systems, termed as LLM-based RS. Current approaches generally fall into two main paradigms, the ID direct usage paradigm and the ID translation paradigm, noting their core weakness stems from lacking recommendation knowledge and uniqueness. To address this limitation, we propose a new paradigm, ID representation, which incorporates pre-trained ID embeddings into LLMs in a complementary manner. In this work, we present RA-Rec, an efficient ID representation alignment framework for LLM-based recommendation, which is compatible with multiple ID-based methods and LLM architectures. Specifically, we treat ID embeddings as soft prompts and design an innovative alignment module and an efficient tuning method with tailored data construction for alignment. Extensive experiments demonstrate RA-Rec substantially outperforms current state-of-the-art methods, achieving up to 3.0% absolute HitRate@100 improvements while utilizing less than 10x training data.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2402.04535",
        "abstract url": "https://arxiv.org/abs/2402.04535",
        "title": "MuNES: Multifloor Navigation Including Elevators and Stairs",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "We propose a scheme called MuNES for single mapping and trajectory planning including elevators and stairs. Optimized multifloor trajectories are important for optimal interfloor movements of robots. However, given two or more options of moving between floors, it is difficult to select the best trajectory because there are no suitable indoor multifloor maps in the existing methods. To solve this problem, MuNES creates a single multifloor map including elevators and stairs by estimating altitude changes based on pressure data. In addition, the proposed method performs floor-based loop detection for faster and more accurate loop closure. The single multifloor map is then voxelized leaving only the parts needed for trajectory planning. An optimal and realistic multifloor trajectory is generated by exploring the voxels using an A* algorithm based on the proposed cost function, which affects realistic factors. We tested this algorithm using data acquired from around a campus and note that a single accurate multifloor map could be created. Furthermore, optimal and realistic multifloor trajectory could be found by selecting the means of motion between floors between elevators and stairs according to factors such as the starting point, ending point, and elevator waiting time. The code and data used in this work are available at https://github.com/donghwijung/MuNES.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04546",
        "abstract url": "https://arxiv.org/abs/2402.04546",
        "title": "LiDAR-Forest Dataset: LiDAR Point Cloud Simulation Dataset for Forestry Application",
        "rating": -2,
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ]
        ],
        "abstract": "The popularity of LiDAR devices and sensor technology has gradually empowered users from autonomous driving to forest monitoring, and research on 3D LiDAR has made remarkable progress over the years. Unlike 2D images, whose focused area is visible and rich in texture information, understanding the point distribution can help companies and researchers find better ways to develop point-based 3D applications. In this work, we contribute an unreal-based LiDAR simulation tool and a 3D simulation dataset named LiDAR-Forest, which can be used by various studies to evaluate forest reconstruction, tree DBH estimation, and point cloud compression for easy visualization. The simulation is customizable in tree species, LiDAR types and scene generation, with low cost and high efficiency.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2402.04554",
        "abstract url": "https://arxiv.org/abs/2402.04554",
        "title": "BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial Imagery",
        "rating": -2,
        "keywords": [
            [
                "NeRF",
                "Radiance Fields"
            ],
            [
                "drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this study, we introduce BirdNeRF, an adaptation of Neural Radiance Fields (NeRF) designed specifically for reconstructing large-scale scenes using aerial imagery. Unlike previous research focused on small-scale and object-centric NeRF reconstruction, our approach addresses multiple challenges, including (1) Addressing the issue of slow training and rendering associated with large models. (2) Meeting the computational demands necessitated by modeling a substantial number of images, requiring extensive resources such as high-performance GPUs. (3) Overcoming significant artifacts and low visual fidelity commonly observed in large-scale reconstruction tasks due to limited model capacity. Specifically, we present a novel bird-view pose-based spatial decomposition algorithm that decomposes a large aerial image set into multiple small sets with appropriately sized overlaps, allowing us to train individual NeRFs of sub-scene. This decomposition approach not only decouples rendering time from the scene size but also enables rendering to scale seamlessly to arbitrarily large environments. Moreover, it allows for per-block updates of the environment, enhancing the flexibility and adaptability of the reconstruction process. Additionally, we propose a projection-guided novel view re-rendering strategy, which aids in effectively utilizing the independently trained sub-scenes to generate superior rendering results. We evaluate our approach on existing datasets as well as against our own drone footage, improving reconstruction speed by 10x over classical photogrammetry software and 50x over state-of-the-art large-scale NeRF solution, on a single GPU with similar rendering quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05137",
        "abstract url": "https://arxiv.org/abs/2402.05137",
        "title": "LtU-ILI: An All-in-One Framework for Implicit Inference in Astrophysics and Cosmology",
        "rating": -2,
        "keywords": [
            [
                "X-ray"
            ]
        ],
        "abstract": "This paper presents the Learning the Universe Implicit Likelihood Inference (LtU-ILI) pipeline, a codebase for rapid, user-friendly, and cutting-edge machine learning (ML) inference in astrophysics and cosmology. The pipeline includes software for implementing various neural architectures, training schema, priors, and density estimators in a manner easily adaptable to any research workflow. It includes comprehensive validation metrics to assess posterior estimate coverage, enhancing the reliability of inferred results. Additionally, the pipeline is easily parallelizable, designed for efficient exploration of modeling hyperparameters. To demonstrate its capabilities, we present real applications across a range of astrophysics and cosmology problems, such as: estimating galaxy cluster masses from X-ray photometry; inferring cosmology from matter power spectra and halo point clouds; characterising progenitors in gravitational wave signals; capturing physical dust parameters from galaxy colors and luminosities; and establishing properties of semi-analytic models of galaxy formation. We also include exhaustive benchmarking and comparisons of all implemented methods as well as discussions about the challenges and pitfalls of ML inference in astronomical sciences. All code and examples are made publicly available at https://github.com/maho3/ltu-ili.",
        "subjects": [
            "astro-ph.IM"
        ],
        "comment": "20 pages, 10 figures, submitted to the Open Journal of Astrophysics. Code available at https://github.com/maho3/ltu-ili"
    },
    {
        "paper id": "2402.16874",
        "abstract url": "https://arxiv.org/abs/2402.16874",
        "title": "Enhancing Retrieval Processes for Language Generation with Augmented Queries",
        "rating": -2,
        "keywords": [
            [
                "face"
            ]
        ],
        "abstract": "In the rapidly changing world of smart technology, searching for documents has become more challenging due to the rise of advanced language models. These models sometimes face difficulties, like providing inaccurate information, commonly known as \"hallucination.\" This research focuses on addressing this issue through Retrieval-Augmented Generation (RAG), a technique that guides models to give accurate responses based on real facts. To overcome scalability issues, the study explores connecting user queries with sophisticated language models such as BERT and Orca2, using an innovative query optimization process. The study unfolds in three scenarios: first, without RAG, second, without additional assistance, and finally, with extra help. Choosing the compact yet efficient Orca2 7B model demonstrates a smart use of computing resources. The empirical results indicate a significant improvement in the initial language model's performance under RAG, particularly when assisted with prompts augmenters. Consistency in document retrieval across different encodings highlights the effectiveness of using language model-generated queries. The introduction of UMAP for BERT further simplifies document retrieval while maintaining strong results.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "28 pages, 10 annexes, 2 figures"
    },
    {
        "paper id": "2402.03771",
        "abstract url": "https://arxiv.org/abs/2402.03771",
        "title": "Reinforcement Learning from Bagged Reward: A Transformer-based Approach for Instance-Level Reward Redistribution",
        "rating": -2.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In reinforcement Learning (RL), an instant reward signal is generated for each action of the agent, such that the agent learns to maximize the cumulative reward to obtain the optimal policy. However, in many real-world applications, the instant reward signals are not obtainable by the agent. Instead, the learner only obtains rewards at the ends of bags, where a bag is defined as a partial sequence of a complete trajectory. In this situation, the learner has to face the significant difficulty of exploring the unknown instant rewards in the bags, which could not be addressed by existing approaches, including those trajectory-based approaches that consider only complete trajectories and ignore the inner reward distributions. To formally study this situation, we introduce a novel RL setting termed Reinforcement Learning from Bagged Rewards (RLBR), where only the bagged rewards of sequences can be obtained. We provide the theoretical study to establish the connection between RLBR and standard RL in Markov Decision Processes (MDPs). To effectively explore the reward distributions within the bagged rewards, we propose a Transformer-based reward model, the Reward Bag Transformer (RBT), which uses the self-attention mechanism for interpreting the contextual nuances and temporal dependencies within each bag. Extensive experimental analyses demonstrate the superiority of our method, particularly in its ability to mimic the original MDP's reward distribution, highlighting its proficiency in contextual understanding and adaptability to environmental dynamics.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03837",
        "abstract url": "https://arxiv.org/abs/2402.03837",
        "title": "Expressivity of Geometric Inhomogeneous Random Graphs -- Metric and Non-Metric",
        "rating": -2.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "face"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Recently there has been increased interest in fitting generative graph models to real-world networks. In particular, Bl\u00e4sius et al. have proposed a framework for systematic evaluation of the expressivity of random graph models. We extend this framework to Geometric Inhomogeneous Random Graphs (GIRGs). This includes a family of graphs induced by non-metric distance functions which allow capturing more complex models of partial similarity between nodes as a basis of connection - as well as homogeneous and non-homogeneous feature spaces. As part of the extension, we develop schemes for estimating the multiplicative constant and the long-range parameter in the connection probability. Moreover, we devise an algorithm for sampling Minimum-Component-Distance GIRGs whose runtime is linear both in the number of vertices and in the dimension of the underlying geometric space. Our results provide evidence that GIRGs are more realistic candidates with respect to various graph features such as closeness centrality, betweenness centrality, local clustering coefficient, and graph effective diameter, while they face difficulties to replicate higher variance and more extreme values of graph statistics observed in real-world networks.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "arXiv admin comment: This version has been removed by arXiv administrators as the submitter did not have the rights to agree to the license at the time of submission"
    },
    {
        "paper id": "2402.04296",
        "abstract url": "https://arxiv.org/abs/2402.04296",
        "title": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for $100\\times$ Faster Inference",
        "rating": -2.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hypergraph Neural Networks (HGNNs) have recently attracted much attention and exhibited satisfactory performance due to their superiority in high-order correlation modeling. However, it is noticed that the high-order modeling capability of hypergraph also brings increased computation complexity, which hinders its practical industrial deployment. In practice, we find that one key barrier to the efficient deployment of HGNNs is the high-order structural dependencies during inference. In this paper, we propose to bridge the gap between the HGNNs and inference-efficient Multi-Layer Perceptron (MLPs) to eliminate the hypergraph dependency of HGNNs and thus reduce computational complexity as well as improve inference speed. Specifically, we introduce LightHGNN and LightHGNN$^+$ for fast inference with low complexity. LightHGNN directly distills the knowledge from teacher HGNNs to student MLPs via soft labels, and LightHGNN$^+$ further explicitly injects reliable high-order correlations into the student MLPs to achieve topology-aware distillation and resistance to over-smoothing. Experiments on eight hypergraph datasets demonstrate that even without hypergraph dependency, the proposed LightHGNNs can still achieve competitive or even better performance than HGNNs and outperform vanilla MLPs by $16.3$ on average. Extensive experiments on three graph datasets further show the average best performance of our LightHGNNs compared with all other methods. Experiments on synthetic hypergraphs with 5.5w vertices indicate LightHGNNs can run $100\\times$ faster than HGNNs, showcasing their ability for latency-sensitive deployments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Some details are missing. The method of this paper is not complete"
    },
    {
        "paper id": "2402.04325",
        "abstract url": "https://arxiv.org/abs/2402.04325",
        "title": "Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons",
        "rating": -2.5,
        "keywords": [
            [
                "attacks"
            ],
            [
                "healthcare",
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Neural Networks (DNNs) have revolutionized a wide range of industries, from healthcare and finance to automotive, by offering unparalleled capabilities in data analysis and decision-making. Despite their transforming impact, DNNs face two critical challenges: the vulnerability to adversarial attacks and the increasing computational costs associated with more complex and larger models. In this paper, we introduce an effective method designed to simultaneously enhance adversarial robustness and execution efficiency. Unlike prior studies that enhance robustness via uniformly injecting noise, we introduce a non-uniform noise injection algorithm, strategically applied at each DNN layer to disrupt adversarial perturbations introduced in attacks. By employing approximation techniques, our approach identifies and protects essential neurons while strategically introducing noise into non-essential neurons. Our experimental results demonstrate that our method successfully enhances both robustness and efficiency across several attack scenarios, model architectures, and datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04384",
        "abstract url": "https://arxiv.org/abs/2402.04384",
        "title": "Denoising Diffusion Probabilistic Models in Six Simple Steps",
        "rating": -2.5,
        "keywords": [
            [
                "Diffusion",
                "synthesis"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) are a very popular class of deep generative model that have been successfully applied to a diverse range of problems including image and video generation, protein and material synthesis, weather forecasting, and neural surrogates of partial differential equations. Despite their ubiquity it is hard to find an introduction to DDPMs which is simple, comprehensive, clean and clear. The compact explanations necessary in research papers are not able to elucidate all of the different design steps taken to formulate the DDPM and the rationale of the steps that are presented is often omitted to save space. Moreover, the expositions are typically presented from the variational lower bound perspective which is unnecessary and arguably harmful as it obfuscates why the method is working and suggests generalisations that do not perform well in practice. On the other hand, perspectives that take the continuous time-limit are beautiful and general, but they have a high barrier-to-entry as they require background knowledge of stochastic differential equations and probability flow. In this note, we distill down the formulation of the DDPM into six simple steps each of which comes with a clear rationale. We assume that the reader is familiar with fundamental topics in machine learning including basic probabilistic modelling, Gaussian distributions, maximum likelihood estimation, and deep learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04469",
        "abstract url": "https://arxiv.org/abs/2402.04469",
        "title": "IoT Network Traffic Analysis with Deep Learning",
        "rating": -2.5,
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As IoT networks become more complex and generate massive amounts of dynamic data, it is difficult to monitor and detect anomalies using traditional statistical methods and machine learning methods. Deep learning algorithms can process and learn from large amounts of data and can also be trained using unsupervised learning techniques, meaning they don't require labelled data to detect anomalies. This makes it possible to detect new and unknown anomalies that may not have been detected before. Also, deep learning algorithms can be automated and highly scalable; thereby, they can run continuously in the backend and make it achievable to monitor large IoT networks instantly. In this work, we conduct a literature review on the most recent works using deep learning techniques and implement a model using ensemble techniques on the KDD Cup 99 dataset. The experimental results showcase the impressive performance of our deep anomaly detection model, achieving an accuracy of over 98\\%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "PerCom 2024 Workshop"
    },
    {
        "paper id": "2402.05971",
        "abstract url": "https://arxiv.org/abs/2402.05971",
        "title": "Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective",
        "rating": -2.5,
        "keywords": [
            [
                "synthesis"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The yield of a chemical reaction quantifies the percentage of the target product formed in relation to the reactants consumed during the chemical reaction. Accurate yield prediction can guide chemists toward selecting high-yield reactions during synthesis planning, offering valuable insights before dedicating time and resources to wet lab experiments. While recent advancements in yield prediction have led to overall performance improvement across the entire yield range, an open challenge remains in enhancing predictions for high-yield reactions, which are of greater concern to chemists. In this paper, we argue that the performance gap in high-yield predictions results from the imbalanced distribution of real-world data skewed towards low-yield reactions, often due to unreacted starting materials and inherent ambiguities in the reaction processes. Despite this data imbalance, existing yield prediction methods continue to treat different yield ranges equally, assuming a balanced training distribution. Through extensive experiments on three real-world yield prediction datasets, we emphasize the urgent need to reframe reaction yield prediction as an imbalanced regression problem. Finally, we demonstrate that incorporating simple cost-sensitive re-weighting methods can significantly enhance the performance of yield prediction models on underrepresented high-yield regions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10098",
        "abstract url": "https://arxiv.org/abs/2402.10098",
        "title": "Parameter-tuning-free data entry error unlearning with adaptive selective synaptic dampening",
        "rating": -2.5,
        "keywords": [
            [
                "model editing",
                "unlearning"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data entry constitutes a fundamental component of the machine learning pipeline, yet it frequently results in the introduction of labelling errors. When a model has been trained on a dataset containing such errors its performance is reduced. This leads to the challenge of efficiently unlearning the influence of the erroneous data to improve the model performance without needing to completely retrain the model. While model editing methods exist for cases in which the correct label for a wrong entry is known, we focus on the case of data entry errors where we do not know the correct labels for the erroneous data. Our contribution is twofold. First, we introduce an extension to the selective synaptic dampening unlearning method that removes the need for parameter tuning, making unlearning accessible to practitioners. We demonstrate the performance of this extension, adaptive selective synaptic dampening (ASSD), on various ResNet18 and Vision Transformer unlearning tasks. Second, we demonstrate the performance of ASSD in a supply chain delay prediction problem with labelling errors using real-world data where we randomly introduce various levels of labelling errors. The application of this approach is particularly compelling in industrial settings, such as supply chain management, where a significant portion of data entry occurs manually through Excel sheets, rendering it error-prone. ASSD shows strong performance on general unlearning benchmarks and on the error correction problem where it outperforms fine-tuning for error correction.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03705",
        "abstract url": "https://arxiv.org/abs/2402.03705",
        "title": "FoolSDEdit: Deceptively Steering Your Edits Towards Targeted Attribute-aware Distribution",
        "rating": -3,
        "keywords": [
            [
                "diffusion",
                "synthesis"
            ],
            [
                "architecture search"
            ],
            [
                "graph"
            ],
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Guided image synthesis methods, like SDEdit based on the diffusion model, excel at creating realistic images from user inputs such as stroke paintings. However, existing efforts mainly focus on image quality, often overlooking a key point: the diffusion model represents a data distribution, not individual images. This introduces a low but critical chance of generating images that contradict user intentions, raising ethical concerns. For example, a user inputting a stroke painting with female characteristics might, with some probability, get male faces from SDEdit. To expose this potential vulnerability, we aim to build an adversarial attack forcing SDEdit to generate a specific data distribution aligned with a specified attribute (e.g., female), without changing the input's attribute characteristics. We propose the Targeted Attribute Generative Attack (TAGA), using an attribute-aware objective function and optimizing the adversarial noise added to the input stroke painting. Empirical studies reveal that traditional adversarial noise struggles with TAGA, while natural perturbations like exposure and motion blur easily alter generated images' attributes. To execute effective attacks, we introduce FoolSDEdit: We design a joint adversarial exposure and blur attack, adding exposure and motion blur to the stroke painting and optimizing them together. We optimize the execution strategy of various perturbations, framing it as a network architecture search problem. We create the SuperPert, a graph representing diverse execution strategies for different perturbations. After training, we obtain the optimized execution strategy for effective TAGA against SDEdit. Comprehensive experiments on two datasets show our method compelling SDEdit to generate a targeted attribute-aware data distribution, significantly outperforming baselines.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03714",
        "abstract url": "https://arxiv.org/abs/2402.03714",
        "title": "Advancing Location-Invariant and Device-Agnostic Motion Activity Recognition on Wearable Devices",
        "rating": -3,
        "keywords": [
            [
                "synthesis"
            ],
            [
                "face"
            ]
        ],
        "abstract": "Wearable sensors have permeated into people's lives, ushering impactful applications in interactive systems and activity recognition. However, practitioners face significant obstacles when dealing with sensing heterogeneities, requiring custom models for different platforms. In this paper, we conduct a comprehensive evaluation of the generalizability of motion models across sensor locations. Our analysis highlights this challenge and identifies key on-body locations for building location-invariant models that can be integrated on any device. For this, we introduce the largest multi-location activity dataset (N=50, 200 cumulative hours), which we make publicly available. We also present deployable on-device motion models reaching 91.41% frame-level F1-score from a single model irrespective of sensor placements. Lastly, we investigate cross-location data synthesis, aiming to alleviate the laborious data collection tasks by synthesizing data in one location given data from another. These contributions advance our vision of low-barrier, location-invariant activity recognition systems, catalyzing research in HCI and ubiquitous computing.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03724",
        "abstract url": "https://arxiv.org/abs/2402.03724",
        "title": "Statistical Test for Anomaly Detections by Variational Auto-Encoders",
        "rating": -3,
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "medical",
                "diagnosis"
            ]
        ],
        "abstract": "In this study, we consider the reliability assessment of anomaly detection (AD) using Variational Autoencoder (VAE). Over the last decade, VAE-based AD has been actively studied in various perspective, from method development to applied research. However, when the results of ADs are used in high-stakes decision-making, such as in medical diagnosis, it is necessary to ensure the reliability of the detected anomalies. In this study, we propose the VAE-AD Test as a method for quantifying the statistical reliability of VAE-based AD within the framework of statistical testing. Using the VAE-AD Test, the reliability of the anomaly regions detected by a VAE can be quantified in the form of p-values. This means that if an anomaly is declared when the p-value is below a certain threshold, it is possible to control the probability of false detection to a desired level. Since the VAE-AD Test is constructed based on a new statistical inference framework called selective inference, its validity is theoretically guaranteed in finite samples. To demonstrate the validity and effectiveness of the proposed VAE-AD Test, numerical experiments on artificial data and applications to brain image analysis are conducted.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03761",
        "abstract url": "https://arxiv.org/abs/2402.03761",
        "title": "Deep Learning-Based Correction and Unmixing of Hyperspectral Images for Brain Tumor Surgery",
        "rating": -3,
        "keywords": [
            [
                "biopsies",
                "Surgery",
                "Tumor"
            ],
            [
                "Hyperspectral Images"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Hyperspectral Imaging (HSI) for fluorescence-guided brain tumor resection enables visualization of differences between tissues that are not distinguishable to humans. This augmentation can maximize brain tumor resection, improving patient outcomes. However, much of the processing in HSI uses simplified linear methods that are unable to capture the non-linear, wavelength-dependent phenomena that must be modeled for accurate recovery of fluorophore abundances. We therefore propose two deep learning models for correction and unmixing, which can account for the nonlinear effects and produce more accurate estimates of abundances. Both models use an autoencoder-like architecture to process the captured spectra. One is trained with protoporphyrin IX (PpIX) concentration labels. The other undergoes semi-supervised training, first learning hyperspectral unmixing self-supervised and then learning to correct fluorescence emission spectra for heterogeneous optical and geometric properties using a reference white-light reflectance spectrum in a few-shot manner. The models were evaluated against phantom and pig brain data with known PpIX concentration; the supervised model achieved Pearson correlation coefficients (R values) between the known and computed PpIX concentrations of 0.997 and 0.990, respectively, whereas the classical approach achieved only 0.93 and 0.82. The semi-supervised approach's R values were 0.98 and 0.91, respectively. On human data, the semi-supervised model gives qualitatively more realistic results than the classical method, better removing bright spots of specular reflectance and reducing the variance in PpIX abundance over biopsies that should be relatively homogeneous. These results show promise for using deep learning to improve HSI in fluorescence-guided neurosurgery.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "20 pages, 8 figures, 3 tables - Under Review"
    },
    {
        "paper id": "2402.03781",
        "abstract url": "https://arxiv.org/abs/2402.03781",
        "title": "MolTC: Towards Molecular Relational Modeling In Language Models",
        "rating": -3,
        "keywords": [
            [
                "GNN"
            ],
            [
                "biochemical"
            ]
        ],
        "abstract": "Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities, has emerged as a promising way for efficient and effective MRL. Despite their potential, these methods predominantly rely on the textual data, thus not fully harnessing the wealth of structural information inherent in molecular graphs. Moreover, the absence of a unified framework exacerbates the issue of information underutilization, as it hinders the sharing of interaction mechanism learned across diverse datasets. To address these challenges, this work proposes a novel LLM-based multi-modal framework for Molecular inTeraction prediction following Chain-of-Thought (CoT) theory, termed MolTC, which effectively integrate graphical information of two molecules in pair. For achieving a unified MRL, MolTC innovatively develops a dynamic parameter-sharing strategy for cross-dataset information sharing. Moreover, to train MolTC efficiently, we introduce a Multi-hierarchical CoT concept to refine its training paradigm, and conduct a comprehensive Molecular Interactive Instructions dataset for the development of biochemical LLMs involving MRL. Our experiments, conducted across various datasets involving over 4,000,000 molecular pairs, exhibit the superiority of our method over current GNN and LLM-based baselines. Code is available at https://github.com/MangoKiller/MolTC.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03838",
        "abstract url": "https://arxiv.org/abs/2402.03838",
        "title": "Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels",
        "rating": -3,
        "keywords": [
            [
                "graph"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molecular datasets, where the input graphs have a few tens of nodes. The efficiency of the SWWL kernel is then illustrated on graph regression in computational fluid dynamics and solid mechanics, where the input graphs are made up of tens of thousands of nodes.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03840",
        "abstract url": "https://arxiv.org/abs/2402.03840",
        "title": "Belief Scene Graphs: Expanding Partial Scenes with Objects through Computation of Expectation",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "In this article, we propose the novel concept of Belief Scene Graphs, which are utility-driven extensions of partial 3D scene graphs, that enable efficient high-level task planning with partial information. We propose a graph-based learning methodology for the computation of belief (also referred to as expectation) on any given 3D scene graph, which is then used to strategically add new nodes (referred to as blind nodes) that are relevant for a robotic mission. We propose the method of Computation of Expectation based on Correlation Information (CECI), to reasonably approximate real Belief/Expectation, by learning histograms from available training data. A novel Graph Convolutional Neural Network (GCN) model is developed, to learn CECI from a repository of 3D scene graphs. As no database of 3D scene graphs exists for the training of the novel CECI model, we present a novel methodology for generating a 3D scene graph dataset based on semantically annotated real-life 3D spaces. The generated dataset is then utilized to train the proposed CECI model and for extensive validation of the proposed method. We establish the novel concept of \\textit{Belief Scene Graphs} (BSG), as a core component to integrate expectations into abstract representations. This new concept is an evolution of the classical 3D scene graph concept and aims to enable high-level reasoning for the task planning and optimization of a variety of robotics missions. The efficacy of the overall framework has been evaluated in an object search scenario, and has also been tested on a real-life experiment to emulate human common sense of unseen-objects.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at ICRA 2024"
    },
    {
        "paper id": "2402.03871",
        "abstract url": "https://arxiv.org/abs/2402.03871",
        "title": "Geometric quantum machine learning of BQP$^A$ protocols and latent graph classifiers",
        "rating": -3,
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Geometric quantum machine learning (GQML) aims to embed problem symmetries for learning efficient solving protocols. However, the question remains if (G)QML can be routinely used for constructing protocols with an exponential separation from classical analogs. In this Letter we consider Simon's problem for learning properties of Boolean functions, and show that this can be related to an unsupervised circuit classification problem. Using the workflow of geometric QML, we learn from first principles Simon's algorithm, thus discovering an example of BQP$^A\\neq$BPP protocol with respect to some dataset (oracle $A$). Our key findings include the development of an equivariant feature map for embedding Boolean functions, based on twirling with respect to identified bitflip and permutational symmetries, and measurement based on invariant observables with a sampling advantage. The proposed workflow points to the importance of data embeddings and classical post-processing, while keeping the variational circuit as a trivial identity operator. Next, developing the intuition for the function learning, we visualize instances as directed computational hypergraphs, and observe that the GQML protocol can access their global topological features for distinguishing bijective and surjective functions. Finally, we discuss the prospects for learning other BQP$^A$-type protocols, and conjecture that this depends on the ability of simplifying embeddings-based oracles $A$ applied as a linear combination of unitaries.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2402.03946",
        "abstract url": "https://arxiv.org/abs/2402.03946",
        "title": "BioNet-XR: Biological Network Visualization Framework for Virtual Reality and Mixed Reality Environments",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "BioNet-XR"
            ]
        ],
        "abstract": "Protein-protein interaction networks (PPIN) enable the study of cellular processes in organisms. Visualizing PPINs in extended reality (XR), including virtual reality (VR) and mixed reality (MR), is crucial for exploring subnetworks, evaluating protein positions, and collaboratively analyzing and discussing on networks with the help of recent technological advancements. Here, we present BioNet-XR, a 3D visualization framework, to visualize PPINs in VR and MR environments. BioNet-XR was developed with the Unity3D game engine. Our framework provides state-of-the-art methods and visualization features including teleportation between nodes, general and first-person view to explore the network, subnetwork construction via PageRank, Steiner tree, and all-pair shortest path algorithms for a given set of initial nodes. We used usability tests to gather feedback from both specialists (bioinformaticians) and generalists (multidisciplinary groups), addressing the need for usability evaluations of visualization tools. In the MR version of BioNet-XR, users can seamlessly transition to real-world environments and interact with protein interaction networks. BioNet-XR is highly modular and adaptable for visualization of other biological networks, such as metabolic and regulatory networks, and extension with additional network methods.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03947",
        "abstract url": "https://arxiv.org/abs/2402.03947",
        "title": "Reinforcement Learning for Collision-free Flight Exploiting Deep Collision Encoding",
        "rating": -3,
        "keywords": [
            [
                "depth"
            ],
            [
                "Flight"
            ],
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "This work contributes a novel deep navigation policy that enables collision-free flight of aerial robots based on a modular approach exploiting deep collision encoding and reinforcement learning. The proposed solution builds upon a deep collision encoder that is trained on both simulated and real depth images using supervised learning such that it compresses the high-dimensional depth data to a low-dimensional latent space encoding collision information while accounting for the robot size. This compressed encoding is combined with an estimate of the robot's odometry and the desired target location to train a deep reinforcement learning navigation policy that offers low-latency computation and robust sim2real performance. A set of simulation and experimental studies in diverse environments are conducted and demonstrate the efficiency of the emerged behavior and its resilience in real-life deployments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 8 figures. Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2024"
    },
    {
        "paper id": "2402.04038",
        "abstract url": "https://arxiv.org/abs/2402.04038",
        "title": "PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network",
        "rating": -3,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) have gained popularity for various graph-related tasks. However, similar to deep neural networks, GNNs are also vulnerable to adversarial attacks. Empirical studies have shown that adversarially robust generalization has a pivotal role in establishing effective defense algorithms against adversarial attacks. In this paper, we contribute by providing adversarially robust generalization bounds for two kinds of popular GNNs, graph convolutional network (GCN) and message passing graph neural network, using the PAC-Bayesian framework. Our result reveals that spectral norm of the diffusion matrix on the graph and spectral norm of the weights as well as the perturbation factor govern the robust generalization bounds of both models. Our bounds are nontrivial generalizations of the results developed in (Liao et al., 2020) from the standard setting to adversarial setting while avoiding exponential dependence of the maximum node degree. As corollaries, we derive better PAC-Bayesian robust generalization bounds for GCN in the standard setting, which improve the bounds in (Liao et al., 2020) by avoiding exponential dependence on the maximum node degree.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "32pages"
    },
    {
        "paper id": "2402.04056",
        "abstract url": "https://arxiv.org/abs/2402.04056",
        "title": "Collaborative Deep Reinforcement Learning for Resource Optimization in Non-Terrestrial Networks",
        "rating": -3,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "Non-terrestrial networks (NTNs) with low-earth orbit (LEO) satellites have been regarded as promising remedies to support global ubiquitous wireless services. Due to the rapid mobility of LEO satellite, inter-beam/satellite handovers happen frequently for a specific user equipment (UE). To tackle this issue, earth-fixed cell scenarios have been under studied, in which the LEO satellite adjusts its beam direction towards a fixed area within its dwell duration, to maintain stable transmission performance for the UE. Therefore, it is required that the LEO satellite performs real-time resource allocation, which however is unaffordable by the LEO satellite with limited computing capability. To address this issue, in this paper, we propose a two-time-scale collaborative deep reinforcement learning (DRL) scheme for beam management and resource allocation in NTNs, in which LEO satellite and UE with different control cycles update their decision-making policies through a sequential manner. Specifically, UE updates its policy subject to improving the value functions of both the agents. Furthermore, the LEO satellite only makes decisions through finite-step rollouts with a reference decision trajectory received from the UE. Simulation results show that the proposed scheme can effectively balance the throughput performance and computational complexity over traditional greedy-searching schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04058",
        "abstract url": "https://arxiv.org/abs/2402.04058",
        "title": "A Digital Twin Design Methodology for Control, Simulation, and Monitoring of Fluidic Circuits",
        "rating": -3,
        "keywords": [
            [
                "synthesis"
            ],
            [
                "diagnosis"
            ]
        ],
        "abstract": "We propose a synthesis method for the design of digital twins applicable to various systems (pneumatic, hydraulic, electrical/electronic circuits). The methodology allows representing the operation of these systems through an active digital twin, thereby enabling a more suitable and easier computer-aided design, simulation, control, and monitoring. Furthermore, our methodology enables the detection of a system's actions on its own inputs (for example, in pneumatics: backflow of gases trapped in part of a fluidic system onto its own inputs). During the simulation or monitoring phase, the approach also facilitates real-time diagnosis of the controlled system. The outputs, on the controlled physical system or its digital twin, do not depend only on the current inputs but also on the history of the inputs and the history of internal states and variables. In other words, the underlying sequential logic has a memory while an only combinational logic approach does not. These capabilities can contribute to the digital transformation of the factory of the future.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2402.04070",
        "abstract url": "https://arxiv.org/abs/2402.04070",
        "title": "Spatial Assisted Human-Drone Collaborative Navigation and Interaction through Immersive Mixed Reality",
        "rating": -3,
        "keywords": [
            [
                "robot",
                "Navigation"
            ],
            [
                "Drone"
            ]
        ],
        "abstract": "Aerial robots have the potential to play a crucial role in assisting humans with complex and dangerous tasks. Nevertheless, the future industry demands innovative solutions to streamline the interaction process between humans and drones to enable seamless collaboration and efficient co-working. In this paper, we present a novel tele-immersive framework that promotes cognitive and physical collaboration between humans and robots through Mixed Reality (MR). This framework incorporates a novel bi-directional spatial awareness and a multi-modal virtual-physical interaction approaches. The former seamlessly integrates the physical and virtual worlds, offering bidirectional egocentric and exocentric environmental representations. The latter, leveraging the proposed spatial representation, further enhances the collaboration combining a robot planning algorithm for obstacle avoidance with a variable admittance control. This allows users to issue commands based on virtual forces while maintaining compatibility with the environment map. We validate the proposed approach by performing several collaborative planning and exploration tasks involving a drone and an user equipped with a MR headset.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Currently Accepted at International Conference on Robotics and Automation (ICRA) 2024, Nominated as Finalist for IEEE ICRA 2024 Best Paper Award on Unmanned Aerial Vehicles"
    },
    {
        "paper id": "2402.04142",
        "abstract url": "https://arxiv.org/abs/2402.04142",
        "title": "Human Emotions Analysis and Recognition Using EEG Signals in Response to 360$^\\circ$ Videos",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "health"
            ]
        ],
        "abstract": "Emotion recognition (ER) technology is an integral part for developing innovative applications such as drowsiness detection and health monitoring that plays a pivotal role in contemporary society. This study delves into ER using electroencephalography (EEG), within immersive virtual reality (VR) environments. There are four main stages in our proposed methodology including data acquisition, pre-processing, feature extraction, and emotion classification. Acknowledging the limitations of existing 2D datasets, we introduce a groundbreaking 3D VR dataset to elevate the precision of emotion elicitation. Leveraging the Interaxon Muse headband for EEG recording and Oculus Quest 2 for VR stimuli, we meticulously recorded data from 40 participants, prioritizing subjects without reported mental illnesses. Pre-processing entails rigorous cleaning, uniform truncation, and the application of a Savitzky-Golay filter to the EEG data. Feature extraction encompasses a comprehensive analysis of metrics such as power spectral density, correlation, rational and divisional asymmetry, and power spectrum. To ensure the robustness of our model, we employed a 10-fold cross-validation, revealing an average validation accuracy of 85.54\\%, with a noteworthy maximum accuracy of 90.20\\% in the best fold. Subsequently, the trained model demonstrated a commendable test accuracy of 82.03\\%, promising favorable outcomes.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04171",
        "abstract url": "https://arxiv.org/abs/2402.04171",
        "title": "3D Volumetric Super-Resolution in Radiology Using 3D RRDB-GAN",
        "rating": -3,
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "GAN",
                "Super-Resolution"
            ],
            [
                "medical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "This study introduces the 3D Residual-in-Residual Dense Block GAN (3D RRDB-GAN) for 3D super-resolution for radiology imagery. A key aspect of 3D RRDB-GAN is the integration of a 2.5D perceptual loss function, which contributes to improved volumetric image quality and realism. The effectiveness of our model was evaluated through 4x super-resolution experiments across diverse datasets, including Mice Brain MRH, OASIS, HCP1200, and MSD-Task-6. These evaluations, encompassing both quantitative metrics like LPIPS and FID and qualitative assessments through sample visualizations, demonstrate the models effectiveness in detailed image analysis. The 3D RRDB-GAN offers a significant contribution to medical imaging, particularly by enriching the depth, clarity, and volumetric detail of medical images. Its application shows promise in enhancing the interpretation and analysis of complex medical imagery from a comprehensive 3D perspective.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04228",
        "abstract url": "https://arxiv.org/abs/2402.04228",
        "title": "Intelligent Collective Escape of Swarm Robots Based on a Novel Fish-inspired Self-adaptive Approach with Neurodynamic Models",
        "rating": -3,
        "keywords": [
            [
                "robot"
            ],
            [
                "bio-inspired"
            ]
        ],
        "abstract": "Fish schools present high-efficiency group behaviors through simple individual interactions to collective migration and dynamic escape from the predator. The school behavior of fish is usually a good inspiration to design control architecture for swarm robots. In this paper, a novel fish-inspired self-adaptive approach is proposed for collective escape for the swarm robots. In addition, a bio-inspired neural network (BINN) is introduced to generate collision-free escape robot trajectories through the combination of attractive and repulsive forces. Furthermore, to cope with dynamic environments, a neurodynamics-based self-adaptive mechanism is proposed to improve the self-adaptive performance of the swarm robots in the changing environment. Similar to fish escape maneuvers, simulation and experimental results show that the swarm robots are capable of collectively leaving away from the threats. Several comparison studies demonstrated that the proposed approach can significantly improve the effectiveness and efficiency of system performance, and the flexibility and robustness in complex environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This article is accepted for publication in a future issue of IEEE Transactions on Industrial Electronics"
    },
    {
        "paper id": "2402.04299",
        "abstract url": "https://arxiv.org/abs/2402.04299",
        "title": "Translating the future: Image-to-image translation for the prediction of future brain metabolism",
        "rating": -3,
        "keywords": [
            [
                "diagnosis",
                "disease"
            ],
            [
                "forecast"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder leading to cognitive decline. [$^{18}$F]-Fluorodeoxyglucose positron emission tomography ([$^{18}$F]-FDG PET) is used to monitor brain metabolism, aiding in the diagnosis and assessment of AD over time. However, the feasibility of multi-time point [$^{18}$F]-FDG PET scans for diagnosis is limited due to radiation exposure, cost, and patient burden. To address this, we have developed a predictive image-to-image translation (I2I) model to forecast future [$^{18}$F]-FDG PET scans using baseline and year-one data. The proposed model employs a convolutional neural network architecture with long-short term memory and was trained on [$^{18}$F]-FDG PET data from 161 individuals from the Alzheimer's Disease Neuroimaging Initiative. Our I2I network showed high accuracy in predicting year-two [18F]-FDG PET scans, with a mean absolute error of 0.031 and a structural similarity index of 0.961. Furthermore, the model successfully predicted PET scans up to seven years post-baseline. Notably, the predicted [$^{18}$F]-FDG PET signal in an AD-susceptible meta-region was highly accurate for individuals with mild cognitive impairment across years. In contrast, a linear model was sufficient for predicting brain metabolism in cognitively normal and dementia subjects. In conclusion, both the I2I network and the linear model could offer valuable prognostic insights, guiding early intervention strategies to preemptively address anticipated declines in brain metabolism and potentially to monitor treatment effects.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Accepted to SPIE Medical Imaging 2024"
    },
    {
        "paper id": "2402.04332",
        "abstract url": "https://arxiv.org/abs/2402.04332",
        "title": "Proactive Blockage Prediction for UAV assisted Handover in Future Wireless Network",
        "rating": -3,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "The future wireless communication applications demand seamless connectivity, higher throughput, and low latency, for which the millimeter-wave (mmWave) band is considered a potential technology. Nevertheless, line-of-sight (LoS) is often mandatory for mmWave band communication, and it renders these waves sensitive to sudden changes in the environment. Therefore, it is necessary to maintain the LoS link for a reliable connection. One such technique to maintain LoS is using proactive handover (HO). However, proactive HO is challenging, requiring continuous information about the surrounding wireless network to anticipate potential blockage. This paper presents a proactive blockage prediction mechanism where an unmanned aerial vehicle (UAV) is used as the base station for HO. The proposed scheme uses computer vision (CV) to obtain potential blocking objects, user speed, and location. To assess the effectiveness of the proposed scheme, the system is evaluated using a publicly available dataset for blockage prediction. The study integrates scenarios from Vision-based Wireless (ViWi) and UAV channel modeling, generating wireless data samples relevant to UAVs. The antenna modeling on the UAV end incorporates a polarization-matched scenario to optimize signal reception. The results demonstrate that UAV-assisted Handover not only ensures seamless connectivity but also enhances overall network performance by 20%. This research contributes to the advancement of proactive blockage mitigation strategies in wireless networks, showcasing the potential of UAVs as dynamic and adaptable base stations.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04354",
        "abstract url": "https://arxiv.org/abs/2402.04354",
        "title": "3D printer-controlled syringe pumps for dual, active, regulable and simultaneous dispensing of reagents. Manufacturing of immunochromatographic test strips",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "biomarkers"
            ]
        ],
        "abstract": "Lateral flow immunoassays (LFIA) are widely used worldwide for the detection of different analytes because they combine multiple advantages such as low production cost, simplicity, and portability, which allows biomarkers detection without requiring infrastructure or highly trained personnel. Here we propose to provide solutions to the manufacturing process of LFIA at laboratory-scale, particularly to the controlled and active dispensing of the reagents in the form the Test Lines (TL) and the Control Lines (CL). To accomplish this task, we adapted a 3D printer to also control Syringe Pumps (SP), since the proposed adaptation of a 3D printer is easy, free and many laboratories already have it in their infrastructure. In turn, the standard function of the 3D printer can be easily restored by disconnecting the SPs and reconnecting the extruder. Additionally, the unified control of the 3D printer enables dual, active, regulable and simultaneous dispensing, four features that are typically found only in certain high-cost commercial equipment. With the proposed setup, the challenge of dispensing simultaneously at least 2 lines (CL and TL) with SPs controlled by a 3D printer was addressed, including regulation in the width of dispensed lines within experimental limits. Also, the construction of a LFIA for the detection of leptospirosis is shown as a practical example of automatized reagent dispensing.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "19 pages, 4 figures"
    },
    {
        "paper id": "2402.04426",
        "abstract url": "https://arxiv.org/abs/2402.04426",
        "title": "Quantitative Metrics for Benchmarking Medical Image Harmonization",
        "rating": -3,
        "keywords": [
            [
                "Medical"
            ],
            [
                "quality assessment"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Image harmonization is an important preprocessing strategy to address domain shifts arising from data acquired using different machines and scanning protocols in medical imaging. However, benchmarking the effectiveness of harmonization techniques has been a challenge due to the lack of widely available standardized datasets with ground truths. In this context, we propose three metrics: two intensity harmonization metrics and one anatomy preservation metric for medical images during harmonization, where no ground truths are required. Through extensive studies on a dataset with available harmonization ground truth, we demonstrate that our metrics are correlated with established image quality assessment metrics. We show how these novel metrics may be applied to real-world scenarios where no harmonization ground truth exists. Additionally, we provide insights into different interpretations of the metric values, shedding light on their significance in the context of the harmonization process. As a result of our findings, we advocate for the adoption of these quantitative harmonization metrics as a standard for benchmarking the performance of image harmonization techniques.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Accepted for presentation at the ISBI 2024"
    },
    {
        "paper id": "2402.04431",
        "abstract url": "https://arxiv.org/abs/2402.04431",
        "title": "ARMAN: A Reconfigurable Monolithic 3D Accelerator Architecture for Convolutional Neural Networks",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "face"
            ]
        ],
        "abstract": "The Convolutional Neural Network (CNN) has emerged as a powerful and versatile tool for artificial intelligence (AI) applications. Conventional computing architectures face challenges in meeting the demanding processing requirements of compute-intensive CNN applications, as they suffer from limited throughput and low utilization. To this end, specialized accelerators have been developed to speed up CNN computations. However, as we demonstrate in this paper via extensive design space exploration, different neural network models have different characteristics, which calls for different accelerator architectures and configurations to match their computing demand. We show that a one-size-fits-all fixed architecture does not guarantee optimal power/energy/performance trade-off. To overcome this challenge, this paper proposes ARMAN, a novel reconfigurable systolic-array-based accelerator architecture based on Monolithic 3D (M3D) technology for CNN inference. The proposed accelerator offers the flexibility to reconfigure among different scale-up or scale-out arrangements depending on the neural network structure, providing the optimal trade-off across power, energy, and performance for various neural network models. We demonstrate the effectiveness of our approach through evaluations of multiple benchmarks. The results demonstrate that the proposed accelerator exhibits up to 2x, 2.24x, 1.48x, and 2x improvements in terms of execution cycles, power, energy, and EDP respectively, over the non-configurable architecture.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04517",
        "abstract url": "https://arxiv.org/abs/2402.04517",
        "title": "Automating the audit of electronic invoices with a soft robot",
        "rating": -3,
        "keywords": [
            [
                "robot"
            ],
            [
                "Medical"
            ]
        ],
        "abstract": "Taiwan's Chi Mei Medical Center has completed four challenges mentioned in published robotic process automation (RPA) studies including automating a dynamic process, designing feasible human-robot collaboration, incorporating other emerging technologies, and bringing positive business impacts. Its executives called a committee to implement the electronic invoicing. This implementation includes the creation of a software robot to download automatically cloud electronic invoice (E-invoice) data from Taiwan's E-invoice platform and detect the inconsistency between them and on-premise data. This bot operates when internal auditors are off their office. They satisfied this software robot since the remaining work is only verifying the resulting inconsistency. The Chi Mei Medical Center measured the time and costs before and after adopting software robots to audit E-invoice; consequently, it welcomed more bots automating other business processes. In conclusion, integrating a software robot with other emerging technologies mitigates the possible errors provided by this bot. A good human-robot collaboration relies on the consideration of human perspective in choosing RPA tasks. Free bot creators are sufficient to verify that automating a business process using a bot is a reasonable investment.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "11 pages, 6 figures, 1 table"
    },
    {
        "paper id": "2402.04518",
        "abstract url": "https://arxiv.org/abs/2402.04518",
        "title": "FLAGRED -- Fuzzy Logic-based Algorithm Generalizing Risk Estimation for Drones",
        "rating": -3,
        "keywords": [
            [
                "robot"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "Accurately estimating risk in real-time is essential for ensuring the safety and efficiency of many applications involving autonomous robot systems. This paper presents a novel, generalizable algorithm for the real-time estimation of risks created by external disturbances on multirotors. Unlike conventional approaches, our method requires no additional sensors, accurate drone models, or large datasets. It employs motor command data in a fuzzy logic system, overcoming barriers to real-world implementation. Inherently adaptable, it utilizes fundamental drone characteristics, making it applicable to diverse drone models. The efficiency of the algorithm has been confirmed through comprehensive real-world testing on various platforms. It proficiently discerned between high and low-risk scenarios resulting from diverse wind disturbances and varying thrust-to-weight ratios. The algorithm surpassed the widely-recognized ArduCopter wind estimation algorithm in performance and demonstrated its capability to promptly detect brief gusts.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 9 figures"
    },
    {
        "paper id": "2402.04533",
        "abstract url": "https://arxiv.org/abs/2402.04533",
        "title": "Minimizing Block Incentive Volatility Through Verkle Tree-Based Dynamic Transaction Storage",
        "rating": -3,
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "Transaction fees are a crucial revenue source for miners in public and consortium blockchains. However, while public blockchains have additional revenue streams, transaction fees serve as the primary income for miners in consortium blockchains formed by various financial institutions. These miners allocate different levels of computing resources to process transactions and earn corresponding fees. Nonetheless, relying solely on transaction fees can lead to significant volatility and encourage non-standard mining behaviors, thereby posing threats to the blockchain's security and integrity. Despite previous attempts to mitigate the impact of transaction fees on illicit mining behaviors, a comprehensive solution to this vulnerability is yet to be established. To address this gap, we introduce a novel approach that leverages Dynamic Transaction Storage (DTS) strategies to effectively minimize block incentive volatility. Our solution implements a Verkle tree-based storage mechanism to reduce bandwidth consumption. Moreover, to configure the DTS strategies, we evaluate several optimization algorithms and formulate the challenge as a Vehicle Routing Problem. Our experiments conducted using historical transactions from Bitcoin and remittance data from the Industrial and Commercial Bank of China reveal that the strategy focusing on time-based transaction incorporation priority, while excluding a designated space for small-fee transactions, as discovered by the gradient-based optimizer algorithm, proves most effective in reducing volatility. Hence, the DTS strategy can sustain stable block incentives irrespective of transaction types or user bidding behavior. Furthermore, the inclusion of higher-fee transactions, often smaller in size, can alleviate propagation delays and the occurrence of forks.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06663",
        "abstract url": "https://arxiv.org/abs/2402.06663",
        "title": "Explainable Adversarial Learning Framework on Physical Layer Secret Keys Combating Malicious Reconfigurable Intelligent Surface",
        "rating": -3,
        "keywords": [
            [
                "GAN"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "The development of reconfigurable intelligent surfaces (RIS) is a double-edged sword to physical layer security (PLS). Whilst a legitimate RIS can yield beneficial impacts including increased channel randomness to enhance physical layer secret key generation (PL-SKG), malicious RIS can poison legitimate channels and crack most of existing PL-SKGs. In this work, we propose an adversarial learning framework between legitimate parties (namely Alice and Bob) to address this Man-in-the-middle malicious RIS (MITM-RIS) eavesdropping. First, the theoretical mutual information gap between legitimate pairs and MITM-RIS is deduced. Then, Alice and Bob leverage generative adversarial networks (GANs) to learn to achieve a common feature surface that does not have mutual information overlap with MITM-RIS. Next, we aid signal processing interpretation of black-box neural networks by using a symbolic explainable AI (xAI) representation. These symbolic terms of dominant neurons aid feature engineering-based validation and future design of PLS common feature space. Simulation results show that our proposed GAN-based and symbolic-based PL-SKGs can achieve high key agreement rates between legitimate users, and is even resistant to MITM-RIS Eve with the knowledge of legitimate feature generation (NNs or formulas). This therefore paves the way to secure wireless communications with untrusted reflective devices in future 6G.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08808",
        "abstract url": "https://arxiv.org/abs/2403.08808",
        "title": "A Bionic Data-driven Approach for Long-distance Underwater Navigation with Anomaly Resistance",
        "rating": -3,
        "keywords": [
            [
                "Navigation"
            ],
            [
                "Bionic"
            ]
        ],
        "abstract": "Various animals exhibit accurate navigation using environment cues. The Earth's magnetic field has been proved a reliable information source in long-distance fauna migration. Inspired by animal navigation, this work proposes a bionic and data-driven approach for long-distance underwater navigation. The proposed approach uses measured geomagnetic data for the navigation, and requires no GPS systems or geographical maps. Particularly, we construct and train a Temporal Attention-based Long Short-Term Memory (TA-LSTM) network to predict the heading angle during the navigation. To mitigate the impact of geomagnetic anomalies, we develop the mechanism to detect and quantify the anomalies based on Maximum Likelihood Estimation. We integrate the developed mechanism with the TA-LSTM, and calibrate the predicted heading angles to gain resistance against geomagnetic anomalies. Using the retrieved data from the WMM model, we conduct numerical simulations with diversified navigation conditions to test our approach. The simulation results demonstrate a resilience navigation against geomagnetic anomalies by our approach, along with precision and stability of the underwater navigation in single and multiple destination missions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.08643",
        "abstract url": "https://arxiv.org/abs/2404.08643",
        "title": "6AInets: Harnessing artificial intelligence for the 6G network security: Impacts and Challenges",
        "rating": -3,
        "keywords": [
            [
                "attack"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "This decade has witnessed the initiation of the digital revolution, as anticipated with the advent of 5G networks. Looking ahead to the 6G communication era, considerations are being made regarding how individuals will engage with the digital virtual world. The design of 6G technology, which will present enormous opportunities to develop and enhance human potential, will have a major impact on communications in the 2030s. We believe that in 6G we will see an unprecedented transformation that will set it apart from earlier wireless cellular network generations. Specifically, 6G will leverage ubiquitous AI services ranging from the network's core to its end devices, going beyond unpredictable limits. Despite the numerous advantages offered by 6G over existing technologies, there remains a pressing need to address security concerns. For example, the automation of critical processes in the 6G infrastructure will lead to a significantly broader and more intricate attack surface. Thus, the significance of Artificial Intelligence (AI) in providing security aspects within the envisioned 6G paradigm is substantial, but its integration presents a dual-edged dynamic. Therefore, to strengthen and validate the relevance of AI in securing 6G networks, this article elucidates how AI can be strategically used in 6G security, addressing potential challenges, and proposing solutions to enhance its role in securing networks.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "7 pages, 1 figure"
    },
    {
        "paper id": "2402.04030",
        "abstract url": "https://arxiv.org/abs/2402.04030",
        "title": "Reducing the Cost of Quantum Chemical Data By Backpropagating Through Density Functional Theory",
        "rating": -3.5,
        "keywords": [
            [
                "Chemical"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Density Functional Theory (DFT) accurately predicts the quantum chemical properties of molecules, but scales as $O(N_{\\text{electrons}}^3)$. Sch\u00fctt et al. (2019) successfully approximate DFT 1000x faster with Neural Networks (NN). Arguably, the biggest problem one faces when scaling to larger molecules is the cost of DFT labels. For example, it took years to create the PCQ dataset (Nakata & Shimazaki, 2017) on which subsequent NNs are trained within a week. DFT labels molecules by minimizing energy $E(\\cdot )$ as a \"loss function.\" We bypass dataset creation by directly training NNs with $E(\\cdot )$ as a loss function. For comparison, Sch\u00fctt et al. (2019) spent 626 hours creating a dataset on which they trained their NN for 160h, for a total of 786h; our method achieves comparable performance within 31h.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05138",
        "abstract url": "https://arxiv.org/abs/2402.05138",
        "title": "SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark",
        "rating": -3.5,
        "keywords": [
            [
                "Biology"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including Mathematics, Physics, Chemistry, and Biology. It features a blend of multiple-choice and free-response formats, ensuring a comprehensive evaluation of AI models' abilities. Additionally, our benchmark provides specific knowledge points for each problem and detailed explanations for each answer. SceMQA also uniquely presents problems with identical contexts but varied questions to facilitate a more thorough and accurate assessment of reasoning capabilities. In the experiment, we evaluate both open-source and close-source state-of-the-art Multimodal Large Language Models (MLLMs), across various experimental settings. The results show that further research and development are needed in developing more capable MLLM, as highlighted by only 50% to 60% accuracy achieved by the strongest models. Our benchmark and analysis will be available at https://scemqa.github.io/",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2402.05140",
        "abstract url": "https://arxiv.org/abs/2402.05140",
        "title": "Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains",
        "rating": -3.5,
        "keywords": [
            [
                "biomedical"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in understanding and generating natural language. However, their capabilities wane in highly specialized domains underrepresented in the pretraining corpus, such as physical and biomedical sciences. This work explores how to repurpose general LLMs into effective task solvers for specialized domains. We introduce a novel, model-agnostic framework for learning custom input tags, which are parameterized as continuous vectors appended to the LLM's embedding layer, to condition the LLM. We design two types of input tags: domain tags are used to delimit specialized representations (e.g., chemical formulas) and provide domain-relevant context; function tags are used to represent specific functions (e.g., predicting molecular properties) and compress function-solving instructions. We develop a three-stage protocol to learn these tags using auxiliary data and domain knowledge. By explicitly disentangling task domains from task functions, our method enables zero-shot generalization to unseen problems through diverse combinations of the input tags. It also boosts LLM's performance in various specialized domains, such as predicting protein or chemical properties and modeling drug-target interactions, outperforming expert models tailored to these tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04061",
        "abstract url": "https://arxiv.org/abs/2402.04061",
        "title": "TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments",
        "rating": -4,
        "keywords": [
            [
                "robot",
                "Navigation"
            ],
            [
                "graph"
            ],
            [
                "face"
            ]
        ],
        "abstract": "Autonomous robots exploring unknown environments face a significant challenge: navigating effectively without prior maps and with limited external feedback. This challenge intensifies in sparse reward environments, where traditional exploration techniques often fail. In this paper, we present TopoNav, a novel topological navigation framework that integrates active mapping, hierarchical reinforcement learning, and intrinsic motivation to enable efficient goal-oriented exploration and navigation in sparse-reward settings. TopoNav dynamically constructs a topological map of the environment, capturing key locations and pathways. A two-level hierarchical policy architecture, comprising a high-level graph traversal policy and low-level motion control policies, enables effective navigation and obstacle avoidance while maintaining focus on the overall goal. Additionally, TopoNav incorporates intrinsic motivation to guide exploration toward relevant regions and frontier nodes in the topological map, addressing the challenges of sparse extrinsic rewards. We evaluate TopoNav both in the simulated and real-world off-road environments using a Clearpath Jackal robot, across three challenging navigation scenarios: goal-reaching, feature-based navigation, and navigation in complex terrains. We observe an increase in exploration coverage by 7- 20%, in success rates by 9-19%, and reductions in navigation times by 15-36% across various scenarios, compared to state-of-the-art methods",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Paper under review for IROS 2024"
    },
    {
        "paper id": "2402.04097",
        "abstract url": "https://arxiv.org/abs/2402.04097",
        "title": "Analysis of Deep Image Prior and Exploiting Self-Guidance for Image Reconstruction",
        "rating": -4,
        "keywords": [
            [
                "inpainting"
            ],
            [
                "medical",
                "MRI"
            ],
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The ability of deep image prior (DIP) to recover high-quality images from incomplete or corrupted measurements has made it popular in inverse problems in image restoration and medical imaging including magnetic resonance imaging (MRI). However, conventional DIP suffers from severe overfitting and spectral bias effects. In this work, we first provide an analysis of how DIP recovers information from undersampled imaging measurements by analyzing the training dynamics of the underlying networks in the kernel regime for different architectures. This study sheds light on important underlying properties for DIP-based recovery. Current research suggests that incorporating a reference image as network input can enhance DIP's performance in image reconstruction compared to using random inputs. However, obtaining suitable reference images requires supervision, and raises practical difficulties. In an attempt to overcome this obstacle, we further introduce a self-driven reconstruction process that concurrently optimizes both the network weights and the input while eliminating the need for training data. Our method incorporates a novel denoiser regularization term which enables robust and stable joint estimation of both the network input and reconstructed image. We demonstrate that our self-guided method surpasses both the original DIP and modern supervised methods in terms of MR image reconstruction performance and outperforms previous DIP-based schemes for image inpainting.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04447",
        "abstract url": "https://arxiv.org/abs/2402.04447",
        "title": "Context-Aware Spectrum Coexistence of Terrestrial Beyond 5G Networks in Satellite Bands",
        "rating": -4,
        "keywords": [
            [
                "5G"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Spectrum sharing between terrestrial 5G and incumbent networks in the satellite bands presents a promising avenue to satisfy the ever-increasing bandwidth demand of the next-generation wireless networks. However, protecting incumbent operations from harmful interference poses a fundamental challenge in accommodating terrestrial broadband cellular networks in the satellite bands. State-of-the-art spectrum-sharing policies usually consider several worst-case assumptions and ignore site-specific contextual factors in making spectrum-sharing decisions, and thus, often results in under-utilization of the shared band for the secondary licensees. To address such limitations, this paper introduces CAT3S (Context-Aware Terrestrial-Satellite Spectrum Sharing) framework that empowers the coexisting terrestrial 5G network to maximize utilization of the shared satellite band without creating harmful interference to the incumbent links by exploiting the contextual factors. CAT3S consists of the following two components: (i) context-acquisition unit to collect and process essential contextual information for spectrum sharing and (ii) context-aware base station (BS) control unit to optimize the set of operational BSs and their operation parameters (i.e., transmit power and active beams per sector). To evaluate the performance of the CAT3S, a realistic spectrum coexistence case study over the 12 GHz band is considered. Experiment results demonstrate that the proposed CAT3S achieves notably higher spectrum utilization than state-of-the-art spectrum-sharing policies in different weather contexts.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04498",
        "abstract url": "https://arxiv.org/abs/2402.04498",
        "title": "Pathspace Kalman Filters with Dynamic Process Uncertainty for Analyzing Time-course Data",
        "rating": -4,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Kalman Filter (KF) is an optimal linear state prediction algorithm, with applications in fields as diverse as engineering, economics, robotics, and space exploration. Here, we develop an extension of the KF, called a Pathspace Kalman Filter (PKF) which allows us to a) dynamically track the uncertainties associated with the underlying data and prior knowledge, and b) take as input an entire trajectory and an underlying mechanistic model, and using a Bayesian methodology quantify the different sources of uncertainty. An application of this algorithm is to automatically detect temporal windows where the internal mechanistic model deviates from the data in a time-dependent manner. First, we provide theorems characterizing the convergence of the PKF algorithm. Then, we numerically demonstrate that the PKF outperforms conventional KF methods on a synthetic dataset lowering the mean-squared-error by several orders of magnitude. Finally, we apply this method to biological time-course dataset involving over 1.8 million gene expression measurements.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "32 pages, 8 figures, Submitted for review"
    },
    {
        "paper id": "2402.04507",
        "abstract url": "https://arxiv.org/abs/2402.04507",
        "title": "A Review on Digital Pixel Sensors",
        "rating": -4,
        "keywords": [
            [
                "3D"
            ],
            [
                "medical"
            ],
            [
                "IoT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Digital pixel sensor (DPS) has evolved as a pivotal component in modern imaging systems and has the potential to revolutionize various fields such as medical imaging, astronomy, surveillance, IoT devices, etc. Compared to analog pixel sensors, the DPS offers high speed and good image quality. However, the introduced intrinsic complexity within each pixel, primarily attributed to the accommodation of the ADC circuit, engenders a substantial increase in the pixel pitch. Unfortunately, such a pronounced escalation in pixel pitch drastically undermines the feasibility of achieving high-density integration, which is an obstacle that significantly narrows down the field of potential applications. Nonetheless, designing compact conversion circuits along with strategic integration of 3D architectural paradigms can be a potential remedy to the prevailing situation. This review article presents a comprehensive overview of the vast area of DPS technology. The operating principles, advantages, and challenges of different types of DPS circuits have been analyzed. We categorize the schemes into several categories based on ADC operation. A comparative study based on different performance metrics has also been showcased for a well-rounded understanding.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.00765",
        "abstract url": "https://arxiv.org/abs/2403.00765",
        "title": "An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots",
        "rating": -4,
        "keywords": [
            [
                "3D"
            ],
            [
                "robot"
            ],
            [
                "face"
            ]
        ],
        "abstract": "As data science applications gain adoption across industries, the tooling landscape matures to facilitate the life cycle of such applications and provide solutions to the challenges involved to boost the productivity of the people involved. Reinforcement learning with agents in a 3D world could still face challenges: the knowledge required to use a simulation software as well as the utilization of a standalone simulation software in unattended training pipelines. In this paper we review tools and approaches to train reinforcement learning agents for robots in 3D worlds with respect to the robot Robotino and argue that the separation of the simulation environment for creators of virtual worlds and the model development environment for data scientists is not a well covered topic. Often both are the same and data scientists require knowledge of the simulation software to work directly with their APIs. Moreover, sometimes creators of virtual worlds and data scientists even work on the same files. We want to contribute to that topic by describing an approach where data scientists don't require knowledge about the simulation software. Our approach uses the standalone simulation software Webots, the Robot Operating System to communicate with simulated robots as well as the simulation software itself and container technology to separate the simulation from the model development environment. We put emphasize on the APIs the data scientists work with and the use of a standalone simulation software in unattended training pipelines. We show the parts that are specific to the Robotino and the robot task to learn.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Latex with llncs.cls, 17 pages, 5 figures"
    },
    {
        "paper id": "2402.03706",
        "abstract url": "https://arxiv.org/abs/2402.03706",
        "title": "MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats",
        "rating": -5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "thermal"
            ],
            [
                "UAV",
                "Drone"
            ]
        ],
        "abstract": "In response to the evolving challenges posed by small unmanned aerial vehicles (UAVs), which possess the potential to transport harmful payloads or independently cause damage, we introduce MMAUD: a comprehensive Multi-Modal Anti-UAV Dataset. MMAUD addresses a critical gap in contemporary threat detection methodologies by focusing on drone detection, UAV-type classification, and trajectory estimation. MMAUD stands out by combining diverse sensory inputs, including stereo vision, various Lidars, Radars, and audio arrays. It offers a unique overhead aerial detection vital for addressing real-world scenarios with higher fidelity than datasets captured on specific vantage points using thermal and RGB. Additionally, MMAUD provides accurate Leica-generated ground truth data, enhancing credibility and enabling confident refinement of algorithms and models, which has never been seen in other datasets. Most existing works do not disclose their datasets, making MMAUD an invaluable resource for developing accurate and efficient solutions. Our proposed modalities are cost-effective and highly adaptable, allowing users to experiment and implement new UAV threat detection tools. Our dataset closely simulates real-world scenarios by incorporating ambient heavy machinery sounds. This approach enhances the dataset's applicability, capturing the exact challenges faced during proximate vehicular operations. It is expected that MMAUD can play a pivotal role in advancing UAV threat detection, classification, trajectory estimation capabilities, and beyond. Our dataset, codes, and designs will be available in https://github.com/ntu-aris/MMAUD.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted by ICRA 2024"
    },
    {
        "paper id": "2402.03784",
        "abstract url": "https://arxiv.org/abs/2402.03784",
        "title": "AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction",
        "rating": -5.0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "graph"
            ],
            [
                "health"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Air quality prediction and modelling plays a pivotal role in public health and environment management, for individuals and authorities to make informed decisions. Although traditional data-driven models have shown promise in this domain, their long-term prediction accuracy can be limited, especially in scenarios with sparse or incomplete data and they often rely on black-box deep learning structures that lack solid physical foundation leading to reduced transparency and interpretability in predictions. To address these limitations, this paper presents a novel approach named Physics guided Neural Network for Air Quality Prediction (AirPhyNet). Specifically, we leverage two well-established physics principles of air particle movement (diffusion and advection) by representing them as differential equation networks. Then, we utilize a graph structure to integrate physics knowledge into a neural network architecture and exploit latent representations to capture spatio-temporal relationships within the air quality data. Experiments on two real-world benchmark datasets demonstrate that AirPhyNet outperforms state-of-the-art models for different testing scenarios including different lead time (24h, 48h, 72h), sparse data and sudden change prediction, achieving reduction in prediction errors up to 10%. Moreover, a case study further validates that our model captures underlying physical processes of particle movement and generates accurate predictions with real physical meaning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by the 12th International Conference on Learning Representations (ICLR 2024)"
    },
    {
        "paper id": "2402.03981",
        "abstract url": "https://arxiv.org/abs/2402.03981",
        "title": "Controllable Diverse Sampling for Diffusion Based Motion Behavior Forecasting",
        "rating": -5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "autonomous driving",
                "trajectory"
            ],
            [
                "face"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In autonomous driving tasks, trajectory prediction in complex traffic environments requires adherence to real-world context conditions and behavior multimodalities. Existing methods predominantly rely on prior assumptions or generative models trained on curated data to learn road agents' stochastic behavior bounded by scene constraints. However, they often face mode averaging issues due to data imbalance and simplistic priors, and could even suffer from mode collapse due to unstable training and single ground truth supervision. These issues lead the existing methods to a loss of predictive diversity and adherence to the scene constraints. To address these challenges, we introduce a novel trajectory generator named Controllable Diffusion Trajectory (CDT), which integrates map information and social interactions into a Transformer-based conditional denoising diffusion model to guide the prediction of future trajectories. To ensure multimodality, we incorporate behavioral tokens to direct the trajectory's modes, such as going straight, turning right or left. Moreover, we incorporate the predicted endpoints as an alternative behavioral token into the CDT model to facilitate the prediction of accurate trajectories. Extensive experiments on the Argoverse 2 benchmark demonstrate that CDT excels in generating diverse and scene-compliant trajectories in complex urban settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04032",
        "abstract url": "https://arxiv.org/abs/2402.04032",
        "title": "HEAM : Hashed Embedding Acceleration using Processing-In-Memory",
        "rating": -5,
        "keywords": [
            [
                "3D"
            ],
            [
                "face"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "In today's data centers, personalized recommendation systems face challenges such as the need for large memory capacity and high bandwidth, especially when performing embedding operations. Previous approaches have relied on DIMM-based near-memory processing techniques or introduced 3D-stacked DRAM to address memory-bound issues and expand memory bandwidth. However, these solutions fall short when dealing with the expanding size of personalized recommendation systems. Recommendation models have grown to sizes exceeding tens of terabytes, making them challenging to run efficiently on traditional single-node inference servers. Although various algorithmic methods have been proposed to reduce embedding table capacity, they often result in increased memory access or inefficient utilization of memory resources. This paper introduces HEAM, a heterogeneous memory architecture that integrates 3D-stacked DRAM with DIMM to accelerate recommendation systems in which compositional embedding is utilized-a technique aimed at reducing the size of embedding tables. The architecture is organized into a three-tier memory hierarchy consisting of conventional DIMM, 3D-stacked DRAM with a base die-level Processing-In-Memory (PIM), and a bank group-level PIM incorporating lookup tables. This setup is specifically designed to accommodate the unique aspects of compositional embedding, such as temporal locality and embedding table capacity. This design effectively reduces bank access, improves access efficiency, and enhances overall throughput, resulting in a 6.3 times speedup and 58.9% energy savings compared to the baseline.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "10 pages, 12 figures"
    },
    {
        "paper id": "2402.04178",
        "abstract url": "https://arxiv.org/abs/2402.04178",
        "title": "SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models",
        "rating": -5,
        "keywords": [
            [
                "depth"
            ],
            [
                "diffusion",
                "GAN"
            ],
            [
                "infrared"
            ],
            [
                "attack"
            ],
            [
                "Face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal large language models (MLLMs) have demonstrated remarkable problem-solving capabilities in various vision fields (e.g., generic object recognition and grounding) based on strong visual semantic representation and language reasoning ability. However, whether MLLMs are sensitive to subtle visual spoof/forged clues and how they perform in the domain of face attack detection (e.g., face spoofing and forgery detection) is still unexplored. In this paper, we introduce a new benchmark, namely SHIELD, to evaluate the ability of MLLMs on face spoofing and forgery detection. Specifically, we design true/false and multiple-choice questions to evaluate multimodal face data in these two face security tasks. For the face anti-spoofing task, we evaluate three different modalities (i.e., RGB, infrared, depth) under four types of presentation attacks (i.e., print attack, replay attack, rigid mask, paper mask). For the face forgery detection task, we evaluate GAN-based and diffusion-based data with both visual and acoustic modalities. Each question is subjected to both zero-shot and few-shot tests under standard and chain of thought (COT) settings. The results indicate that MLLMs hold substantial potential in the face security domain, offering advantages over traditional specific models in terms of interpretability, multimodal flexible reasoning, and joint face spoof and forgery detection. Additionally, we develop a novel Multi-Attribute Chain of Thought (MA-COT) paradigm for describing and judging various task-specific and task-irrelevant attributes of face images, which provides rich task-related knowledge for subtle spoof/forged clue mining. Extensive experiments in separate face anti-spoofing, separate face forgery detection, and joint detection tasks demonstrate the effectiveness of the proposed MA-COT. The project is available at https$:$//github.com/laiyingxin2/SHIELD",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04519",
        "abstract url": "https://arxiv.org/abs/2402.04519",
        "title": "BioDrone: A Bionic Drone-based Single Object Tracking Benchmark for Robust Vision",
        "rating": -5,
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "BioDrone"
            ],
            [
                "UAV",
                "Drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Single object tracking (SOT) is a fundamental problem in computer vision, with a wide range of applications, including autonomous driving, augmented reality, and robot navigation. The robustness of SOT faces two main challenges: tiny target and fast motion. These challenges are especially manifested in videos captured by unmanned aerial vehicles (UAV), where the target is usually far away from the camera and often with significant motion relative to the camera. To evaluate the robustness of SOT methods, we propose BioDrone -- the first bionic drone-based visual benchmark for SOT. Unlike existing UAV datasets, BioDrone features videos captured from a flapping-wing UAV system with a major camera shake due to its aerodynamics. BioDrone hence highlights the tracking of tiny targets with drastic changes between consecutive frames, providing a new robust vision benchmark for SOT. To date, BioDrone offers the largest UAV-based SOT benchmark with high-quality fine-grained manual annotations and automatically generates frame-level labels, designed for robust vision analyses. Leveraging our proposed BioDrone, we conduct a systematic evaluation of existing SOT methods, comparing the performance of 20 representative models and studying novel means of optimizing a SOTA method (KeepTrack KeepTrack) for robust SOT. Our evaluation leads to new baselines and insights for robust SOT. Moving forward, we hope that BioDrone will not only serve as a high-quality benchmark for robust SOT, but also invite future research into robust computer vision. The database, toolkits, evaluation server, and baseline results are available at http://biodrone.aitestunion.com.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper is published in IJCV (refer to DOI). Please cite the published IJCV"
    },
    {
        "paper id": "2402.06666",
        "abstract url": "https://arxiv.org/abs/2402.06666",
        "title": "Weather Prediction with Diffusion Guided by Realistic Forecast Processes",
        "rating": -5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "face"
            ],
            [
                "Forecast"
            ]
        ],
        "abstract": "Weather forecasting remains a crucial yet challenging domain, where recently developed models based on deep learning (DL) have approached the performance of traditional numerical weather prediction (NWP) models. However, these DL models, often complex and resource-intensive, face limitations in flexibility post-training and in incorporating NWP predictions, leading to reliability concerns due to potential unphysical predictions. In response, we introduce a novel method that applies diffusion models (DM) for weather forecasting. In particular, our method can achieve both direct and iterative forecasting with the same modeling framework. Our model is not only capable of generating forecasts independently but also uniquely allows for the integration of NWP predictions, even with varying lead times, during its sampling process. The flexibility and controllability of our model empowers a more trustworthy DL system for the general weather community. Additionally, incorporating persistence and climatology data further enhances our model's long-term forecasting stability. Our empirical findings demonstrate the feasibility and generalizability of this approach, suggesting a promising direction for future, more sophisticated diffusion models without the need for retraining.",
        "subjects": [
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03707",
        "abstract url": "https://arxiv.org/abs/2402.03707",
        "title": "RLAs for 2-Seat STV Elections: Revisited",
        "rating": -10,
        "keywords": [],
        "abstract": "Single Transferable Vote (STV) elections are a principled approach to electing multiple candidates in a single election. Each ballot has a starting value of 1, and a candidate is elected if they gather a total vote value more than a defined quota. Votes over the quota have their value reduced by a transfer value so as to remove the quota, and are passed to the next candidate on the ballot. Risk-limiting audits (RLAs) are a statistically sound approach to election auditing which guarantees that failure to detect an error in the result is bounded by a limit. A first approach to RLAs for 2-seat STV elections has been defined. In this paper we show how we can improve this approach by reasoning about lower bounds on transfer values, and how we can extend the approach to partially audit an election, if the method does not support a full audit.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03735",
        "abstract url": "https://arxiv.org/abs/2402.03735",
        "title": "Investigating the Utility of ChatGPT in the Issue Tracking System: An Exploratory Study",
        "rating": -10,
        "keywords": [],
        "abstract": "Issue tracking systems serve as the primary tool for incorporating external users and customizing a software project to meet the users' requirements. However, the limited number of contributors and the challenge of identifying the best approach for each issue often impede effective resolution. Recently, an increasing number of developers are turning to AI tools like ChatGPT to enhance problem-solving efficiency. While previous studies have demonstrated the potential of ChatGPT in areas such as automatic program repair, debugging, and code generation, there is a lack of study on how developers explicitly utilize ChatGPT to resolve issues in their tracking system. Hence, this study aims to examine the interaction between ChatGPT and developers to analyze their prevalent activities and provide a resolution. In addition, we assess the code reliability by confirming if the code produced by ChatGPT was integrated into the project's codebase using the clone detection tool NiCad. Our investigation reveals that developers mainly use ChatGPT for brainstorming solutions but often opt to write their code instead of using ChatGPT-generated code, possibly due to concerns over the generation of \"hallucinated code\", as highlighted in the literature.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted in MSR 2024"
    },
    {
        "paper id": "2402.03772",
        "abstract url": "https://arxiv.org/abs/2402.03772",
        "title": "Fundamental Limits of Two-Hop MIMO Channels: An Asymptotic Approach",
        "rating": -10,
        "keywords": [],
        "abstract": "Multi-antenna relays and intelligent reflecting surfaces (IRSs) have been utilized to construct favorable channels to improve the performance of wireless systems. A common feature between relay systems and IRS-aided systems is the two-hop multiple-input multiple-output (MIMO) channel. As a result, the mutual information (MI) of two-hop MIMO channels has been widely investigated with very engaging results. However, a rigorous investigation on the fundamental limits of two-hop MIMO channels, i.e., the first and second-order analysis, is not yet available in the literature, due to the difficulties caused by the two-hop (product) channel and the noise introduced by the relay (active IRS). In this paper, we employ large-scale random matrix theory (RMT), specifically Gaussian tools, to derive the closed-form deterministic approximation for the mean and variance of the MI. Additionally, we determine the convergence rate for the mean, variance and the characteristic function of the MI, and prove the asymptotic Gaussianity. Furthermore, we also investigate the analytical properties of the fundamental equations that describe the closed-form approximation and prove the existence and uniqueness of the solution. An iterative algorithm is then proposed to obtain the solution for the fundamental equations. Numerical results validate the accuracy of the theoretical analysis.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03773",
        "abstract url": "https://arxiv.org/abs/2402.03773",
        "title": "Encoding Version History Context for Better Code Representation",
        "rating": -10,
        "keywords": [],
        "abstract": "With the exponential growth of AI tools that generate source code, understanding software has become crucial. When developers comprehend a program, they may refer to additional contexts to look for information, e.g. program documentation or historical code versions. Therefore, we argue that encoding this additional contextual information could also benefit code representation for deep learning. Recent papers incorporate contextual data (e.g. call hierarchy) into vector representation to address program comprehension problems. This motivates further studies to explore additional contexts, such as version history, to enhance models' understanding of programs. That is, insights from version history enable recognition of patterns in code evolution over time, recurring issues, and the effectiveness of past solutions. Our paper presents preliminary evidence of the potential benefit of encoding contextual information from the version history to predict code clones and perform code classification. We experiment with two representative deep learning models, ASTNN and CodeBERT, to investigate whether combining additional contexts with different aggregations may benefit downstream activities. The experimental result affirms the positive impact of combining version history into source code representation in all scenarios; however, to ensure the technique performs consistently, we need to conduct a holistic investigation on a larger code base using different combinations of contexts, aggregation, and models. Therefore, we propose a research agenda aimed at exploring various aspects of encoding additional context to improve code representation and its optimal utilisation in specific situations.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "5 pages (plus 1 for references), 1 figure, 3 tables, paper was accepted to 21st International Conference on Mining Software Repositories (MSR 2024)"
    },
    {
        "paper id": "2402.03777",
        "abstract url": "https://arxiv.org/abs/2402.03777",
        "title": "Improving Automated Code Reviews: Learning from Experience",
        "rating": -10,
        "keywords": [],
        "abstract": "Modern code review is a critical quality assurance process that is widely adopted in both industry and open source software environments. This process can help newcomers learn from the feedback of experienced reviewers; however, it often brings a large workload and stress to reviewers. To alleviate this burden, the field of automated code reviews aims to automate the process, teaching large language models to provide reviews on submitted code, just as a human would. A recent approach pre-trained and fine-tuned the code intelligent language model on a large-scale code review corpus. However, such techniques did not fully utilise quality reviews amongst the training data. Indeed, reviewers with a higher level of experience or familiarity with the code will likely provide deeper insights than the others. In this study, we set out to investigate whether higher-quality reviews can be generated from automated code review models that are trained based on an experience-aware oversampling technique. Through our quantitative and qualitative evaluation, we find that experience-aware oversampling can increase the correctness, level of information, and meaningfulness of reviews generated by the current state-of-the-art model without introducing new data. The results suggest that a vast amount of high-quality reviews are underutilised with current training strategies. This work sheds light on resource-efficient ways to boost automated code review models.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by the 21st International Conference on Mining Software Repositories (MSR 24)"
    },
    {
        "paper id": "2402.03778",
        "abstract url": "https://arxiv.org/abs/2402.03778",
        "title": "All-Optical, Reconfigurable and Power Independent Neural Activation Function by Means of Phase Modulation",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we present numerical results concerning an integrated photonic non-linear activation function that relies on a power independent, non-linear phase to amplitude conversion in a passive optical resonator. The underlying mechanism is universal to all optical filters, whereas here, simulations were based on micro-ring resonators (MRRs). Investigation revealed that the photonic neural node can be tuned to support a wide variety of continuous activation functions that are relevant to the neural network architectures, such as the sigmoid and the softplus functions. The proposed photonic node is numerically evaluated in the context of time delayed reservoir computing (TDRC) scheme, targeting the one-step ahead prediction of the Santa Fe series. The proposed phase to amplitude TDRC is benchmarked versus the conventional amplitude based TDRC, showcasing a performance boost by one order of magnitude.",
        "subjects": [
            "physics.optics"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2402.03779",
        "abstract url": "https://arxiv.org/abs/2402.03779",
        "title": "EERO: Early Exit with Reject Option for Efficient Classification with limited budget",
        "rating": -10,
        "keywords": [],
        "abstract": "The increasing complexity of advanced machine learning models requires innovative approaches to manage computational resources effectively. One such method is the Early Exit strategy, which allows for adaptive computation by providing a mechanism to shorten the processing path for simpler data instances. In this paper, we propose EERO, a new methodology to translate the problem of early exiting to a problem of using multiple classifiers with reject option in order to better select the exiting head for each instance. We calibrate the probabilities of exiting at the different heads using aggregation with exponential weights to guarantee a fixed budget .We consider factors such as Bayesian risk, budget constraints, and head-specific budget consumption. Experimental results, conducted using a ResNet-18 model and a ConvNext architecture on Cifar and ImageNet datasets, demonstrate that our method not only effectively manages budget allocation but also enhances accuracy in overthinking scenarios.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03787",
        "abstract url": "https://arxiv.org/abs/2402.03787",
        "title": "The beltway problem over orthogonal groups",
        "rating": -10,
        "keywords": [],
        "abstract": "The classical beltway problem entails recovering a set of points from their unordered pairwise distances on the circle. This problem can be viewed as a special case of the crystallographic phase retrieval problem of recovering a sparse signal from its periodic autocorrelation. Based on this interpretation, and motivated by cryo-electron microscopy, we suggest a natural generalization to orthogonal groups: recovering a sparse signal, up to an orthogonal transformation, from its autocorrelation over the orthogonal group. If the support of the signal is collision-free, we bound the number of solutions to the beltway problem over orthogonal groups, and prove that this bound is exactly one when the support of the signal is radially collision-free (i.e., the support points have distinct magnitudes). We also prove that if the pairwise products of the signal's weights are distinct, then the autocorrelation determines the signal uniquely, up to an orthogonal transformation. We conclude the paper by considering binary signals and show that in this case, the collision-free condition need not be sufficient to determine signals up to orthogonal transformation.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03791",
        "abstract url": "https://arxiv.org/abs/2402.03791",
        "title": "Adaptive Blockwise Task-interleaved Pipeline Parallelism",
        "rating": -10,
        "keywords": [],
        "abstract": "Efficient distributed training serves as a powerful catalyst and an essential foundation for the development of large-scale neural networks. In distributed training scenarios, various pipeline parallelism methods are cleverly designed and widely employed. In this paper, we propose ZeroPP, a highly efficient and flexible pipeline parallelism method that trades off pipeline bubbles, memory usage, and communication through adaptive scheduling units. ZeroPP achieves minimal pipeline bubbles by carefully staggering the computation tasks of forward, input gradient, and weight gradient within a scheduling unit. Additionally, ZeroPP optimizes the combination of pipeline parallelism and fully sharded data parallelism using a blockwise schedule. We conduct experiments with popular GPT-style models and observe up to a 30% increase in throughput compared to the state-of-the-art breath-first pipeline parallelism. Besides, our evaluation also demonstrates up to a 68% increase in throughput and a 10% reduction in memory consumption compared to the memory-efficient 1F1B method.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03805",
        "abstract url": "https://arxiv.org/abs/2402.03805",
        "title": "Automated Description Generation for Software Patches",
        "rating": -10,
        "keywords": [],
        "abstract": "Software patches are pivotal in refining and evolving codebases, addressing bugs, vulnerabilities, and optimizations. Patch descriptions provide detailed accounts of changes, aiding comprehension and collaboration among developers. However, manual description creation poses challenges in terms of time consumption and variations in quality and detail. In this paper, we propose PATCHEXPLAINER, an approach that addresses these challenges by framing patch description generation as a machine translation task. In PATCHEXPLAINER, we leverage explicit representations of critical elements, historical context, and syntactic conventions. Moreover, the translation model in PATCHEXPLAINER is designed with an awareness of description similarity. Particularly, the model is explicitly trained to recognize and incorporate similarities present in patch descriptions clustered into groups, improving its ability to generate accurate and consistent descriptions across similar patches. The dual objectives maximize similarity and accurately predict affiliating groups. Our experimental results on a large dataset of real-world software patches show that PATCHEXPLAINER consistently outperforms existing methods, with improvements up to 189% in BLEU, 5.7X in Exact Match rate, and 154% in Semantic Similarity, affirming its effectiveness in generating software patch descriptions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Pre-print version of PATCHEXPLAINER"
    },
    {
        "paper id": "2402.03806",
        "abstract url": "https://arxiv.org/abs/2402.03806",
        "title": "Explainable Automated Machine Learning for Credit Decisions: Enhancing Human Artificial Intelligence Collaboration in Financial Engineering",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper explores the integration of Explainable Automated Machine Learning (AutoML) in the realm of financial engineering, specifically focusing on its application in credit decision-making. The rapid evolution of Artificial Intelligence (AI) in finance has necessitated a balance between sophisticated algorithmic decision-making and the need for transparency in these systems. The focus is on how AutoML can streamline the development of robust machine learning models for credit scoring, while Explainable AI (XAI) methods, particularly SHapley Additive exPlanations (SHAP), provide insights into the models' decision-making processes. This study demonstrates how the combination of AutoML and XAI not only enhances the efficiency and accuracy of credit decisions but also fosters trust and collaboration between humans and AI systems. The findings underscore the potential of explainable AutoML in improving the transparency and accountability of AI-driven financial decisions, aligning with regulatory requirements and ethical considerations.",
        "subjects": [
            "q-fin.RM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03812",
        "abstract url": "https://arxiv.org/abs/2402.03812",
        "title": "FDO Manager: Minimum Viable FAIR Digital Object Implementation",
        "rating": -10,
        "keywords": [],
        "abstract": "The concept of FAIR Digital Objects (FDOs) aims to revolutionise the field of digital preservation and accessibility in the next few years. Central to this revolution is the alignment of FDOs with the FAIR (Findable, Accessible, Interoperable, Reusable) Principles, particularly emphasizing machine-actionability and interoperability across diverse data ecosystems. This abstract introduces the \"FDO Manager\", a Minimum Viable Implementation, designed to optimize the management of FDOs following these principles and the FDO specifications. The FDO Manager is tailored to manage research artefacts such as datasets, codes, and publications, to foster increased transparency and reproducibility in research. The abstract presents the implementation details of the FDO Manager, its underlying architecture, and the metadata schemas it employs, thereby offering a clear and comprehensive understanding of its functionalities and impact on the research domain.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03813",
        "abstract url": "https://arxiv.org/abs/2402.03813",
        "title": "NK Hybrid Genetic Algorithm for Clustering",
        "rating": -10,
        "keywords": [],
        "abstract": "The NK hybrid genetic algorithm for clustering is proposed in this paper. In order to evaluate the solutions, the hybrid algorithm uses the NK clustering validation criterion 2 (NKCV2). NKCV2 uses information about the disposition of $N$ small groups of objects. Each group is composed of $K+1$ objects of the dataset. Experimental results show that density-based regions can be identified by using NKCV2 with fixed small $K$. In NKCV2, the relationship between decision variables is known, which in turn allows us to apply gray box optimization. Mutation operators, a partition crossover, and a local search strategy are proposed, all using information about the relationship between decision variables. In partition crossover, the evaluation function is decomposed into $q$ independent components; partition crossover then deterministically returns the best among $2^q$ possible offspring with computational complexity $O(N)$. The NK hybrid genetic algorithm allows the detection of clusters with arbitrary shapes and the automatic estimation of the number of clusters. In the experiments, the NK hybrid genetic algorithm produced very good results when compared to another genetic algorithm approach and to state-of-art clustering algorithms.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03817",
        "abstract url": "https://arxiv.org/abs/2402.03817",
        "title": "Improvement of Frequency Source Phase Noise Reduction Design under Vibration Condition",
        "rating": -10,
        "keywords": [],
        "abstract": "Reasonable vibration reduction design is an important way to achieve low phase noise index of airborne frequency source output signal. Aiming at the problem of phase noise deterioration of an airborne frequency source under random condition, this paper proposes to improve the vibration reduction mode crystal oscillator and reduce the distance between the barycenter of frequency source and crystal oscillator vibration based on the analysis of the relationship between the frequency source and the phase noise of output signal. Experimental results show that the active noise control system achieves 62dB phase noise compensation under the random vibration of 0.04-0.1g*g/Hz amplitude range and 5-2000 Hz frequency range.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "17 pages,29 figures"
    },
    {
        "paper id": "2402.03819",
        "abstract url": "https://arxiv.org/abs/2402.03819",
        "title": "Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies",
        "rating": -10,
        "keywords": [],
        "abstract": "Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03820",
        "abstract url": "https://arxiv.org/abs/2402.03820",
        "title": "PMSM transient response optimization by end-to-end optimal control",
        "rating": -10,
        "keywords": [],
        "abstract": "Speed responses of motors, especially Permanent Magnet Synchronous Motors (PMSMs), are increasing in importance for recent applications, such as electric vehicles or quadrotors. These applications require quick acceleration performance. However, commercial controllers are based mainly on Proportional-Integral (PI) controllers, which are suitable for eliminating steady-state errors but unsuitable for transient response optimization. In this paper, we replaced whole conventional controllers with an end-to-end Recurrent Neural Network (RNN) that has a regularized transition matrix. Our end-to-end controller directly minimizes the transient response time on the basis of optimal control theory. Computer-simulated results show that speed response indices improved using the RNN rather than a PI controller, while both were under comparable power losses. The current vector trajectories of the RNN showed that the RNN could automatically determine arbitrary trajectories in the flux-weakening region in accordance with an arbitrarily designed loss function. In contrast, the traditional flux-weakening methods using PI controllers have pre-determined current vector trajectories.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03860",
        "abstract url": "https://arxiv.org/abs/2402.03860",
        "title": "AED: Adaptable Error Detection for Few-shot Imitation Policy",
        "rating": -10,
        "keywords": [],
        "abstract": "We study how to report few-shot imitation (FSI) policies' behavior errors in novel environments, a novel task named adaptable error detection (AED). The potential to cause serious damage to surrounding areas limits the application of FSI policies in real-world scenarios. Thus, a robust system is necessary to notify operators when FSI policies are inconsistent with the intent of demonstrations. We develop a cross-domain benchmark for the challenging AED task, consisting of 329 base and 158 novel environments. This task introduces three challenges, including (1) detecting behavior errors in novel environments, (2) behavior errors occurring without revealing notable changes, and (3) lacking complete temporal information of the rollout due to the necessity of online detection. To address these challenges, we propose Pattern Observer (PrObe) to parse discernible patterns in the policy feature representations of normal or error states, whose effectiveness is verified in the proposed benchmark. Through our comprehensive evaluation, PrObe consistently surpasses strong baselines and demonstrates a robust capability to identify errors arising from a wide range of FSI policies. Moreover, we conduct comprehensive ablations and experiments (error correction, demonstration quality, etc.) to validate the practicality of our proposed task and methodology.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03880",
        "abstract url": "https://arxiv.org/abs/2402.03880",
        "title": "Aperiodic two-layer energy management system for community microgrids based on blockchain strategy",
        "rating": -10,
        "keywords": [],
        "abstract": "This work proposes a geographically-based split of the community microgrids into clusters of members that tend to have similar consumption and generation profiles. Assuming a community microgrid divided into clusters, a two-layer architecture is developed to facilitate the greater penetration of distributed energy resources in an efficient way. The first layer, referred as the market layer, is responsible for creating local energy markets with the aim of maximising the economic benefits for community microgrid members. The second layer is responsible for the network reconfiguration, which is based on the energy balance within each cluster. This layer complies with the IEC 61850 communication standard, in order to control commercial sectionalizing and tie switches. This allows the community microgrid network to be reconfigured to minimise energy exchanges with the main grid. To implement this two-layer energy management strategy, an aperiodic market approach based on Blockchain technology, and the additional functionality offered by Smart Contracts is adopted. This embraces the concept of energy communities since it decentralizes the control and eliminates intermediaries. The use of aperiodic control techniques helps to overcome the challenges of using Blockchain technology in terms of storage, computational requirements and member privacy. The scalability and modularity of the Smart Contract-based system allow each cluster of members to be designed by tailoring the system to their specific needs. The implementation of this strategy is based on low-cost off-the-shelf devices, such as Raspberry Pi 4 Model B boards, which operate as Blockchain nodes of community microgrid members. Finally, the strategy has been validated by emulating two use cases based on the IEEE 123-node system network model highlighting the benefits of the proposal.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03881",
        "abstract url": "https://arxiv.org/abs/2402.03881",
        "title": "DEthna: Accurate Ethereum Network Topology Discovery with Marked Transactions",
        "rating": -10,
        "keywords": [],
        "abstract": "In Ethereum, the ledger exchanges messages along an underlying Peer-to-Peer (P2P) network to reach consistency. Understanding the underlying network topology of Ethereum is crucial for network optimization, security and scalability. However, the accurate discovery of Ethereum network topology is non-trivial due to its deliberately designed security mechanism. Consequently, existing measuring schemes cannot accurately infer the Ethereum network topology with a low cost. To address this challenge, we propose the Distributed Ethereum Network Analyzer (DEthna) tool, which can accurately and efficiently measure the Ethereum network topology. In DEthna, a novel parallel measurement model is proposed that can generate marked transactions to infer link connections based on the transaction replacement and propagation mechanism in Ethereum. Moreover, a workload offloading scheme is designed so that DEthna can be deployed on multiple distributed probing nodes so as to measure a large-scale Ethereum network at a low cost. We run DEthna on Goerli (the most popular Ethereum test network) to evaluate its capability in discovering network topology. The experimental results demonstrate that DEthna significantly outperforms the state-of-the-art baselines. Based on DEthna, we further analyze characteristics of the Ethereum network revealing that there exist more than 50% low-degree Ethereum nodes that weaken the network robustness.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted for publication in IEEE INFOCOM 2024"
    },
    {
        "paper id": "2402.03883",
        "abstract url": "https://arxiv.org/abs/2402.03883",
        "title": "A Framework for Bilevel Optimization on Riemannian Manifolds",
        "rating": -10,
        "keywords": [],
        "abstract": "Bilevel optimization has seen an increasing presence in various domains of applications. In this work, we propose a framework for solving bilevel optimization problems where variables of both lower and upper level problems are constrained on Riemannian manifolds. We provide several hypergradient estimation strategies on manifolds and study their estimation error. We provide convergence and complexity analysis for the proposed hypergradient descent algorithm on manifolds. We also extend the developments to stochastic bilevel optimization and to the use of general retraction. We showcase the utility of the proposed framework on various applications.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03886",
        "abstract url": "https://arxiv.org/abs/2402.03886",
        "title": "Full-Duplex Millimeter Wave MIMO Channel Estimation: A Neural Network Approach",
        "rating": -10,
        "keywords": [],
        "abstract": "Millimeter wave (mmWave) multiple-input-multi-output (MIMO) is now a reality with great potential for further improvement. We study full-duplex transmissions as an effective way to improve mmWave MIMO systems. Compared to half-duplex systems, full-duplex transmissions may offer higher data rates and lower latency. However, full-duplex transmission is hindered by self-interference (SI) at the receive antennas, and SI channel estimation becomes a crucial step to make the full-duplex systems feasible. In this paper, we address the problem of channel estimation in full-duplex mmWave MIMO systems using neural networks (NNs). Our approach involves sharing pilot resources between user equipments (UEs) and transmit antennas at the base station (BS), aiming to reduce the pilot overhead in full-duplex systems and to achieve a comparable level to that of a half-duplex system. Additionally, in the case of separate antenna configurations in a full-duplex BS, providing channel estimates of transmit antenna (TX) arrays to the downlink UEs poses another challenge, as the TX arrays are not capable of receiving pilot signals. To address this, we employ an NN to map the channel from the downlink UEs to the receive antenna (RX) arrays to the channel from the TX arrays to the downlink UEs. We further elaborate on how NNs perform the estimation with different architectures, (e.g., different numbers of hidden layers), the introduction of non-linear distortion (e.g., with a 1-bit analog-to-digital converter (ADC)), and different channel conditions (e.g., low-correlated and high-correlated channels). Our work provides novel insights into NN-based channel estimators.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03891",
        "abstract url": "https://arxiv.org/abs/2402.03891",
        "title": "Control-Flow Refinement for Probabilistic Programs in KoAT",
        "rating": -10,
        "keywords": [],
        "abstract": "Recently, we showed how to use control-flow refinement (CFR) to improve automatic complexity analysis of integer programs. While up to now CFR was limited to classical programs, in this paper we extend CFR to probabilistic programs and show its soundness for complexity analysis. To demonstrate its benefits, we implemented our new CFR technique in our complexity analysis tool KoAT.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03892",
        "abstract url": "https://arxiv.org/abs/2402.03892",
        "title": "Bezier surfaces with prescribed diagonals",
        "rating": -10,
        "keywords": [],
        "abstract": "The affine space of all tensor product B\u00e9zier patches of degree nxn with prescribed main diagonal curves is determined. First, the pair of B\u00e9zier curves which can be diagonals of a B\u00e9zier patch is characterized. Besides prescribing the diagonal curves, other related problems are considered, those where boundary curves or tangent planes along boundary curves are also prescribed.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03897",
        "abstract url": "https://arxiv.org/abs/2402.03897",
        "title": "Robust Data-EnablEd Predictive Leading Cruise Control via Reachability Analysis",
        "rating": -10,
        "keywords": [],
        "abstract": "Data-driven predictive control promises modelfree wave-dampening strategies for Connected and Autonomous Vehicles (CAVs) in mixed traffic flow. However, the performance suffers from unknown noise and disturbances, which could occur in offline data collection and online predictive control. In this paper, we propose a Robust Data-EnablEd Predictive Leading Cruise Control (RDeeP-LCC) method based on reachability analysis, aiming to achieve safe and optimal control of CAVs under bounded process noise and external disturbances. Precisely, we decouple the mixed platoon system into an error system and a nominal system, and tighten the constraint via the data-driven reachable set technique. Then, the enhanced safety constraint is integrated with the data-driven predictive control formulation to achieve stronger robust control performance for CAVs. Simulations validate the effectiveness of the proposed method in mitigating traffic waves with better robustness.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03901",
        "abstract url": "https://arxiv.org/abs/2402.03901",
        "title": "Batch Universal Prediction",
        "rating": -10,
        "keywords": [],
        "abstract": "Large language models (LLMs) have recently gained much popularity due to their surprising ability at generating human-like English sentences. LLMs are essentially predictors, estimating the probability of a sequence of words given the past. Therefore, it is natural to evaluate their performance from a universal prediction perspective. In order to do that fairly, we introduce the notion of batch regret as a modification of the classical average regret, and we study its asymptotical value for add-constant predictors, in the case of memoryless sources and first-order Markov sources.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03916",
        "abstract url": "https://arxiv.org/abs/2402.03916",
        "title": "Can Large Language Models Detect Rumors on Social Media?",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we investigate to use Large Language Models (LLMs) for rumor detection on social media. However, it is challenging for LLMs to reason over the entire propagation information on social media, which contains news contents and numerous comments, due to LLMs may not concentrate on key clues in the complex propagation information, and have trouble in reasoning when facing massive and redundant information. Accordingly, we propose an LLM-empowered Rumor Detection (LeRuD) approach, in which we design prompts to teach LLMs to reason over important clues in news and comments, and divide the entire propagation information into a Chain-of-Propagation for reducing LLMs' burden. We conduct extensive experiments on the Twitter and Weibo datasets, and LeRuD outperforms several state-of-the-art rumor detection models by 3.2% to 7.7%. Meanwhile, by applying LLMs, LeRuD requires no data for training, and thus shows more promising rumor detection ability in few-shot or zero-shot scenarios.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03928",
        "abstract url": "https://arxiv.org/abs/2402.03928",
        "title": "Approximating the Core via Iterative Coalition Sampling",
        "rating": -10,
        "keywords": [],
        "abstract": "The core is a central solution concept in cooperative game theory, defined as the set of feasible allocations or payments such that no subset of agents has incentive to break away and form their own subgroup or coalition. However, it has long been known that the core (and approximations, such as the least-core) are hard to compute. This limits our ability to analyze cooperative games in general, and to fully embrace cooperative game theory contributions in domains such as explainable AI (XAI), where the core can complement the Shapley values to identify influential features or instances supporting predictions by black-box models. We propose novel iterative algorithms for computing variants of the core, which avoid the computational bottleneck of many other approaches; namely solving large linear programs. As such, they scale better to very large problems as we demonstrate across different classes of cooperative games, including weighted voting games, induced subgraph games, and marginal contribution networks. We also explore our algorithms in the context of XAI, providing further evidence of the power of the core for such applications.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "Published in AAMAS 2024"
    },
    {
        "paper id": "2402.03935",
        "abstract url": "https://arxiv.org/abs/2402.03935",
        "title": "On the Accuracy of Phase Extraction from a Known-Frequency Noisy Sinusoidal Signal",
        "rating": -10,
        "keywords": [],
        "abstract": "Accurate phase extraction from sinusoidal signals is a crucial task in various signal processing applications. While prior research predominantly addresses the case of asynchronous sampling with unknown signal frequency, this study focuses on the more specific situation where synchronous sampling is possible, and the signal's frequency is known. In this framework, a comprehensive analysis of phase estimation accuracy in the presence of both additive and phase noises is presented. A closed-form expression for the asymptotic Probability Density Function (PDF) of the resulting phase estimator is presented, and validated by simulations that depict Root Mean Square Error (RMSE) trends in different noise scenarios. The latter estimator is asymptotically efficient, exhibiting fast convergence towards its Cram\u00e9r-Rao Lower Bound (CRLB). Three distinct RMSE behaviours were identified depending on the Signal to Noise Ratio (SNR), sample count (N), and noise level: (i) saturation towards a random guess at low SNR values, (ii) linear decreasing relationship with the square roots of N and SNR at moderate noise levels, and (iii) saturation at high SNR towards a noise floor function of the phase noise level. By quantifying the impact of sample count, additive noise, and phase noise on phase estimation accuracy, this work provides valuable insights for designing systems that require precise phase extraction, such as phase-based fluorescence assays or system identification.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "12 pages, 11 figures, initially submitted to Analog Integrated Circuits and Signal Processing the 19th December 2023, Updated 2024/02/07: added watermark, Updated 2024/03/26 : due to a lack of response from AICSP despite several follow-up, we withdrew it, and submitted it to IEEE Transactions on Signal Processing instead"
    },
    {
        "paper id": "2402.03938",
        "abstract url": "https://arxiv.org/abs/2402.03938",
        "title": "Apparent Distance and a Notion of BCH Multivariate Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper is devoted to studying two main problems: 1) computing the apparent distance of an Abelian code and 2) giving a notion of Bose, Ray-Chaudhuri, Hocquenghem (BCH) multivariate code. To do this, we first strengthen the notion of an apparent distance by introducing the notion of a strong apparent distance; then, we present an algorithm to compute the strong apparent distance of an Abelian code, based on some manipulations of hypermatrices associated with its generating idempotent. Our method uses less computations than those given by Camion and Sabin; furthermore, in the bivariate case, the order of computation complexity is reduced from exponential to linear. Then, we use our techniques to develop a notion of a BCH code in the multivariate case, and we extend most of the classical results on cyclic BCH codes. Finally, we apply our method to the design of Abelian codes with maximum dimension with respect to a fixed apparent distance and a fixed length.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03945",
        "abstract url": "https://arxiv.org/abs/2402.03945",
        "title": "Using metaheuristics for the location of bicycle stations",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we solve the problem of finding the best locations to place stations for depositing/collecting shared bicycles. To do this, we model the problem as the p-median problem, that is a major existing localization problem in optimization. The p-median problem seeks to place a set of facilities (bicycle stations) in a way that minimizes the distance between a set of clients (citizens) and their closest facility (bike station). We have used a genetic algorithm, iterated local search, particle swarm optimization, simulated annealing, and variable neighbourhood search, to find the best locations for the bicycle stations and study their comparative advantages. We use irace to parameterize each algorithm automatically, to contribute with a methodology to fine-tune algorithms automatically. We have also studied different real data (distance and weights) from diverse open data sources from a real city, Malaga (Spain), hopefully leading to a final smart city application. We have compared our results with the implemented solution in Malaga. Finally, we have analyzed how we can use our proposal to improve the existing system in the city by adding more stations.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03955",
        "abstract url": "https://arxiv.org/abs/2402.03955",
        "title": "A linear dissipativity approach to incremental input-to-state stability for a class of positive Lur'e systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Incremental stability properties are considered for certain systems of forced, nonlinear differential equations with a particular positivity structure. An incremental stability estimate is derived for pairs of input/state/output trajectories of the Lur'e systems under consideration, from which a number of consequences are obtained, including the incremental exponential input-to-state stability property and certain input-output stability concepts with linear gain. Incremental stability estimates provide a basis for an investigation into the response to convergent and (almost) periodic forcing terms, and is treated presently. Our results show that an incremental version of the real Aizerman conjecture is true for positive Lur'e systems when an incremental gain condition is imposed on the nonlinear term, as we describe. Our argumentation is underpinned by linear dissipativity theory -- a property of positive linear control systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "28 pages, 3 figures (comprising 8 subpanels). Submitting to Arxiv for early dissemination of results. This version was submitted in Dec 2023 to a journal for possible publication"
    },
    {
        "paper id": "2402.03961",
        "abstract url": "https://arxiv.org/abs/2402.03961",
        "title": "Self-Reproduction and Evolution in Cellular Automata: 25 Years after Evoloops",
        "rating": -10,
        "keywords": [],
        "abstract": "The year of 2024 marks the 25th anniversary of the publication of evoloops, an evolutionary variant of Chris Langton's self-reproducing loops which proved that Darwinian evolution of self-reproducing organisms by variation and natural selection is possible within deterministic cellular automata. Over the last few decades, this line of Artificial Life research has since undergone several important developments. Although it experienced a relative dormancy of activities for a while, the recent rise of interest in open-ended evolution and the success of continuous cellular automata models have brought researchers' attention back to how to make spatio-temporal patterns self-reproduce and evolve within spatially distributed computational media. This article provides a review of the relevant literature on this topic over the past 25 years and highlights the major accomplishments made so far, the challenges being faced, and promising future research directions.",
        "subjects": [
            "nlin.CG"
        ],
        "comment": "18 pages, 2 figures"
    },
    {
        "paper id": "2402.03964",
        "abstract url": "https://arxiv.org/abs/2402.03964",
        "title": "Almost Perfect Mutually Unbiased Bases that are Sparse",
        "rating": -10,
        "keywords": [],
        "abstract": "In dimension $d$, Mutually Unbiased Bases (MUBs) are a collection of orthonormal bases over $\\mathbb{C}^d$ such that for any two vectors $v_1, v_2$ belonging to different bases, the scalar product $|\\braket{v_1|v_2}| = \\frac{1}{\\sqrt{d}}$. The upper bound on the number of such bases is $d+1$. Constructions to achieve this bound are known when $d$ is some power of prime. The situation is more restrictive in other cases and also when we consider the results over real rather than complex. Thus, certain relaxations of this model are considered in literature and consequently Approximate MUBs (AMUB) are studied. This enables one to construct potentially large number of such objects for $\\mathbb{C}^d$ as well as in $\\mathbb{R}^d$. In this regard, we propose the concept of Almost Perfect MUBs (APMUB), where we restrict the absolute value of inner product $|\\braket{v_1|v_2}|$ to be two-valued, one being 0 and the other $ \\leq \\frac{1+\\mathcal{O}(d^{-\u03bb})}{\\sqrt{d}}$, such that $\u03bb> 0$ and the numerator $1 + \\mathcal{O}(d^{-\u03bb}) \\leq 2$. Each such vector constructed, has an important feature that large number of its components are zero and the non-zero components are of equal magnitude. Our techniques are based on combinatorial structures related to RBDs. We show that for several composite dimensions $d$, one can construct $\\mathcal{O}(\\sqrt{d})$ many APMUBs, in which cases the number of MUBs are significantly small. To be specific, this result works for $d$ of the form $(q-e)(q+f), \\ q, e, f \\in \\mathbb{N}$, with the conditions $0 \\leq f \\leq e$ for constant $e, f$ and $q$ some power of prime. We also show that such APMUBs provide sets of Bi-angular vectors which are $\\mathcal{O}(d^{\\frac{3}{2}})$ in numbers, having high angular distances among them. Finally, as the MUBs are equivalent to a set of Hadamard matrices, we show that the APMUBs are so with the set of Weighing matrices.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03965",
        "abstract url": "https://arxiv.org/abs/2402.03965",
        "title": "Cyclic and BCH Codes whose Minimum Distance Equals their Maximum BCH bound",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper we study the family of cyclic codes such that its minimum distance reaches the maximum of its BCH bounds. We also show a way to construct cyclic codes with that property by means of computations of some divisors of a polynomial of the form X^n-1. We apply our results to the study of those BCH codes C, with designed distance delta, that have minimum distance d(C)= delta. Finally, we present some examples of new binary BCH codes satisfying that condition. To do this, we make use of two related tools: the discrete Fourier transform and the notion of apparent distance of a code, originally defined for multivariate abelian codes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03972",
        "abstract url": "https://arxiv.org/abs/2402.03972",
        "title": "Joint Intrinsic Motivation for Coordinated Exploration in Multi-Agent Deep Reinforcement Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "Multi-agent deep reinforcement learning (MADRL) problems often encounter the challenge of sparse rewards. This challenge becomes even more pronounced when coordination among agents is necessary. As performance depends not only on one agent's behavior but rather on the joint behavior of multiple agents, finding an adequate solution becomes significantly harder. In this context, a group of agents can benefit from actively exploring different joint strategies in order to determine the most efficient one. In this paper, we propose an approach for rewarding strategies where agents collectively exhibit novel behaviors. We present JIM (Joint Intrinsic Motivation), a multi-agent intrinsic motivation method that follows the centralized learning with decentralized execution paradigm. JIM rewards joint trajectories based on a centralized measure of novelty designed to function in continuous environments. We demonstrate the strengths of this approach both in a synthetic environment designed to reveal shortcomings of state-of-the-art MADRL methods, and in simulated robotic tasks. Results show that joint exploration is crucial for solving tasks where the optimal strategy requires a high level of coordination.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "13 pages, 13 figures. Published as an extended abstract at AAMAS 2024"
    },
    {
        "paper id": "2402.03975",
        "abstract url": "https://arxiv.org/abs/2402.03975",
        "title": "Smoothed analysis of deterministic discounted and mean-payoff games",
        "rating": -10,
        "keywords": [],
        "abstract": "We devise a policy-iteration algorithm for deterministic two-player discounted and mean-payoff games, that runs in polynomial time with high probability, on any input where each payoff is chosen independently from a sufficiently random distribution. This includes the case where an arbitrary set of payoffs has been perturbed by a Gaussian, showing for the first time that deterministic two-player games can be solved efficiently, in the sense of smoothed analysis. More generally, we devise a condition number for deterministic discounted and mean-payoff games, and show that our algorithm runs in time polynomial in this condition number. Our result confirms a previous conjecture of Boros et al., which was claimed as a theorem and later retracted. It stands in contrast with a recent counter-example by Christ and Yannakakis, showing that Howard's policy-iteration algorithm does not run in smoothed polynomial time on stochastic single-player mean-payoff games. Our approach is inspired by the analysis of random optimal assignment instances by Frieze and Sorkin, and the analysis of bias-induced policies for mean-payoff games by Akian, Gaubert and Hochart.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03978",
        "abstract url": "https://arxiv.org/abs/2402.03978",
        "title": "Reconfigurable Power Converters with Increased Utilization for Unbalanced Power Distribution System Applications",
        "rating": -10,
        "keywords": [],
        "abstract": "A low-cost reconfiguration stage connected at the output of balanced three-phase, multi-terminal ac/dc/ac converters can increase the feasible set of power injections substantially, increasing converter utilization and therefore achieving a lower system cost. However, the approach has yet to be explored for phase unbalance mitigation in power distribution networks, an important application for future energy systems. This study addresses this by considering power converter reconfiguration's potential for increasing the feasible set of power transfers of four-wire power converters. Reconfigurable topologies are compared against both conventional four-wire designs and an idealised, fully reconfigurable converter. Results show that conventional converters need up to 75.3% greater capacity to yield a capability chart of equivalent size to an idealised reconfigurable converter. The number and capacity of legs impact the capability chart's size, as do constraints on dc-side power injections. The proposed approach shows significant promise for maximizing the utilization of power electronics used to mitigate impacts of phase unbalance.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Submitted to 13th International Conference on Power Electronics, Machines and Drives (PEMD 2024)"
    },
    {
        "paper id": "2402.03982",
        "abstract url": "https://arxiv.org/abs/2402.03982",
        "title": "On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions",
        "rating": -10,
        "keywords": [],
        "abstract": "The Adaptive Momentum Estimation (Adam) algorithm is highly effective in training various deep learning tasks. Despite this, there's limited theoretical understanding for Adam, especially when focusing on its vanilla form in non-convex smooth scenarios with potential unbounded gradients and affine variance noise. In this paper, we study vanilla Adam under these challenging conditions. We introduce a comprehensive noise model which governs affine variance noise, bounded noise and sub-Gaussian noise. We show that Adam can find a stationary point with a $\\mathcal{O}(\\text{poly}(\\log T)/\\sqrt{T})$ rate in high probability under this general noise model where $T$ denotes total number iterations, matching the lower rate of stochastic first-order algorithms up to logarithm factors. More importantly, we reveal that Adam is free of tuning step-sizes with any problem-parameters, yielding a better adaptation property than the Stochastic Gradient Descent under the same conditions. We also provide a probabilistic convergence result for Adam under a generalized smooth condition which allows unbounded smoothness parameters and has been illustrated empirically to more accurately capture the smooth property of many practical objective functions.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03987",
        "abstract url": "https://arxiv.org/abs/2402.03987",
        "title": "Tail-Erasure-Correcting Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "The increasing demand for data storage has prompted the exploration of new techniques, with molecular data storage being a promising alternative. In this work, we develop coding schemes for a new storage paradigm that can be represented as a collection of two-dimensional arrays. Motivated by error patterns observed in recent prototype architectures, our study focuses on correcting erasures in the last few symbols of each row, and also correcting arbitrary deletions across rows. We present code constructions and explicit encoders and decoders that are shown to be nearly optimal in many scenarios. We show that the new coding schemes are capable of effectively mitigating these errors, making these emerging storage platforms potentially promising solutions.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.03990",
        "abstract url": "https://arxiv.org/abs/2402.03990",
        "title": "Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation",
        "rating": -10,
        "keywords": [],
        "abstract": "We study the effect of the batch size to the total gradient variance in differentially private stochastic gradient descent (DP-SGD), seeking a theoretical explanation for the usefulness of large batch sizes. As DP-SGD is the basis of modern DP deep learning, its properties have been widely studied, and recent works have empirically found large batch sizes to be beneficial. However, theoretical explanations of this benefit are currently heuristic at best. We first observe that the total gradient variance in DP-SGD can be decomposed into subsampling-induced and noise-induced variances. We then prove that in the limit of an infinite number of iterations, the effective noise-induced variance is invariant to the batch size. The remaining subsampling-induced variance decreases with larger batch sizes, so large batches reduce the effective total gradient variance. We confirm numerically that the asymptotic regime is relevant in practical settings when the batch size is not small, and find that outside the asymptotic regime, the total gradient variance decreases even more with large batch sizes. We also find a sufficient condition that implies that large batch sizes similarly reduce effective DP noise variance for one iteration of DP-SGD.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04022",
        "abstract url": "https://arxiv.org/abs/2402.04022",
        "title": "A General Theory for Kernel Packets: from state space model to compactly supported basis",
        "rating": -10,
        "keywords": [],
        "abstract": "It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to $\\CalO(n)$ for $n$ data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance $K$ such that $\\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \\leq t_1$, 0 $\\leq j \\leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th derivative acting on $t$. We extend this idea to the backward SS model formulation, leading to the left KP for next $m$ consecutive points: $\\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ KP functions compactly supported on $(t_0,t_{2m})$. KPs improve GP prediction time to $\\mathcal{O}(\\log n)$ or $\\mathcal{O}(1)$, enable broader applications including GP's derivatives and kernel multiplications, and can be generalized to multi-dimensional additive and product kernels for scattered data.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04074",
        "abstract url": "https://arxiv.org/abs/2402.04074",
        "title": "Mean-Square Stability and Stabilizability for LTI and Stochastic Systems Connected in Feedback",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, the feedback stabilization of a linear time-invariant (LTI) multiple-input multiple-output (MIMO) system cascaded by a linear stochastic system is studied in the mean-square sense. Here, the linear stochastic system can model a class of correlated stochastic uncertainties such as channel uncertainties induced by packet loss and random transmission delays in networked systems. By proposing a key parameter called coefficient of frequency variation to characterize the correlation of the stochastic uncertainties, we present a necessary and sufficient condition of the mean-square stability for this MIMO stochastic feedback system. After then a necessary and sufficient condition for the mean-square stabilizability is provided, which reveals a fundamental limit imposed by the system's unstable poles, nonminimum-phase (NMP) zeros, relative degrees (input delays), and the coefficient of frequency variation of the stochastic uncertainties. A numerical example is presented to illustrate the fundamental constraints in the mean-square stabilizability of MIMO networked systems with parallel communication channels.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04083",
        "abstract url": "https://arxiv.org/abs/2402.04083",
        "title": "Cooperation and profit allocation in distribution chains",
        "rating": -10,
        "keywords": [],
        "abstract": "We study the coordination of actions and the allocation of profit in supply chains under decentralized control in which a single supplier supplies several retailers with goods for replenishment of stocks. The goal of the supplier and the retailers is to maximize their individual profits. Since the outcome under decentralized control is inefficient, cooperation among firms by means of coordination of actions may improve the individual profits. Cooperation is studied by means of cooperative game theory. Among others we show that the corresponding games are balanced and we propose a stable solution concept for these games.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04102",
        "abstract url": "https://arxiv.org/abs/2402.04102",
        "title": "Use of Multi-CNNs for Section Analysis in Static Malware Detection",
        "rating": -10,
        "keywords": [],
        "abstract": "Existing research on malware detection focuses almost exclusively on the detection rate. However, in some cases, it is also important to understand the results of our algorithm, or to obtain more information, such as where to investigate in the file for an analyst. In this aim, we propose a new model to analyze Portable Executable files. Our method consists in splitting the files in different sections, then transform each section into an image, in order to train convolutional neural networks to treat specifically each identified section. Then we use all these scores returned by CNNs to compute a final detection score, using models that enable us to improve our analysis of the importance of each section in the final score.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2312.12161"
    },
    {
        "paper id": "2402.04114",
        "abstract url": "https://arxiv.org/abs/2402.04114",
        "title": "SCAFFLSA: Quantifying and Eliminating Heterogeneity Bias in Federated Linear Stochastic Approximation and Temporal Difference Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we perform a non-asymptotic analysis of the federated linear stochastic approximation (FedLSA) algorithm. We explicitly quantify the bias introduced by local training with heterogeneous agents, and investigate the sample complexity of the algorithm. We show that the communication complexity of FedLSA scales polynomially with the desired precision $\u03b5$, which limits the benefits of federation. To overcome this, we propose SCAFFLSA, a novel variant of FedLSA, that uses control variates to correct the bias of local training, and prove its convergence without assumptions on statistical heterogeneity. We apply the proposed methodology to federated temporal difference learning with linear function approximation, and analyze the corresponding complexity improvements.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04134",
        "abstract url": "https://arxiv.org/abs/2402.04134",
        "title": "A quasi-optimal lower bound for skew polynomial multiplication",
        "rating": -10,
        "keywords": [],
        "abstract": "We establish a lower bound for the complexity of multiplying two skew polynomials. The lower bound coincides with the upper bound conjectured by Caruso and Borgne in 2017, up to a log factor. We present algorithms for three special cases, indicating that the aforementioned lower bound is quasi-optimal. In fact, our lower bound is quasi-optimal in the sense of bilinear complexity. In addition, we discuss the average bilinear complexity of simultaneous multiplication of skew polynomials and the complexity of skew polynomial multiplication in the case of towers of extensions.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04141",
        "abstract url": "https://arxiv.org/abs/2402.04141",
        "title": "Multi-line AI-assisted Code Authoring",
        "rating": -10,
        "keywords": [],
        "abstract": "CodeCompose is an AI-assisted code authoring tool powered by large language models (LLMs) that provides inline suggestions to 10's of thousands of developers at Meta. In this paper, we present how we scaled the product from displaying single-line suggestions to multi-line suggestions. This evolution required us to overcome several unique challenges in improving the usability of these suggestions for developers. First, we discuss how multi-line suggestions can have a 'jarring' effect, as the LLM's suggestions constantly move around the developer's existing code, which would otherwise result in decreased productivity and satisfaction. Second, multi-line suggestions take significantly longer to generate; hence we present several innovative investments we made to reduce the perceived latency for users. These model-hosting optimizations sped up multi-line suggestion latency by 2.5x. Finally, we conduct experiments on 10's of thousands of engineers to understand how multi-line suggestions impact the user experience and contrast this with single-line suggestions. Our experiments reveal that (i) multi-line suggestions account for 42% of total characters accepted (despite only accounting for 16% for displayed suggestions) (ii) multi-line suggestions almost doubled the percentage of keystrokes saved for users from 9% to 17%. Multi-line CodeCompose has been rolled out to all engineers at Meta, and less than 1% of engineers have opted out of multi-line suggestions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04149",
        "abstract url": "https://arxiv.org/abs/2402.04149",
        "title": "Dynamic Realization Games in Newsvendor Inventory Centralization",
        "rating": -10,
        "keywords": [],
        "abstract": "Consider a set N of n (>1) stores with single-item and single-period nondeterministic demands like in a classic newsvendor setting with holding and penalty costs only. Assume a risk-pooling single-warehouse centralized inventory ordering option. Allocation of costs in the centralized inventory ordering corresponds to modelling it as a cooperative cost game whose players are the stores. It has been shown that when holding and penalty costs are identical for all subsets of stores, the game based on optimal expected costs has a non empty core (Hartman et. al., 2000, Muller \\textit{et. al.}, 2002). In this paper we examine a related inventory centralization game based on demand realizations that has, in general, an empty core even with identical penalty and holding costs (Hartman and Dror, 2005). We propose a repeated cost allocation scheme for dynamic realization games based on allocation processes introduced by Lehrer (2002a). We prove that the cost subsequences of the dynamic realization game process, based on Lehrer's rules, converge almost surely to either a least square value or the core of the expected game. We extend the above results to more general dynamic cost games and relax the independence hypothesis of the sequence of players' demands at different stages.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04180",
        "abstract url": "https://arxiv.org/abs/2402.04180",
        "title": "Deep-Learning Estimation of Weight Distribution Using Joint Kinematics for Lower-Limb Exoskeleton Control",
        "rating": -10,
        "keywords": [],
        "abstract": "In the control of lower-limb exoskeletons with feet, the phase in the gait cycle can be identified by monitoring the weight distribution at the feet. This phase information can be used in the exoskeleton's controller to compensate the dynamics of the exoskeleton and to assign impedance parameters. Typically the weight distribution is calculated using data from sensors such as treadmill force plates or insole force sensors. However, these solutions increase both the setup complexity and cost. For this reason, we propose a deep-learning approach that uses a short time window of joint kinematics to predict the weight distribution of an exoskeleton in real time. The model was trained on treadmill walking data from six users wearing a four-degree-of-freedom exoskeleton and tested in real time on three different users wearing the same device. This test set includes two users not present in the training set to demonstrate the model's ability to generalize across individuals. Results show that the proposed method is able to fit the actual weight distribution with R2=0.9 and is suitable for real-time control with prediction times less than 1 ms. Experiments in closed-loop exoskeleton control show that deep-learning-based weight distribution estimation can be used to replace force sensors in overground and treadmill walking.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04183",
        "abstract url": "https://arxiv.org/abs/2402.04183",
        "title": "Incivility in Open Source Projects: A Comprehensive Annotated Dataset of Locked GitHub Issue Threads",
        "rating": -10,
        "keywords": [],
        "abstract": "In the dynamic landscape of open source software (OSS) development, understanding and addressing incivility within issue discussions is crucial for fostering healthy and productive collaborations. This paper presents a curated dataset of 404 locked GitHub issue discussion threads and 5961 individual comments, collected from 213 OSS projects. We annotated the comments with various categories of incivility using Tone Bearing Discussion Features (TBDFs), and, for each issue thread, we annotated the triggers, targets, and consequences of incivility. We observed that Bitter frustration, Impatience, and Mocking are the most prevalent TBDFs exhibited in our dataset. The most common triggers, targets, and consequences of incivility include Failed use of tool/code or error messages, People, and Discontinued further discussion, respectively. This dataset can serve as a valuable resource for analyzing incivility in OSS and improving automated tools to detect and mitigate such behavior.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04200",
        "abstract url": "https://arxiv.org/abs/2402.04200",
        "title": "Information Systems and Software Engineering: The Case for Convergence",
        "rating": -10,
        "keywords": [],
        "abstract": "The Information Systems (IS) and Software Engineering (SE) fields share a remarkable number of similarities in their historical evolution to date. These similarities are briefly outlined below. An analysis of 10 years (2001-2010) of publications in the primary journals in both fields also reveals a good deal of overlap in research topics. Given the challenges faced by both as young disciplines, there is potentially much to gain from a closer interaction between both fields than has traditionally been the case. This article seeks to encourage such interaction, and illustrates how this might usefully occur in the area of design. It concludes by proposing a number of practical initiatives that could stimulate and facilitate interaction between the IS and SE fields",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04208",
        "abstract url": "https://arxiv.org/abs/2402.04208",
        "title": "Production-inventory games and pmas games: characterizations of the Owen point",
        "rating": -10,
        "keywords": [],
        "abstract": "Production-inventory games were introduced in Guardiola et al. (2007) as a new class of totally balanced combinatorial optimization games. From among all core-allocations, the Owen point was proposed as a specifically appealing solution. In this paper we study some relationships of the class of production-inventory games and other classes of new and known games. In addition, we propose three axiomatic characterizations of the Owen point. We use eight axioms for these characterizations, among those, inessentiality and additivity of players' demands are used for the first time in this paper.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04231",
        "abstract url": "https://arxiv.org/abs/2402.04231",
        "title": "Further Constructions of AMUBs for Non-prime power Composite Dimensions",
        "rating": -10,
        "keywords": [],
        "abstract": "Construction of a large class of Mutually Unbiased Bases (MUBs) for non-prime power composite dimensions ($d = k\\times s$) is a long standing open problem, which leads to different construction methods for the class Approximate MUBs (AMUBs) by relaxing the criterion that the absolute value of the dot product between two vectors chosen from different bases should be $\\leq \\frac\u03b2{\\sqrt{d}}$. In this chapter, we consider a more general class of AMUBs (ARMUBs, considering the real ones too), compared to our earlier work in [Cryptography and Communications, 14(3): 527--549, 2022]. We note that the quality of AMUBs (ARMUBs) constructed using RBD$(X,A)$ with $|X|= d$, critically depends on the parameters, $|s-k|$, $\u03bc$ (maximum number of elements common between any pair of blocks), and the set of block sizes. We present the construction of $\\mathcal{O}(\\sqrt{d})$ many $\u03b2$-AMUBs for composite $d$ when $|s-k|< \\sqrt{d}$, using RBDs having block sizes approximately $\\sqrt{d}$, such that $|\\braket{\u03c8^l_i|\u03c8^m_j}| \\leq \\frac\u03b2{\\sqrt{d}}$ where $\u03b2= 1 + \\frac{|s-k|}{2\\sqrt{d}}+ \\mathcal{O}(d^{-1}) \\leq 2$. Moreover, if real Hadamard matrix of order $k$ or $s$ exists, then one can construct at least $N(k)+1$ (or $N(s)+1$) many $\u03b2$-ARMUBs for dimension $d$, with $\u03b2\\leq 2 - \\frac{|s-k|}{2\\sqrt{d}}+ \\mathcal{O}(d^{-1})< 2$, where $N(w)$ is the number of MOLS$(w)$. This improves and generalizes some of our previous results for ARMUBs from two points, viz., the real cases are now extended to complex ones too. The earlier efforts use some existing RBDs, whereas here we consider new instances of RBDs that provide better results. Similar to the earlier cases, the AMUBs (ARMUBs) constructed using RBDs are in general very sparse, where the sparsity $(\u03b5)$ is $1 - \\mathcal{O}(d^{-\\frac{1}{2}})$.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04240",
        "abstract url": "https://arxiv.org/abs/2402.04240",
        "title": "Novel IMU-based Adaptive Estimator of the Center of Rotation of Joints for Movement Analysis",
        "rating": -10,
        "keywords": [],
        "abstract": "The location of the center of rotation (COR) of joints is a key parameter in multiple applications of human motion analysis. The aim of this work was to propose a novel real-time estimator of the center of fixed joints using an inertial measurement unit (IMU). Since the distance to this center commonly varies during the joint motion due to soft tissue artifacts (STA), our approach is aimed at adapting to these small variations when the COR is fixed. Our proposal, called ArVEd, to the best of our knowledge, is the first real-time estimator of the IMU-joint center vector based on one IMU. Previous works are off-line and require a complete measurement batch to be solved and most of them are not tested on the real scenario. The algorithm is based on an Extended Kalman Filter (EKF) that provides an adaptive vector to STA motion variations at each time instant, without requiring a pre-processing stage to reduce the level of noise. ArVEd has been tested through different experiments, including synthetic and real data. The synthetic data are obtained from a simulated spherical pendulum whose COR is fixed, considering both a constant and a variable IMU-joint vector, that simulates translational IMU motions due to STA. The results prove that ArVEd is adapted to obtain a vector per sample with an accuracy of 6.8$\\pm$3.9 on the synthetic data, that means an error lower than 3.5% of the simulated IMU-joint vector. Its accuracy is also tested on the real scenario estimating the COR of the hip of 5 volunteers using as reference the results from an optical system. In this case, ArVEd gets an average error of 9.5% of the real vector value. In all the experiments, ArVEd outperforms the published results of the reference algorithms.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "\\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2402.04241",
        "abstract url": "https://arxiv.org/abs/2402.04241",
        "title": "Algebraic identifiability of partial differential equation models",
        "rating": -10,
        "keywords": [],
        "abstract": "Differential equation models are crucial to scientific processes. The values of model parameters are important for analyzing the behaviour of solutions. A parameter is called globally identifiable if its value can be uniquely determined from the input and output functions. To determine if a parameter estimation problem is well-posed for a given model, one must check if the model parameters are globally identifiable. This problem has been intensively studied for ordinary differential equation models, with theory and several efficient algorithms and software packages developed. A comprehensive theory of algebraic identifiability for PDEs has hitherto not been developed due to the complexity of initial and boundary conditions. Here, we provide theory and algorithms, based on differential algebra, for testing identifiability of polynomial PDE models. We showcase this approach on PDE models arising in the sciences.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04243",
        "abstract url": "https://arxiv.org/abs/2402.04243",
        "title": "Invariant Set Estimation for Piecewise Affine Dynamical Systems Using Piecewise Affine Barrier Function",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper introduces an algorithm for approximating the invariant set of closed-loop controlled dynamical systems identified using ReLU neural networks or piecewise affine PWA functions, particularly addressing the challenge of providing safety guarantees for ReLU networks commonly used in safety-critical applications. The invariant set of PWA dynamical system is estimated using ReLU networks or its equivalent PWA function. This method entails formulating the barrier function as a PWA function and converting the search process into a linear optimization problem using vertices. We incorporate a domain refinement strategy to increase flexibility in case the optimization does not find a valid barrier function. Moreover, the objective of optimization is to maximize the invariant set based on the current partition. Our experimental results demonstrate the effectiveness and efficiency of our approach, demonstrating its potential for ensuring the safety of PWA dynamical systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Preprint submitted to European Journal of Control, 9 pages, 7 figures"
    },
    {
        "paper id": "2402.04295",
        "abstract url": "https://arxiv.org/abs/2402.04295",
        "title": "Constructions of Abelian Codes multiplying dimension of cyclic codes",
        "rating": -10,
        "keywords": [],
        "abstract": "In this note, we apply some techniques developed in [1]-[3] to give a particular construction of bivariate Abelian Codes from cyclic codes, multiplying their dimension and preserving their apparent distance. We show that, in the case of cyclic codes whose maximum BCH bound equals its minimum distance the obtained abelian code verifies the same property; that is, the strong apparent distance and the minimum distance coincide. We finally use this construction to multiply Reed-Solomon codes to abelian codes",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2402.03938"
    },
    {
        "paper id": "2402.04319",
        "abstract url": "https://arxiv.org/abs/2402.04319",
        "title": "A Modified de Casteljau Subdivision that Supports Smooth Stitching with Hierarchically Organized Bicubic Bezier Patches",
        "rating": -10,
        "keywords": [],
        "abstract": "One of the theoretically intriguing problems in computer-aided geometric modeling comes from the stitching of the tensor product Bezier patches. When they share an extraordinary vertex, it is not possible to obtain continuity C1 or G1 along the edges emanating from that extraordinary vertex. Unfortunately, this stitching problem cannot be solved by using higher degree or rational polynomials. In this paper, we present a modified de Casteljau subdivision algorithm that can provide a solution to this problem. Our modified de Casteljau subdivision, when combined with topological modeling, provides a framework for interactive real-time modeling of piecewise smooth manifold meshes with arbitrary topology. The main advantage of the modified subdivision is that the continuity C1 on a given boundary edge does not depend on the positions of the control points on other boundary edges. The modified subdivision allows us to obtain the desired C1 continuity along the edges emanating from the extraordinary vertices along with the desired G1 continuity in the extraordinary vertices.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2402.04326",
        "abstract url": "https://arxiv.org/abs/2402.04326",
        "title": "Personality Trait Recognition using ECG Spectrograms and Deep Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper presents an innovative approach to recognizing personality traits using deep learning (DL) methods applied to electrocardiogram (ECG) signals. Within the framework of detecting the big five personality traits model encompassing extra-version, neuroticism, agreeableness, conscientiousness, and openness, the research explores the potential of ECG-derived spectrograms as informative features. Optimal window sizes for spectrogram generation are determined, and a convolutional neural network (CNN), specifically Resnet-18, and visual transformer (ViT) are employed for feature extraction and personality trait classification. The study utilizes the publicly available ASCERTAIN dataset, which comprises various physiological signals, including ECG recordings, collected from 58 participants during the presentation of video stimuli categorized by valence and arousal levels. The outcomes of this study demonstrate noteworthy performance in personality trait classification, consistently achieving F1-scores exceeding 0.9 across different window sizes and personality traits. These results emphasize the viability of ECG signal spectrograms as a valuable modality for personality trait recognition, with Resnet-18 exhibiting effectiveness in discerning distinct personality traits.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04328",
        "abstract url": "https://arxiv.org/abs/2402.04328",
        "title": "Production-Inventory games: a new class of totally balanced combinatorial optimization games",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper we introduce a new class of cooperative games that arise from production-inventory problems. Several agents have to cover their demand over a finite time horizon and shortages are allowed. Each agent has its own unit production, inventory-holding and backlogging cost. Cooperation among agents is given by sharing production processes and warehouse facilities: agents in a coalition produce with \\ the cheapest production cost and store with the cheapest inventory cost. We prove that the resulting cooperative game is totally balanced and the Owen set reduces to a singleton: the Owen point. Based on this type of allocation we find a population monotonic allocation scheme for this class of games. Finally, we point out the relationship of the Owen point with other well-known allocation rules such as the nucleolus and the Shapley value.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04334",
        "abstract url": "https://arxiv.org/abs/2402.04334",
        "title": "Home Automation System based on Intelligent Transducer Enablers",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper presents a novel home automation system named HASITE (Home Automation System based on Intelligent Transducer Enablers), which has been specifically designed to identify and configure transducers easily and quickly. These features are especially useful in situations where many transducers are deployed, since their setup becomes a cumbersome task that consumes a significant amount of time and human resources. HASITE simplifies the deployment of a home automation system by using wireless networks and both self-configuration and self-registration protocols. Thanks to the application of these three elements, HASITE is able to add new transducers by just powering them up. According to the tests performed in different realistic scenarios, a transducer is ready to be used in less than 13 s. Moreover, all HASITE functionalities can be accessed through an API, which also allows for the integration of third-party systems. As an example, an Android application based on the API is presented. Remote users can use it to interact with transducers by just using a regular smartphone or a tablet.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "27 pages, 17 figures, accepted version of Sensors journal article"
    },
    {
        "paper id": "2402.04336",
        "abstract url": "https://arxiv.org/abs/2402.04336",
        "title": "p-additive games: a class of totally balanced games arising from inventory situations with temporary discounts",
        "rating": -10,
        "keywords": [],
        "abstract": "We introduce a new class of totally balanced cooperative TU games, namely p -additive games. It is inspired by the class of inventory games that arises from inventory situations with temporary discounts (Toledo, 2002) and contains the class of inventory cost games (Meca et al. 2003). It is shown that every p-additive game and its corresponding subgames have a nonempty core. We also focus on studying the character concave or convex and monotone of p-additive games. In addition, the modified SOC-rule is proposed as a solution for p-additive games. This solution is suitable for p-additive games since it is a core-allocation which can be reached through a population monotonic allocation scheme. Moreover, two characterizations of the modified SOC-rule are provided.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04355",
        "abstract url": "https://arxiv.org/abs/2402.04355",
        "title": "PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation",
        "rating": -10,
        "keywords": [],
        "abstract": "We propose a comprehensive sample-based method for assessing the quality of generative models. The proposed approach enables the estimation of the probability that two sets of samples are drawn from the same distribution, providing a statistically rigorous method for assessing the performance of a single generative model or the comparison of multiple competing models trained on the same dataset. This comparison can be conducted by dividing the space into non-overlapping regions and comparing the number of data samples in each region. The method only requires samples from the generative model and the test data. It is capable of functioning directly on high-dimensional data, obviating the need for dimensionality reduction. Significantly, the proposed method does not depend on assumptions regarding the density of the true distribution, and it does not rely on training or fitting any auxiliary models. Instead, it focuses on approximating the integral of the density (probability mass) across various sub-regions within the data space.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "14 pages, 13 figures"
    },
    {
        "paper id": "2402.04357",
        "abstract url": "https://arxiv.org/abs/2402.04357",
        "title": "Building Retrieval Systems for the ClueWeb22-B Corpus",
        "rating": -10,
        "keywords": [],
        "abstract": "The ClueWeb22 dataset containing nearly 10 billion documents was released in 2022 to support academic and industry research. The goal of this project was to build retrieval baselines for the English section of the \"super head\" part (category B) of this dataset. These baselines can then be used by the research community to compare their systems and also to generate data to train/evaluate new retrieval and ranking algorithms. The report covers sparse and dense first stage retrievals as well as neural rerankers that were implemented for this dataset. These systems are available as a service on a Carnegie Mellon University cluster.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04364",
        "abstract url": "https://arxiv.org/abs/2402.04364",
        "title": "Exponential Separation Between Powers of Regular and General Resolution Over Parities",
        "rating": -10,
        "keywords": [],
        "abstract": "Proving super-polynomial lower bounds on the size of proofs of unsatisfiability of Boolean formulas using resolution over parities is an outstanding problem that has received a lot of attention after its introduction by Raz and Tzamaret [Ann. Pure Appl. Log.'08]. Very recently, Efremenko, Garl\u00edk and Itsykson [ECCC'23] proved the first exponential lower bounds on the size of ResLin proofs that were additionally restricted to be bottom-regular. We show that there are formulas for which such regular ResLin proofs of unsatisfiability continue to have exponential size even though there exists short proofs of their unsatisfiability in ordinary, non-regular resolution. This is the first super-polynomial separation between the power of general ResLin and and that of regular ResLin for any natural notion of regularity. Our argument, while building upon the work of Efremenko et al., uses additional ideas from the literature on lifting theorems.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04380",
        "abstract url": "https://arxiv.org/abs/2402.04380",
        "title": "Assured LLM-Based Software Engineering",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper we address the following question: How can we use Large Language Models (LLMs) to improve code independently of a human, while ensuring that the improved code - does not regress the properties of the original code? - improves the original in a verifiable and measurable way? To address this question, we advocate Assured LLM-Based Software Engineering; a generate-and-test approach, inspired by Genetic Improvement. Assured LLMSE applies a series of semantic filters that discard code that fails to meet these twin guarantees. This overcomes the potential problem of LLM's propensity to hallucinate. It allows us to generate code using LLMs, independently of any human. The human plays the role only of final code reviewer, as they would do with code generated by other human engineers. This paper is an outline of the content of the keynote by Mark Harman at the International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, Monday 15th April 2024, Lisbon, Portugal.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "6 pages, 1 figure, InteNSE 24: ACM International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, April, 2024, Lisbon, Portugal"
    },
    {
        "paper id": "2402.04391",
        "abstract url": "https://arxiv.org/abs/2402.04391",
        "title": "The Howard-Harvard effect: Institutional reproduction of intersectional inequalities",
        "rating": -10,
        "keywords": [],
        "abstract": "The US higher education system concentrates the production of science and scientists within a few institutions. This has implications for minoritized scholars and the topics with which they are disproportionately associated. This paper examines topical alignment between institutions and authors of varying intersectional identities, and the relationship with prestige and scientific impact. We observe a Howard-Harvard effect, in which the topical profile of minoritized scholars are amplified in mission-driven institutions and decreased in prestigious institutions. Results demonstrate a consistent pattern of inequality in topics and research impact. Specifically, we observe statistically significant differences between minoritized scholars and White men in citations and journal impact. The aggregate research profile of prestigious US universities is highly correlated with the research profile of White men, and highly negatively correlated with the research profile of minoritized women. Furthermore, authors affiliated with more prestigious institutions are associated with increasing inequalities in both citations and journal impact. Academic institutions and funders are called to create policies to mitigate the systemic barriers that prevent the United States from achieving a fully robust scientific ecosystem.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04392",
        "abstract url": "https://arxiv.org/abs/2402.04392",
        "title": "Factorial Basis Method for q-Series Applications",
        "rating": -10,
        "keywords": [],
        "abstract": "The Factorial Basis method, initially designed for quasi-triangular, shift-compatible factorial bases, provides solutions to linear recurrence equations in the form of definite-sums. This paper extends the Factorial Basis method to its q-analog, enabling its application in q-calculus. We demonstrate the adaptation of the method to q-sequences and its utility in the realm of q-combinatorics. The extended technique is employed to automatically prove established identities and unveil novel ones, particularly some associated with the Rogers-Ramanujan identities.",
        "subjects": [
            "cs.SC"
        ],
        "comment": "9 double-column pages"
    },
    {
        "paper id": "2402.04395",
        "abstract url": "https://arxiv.org/abs/2402.04395",
        "title": "Auto-Encoder Optimized PAM IM/DD Transceivers for Amplified Fiber Links",
        "rating": -10,
        "keywords": [],
        "abstract": "We examine pulse amplitude modulation (PAM) for intensity modulation and direct detection systems. Using a straight-forward, mixed noise model, we optimize the constellations with an autoencoder-based neural network (NN), an improve required signal-to-noise ratio of 4 dB for amplified spontaneous emission (ASE)-limited PAM4 and PAM8, without increasing system complexity. Performance can also be improved in O-band wavelength division multiplexing system with semiconductor optical amplifier amplification and chromatic dispersion. We show via simulation that for such a system operating at 53 Gbaud, we can extend the reach of PAM4 by 10-25 km with an optimized constellation and a NN decoder. We present an experimental validation of 4 dB improvement of an ASE-limited PAM4 at 60 Gbaud using an optimized constellation and a NN decoder.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages and 11 figures"
    },
    {
        "paper id": "2402.04399",
        "abstract url": "https://arxiv.org/abs/2402.04399",
        "title": "A Repeated Auction Model for Load-Aware Dynamic Resource Allocation in Multi-Access Edge Computing",
        "rating": -10,
        "keywords": [],
        "abstract": "Multi-access edge computing (MEC) is one of the enabling technologies for high-performance computing at the edge of the 6 G networks, supporting high data rates and ultra-low service latency. Although MEC is a remedy to meet the growing demand for computation-intensive applications, the scarcity of resources at the MEC servers degrades its performance. Hence, effective resource management is essential; nevertheless, state-of-the-art research lacks efficient economic models to support the exponential growth of the MEC-enabled applications market. We focus on designing a MEC offloading service market based on a repeated auction model with multiple resource sellers (e.g., network operators and service providers) that compete to sell their computing resources to the offloading users. We design a computationally-efficient modified Generalized Second Price (GSP)-based algorithm that decides on pricing and resource allocation by considering the dynamic offloading requests arrival and the servers' computational workloads. Besides, we propose adaptive best-response bidding strategies for the resource sellers, satisfying the symmetric Nash equilibrium (SNE) and individual rationality properties. Finally, via intensive numerical results, we show the effectiveness of our proposed resource allocation mechanism.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "17 pages, 11 figures"
    },
    {
        "paper id": "2402.04405",
        "abstract url": "https://arxiv.org/abs/2402.04405",
        "title": "Interpretable domain knowledge enhanced machine learning framework on axial capacity prediction of circular CFST columns",
        "rating": -10,
        "keywords": [],
        "abstract": "This study introduces a novel machine learning framework, integrating domain knowledge, to accurately predict the bearing capacity of CFSTs, bridging the gap between traditional engineering and machine learning techniques. Utilizing a comprehensive database of 2621 experimental data points on CFSTs, we developed a Domain Knowledge Enhanced Neural Network (DKNN) model. This model incorporates advanced feature engineering techniques, including Pearson correlation, XGBoost, and Random tree algorithms. The DKNN model demonstrated a marked improvement in prediction accuracy, with a Mean Absolute Percentage Error (MAPE) reduction of over 50% compared to existing models. Its robustness was confirmed through extensive performance assessments, maintaining high accuracy even in noisy environments. Furthermore, sensitivity and SHAP analysis were conducted to assess the contribution of each effective parameter to axial load capacity and propose design recommendations for the diameter of cross-section, material strength range and material combination. This research advances CFST predictive modelling, showcasing the potential of integrating machine learning with domain expertise in structural engineering. The DKNN model sets a new benchmark for accuracy and reliability in the field.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "Journal Research Article"
    },
    {
        "paper id": "2402.04424",
        "abstract url": "https://arxiv.org/abs/2402.04424",
        "title": "Optimal Binary Signaling for a Two Sensor Gaussian MAC Network",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider a two sensor distributed detection system transmitting a binary non-uniform source over a Gaussian multiple access channel (MAC). We model the network via binary sensors whose outputs are generated by binary symmetric channels of different noise levels. We prove an optimal one dimensional constellation design under individual sensor power constraints which minimizes the error probability of detecting the source. Three distinct cases arise for this optimization based on the parameters in the problem setup. In the most notable case (Case III), the optimal signaling design is to not necessarily use all of the power allocated to the more noisy sensor (with less correlation to the source). We compare the error performance of the optimal one dimensional constellation to orthogonal signaling. The results show that the optimal one dimensional constellation achieves lower error probability than using orthogonal channels.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04436",
        "abstract url": "https://arxiv.org/abs/2402.04436",
        "title": "Continuous Multidimensional Scaling",
        "rating": -10,
        "keywords": [],
        "abstract": "Multidimensional scaling (MDS) is the act of embedding proximity information about a set of $n$ objects in $d$-dimensional Euclidean space. As originally conceived by the psychometric community, MDS was concerned with embedding a fixed set of proximities associated with a fixed set of objects. Modern concerns, e.g., that arise in developing asymptotic theories for statistical inference on random graphs, more typically involve studying the limiting behavior of a sequence of proximities associated with an increasing set of objects. Standard results from the theory of point-to-set maps imply that, if $n$ is fixed and a sequence of proximities converges, then the limit of the embedded structures is the embedded structure of the limiting proximities. But what if $n$ increases? It then becomes necessary to reformulate MDS so that the entire sequence of embedding problems can be viewed as a sequence of optimization problems in a fixed space. We present such a reformulation and derive some consequences.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "15 pages. Modified a sentence in the Abstract for greater clarity"
    },
    {
        "paper id": "2402.04438",
        "abstract url": "https://arxiv.org/abs/2402.04438",
        "title": "The domino problem is decidable for robust tilesets",
        "rating": -10,
        "keywords": [],
        "abstract": "One of the most fundamental problems in tiling theory is the domino problem: given a set of tiles and tiling rules, decide if there exists a way to tile the plane using copies of tiles and following their rules. The problem is known to be undecidable in general and even for sets of Wang tiles, which are unit square tiles wearing colours on their edges which can be assembled provided they share the same colour on their common edge, as proven by Berger in the 1960s. In this paper, we focus on Wang tilesets. We prove that the domino problem is decidable for robust tilesets, i.e. tilesets that either cannot tile the plane or can but, if so, satisfy some particular invariant provably. We establish that several famous tilesets considered in the literature are robust. We give arguments that this is true for all tilesets unless they are produced from non-robust Turing machines: a Turing machine is said to be non-robust if it does not halt and furthermore does so non-provably. As a side effect of our work, we provide a sound and relatively complete method for proving that a tileset can tile the plane. Our analysis also provides explanations for the observed similarities between proofs in the literature for various tilesets, as well as of phenomena that have been observed experimentally in the systematic study of tilesets using computer methods.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04444",
        "abstract url": "https://arxiv.org/abs/2402.04444",
        "title": "Equitable Networked Microgrid Topology Reconfiguration for Wildfire Risk Mitigation",
        "rating": -10,
        "keywords": [],
        "abstract": "Increasing amount of wildfires in recent years consistently challenges the safe and reliable operations of power systems. To prevent power lines and other electrical components from causing wildfires under extreme conditions, electric utilities often deploy public safety power shutoffs (PSPS) to mitigate the wildfire risks therein. Although PSPS are effective countermeasures against wildfires, uncoordinated strategies can cause disruptions in electricity supply and even lead to cascading failures. Meanwhile, it is extremely important to consider mitigating biased decisions on different communities and populations during the implementation of shutoff actions. In this work, we primarily focus on the dynamic reconfiguration problem of networked microgrids with distributed energy resources. In particular, we formulate a rolling horizon optimization problem allowing for flexible network reconfiguration at each time interval to mitigate wildfire risks. To promote equity and fairness during the span of shutoffs, we further enforce a range of constraints associated with load shedding to discourage disproportionate impact on individual load blocks. Numerical studies on the modified IEEE 13-bus system and a larger-sized Smart-DS system demonstrate the performance of the proposed algorithm towards more equitable power shutoff operations.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04452",
        "abstract url": "https://arxiv.org/abs/2402.04452",
        "title": "Symbolic Computation of Sequential Equilibria",
        "rating": -10,
        "keywords": [],
        "abstract": "The sequential equilibrium is a standard solution concept for extensive-form games with imperfect information that includes an explicit representation of the players' beliefs. An assessment consisting of a strategy and a belief is a sequential equilibrium if it satisfies the properties of sequential rationality and consistency. Our main result is that both properties together can be written as a single finite system of polynomial equations and inequalities. The solutions to this system are exactly the sequential equilibria of the game. We construct this system explicitly and describe an implementation that solves it using cylindrical algebraic decomposition. To write consistency as a finite system of equations, we need to compute the extreme directions of a set of polyhedral cones. We propose a modified version of the double description method, optimized for this specific purpose. To the best of our knowledge, our implementation is the first to symbolically solve general finite imperfect information games for sequential equilibria.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "Accepted as a full paper at AAMAS 2024"
    },
    {
        "paper id": "2402.04453",
        "abstract url": "https://arxiv.org/abs/2402.04453",
        "title": "The Potential of AutoML for Recommender Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Automated Machine Learning (AutoML) has greatly advanced applications of Machine Learning (ML) including model compression, machine translation, and computer vision. Recommender Systems (RecSys) can be seen as an application of ML. Yet, AutoML has found little attention in the RecSys community; nor has RecSys found notable attention in the AutoML community. Only few and relatively simple Automated Recommender Systems (AutoRecSys) libraries exist that adopt AutoML techniques. However, these libraries are based on student projects and do not offer the features and thorough development of AutoML libraries. We set out to determine how AutoML libraries perform in the scenario of an inexperienced user who wants to implement a recommender system. We compared the predictive performance of 60 AutoML, AutoRecSys, ML, and RecSys algorithms from 15 libraries, including a mean predictor baseline, on 14 explicit feedback RecSys datasets. To simulate the perspective of an inexperienced user, the algorithms were evaluated with default hyperparameters. We found that AutoML and AutoRecSys libraries performed best. AutoML libraries performed best for six of the 14 datasets (43%), but it was not always the same AutoML library performing best. The single-best library was the AutoRecSys library Auto-Surprise, which performed best on five datasets (36%). On three datasets (21%), AutoML libraries performed poorly, and RecSys libraries with default parameters performed best. Although, while obtaining 50% of all placements in the top five per dataset, RecSys algorithms fall behind AutoML on average. ML algorithms generally performed the worst.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04479",
        "abstract url": "https://arxiv.org/abs/2402.04479",
        "title": "Unleashing the Potential of LTE for Next Generation Railway Communications",
        "rating": -10,
        "keywords": [],
        "abstract": "In an increasingly demanding marketplace that will put great strain on railway services, research on broadband wireless communication must continue to strive for improvement. Based on the mature narrowband GSM technology, Global System for Mobile Communications-Railways (GSM-R) has been deployed both for operational and voice communications. Although GSM-R fulfills the requirements of current railway services, it imposes limited capacity and high costs that restrict enhancements of operational efficiency, passenger security and transport quality. 4G Long Term Evolution (LTE) is expected to be the natural successor of GSM-R not only for its technical advantages and increasing performance, but also due to the current evolution of general-purpose communication systems. This paper examines the key features of LTE as well as its technical ability to support both the migration of current railway services and the provisioning of future ones.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This is a portion of the ACCEPTED VERSION of the published document in: Kassab, M., Berbineau,M., Vinel, A., Jonsson, M., Garcia, F., Soler, J. (eds) Communication Technologies for Vehicles. Nets4Cars/Nets4Trains/Nets4Aircraft 2015. Lecture Notes in Computer Science, vol 9066. Springer, Cham. https://doi.org/10.1007/978-3-319-17765-6_14"
    },
    {
        "paper id": "2402.04486",
        "abstract url": "https://arxiv.org/abs/2402.04486",
        "title": "Outer Code Designs for Augmented and Local-Global Polar Code Architectures",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we introduce two novel methods to design outer polar codes for two previously proposed concatenated polar code architectures: augmented polar codes and local-global polar codes. These methods include a stopping set (SS) construction and a nonstationary density evolution (NDE) construction. Simulation results demonstrate the advantage of these methods over previously proposed constructions based on density evolution (DE) and LLR evolution.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2402.04491",
        "abstract url": "https://arxiv.org/abs/2402.04491",
        "title": "Modeling and Characterizing Service Interference in Dynamic Infrastructures",
        "rating": -10,
        "keywords": [],
        "abstract": "Performance interference can occur when various services are executed over the same physical infrastructure in a cloud system. This can lead to performance degradation compared to the execution of services in isolation. This work proposes a Confirmatory Factor Analysis (CFA)-based model to estimate performance interference across containers, caused by the use of CPU, memory and IO across a number of co-hosted applications. The approach provides resource characterization through human comprehensible indices expressed as time series, so the interference in the entire execution lifetime of a service can be analyzed. Our experiments, based on the combination of real services with different profiles executed in Docker containers, suggest that our model can accurately predict the overall execution time, for different service combinations. The approach can be used by a service designer to identify phases, during the execution life-cycle of a service, that are likely to lead to a greater degree of interference, and to ensure that only complementary services are hosted on the same physical machine. Interference-awareness of this kind will enable more intelligent resource management and scheduling for cloud systems, and may be used to dynamically modify scheduling decisions.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04493",
        "abstract url": "https://arxiv.org/abs/2402.04493",
        "title": "A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Low-Rank MDPs",
        "rating": -10,
        "keywords": [],
        "abstract": "Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward using a pre-collected dataset. Offline RL with low-rank MDPs or general function approximation has been widely studied recently, but existing algorithms with sample complexity $O(\u03b5^{-2})$ for finding an $\u03b5$-optimal policy either require a uniform data coverage assumptions or are computationally inefficient. In this paper, we propose a primal dual algorithm for offline RL with low-rank MDPs in the discounted infinite-horizon setting. Our algorithm is the first computationally efficient algorithm in this setting that achieves sample complexity of $O(\u03b5^{-2})$ with partial data coverage assumption. This improves upon a recent work that requires $O(\u03b5^{-4})$ samples. Moreover, our algorithm extends the previous work to the offline constrained RL setting by supporting constraints on additional reward signals.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04506",
        "abstract url": "https://arxiv.org/abs/2402.04506",
        "title": "Processing All-Sky Images At Scale On The Amazon Cloud: A HiPS Example",
        "rating": -10,
        "keywords": [],
        "abstract": "We report here on a project that has developed a practical approach to processing all-sky image collections on cloud platforms, using as an exemplar application the creation of three-color Hierarchical Progressive Survey (HiPS) maps of the 2MASS data set with the Montage Image Mosaic Engine on Amazon Web Services. We will emphasize issues that must be considered by scientists wishing to use cloud platforms to perform such parallel processing, so providing a guide for scientists wishing to exploit cloud platforms for similar large-scale processing. A HiPS map is based on the HEALPix sky-tiling scheme. Progressive zooming of a HiPS map reveals an image sampled at ever smaller or larger spatial scales that are defined by the HEALPix standard. Briefly, the approach used by Montage involves creating a base mosaic at the lowest required HEALPix level, usually chosen to match as closely as possible the spatial sampling of the input images, then cutting out the HiPS cells in PNG format from this mosaic. The process is repeated at successive HEALPix levels to create a nested collection of FITS files, from which PNG files are created that are shown in HiPS viewers. Stretching FITS files to produce PNGs is based on an image histogram. For composite regions (up and including the whole sky), the histograms for each tile can be combined to create a composite histogram for the region. Using this single histogram for each of the individual FITS files means all the PNGs are on the same brightness scale and displaying them side by side in a HiPS viewer produces a continuous uniform map across the entire sky.",
        "subjects": [
            "astro-ph.IM"
        ],
        "comment": "4 pages, 1 figure, ADASS 2024 proceedings"
    },
    {
        "paper id": "2402.04534",
        "abstract url": "https://arxiv.org/abs/2402.04534",
        "title": "M2fNet: Multi-modal Forest Monitoring Network on Large-scale Virtual Dataset",
        "rating": -10,
        "keywords": [],
        "abstract": "Forest monitoring and education are key to forest protection, education and management, which is an effective way to measure the progress of a country's forest and climate commitments. Due to the lack of a large-scale wild forest monitoring benchmark, the common practice is to train the model on a common outdoor benchmark (e.g., KITTI) and evaluate it on real forest datasets (e.g., CanaTree100). However, there is a large domain gap in this setting, which makes the evaluation and deployment difficult. In this paper, we propose a new photorealistic virtual forest dataset and a multimodal transformer-based algorithm for tree detection and instance segmentation. To the best of our knowledge, it is the first time that a multimodal detection and segmentation algorithm is applied to large-scale forest scenes. We believe that the proposed dataset and method will inspire the simulation, computer vision, education, and forestry communities towards a more comprehensive multi-modal understanding.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2402.04536",
        "abstract url": "https://arxiv.org/abs/2402.04536",
        "title": "Tactile-based Object Retrieval From Granular Media",
        "rating": -10,
        "keywords": [],
        "abstract": "We introduce GEOTACT, a robotic manipulation method capable of retrieving objects buried in granular media. This is a challenging task due to the need to interact with granular media, and doing so based exclusively on tactile feedback, since a buried object can be completely hidden from vision. Tactile feedback is in itself challenging in this context, due to ubiquitous contact with the surrounding media, and the inherent noise level induced by the tactile readings. To address these challenges, we use a learning method trained end-to-end with simulated sensor noise. We show that our problem formulation leads to the natural emergence of learned pushing behaviors that the manipulator uses to reduce uncertainty and funnel the object to a stable grasp despite spurious and noisy tactile readings. We also introduce a training curriculum that enables learning these behaviors in simulation, followed by zero-shot transfer to real hardware. To the best of our knowledge, GEOTACT is the first method to reliably retrieve a number of different objects from a granular environment, doing so on real hardware and with integrated tactile sensing. Videos and additional information can be found at https://jxu.ai/geotact.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04548",
        "abstract url": "https://arxiv.org/abs/2402.04548",
        "title": "NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering",
        "rating": -10,
        "keywords": [],
        "abstract": "Open Retrieval Conversational Question Answering (OrConvQA) answers a question given a conversation as context and a document collection. A typical OrConvQA pipeline consists of three modules: a Retriever to retrieve relevant documents from the collection, a Reranker to rerank them given the question and the context, and a Reader to extract an answer span. The conversational turns can provide valuable context to answer the final query. State-of-the-art OrConvQA systems use the same history modeling for all three modules of the pipeline. We hypothesize this as suboptimal. Specifically, we argue that a broader context is needed in the first modules of the pipeline to not miss relevant documents, while a narrower context is needed in the last modules to identify the exact answer span. We propose NORMY, the first unsupervised non-uniform history modeling pipeline which generates the best conversational history for each module. We further propose a novel Retriever for NORMY, which employs keyphrase extraction on the conversation history, and leverages passages retrieved in previous turns as additional context. We also created a new dataset for OrConvQA, by expanding the doc2dial dataset. We implemented various state-of-the-art history modeling techniques and comprehensively evaluated them separately for each module of the pipeline on three datasets: OR-QUAC, our doc2dial extension, and ConvMix. Our extensive experiments show that NORMY outperforms the state-of-the-art in the individual modules and in the end-to-end system.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted for publication at IEEE ICSC 2024"
    },
    {
        "paper id": "2402.04550",
        "abstract url": "https://arxiv.org/abs/2402.04550",
        "title": "Riemann-Lebesgue Forest for Regression",
        "rating": -10,
        "keywords": [],
        "abstract": "We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea of RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree which has a chance to split the node from response $Y$ or a direction in feature space $\\mathbf{X}$ at each non-terminal node. We generalize the asymptotic performance of RLF under different parameter settings mainly through Hoeffding decomposition \\cite{Vaart} and Stein's method \\cite{Chen2010NormalAB}. When the underlying function $Y=f(\\mathbf{X})$ follows an additive regression model, RLF is consistent with the argument from \\cite{Scornet2014ConsistencyOR}. The competitive performance of RLF against original random forest \\cite{Breiman2001RandomF} is demonstrated by experiments in simulation data and real world datasets.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04568",
        "abstract url": "https://arxiv.org/abs/2402.04568",
        "title": "Enhancing User Interaction in ChatGPT: Characterizing and Consolidating Multiple Prompts for Issue Resolution",
        "rating": -10,
        "keywords": [],
        "abstract": "Prompt design plays a crucial role in shaping the efficacy of ChatGPT, influencing the model's ability to extract contextually accurate responses. Thus, optimal prompt construction is essential for maximizing the utility and performance of ChatGPT. However, sub-optimal prompt design may necessitate iterative refinement, as imprecise or ambiguous instructions can lead to undesired responses from ChatGPT. Existing studies explore several prompt patterns and strategies to improve the relevance of responses generated by ChatGPT. However, the exploration of constraints that necessitate the submission of multiple prompts is still an unmet attempt. In this study, our contributions are twofold. First, we attempt to uncover gaps in prompt design that demand multiple iterations. In particular, we manually analyze 686 prompts that were submitted to resolve issues related to Java and Python programming languages and identify eleven prompt design gaps (e.g., missing specifications). Such gap exploration can enhance the efficacy of single prompts in ChatGPT. Second, we attempt to reproduce the ChatGPT response by consolidating multiple prompts into a single one. We can completely consolidate prompts with four gaps (e.g., missing context) and partially consolidate prompts with three gaps (e.g., additional functionality). Such an effort provides concrete evidence to users to design more optimal prompts mitigating these gaps. Our study findings and evidence can - (a) save users time, (b) reduce costs, and (c) increase user satisfaction.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper has been accepted at the 21st International Conference on Mining Software Repositories (MSR 2024)"
    },
    {
        "paper id": "2402.04570",
        "abstract url": "https://arxiv.org/abs/2402.04570",
        "title": "RIS-NOMA integrated low-complexity transceiver architecture: Sum rate and energy efficiency perspective",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper aims to explore reconfigurable intelligent surface (RIS) integration in a millimeter wave (mmWave) communication system with low-complexity transceiver architecture under imperfect CSI assumption. Towards this, we propose a RIS-aided system with a fully analog (FA) architecture at the base station. However, to overcome the disadvantage of single-user transmission due to the single RF-chain, we employ NOMA. For such a system, we formulate sum rate (SR) and energy efficiency (EE) maximization problems to obtain the joint transmit beamformer, RIS phase shift matrix, and power allocation solutions under minimum rate constraint. We first tackle the fractional objectives of both problems by reformulating the SR and EE maximization problems into equivalent quadratic forms using the quadratic transform. On the other hand, we employ successive convex approximation and the semi-definite relaxation technique to handle the non-convex minimum rate and unit modulus constraint of the RIS phase shifts, respectively. Next, we propose an alternating optimization-based algorithm that iterates over the transmit beamformer, power allocation, and RIS phase shift subproblems. Further, we also show that the quadratic reformulation is equivalent to the WMSE-based reformulation for the case of SR maximization problem. Our numerical results show that the proposed RIS-NOMA integrated FA architecture system outperforms the optimally configured fully digital architecture in terms of SR at low SNR and EE for a wide range of SNR while still maintaining low hardware complexity and cost. Finally, we present the numerical performance analysis of the RIS-NOMA integrated low-complexity system for various system configuration parameters.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04575",
        "abstract url": "https://arxiv.org/abs/2402.04575",
        "title": "Can We Identify Stack Overflow Questions Requiring Code Snippets? Investigating the Cause & Effect of Missing Code Snippets",
        "rating": -10,
        "keywords": [],
        "abstract": "On the Stack Overflow (SO) Q&A site, users often request solutions to their code-related problems (e.g., errors, unexpected behavior). Unfortunately, they often miss required code snippets during their question submission, which could prevent their questions from getting prompt and appropriate answers. In this study, we conduct an empirical study investigating the cause & effect of missing code snippets in SO questions whenever required. Here, our contributions are threefold. First, we analyze how the presence or absence of required code snippets affects the correlation between question types (missed code, included code after requests & had code snippets during submission) and corresponding answer meta-data (e.g., presence of an accepted answer). According to our analysis, the chance of getting accepted answers is three times higher for questions that include required code snippets during their question submission than those that missed the code. We also investigate whether the confounding factors (e.g., user reputation) affect questions receiving answers besides the presence or absence of required code snippets. We found that such factors do not hurt the correlation between the presence or absence of required code snippets and answer meta-data. Second, we surveyed 64 practitioners to understand why users miss necessary code snippets. About 60% of them agree that users are unaware of whether their questions require any code snippets. Third, we thus extract four text-based features (e.g., keywords) and build six ML models to identify the questions that need code snippets. Our models can predict the target questions with 86.5% precision, 90.8% recall, 85.3% F1-score, and 85.2% overall accuracy. Our work has the potential to save significant time in programming question-answering and improve the quality of the valuable knowledge base by decreasing unanswered and unresolved questions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper has been accepted for inclusion in the International Conference on Software Analysis, Evolution, and Reengineering (SANER 2024) technical program"
    },
    {
        "paper id": "2402.04581",
        "abstract url": "https://arxiv.org/abs/2402.04581",
        "title": "Boosting Reinforcement Learning Algorithms in Continuous Robotic Reaching Tasks using Adaptive Potential Functions",
        "rating": -10,
        "keywords": [],
        "abstract": "In reinforcement learning, reward shaping is an efficient way to guide the learning process of an agent, as the reward can indicate the optimal policy of the task. The potential-based reward shaping framework was proposed to guarantee policy invariance after reward shaping, where a potential function is used to calculate the shaping reward. In former work, we proposed a novel adaptive potential function (APF) method to learn the potential function concurrently with training the agent based on information collected by the agent during the training process, and examined the APF method in discrete action space scenarios. This paper investigates the feasibility of using APF in solving continuous-reaching tasks in a real-world robotic scenario with continuous action space. We combine the Deep Deterministic Policy Gradient (DDPG) algorithm and our proposed method to form a new algorithm called APF-DDPG. To compare APF-DDPG with DDPG, we designed a task where the agent learns to control Baxter's right arm to reach a goal position. The experimental results show that the APF-DDPG algorithm outperforms the DDPG algorithm on both learning speed and robustness.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2402.05141",
        "abstract url": "https://arxiv.org/abs/2402.05141",
        "title": "Tensor Completion via Integer Optimization",
        "rating": -10,
        "keywords": [],
        "abstract": "The main challenge with the tensor completion problem is a fundamental tension between computation power and the information-theoretic sample complexity rate. Past approaches either achieve the information-theoretic rate but lack practical algorithms to compute the corresponding solution, or have polynomial-time algorithms that require an exponentially-larger number of samples for low estimation error. This paper develops a novel tensor completion algorithm that resolves this tension by achieving both provable convergence (in numerical tolerance) in a linear number of oracle steps and the information-theoretic rate. Our approach formulates tensor completion as a convex optimization problem constrained using a gauge-based tensor norm, which is defined in a way that allows the use of integer linear optimization to solve linear separation problems over the unit-ball in this new norm. Adaptations based on this insight are incorporated into a Frank-Wolfe variant to build our algorithm. We show our algorithm scales-well using numerical experiments on tensors with up to ten million entries.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05142",
        "abstract url": "https://arxiv.org/abs/2402.05142",
        "title": "The Foundations of Computational Management: A Systematic Approach to Task Automation for the Integration of Artificial Intelligence into Existing Workflows",
        "rating": -10,
        "keywords": [],
        "abstract": "Driven by the rapid ascent of artificial intelligence (AI), organizations are at the epicenter of a seismic shift, facing a crucial question: How can AI be successfully integrated into existing operations? To help answer it, manage expectations and mitigate frustration, this article introduces Computational Management, a systematic approach to task automation for enhancing the ability of organizations to harness AI's potential within existing workflows. Computational Management acts as a bridge between the strategic insights of management science with the analytical rigor of computational thinking. The article offers three easy step-by-step procedures to begin the process of implementing AI within a workflow. Such procedures focus on task (re)formulation, on the assessment of the automation potential of tasks, on the completion of task specification templates for AI selection and adaptation. Included in the article there are manual and automated methods, with prompt suggestions for publicly available LLMs, to complete these three procedures. The first procedure, task (re)formulation, focuses on breaking down work activities into basic units, so they can be completed by one agent, involve a single well-defined action, and produce a distinct outcome. The second, allows the assessment of the granular task and its suitability for automation, using the Task Automation Index to rank tasks based on whether they have standardized input, well-defined rules, repetitiveness, data dependency, and objective outputs. The third, focuses on a task specification template which details information on 16 critical components of tasks, and can be used as a checklist to select or adapt the most suitable AI solution for integration into existing workflows. Computational Management provides a roadmap and a toolkit for humans and AI to thrive together, while enhancing organizational efficiency and innovation.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "29 pages, 3 appendices"
    },
    {
        "paper id": "2402.06664",
        "abstract url": "https://arxiv.org/abs/2402.06664",
        "title": "LLM Agents can Autonomously Hack Websites",
        "rating": -10,
        "keywords": [],
        "abstract": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves. As a result, these LLMs can now function autonomously as agents. With the rise in capabilities of these agents, recent work has speculated on how LLM agents would affect cybersecurity. However, not much is known about the offensive capabilities of LLM agents. In this work, we show that LLM agents can autonomously hack websites, performing tasks as complex as blind database schema extraction and SQL injections without human feedback. Importantly, the agent does not need to know the vulnerability beforehand. This capability is uniquely enabled by frontier models that are highly capable of tool use and leveraging extended context. Namely, we show that GPT-4 is capable of such hacks, but existing open-source models are not. Finally, we show that GPT-4 is capable of autonomously finding vulnerabilities in websites in the wild. Our findings raise questions about the widespread deployment of LLMs.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.07932",
        "abstract url": "https://arxiv.org/abs/2402.07932",
        "title": "A Human-Machine Collaboration Framework for the Development of Schemas",
        "rating": -10,
        "keywords": [],
        "abstract": "The Winograd Schema Challenge (WSC), a seemingly well-thought-out test for machine intelligence, has been proposed to shed light on developing systems that exhibit human behavior. Since its introduction, it aimed to pivot the focus of the AI community from the technology to the science of AI. While common and trivial for humans, studies show that it is still challenging for machines, especially when they have to deal with novel schemas, that is, well-designed sentences that require the resolving of definite pronouns. As researchers have become increasingly interested in the challenge itself, this presumably necessitates the availability of an extensive collection of Winograd schemas, which goes beyond what human experts can reasonably develop themselves, especially after proposed ways of utilizing them as novel forms of CAPTCHAs. To address this necessity, we propose a novel framework that explicitly focuses on how humans and machines can collaborate as teammates to design novel schemas from scratch. This is being accomplished by combining two recent studies from the literature: i) Winventor, a machine-driven approach for the development of large amounts of Winograd schemas, albeit not of high quality, and ii) WinoFlexi, an online crowdsourcing system that allows crowd workers to develop a limited number of schemas often of similar quality to that of experts. Our proposal crafts a new road map toward developing a novel collaborative platform that amplifies human and machine intelligence by combining their complementary strengths.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2402.07933",
        "abstract url": "https://arxiv.org/abs/2402.07933",
        "title": "Human-Centered AI Product Prototyping with No-Code AutoML: Conceptual Framework, Potentials and Limitations",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper evaluates No-Code AutoML as a solution for challenges in AI product prototyping, characterized by unpredictability and inaccessibility to non-experts, and proposes a conceptual framework. This complexity of AI products hinders seamless execution and interdisciplinary collaboration crucial for human-centered AI products. Relevant to industry and innovation, it affects strategic decision-making and investment risk mitigation. Current approaches provide limited insights into the potential and feasibility of AI product ideas. Employing Design Science Research, the study identifies challenges and integrates no-code AutoML as a solution by presenting a framework for AI product prototyping with No-code AutoML. A case study confirms its potential in supporting non-experts, offering a structured approach to AI product development. The framework facilitates accessible and interpretable prototyping, benefiting academia, managers, and decision-makers. Strategic integration of no-code AutoML enhances efficiency, empowers non-experts, and informs early-stage decisions, albeit with acknowledged limitations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08804",
        "abstract url": "https://arxiv.org/abs/2403.08804",
        "title": "Forward Direct Feedback Alignment for Online Gradient Estimates of Spiking Neural Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "There is an interest in finding energy efficient alternatives to current state of the art neural network training algorithms. Spiking neural network are a promising approach, because they can be simulated energy efficiently on neuromorphic hardware platforms. However, these platforms come with limitations on the design of the training algorithm. Most importantly, backpropagation cannot be implemented on those. We propose a novel neuromorphic algorithm, the \\textit{Spiking Forward Direct Feedback Alignment} (SFDFA) algorithm, an adaption of \\textit{Forward Direct Feedback Alignment} to train SNNs. SFDFA estimates the weights between output and hidden neurons as feedback connections. The main contribution of this paper is to describe how exact local gradients of spikes can be computed in an online manner while taking into account the intra-neuron dependencies between post-synaptic spikes and derive a dynamical system for neuromorphic hardware compatibility. We compare the SFDFA algorithm with a number of competitor algorithms and show that the proposed algorithm achieves higher performance and convergence rates.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08805",
        "abstract url": "https://arxiv.org/abs/2403.08805",
        "title": "Properties of Shannon and R\u00e9nyi entropies of the Poisson distribution as the functions of intensity parameter",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider two types of entropy, namely, Shannon and R\u00e9nyi entropies of the Poisson distribution, and establish their properties as the functions of intensity parameter. More precisely, we prove that both entropies increase with intensity. While for Shannon entropy the proof is comparatively simple, for R\u00e9nyi entropy, which depends on additional parameter $\u03b1>0$, we can characterize it as nontrivial. The proof is based on application of Karamata's inequality to the terms of Poisson distribution.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "23 pages, 8 figures"
    },
    {
        "paper id": "2403.08807",
        "abstract url": "https://arxiv.org/abs/2403.08807",
        "title": "Effective anytime algorithm for multiobjective combinatorial optimization problems",
        "rating": -10,
        "keywords": [],
        "abstract": "In multiobjective optimization, the result of an optimization algorithm is a set of efficient solutions from which the decision maker selects one. It is common that not all the efficient solutions can be computed in a short time and the search algorithm has to be stopped prematurely to analyze the solutions found so far. A set of efficient solutions that are well-spread in the objective space is preferred to provide the decision maker with a great variety of solutions. However, just a few exact algorithms in the literature exist with the ability to provide such a well-spread set of solutions at any moment: we call them anytime algorithms. We propose a new exact anytime algorithm for multiobjective combinatorial optimization combining three novel ideas to enhance the anytime behavior. We compare the proposed algorithm with those in the state-of-the-art for anytime multiobjective combinatorial optimization using a set of 480 instances from different well-known benchmarks and four different performance measures: the overall non-dominated vector generation ratio, the hypervolume, the general spread and the additive epsilon indicator. A comprehensive experimental study reveals that our proposal outperforms the previous algorithms in most of the instances.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2403.18831",
        "abstract url": "https://arxiv.org/abs/2403.18831",
        "title": "DeepTraderX: Challenging Conventional Trading Strategies with Deep Learning in Multi-Threaded Market Simulations",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we introduce DeepTraderX (DTX), a simple Deep Learning-based trader, and present results that demonstrate its performance in a multi-threaded market simulation. In a total of about 500 simulated market days, DTX has learned solely by watching the prices that other strategies produce. By doing this, it has successfully created a mapping from market data to quotes, either bid or ask orders, to place for an asset. Trained on historical Level-2 market data, i.e., the Limit Order Book (LOB) for specific tradable assets, DTX processes the market state $S$ at each timestep $T$ to determine a price $P$ for market orders. The market data used in both training and testing was generated from unique market schedules based on real historic stock market data. DTX was tested extensively against the best strategies in the literature, with its results validated by statistical analysis. Our findings underscore DTX's capability to rival, and in many instances, surpass, the performance of public-domain traders, including those that outclass human traders, emphasising the efficiency of simple models, as this is required to succeed in intricate multi-threaded simulations. This highlights the potential of leveraging \"black-box\" Deep Learning systems to create more efficient financial markets.",
        "subjects": [
            "q-fin.TR"
        ],
        "comment": "11 pages, 9 png figures, uses apalike.sty and SCITEPRESS.sty, to be published in the proceedings of ICAART 2024"
    },
    {
        "paper id": "2403.18832",
        "abstract url": "https://arxiv.org/abs/2403.18832",
        "title": "Rationale Dataset and Analysis for the Commit Messages of the Linux Kernel Out-of-Memory Killer",
        "rating": -10,
        "keywords": [],
        "abstract": "Code commit messages can contain useful information on why a developer has made a change. However, the presence and structure of rationale in real-world code commit messages is not well studied. Here, we detail the creation of a labelled dataset to analyze the code commit messages of the Linux Kernel Out-Of-Memory Killer component. We study aspects of rationale information, such as presence, temporal evolution, and structure. We find that 98.9% of commits in our dataset contain sentences with rationale information, and that experienced developers report rationale in about 60% of the sentences in their commits. We report on the challenges we faced and provide examples for our labelling.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.07207",
        "abstract url": "https://arxiv.org/abs/2404.07207",
        "title": "Evolving Military Broadband Wireless Communication Systems: WiMAX, LTE and WLAN",
        "rating": -10,
        "keywords": [],
        "abstract": "Emerging technologies for mobile broadband wireless are being considered as a Commercial Off-The-Shelf solution to cover the operational requirements of the future warfare. The capabilities of these technologies are being enhanced to meet the growing market demands on performance. In this context, several standards such as WiMAX, LTE or WLAN are introducing themselves as strong candidates to fulfill these requirements. This paper presents an innovative scenario-based approach to develop a Military Broadband Wireless Communication System (MBWCS). Its main objective is to analyze how similar a military MBWCS can be to the identified civil standards, taking operational and high level technical requirements into account. This specification will be used for analyzing the applicability and the modifications of each of the standards layers individually. Proving the feasibility and aptitude of each standard provides strong foundations to address a MBWCS in the most efficient way.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "This is an ACCEPTED VERSION of the following published document Proc. of 2016 International Conference on Military Communications and Information Systems (ICMCIS), Brussels, Belgium, 2016, pp. 1-8"
    }
]