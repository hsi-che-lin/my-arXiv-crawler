[
    {
        "paper id": "2402.04655",
        "abstract url": "https://arxiv.org/abs/2402.04655",
        "title": "Open-Vocabulary Calibration for Vision-Language Models",
        "rating": 2.5,
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Vision-language models (VLMs) have emerged as formidable tools, showing their strong capability in handling various open-vocabulary tasks in image recognition, text-driven visual content generation, and visual chatbots, to name a few. In recent years, considerable efforts and resources have been devoted to adaptation methods for improving downstream performance of VLMs, particularly on parameter-efficient fine-tuning methods like prompt learning. However, a crucial aspect that has been largely overlooked is the confidence calibration problem in fine-tuned VLMs, which could greatly reduce reliability when deploying such models in the real world. This paper bridges the gap by systematically investigating the confidence calibration problem in the context of prompt learning and reveals that existing calibration methods are insufficient to address the problem, especially in the open-vocabulary setting. To solve the problem, we present a simple and effective approach called Distance-Aware Calibration (DAC), which is based on scaling the temperature using as guidance the distance between predicted text labels and base classes. The experiments with 7 distinct prompt learning methods applied across 11 diverse downstream datasets demonstrate the effectiveness of DAC, which achieves high efficacy without sacrificing the inference speed.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2402.04630",
        "abstract url": "https://arxiv.org/abs/2402.04630",
        "title": "LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors",
        "rating": 2,
        "keywords": [
            [
                "vision language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Inspired by the outstanding zero-shot capability of vision language models (VLMs) in image classification tasks, open-vocabulary object detection has attracted increasing interest by distilling the broad VLM knowledge into detector training. However, most existing open-vocabulary detectors learn by aligning region embeddings with categorical labels (e.g., bicycle) only, disregarding the capability of VLMs on aligning visual embeddings with fine-grained text description of object parts (e.g., pedals and bells). This paper presents DVDet, a Descriptor-Enhanced Open Vocabulary Detector that introduces conditional context prompts and hierarchical textual descriptors that enable precise region-text alignment as well as open-vocabulary detection training in general. Specifically, the conditional context prompt transforms regional embeddings into image-like representations that can be directly integrated into general open vocabulary detection training. In addition, we introduce large language models as an interactive and implicit knowledge repository which enables iterative mining and refining visually oriented textual descriptors for precise region-text alignment. Extensive experiments over multiple large-scale benchmarks show that DVDet outperforms the state-of-the-art consistently by large margins.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04788",
        "abstract url": "https://arxiv.org/abs/2402.04788",
        "title": "MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark",
        "rating": 2,
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have gained significant attention recently, showing remarkable potential in artificial general intelligence. However, assessing the utility of MLLMs presents considerable challenges, primarily due to the absence multimodal benchmarks that align with human preferences. Inspired by LLM-as-a-Judge in LLMs, this paper introduces a novel benchmark, termed MLLM-as-a-Judge, to assess the ability of MLLMs in assisting judges including three distinct tasks: Scoring Evaluation, Pair Comparison, and Batch Ranking. Our study reveals that, while MLLMs demonstrate remarkable human-like discernment in Pair Comparisons, there is a significant divergence from human preferences in Scoring Evaluation and Batch Ranking tasks. Furthermore, MLLMs still face challenges in judgment, including diverse biases, hallucinatory responses, and inconsistencies, even for advanced models such as GPT-4V. These findings emphasize the pressing need for enhancements and further research efforts regarding MLLMs as fully reliable evaluators. Code and dataset are available at https://github.com/Dongping-Chen/MLLM-as-a-Judge.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05374",
        "abstract url": "https://arxiv.org/abs/2402.05374",
        "title": "CIC: A framework for Culturally-aware Image Captioning",
        "rating": 2,
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image Captioning generates descriptive sentences from images using Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved greatly. However, current methods lack the generation of detailed descriptive captions for the cultural elements depicted in the images, such as the traditional clothing worn by people from Asian cultural groups. In this paper, we propose a new framework, \\textbf{Culturally-aware Image Captioning (CIC)}, that generates captions and describes cultural elements extracted from cultural visual elements in images representing cultures. Inspired by methods combining visual modality and Large Language Models (LLMs) through appropriate prompts, our framework (1) generates questions based on cultural categories from images, (2) extracts cultural visual elements from Visual Question Answering (VQA) using generated questions, and (3) generates culturally-aware captions using LLMs with the prompts. Our human evaluation conducted on 45 participants from 4 different cultural groups with a high understanding of the corresponding culture shows that our proposed framework generates more culturally descriptive captions when compared to the image captioning baseline based on VLPs. Our code and dataset will be made publicly available upon acceptance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in IJCAI 2024"
    },
    {
        "paper id": "2402.04632",
        "abstract url": "https://arxiv.org/abs/2402.04632",
        "title": "GSN: Generalisable Segmentation in Neural Radiance Field",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Traditional Radiance Field (RF) representations capture details of a specific scene and must be trained afresh on each scene. Semantic feature fields have been added to RFs to facilitate several segmentation tasks. Generalised RF representations learn the principles of view interpolation. A generalised RF can render new views of an unknown and untrained scene, given a few views. We present a way to distil feature fields into the generalised GNT representation. Our GSN representation generates new views of unseen scenes on the fly along with consistent, per-pixel semantic features. This enables multi-view segmentation of arbitrary new scenes. We show different semantic features being distilled into generalised RFs. Our multi-view segmentation results are on par with methods that use traditional RFs. GSN closes the gap between standard and generalisable RF methods significantly. Project Page: https://vinayak-vg.github.io/GSN/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at the Main Technical Track of AAAI 2024"
    },
    {
        "paper id": "2402.04764",
        "abstract url": "https://arxiv.org/abs/2402.04764",
        "title": "Code as Reward: Empowering Reinforcement Learning with VLMs",
        "rating": 1.5,
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Pre-trained Vision-Language Models (VLMs) are able to understand visual concepts, describe and decompose complex tasks into sub-tasks, and provide feedback on task completion. In this paper, we aim to leverage these capabilities to support the training of reinforcement learning (RL) agents. In principle, VLMs are well suited for this purpose, as they can naturally analyze image-based observations and provide feedback (reward) on learning progress. However, inference in VLMs is computationally expensive, so querying them frequently to compute rewards would significantly slowdown the training of an RL agent. To address this challenge, we propose a framework named Code as Reward (VLM-CaR). VLM-CaR produces dense reward functions from VLMs through code generation, thereby significantly reducing the computational burden of querying the VLM directly. We show that the dense rewards generated through our approach are very accurate across a diverse set of discrete and continuous environments, and can be more effective in training RL policies than the original sparse environment rewards.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04824",
        "abstract url": "https://arxiv.org/abs/2402.04824",
        "title": "Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "workshop",
                "AAAI"
            ]
        ],
        "abstract": "Albrecht and Stone (2018) state that modeling of changing behaviors remains an open problem \"due to the essentially unconstrained nature of what other agents may do\". In this work we evaluate the adaptability of neural artificial agents towards assumed partner behaviors in a collaborative reference game. In this game success is achieved when a knowledgeable Guide can verbally lead a Follower to the selection of a specific puzzle piece among several distractors. We frame this language grounding and coordination task as a reinforcement learning problem and measure to which extent a common reinforcement training algorithm (PPO) is able to produce neural agents (the Guides) that perform well with various heuristic Follower behaviors that vary along the dimensions of confidence and autonomy. We experiment with a learning signal that in addition to the goal condition also respects an assumed communicative effort. Our results indicate that this novel ingredient leads to communicative strategies that are less verbose (staying silent in some of the steps) and that with respect to that the Guide's strategies indeed adapt to the partner's level of confidence and autonomy.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work presented at the \"Cooperative Multi-Agent Systems Decision-making and Learning\" workshop (AAAI'24)"
    },
    {
        "paper id": "2402.04902",
        "abstract url": "https://arxiv.org/abs/2402.04902",
        "title": "L4Q: Parameter Efficient Quantization-Aware Training on Large Language Models via LoRA-wise LSQ",
        "rating": 1.5,
        "keywords": [
            [
                "Parameter Efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Post-training quantization (PTQ) and quantization-aware training (QAT) methods are gaining popularity in mitigating the high memory and computational costs associated with Large Language Models (LLMs). In resource-constrained scenarios, PTQ, with its reduced training overhead, is often preferred over QAT, despite the latter's potential for higher accuracy. Meanwhile, parameter-efficient fine-tuning (PEFT) methods like low-rank adaptation (LoRA) have been introduced, and recent efforts have explored quantization-aware PEFT techniques. However, these approaches may lack generality due to their reliance on the pre-quantized model's configuration. Their effectiveness may be compromised by non-linearly quantized or mixed-precision weights, and the retraining of specific quantization parameters might impede optimal performance. To address these challenges, we propose L4Q, an algorithm for parameter-efficient quantization-aware training. L4Q leverages LoRA-wise learned quantization step size for LLMs, aiming to enhance generality. The simultaneous quantization-and-fine-tuning process of L4Q is applicable to high-precision models, yielding linearly quantized weights with superior accuracy. Our experiments, conducted on the LLaMA and LLaMA2 model families using an instructional dataset, showcase L4Q's capabilities in language comprehension and few-shot in-context learning, achieving sub-4-bit precision while maintaining comparable training times to applying PEFT on a quantized model.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 2 figures"
    },
    {
        "paper id": "2402.04911",
        "abstract url": "https://arxiv.org/abs/2402.04911",
        "title": "What Values Do ImageNet-trained Classifiers Enact?",
        "rating": 1.5,
        "keywords": [
            [
                "social bias"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "We identify \"values\" as actions that classifiers take that speak to open questions of significant social concern. Investigating a classifier's values builds on studies of social bias that uncover how classifiers participate in social processes beyond their creators' forethought. In our case, this participation involves what counts as nutritious, what it means to be modest, and more. Unlike AI social bias, however, a classifier's values are not necessarily morally loathsome. Attending to image classifiers' values can facilitate public debate and introspection about the future of society. To substantiate these claims, we report on an extensive examination of both ImageNet training/validation data and ImageNet-trained classifiers with custom testing data. We identify perceptual decision boundaries in 118 categories that address open questions in society, and through quantitative testing of rival datasets we find that ImageNet-trained classifiers enact at least 7 values through their perceptual decisions. To contextualize these results, we develop a conceptual framework that integrates values, social bias, and accuracy, and we describe a rhetorical method for identifying how context affects the values that a classifier enacts. We also discover that classifier performance does not straightforwardly reflect the proportions of subgroups in a training set. Our findings bring a rich sense of the social world to ML researchers that can be applied to other domains beyond computer vision.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Submitted to FAT [FAccT] 2020, 12 pages, 4 figures, 3 appendices"
    },
    {
        "paper id": "2402.05147",
        "abstract url": "https://arxiv.org/abs/2402.05147",
        "title": "ApiQ: Finetuning of 2-Bit Quantized Large Language Model",
        "rating": 1.5,
        "keywords": [
            [
                "efficient finetuning",
                "GPU memory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Memory-efficient finetuning of large language models (LLMs) has recently attracted huge attention with the increasing size of LLMs, primarily due to the constraints posed by GPU memory limitations and the comparable results of these methods with full finetuning. Despite the advancements, current strategies for memory-efficient finetuning, such as QLoRA, exhibit inconsistent performance across diverse bit-width quantizations and multifaceted tasks. This inconsistency largely stems from the detrimental impact of the quantization process on preserved knowledge, leading to catastrophic forgetting and undermining the utilization of pretrained models for finetuning purposes. In this work, we introduce a novel quantization framework named ApiQ, designed to restore the lost information from quantization by concurrently initializing LoRA components and quantizing the weights of LLMs. This approach ensures the maintenance of the original LLM's activation precision while mitigating the error propagation from shallower into deeper layers. Through comprehensive evaluations conducted on a spectrum of language tasks with various models, ApiQ demonstrably minimizes activation error during quantization. Consequently, it consistently achieves superior finetuning outcomes across various bit-widths of quantization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "compared to v0: new histogram formats for better reading"
    },
    {
        "paper id": "2402.05158",
        "abstract url": "https://arxiv.org/abs/2402.05158",
        "title": "Enhancement of Bengali OCR by Specialized Models and Advanced Techniques for Diverse Document Types",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "This research paper presents a unique Bengali OCR system with some capabilities. The system excels in reconstructing document layouts while preserving structure, alignment, and images. It incorporates advanced image and signature detection for accurate extraction. Specialized models for word segmentation cater to diverse document types, including computer-composed, letterpress, typewriter, and handwritten documents. The system handles static and dynamic handwritten inputs, recognizing various writing styles. Furthermore, it has the ability to recognize compound characters in Bengali. Extensive data collection efforts provide a diverse corpus, while advanced technical components optimize character and word recognition. Additional contributions include image, logo, signature and table recognition, perspective correction, layout reconstruction, and a queuing module for efficient and scalable processing. The system demonstrates outstanding performance in efficient and accurate text extraction and analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 7 figures, 4 table Link of the paper https://openaccess.thecvf.com/content/WACV2024W/WVLL/html/Rabby_Enhancement_of_Bengali_OCR_by_Specialized_Models_and_Advanced_Techniques_WACVW_2024_paper.html"
    },
    {
        "paper id": "2402.05382",
        "abstract url": "https://arxiv.org/abs/2402.05382",
        "title": "Task-customized Masked AutoEncoder via Mixture of Cluster-conditional Experts",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Masked Autoencoder~(MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training. However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result in negative transfer, impeding MAE's scalability. To address this issue, we propose a novel MAE-based pre-training paradigm, Mixture of Cluster-conditional Experts (MoCE), which can be trained once but provides customized pre-training models for diverse downstream tasks. Different from the mixture of experts (MoE), our MoCE trains each expert only with semantically relevant images by using cluster-conditional gates. Thus, each downstream task can be allocated to its customized model pre-trained with data most similar to the downstream data. Experiments on a collection of 11 downstream tasks show that MoCE outperforms the vanilla MAE by 2.45\\% on average. It also obtains new state-of-the-art self-supervised learning results on detection and segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2023"
    },
    {
        "paper id": "2402.04588",
        "abstract url": "https://arxiv.org/abs/2402.04588",
        "title": "UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Open-source large language models (LLMs) have gained significant strength across diverse fields. Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual abilities. In this work, we therefore construct an open-source multilingual supervised fine-tuning dataset. Different from previous works that simply translate English instructions, we consider both the language-specific and language-agnostic abilities of LLMs. Firstly, we introduce a knowledge-grounded data augmentation approach to elicit more language-specific knowledge of LLMs, improving their ability to serve users from different countries. Moreover, we find modern LLMs possess strong cross-lingual transfer capabilities, thus repeatedly learning identical content in various languages is not necessary. Consequently, we can substantially prune the language-agnostic supervised fine-tuning (SFT) data without any performance degradation, making multilingual SFT more efficient. The resulting UltraLink dataset comprises approximately 1 million samples across five languages (i.e., En, Zh, Ru, Fr, Es), and the proposed data construction method can be easily extended to other languages. UltraLink-LM, which is trained on UltraLink, outperforms several representative baselines across many tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in Progress"
    },
    {
        "paper id": "2402.04609",
        "abstract url": "https://arxiv.org/abs/2402.04609",
        "title": "Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Post-editing has proven effective in improving the quality of text generated by large language models (LLMs) such as GPT-3.5 or GPT-4, particularly when direct updating of their parameters to enhance text quality is infeasible or expensive. However, relying solely on smaller language models for post-editing can limit the LLMs' ability to generalize across domains. Moreover, the editing strategies in these methods are not optimally designed for text-generation tasks. To address these limitations, we propose a neural programmer-interpreter approach that preserves the domain generalization ability of LLMs when editing their output. The editing actions in this framework are specifically devised for text generation. Extensive experiments demonstrate that the programmer-interpreter significantly enhances GPT-3.5's performance in logical form-to-text conversion and low-resource machine translation, surpassing other state-of-the-art (SOTA) LLM post-editing methods in cross-domain settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL 2024 (findings), short paper, 5 pages"
    },
    {
        "paper id": "2402.04614",
        "abstract url": "https://arxiv.org/abs/2402.04614",
        "title": "Faithfulness vs. Plausibility: On the (Un)Reliability of Explanations from Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are deployed as powerful tools for several natural language processing (NLP) applications. Recent works show that modern LLMs can generate self-explanations (SEs), which elicit their intermediate reasoning steps for explaining their behavior. Self-explanations have seen widespread adoption owing to their conversational and plausible nature. However, there is little to no understanding of their faithfulness. In this work, we discuss the dichotomy between faithfulness and plausibility in SEs generated by LLMs. We argue that while LLMs are adept at generating plausible explanations -- seemingly logical and coherent to human users -- these explanations do not necessarily align with the reasoning processes of the LLMs, raising concerns about their faithfulness. We highlight that the current trend towards increasing the plausibility of explanations, primarily driven by the demand for user-friendly interfaces, may come at the cost of diminishing their faithfulness. We assert that the faithfulness of explanations is critical in LLMs employed for high-stakes decision-making. Moreover, we emphasize the need for a systematic characterization of faithfulness-plausibility requirements of different real-world applications and ensure explanations meet those needs. While there are several approaches to improving plausibility, improving faithfulness is an open challenge. We call upon the community to develop novel methods to enhance the faithfulness of self explanations thereby enabling transparent deployment of LLMs in diverse high-stakes settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04615",
        "abstract url": "https://arxiv.org/abs/2402.04615",
        "title": "ScreenAI: A Vision-Language Model for UI and Infographics Understanding",
        "rating": 1,
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Screen user interfaces (UIs) and infographics, sharing similar visual language and design principles, play important roles in human communication and human-machine interaction. We introduce ScreenAI, a vision-language model that specializes in UI and infographics understanding. Our model improves upon the PaLI architecture with the flexible patching strategy of pix2struct and is trained on a unique mixture of datasets. At the heart of this mixture is a novel screen annotation task in which the model has to identify the type and location of UI elements. We use these text annotations to describe screens to Large Language Models and automatically generate question-answering (QA), UI navigation, and summarization training datasets at scale. We run ablation studies to demonstrate the impact of these design choices. At only 5B parameters, ScreenAI achieves new state-of-the-artresults on UI- and infographics-based tasks (Multi-page DocVQA, WebSRC, MoTIF and Widget Captioning), and new best-in-class performance on others (Chart QA, DocVQA, and InfographicVQA) compared to models of similar size. Finally, we release three new datasets: one focused on the screen annotation task and two others focused on question answering.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Revision notes: 1) In Appendix I, added dataset location for ScreenQA Short in Appendix I. 2) In Table 4, updated evaluation numbers for Screen Annotation and Complex Screen QA benchmarks as the datasets are updated. 3) Updated Figure 4 to reflect the changes in evaluation numbers described in 2). 4) Minor revisions in other places"
    },
    {
        "paper id": "2402.04616",
        "abstract url": "https://arxiv.org/abs/2402.04616",
        "title": "TinyLLM: Learning a Small Student from Multiple Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Transferring the reasoning capability from stronger large language models (LLMs) to smaller ones has been quite appealing, as smaller LLMs are more flexible to deploy with less expense. Among the existing solutions, knowledge distillation stands out due to its outstanding efficiency and generalization. However, existing methods suffer from several drawbacks, including limited knowledge diversity and the lack of rich contextual information. To solve the problems and facilitate the learning of compact language models, we propose TinyLLM, a new knowledge distillation paradigm to learn a small student LLM from multiple large teacher LLMs. In particular, we encourage the student LLM to not only generate the correct answers but also understand the rationales behind these answers. Given that different LLMs possess diverse reasoning skills, we guide the student model to assimilate knowledge from various teacher LLMs. We further introduce an in-context example generator and a teacher-forcing Chain-of-Thought strategy to ensure that the rationales are accurate and grounded in contextually appropriate scenarios. Extensive experiments on six datasets across two reasoning tasks demonstrate the superiority of our method. Results show that TinyLLM can outperform large teacher LLMs significantly, despite a considerably smaller model size.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04617",
        "abstract url": "https://arxiv.org/abs/2402.04617",
        "title": "InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have emerged as a cornerstone in real-world applications with lengthy streaming inputs, such as LLM-driven agents. However, existing LLMs, pre-trained on sequences with restricted maximum length, cannot generalize to longer sequences due to the out-of-domain and distraction issues. To alleviate these issues, existing efforts employ sliding attention windows and discard distant tokens to achieve the processing of extremely long sequences. Unfortunately, these approaches inevitably fail to capture long-distance dependencies within sequences to deeply understand semantics. This paper introduces a training-free memory-based method, InfLLM, to unveil the intrinsic ability of LLMs to process streaming long sequences. Specifically, InfLLM stores distant contexts into additional memory units and employs an efficient mechanism to lookup token-relevant units for attention computation. Thereby, InfLLM allows LLMs to efficiently process long sequences while maintaining the ability to capture long-distance dependencies. Without any training, InfLLM enables LLMs pre-trained on sequences of a few thousand tokens to achieve superior performance than competitive baselines continually training these LLMs on long sequences. Even when the sequence length is scaled to $1,024$K, InfLLM still effectively captures long-distance dependencies.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04618",
        "abstract url": "https://arxiv.org/abs/2402.04618",
        "title": "Multi-Scale Semantic Segmentation with Modified MBConv Blocks",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, MBConv blocks, initially designed for efficiency in resource-limited settings and later adapted for cutting-edge image classification performances, have demonstrated significant potential in image classification tasks. Despite their success, their application in semantic segmentation has remained relatively unexplored. This paper introduces a novel adaptation of MBConv blocks specifically tailored for semantic segmentation. Our modification stems from the insight that semantic segmentation requires the extraction of more detailed spatial information than image classification. We argue that to effectively perform multi-scale semantic segmentation, each branch of a U-Net architecture, regardless of its resolution, should possess equivalent segmentation capabilities. By implementing these changes, our approach achieves impressive mean Intersection over Union (IoU) scores of 84.5% and 84.0% on the Cityscapes test and validation datasets, respectively, demonstrating the efficacy of our proposed modifications in enhancing semantic segmentation performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04636",
        "abstract url": "https://arxiv.org/abs/2402.04636",
        "title": "TransLLaMa: LLM-based Simultaneous Translation System",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Decoder-only large language models (LLMs) have recently demonstrated impressive capabilities in text generation and reasoning. Nonetheless, they have limited applications in simultaneous machine translation (SiMT), currently dominated by encoder-decoder transformers. This study demonstrates that, after fine-tuning on a small dataset comprising causally aligned source and target sentence pairs, a pre-trained open-source LLM can control input segmentation directly by generating a special \"wait\" token. This obviates the need for a separate policy and enables the LLM to perform English-German and English-Russian SiMT tasks with BLEU scores that are comparable to those of specific state-of-the-art baselines. We also evaluated closed-source models such as GPT-4, which displayed encouraging results in performing the SiMT task without prior training (zero-shot), indicating a promising avenue for enhancing future SiMT systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04677",
        "abstract url": "https://arxiv.org/abs/2402.04677",
        "title": "Source Identification in Abstractive Summarization",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Neural abstractive summarization models make summaries in an end-to-end manner, and little is known about how the source information is actually converted into summaries. In this paper, we define input sentences that contain essential information in the generated summary as $\\textit{source sentences}$ and study how abstractive summaries are made by analyzing the source sentences. To this end, we annotate source sentences for reference summaries and system summaries generated by PEGASUS on document-summary pairs sampled from the CNN/DailyMail and XSum datasets. We also formulate automatic source sentence detection and compare multiple methods to establish a strong baseline for the task. Experimental results show that the perplexity-based method performs well in highly abstractive settings, while similarity-based methods perform robustly in relatively extractive settings. Our code and data are available at https://github.com/suhara/sourcesum.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EACL 2024"
    },
    {
        "paper id": "2402.04678",
        "abstract url": "https://arxiv.org/abs/2402.04678",
        "title": "Large Language Models As Faithful Explainers",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have recently become proficient in addressing complex tasks by utilizing their rich internal knowledge and reasoning ability. Consequently, this complexity hinders traditional input-focused explanation algorithms for explaining the complex decision-making processes of LLMs. Recent advancements have thus emerged for self-explaining their predictions through a single feed-forward inference in a natural language format. However, natural language explanations are often criticized for lack of faithfulness since these explanations may not accurately reflect the decision-making behaviors of the LLMs. In this work, we introduce a generative explanation framework, xLLM, to improve the faithfulness of the explanations provided in natural language formats for LLMs. Specifically, we propose an evaluator to quantify the faithfulness of natural language explanation and enhance the faithfulness by an iterative optimization process of xLLM, with the goal of maximizing the faithfulness scores. Experiments conducted on three NLU datasets demonstrate that xLLM can significantly improve the faithfulness of generated explanations, which are in alignment with the behaviors of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04729",
        "abstract url": "https://arxiv.org/abs/2402.04729",
        "title": "A Video-Aware FEC-Based Unequal Loss Protection System for Video Streaming over RTP",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "A video-aware unequal loss protection (ULP) system for protecting RTP video streaming in bursty packet loss networks is proposed. Considering the relevance of the frame, the state of the channel, and the bitrate constraints of the protection bitstream, our algorithm selects in real time the most suitable frames to be protected through forward error protection (FEC) techniques. It benefits from a wise RTP encapsulation that allows working at a frame level without requiring any further process than that of parsing RTP headers. This makes our system straightforward and fast, perfectly suitable to be included in commercial video streaming servers. Simulation results show how our technique outperforms other proposed ULP schemes.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04739",
        "abstract url": "https://arxiv.org/abs/2402.04739",
        "title": "Application-Layer FEC Scheme Configuration Optimization via Hybrid Simulated Annealing",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "An optimization technique based on an adapted combination of simulated annealing (SA) and tabu search (TS) is presented. This method aims at finding near-optimal unequal error protection (UEP) application-layer FEC code configurations. This approach is intended to smartly protect audio and video transmission over IP networks when hard time restrictions apply. The considered code is a UEP version of the widely-used Pro-MPEG COP3 codes enabling the use of several matrices of dissimilar size and thus of unequal recovery capability. Finding the optimal configuration frequently requires the evaluation of a large solution space. So, to fulfill the imposed constraints, SA is adapted to the specifics of the scenario. In particular, the annealing schedule is conditioned by the real-time restrictions. Furthermore, solution neighborhood structures are determined by a proposed definition of distance between protection configurations, which, jointly with TS, conditions the selection of candidate solutions. Experimental results show a significantly improved performance of the optimization process, which invariably fulfills imposed timing constraints, at the expense of a very low distortion increase, when compared to using exhaustive search. These results allow the use of UEP Pro-MPEG COP3 codes for protecting video and audio transmission, which distinctly outperforms the standard code in a wide range of scenarios.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04762",
        "abstract url": "https://arxiv.org/abs/2402.04762",
        "title": "Color Recognition in Challenging Lighting Environments: CNN Approach",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Light plays a vital role in vision either human or machine vision, the perceived color is always based on the lighting conditions of the surroundings. Researchers are working to enhance the color detection techniques for the application of computer vision. They have implemented proposed several methods using different color detection approaches but still, there is a gap that can be filled. To address this issue, a color detection method, which is based on a Convolutional Neural Network (CNN), is proposed. Firstly, image segmentation is performed using the edge detection segmentation technique to specify the object and then the segmented object is fed to the Convolutional Neural Network trained to detect the color of an object in different lighting conditions. It is experimentally verified that our method can substantially enhance the robustness of color detection in different lighting conditions, and our method performed better results than existing methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04779",
        "abstract url": "https://arxiv.org/abs/2402.04779",
        "title": "StableMask: Refining Causal Masking in Decoder-only Transformer",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The decoder-only Transformer architecture with causal masking and relative position encoding (RPE) has become the de facto choice in language modeling. Despite its exceptional performance across various tasks, we have identified two limitations: First, it requires all attention scores to be non-zero and sum up to 1, even if the current embedding has sufficient self-contained information. This compels the model to assign disproportional excessive attention to specific tokens. Second, RPE-based Transformers are not universal approximators due to their limited capacity at encoding absolute positional information, which limits their application in position-critical tasks. In this work, we propose StableMask: a parameter-free method to address both limitations by refining the causal mask. It introduces pseudo-attention values to balance attention distributions and encodes absolute positional information via a progressively decreasing mask ratio. StableMask's effectiveness is validated both theoretically and empirically, showing significant enhancements in language models with parameter sizes ranging from 71M to 1.4B across diverse datasets and encoding methods. We further show that it naturally supports (1) efficient extrapolation without special tricks such as StreamingLLM and (2) easy integration with existing attention optimization techniques.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2402.04787",
        "abstract url": "https://arxiv.org/abs/2402.04787",
        "title": "A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The self-rationalising capabilities of LLMs are appealing because the generated explanations can give insights into the plausibility of the predictions. However, how faithful the explanations are to the predictions is questionable, raising the need to explore the patterns behind them further. To this end, we propose a hypothesis-driven statistical framework. We use a Bayesian network to implement a hypothesis about how a task (in our example, natural language inference) is solved, and its internal states are translated into natural language with templates. Those explanations are then compared to LLM-generated free-text explanations using automatic and human evaluations. This allows us to judge how similar the LLM's and the Bayesian network's decision processes are. We demonstrate the usage of our framework with an example hypothesis and two realisations in Bayesian networks. The resulting models do not exhibit a strong similarity to GPT-3.5. We discuss the implications of this as well as the framework's potential to approximate LLM decisions better in future work.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04805",
        "abstract url": "https://arxiv.org/abs/2402.04805",
        "title": "Progressive unsupervised domain adaptation for ASR using ensemble models and multi-stage training",
        "rating": 1,
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "In Automatic Speech Recognition (ASR), teacher-student (T/S) training has shown to perform well for domain adaptation with small amount of training data. However, adaption without ground-truth labels is still challenging. A previous study has shown the effectiveness of using ensemble teacher models in T/S training for unsupervised domain adaptation (UDA) but its performance still lags behind compared to the model trained on in-domain data. This paper proposes a method to yield better UDA by training multi-stage students with ensemble teacher models. Initially, multiple teacher models are trained on labelled data from read and meeting domains. These teachers are used to train a student model on unlabelled out-of-domain telephone speech data. To improve the adaptation, subsequent student models are trained sequentially considering previously trained model as their teacher. Experiments are conducted with three teachers trained on AMI, WSJ and LibriSpeech and three stages of students on SwitchBoard data. Results shown on eval00 test set show significant WER improvement with multi-stage training with an absolute gain of 9.8%, 7.7% and 3.3% at each stage.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04823",
        "abstract url": "https://arxiv.org/abs/2402.04823",
        "title": "How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Deep Generative Models (DGMs) have been shown to be powerful tools for generating tabular data, as they have been increasingly able to capture the complex distributions that characterize them. However, to generate realistic synthetic data, it is often not enough to have a good approximation of their distribution, as it also requires compliance with constraints that encode essential background knowledge on the problem at hand. In this paper, we address this limitation and show how DGMs for tabular data can be transformed into Constrained Deep Generative Models (C-DGMs), whose generated samples are guaranteed to be compliant with the given constraints. This is achieved by automatically parsing the constraints and transforming them into a Constraint Layer (CL) seamlessly integrated with the DGM. Our extensive experimental analysis with various DGMs and tasks reveals that standard DGMs often violate constraints, some exceeding $95\\%$ non-compliance, while their corresponding C-DGMs are never non-compliant. Then, we quantitatively demonstrate that, at training time, C-DGMs are able to exploit the background knowledge expressed by the constraints to outperform their standard counterparts with up to $6.5\\%$ improvement in utility and detection. Further, we show how our CL does not necessarily need to be integrated at training time, as it can be also used as a guardrail at inference time, still producing some improvements in the overall performance of the models. Finally, we show that our CL does not hinder the sample generation time of the models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at ICLR 2024"
    },
    {
        "paper id": "2402.04833",
        "abstract url": "https://arxiv.org/abs/2402.04833",
        "title": "Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "There is a consensus that instruction fine-tuning of LLMs requires high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR 2024) are state-of-the-art methods for selecting such high-quality examples, either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show that the extremely simple baseline of selecting the 1,000 instructions with longest responses from standard datasets can consistently outperform these sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining competitive on the OpenLLM benchmarks that test factual knowledge. We demonstrate this for several state-of-the-art LLMs (Llama-2-7B, Llama-2-13B, and Mistral-7B) and datasets (Alpaca-52k and Evol-Instruct-70k). In addition, a lightweight refinement of such long instructions can further improve the abilities of the fine-tuned LLMs, and allows us to obtain the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0 while training on only 1,000 examples and no extra preference data. We also conduct a thorough analysis of our models to ensure that their enhanced performance is not simply due to GPT-4's preference for longer responses, thus ruling out any artificial improvement. In conclusion, our findings suggest that fine-tuning on the longest instructions should be the default baseline for any research on instruction fine-tuning.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint. 25 pages, 24 figures"
    },
    {
        "paper id": "2402.04835",
        "abstract url": "https://arxiv.org/abs/2402.04835",
        "title": "SARI: Simplistic Average and Robust Identification based Noisy Partial Label Learning",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Partial label learning (PLL) is a weakly-supervised learning paradigm where each training instance is paired with a set of candidate labels (partial label), one of which is the true label. Noisy PLL (NPLL) relaxes this constraint by allowing some partial labels to not contain the true label, enhancing the practicality of the problem. Our work centers on NPLL and presents a minimalistic framework called SARI that initially assigns pseudo-labels to images by exploiting the noisy partial labels through a weighted nearest neighbour algorithm. These pseudo-label and image pairs are then used to train a deep neural network classifier with label smoothing and standard regularization techniques. The classifier's features and predictions are subsequently employed to refine and enhance the accuracy of pseudo-labels. SARI combines the strengths of Average Based Strategies (in pseudo labelling) and Identification Based Strategies (in classifier training) from the literature. We perform thorough experiments on seven datasets and compare SARI against nine NPLL and PLL methods from the prior art. SARI achieves state-of-the-art results in almost all studied settings, obtaining substantial gains in fine-grained classification and extreme noise settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 6 tables, 2 figures"
    },
    {
        "paper id": "2402.04838",
        "abstract url": "https://arxiv.org/abs/2402.04838",
        "title": "PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity Recognition",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we aim to reduce generation latency for Named Entity Recognition (NER) with Large Language Models (LLMs). The main cause of high latency in LLMs is the sequential decoding process, which autoregressively generates all labels and mentions for NER, significantly increase the sequence length. To this end, we introduce Parallel Decoding in LLM for NE} (PaDeLLM-NER), a approach that integrates seamlessly into existing generative model frameworks without necessitating additional modules or architectural modifications. PaDeLLM-NER allows for the simultaneous decoding of all mentions, thereby reducing generation latency. Experiments reveal that PaDeLLM-NER significantly increases inference speed that is 1.76 to 10.22 times faster than the autoregressive approach for both English and Chinese. Simultaneously it maintains the quality of predictions as evidenced by the performance that is on par with the state-of-the-art across various datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04841",
        "abstract url": "https://arxiv.org/abs/2402.04841",
        "title": "Data-efficient Large Vision Models through Sequential Autoregression",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Training general-purpose vision models on purely sequential visual data, eschewing linguistic inputs, has heralded a new frontier in visual understanding. These models are intended to not only comprehend but also seamlessly transit to out-of-domain tasks. However, current endeavors are hamstrung by an over-reliance on colossal models, exemplified by models with upwards of 3B parameters, and the necessity for an extensive corpus of visual data, often comprising a staggering 400B tokens. In this paper, we delve into the development of an efficient, autoregression-based vision model, innovatively architected to operate on a limited dataset. We meticulously demonstrate how this model achieves proficiency in a spectrum of visual tasks spanning both high-level and low-level semantic understanding during the testing phase. Our empirical evaluations underscore the model's agility in adapting to various tasks, heralding a significant reduction in the parameter footprint, and a marked decrease in training data requirements, thereby paving the way for more sustainable and accessible advancements in the field of generalist vision models. The code is available at https://github.com/ggjy/DeLVM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2402.04868",
        "abstract url": "https://arxiv.org/abs/2402.04868",
        "title": "Perceptually Equivalent Resolution in Handheld Devices for Streaming Bandwidth Saving",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "We present the description, results, and analysis of the experiments conducted to find the equivalent resolution associated with handheld devices. That is, the resolution from which users stop perceiving quality improvements if better resolutions are presented to them in such devices. Thus, it is the maximum resolution that it is worth considering for generating and delivering video, as long as sequences are not too intensively compressed. Therefore, the detection of the equivalent resolutions allows for notable savings in bandwidth consumption. Subjective assessments have been carried out on fifty subjects using a set of video sequences of very different nature and four handheld devices with a broad range of screen dimensions. The results prove that the equivalent resolution in current handheld devices is 720p as higher resolutions are not valued by users.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04914",
        "abstract url": "https://arxiv.org/abs/2402.04914",
        "title": "Personalized Text Generation with Fine-Grained Linguistic Control",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized. However, most research on controllable text generation focuses on controlling the content or modeling specific high-level/coarse-grained attributes that reflect authors' writing styles, such as formality, domain, or sentiment. In this paper, we focus on controlling fine-grained attributes spanning multiple linguistic dimensions, such as lexical and syntactic attributes. We introduce a novel benchmark to train generative models and evaluate their ability to generate personalized text based on multiple fine-grained linguistic attributes. We systematically investigate the performance of various large language models on our benchmark and draw insights from the factors that impact their performance. We make our code, data, and pretrained models publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04953",
        "abstract url": "https://arxiv.org/abs/2402.04953",
        "title": "4-Dimensional deformation part model for pose estimation using Kalman filter constraints",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The main goal of this article is to analyze the effect on pose estimation accuracy when using a Kalman filter added to 4-dimensional deformation part model partial solutions. The experiments run with two data sets showing that this method improves pose estimation accuracy compared with state-of-the-art methods and that a Kalman filter helps to increase this accuracy.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04957",
        "abstract url": "https://arxiv.org/abs/2402.04957",
        "title": "Reconfidencing LLMs from the Grouping Loss Perspective",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible to generating hallucinated answers in a confident tone. While efforts to elicit and calibrate confidence scores have proven useful, recent findings show that controlling uncertainty must go beyond calibration: predicted scores may deviate significantly from the actual posterior probabilities due to the impact of grouping loss. In this work, we construct a new evaluation dataset derived from a knowledge base to assess confidence scores given to answers of Mistral and LLaMA. Experiments show that they tend to be overconfident. Further, we show that they are more overconfident on some answers than others, \\emph{eg} depending on the nationality of the person in the query. In uncertainty-quantification theory, this is grouping loss. To address this, we propose a solution to reconfidence LLMs, canceling not only calibration but also grouping loss. The LLMs, after the reconfidencing process, indicate improved confidence alignment with the accuracy of their responses.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04967",
        "abstract url": "https://arxiv.org/abs/2402.04967",
        "title": "Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper delves into the formidable challenge of cross-domain generalization in multimodal hate meme detection, presenting compelling findings. We provide enough pieces of evidence supporting the hypothesis that only the textual component of hateful memes enables the existing multimodal classifier to generalize across different domains, while the image component proves highly sensitive to a specific training dataset. The evidence includes demonstrations showing that hate-text classifiers perform similarly to hate-meme classifiers in a zero-shot setting. Simultaneously, the introduction of captions generated from images of memes to the hate-meme classifier worsens performance by an average F1 of 0.02. Through blackbox explanations, we identify a substantial contribution of the text modality (average of 83%), which diminishes with the introduction of meme's image captions (52%). Additionally, our evaluation on a newly created confounder dataset reveals higher performance on text confounders as compared to image confounders with an average $\u0394$F1 of 0.18.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at EACL'2024 Findings"
    },
    {
        "paper id": "2402.05000",
        "abstract url": "https://arxiv.org/abs/2402.05000",
        "title": "Pedagogical Alignment of Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we introduce the novel concept of pedagogically aligned Large Language Models (LLMs) that signifies a transformative shift in the application of LLMs within educational contexts. Rather than providing direct responses to user queries, pedagogically-aligned LLMs function as scaffolding tools, breaking complex problems into manageable subproblems and guiding students towards the final answer through constructive feedback and hints. The objective is to equip learners with problem-solving strategies that deepen their understanding and internalization of the subject matter. Previous research in this field has primarily applied the supervised finetuning approach without framing the objective as an alignment problem, hence not employing reinforcement learning through human feedback (RLHF) methods. This study reinterprets the narrative by viewing the task through the lens of alignment and demonstrates how RLHF methods emerge naturally as a superior alternative for aligning LLM behaviour. Building on this perspective, we propose a novel approach for constructing a reward dataset specifically designed for the pedagogical alignment of LLMs. We apply three state-of-the-art RLHF algorithms and find that they outperform SFT significantly. Our qualitative analyses across model differences and hyperparameter sensitivity further validate the superiority of RLHF over SFT. Also, our study sheds light on the potential of online feedback for enhancing the performance of pedagogically-aligned LLMs, thus providing valuable insights for the advancement of these models in educational settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05008",
        "abstract url": "https://arxiv.org/abs/2402.05008",
        "title": "EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present EfficientViT-SAM, a new family of accelerated segment anything models. We retain SAM's lightweight prompt encoder and mask decoder while replacing the heavy image encoder with EfficientViT. For the training, we begin with the knowledge distillation from the SAM-ViT-H image encoder to EfficientViT. Subsequently, we conduct end-to-end training on the SA-1B dataset. Benefiting from EfficientViT's efficiency and capacity, EfficientViT-SAM delivers 48.9x measured TensorRT speedup on A100 GPU over SAM-ViT-H without sacrificing performance. Our code and pre-trained models are released at https://github.com/mit-han-lab/efficientvit.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "tech report"
    },
    {
        "paper id": "2402.05034",
        "abstract url": "https://arxiv.org/abs/2402.05034",
        "title": "How BERT Speaks Shakespearean English? Evaluating Historical Bias in Contextual Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we explore the idea of analysing the historical bias of contextual language models based on BERT by measuring their adequacy with respect to Early Modern (EME) and Modern (ME) English. In our preliminary experiments, we perform fill-in-the-blank tests with 60 masked sentences (20 EME-specific, 20 ME-specific and 20 generic) and three different models (i.e., BERT Base, MacBERTh, English HLM). We then rate the model predictions according to a 5-point bipolar scale between the two language varieties and derive a weighted score to measure the adequacy of each model to EME and ME varieties of English.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05106",
        "abstract url": "https://arxiv.org/abs/2402.05106",
        "title": "Image captioning for Brazilian Portuguese using GRIT model",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This work presents the early development of a model of image captioning for the Brazilian Portuguese language. We used the GRIT (Grid - and Region-based Image captioning Transformer) model to accomplish this work. GRIT is a Transformer-only neural architecture that effectively utilizes two visual features to generate better captions. The GRIT method emerged as a proposal to be a more efficient way to generate image captioning. In this work, we adapt the GRIT model to be trained in a Brazilian Portuguese dataset to have an image captioning method for the Brazilian Portuguese Language.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2207.09666 by other authors"
    },
    {
        "paper id": "2402.05111",
        "abstract url": "https://arxiv.org/abs/2402.05111",
        "title": "Edu-ConvoKit: An Open-Source Library for Education Conversation Data",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We introduce Edu-ConvoKit, an open-source library designed to handle pre-processing, annotation and analysis of conversation data in education. Resources for analyzing education conversation data are scarce, making the research challenging to perform and therefore hard to access. We address these challenges with Edu-ConvoKit. Edu-ConvoKit is open-source (https://github.com/stanfordnlp/edu-convokit ), pip-installable (https://pypi.org/project/edu-convokit/ ), with comprehensive documentation (https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is available at: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additional resources, such as Colab applications of Edu-ConvoKit to three diverse education datasets and a repository of Edu-ConvoKit related papers, that can be found in our GitHub repository.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "https://github.com/stanfordnlp/edu-convokit https://edu-convokit.readthedocs.io/en/latest/"
    },
    {
        "paper id": "2402.05201",
        "abstract url": "https://arxiv.org/abs/2402.05201",
        "title": "The Effect of Sampling Temperature on Problem Solving in Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then, we used four popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.0. Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature in the range 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks. In addition, these results appear to hold regardless of the LLM, the prompt-engineering technique, or the problem domain. All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05282",
        "abstract url": "https://arxiv.org/abs/2402.05282",
        "title": "TreeForm: End-to-end Annotation and Evaluation for Form Document Parsing",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Visually Rich Form Understanding (VRFU) poses a complex research problem due to the documents' highly structured nature and yet highly variable style and content. Current annotation schemes decompose form understanding and omit key hierarchical structure, making development and evaluation of end-to-end models difficult. In this paper, we propose a novel F1 metric to evaluate form parsers and describe a new content-agnostic, tree-based annotation scheme for VRFU: TreeForm. We provide methods to convert previous annotation schemes into TreeForm structures and evaluate TreeForm predictions using a modified version of the normalized tree-edit distance. We present initial baselines for our end-to-end performance metric and the TreeForm edit distance, averaged over the FUNSD and XFUND datasets, of 61.5 and 26.4 respectively. We hope that TreeForm encourages deeper research in annotating, modeling, and evaluating the complexities of form-like documents.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05301",
        "abstract url": "https://arxiv.org/abs/2402.05301",
        "title": "BIKED++: A Multimodal Dataset of 1.4 Million Bicycle Image and Parametric CAD Designs",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a public dataset of 1.4 million procedurally-generated bicycle designs represented parametrically, as JSON files, and as rasterized images. The dataset is created through the use of a rendering engine which harnesses the BikeCAD software to generate vector graphics from parametric designs. This rendering engine is discussed in the paper and also released publicly alongside the dataset. Though this dataset has numerous applications, a principal motivation is the need to train cross-modal predictive models between parametric and image-based design representations. For example, we demonstrate that a predictive model can be trained to accurately estimate Contrastive Language-Image Pretraining (CLIP) embeddings from a parametric representation directly. This allows similarity relations to be established between parametric bicycle designs and text strings or reference images. Trained predictive models are also made public. The dataset joins the BIKED dataset family which includes thousands of mixed-representation human-designed bicycle models and several datasets quantifying design performance. The code and dataset can be found at: https://github.com/Lyleregenwetter/BIKED_multimodal/tree/main",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05310",
        "abstract url": "https://arxiv.org/abs/2402.05310",
        "title": "Dual-disentangled Deep Multiple Clustering",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multiple clustering has gathered significant attention in recent years due to its potential to reveal multiple hidden structures of the data from different perspectives. Most of multiple clustering methods first derive feature representations by controlling the dissimilarity among them, subsequently employing traditional clustering methods (e.g., k-means) to achieve the final multiple clustering outcomes. However, the learned feature representations can exhibit a weak relevance to the ultimate goal of distinct clustering. Moreover, these features are often not explicitly learned for the purpose of clustering. Therefore, in this paper, we propose a novel Dual-Disentangled deep Multiple Clustering method named DDMC by learning disentangled representations. Specifically, DDMC is achieved by a variational Expectation-Maximization (EM) framework. In the E-step, the disentanglement learning module employs coarse-grained and fine-grained disentangled representations to obtain a more diverse set of latent factors from the data. In the M-step, the cluster assignment module utilizes a cluster objective function to augment the effectiveness of the cluster output. Our extensive experiments demonstrate that DDMC consistently outperforms state-of-the-art methods across seven commonly used tasks. Our code is available at https://github.com/Alexander-Yao/DDMC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by SDM'24. Project page: https://github.com/Alexander-Yao/DDMC"
    },
    {
        "paper id": "2402.05349",
        "abstract url": "https://arxiv.org/abs/2402.05349",
        "title": "Scrapping The Web For Early Wildfire Detection",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Early wildfire detection is of the utmost importance to enable rapid response efforts, and thus minimize the negative impacts of wildfire spreads. To this end, we present \\Pyro, a web-scraping-based dataset composed of videos of wildfires from a network of cameras that were enhanced with manual bounding-box-level annotations. Our dataset was filtered based on a strategy to improve the quality and diversity of the data, reducing the final data to a set of 10,000 images. We ran experiments using a state-of-the-art object detection model and found out that the proposed dataset is challenging and its use in concordance with other public dataset helps to reach higher results overall. We will make our code and data publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Preprint of ongoing work"
    },
    {
        "paper id": "2402.05376",
        "abstract url": "https://arxiv.org/abs/2402.05376",
        "title": "Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms in Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks and exhibited impressive reasoning abilities by applying zero-shot Chain-of-Thought (CoT) prompting. However, due to the evolving nature of sentence prefixes during the pre-training phase, existing zero-shot CoT prompting methods that employ identical CoT prompting across all task instances may not be optimal. In this paper, we introduce a novel zero-shot prompting method that leverages evolutionary algorithms to generate diverse promptings for LLMs dynamically. Our approach involves initializing two CoT promptings, performing evolutionary operations based on LLMs to create a varied set, and utilizing the LLMs to select a suitable CoT prompting for a given problem. Additionally, a rewriting operation, guided by the selected CoT prompting, enhances the understanding of the LLMs about the problem. Extensive experiments conducted across ten reasoning datasets demonstrate the superior performance of our proposed method compared to current zero-shot CoT prompting methods on GPT-3.5-turbo and GPT-4. Moreover, in-depth analytical experiments underscore the adaptability and effectiveness of our method in various reasoning tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "17 pages, 5 figures, 16 tables"
    },
    {
        "paper id": "2402.05394",
        "abstract url": "https://arxiv.org/abs/2402.05394",
        "title": "Enhancing Zero-shot Counting via Language-guided Exemplar Learning",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, Class-Agnostic Counting (CAC) problem has garnered increasing attention owing to its intriguing generality and superior efficiency compared to Category-Specific Counting (CSC). This paper proposes a novel ExpressCount to enhance zero-shot object counting by delving deeply into language-guided exemplar learning. Specifically, the ExpressCount is comprised of an innovative Language-oriented Exemplar Perceptron and a downstream visual Zero-shot Counting pipeline. Thereinto, the perceptron hammers at exploiting accurate exemplar cues from collaborative language-vision signals by inheriting rich semantic priors from the prevailing pre-trained Large Language Models (LLMs), whereas the counting pipeline excels in mining fine-grained features through dual-branch and cross-attention schemes, contributing to the high-quality similarity learning. Apart from building a bridge between the LLM in vogue and the visual counting tasks, expression-guided exemplar estimation significantly advances zero-shot learning capabilities for counting instances with arbitrary classes. Moreover, devising a FSC-147-Express with annotations of meticulous linguistic expressions pioneers a new venue for developing and validating language-based counting models. Extensive experiments demonstrate the state-of-the-art performance of our ExpressCount, even showcasing the accuracy on par with partial CSC models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05398",
        "abstract url": "https://arxiv.org/abs/2402.05398",
        "title": "On the Effect of Image Resolution on Semantic Segmentation",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "High-resolution semantic segmentation requires substantial computational resources. Traditional approaches in the field typically downscale the input images before processing and then upscale the low-resolution outputs back to their original dimensions. While this strategy effectively identifies broad regions, it often misses finer details. In this study, we demonstrate that a streamlined model capable of directly producing high-resolution segmentations can match the performance of more complex systems that generate lower-resolution results. By simplifying the network architecture, we enable the processing of images at their native resolution. Our approach leverages a bottom-up information propagation technique across various scales, which we have empirically shown to enhance segmentation accuracy. We have rigorously tested our method using leading-edge semantic segmentation datasets. Specifically, for the Cityscapes dataset, we further boost accuracy by applying the Noisy Student Training technique.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2209.08667 by other authors"
    },
    {
        "paper id": "2402.05403",
        "abstract url": "https://arxiv.org/abs/2402.05403",
        "title": "In-Context Principle Learning from Mistakes",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In-context learning (ICL, also known as few-shot prompting) has been the standard method of adapting LLMs to downstream tasks, by learning from a few input-output examples. Nonetheless, all ICL-based approaches only learn from correct input-output pairs. In this paper, we revisit this paradigm, by learning more from the few given input-output examples. We introduce Learning Principles (LEAP): First, we intentionally induce the model to make mistakes on these few examples; then we reflect on these mistakes, and learn explicit task-specific \"principles\" from them, which help solve similar problems and avoid common mistakes; finally, we prompt the model to answer unseen test questions using the original few-shot examples and these learned general principles. We evaluate LEAP on a wide range of benchmarks, including multi-hop question answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning, and math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the strongest available LLMs such as GPT-3.5-turbo, GPT-4, GPT-4 turbo and Claude-2.1. For example, LEAP improves over the standard few-shot prompting using GPT-4 by 7.5% in DROP, and by 3.3% in HotpotQA. Importantly, LEAP does not require any more input or examples than the standard few-shot prompting settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05974",
        "abstract url": "https://arxiv.org/abs/2402.05974",
        "title": "RAGE for the Machine: Image Compression with Low-Cost Random Access for Embedded Applications",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "We introduce RAGE, an image compression framework that achieves four generally conflicting objectives: 1) good compression for a wide variety of color images, 2) computationally efficient, fast decompression, 3) fast random access of images with pixel-level granularity without the need to decompress the entire image, 4) support for both lossless and lossy compression. To achieve these, we rely on the recent concept of generalized deduplication (GD), which is known to provide efficient lossless (de)compression and fast random access in time-series data, and deliver key expansions suitable for image compression, both lossless and lossy. Using nine different datasets, incl. graphics, logos, natural images, we show that RAGE has similar or better compression ratios to state-of-the-art lossless image compressors, while delivering pixel-level random access capabilities. Tests in an ARM Cortex-M33 platform show seek times between 9.9 and 40.6~ns and average decoding time per pixel between 274 and 1226~ns. Our measurements also show that RAGE's lossy variant, RAGE-Q, outperforms JPEG by several fold in terms of distortion in embedded graphics and has reasonable compression and distortion for natural images.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "7 pages, submitted, 10 figures, submitted to IEEE International Conference on Image Processing (ICIP)"
    },
    {
        "paper id": "2402.05978",
        "abstract url": "https://arxiv.org/abs/2402.05978",
        "title": "Combining shape and contour features to improve tool wear monitoring in milling processes",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, a new system based on combinations of a shape descriptor and a contour descriptor has been proposed for classifying inserts in milling processes according to their wear level following a computer vision based approach. To describe the wear region shape we have proposed a new descriptor called ShapeFeat and its contour has been characterized using the method BORCHIZ that, to the best of our knowledge, achieves the best performance for tool wear monitoring following a computer vision-based approach. Results show that the combination of BORCHIZ with ShapeFeat using a late fusion method improves the classification performance significantly, obtaining an accuracy of 91.44% in the binary classification (i.e. the classification of the wear as high or low) and 82.90% using three target classes (i.e. classification of the wear as high, medium or low). These results outperform the ones obtained by both descriptors used on their own, which achieve accuracies of 88.70 and 80.67% for two and three classes, respectively, using ShapeFeat and 87.06 and 80.24% with B-ORCHIZ. This study yielded encouraging results for the manufacturing community in order to classify automatically the inserts in terms of their wear for milling processes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10938",
        "abstract url": "https://arxiv.org/abs/2402.10938",
        "title": "News Source Credibility Assessment: A Reddit Case Study",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the era of social media platforms, identifying the credibility of online content is crucial to combat misinformation. We present the CREDiBERT (CREDibility assessment using Bi-directional Encoder Representations from Transformers), a source credibility assessment model fine-tuned for Reddit submissions focusing on political discourse as the main contribution. We adopt a semi-supervised training approach for CREDiBERT, leveraging Reddit's community-based structure. By encoding submission content using CREDiBERT and integrating it into a Siamese neural network, we significantly improve the binary classification of submission credibility, achieving a 9% increase in F1 score compared to existing methods. Additionally, we introduce a new version of the post-to-post network in Reddit that efficiently encodes user interactions to enhance the binary classification task by nearly 8% in F1 score. Finally, we employ CREDiBERT to evaluate the susceptibility of subreddits with respect to different topics.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "12 pages; 3 figures"
    },
    {
        "paper id": "2402.04596",
        "abstract url": "https://arxiv.org/abs/2402.04596",
        "title": "Towards Improved Imbalance Robustness in Continual Multi-Label Learning with Dual Output Spiking Architecture (DOSA)",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Algorithms designed for addressing typical supervised classification problems can only learn from a fixed set of samples and labels, making them unsuitable for the real world, where data arrives as a stream of samples often associated with multiple labels over time. This motivates the study of task-agnostic continual multi-label learning problems. While algorithms using deep learning approaches for continual multi-label learning have been proposed in the recent literature, they tend to be computationally heavy. Although spiking neural networks (SNNs) offer a computationally efficient alternative to artificial neural networks, existing literature has not used SNNs for continual multi-label learning. Also, accurately determining multiple labels with SNNs is still an open research problem. This work proposes a dual output spiking architecture (DOSA) to bridge these research gaps. A novel imbalance-aware loss function is also proposed, improving the multi-label classification performance of the model by making it more robust to data imbalance. A modified F1 score is presented to evaluate the effectiveness of the proposed loss function in handling imbalance. Experiments on several benchmark multi-label datasets show that DOSA trained with the proposed loss function shows improved robustness to data imbalance and obtains better continual multi-label learning performance than CIFDM, a previous state-of-the-art algorithm.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 4 figures, 4 tables, 45 references. Submitted to IJCNN 2024"
    },
    {
        "paper id": "2402.04597",
        "abstract url": "https://arxiv.org/abs/2402.04597",
        "title": "CMSA algorithm for solving the prioritized pairwise test data generation problem in software product lines",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In Software Product Lines (SPLs) it may be difficult or even impossible to test all the products of the family because of the large number of valid feature combinations that may exist. Thus, we want to find a minimal subset of the product family that allows us to test all these possible combinations (pairwise). Furthermore, when testing a single product is a great effort, it is desirable to first test products composed of a set of priority features. This problem is called Prioritized Pairwise Test Data Generation Problem. State-of-the-art algorithms based on Integer Linear Programming for this problema are faster enough for small and medium instances. However, there exists some real instances that are too large to be computed with these algorithms in a reasonable time because of the exponential growth of the number of candidate solutions. Also, these heuristics not always lead us to the best solutions. In this work we propose a new approach based on a hybrid metaheuristic algorithm called Construct, Merge, Solve & Adapt. We compare this matheuristic with four algorithms: a Hybrid algorithm based on Integer Linear Programming ((HILP), a Hybrid algorithm based on Integer Nonlinear Programming (HINLP), the Parallel Prioritized Genetic Solver (PPGS), and a greedy algorithm called prioritized-ICPL. The analysis reveals that CMSA results in statistically significantly better quality solutions in most instances and for most levels of weighted coverage, although it requires more execution time.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Preprint of the submitted version of the article in Journal of Heuristics"
    },
    {
        "paper id": "2402.04625",
        "abstract url": "https://arxiv.org/abs/2402.04625",
        "title": "Noise Map Guidance: Inversion with Spatial Context for Real Image Editing",
        "rating": 0.5,
        "keywords": [
            [
                "diffusion",
                "synthesis",
                "Image Editing"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Text-guided diffusion models have become a popular tool in image synthesis, known for producing high-quality and diverse images. However, their application to editing real images often encounters hurdles primarily due to the text condition deteriorating the reconstruction quality and subsequently affecting editing fidelity. Null-text Inversion (NTI) has made strides in this area, but it fails to capture spatial context and requires computationally intensive per-timestep optimization. Addressing these challenges, we present Noise Map Guidance (NMG), an inversion method rich in a spatial context, tailored for real-image editing. Significantly, NMG achieves this without necessitating optimization, yet preserves the editing quality. Our empirical investigations highlight NMG's adaptability across various editing techniques and its robustness to variants of DDIM inversions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2402.04644",
        "abstract url": "https://arxiv.org/abs/2402.04644",
        "title": "LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fine-tuning is becoming widely used for leveraging the power of pre-trained foundation models in new downstream tasks. While there are many successes of fine-tuning on various tasks, recent studies have observed challenges in the generalization of fine-tuned models to unseen distributions (i.e., out-of-distribution; OOD). To improve OOD generalization, some previous studies identify the limitations of fine-tuning data and regulate fine-tuning to preserve the general representation learned from pre-training data. However, potential limitations in the pre-training data and models are often ignored. In this paper, we contend that overly relying on the pre-trained representation may hinder fine-tuning from learning essential representations for downstream tasks and thus hurt its OOD generalization. It can be especially catastrophic when new tasks are from different (sub)domains compared to pre-training data. To address the issues in both pre-training and fine-tuning data, we propose a novel generalizable fine-tuning method LEVI, where the pre-trained model is adaptively ensembled layer-wise with a small task-specific model, while preserving training and inference efficiencies. By combining two complementing models, LEVI effectively suppresses problematic features in both the fine-tuning data and pre-trained model and preserves useful features for new tasks. Broad experiments with large language and vision models show that LEVI greatly improves fine-tuning generalization via emphasizing different views from fine-tuning data and pre-trained features.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04646",
        "abstract url": "https://arxiv.org/abs/2402.04646",
        "title": "Learning with Diversification from Block Sparse Signal",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a novel prior called Diversified Block Sparse Prior to characterize the widespread block sparsity phenomenon in real-world data. By allowing diversification on variance and correlation matrix, we effectively address the sensitivity issue of existing block sparse learning methods to pre-defined block information, which enables adaptive block estimation while mitigating the risk of overfitting. Based on this, a diversified block sparse Bayesian learning method (DivSBL) is proposed, utilizing EM algorithm and dual ascent method for hyperparameter estimation. Moreover, we establish the global and local optimality theory of our model. Experiments validate the advantages of DivSBL over existing algorithms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 12 figures, 3 tables"
    },
    {
        "paper id": "2402.04672",
        "abstract url": "https://arxiv.org/abs/2402.04672",
        "title": "G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection",
        "rating": 0.5,
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "In this paper, we focus on a realistic yet challenging task, Single Domain Generalization Object Detection (S-DGOD), where only one source domain's data can be used for training object detectors, but have to generalize multiple distinct target domains. In S-DGOD, both high-capacity fitting and generalization abilities are needed due to the task's complexity. Differentiable Neural Architecture Search (NAS) is known for its high capacity for complex data fitting and we propose to leverage Differentiable NAS to solve S-DGOD. However, it may confront severe over-fitting issues due to the feature imbalance phenomenon, where parameters optimized by gradient descent are biased to learn from the easy-to-learn features, which are usually non-causal and spuriously correlated to ground truth labels, such as the features of background in object detection data. Consequently, this leads to serious performance degradation, especially in generalizing to unseen target domains with huge domain gaps between the source domain and target domains. To address this issue, we propose the Generalizable loss (G-loss), which is an OoD-aware objective, preventing NAS from over-fitting by using gradient descent to optimize parameters not only on a subset of easy-to-learn features but also the remaining predictive features for generalization, and the overall framework is named G-NAS. Experimental results on the S-DGOD urban-scene datasets demonstrate that the proposed G-NAS achieves SOTA performance compared to baseline methods. Codes are available at https://github.com/wufan-cse/G-NAS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by AAAI24"
    },
    {
        "paper id": "2402.04744",
        "abstract url": "https://arxiv.org/abs/2402.04744",
        "title": "Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "N:M Structured sparsity has garnered significant interest as a result of relatively modest overhead and improved efficiency. Additionally, this form of sparsity holds considerable appeal for reducing the memory footprint owing to their modest representation overhead. There have been efforts to develop training recipes for N:M structured sparsity, they primarily focus on low-sparsity regions ($\\sim$50\\%). Nonetheless, performance of models trained using these approaches tends to decline when confronted with high-sparsity regions ($>$80\\%). In this work, we study the effectiveness of existing sparse training recipes at \\textit{high-sparsity regions} and argue that these methods fail to sustain the model quality on par with low-sparsity regions. We demonstrate that the significant factor contributing to this disparity is the presence of elevated levels of induced noise in the gradient magnitudes. To mitigate this undesirable effect, we employ decay mechanisms to progressively restrict the flow of gradients towards pruned elements. Our approach improves the model quality by up to 2$\\%$ and 5$\\%$ in vision and language models at high sparsity regime, respectively. We also evaluate the trade-off between model accuracy and training compute cost in terms of FLOPs. At iso-training FLOPs, our method yields better performance compared to conventional sparse training recipes, exhibiting an accuracy improvement of up to 2$\\%$. The source code is available at https://github.com/abhibambhaniya/progressive_gradient_flow_nm_sparsity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "18 pages, 8 figures, 17 tables. Code is available at https://github.com/abhibambhaniya/progressive_gradient_flow_nm_sparsity"
    },
    {
        "paper id": "2402.04754",
        "abstract url": "https://arxiv.org/abs/2402.04754",
        "title": "Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints",
        "rating": 0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Controllable layout generation refers to the process of creating a plausible visual arrangement of elements within a graphic design (e.g., document and web designs) with constraints representing design intentions. Although recent diffusion-based models have achieved state-of-the-art FID scores, they tend to exhibit more pronounced misalignment compared to earlier transformer-based models. In this work, we propose the $\\textbf{LA}$yout $\\textbf{C}$onstraint diffusion mod$\\textbf{E}$l (LACE), a unified model to handle a broad range of layout generation tasks, such as arranging elements with specified attributes and refining or completing a coarse layout design. The model is based on continuous diffusion models. Compared with existing methods that use discrete diffusion models, continuous state-space design can enable the incorporation of differentiable aesthetic constraint functions in training. For conditional generation, we introduce conditions via masked input. Extensive experiment results show that LACE produces high-quality layouts and outperforms existing state-of-the-art baselines.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2024"
    },
    {
        "paper id": "2402.04783",
        "abstract url": "https://arxiv.org/abs/2402.04783",
        "title": "Analyzing the Neural Tangent Kernel of Periodically Activated Coordinate Networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, neural networks utilizing periodic activation functions have been proven to demonstrate superior performance in vision tasks compared to traditional ReLU-activated networks. However, there is still a limited understanding of the underlying reasons for this improved performance. In this paper, we aim to address this gap by providing a theoretical understanding of periodically activated networks through an analysis of their Neural Tangent Kernel (NTK). We derive bounds on the minimum eigenvalue of their NTK in the finite width setting, using a fairly general network architecture which requires only one wide layer that grows at least linearly with the number of data samples. Our findings indicate that periodically activated networks are \\textit{notably more well-behaved}, from the NTK perspective, than ReLU activated networks. Additionally, we give an application to the memorization capacity of such networks and verify our theoretical predictions empirically. Our study offers a deeper understanding of the properties of periodically activated neural networks and their potential in the field of deep learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2402.02711"
    },
    {
        "paper id": "2402.04792",
        "abstract url": "https://arxiv.org/abs/2402.04792",
        "title": "Direct Language Model Alignment from Online AI Feedback",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Direct alignment from preferences (DAP) methods, such as DPO, have recently emerged as efficient alternatives to reinforcement learning from human feedback (RLHF), that do not require a separate reward model. However, the preference datasets used in DAP methods are usually collected ahead of training and never updated, thus the feedback is purely offline. Moreover, responses in these datasets are often sampled from a language model distinct from the one being aligned, and since the model evolves over training, the alignment phase is inevitably off-policy. In this study, we posit that online feedback is key and improves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as annotator: on each training iteration, we sample two responses from the current model and prompt the LLM annotator to choose which one is preferred, thus providing online feedback. Despite its simplicity, we demonstrate via human evaluation in several tasks that OAIF outperforms both offline DAP and RLHF methods. We further show that the feedback leveraged in OAIF is easily controllable, via instruction prompts to the LLM annotator.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "18 pages, 9 figures, 4 tables"
    },
    {
        "paper id": "2402.04794",
        "abstract url": "https://arxiv.org/abs/2402.04794",
        "title": "Scalable Multi-view Clustering via Explicit Kernel Features Maps",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A growing awareness of multi-view learning as an important component in data science and machine learning is a consequence of the increasing prevalence of multiple views in real-world applications, especially in the context of networks. In this paper we introduce a new scalability framework for multi-view subspace clustering. An efficient optimization strategy is proposed, leveraging kernel feature maps to reduce the computational burden while maintaining good clustering performance. The scalability of the algorithm means that it can be applied to large-scale datasets, including those with millions of data points, using a standard machine, in a few minutes. We conduct extensive experiments on real-world benchmark networks of various sizes in order to evaluate the performance of our algorithm against state-of-the-art multi-view subspace clustering methods and attributed-network multi-view approaches.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04812",
        "abstract url": "https://arxiv.org/abs/2402.04812",
        "title": "Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Understanding preferences, opinions, and sentiment of the workforce is paramount for effective employee lifecycle management. Open-ended survey responses serve as a valuable source of information. This paper proposes a machine learning approach for aspect-based sentiment analysis (ABSA) of Dutch open-ended responses in employee satisfaction surveys. Our approach aims to overcome the inherent noise and variability in these responses, enabling a comprehensive analysis of sentiments that can support employee lifecycle management. Through response clustering we identify six key aspects (salary, schedule, contact, communication, personal attention, agreements), which we validate by domain experts. We compile a dataset of 1,458 Dutch survey responses, revealing label imbalance in aspects and sentiments. We propose few-shot approaches for ABSA based on Dutch BERT models, and compare them against bag-of-words and zero-shot baselines. Our work significantly contributes to the field of ABSA by demonstrating the first successful application of Dutch pre-trained language models to aspect-based sentiment analysis in the domain of human resources (HR).",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at NLP4HR Workshop at EACL2024"
    },
    {
        "paper id": "2402.04814",
        "abstract url": "https://arxiv.org/abs/2402.04814",
        "title": "BOWLL: A Deceptively Simple Open World Lifelong Learner",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The quest to improve scalar performance numbers on predetermined benchmarks seems to be deeply engraved in deep learning. However, the real world is seldom carefully curated and applications are seldom limited to excelling on test sets. A practical system is generally required to recognize novel concepts, refrain from actively including uninformative data, and retain previously acquired knowledge throughout its lifetime. Despite these key elements being rigorously researched individually, the study of their conjunction, open world lifelong learning, is only a recent trend. To accelerate this multifaceted field's exploration, we introduce its first monolithic and much-needed baseline. Leveraging the ubiquitous use of batch normalization across deep neural networks, we propose a deceptively simple yet highly effective way to repurpose standard models for open world lifelong learning. Through extensive empirical evaluation, we highlight why our approach should serve as a future standard for models that are able to effectively maintain their knowledge, selectively focus on informative data, and accelerate future learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04832",
        "abstract url": "https://arxiv.org/abs/2402.04832",
        "title": "Structured d-DNNF Is Not Closed Under Negation",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Both structured d-DNNF and SDD can be exponentially more succinct than OBDD. Moreover, SDD is essentially as tractable as OBDD. But this has left two important open questions. Firstly, does OBDD support more tractable transformations than structured d-DNNF? And secondly, is structured d-DNNF more succinct than SDD? In this paper, we answer both questions in the affirmative. For the first question we show that, unlike OBDD, structured d-DNNF does not support polytime negation, disjunction, or existential quantification operations. As a corollary, we deduce that there are functions with an equivalent polynomial-sized structured d-DNNF but with no such representation as an SDD, thus answering the second question. We also lift this second result to arithmetic circuits (AC) to show a succinctness gap between PSDD and the monotone AC analogue to structured d-DNNF.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "9 pages, 2 figures"
    },
    {
        "paper id": "2402.04836",
        "abstract url": "https://arxiv.org/abs/2402.04836",
        "title": "On the Completeness of Invariant Geometric Deep Learning Models",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Invariant models, one important class of geometric deep learning models, are capable of generating meaningful geometric representations by leveraging informative geometric features. These models are characterized by their simplicity, good experimental results and computational efficiency. However, their theoretical expressive power still remains unclear, restricting a deeper understanding of the potential of such models. In this work, we concentrate on characterizing the theoretical expressiveness of invariant models. We first rigorously bound the expressiveness of the most classical invariant model, Vanilla DisGNN (message passing neural networks incorporating distance), restricting its unidentifiable cases to be only those highly symmetric geometric graphs. To break these corner cases' symmetry, we introduce a simple yet E(3)-complete invariant design by nesting Vanilla DisGNN, named GeoNGNN. Leveraging GeoNGNN as a theoretical tool, we for the first time prove the E(3)-completeness of three well-established geometric models: DimeNet, GemNet and SphereNet. Our results fill the gap in the theoretical power of invariant models, contributing to a rigorous and comprehensive understanding of their capabilities. Experimentally, GeoNGNN exhibits good inductive bias in capturing local environments, and achieves competitive results w.r.t. complicated models relying on high-order invariant/equivariant representations while exhibiting significantly faster computational speed.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04869",
        "abstract url": "https://arxiv.org/abs/2402.04869",
        "title": "Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As a key component to intuitive cognition and reasoning solutions in human intelligence, causal knowledge provides great potential for reinforcement learning (RL) agents' interpretability towards decision-making by helping reduce the searching space. However, there is still a considerable gap in discovering and incorporating causality into RL, which hinders the rapid development of causal RL. In this paper, we consider explicitly modeling the generation process of states with the causal graphical model, based on which we augment the policy. We formulate the causal structure updating into the RL interaction process with active intervention learning of the environment. To optimize the derived objective, we propose a framework with theoretical performance guarantees that alternates between two steps: using interventions for causal structure learning during exploration and using the learned causal structure for policy guidance during exploitation. Due to the lack of public benchmarks that allow direct intervention in the state space, we design the root cause localization task in our simulated fault alarm environment and then empirically show the effectiveness and robustness of the proposed method against state-of-the-art baselines. Theoretical analysis shows that our performance improvement attributes to the virtuous cycle of causal-guided policy learning and causal structure learning, which aligns with our experimental results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04875",
        "abstract url": "https://arxiv.org/abs/2402.04875",
        "title": "On Provable Length and Compositional Generalization",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04879",
        "abstract url": "https://arxiv.org/abs/2402.04879",
        "title": "Comparing Methods for Creating a National Random Sample of Twitter Users",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Twitter data has been widely used by researchers across various social and computer science disciplines. A common aim when working with Twitter data is the construction of a random sample of users from a given country. However, while several methods have been proposed in the literature, their comparative performance is mostly unexplored. In this paper, we implement four common methods to collect a random sample of Twitter users in the US: 1% Stream, Bounding Box, Location Query, and Language Query. Then, we compare the methods according to their tweet- and user-level metrics as well as their accuracy in estimating US population with and without using inclusion probabilities of various demographics. Our results show that the 1% Stream method performs differently than others in tweet- and user-level metrics, and best for the construction of a population representative sample. We discuss the conditions under which the 1% Stream method may not be suitable and suggest the Bounding Box method as the second-best method to use.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04892",
        "abstract url": "https://arxiv.org/abs/2402.04892",
        "title": "A Unified Framework for Probabilistic Verification of AI Systems via Weighted Model Integration",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The probabilistic formal verification (PFV) of AI systems is in its infancy. So far, approaches have been limited to ad-hoc algorithms for specific classes of models and/or properties. We propose a unifying framework for the PFV of AI systems based onWeighted Model Integration (WMI), which allows to frame the problem in very general terms. Crucially, this reduction enables the verification of many properties of interest, like fairness, robustness or monotonicity, over a wide range of machine learning models, without making strong distributional assumptions. We support the generality of the approach by solving multiple verification tasks with a single, off-the-shelf WMI solver, then discuss the scalability challenges and research directions related to this promising framework.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04898",
        "abstract url": "https://arxiv.org/abs/2402.04898",
        "title": "The Strain of Success: A Predictive Model for Injury Risk Mitigation and Team Success in Soccer",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we present a novel sequential team selection model in soccer. Specifically, we model the stochastic process of player injury and unavailability using player-specific information learned from real-world soccer data. Monte-Carlo Tree Search is used to select teams for games that optimise long-term team performance across a soccer season by reasoning over player injury probability. We validate our approach compared to benchmark solutions for the 2018/19 English Premier League season. Our model achieves similar season expected points to the benchmark whilst reducing first-team injuries by ~13% and the money inefficiently spent on injured players by ~11% - demonstrating the potential to reduce costs and improve player welfare in real-world soccer teams.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "19 pages (16 main, 2 references, 1 appendix), 10 figures (9 main, 1 appendix). Accepted at the MIT Sloan Sports Analytics Conference 2024 Research Paper Competition"
    },
    {
        "paper id": "2402.04906",
        "abstract url": "https://arxiv.org/abs/2402.04906",
        "title": "Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 8 figures"
    },
    {
        "paper id": "2402.04910",
        "abstract url": "https://arxiv.org/abs/2402.04910",
        "title": "Exploring responsible applications of Synthetic Data to advance Online Safety Research and Development",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The use of synthetic data provides an opportunity to accelerate online safety research and development efforts while showing potential for bias mitigation, facilitating data storage and sharing, preserving privacy and reducing exposure to harmful content. However, the responsible use of synthetic data requires caution regarding anticipated risks and challenges. This short report explores the potential applications of synthetic data to the domain of online safety, and addresses the ethical challenges that effective use of the technology may present.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04918",
        "abstract url": "https://arxiv.org/abs/2402.04918",
        "title": "Prompting Implicit Discourse Relation Annotation",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Pre-trained large language models, such as ChatGPT, archive outstanding performance in various reasoning tasks without supervised training and were found to have outperformed crowdsourcing workers. Nonetheless, ChatGPT's performance in the task of implicit discourse relation classification, prompted by a standard multiple-choice question, is still far from satisfactory and considerably inferior to state-of-the-art supervised approaches. This work investigates several proven prompting techniques to improve ChatGPT's recognition of discourse relations. In particular, we experimented with breaking down the classification task that involves numerous abstract labels into smaller subtasks. Nonetheless, experiment results show that the inference accuracy hardly changes even with sophisticated prompt engineering, suggesting that implicit discourse relation classification is not yet resolvable under zero-shot or few-shot settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "To appear at the Linguistic Annotation Workshop 2024"
    },
    {
        "paper id": "2402.04938",
        "abstract url": "https://arxiv.org/abs/2402.04938",
        "title": "An approach to automated videogame beta testing",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Videogames developed in the 1970s and 1980s were modest programs created in a couple of months by a single person, who played the roles of designer, artist and programmer. Since then, videogames have evolved to become a multi-million dollar industry. Today, AAA game development involves hundreds of people working together over several years. Management and engineering requirements have changed at the same pace. Although many of the processes have been adapted over time, this is not quite true for quality assurance tasks, which are still done mainly manually by human beta testers due to the specific peculiarities of videogames. This paper presents an approach to automate this beta testing.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04971",
        "abstract url": "https://arxiv.org/abs/2402.04971",
        "title": "Multi-Sender Persuasion -- A Computational Perspective",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We consider multiple senders with informational advantage signaling to convince a single self-interested actor towards certain actions. Generalizing the seminal Bayesian Persuasion framework, such settings are ubiquitous in computational economics, multi-agent learning, and machine learning with multiple objectives. The core solution concept here is the Nash equilibrium of senders' signaling policies. Theoretically, we prove that finding an equilibrium in general is PPAD-Hard; in fact, even computing a sender's best response is NP-Hard. Given these intrinsic difficulties, we turn to finding local Nash equilibria. We propose a novel differentiable neural network to approximate this game's non-linear and discontinuous utilities. Complementing this with the extra-gradient algorithm, we discover local equilibria that Pareto dominates full-revelation equilibria and those found by existing neural networks. Broadly, our theoretical and empirical contributions are of interest to a large class of economic problems.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04982",
        "abstract url": "https://arxiv.org/abs/2402.04982",
        "title": "Beyond explaining: XAI-based Adaptive Learning with SHAP Clustering for Energy Consumption Prediction",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents an approach integrating explainable artificial intelligence (XAI) techniques with adaptive learning to enhance energy consumption prediction models, with a focus on handling data distribution shifts. Leveraging SHAP clustering, our method provides interpretable explanations for model predictions and uses these insights to adaptively refine the model, balancing model complexity with predictive performance. We introduce a three-stage process: (1) obtaining SHAP values to explain model predictions, (2) clustering SHAP values to identify distinct patterns and outliers, and (3) refining the model based on the derived SHAP clustering characteristics. Our approach mitigates overfitting and ensures robustness in handling data distribution shifts. We evaluate our method on a comprehensive dataset comprising energy consumption records of buildings, as well as two additional datasets to assess the transferability of our approach to other domains, regression, and classification problems. Our experiments demonstrate the effectiveness of our approach in both task types, resulting in improved predictive performance and interpretable model explanations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "A short version of this paper was published at the Australasian Joint Conference on Artificial Intelligence in 2023"
    },
    {
        "paper id": "2402.04987",
        "abstract url": "https://arxiv.org/abs/2402.04987",
        "title": "PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work studies algorithms for learning from aggregate responses. We focus on the construction of aggregation sets (called bags in the literature) for event-level loss functions. We prove for linear regression and generalized linear models (GLMs) that the optimal bagging problem reduces to one-dimensional size-constrained $k$-means clustering. Further, we theoretically quantify the advantage of using curated bags over random bags. We then propose the PriorBoost algorithm, which adaptively forms bags of samples that are increasingly homogeneous with respect to (unobserved) individual responses to improve model quality. We study label differential privacy for aggregate learning, and we also provide extensive experiments showing that PriorBoost regularly achieves optimal model quality for event-level predictions, in stark contrast to non-adaptive algorithms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "29 pages, 4 figures"
    },
    {
        "paper id": "2402.04999",
        "abstract url": "https://arxiv.org/abs/2402.04999",
        "title": "A Longitudinal Study of Italian and French Reddit Conversations Around the Russian Invasion of Ukraine",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Global events like wars and pandemics can intensify online discussions, fostering information sharing and connection among individuals. However, the divisive nature of such events may lead to polarization within online communities, shaping the dynamics of online interactions. Our study delves into the conversations within the largest Italian and French Reddit communities, specifically examining how the Russian invasion of Ukraine affected online interactions. We use a dataset with over 3 million posts (i.e., comments and submissions) to (1) describe the patterns of moderation activity and (2) characterize war-related discussions in the subreddits. We found changes in moderators' behavior, who became more active during the first month of the war. Moreover, we identified a connection between the daily sentiment of comments and the prevalence of war-related discussions. These discussions were not only more negative and toxic compared to non-war-related ones but also did not involve a specific demographic group. Our research reveals that there is no tendency for users with similar characteristics to interact more. Overall, our study reveals how the war in Ukraine had a negative influence on daily conversations in the analyzed communities. This sheds light on how users responded to this significant event, providing insights into the dynamics of online discussions during events of global relevance.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "18 pages, 10 figures, Accepted at ACM WEBSCI'24 - Update: Added a reference"
    },
    {
        "paper id": "2402.05002",
        "abstract url": "https://arxiv.org/abs/2402.05002",
        "title": "Randomized Confidence Bounds for Stochastic Partial Monitoring",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The partial monitoring (PM) framework provides a theoretical formulation of sequential learning problems with incomplete feedback. On each round, a learning agent plays an action while the environment simultaneously chooses an outcome. The agent then observes a feedback signal that is only partially informative about the (unobserved) outcome. The agent leverages the received feedback signals to select actions that minimize the (unobserved) cumulative loss. In contextual PM, the outcomes depend on some side information that is observable by the agent before selecting the action on each round. In this paper, we consider the contextual and non-contextual PM settings with stochastic outcomes. We introduce a new class of strategies based on the randomization of deterministic confidence bounds, that extend regret guarantees to settings where existing stochastic strategies are not applicable. Our experiments show that the proposed RandCBP and RandCBPside* strategies improve state-of-the-art baselines in PM games. To encourage the adoption of the PM framework, we design a use case on the real-world problem of monitoring the error rate of any deployed classification system.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05006",
        "abstract url": "https://arxiv.org/abs/2402.05006",
        "title": "Scalable Algorithm for Finding Balanced Subgraphs with Tolerance in Signed Networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Signed networks, characterized by edges labeled as either positive or negative, offer nuanced insights into interaction dynamics beyond the capabilities of unsigned graphs. Central to this is the task of identifying the maximum balanced subgraph, crucial for applications like polarized community detection in social networks and portfolio analysis in finance. Traditional models, however, are limited by an assumption of perfect partitioning, which fails to mirror the complexities of real-world data. Addressing this gap, we introduce an innovative generalized balanced subgraph model that incorporates tolerance for irregularities. Our proposed region-based heuristic algorithm, tailored for this NP-hard problem, strikes a balance between low time complexity and high-quality outcomes. Comparative experiments validate its superior performance against leading solutions, delivering enhanced effectiveness (notably larger subgraph sizes) and efficiency (achieving up to 100x speedup) in both traditional and generalized contexts.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2402.05025",
        "abstract url": "https://arxiv.org/abs/2402.05025",
        "title": "Strong convexity-guided hyper-parameter optimization for flatter losses",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel white-box approach to hyper-parameter optimization. Motivated by recent work establishing a relationship between flat minima and generalization, we first establish a relationship between the strong convexity of the loss and its flatness. Based on this, we seek to find hyper-parameter configurations that improve flatness by minimizing the strong convexity of the loss. By using the structure of the underlying neural network, we derive closed-form equations to approximate the strong convexity parameter, and attempt to find hyper-parameters that minimize it in a randomized fashion. Through experiments on 14 classification datasets, we show that our method achieves strong performance at a fraction of the runtime.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "v1"
    },
    {
        "paper id": "2402.05028",
        "abstract url": "https://arxiv.org/abs/2402.05028",
        "title": "Community detection problem based on polarization measures:an application to Twitter: the COVID-19 case in Spain",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In this paper, we address one of the most important topics in the field of Social Networks Analysis: the community detection problem with additional information. That additional information is modeled by a fuzzy measure that represents the risk of polarization. Particularly, we are interested in dealing with the problem of taking into account the polarization of nodes in the community detection problem. Adding this type of information to the community detection problem makes it more realistic, as a community is more likely to be defined if the corresponding elements are willing to maintain a peaceful dialogue. The polarization capacity is modeled by a fuzzy measure based on the JDJpol measure of polarization related to two poles. We also present an efficient algorithm for finding groups whose elements are no polarized. Hereafter, we work in a real case. It is a network obtained from Twitter, concerning the political position against the Spanish government taken by several influential users. We analyze how the partitions obtained change when some additional information related to how polarized that society is, is added to the problem.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "27 pages"
    },
    {
        "paper id": "2402.05033",
        "abstract url": "https://arxiv.org/abs/2402.05033",
        "title": "Simulated Overparameterization",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we introduce a novel paradigm called Simulated Overparametrization (SOP). SOP merges the computational efficiency of compact models with the advanced learning proficiencies of overparameterized models. SOP proposes a unique approach to model training and inference, where a model with a significantly larger number of parameters is trained in such a way that a smaller, efficient subset of these parameters is used for the actual computation during inference. Building upon this framework, we present a novel, architecture agnostic algorithm called \"majority kernels\", which seamlessly integrates with predominant architectures, including Transformer models. Majority kernels enables the simulated training of overparameterized models, resulting in performance gains across architectures and tasks. Furthermore, our approach adds minimal overhead to the cost incurred (wall clock time) at training time. The proposed approach shows strong performance on a wide variety of datasets and models, even outperforming strong baselines such as combinatorial optimization methods based on submodular optimization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05048",
        "abstract url": "https://arxiv.org/abs/2402.05048",
        "title": "How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial intelligence (AI) has driven many information and communication technology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has expanded far beyond AI since the Turing test proposal. Critically, recent AI regulation proposals adopt AI definitions affecting ICT techniques, approaches, and systems that are not AI. In some cases, even works from mathematics, statistics, and engineering would be affected. Worryingly, AI misdefinitions are observed from Western societies to the Global South. In this paper, we propose a framework to score how validated as appropriately-defined for regulation (VADER) an AI definition is. Our online, publicly-available VADER framework scores the coverage of premises that should underlie AI definitions for regulation, which aim to (i) reproduce principles observed in other successful technology regulations, and (ii) include all AI techniques and approaches while excluding non-AI works. Regarding the latter, our score is based on a dataset of representative AI, non-AI ICT, and non-ICT examples. We demonstrate our contribution by reviewing the AI regulation proposals of key players, namely the United States, United Kingdom, European Union, and Brazil. Importantly, none of the proposals assessed achieve the appropriateness score, ranging from a revision need to a concrete risk to ICT systems and works from other fields.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05070",
        "abstract url": "https://arxiv.org/abs/2402.05070",
        "title": "A Roadmap to Pluralistic Alignment",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "With increased power and prevalence of AI systems, it is ever more critical that AI systems are designed to serve all, i.e., people with diverse values and perspectives. However, aligning models to serve pluralistic human values remains an open research question. In this piece, we propose a roadmap to pluralistic alignment, specifically using language models as a test bed. We identify and formalize three possible ways to define and operationalize pluralism in AI systems: 1) Overton pluralistic models that present a spectrum of reasonable responses; 2) Steerably pluralistic models that can steer to reflect certain perspectives; and 3) Distributionally pluralistic models that are well-calibrated to a given population in distribution. We also propose and formalize three possible classes of pluralistic benchmarks: 1) Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which explicitly model diverse human ratings. We use this framework to argue that current alignment techniques may be fundamentally limited for pluralistic AI; indeed, we highlight empirical evidence, both from our own experiments and from other work, that standard alignment procedures might reduce distributional pluralism in models, motivating the need for further research on pluralistic alignment.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05076",
        "abstract url": "https://arxiv.org/abs/2402.05076",
        "title": "Markovian Analysis of Information Cascades with Fake Agents",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "People often learn from other's actions when they make decisions while doing online shopping. This kind of observational learning may lead to information cascades, which means agents might ignore their own signals and follow the 'trend' created collectively by the actions of their predecessors. It is well-known that with rational agents, such a cascade model can result in either correct or incorrect cascades. In this paper, we additionally consider the presence of fake agents who always take fixed actions and we investigate their influence on the outcome of these cascades. We propose an infinite Markov Chain sequence structure and a tree structure to analyze how the fraction and the type of such fake agents impacts behavior of the upcoming agents. We show that an increase in the fraction of fake agents may reduce the chances of their preferred outcome, and also there is a certain lower bound for the probability of a wrong cascade. In particular, we discuss the probability of an agent being fake tends to 1 and the effect of a constant portion of fake agents.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05099",
        "abstract url": "https://arxiv.org/abs/2402.05099",
        "title": "Hydragen: High-Throughput LLM Inference with Shared Prefixes",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformer-based large language models (LLMs) are now deployed to hundreds of millions of users. LLM inference is commonly performed on batches of sequences that share a prefix, such as few-shot examples or a chatbot system prompt. Decoding in this large-batch setting can be bottlenecked by the attention operation, which reads large key-value (KV) caches from memory and computes inefficient matrix-vector products for every sequence in the batch. In this work, we introduce Hydragen, a hardware-aware exact implementation of attention with shared prefixes. Hydragen computes attention over the shared prefix and unique suffixes separately. This decomposition enables efficient prefix attention by batching queries together across sequences, reducing redundant memory reads and enabling the use of hardware-friendly matrix multiplications. Our method can improve end-to-end LLM throughput by up to 32x against competitive baselines, with speedup growing with the batch size and shared prefix length. Hydragen also enables the use of very long shared contexts: with a high batch size, increasing the prefix length from 1K to 16K tokens decreases Hydragen throughput by less than 15%, while the throughput of baselines drops by over 90%. Hydragen generalizes beyond simple prefix-suffix decomposition and can be applied to tree-based prompt sharing patterns, allowing us to further reduce inference time on competitive programming problems by 55%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05109",
        "abstract url": "https://arxiv.org/abs/2402.05109",
        "title": "Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "To combat the memory bandwidth-bound nature of autoregressive LLM inference, previous research has proposed the speculative decoding framework. To perform speculative decoding, a small draft model proposes candidate continuations of the input sequence, that are then verified in parallel by the base model. One way to specify the draft model, as used in the recent Medusa decoding framework, is as a collection of light-weight heads, called draft heads, that operate on the base model's hidden states. To date, all existing draft heads have been sequentially independent, meaning that they speculate tokens in the candidate continuation independently of any preceding tokens in the candidate continuation. In this work, we propose Hydra heads, a sequentially dependent, drop-in replacement for standard draft heads that significantly improves speculation accuracy. Decoding with Hydra heads improves throughput compared to Medusa decoding with standard draft heads. We further explore the design space of Hydra head training objectives and architectures, and propose a carefully-tuned Hydra head recipe, which we call Hydra++, that improves decoding throughput by 1.31x and 2.71x compared to Medusa decoding and autoregressive decoding, respectively. Overall, Hydra heads are a simple intervention on standard draft heads that significantly improve the end-to-end speed of draft head based speculative decoding.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05149",
        "abstract url": "https://arxiv.org/abs/2402.05149",
        "title": "FlowPG: Action-constrained Policy Gradient with Normalizing Flows",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Action-constrained reinforcement learning (ACRL) is a popular approach for solving safety-critical and resource-allocation related decision making problems. A major challenge in ACRL is to ensure agent taking a valid action satisfying constraints in each RL step. Commonly used approach of using a projection layer on top of the policy network requires solving an optimization program which can result in longer training time, slow convergence, and zero gradient problem. To address this, first we use a normalizing flow model to learn an invertible, differentiable mapping between the feasible action space and the support of a simple distribution on a latent variable, such as Gaussian. Second, learning the flow model requires sampling from the feasible action space, which is also challenging. We develop multiple methods, based on Hamiltonian Monte-Carlo and probabilistic sentential decision diagrams for such action sampling for convex and non-convex constraints. Third, we integrate the learned normalizing flow with the DDPG algorithm. By design, a well-trained normalizing flow will transform policy output into a valid action without requiring an optimization solver. Empirically, our approach results in significantly fewer constraint violations (upto an order-of-magnitude for several instances) and is multiple times faster on a variety of continuous control tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05173",
        "abstract url": "https://arxiv.org/abs/2402.05173",
        "title": "Towards Understanding Inductive Bias in Transformers: A View From Infinity",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study inductive bias in Transformers in the infinitely over-parameterized Gaussian process limit and argue transformers tend to be biased towards more permutation symmetric functions in sequence space. We show that the representation theory of the symmetric group can be used to give quantitative analytical predictions when the dataset is symmetric to permutations between tokens. We present a simplified transformer block and solve the model at the limit, including accurate predictions for the learning curves and network outputs. We show that in common setups, one can derive tight bounds in the form of a scaling law for the learnability as a function of the context length. Finally, we argue WikiText dataset, does indeed possess a degree of permutation symmetry.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05232",
        "abstract url": "https://arxiv.org/abs/2402.05232",
        "title": "Universal Neural Functionals",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A challenging problem in many modern machine learning tasks is to process weight-space features, i.e., to transform or extract information from the weights and gradients of a neural network. Recent works have developed promising weight-space models that are equivariant to the permutation symmetries of simple feedforward networks. However, they are not applicable to general architectures, since the permutation symmetries of a weight space can be complicated by recurrence or residual connections. This work proposes an algorithm that automatically constructs permutation equivariant models, which we refer to as universal neural functionals (UNFs), for any weight space. Among other applications, we demonstrate how UNFs can be substituted into existing learned optimizer designs, and find promising improvements over prior methods when optimizing small image classifiers and language models. Our results suggest that learned optimizers can benefit from considering the (symmetry) structure of the weight space they optimize. We open-source our library for constructing UNFs at https://github.com/AllanYangZhou/universal_neural_functional.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05234",
        "abstract url": "https://arxiv.org/abs/2402.05234",
        "title": "QGFN: Controllable Greediness with Action Values",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generative Flow Networks (GFlowNets; GFNs) are a family of reward/energy-based generative methods for combinatorial objects, capable of generating diverse and high-utility samples. However, biasing GFNs towards producing high-utility samples is non-trivial. In this work, we leverage connections between GFNs and reinforcement learning (RL) and propose to combine the GFN policy with an action-value estimate, $Q$, to create greedier sampling policies which can be controlled by a mixing parameter. We show that several variants of the proposed method, QGFN, are able to improve on the number of high-reward samples generated in a variety of tasks without sacrificing diversity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2402.05264",
        "abstract url": "https://arxiv.org/abs/2402.05264",
        "title": "AdaBatchGrad: Combining Adaptive Batch Size and Adaptive Step Size",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a novel adaptation of the Stochastic Gradient Descent (SGD), termed AdaBatchGrad. This modification seamlessly integrates an adaptive step size with an adjustable batch size. An increase in batch size and a decrease in step size are well-known techniques to tighten the area of convergence of SGD and decrease its variance. A range of studies by R. Byrd and J. Nocedal introduced various testing techniques to assess the quality of mini-batch gradient approximations and choose the appropriate batch sizes at every step. Methods that utilized exact tests were observed to converge within $O(LR^2/\\varepsilon)$ iterations. Conversely, inexact test implementations sometimes resulted in non-convergence and erratic performance. To address these challenges, AdaBatchGrad incorporates both adaptive batch and step sizes, enhancing the method's robustness and stability. For exact tests, our approach converges in $O(LR^2/\\varepsilon)$ iterations, analogous to standard gradient descent. For inexact tests, it achieves convergence in $O(\\max\\lbrace LR^2/\\varepsilon, \u03c3^2 R^2/\\varepsilon^2 \\rbrace )$ iterations. This makes AdaBatchGrad markedly more robust and computationally efficient relative to prevailing methods. To substantiate the efficacy of our method, we experimentally show, how the introduction of adaptive step size and adaptive batch size gradually improves the performance of regular SGD. The results imply that AdaBatchGrad surpasses alternative methods, especially when applied to inexact tests.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05274",
        "abstract url": "https://arxiv.org/abs/2402.05274",
        "title": "Convergence for Natural Policy Gradient on Infinite-State Average-Reward Markov Decision Processes",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Infinite-state Markov Decision Processes (MDPs) are essential in modeling and optimizing a wide variety of engineering problems. In the reinforcement learning (RL) context, a variety of algorithms have been developed to learn and optimize these MDPs. At the heart of many popular policy-gradient based learning algorithms, such as natural actor-critic, TRPO, and PPO, lies the Natural Policy Gradient (NPG) algorithm. Convergence results for these RL algorithms rest on convergence results for the NPG algorithm. However, all existing results on the convergence of the NPG algorithm are limited to finite-state settings. We prove the first convergence rate bound for the NPG algorithm for infinite-state average-reward MDPs, proving a $O(1/\\sqrt{T})$ convergence rate, if the NPG algorithm is initialized with a good initial policy. Moreover, we show that in the context of a large class of queueing MDPs, the MaxWeight policy suffices to satisfy our initial-policy requirement and achieve a $O(1/\\sqrt{T})$ convergence rate. Key to our result are state-dependent bounds on the relative value function achieved by the iterate policies of the NPG algorithm.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2402.05279",
        "abstract url": "https://arxiv.org/abs/2402.05279",
        "title": "Safety Filters for Black-Box Dynamical Systems by Learning Discriminating Hyperplanes",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning-based approaches are emerging as an effective approach for safety filters for black-box dynamical systems. Existing methods have relied on certificate functions like Control Barrier Functions (CBFs) and Hamilton-Jacobi (HJ) reachability value functions. The primary motivation for our work is the recognition that ultimately, enforcing the safety constraint as a control input constraint at each state is what matters. By focusing on this constraint, we can eliminate dependence on any specific certificate function-based design. To achieve this, we define a discriminating hyperplane that shapes the half-space constraint on control input at each state, serving as a sufficient condition for safety. This concept not only generalizes over traditional safety methods but also simplifies safety filter design by eliminating dependence on specific certificate functions. We present two strategies to learn the discriminating hyperplane: (a) a supervised learning approach, using pre-verified control invariant sets for labeling, and (b) a reinforcement learning (RL) approach, which does not require such labels. The main advantage of our method, unlike conventional safe RL approaches, is the separation of performance and safety. This offers a reusable safety filter for learning new tasks, avoiding the need to retrain from scratch. As such, we believe that the new notion of the discriminating hyperplane offers a more generalizable direction towards designing safety filters, encompassing and extending existing certificate-function-based or safe RL methodologies.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "* indicate co-first authors. This is an extended version of the paper submitted to L4DC 2024"
    },
    {
        "paper id": "2402.05280",
        "abstract url": "https://arxiv.org/abs/2402.05280",
        "title": "No Dimensional Sampling Coresets for Classification",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We refine and generalize what is known about coresets for classification problems via the sensitivity sampling framework. Such coresets seek the smallest possible subsets of input data, so one can optimize a loss function on the coreset and ensure approximation guarantees with respect to the original data. Our analysis provides the first no dimensional coresets, so the size does not depend on the dimension. Moreover, our results are general, apply for distributional input and can use iid samples, so provide sample complexity bounds, and work for a variety of loss functions. A key tool we develop is a Radamacher complexity version of the main sensitivity sampling approach, which can be of independent interest.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "47 Pages"
    },
    {
        "paper id": "2402.05284",
        "abstract url": "https://arxiv.org/abs/2402.05284",
        "title": "Analyzing Adversarial Inputs in Deep Reinforcement Learning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, Deep Reinforcement Learning (DRL) has become a popular paradigm in machine learning due to its successful applications to real-world and complex systems. However, even the state-of-the-art DRL models have been shown to suffer from reliability concerns -- for example, their susceptibility to adversarial inputs, i.e., small and abundant input perturbations that can fool the models into making unpredictable and potentially dangerous decisions. This drawback limits the deployment of DRL systems in safety-critical contexts, where even a small error cannot be tolerated. In this work, we present a comprehensive analysis of the characterization of adversarial inputs, through the lens of formal verification. Specifically, we introduce a novel metric, the Adversarial Rate, to classify models based on their susceptibility to such perturbations, and present a set of tools and algorithms for its computation. Our analysis empirically demonstrates how adversarial inputs can affect the safety of a given DRL system with respect to such perturbations. Moreover, we analyze the behavior of these configurations to suggest several useful practices and guidelines to help mitigate the vulnerability of trained DRL networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05307",
        "abstract url": "https://arxiv.org/abs/2402.05307",
        "title": "Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches. Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage. This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting. Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture. We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning. One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable. The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable. Another lesson is that using logic in the context of a numerical simulation involves a non-trivial mapping from raw (e.g., real-valued time series) simulation data to logical predicates. Some open questions this note exposes include: What are the limits of rule-based controllers, and how learnable are they? Do the differentiable interpretable approaches discussed here scale to large, complex, uncertain systems? Can we truly achieve interpretability? We highlight these and other themes across the three approaches.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05309",
        "abstract url": "https://arxiv.org/abs/2402.05309",
        "title": "Investigating Generalization Behaviours of Generative Flow Networks",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generative Flow Networks (GFlowNets, GFNs) are a generative framework for learning unnormalized probability mass functions over discrete spaces. Since their inception, GFlowNets have proven to be useful for learning generative models in applications where the majority of the discrete space is unvisited during training. This has inspired some to hypothesize that GFlowNets, when paired with deep neural networks (DNNs), have favourable generalization properties. In this work, we empirically verify some of the hypothesized mechanisms of generalization of GFlowNets. In particular, we find that the functions that GFlowNets learn to approximate have an implicit underlying structure which facilitate generalization. We also find that GFlowNets are sensitive to being trained offline and off-policy; however, the reward implicitly learned by GFlowNets is robust to changes in the training distribution.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05346",
        "abstract url": "https://arxiv.org/abs/2402.05346",
        "title": "KIX: A Metacognitive Generalization Framework",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Humans and other animals aptly exhibit general intelligence behaviors in solving a variety of tasks with flexibility and ability to adapt to novel situations by reusing and applying high level knowledge acquired over time. But artificial agents are more of a specialist, lacking such generalist behaviors. Artificial agents will require understanding and exploiting critical structured knowledge representations. We present a metacognitive generalization framework, Knowledge-Interaction-eXecution (KIX), and argue that interactions with objects leveraging type space facilitate the learning of transferable interaction concepts and generalization. It is a natural way of integrating knowledge into reinforcement learning and promising to act as an enabler for autonomous and generalist behaviors in artificial intelligence systems.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05356",
        "abstract url": "https://arxiv.org/abs/2402.05356",
        "title": "Exploring Learning Complexity for Downstream Data Pruning",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The over-parameterized pre-trained models pose a great challenge to fine-tuning with limited computation resources. An intuitive solution is to prune the less informative samples from the fine-tuning dataset. A series of training-based scoring functions are proposed to quantify the informativeness of the data subset but the pruning cost becomes non-negligible due to the heavy parameter updating. For efficient pruning, it is viable to adapt the similarity scoring function of geometric-based methods from training-based to training-free. However, we empirically show that such adaption distorts the original pruning and results in inferior performance on the downstream tasks. In this paper, we propose to treat the learning complexity (LC) as the scoring function for classification and regression tasks. Specifically, the learning complexity is defined as the average predicted confidence of subnets with different capacities, which encapsulates data processing within a converged model. Then we preserve the diverse and easy samples for fine-tuning. Extensive experiments with vision datasets demonstrate the effectiveness and efficiency of the proposed scoring function for classification tasks. For the instruction fine-tuning of large language models, our method achieves state-of-the-art performance with stable convergence, outperforming the full training with only 10\\% of the instruction dataset.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05369",
        "abstract url": "https://arxiv.org/abs/2402.05369",
        "title": "Noise Contrastive Alignment of Language Models with Explicit Rewards",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs). Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations. Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data. Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories. By contrasting NCA and InfoNCA, we show that InfoNCA and DPO adjust relative likelihood across different responses to a single instruction, while NCA optimizes absolute likelihood for each response. We apply our methods to align a 7B language model with a GPT-4 annotated reward dataset. Experimental results suggest that InfoNCA surpasses the DPO baseline in GPT-4 evaluations, while NCA enjoys better training stability with competitive performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05375",
        "abstract url": "https://arxiv.org/abs/2402.05375",
        "title": "Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models",
        "rating": 0.5,
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The success of recent text-to-image diffusion models is largely due to their capacity to be guided by a complex text prompt, which enables users to precisely describe the desired content. However, these models struggle to effectively suppress the generation of undesired content, which is explicitly requested to be omitted from the generated image in the prompt. In this paper, we analyze how to manipulate the text embeddings and remove unwanted content from them. We introduce two contributions, which we refer to as $\\textit{soft-weighted regularization}$ and $\\textit{inference-time text embedding optimization}$. The first regularizes the text embedding matrix and effectively suppresses the undesired content. The second method aims to further suppress the unwanted content generation of the prompt, and encourages the generation of desired content. We evaluate our method quantitatively and qualitatively on extensive experiments, validating its effectiveness. Furthermore, our method is generalizability to both the pixel-space diffusion models (i.e. DeepFloyd-IF) and the latent-space diffusion models (i.e. Stable Diffusion).",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICLR 2024. Our code is available in https://github.com/sen-mao/SuppressEOT"
    },
    {
        "paper id": "2402.05379",
        "abstract url": "https://arxiv.org/abs/2402.05379",
        "title": "Tradeoffs of Diagonal Fisher Information Matrix Estimators",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Fisher information matrix characterizes the local geometry in the parameter space of neural networks. It elucidates insightful theories and useful tools to understand and optimize neural networks. Given its high computational cost, practitioners often use random estimators and evaluate only the diagonal entries. We examine two such estimators, whose accuracy and sample complexity depend on their associated variances. We derive bounds of the variances and instantiate them in regression and classification networks. We navigate trade-offs of both estimators based on analytical and numerical studies. We find that the variance quantities depend on the non-linearity with respect to different parameter groups and should not be neglected when estimating the Fisher information.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05400",
        "abstract url": "https://arxiv.org/abs/2402.05400",
        "title": "Optimizing for ROC Curves on Class-Imbalanced Data by Training over a Family of Loss Functions",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although binary classification is a well-studied problem in computer vision, training reliable classifiers under severe class imbalance remains a challenging problem. Recent work has proposed techniques that mitigate the effects of training under imbalance by modifying the loss functions or optimization methods. While this work has led to significant improvements in the overall accuracy in the multi-class case, we observe that slight changes in hyperparameter values of these methods can result in highly variable performance in terms of Receiver Operating Characteristic (ROC) curves on binary problems with severe imbalance. To reduce the sensitivity to hyperparameter choices and train more general models, we propose training over a family of loss functions, instead of a single loss function. We develop a method for applying Loss Conditional Training (LCT) to an imbalanced classification problem. Extensive experiment results, on both CIFAR and Kaggle competition datasets, show that our method improves model performance and is more robust to hyperparameter choices. Code will be made available at: https://github.com/klieberman/roc_lct.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05401",
        "abstract url": "https://arxiv.org/abs/2402.05401",
        "title": "Adaptive Activation Functions for Predictive Modeling with Sparse Experimental Data",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A pivotal aspect in the design of neural networks lies in selecting activation functions, crucial for introducing nonlinear structures that capture intricate input-output patterns. While the effectiveness of adaptive or trainable activation functions has been studied in domains with ample data, like image classification problems, significant gaps persist in understanding their influence on classification accuracy and predictive uncertainty in settings characterized by limited data availability. This research aims to address these gaps by investigating the use of two types of adaptive activation functions. These functions incorporate shared and individual trainable parameters per hidden layer and are examined in three testbeds derived from additive manufacturing problems containing fewer than one hundred training instances. Our investigation reveals that adaptive activation functions, such as Exponential Linear Unit (ELU) and Softplus, with individual trainable parameters, result in accurate and confident prediction models that outperform fixed-shape activation functions and the less flexible method of using identical trainable activation functions in a hidden layer. Therefore, this work presents an elegant way of facilitating the design of adaptive neural networks in scientific and engineering problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 figures"
    },
    {
        "paper id": "2402.05406",
        "abstract url": "https://arxiv.org/abs/2402.05406",
        "title": "Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Given the generational gap in available hardware between lay practitioners and the most endowed institutions, LLMs are becoming increasingly inaccessible as they grow in size. Whilst many approaches have been proposed to compress LLMs to make their resource consumption manageable, these methods themselves tend to be resource intensive, putting them out of the reach of the very user groups they target. In this work, we explore the problem of structured pruning of LLMs using only forward passes. We seek to empower practitioners to prune models so large that their available hardware has just enough memory to run inference. We develop Bonsai, a gradient-free, perturbative pruning method capable of delivering small, fast, and accurate pruned models. We observe that Bonsai outputs pruned models that (i) outperform those generated by more expensive gradient-based structured pruning methods, and (ii) are twice as fast (with comparable accuracy) as those generated by semi-structured pruning methods requiring comparable resources as Bonsai. We also leverage Bonsai to produce a new sub-2B model using a single A6000 that yields state-of-the-art performance on 4/6 tasks on the Huggingface Open LLM leaderboard.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, 4 fiigures, 15 tables"
    },
    {
        "paper id": "2402.05408",
        "abstract url": "https://arxiv.org/abs/2402.05408",
        "title": "MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis",
        "rating": 0.5,
        "keywords": [
            [
                "diffusion",
                "Synthesis",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We present a Multi-Instance Generation (MIG) task, simultaneously generating multiple instances with diverse controls in one image. Given a set of predefined coordinates and their corresponding descriptions, the task is to ensure that generated instances are accurately at the designated locations and that all instances' attributes adhere to their corresponding description. This broadens the scope of current research on Single-instance generation, elevating it to a more versatile and practical dimension. Inspired by the idea of divide and conquer, we introduce an innovative approach named Multi-Instance Generation Controller (MIGC) to address the challenges of the MIG task. Initially, we break down the MIG task into several subtasks, each involving the shading of a single instance. To ensure precise shading for each instance, we introduce an instance enhancement attention mechanism. Lastly, we aggregate all the shaded instances to provide the necessary information for accurately generating multiple instances in stable diffusion (SD). To evaluate how well generation models perform on the MIG task, we provide a COCO-MIG benchmark along with an evaluation pipeline. Extensive experiments were conducted on the proposed COCO-MIG benchmark, as well as on various commonly used benchmarks. The evaluation results illustrate the exceptional control capabilities of our model in terms of quantity, position, attribute, and interaction. Code and demos will be released at https://migcproject.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for publication in CVPR 2024"
    },
    {
        "paper id": "2403.05549",
        "abstract url": "https://arxiv.org/abs/2403.05549",
        "title": "A Scheduling Perspective on Modular Educational Systems in Europe",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "In modular educational systems, students are allowed to choose a part of their own curriculum themselves. This is typically done in the final class levels which lead to maturity for university access. The rationale behind letting students choose their courses themselves is to enhance self-responsibility, improve student motivation, and allow a focus on specific areas of interest. A central instrument for bringing these systems to fruition is the timetable. However, scheduling the timetable in such systems can be an extremely challenging and time-consuming task. In this study, we present a framework for classifying modular educational systems in Europe that reflects different degrees of freedom regarding student choices, and explore the consequences from the perspective of scheduling a timetable that satisfies all requirements from the organizational and the pedagogical perspective. For this purpose, we conducted interviews in Austria, Germany, Finland, Switzerland, the Netherlands, and Luxembourg and apply the framework to these educational systems, finding that among them the Finnish system shows the highest degree of modularity. After analyzing the consequences of modularity from the scheduling perspective, we assess the necessity for automated scheduling methods, which are central for realizing the potential and many benefits of modular education in practice.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Preprint submitted to International Journal of Educational Research"
    },
    {
        "paper id": "2403.05550",
        "abstract url": "https://arxiv.org/abs/2403.05550",
        "title": "Teranga Go!: Carpooling Collaborative Consumption Community with multi-criteria hesitant fuzzy linguistic term set opinions to build confidence and trust",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Classic Delphi and Fuzzy Delphi methods are used to test content validity of a data collection tools such as questionnaires. Fuzzy Delphi takes the opinion issued by judges from a linguistic perspective reducing ambiguity in opinions by using fuzzy numbers. We propose an extension named 2-Tuple Fuzzy Linguistic Delphi method to deal with scenarios in which judges show different expertise degrees by using fuzzy multigranular semantics of the linguistic terms and to obtain intermediate and final results expressed by 2-tuple linguistic values. The key idea of our proposal is to validate the full questionnaire by means of the evaluation of its parts, defining the validity of each item as a Decision Making problem. Taking the opinion of experts, we measure the degree of consensus, the degree of consistency, and the linguistic score of each item, in order to detect those items that affect, positively or negatively, the quality of the instrument. Considering the real need to evaluate a b-learning educational experience with a consensual questionnaire, we present a Decision Making model for questionnaire validation that solve it. Additionally, we contribute to this consensus reaching problem by developing an online tool under GPL v3 license. The software visualizes the collective valuations for each iteration and assists to determine which parts of the questionnaire should be modified to reach a consensual solution.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "project at https://github.com/rosanamontes/teranga.go. arXiv admin note: substantial text overlap with arXiv:2402.01775"
    },
    {
        "paper id": "2403.06988",
        "abstract url": "https://arxiv.org/abs/2403.06988",
        "title": "Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2$\\times$ speedup over unconstrained decoding -- thereby outperforming existing approaches by a wide margin.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04587",
        "abstract url": "https://arxiv.org/abs/2402.04587",
        "title": "Sparse Anatomical Prompt Semi-Supervised Learning with Masked Image Modeling for CBCT Tooth Segmentation",
        "rating": 0,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate tooth identification and segmentation in Cone Beam Computed Tomography (CBCT) dental images can significantly enhance the efficiency and precision of manual diagnoses performed by dentists. However, existing segmentation methods are mainly developed based on large data volumes training, on which their annotations are extremely time-consuming. Meanwhile, the teeth of each class in CBCT dental images being closely positioned, coupled with subtle inter-class differences, gives rise to the challenge of indistinct boundaries when training model with limited data. To address these challenges, this study aims to propose a tasked-oriented Masked Auto-Encoder paradigm to effectively utilize large amounts of unlabeled data to achieve accurate tooth segmentation with limited labeled data. Specifically, we first construct a self-supervised pre-training framework of masked auto encoder to efficiently utilize unlabeled data to enhance the network performance. Subsequently, we introduce a sparse masked prompt mechanism based on graph attention to incorporate boundary information of the teeth, aiding the network in learning the anatomical structural features of teeth. To the best of our knowledge, we are pioneering the integration of the mask pre-training paradigm into the CBCT tooth segmentation task. Extensive experiments demonstrate both the feasibility of our proposed method and the potential of the boundary prompt mechanism.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04599",
        "abstract url": "https://arxiv.org/abs/2402.04599",
        "title": "Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporal-Viewpoint Alignment",
        "rating": 0,
        "keywords": [
            [
                "3D",
                "Skeleton"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video sequences exhibit significant nuisance variations (undesired effects) of speed of actions, temporal locations, and subjects' poses, leading to temporal-viewpoint misalignment when comparing two sets of frames or evaluating the similarity of two sequences. Thus, we propose Joint tEmporal and cAmera viewpoiNt alIgnmEnt (JEANIE) for sequence pairs. In particular, we focus on 3D skeleton sequences whose camera and subjects' poses can be easily manipulated in 3D. We evaluate JEANIE on skeletal Few-shot Action Recognition (FSAR), where matching well temporal blocks (temporal chunks that make up a sequence) of support-query sequence pairs (by factoring out nuisance variations) is essential due to limited samples of novel classes. Given a query sequence, we create its several views by simulating several camera locations. For a support sequence, we match it with view-simulated query sequences, as in the popular Dynamic Time Warping (DTW). Specifically, each support temporal block can be matched to the query temporal block with the same or adjacent (next) temporal index, and adjacent camera views to achieve joint local temporal-viewpoint warping. JEANIE selects the smallest distance among matching paths with different temporal-viewpoint warping patterns, an advantage over DTW which only performs temporal alignment. We also propose an unsupervised FSAR akin to clustering of sequences with JEANIE as a distance measure. JEANIE achieves state-of-the-art results on NTU-60, NTU-120, Kinetics-skeleton and UWA3D Multiview Activity II on supervised and unsupervised FSAR, and their meta-learning inspired fusion.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by the International Journal of Computer Vision (IJCV). An extension of our ACCV'22 paper [arXiv:arXiv:2210.16820] which was distinguished by the Sang Uk Lee Best Student Paper Award"
    },
    {
        "paper id": "2402.04624",
        "abstract url": "https://arxiv.org/abs/2402.04624",
        "title": "MEMORYLLM: Towards Self-Updatable Large Language Models",
        "rating": 0,
        "keywords": [
            [
                "model editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Existing Large Language Models (LLMs) usually remain static after deployment, which might make it hard to inject new knowledge into the model. We aim to build models containing a considerable portion of self-updatable parameters, enabling the model to integrate new knowledge effectively and efficiently. To this end, we introduce MEMORYLLM, a model that comprises a transformer and a fixed-size memory pool within the latent space of the transformer. MEMORYLLM can self-update with text knowledge and memorize the knowledge injected earlier. Our evaluations demonstrate the ability of MEMORYLLM to effectively incorporate new knowledge, as evidenced by its performance on model editing benchmarks. Meanwhile, the model exhibits long-term information retention capacity, which is validated through our custom-designed evaluations and long-context benchmarks. MEMORYLLM also shows operational integrity without any sign of performance degradation even after nearly a million memory updates.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2402.04648",
        "abstract url": "https://arxiv.org/abs/2402.04648",
        "title": "OV-NeRF: Open-vocabulary Neural Radiance Fields with Vision and Language Foundation Models for 3D Semantic Understanding",
        "rating": 0,
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The development of Neural Radiance Fields (NeRFs) has provided a potent representation for encapsulating the geometric and appearance characteristics of 3D scenes. Enhancing the capabilities of NeRFs in open-vocabulary 3D semantic perception tasks has been a recent focus. However, current methods that extract semantics directly from Contrastive Language-Image Pretraining (CLIP) for semantic field learning encounter difficulties due to noisy and view-inconsistent semantics provided by CLIP. To tackle these limitations, we propose OV-NeRF, which exploits the potential of pre-trained vision and language foundation models to enhance semantic field learning through proposed single-view and cross-view strategies. First, from the single-view perspective, we introduce Region Semantic Ranking (RSR) regularization by leveraging 2D mask proposals derived from SAM to rectify the noisy semantics of each training view, facilitating accurate semantic field learning. Second, from the cross-view perspective, we propose a Cross-view Self-enhancement (CSE) strategy to address the challenge raised by view-inconsistent semantics. Rather than invariably utilizing the 2D inconsistent semantics from CLIP, CSE leverages the 3D consistent semantics generated from the well-trained semantic field itself for semantic field training, aiming to reduce ambiguity and enhance overall semantic consistency across different views. Extensive experiments validate our OV-NeRF outperforms current state-of-the-art methods, achieving a significant improvement of 20.31% and 18.42% in mIoU metric on Replica and Scannet, respectively. Furthermore, our approach exhibits consistent superior results across various CLIP configurations, further verifying its robustness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04686",
        "abstract url": "https://arxiv.org/abs/2402.04686",
        "title": "The Influence of Autofocus Lenses in the Camera Calibration Process",
        "rating": 0,
        "keywords": [
            [
                "robotics",
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Camera calibration is a crucial step in robotics and computer vision. Accurate camera parameters are necessary to achieve robust applications. Nowadays, camera calibration process consists of adjusting a set of data to a pin-hole model, assuming that with a reprojection error close to cero, camera parameters are correct. Since all camera parameters are unknown, computed results are considered true. However, the pin-hole model does not represent the camera behavior accurately if the focus is considered. Real cameras change the focal length slightly to obtain sharp objects in the image and this feature skews the calibration result if a unique pin-hole model is computed with a constant focal length. In this paper, a deep analysis of the camera calibration process is done to detect and strengthen its weaknesses. The camera is mounted in a robot arm to known extrinsic camera parameters with accuracy and to be able to compare computed results with the true ones. Based on the bias that exist between computed results and the true ones, a modification of the widely accepted camera calibration method using images of a planar template is presented. A pin-hole model with distance dependent focal length is proposed to improve the calibration process substantially",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04699",
        "abstract url": "https://arxiv.org/abs/2402.04699",
        "title": "EvoSeed: Unveiling the Threat on Deep Neural Networks with Real-World Illusions",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks are exploited using natural adversarial samples, which have no impact on human perception but are misclassified. Current approaches often rely on the white-box nature of deep neural networks to generate these adversarial samples or alter the distribution of adversarial samples compared to training distribution. To alleviate the limitations of current approaches, we propose EvoSeed, a novel evolutionary strategy-based search algorithmic framework to generate natural adversarial samples. Our EvoSeed framework uses auxiliary Diffusion and Classifier models to operate in a model-agnostic black-box setting. We employ CMA-ES to optimize the search for an adversarial seed vector, which, when processed by the Conditional Diffusion Model, results in an unrestricted natural adversarial sample misclassified by the Classifier Model. Experiments show that generated adversarial images are of high image quality and are transferable to different classifiers. Our approach demonstrates promise in enhancing the quality of adversarial samples using evolutionary algorithms. We hope our research opens new avenues to enhance the robustness of deep neural networks in real-world scenarios. Project Website can be accessed at \\url{https://shashankkotyan.github.io/EvoSeed}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04735",
        "abstract url": "https://arxiv.org/abs/2402.04735",
        "title": "Review of Cetacean's click detection algorithms",
        "rating": 0,
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "The detection of echolocation clicks is key in understanding the intricate behaviors of cetaceans and monitoring their populations. Cetacean species relying on clicks for navigation, foraging and even communications are sperm whales (Physeter macrocephalus) and a variety of dolphin groups. Echolocation clicks are wideband signals of short duration that are often emitted in sequences of varying inter-click-intervals. While datasets and models for clicks exist, the detection and classification of clicks present a significant challenge, mostly due to the diversity of clicks' structures, overlapping signals from simultaneously emitting animals, and the abundance of noise transients from, for example, snapping shrimps and shipping cavitation noise. This paper provides a survey of the many detection and classification methodologies of clicks, ranging from 2002 to 2023. We divide the surveyed techniques into categories by their methodology. Specifically, feature analysis (e.g., phase, ICI and duration), frequency content, energy based detection, supervised and unsupervised machine learning, template matching and adaptive detection approaches. Also surveyed are open access platforms for click detections, and databases openly available for testing. Details of the method applied for each paper are given along with advantages and limitations, and for each category we analyze the remaining challenges. The paper also includes a performance comparison for several schemes over a shared database. Finally, we provide tables summarizing the existing detection schemes in terms of challenges address, methods, detection and classification tools applied, features used and applications.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "23 pages, 6 tables, 4 figures"
    },
    {
        "paper id": "2402.04753",
        "abstract url": "https://arxiv.org/abs/2402.04753",
        "title": "Cortical Surface Diffusion Generative Models",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Cortical surface analysis has gained increased prominence, given its potential implications for neurological and developmental disorders. Traditional vision diffusion models, while effective in generating natural images, present limitations in capturing intricate development patterns in neuroimaging due to limited datasets. This is particularly true for generating cortical surfaces where individual variability in cortical morphology is high, leading to an urgent need for better methods to model brain development and diverse variability inherent across different individuals. In this work, we proposed a novel diffusion model for the generation of cortical surface metrics, using modified surface vision transformers as the principal architecture. We validate our method in the developing Human Connectome Project (dHCP), the results suggest our model demonstrates superior performance in capturing the intricate details of evolving cortical surfaces. Furthermore, our model can generate high-quality realistic samples of cortical surfaces conditioned on postmenstrual age(PMA) at scan.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "4 pages"
    },
    {
        "paper id": "2402.04825",
        "abstract url": "https://arxiv.org/abs/2402.04825",
        "title": "Fast Timing-Conditioned Latent Audio Diffusion",
        "rating": 0,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Generating long-form 44.1kHz stereo audio from text prompts can be computationally demanding. Further, most previous works do not tackle that music and sound effects naturally vary in their duration. Our research focuses on the efficient generation of long-form, variable-length stereo music and sounds at 44.1kHz using text prompts with a generative model. Stable Audio is based on latent diffusion, with its latent defined by a fully-convolutional variational autoencoder. It is conditioned on text prompts as well as timing embeddings, allowing for fine control over both the content and length of the generated music and sounds. Stable Audio is capable of rendering stereo signals of up to 95 sec at 44.1kHz in 8 sec on an A100 GPU. Despite its compute efficiency and fast inference, it is one of the best in two public text-to-music and -audio benchmarks and, differently from state-of-the-art models, can generate music with structure and stereo sounds.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Code: https://github.com/Stability-AI/stable-audio-tools. Metrics: https://github.com/Stability-AI/stable-audio-metrics. Demo: https://stability-ai.github.io/stable-audio-demo"
    },
    {
        "paper id": "2402.04855",
        "abstract url": "https://arxiv.org/abs/2402.04855",
        "title": "Dual-Path Coupled Image Deraining Network via Spatial-Frequency Interaction",
        "rating": 0,
        "keywords": [
            [
                "Deraining"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Transformers have recently emerged as a significant force in the field of image deraining. Existing image deraining methods utilize extensive research on self-attention. Though showcasing impressive results, they tend to neglect critical frequency information, as self-attention is generally less adept at capturing high-frequency details. To overcome this shortcoming, we have developed an innovative Dual-Path Coupled Deraining Network (DPCNet) that integrates information from both spatial and frequency domains through Spatial Feature Extraction Block (SFEBlock) and Frequency Feature Extraction Block (FFEBlock). We have further introduced an effective Adaptive Fusion Module (AFM) for the dual-path feature aggregation. Extensive experiments on six public deraining benchmarks and downstream vision tasks have demonstrated that our proposed method not only outperforms the existing state-of-the-art deraining method but also achieves visually pleasuring results with excellent robustness on downstream vision tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04857",
        "abstract url": "https://arxiv.org/abs/2402.04857",
        "title": "Advancing Anomaly Detection: An Adaptation Model and a New Dataset",
        "rating": 0,
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Industry surveillance is widely applicable in sectors like retail, manufacturing, education, and smart cities, each presenting unique anomalies requiring specialized detection. However, adapting anomaly detection models to novel viewpoints within the same scenario poses challenges. Extending these models to entirely new scenarios necessitates retraining or fine-tuning, a process that can be time consuming. To address these challenges, we propose the Scenario-Adaptive Anomaly Detection (SA2D) method, leveraging the few-shot learning framework for faster adaptation of pre-trained models to new concepts. Despite this approach, a significant challenge emerges from the absence of a comprehensive dataset with diverse scenarios and camera views. In response, we introduce the Multi-Scenario Anomaly Detection (MSAD) dataset, encompassing 14 distinct scenarios captured from various camera views. This real-world dataset is the first high-resolution anomaly detection dataset, offering a solid foundation for training superior models. MSAD includes diverse normal motion patterns, incorporating challenging variations like different lighting and weather conditions. Through experimentation, we validate the efficacy of SA2D, particularly when trained on the MSAD dataset. Our results show that SA2D not only excels under novel viewpoints within the same scenario but also demonstrates competitive performance when faced with entirely new scenarios. This highlights our method's potential in addressing challenges in detecting anomalies across diverse and evolving surveillance scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Research report"
    },
    {
        "paper id": "2402.04883",
        "abstract url": "https://arxiv.org/abs/2402.04883",
        "title": "Toward Accurate Camera-based 3D Object Detection via Cascade Depth Estimation and Calibration",
        "rating": 0,
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent camera-based 3D object detection is limited by the precision of transforming from image to 3D feature spaces, as well as the accuracy of object localization within the 3D space. This paper aims to address such a fundamental problem of camera-based 3D object detection: How to effectively learn depth information for accurate feature lifting and object localization. Different from previous methods which directly predict depth distributions by using a supervised estimation model, we propose a cascade framework consisting of two depth-aware learning paradigms. First, a depth estimation (DE) scheme leverages relative depth information to realize the effective feature lifting from 2D to 3D spaces. Furthermore, a depth calibration (DC) scheme introduces depth reconstruction to further adjust the 3D object localization perturbation along the depth axis. In practice, the DE is explicitly realized by using both the absolute and relative depth optimization loss to promote the precision of depth prediction, while the capability of DC is implicitly embedded into the detection Transformer through a depth denoising mechanism in the training phase. The entire model training is accomplished through an end-to-end manner. We propose a baseline detector and evaluate the effectiveness of our proposal with +2.2%/+2.7% NDS/mAP improvements on NuScenes benchmark, and gain a comparable performance with 55.9%/45.7% NDS/mAP. Furthermore, we conduct extensive experiments to demonstrate its generality based on various detectors with about +2% NDS improvements.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ICRA2024"
    },
    {
        "paper id": "2402.04929",
        "abstract url": "https://arxiv.org/abs/2402.04929",
        "title": "Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel approach to leverage the generalizability capability of Diffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed DM-SFDA method involves fine-tuning a pre-trained text-to-image diffusion model to generate source domain images using features from the target images to guide the diffusion process. Specifically, the pre-trained diffusion model is fine-tuned to generate source samples that minimize entropy and maximize confidence for the pre-trained source model. We then apply established unsupervised domain adaptation techniques to align the generated source images with target domain data. We validate our approach through comprehensive experiments across a range of datasets, including Office-31, Office-Home, and VisDA. The results highlight significant improvements in SFDA performance, showcasing the potential of diffusion models in generating contextually relevant, domain-specific images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2310.01701"
    },
    {
        "paper id": "2402.04930",
        "abstract url": "https://arxiv.org/abs/2402.04930",
        "title": "Blue noise for diffusion models",
        "rating": 0,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most of the existing diffusion models use Gaussian noise for training and sampling across all time steps, which may not optimally account for the frequency contents reconstructed by the denoising network. Despite the diverse applications of correlated noise in computer graphics, its potential for improving the training process has been underexplored. In this paper, we introduce a novel and general class of diffusion models taking correlated noise within and across images into account. More specifically, we propose a time-varying noise model to incorporate correlated noise into the training process, as well as a method for fast generation of correlated noise mask. Our model is built upon deterministic diffusion models and utilizes blue noise to help improve the generation quality compared to using Gaussian white (random) noise only. Further, our framework allows introducing correlation across images within a single mini-batch to improve gradient flow. We perform both qualitative and quantitative evaluations on a variety of datasets using our method, achieving improvements on different tasks over existing deterministic diffusion models in terms of FID metric.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "SIGGRAPH 2024 Conference Proceedings; Project page: https://xchhuang.github.io/bndm"
    },
    {
        "paper id": "2402.04978",
        "abstract url": "https://arxiv.org/abs/2402.04978",
        "title": "An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration",
        "rating": 0,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While Large Language Models (LLMs) demonstrate exceptional performance in a multitude of Natural Language Processing (NLP) tasks, they encounter challenges in practical applications, including issues with hallucinations, inadequate knowledge updating, and limited transparency in the reasoning process. To overcome these limitations, this study innovatively proposes a collaborative training-free reasoning scheme involving tight cooperation between Knowledge Graph (KG) and LLMs. This scheme first involves using LLMs to iteratively explore KG, selectively retrieving a task-relevant knowledge subgraph to support reasoning. The LLMs are then guided to further combine inherent implicit knowledge to reason on the subgraph while explicitly elucidating the reasoning process. Through such a cooperative approach, our scheme achieves more reliable knowledge-based reasoning and facilitates the tracing of the reasoning results. Experimental results show that our scheme significantly progressed across multiple datasets, notably achieving over a 10% improvement on the QALD10 dataset compared to the best baseline and the fine-tuned state-of-the-art (SOTA) work. Building on this success, this study hopes to offer a valuable reference for future research in the fusion of KG and LLMs, thereby enhancing LLMs' proficiency in solving complex issues.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04979",
        "abstract url": "https://arxiv.org/abs/2402.04979",
        "title": "Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens using synthetic Training",
        "rating": 0,
        "keywords": [
            [
                "6d"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current state-of-the-art 6d pose estimation is too compute intensive to be deployed on edge devices, such as Microsoft HoloLens (2) or Apple iPad, both used for an increasing number of augmented reality applications. The quality of AR is greatly dependent on its capabilities to detect and overlay geometry within the scene. We propose a synthetically trained client-server-based augmented reality application, demonstrating state-of-the-art object pose estimation of metallic and texture-less industry objects on edge devices. Synthetic data enables training without real photographs, i.e. for yet-to-be-manufactured objects. Our qualitative evaluation on an AR-assisted sorting task, and quantitative evaluation on both renderings, as well as real-world data recorded on HoloLens 2, sheds light on its real-world applicability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Scandinavian Conference on Image Analysis 2023"
    },
    {
        "paper id": "2402.05044",
        "abstract url": "https://arxiv.org/abs/2402.05044",
        "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models",
        "rating": 0,
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our extensive experiments shed light on the resilience of LLMs against emerging threats and the efficacy of contemporary defense tactics. Data and evaluator are released under https://github.com/OpenSafetyLab/SALAD-BENCH.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "fix institution typo"
    },
    {
        "paper id": "2402.05090",
        "abstract url": "https://arxiv.org/abs/2402.05090",
        "title": "Language-Based Augmentation to Address Shortcut Learning in Object Goal Navigation",
        "rating": 0,
        "keywords": [
            [
                "Vision-Language",
                "VLM"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Deep Reinforcement Learning (DRL) has shown great potential in enabling robots to find certain objects (e.g., `find a fridge') in environments like homes or schools. This task is known as Object-Goal Navigation (ObjectNav). DRL methods are predominantly trained and evaluated using environment simulators. Although DRL has shown impressive results, the simulators may be biased or limited. This creates a risk of shortcut learning, i.e., learning a policy tailored to specific visual details of training environments. We aim to deepen our understanding of shortcut learning in ObjectNav, its implications and propose a solution. We design an experiment for inserting a shortcut bias in the appearance of training environments. As a proof-of-concept, we associate room types to specific wall colors (e.g., bedrooms with green walls), and observe poor generalization of a state-of-the-art (SOTA) ObjectNav method to environments where this is not the case (e.g., bedrooms with blue walls). We find that shortcut learning is the root cause: the agent learns to navigate to target objects, by simply searching for the associated wall color of the target object's room. To solve this, we propose Language-Based (L-B) augmentation. Our key insight is that we can leverage the multimodal feature space of a Vision-Language Model (VLM) to augment visual representations directly at the feature-level, requiring no changes to the simulator, and only an addition of one layer to the model. Where the SOTA ObjectNav method's success rate drops 69%, our proposal has only a drop of 23%.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6 figures, to be published in IEEE IRC 2023"
    },
    {
        "paper id": "2402.05151",
        "abstract url": "https://arxiv.org/abs/2402.05151",
        "title": "CrashFormer: A Multimodal Architecture to Predict the Risk of Crash",
        "rating": 0.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose CrashFormer, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data, an image encoder to use map imagery data, a raw data encoder to utilize demographic information, a feature fusion module for aggregating the encoded features, and a classifier that accepts the aggregated data and makes predictions accordingly. Results from extensive real-world experiments in 10 major US cities show that CrashFormer outperforms state-of-the-art sequential and non-sequential models by 1.8% in F1-score on average when using ``sparse'' input data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "The paper is accepted In 1st ACM SIGSPATIAL International Workshop on Advances in Urban-AI (UrbanAI 23), November 13, 2023, Hamburg, Germany"
    },
    {
        "paper id": "2402.05192",
        "abstract url": "https://arxiv.org/abs/2402.05192",
        "title": "Performance analysis of Deep Learning-based Lossy Point Cloud Geometry Compression Coding Solutions",
        "rating": 0,
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The quality evaluation of three deep learning-based coding solutions for point cloud geometry, notably ADLPCC, PCC GEO CNNv2, and PCGCv2, is presented. The MPEG G-PCC was used as an anchor. Furthermore, LUT SR, which uses multi-resolution Look-Up tables, was also considered. A set of six point clouds representing landscapes and objects were used. As point cloud texture has a great influence on the perceived quality, two different subjective studies that differ in the texture addition model are reported and statistically compared. In the first experiment, the dataset was first encoded with the identified codecs. Then, the texture of the original point cloud was mapped to the decoded point cloud using the Meshlab software, resulting in a point cloud with both geometry and texture information. Finally, the resulting point cloud was encoded with G-PCC using the lossless-geometry-lossy-atts mode, while in the second experiment the texture was mapped directly onto the distorted geometry. Moreover, both subjective evaluations were used to benchmark a set of objective point cloud quality metrics. The two experiments were shown to be statistically different, and the tested metrics revealed quite different behaviors for the two sets of data. The results reveal that the preferred method of evaluation is the encoding of texture information with G-PCC after mapping the texture of the original point cloud to the distorted point cloud. The results suggest that current objective metrics are not suitable to evaluate distortions created by machine learning-based codecs.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05195",
        "abstract url": "https://arxiv.org/abs/2402.05195",
        "title": "$\u03bb$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the recent advances in personalized text-to-image (P-T2I) generative models, it remains challenging to perform finetuning-free multi-subject-driven T2I in a resource-efficient manner. Predominantly, contemporary approaches, involving the training of Hypernetworks and Multimodal Large Language Models (MLLMs), require heavy computing resources that range from 600 to 12300 GPU hours of training. These subject-driven T2I methods hinge on Latent Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention layers. While LDMs offer distinct advantages, P-T2I methods' reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image. In this paper, we present $\u03bb$-ECLIPSE, an alternative prior-training strategy that works in the latent space of a pre-trained CLIP model without relying on the diffusion UNet models. $\u03bb$-ECLIPSE leverages the image-text interleaved pre-training for fast and effective multi-subject-driven P-T2I. Through extensive experiments, we establish that $\u03bb$-ECLIPSE surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization. $\u03bb$-ECLIPSE performs multi-subject driven P-T2I with just 34M parameters and is trained on a mere 74 GPU hours. Additionally, $\u03bb$-ECLIPSE demonstrates the unique ability to perform multi-concept interpolations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://eclipse-t2i.github.io/Lambda-ECLIPSE/"
    },
    {
        "paper id": "2402.05407",
        "abstract url": "https://arxiv.org/abs/2402.05407",
        "title": "Version age-based client scheduling policy for federated learning",
        "rating": 0.0,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Federated Learning (FL) has emerged as a privacy-preserving machine learning paradigm facilitating collaborative training across multiple clients without sharing local data. Despite advancements in edge device capabilities, communication bottlenecks present challenges in aggregating a large number of clients; only a portion of the clients can update their parameters upon each global aggregation. This phenomenon introduces the critical challenge of stragglers in FL and the profound impact of client scheduling policies on global model convergence and stability. Existing scheduling strategies address staleness but predominantly focus on either timeliness or content. Motivated by this, we introduce the novel concept of Version Age of Information (VAoI) to FL. Unlike traditional Age of Information metrics, VAoI considers both timeliness and content staleness. Each client's version age is updated discretely, indicating the freshness of information. VAoI is incorporated into the client scheduling policy to minimize the average VAoI, mitigating the impact of outdated local updates and enhancing the stability of FL systems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 4 figures, ICASSP 2024"
    },
    {
        "paper id": "2402.05977",
        "abstract url": "https://arxiv.org/abs/2402.05977",
        "title": "Tool wear monitoring using an online, automatic and low cost system based on local texture",
        "rating": 0,
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this work we propose a new online, low cost and fast approach based on computer vision and machine learning to determine whether cutting tools used in edge profile milling processes are serviceable or disposable based on their wear level. We created a new dataset of 254 images of edge profile cutting heads which is, to the best of our knowledge, the first publicly available dataset with enough quality for this purpose. All the inserts were segmented and their cutting edges were cropped, obtaining 577 images of cutting edges: 301 functional and 276 disposable. The proposed method is based on (1) dividing the cutting edge image in different regions, called Wear Patches (WP), (2) characterising each one as worn or serviceable using texture descriptors based on different variants of Local Binary Patterns (LBP) and (3) determine, based on the state of these WP, if the cutting edge (and, therefore, the tool) is serviceable or disposable. We proposed and assessed five different patch division configurations. The individual WP were classified by a Support Vector Machine (SVM) with an intersection kernel. The best patch division configuration and texture descriptor for the WP achieves an accuracy of 90.26% in the detection of the disposable cutting edges. These results show a very promising opportunity for automatic wear monitoring in edge profile milling processes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10941",
        "abstract url": "https://arxiv.org/abs/2402.10941",
        "title": "Text2Data: Low-Resource Data Generation with Textual Control",
        "rating": 0,
        "keywords": [
            [
                "diffusion",
                "synthesis",
                "image editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Natural language serves as a common and straightforward control signal for humans to interact seamlessly with machines. Recognizing the importance of this interface, the machine learning community is investing considerable effort in generating data that is semantically coherent with textual instructions. While strides have been made in text-to-data generation spanning image editing, audio synthesis, video creation, and beyond, low-resource areas characterized by expensive annotations or complex data structures, such as molecules, motion dynamics, and time series, often lack textual labels. This deficiency impedes supervised learning, thereby constraining the application of advanced generative models for text-to-data tasks. In response to these challenges in the low-resource scenario, we propose Text2Data, a novel approach that utilizes unlabeled data to understand the underlying data distribution through an unsupervised diffusion model. Subsequently, it undergoes controllable finetuning via a novel constraint optimization-based learning objective that ensures controllability and effectively counteracts catastrophic forgetting. Comprehensive experiments demonstrate that Text2Data is able to achieve enhanced performance regarding controllability across various modalities, including molecules, motions and time series, when compared to existing baselines.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "We propose a method that can achieve text-to-data generation under low-resource situation"
    },
    {
        "paper id": "2403.09681",
        "abstract url": "https://arxiv.org/abs/2403.09681",
        "title": "ViT-MUL: A Baseline Study on Recent Machine Unlearning Methods Applied to Vision Transformers",
        "rating": 0,
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Machine unlearning (MUL) is an arising field in machine learning that seeks to erase the learned information of specific training data points from a trained model. Despite the recent active research in MUL within computer vision, the majority of work has focused on ResNet-based models. Given that Vision Transformers (ViT) have become the predominant model architecture, a detailed study of MUL specifically tailored to ViT is essential. In this paper, we present comprehensive experiments on ViTs using recent MUL algorithms and datasets. We anticipate that our experiments, ablation studies, and findings could provide valuable insights and inspire further research in this field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2403.09683",
        "abstract url": "https://arxiv.org/abs/2403.09683",
        "title": "Counterfactual Image Editing",
        "rating": 0,
        "keywords": [
            [
                "Image Editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Counterfactual image editing is an important task in generative AI, which asks how an image would look if certain features were different. The current literature on the topic focuses primarily on changing individual features while remaining silent about the causal relationships between these features, as present in the real world. In this paper, we formalize the counterfactual image editing task using formal language, modeling the causal relationships between latent generative factors and images through a special type of model called augmented structural causal models (ASCMs). Second, we show two fundamental impossibility results: (1) counterfactual editing is impossible from i.i.d. image samples and their corresponding labels alone; (2) even when the causal relationships between the latent generative factors and images are available, no guarantees regarding the output of the model can be provided. Third, we propose a relaxation for this challenging problem by approximating non-identifiable counterfactual distributions with a new family of counterfactual-consistent estimators. This family exhibits the desirable property of preserving features that the user cares about across both factual and counterfactual worlds. Finally, we develop an efficient algorithm to generate counterfactual images by leveraging neural causal models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04621",
        "abstract url": "https://arxiv.org/abs/2402.04621",
        "title": "Feature Distribution on Graph Topology Mediates the Effect of Graph Convolution: Homophily Perspective",
        "rating": -0.5,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "How would randomly shuffling feature vectors among nodes from the same class affect graph neural networks (GNNs)? The feature shuffle, intuitively, perturbs the dependence between graph topology and features (A-X dependence) for GNNs to learn from. Surprisingly, we observe a consistent and significant improvement in GNN performance following the feature shuffle. Having overlooked the impact of A-X dependence on GNNs, the prior literature does not provide a satisfactory understanding of the phenomenon. Thus, we raise two research questions. First, how should A-X dependence be measured, while controlling for potential confounds? Second, how does A-X dependence affect GNNs? In response, we (i) propose a principled measure for A-X dependence, (ii) design a random graph model that controls A-X dependence, (iii) establish a theory on how A-X dependence relates to graph convolution, and (iv) present empirical analysis on real-world graphs that aligns with the theory. We conclude that A-X dependence mediates the effect of graph convolution, such that smaller dependence improves GNN-based node classification.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04627",
        "abstract url": "https://arxiv.org/abs/2402.04627",
        "title": "SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic \"clues\" in the queries, such as meaningful variable names and inline comments. Finally, we evaluate our approach over the real-world Bgee gene expression knowledge graph and we show that semantic clues can improve model performance by up to 33% compared to a baseline with random variable names and no comments included.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "To appear in Proceedings of SWAT4HCLS 2024: Semantic Web Tools and Applications for Healthcare and Life Sciences"
    },
    {
        "paper id": "2402.04640",
        "abstract url": "https://arxiv.org/abs/2402.04640",
        "title": "Domain Bridge: Generative model-based domain forensic for black-box models",
        "rating": -0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In forensic investigations of machine learning models, techniques that determine a model's data domain play an essential role, with prior work relying on large-scale corpora like ImageNet to approximate the target model's domain. Although such methods are effective in finding broad domains, they often struggle in identifying finer-grained classes within those domains. In this paper, we introduce an enhanced approach to determine not just the general data domain (e.g., human face) but also its specific attributes (e.g., wearing glasses). Our approach uses an image embedding model as the encoder and a generative model as the decoder. Beginning with a coarse-grained description, the decoder generates a set of images, which are then presented to the unknown target model. Successful classifications by the model guide the encoder to refine the description, which in turn, are used to produce a more specific set of images in the subsequent iteration. This iterative refinement narrows down the exact class of interest. A key strength of our approach lies in leveraging the expansive dataset, LAION-5B, on which the generative model Stable Diffusion is trained. This enlarges our search space beyond traditional corpora, such as ImageNet. Empirical results showcase our method's performance in identifying specific attributes of a model's input domain, paving the way for more detailed forensic analyses of deep learning models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04647",
        "abstract url": "https://arxiv.org/abs/2402.04647",
        "title": "Latent Plan Transformer: Planning as Latent Variable Inference",
        "rating": -0.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In tasks aiming for long-term returns, planning becomes necessary. We study generative modeling for planning with datasets repurposed from offline reinforcement learning. Specifically, we identify temporal consistency in the absence of step-wise rewards as one key technical challenge. We introduce the Latent Plan Transformer (LPT), a novel model that leverages a latent space to connect a Transformer-based trajectory generator and the final return. LPT can be learned with maximum likelihood estimation on trajectory-return pairs. In learning, posterior sampling of the latent variable naturally gathers sub-trajectories to form a consistent abstraction despite the finite context. During test time, the latent variable is inferred from an expected return before policy execution, realizing the idea of planning as inference. It then guides the autoregressive policy throughout the episode, functioning as a plan. Our experiments demonstrate that LPT can discover improved decisions from suboptimal trajectories. It achieves competitive performance across several benchmarks, including Gym-Mujoco, Maze2D, and Connect Four, exhibiting capabilities of nuanced credit assignments, trajectory stitching, and adaptation to environmental contingencies. These results validate that latent variable inference can be a strong alternative to step-wise reward prompting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04653",
        "abstract url": "https://arxiv.org/abs/2402.04653",
        "title": "An Over Complete Deep Learning Method for Inverse Problems",
        "rating": -0.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Obtaining meaningful solutions for inverse problems has been a major challenge with many applications in science and engineering. Recent machine learning techniques based on proximal and diffusion-based methods have shown promising results. However, as we show in this work, they can also face challenges when applied to some exemplary problems. We show that similar to previous works on over-complete dictionaries, it is possible to overcome these shortcomings by embedding the solution into higher dimensions. The novelty of the work proposed is that we jointly design and learn the embedding and the regularizer for the embedding vector. We demonstrate the merit of this approach on several exemplary and common inverse problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04710",
        "abstract url": "https://arxiv.org/abs/2402.04710",
        "title": "Incorporating Retrieval-based Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks",
        "rating": -0.5,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have gained considerable traction for their capability to effectively process topological data, yet their interpretability remains a critical concern. Current interpretation methods are dominated by post-hoc explanations to provide a transparent and intuitive understanding of GNNs. However, they have limited performance in interpreting complicated subgraphs and can't utilize the explanation to advance GNN predictions. On the other hand, transparent GNN models are proposed to capture critical subgraphs. While such methods could improve GNN predictions, they usually don't perform well on explanations. Thus, it is desired for a new strategy to better couple GNN explanation and prediction. In this study, we have developed a novel interpretable causal GNN framework that incorporates retrieval-based causal learning with Graph Information Bottleneck (GIB) theory. The framework could semi-parametrically retrieve crucial subgraphs detected by GIB and compress the explanatory subgraphs via a causal module. The framework was demonstrated to consistently outperform state-of-the-art methods, and to achieve 32.71\\% higher precision on real-world explanation scenarios with diverse explanation types. More importantly, the learned explanations were shown able to also improve GNN prediction performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04732",
        "abstract url": "https://arxiv.org/abs/2402.04732",
        "title": "Graph Cuts with Arbitrary Size Constraints Through Optimal Transport",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A common way of partitioning graphs is through minimum cuts. One drawback of classical minimum cut methods is that they tend to produce small groups, which is why more balanced variants such as normalized and ratio cuts have seen more success. However, we believe that with these variants, the balance constraints can be too restrictive for some applications like for clustering of imbalanced datasets, while not being restrictive enough for when searching for perfectly balanced partitions. Here, we propose a new graph cut algorithm for partitioning graphs under arbitrary size constraints. We formulate the graph cut problem as a regularized Gromov-Wasserstein problem. We then propose to solve it using accelerated proximal GD algorithm which has global convergence guarantees, results in sparse solutions and only incurs an additional ratio of $\\mathcal{O}(\\log(n))$ compared to the classical spectral clustering algorithm but was seen to be more efficient.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04786",
        "abstract url": "https://arxiv.org/abs/2402.04786",
        "title": "Multiple bipolar fuzzy measures: an application to community detection problems for networks with additional information",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "In this paper we introduce the concept of multiple bipolar fuzzy measures as a generalization of a bipolar fuzzy measure. We also propose a new definition of a group, which is based on the multidimensional bipolar fuzzy relations of its elements. Taking into account this information, we provide a novel procedure (based on the well-known Louvain algorithm) to deal with community detection problems. This new method considers the multidimensional bipolar information provided by multiple bipolar fuzzy measures, as well as the information provided by a graph. We also give some detailed computational tests, obtained from the application of this algorithm in several benchmark models.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2402.04856",
        "abstract url": "https://arxiv.org/abs/2402.04856",
        "title": "Explaining Learned Reward Functions with Counterfactual Trajectories",
        "rating": -0.5,
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Learning rewards from human behaviour or feedback is a promising approach to aligning AI systems with human values but fails to consistently extract correct reward functions. Interpretability tools could enable users to understand and evaluate possible flaws in learned reward functions. We propose Counterfactual Trajectory Explanations (CTEs) to interpret reward functions in reinforcement learning by contrasting an original with a counterfactual partial trajectory and the rewards they each receive. We derive six quality criteria for CTEs and propose a novel Monte-Carlo-based algorithm for generating CTEs that optimises these quality criteria. Finally, we measure how informative the generated explanations are to a proxy-human model by training it on CTEs. CTEs are demonstrably informative for the proxy-human model, increasing the similarity between its predictions and the reward function on unseen trajectories. Further, it learns to accurately judge differences in rewards between trajectories and generalises to out-of-distribution examples. Although CTEs do not lead to a perfect understanding of the reward, our method, and more generally the adaptation of XAI methods, are presented as a fruitful approach for interpreting learned reward functions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04858",
        "abstract url": "https://arxiv.org/abs/2402.04858",
        "title": "CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay",
        "rating": -0.5,
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models are increasingly solving tasks that are commonly believed to require human-level reasoning ability. However, these models still perform very poorly on benchmarks of general intelligence such as the Abstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a programming-by-examples problem, and introduce a novel and scalable method for language model self-improvement called Code Iteration (CodeIt). Our method iterates between 1) program sampling and hindsight relabeling, and 2) learning from prioritized experience replay. By relabeling the goal of an episode (i.e., the target program output given input) to the realized output produced by the sampled program, our method effectively deals with the extreme sparsity of rewards in program synthesis. Applying CodeIt to the ARC dataset, we demonstrate that prioritized hindsight replay, along with pre-training and data-augmentation, leads to successful inter-task generalization. CodeIt is the first neuro-symbolic approach that scales to the full ARC evaluation dataset. Our method solves 15% of ARC evaluation tasks, achieving state-of-the-art performance and outperforming existing neural and symbolic baselines.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "8 pages, 11 figures"
    },
    {
        "paper id": "2402.04915",
        "abstract url": "https://arxiv.org/abs/2402.04915",
        "title": "Moco: A Learnable Meta Optimizer for Combinatorial Optimization",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Relevant combinatorial optimization problems (COPs) are often NP-hard. While they have been tackled mainly via handcrafted heuristics in the past, advances in neural networks have motivated the development of general methods to learn heuristics from data. Many approaches utilize a neural network to directly construct a solution, but are limited in further improving based on already constructed solutions at inference time. Our approach, Moco, learns a graph neural network that updates the solution construction procedure based on features extracted from the current search state. This meta training procedure targets the overall best solution found during the search procedure given information such as the search budget. This allows Moco to adapt to varying circumstances such as different computational budgets. Moco is a fully learnable meta optimizer that does not utilize any problem specific local search or decomposition. We test Moco on the Traveling Salesman Problem (TSP) and Maximum Independent Set (MIS) and show that it outperforms other approaches on MIS and is overall competitive on the TSP, especially outperforming related approaches, partially even if they use additional local search.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "13 pages, 3 figures"
    },
    {
        "paper id": "2402.05007",
        "abstract url": "https://arxiv.org/abs/2402.05007",
        "title": "Example-based Explanations for Random Forests using Machine Unlearning",
        "rating": -0.5,
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Tree-based machine learning models, such as decision trees and random forests, have been hugely successful in classification tasks primarily because of their predictive power in supervised learning tasks and ease of interpretation. Despite their popularity and power, these models have been found to produce unexpected or discriminatory outcomes. Given their overwhelming success for most tasks, it is of interest to identify sources of their unexpected and discriminatory behavior. However, there has not been much work on understanding and debugging tree-based classifiers in the context of fairness. We introduce FairDebugger, a system that utilizes recent advances in machine unlearning research to identify training data subsets responsible for instances of fairness violations in the outcomes of a random forest classifier. FairDebugger generates top-$k$ explanations (in the form of coherent training data subsets) for model unfairness. Toward this goal, FairDebugger first utilizes machine unlearning to estimate the change in the tree structures of the random forest when parts of the underlying training data are removed, and then leverages the Apriori algorithm from frequent itemset mining to reduce the subset search space. We empirically evaluate our approach on three real-world datasets, and demonstrate that the explanations generated by FairDebugger are consistent with insights from prior studies on these datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05013",
        "abstract url": "https://arxiv.org/abs/2402.05013",
        "title": "Compression of Structured Data with Autoencoders: Provable Benefit of Nonlinearities and Depth",
        "rating": -0.5,
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Autoencoders are a prominent model in many empirical branches of machine learning and lossy data compression. However, basic theoretical questions remain unanswered even in a shallow two-layer setting. In particular, to what degree does a shallow autoencoder capture the structure of the underlying data distribution? For the prototypical case of the 1-bit compression of sparse Gaussian data, we prove that gradient descent converges to a solution that completely disregards the sparse structure of the input. Namely, the performance of the algorithm is the same as if it was compressing a Gaussian source - with no sparsity. For general data distributions, we give evidence of a phase transition phenomenon in the shape of the gradient descent minimizer, as a function of the data sparsity: below the critical sparsity level, the minimizer is a rotation taken uniformly at random (just like in the compression of non-sparse data); above the critical sparsity, the minimizer is the identity (up to a permutation). Finally, by exploiting a connection with approximate message passing algorithms, we show how to improve upon Gaussian performance for the compression of sparse data: adding a denoising function to a shallow architecture already reduces the loss provably, and a suitable multi-layer decoder leads to a further improvement. We validate our findings on image datasets, such as CIFAR-10 and MNIST.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05015",
        "abstract url": "https://arxiv.org/abs/2402.05015",
        "title": "A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?",
        "rating": -0.5,
        "keywords": [
            [
                "parameter-efficient",
                "efficient finetuning"
            ],
            [
                "chemistry"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Automation is one of the cornerstones of contemporary material discovery. Bayesian optimization (BO) is an essential part of such workflows, enabling scientists to leverage prior domain knowledge into efficient exploration of a large molecular space. While such prior knowledge can take many forms, there has been significant fanfare around the ancillary scientific knowledge encapsulated in large language models (LLMs). However, existing work thus far has only explored LLMs for heuristic materials searches. Indeed, recent work obtains the uncertainty estimate -- an integral part of BO -- from point-estimated, non-Bayesian LLMs. In this work, we study the question of whether LLMs are actually useful to accelerate principled Bayesian optimization in the molecular space. We take a sober, dispassionate stance in answering this question. This is done by carefully (i) viewing LLMs as fixed feature extractors for standard but principled BO surrogate models and by (ii) leveraging parameter-efficient finetuning methods and Bayesian neural networks to obtain the posterior of the LLM surrogate. Our extensive experiments with real-world chemistry problems show that LLMs can be useful for BO over molecules, but only if they have been pretrained or finetuned with domain-specific data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05050",
        "abstract url": "https://arxiv.org/abs/2402.05050",
        "title": "Federated Learning Can Find Friends That Are Beneficial",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In Federated Learning (FL), the distributed nature and heterogeneity of client data present both opportunities and challenges. While collaboration among clients can significantly enhance the learning process, not all collaborations are beneficial; some may even be detrimental. In this study, we introduce a novel algorithm that assigns adaptive aggregation weights to clients participating in FL training, identifying those with data distributions most conducive to a specific learning objective. We demonstrate that our aggregation method converges no worse than the method that aggregates only the updates received from clients with the same data distribution. Furthermore, empirical evaluations consistently reveal that collaborations guided by our algorithm outperform traditional FL approaches. This underscores the critical role of judicious client selection and lays the foundation for more streamlined and effective FL implementations in the coming years.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05052",
        "abstract url": "https://arxiv.org/abs/2402.05052",
        "title": "Causal Representation Learning from Multiple Distributions: A General Setting",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In many problems, the measured variables (e.g., image pixels) are just mathematical functions of the hidden causal variables (e.g., the underlying concepts or objects). For the purpose of making predictions in changing environments or making proper changes to the system, it is helpful to recover the hidden causal variables $Z_i$ and their causal relations represented by graph $\\mathcal{G}_Z$. This problem has recently been known as causal representation learning. This paper is concerned with a general, completely nonparametric setting of causal representation learning from multiple distributions (arising from heterogeneous data or nonstationary time series), without assuming hard interventions behind distribution changes. We aim to develop general solutions in this fundamental case; as a by product, this helps see the unique benefit offered by other assumptions such as parametric causal models or hard interventions. We show that under the sparsity constraint on the recovered graph over the latent variables and suitable sufficient change conditions on the causal influences, interestingly, one can recover the moralized graph of the underlying directed acyclic graph, and the recovered latent variables and their relations are related to the underlying causal model in a specific, nontrivial way. In some cases, each latent variable can even be recovered up to component-wise transformations. Experimental results verify our theoretical claims.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05073",
        "abstract url": "https://arxiv.org/abs/2402.05073",
        "title": "NITO: Neural Implicit Fields for Resolution-free Topology Optimization",
        "rating": -0.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Topology optimization is a critical task in engineering design, where the goal is to optimally distribute material in a given space for maximum performance. We introduce Neural Implicit Topology Optimization (NITO), a novel approach to accelerate topology optimization problems using deep learning. NITO stands out as one of the first frameworks to offer a resolution-free and domain-agnostic solution in deep learning-based topology optimization. NITO synthesizes structures with up to seven times better structural efficiency compared to SOTA diffusion models and does so in a tenth of the time. In the NITO framework, we introduce a novel method, the Boundary Point Order-Invariant MLP (BPOM), to represent boundary conditions in a sparse and domain-agnostic manner, moving away from expensive simulation-based approaches. Crucially, NITO circumvents the domain and resolution limitations that restrict Convolutional Neural Network (CNN) models to a structured domain of fixed size -- limitations that hinder the widespread adoption of CNNs in engineering applications. This generalizability allows a single NITO model to train and generate solutions in countless domains, eliminating the need for numerous domain-specific CNNs and their extensive datasets. Despite its generalizability, NITO outperforms SOTA models even in specialized tasks, is an order of magnitude smaller, and is practically trainable at high resolutions that would be restrictive for CNNs. This combination of versatility, efficiency, and performance underlines NITO's potential to transform the landscape of engineering design optimization problems through implicit fields.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05098",
        "abstract url": "https://arxiv.org/abs/2402.05098",
        "title": "On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling",
        "rating": -0.5,
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of training diffusion models to sample from a distribution with a given unnormalized density or energy function. We benchmark several diffusion-structured inference methods, including simulation-based variational approaches and off-policy methods (continuous generative flow networks). Our results shed light on the relative advantages of existing algorithms while bringing into question some claims from past work. We also propose a novel exploration strategy for off-policy methods, based on local search in the target space with the use of a replay buffer, and show that it improves the quality of samples on a variety of target distributions. Our code for the sampling methods and benchmarks studied is made public at https://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusion models for amortized inference.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages; code: https://github.com/GFNOrg/gfn-diffusion"
    },
    {
        "paper id": "2402.05110",
        "abstract url": "https://arxiv.org/abs/2402.05110",
        "title": "Opening the AI black box: program synthesis via mechanistic interpretability",
        "rating": -0.5,
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present MIPS, a novel method for program synthesis based on automated mechanistic interpretability of neural networks trained to perform the desired task, auto-distilling the learned algorithm into Python code. We test MIPS on a benchmark of 62 algorithmic tasks that can be learned by an RNN and find it highly complementary to GPT-4: MIPS solves 32 of them, including 13 that are not solved by GPT-4 (which also solves 30). MIPS uses an integer autoencoder to convert the RNN into a finite state machine, then applies Boolean or integer symbolic regression to capture the learned algorithm. As opposed to large language models, this program synthesis technique makes no use of (and is therefore not limited by) human training data such as algorithms and code from GitHub. We discuss opportunities and challenges for scaling up this approach to make machine-learned models more interpretable and trustworthy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2402.05146",
        "abstract url": "https://arxiv.org/abs/2402.05146",
        "title": "Compressing Deep Reinforcement Learning Networks with a Dynamic Structured Pruning Method for Autonomous Driving",
        "rating": -0.5,
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep reinforcement learning (DRL) has shown remarkable success in complex autonomous driving scenarios. However, DRL models inevitably bring high memory consumption and computation, which hinders their wide deployment in resource-limited autonomous driving devices. Structured Pruning has been recognized as a useful method to compress and accelerate DRL models, but it is still challenging to estimate the contribution of a parameter (i.e., neuron) to DRL models. In this paper, we introduce a novel dynamic structured pruning approach that gradually removes a DRL model's unimportant neurons during the training stage. Our method consists of two steps, i.e. training DRL models with a group sparse regularizer and removing unimportant neurons with a dynamic pruning threshold. To efficiently train the DRL model with a small number of important neurons, we employ a neuron-importance group sparse regularizer. In contrast to conventional regularizers, this regularizer imposes a penalty on redundant groups of neurons that do not significantly influence the output of the DRL model. Furthermore, we design a novel structured pruning strategy to dynamically determine the pruning threshold and gradually remove unimportant neurons with a binary mask. Therefore, our method can remove not only redundant groups of neurons of the DRL model but also achieve high and robust performance. Experimental results show that the proposed method is competitive with existing DRL pruning methods on discrete control environments (i.e., CartPole-v1 and LunarLander-v2) and MuJoCo continuous environments (i.e., Hopper-v3 and Walker2D-v3). Specifically, our method effectively compresses $93\\%$ neurons and $96\\%$ weights of the DRL model in four challenging DRL environments with slight accuracy degradation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05150",
        "abstract url": "https://arxiv.org/abs/2402.05150",
        "title": "Designing deep neural networks for driver intention recognition",
        "rating": -0.5,
        "keywords": [
            [
                "architecture search"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Driver intention recognition studies increasingly rely on deep neural networks. Deep neural networks have achieved top performance for many different tasks, but it is not a common practice to explicitly analyse the complexity and performance of the network's architecture. Therefore, this paper applies neural architecture search to investigate the effects of the deep neural network architecture on a real-world safety critical application with limited computational capabilities. We explore a pre-defined search space for three deep neural network layer types that are capable to handle sequential data (a long-short term memory, temporal convolution, and a time-series transformer layer), and the influence of different data fusion strategies on the driver intention recognition performance. A set of eight search strategies are evaluated for two driver intention recognition datasets. For the two datasets, we observed that there is no search strategy clearly sampling better deep neural network architectures. However, performing an architecture search does improve the model performance compared to the original manually designed networks. Furthermore, we observe no relation between increased model complexity and higher driver intention recognition performance. The result indicate that multiple architectures yield similar performance, regardless of the deep neural network layer type or fusion strategy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05154",
        "abstract url": "https://arxiv.org/abs/2402.05154",
        "title": "Adaptive Hypergraph Network for Trust Prediction",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Trust plays an essential role in an individual's decision-making. Traditional trust prediction models rely on pairwise correlations to infer potential relationships between users. However, in the real world, interactions between users are usually complicated rather than pairwise only. Hypergraphs offer a flexible approach to modeling these complex high-order correlations (not just pairwise connections), since hypergraphs can leverage hyperedeges to link more than two nodes. However, most hypergraph-based methods are generic and cannot be well applied to the trust prediction task. In this paper, we propose an Adaptive Hypergraph Network for Trust Prediction (AHNTP), a novel approach that improves trust prediction accuracy by using higher-order correlations. AHNTP utilizes Motif-based PageRank to capture high-order social influence information. In addition, it constructs hypergroups from both node-level and structure-level attributes to incorporate complex correlation information. Furthermore, AHNTP leverages adaptive hypergraph Graph Convolutional Network (GCN) layers and multilayer perceptrons (MLPs) to generate comprehensive user embeddings, facilitating trust relationship prediction. To enhance model generalization and robustness, we introduce a novel supervised contrastive learning loss for optimization. Extensive experiments demonstrate the superiority of our model over the state-of-the-art approaches in terms of trust prediction accuracy. The source code of this work can be accessed via https://github.com/Sherry-XU1995/AHNTP.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05162",
        "abstract url": "https://arxiv.org/abs/2402.05162",
        "title": "Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications",
        "rating": -0.5,
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\\%$ at the parameter level and $2.5\\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "22 pages, 9 figures. Project page is available at https://boyiwei.com/alignment-attribution/"
    },
    {
        "paper id": "2402.05202",
        "abstract url": "https://arxiv.org/abs/2402.05202",
        "title": "UEyes: An Eye-Tracking Dataset across User Interface Types",
        "rating": -0.5,
        "keywords": [
            [
                "workshop"
            ]
        ],
        "abstract": "Different types of user interfaces differ significantly in the number of elements and how they are displayed. To examine how such differences affect the way users look at UIs, we collected and analyzed a large eye-tracking-based dataset, UEyes (62 participants, 1,980 UI screenshots, near 20K eye movement sequences), covering four major UI types: webpage, desktop UI, mobile UI, and poster. Furthermore, we analyze and discuss the differences in important factors, such as color, location, and gaze direction across UI types, individual viewing strategies and potential future directions. This position paper is a derivative of our recent paper with a particular focus on the UEyes dataset.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted as a CHI2023 workshop paper"
    },
    {
        "paper id": "2402.05275",
        "abstract url": "https://arxiv.org/abs/2402.05275",
        "title": "Exploring Hierarchical Classification Performance for Time Series Data: Dissimilarity Measures and Classifier Comparisons",
        "rating": -0.5,
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The comparative performance of hierarchical classification (HC) and flat classification (FC) methodologies in the realm of time series data analysis is investigated in this study. Dissimilarity measures, including Jensen-Shannon Distance (JSD), Task Similarity Distance (TSD), and Classifier Based Distance (CBD), are leveraged alongside various classifiers such as MINIROCKET, STSF, and SVM. A subset of datasets from the UCR archive, focusing on multi-class cases comprising more than two classes, is employed for analysis. A significant trend is observed wherein HC demonstrates significant superiority over FC when paired with MINIROCKET utilizing TSD, diverging from conventional understandings. Conversely, FC exhibits consistent dominance across all configurations when employing alternative classifiers such as STSF and SVM. Moreover, TSD is found to consistently outperform both CBD and JSD across nearly all scenarios, except in instances involving the STSF classifier where CBD showcases superior performance. This discrepancy underscores the nuanced nature of dissimilarity measures and emphasizes the importance of their tailored selection based on the dataset and classifier employed. Valuable insights into the dynamic interplay between classification methodologies and dissimilarity measures in the realm of time series data analysis are provided by these findings. By elucidating the performance variations across different configurations, a foundation is laid for refining classification methodologies and dissimilarity measures to optimize performance in diverse analytical scenarios. Furthermore, the need for continued research aimed at elucidating the underlying mechanisms driving classification performance in time series data analysis is underscored, with implications for enhancing predictive modeling and decision-making in various domains.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 2 figures, 5th International Mediterranean Congress 1, 1367-1376"
    },
    {
        "paper id": "2402.05290",
        "abstract url": "https://arxiv.org/abs/2402.05290",
        "title": "Do Transformer World Models Give Better Policy Gradients?",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A natural approach for reinforcement learning is to predict future rewards by unrolling a neural network world model, and to backpropagate through the resulting computational graph to learn a policy. However, this method often becomes impractical for long horizons since typical world models induce hard-to-optimize loss landscapes. Transformers are known to efficiently propagate gradients over long horizons: could they be the solution to this problem? Surprisingly, we show that commonly-used transformer world models produce circuitous gradient paths, which can be detrimental to long-range policy gradients. To tackle this challenge, we propose a class of world models called Actions World Models (AWMs), designed to provide more direct routes for gradient propagation. We integrate such AWMs into a policy gradient framework that underscores the relationship between network architectures and the policy gradient updates they inherently represent. We demonstrate that AWMs can generate optimization landscapes that are easier to navigate even when compared to those from the simulator itself. This property allows transformer AWMs to produce better policies than competitive baselines in realistic long-horizon tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Michel Ma and Pierluca D'Oro contributed equally"
    },
    {
        "paper id": "2402.05291",
        "abstract url": "https://arxiv.org/abs/2402.05291",
        "title": "Graph Neural Networks as Fast and High-fidelity Emulators for Finite-Element Ice Sheet Modeling",
        "rating": -0.5,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although the finite element approach of the Ice-sheet and Sea-level System Model (ISSM) solves ice dynamics problems governed by Stokes equations quickly and accurately, such numerical modeling requires intensive computation on central processing units (CPU). In this study, we develop graph neural networks (GNN) as fast surrogate models to preserve the finite element structure of ISSM. Using the 20-year transient simulations in the Pine Island Glacier (PIG), we train and test three GNNs: graph convolutional network (GCN), graph attention network (GAT), and equivariant graph convolutional network (EGCN). These GNNs reproduce ice thickness and velocity with better accuracy than the classic convolutional neural network (CNN) and multi-layer perception (MLP). In particular, GNNs successfully capture the ice mass loss and acceleration induced by higher basal melting rates in the PIG. When our GNN emulators are implemented on graphic processing units (GPUs), they show up to 50 times faster computational time than the CPU-based ISSM simulation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 7 figures, 3 tables, Submitted to Nature Communications on Feb 7, 2024"
    },
    {
        "paper id": "2402.05296",
        "abstract url": "https://arxiv.org/abs/2402.05296",
        "title": "Classifying spam emails using agglomerative hierarchical clustering and a topic-based approach",
        "rating": -0.5,
        "keywords": [
            [
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spam emails are unsolicited, annoying and sometimes harmful messages which may contain malware, phishing or hoaxes. Unlike most studies that address the design of efficient anti-spam filters, we approach the spam email problem from a different and novel perspective. Focusing on the needs of cybersecurity units, we follow a topic-based approach for addressing the classification of spam email into multiple categories. We propose SPEMC-15K-E and SPEMC-15K-S, two novel datasets with approximately 15K emails each in English and Spanish, respectively, and we label them using agglomerative hierarchical clustering into 11 classes. We evaluate 16 pipelines, combining four text representation techniques -Term Frequency-Inverse Document Frequency (TF-IDF), Bag of Words, Word2Vec and BERT- and four classifiers: Support Vector Machine, N\u00e4ive Bayes, Random Forest and Logistic Regression. Experimental results show that the highest performance is achieved with TF-IDF and LR for the English dataset, with a F1 score of 0.953 and an accuracy of 94.6%, and while for the Spanish dataset, TF-IDF with NB yields a F1 score of 0.945 and 98.5% accuracy. Regarding the processing time, TF-IDF with LR leads to the fastest classification, processing an English and Spanish spam email in and on average, respectively.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05353",
        "abstract url": "https://arxiv.org/abs/2402.05353",
        "title": "Revisiting Early-Learning Regularization When Federated Learning Meets Noisy Labels",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the evolving landscape of federated learning (FL), addressing label noise presents unique challenges due to the decentralized and diverse nature of data collection across clients. Traditional centralized learning approaches to mitigate label noise are constrained in FL by privacy concerns and the heterogeneity of client data. This paper revisits early-learning regularization, introducing an innovative strategy, Federated Label-mixture Regularization (FLR). FLR adeptly adapts to FL's complexities by generating new pseudo labels, blending local and global model predictions. This method not only enhances the accuracy of the global model in both i.i.d. and non-i.i.d. settings but also effectively counters the memorization of noisy labels. Demonstrating compatibility with existing label noise and FL techniques, FLR paves the way for improved generalization in FL environments fraught with label inaccuracies.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05359",
        "abstract url": "https://arxiv.org/abs/2402.05359",
        "title": "Prompting with Divide-and-Conquer Program Makes Large Language Models Discerning to Hallucination and Deception",
        "rating": -0.5,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achieve better performance than typical prompting strategies in tasks bothered by intermediate errors and deceptive contents, such as large integer multiplication, hallucination detection and misinformation detection.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2402.05391",
        "abstract url": "https://arxiv.org/abs/2402.05391",
        "title": "Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Knowledge Graphs (KGs) play a pivotal role in advancing various AI applications, with the semantic web community's exploration into multi-modal dimensions unlocking new avenues for innovation. In this survey, we carefully review over 300 articles, focusing on KG-aware research in two principal aspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal tasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into the MMKG realm. We begin by defining KGs and MMKGs, then explore their construction progress. Our review includes two primary task categories: KG-aware multi-modal learning tasks, such as Image Classification and Visual Question Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph Completion and Entity Alignment, highlighting specific research trajectories. For most of these tasks, we provide definitions, evaluation benchmarks, and additionally outline essential insights for conducting relevant research. Finally, we discuss current challenges and identify emerging trends, such as progress in Large Language Modeling and Multi-modal Pre-training strategies. This survey aims to serve as a comprehensive reference for researchers already involved in or considering delving into KG and multi-modal learning research, offering insights into the evolving landscape of MMKG research and supporting future work.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Ongoing work; 41 pages (Main Text), 55 pages (Total), 11 Tables, 13 Figures, 619 citations; Paper list is available at https://github.com/zjukg/KG-MM-Survey"
    },
    {
        "paper id": "2402.05976",
        "abstract url": "https://arxiv.org/abs/2402.05976",
        "title": "RankSum An unsupervised extractive text summarization based on rank fusion",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose Ranksum, an approach for extractive text summarization of single documents based on the rank fusion of four multi-dimensional sentence features extracted for each sentence: topic information, semantic content, significant keywords, and position. The Ranksum obtains the sentence saliency rankings corresponding to each feature in an unsupervised way followed by the weighted fusion of the four scores to rank the sentences according to their significance. The scores are generated in completely unsupervised way, and a labeled document set is required to learn the fusion weights. Since we found that the fusion weights can generalize to other datasets, we consider the Ranksum as an unsupervised approach. To determine topic rank, we employ probabilistic topic models whereas semantic information is captured using sentence embeddings. To derive rankings using sentence embeddings, we utilize Siamese networks to produce abstractive sentence representation and then we formulate a novel strategy to arrange them in their order of importance. A graph-based strategy is applied to find the significant keywords and related sentence rankings in the document. We also formulate a sentence novelty measure based on bigrams, trigrams, and sentence embeddings to eliminate redundant sentences from the summary. The ranks of all the sentences computed for each feature are finally fused to get the final score for each sentence in the document. We evaluate our approach on publicly available summarization datasets CNN/DailyMail and DUC 2002. Experimental results show that our approach outperforms other existing state-of-the-art summarization methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.09456",
        "abstract url": "https://arxiv.org/abs/2402.09456",
        "title": "Optimistic Thompson Sampling for No-Regret Learning in Unknown Games",
        "rating": -0.5,
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work tackles the complexities of multi-player scenarios in \\emph{unknown games}, where the primary challenge lies in navigating the uncertainty of the environment through bandit feedback alongside strategic decision-making. We introduce Thompson Sampling (TS)-based algorithms that exploit the information of opponents' actions and reward structures, leading to a substantial reduction in experimental budgets -- achieving over tenfold improvements compared to conventional approaches. Notably, our algorithms demonstrate that, given specific reward structures, the regret bound depends logarithmically on the total action space, significantly alleviating the curse of multi-player. Furthermore, we unveil the \\emph{Optimism-then-NoRegret} (OTN) framework, a pioneering methodology that seamlessly incorporates our advancements with established algorithms, showcasing its utility in practical scenarios such as traffic routing and radar sensing in the real world.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.10254",
        "abstract url": "https://arxiv.org/abs/2402.10254",
        "title": "Personalized Federated Learning for Statistical Heterogeneity",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The popularity of federated learning (FL) is on the rise, along with growing concerns about data privacy in artificial intelligence applications. FL facilitates collaborative multi-party model learning while simultaneously ensuring the preservation of data confidentiality. Nevertheless, the problem of statistical heterogeneity caused by the presence of diverse client data distributions gives rise to certain challenges, such as inadequate personalization and slow convergence. In order to address the above issues, this paper offers a brief summary of the current research progress in the field of personalized federated learning (PFL). It outlines the PFL concept, examines related techniques, and highlights current endeavors. Furthermore, this paper also discusses potential further research and obstacles associated with PFL.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04594",
        "abstract url": "https://arxiv.org/abs/2402.04594",
        "title": "Ransomware Detection Dynamics: Insights and Implications",
        "rating": -1,
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The rise of ransomware attacks has necessitated the development of effective strategies for identifying and mitigating these threats. This research investigates the utilization of a feature selection algorithm for distinguishing ransomware-related and benign transactions in both Bitcoin (BTC) and United States Dollar (USD). Leveraging the UGRansome dataset, a comprehensive repository of ransomware related BTC and USD transactions, we propose a set of novel features designed to capture the distinct characteristics of ransomware activity within the cryptocurrency ecosystem. These features encompass transaction metadata, ransom analysis, and behavioral patterns, offering a multifaceted view of ransomware-related financial transactions. Through rigorous experimentation and evaluation, we demonstrate the effectiveness of our feature set in accurately extracting BTC and USD transactions, thereby aiding in the early detection and prevention of ransomware-related financial flows. We introduce a Ransomware Feature Selection Algorithm (RFSA) based on Gini Impurity and Mutual Information (MI) for selecting crucial ransomware features from the UGRansome dataset. Insights from the visualization highlight the potential of Gini Impurity and MI-based feature selection to enhance ransomware detection systems by effectively discriminating between ransomware classes. The analysis reveals that approximately 68% of ransomware incidents involve BTC transactions within the range of 1.46 to 2.56, with an average of 2.01 BTC transactions per attack. The findings emphasize the dynamic and adaptable nature of ransomware demands, suggesting that there is no fixed amount for specific cyberattacks, highlighting the evolving landscape of ransomware threats.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04598",
        "abstract url": "https://arxiv.org/abs/2402.04598",
        "title": "Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "In the light of recent advances in embodied data visualizations, we aim to shed light on agency in the context of data visualization. To do so, we introduce Data Agency and Data-Agent Interplay as potential terms and research focus. Furthermore, we exemplify the former in the context of human-robot interaction, and identify future challenges and research questions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "2 pages, 1 figure, Presented as poster at 2023 IEEE Visualization Conference (VIS)"
    },
    {
        "paper id": "2402.04601",
        "abstract url": "https://arxiv.org/abs/2402.04601",
        "title": "Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector",
        "rating": -1,
        "keywords": [
            [
                "Grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models, they are difficult to adapt to decoder-only LLMs. In this paper, we propose an alignment-enhanced corrector for the overcorrection problem that applies to both Seq2Seq models and decoder-only LLMs. Our method first trains a correction model to generate an initial correction of the source sentence. Then, we combine the source sentence with the initial correction and feed it through an alignment model for another round of correction, aiming to enforce the alignment model to focus on potential overcorrection. Moreover, to enhance the model's ability to identify nuances, we further explore the reverse alignment of the source sentence and the initial correction. Finally, we transfer the alignment knowledge from two alignment models to the correction model, instructing it on how to avoid overcorrection. Experimental results on three CGEC datasets demonstrate the effectiveness of our approach in alleviating overcorrection and improving overall performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04631",
        "abstract url": "https://arxiv.org/abs/2402.04631",
        "title": "The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents: New Perspectives and Trends",
        "rating": -1,
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Persuasion, as one of the crucial abilities in human communication, has garnered extensive attention from researchers within the field of intelligent dialogue systems. We humans tend to persuade others to change their viewpoints, attitudes or behaviors through conversations in various scenarios (e.g., persuasion for social good, arguing in online platforms). Developing dialogue agents that can persuade others to accept certain standpoints is essential to achieving truly intelligent and anthropomorphic dialogue system. Benefiting from the substantial progress of Large Language Models (LLMs), dialogue agents have acquired an exceptional capability in context understanding and response generation. However, as a typical and complicated cognitive psychological system, persuasive dialogue agents also require knowledge from the domain of cognitive psychology to attain a level of human-like persuasion. Consequently, the cognitive strategy-enhanced persuasive dialogue agent (defined as CogAgent), which incorporates cognitive strategies to achieve persuasive targets through conversation, has become a predominant research paradigm. To depict the research trends of CogAgent, in this paper, we first present several fundamental cognitive psychology theories and give the formalized definition of three typical cognitive strategies, including the persuasion strategy, the topic path planning strategy, and the argument structure prediction strategy. Then we propose a new system architecture by incorporating the formalized definition to lay the foundation of CogAgent. Representative works are detailed and investigated according to the combined cognitive strategy, followed by the summary of authoritative benchmarks and evaluation metrics. Finally, we summarize our insights on open issues and future directions of CogAgent for upcoming researchers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "36 pages, 6 figures"
    },
    {
        "paper id": "2402.04673",
        "abstract url": "https://arxiv.org/abs/2402.04673",
        "title": "Streamlined Hybrid Annotation Framework using Scalable Codestream for Bandwidth-Restricted UAV Object Detection",
        "rating": -1,
        "keywords": [
            [
                "UAV"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Emergency response missions depend on the fast relay of visual information, a task to which unmanned aerial vehicles are well adapted. However, the effective use of unmanned aerial vehicles is often compromised by bandwidth limitations that impede fast data transmission, thereby delaying the quick decision-making necessary in emergency situations. To address these challenges, this paper presents a streamlined hybrid annotation framework that utilizes the JPEG 2000 compression algorithm to facilitate object detection under limited bandwidth. The proposed framework employs a fine-tuned deep learning network for initial image annotation at lower resolutions and uses JPEG 2000's scalable codestream to selectively enhance the image resolution in critical areas that require human expert annotation. We show that our proposed hybrid framework reduces the response time by a factor of 34 in emergency situations compared to a baseline approach.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04696",
        "abstract url": "https://arxiv.org/abs/2402.04696",
        "title": "Nash Equilibria in Reverse Temporal Voronoi Games",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We study Voronoi games on temporal graphs as introduced by Boehmer et al. (IJCAI 2021) where two players each select a vertex in a temporal graph with the goal of reaching the other vertices earlier than the other player. In this work, we consider the reverse temporal Voronoi game, that is, a player wants to maximize the number of vertices reaching her earlier than the other player. Since temporal distances in temporal graphs are not symmetric in general, this yields a different game. We investigate the difference between the two games with respect to the existence of Nash equilibria in various temporal graph classes including temporal trees, cycles, grids, cliques and split graphs. Our extensive results show that the two games indeed behave quite differently depending on the considered temporal graph class.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04713",
        "abstract url": "https://arxiv.org/abs/2402.04713",
        "title": "Theoretical and Empirical Analysis of Adaptive Entry Point Selection for Graph-based Approximate Nearest Neighbor Search",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "We present a theoretical and empirical analysis of the adaptive entry point selection for graph-based approximate nearest neighbor search (ANNS). We introduce novel concepts: $b\\textit{-monotonic path}$ and $B\\textit{-MSNET}$, which better capture an actual graph in practical algorithms than existing concepts like MSNET. We prove that adaptive entry point selection offers better performance upper bound than the fixed central entry point under more general conditions than previous work. Empirically, we validate the method's effectiveness in accuracy, speed, and memory usage across various datasets, especially in challenging scenarios with out-of-distribution data and hard instances. Our comprehensive study provides deeper insights into optimizing entry points for graph-based ANNS for real-world high-dimensional data applications.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04720",
        "abstract url": "https://arxiv.org/abs/2402.04720",
        "title": "Investigating Driving Interactions: A Robust Multi-Agent Simulation Framework for Autonomous Vehicles",
        "rating": -1,
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ]
        ],
        "abstract": "Current validation methods often rely on recorded data and basic functional checks, which may not be sufficient to encompass the scenarios an autonomous vehicle might encounter. In addition, there is a growing need for complex scenarios with changing vehicle interactions for comprehensive validation. This work introduces a novel synchronous multi-agent simulation framework for autonomous vehicles in interactive scenarios. Our approach creates an interactive scenario and incorporates publicly available edge-case scenarios wherein simulated vehicles are replaced by agents navigating to predefined destinations. We provide a platform that enables the integration of different autonomous driving planning methodologies and includes a set of evaluation metrics to assess autonomous driving behavior. Our study explores different planning setups and adjusts simulation complexity to test the framework's adaptability and performance. Results highlight the critical role of simulating vehicle interactions to enhance autonomous driving systems. Our setup offers unique insights for developing advanced algorithms for complex driving tasks to accelerate future investigations and developments in this field. The multi-agent simulation framework is available as open-source software: https://github.com/TUM-AVS/Frenetix-Motion-Planner",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 Pages. Submitted to IEEE IV 2024 Korea Conference"
    },
    {
        "paper id": "2402.04750",
        "abstract url": "https://arxiv.org/abs/2402.04750",
        "title": "AINS: Affordable Indoor Navigation Solution via Line Color Identification Using Mono-Camera for Autonomous Vehicles",
        "rating": -1,
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "Recently, researchers have been exploring various ways to improve the effectiveness and efficiency of autonomous vehicles by researching new methods, especially for indoor scenarios. Autonomous Vehicles in indoor navigation systems possess many challenges especially the limited accuracy of GPS in indoor scenarios. Several, robust methods have been explored for autonomous vehicles in indoor scenarios to solve this problem, but the ineffectiveness of the proposed methods is the high deployment cost. To address the above-mentioned problems we have presented A low-cost indoor navigation method for autonomous vehicles called Affordable Indoor Navigation Solution (AINS) which is based on based on Monocular Camera. Our proposed solution is mainly based on a mono camera without relying on various huge or power-inefficient sensors to find the path, such as range finders and other navigation sensors. Our proposed method shows that we can deploy autonomous vehicles indoor navigation systems while taking into consideration the cost. We can observe that the results shown by our solution are better than existing solutions and we can reduce the estimated error and time consumption.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04756",
        "abstract url": "https://arxiv.org/abs/2402.04756",
        "title": "Boundary-aware Contrastive Learning for Semi-supervised Nuclei Instance Segmentation",
        "rating": -1,
        "keywords": [
            [
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semi-supervised segmentation methods have demonstrated promising results in natural scenarios, providing a solution to reduce dependency on manual annotation. However, these methods face significant challenges when directly applied to pathological images due to the subtle color differences between nuclei and tissues, as well as the significant morphological variations among nuclei. Consequently, the generated pseudo-labels often contain much noise, especially at the nuclei boundaries. To address the above problem, this paper proposes a boundary-aware contrastive learning network to denoise the boundary noise in a semi-supervised nuclei segmentation task. The model has two key designs: a low-resolution denoising (LRD) module and a cross-RoI contrastive learning (CRC) module. The LRD improves the smoothness of the nuclei boundary by pseudo-labels denoising, and the CRC enhances the discrimination between foreground and background by boundary feature contrastive learning. We conduct extensive experiments to demonstrate the superiority of our proposed method over existing semi-supervised instance segmentation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 3 figures, 6 tables"
    },
    {
        "paper id": "2402.04769",
        "abstract url": "https://arxiv.org/abs/2402.04769",
        "title": "Hierarchical Motion Planning and Offline Robust Model Predictive Control for Autonomous Vehicles",
        "rating": -1,
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "Driving vehicles in complex scenarios under harsh conditions is the biggest challenge for autonomous vehicles (AVs). To address this issue, we propose hierarchical motion planning and robust control strategy using the front-active steering system in complex scenarios with various slippery road adhesion coefficients while considering vehicle uncertain parameters. Behaviors of human vehicles (HVs) are considered and modeled in the form of a car-following model via the Intelligent Driver Model (IDM). Then, in the upper layer, the motion planner first generates an optimal trajectory by using the artificial potential field (APF) algorithm to formulate any surrounding objects, e.g., road marks, boundaries, and static/dynamic obstacles. To track the generated optimal trajectory, in the lower layer, an offline-constrained output feedback robust model predictive control (RMPC) is employed for the linear parameter varying (LPV) system by applying linear matrix inequality (LMI) optimization method that ensures the robustness against the model parameter uncertainties. Furthermore, by augmenting the system model, our proposed approach, called offline RMPC, achieves outstanding efficiency compared to three existing RMPC approaches, e.g., offset-offline RMPC, online RMPC, and offline RMPC without an augmented model (offline RMPC w/o AM), in both improving computing time and reducing input vibrations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages, 9 illustrations, Accepted for publication in American Control Conference (ACC) 2024"
    },
    {
        "paper id": "2402.04777",
        "abstract url": "https://arxiv.org/abs/2402.04777",
        "title": "A fast score-based search algorithm for maximal ancestral graphs using entropy",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "\\emph{Maximal ancestral graph} (MAGs) is a class of graphical model that extend the famous \\emph{directed acyclic graph} in the presence of latent confounders. Most score-based approaches to learn the unknown MAG from empirical data rely on BIC score which suffers from instability and heavy computations. We propose to use the framework of imsets \\citep{studeny2006probabilistic} to score MAGs using empirical entropy estimation and the newly proposed \\emph{refined Markov property} \\citep{hu2023towards}. Our graphical search procedure is similar to \\citet{claassen2022greedy} but improved from our theoretical results. We show that our search algorithm is polynomial in number of nodes by restricting degree, maximal head size and number of discriminating paths. In simulated experiment, our algorithm shows superior performance compared to other state of art MAG learning algorithms.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04789",
        "abstract url": "https://arxiv.org/abs/2402.04789",
        "title": "Making Multicurves Cross Minimally on Surfaces",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "On an orientable surface $S$, consider a collection $\u0393$ of closed curves. The (geometric) intersection number $i_S(\u0393)$ is the minimum number of self-intersections that a collection $\u0393'$ can have, where $\u0393'$ results from a continuous deformation (homotopy) of $\u0393$. We provide algorithms that compute $i_S(\u0393)$ and such a $\u0393'$, assuming that $\u0393$ is given by a collection of closed walks of length $n$ in a graph $M$ cellularly embedded on $S$, in $O(n \\log n)$ time when $M$ and $S$ are fixed. The state of the art is a paper of Despr\u00e9 and Lazarus [SoCG 2017, J. ACM 2019], who compute $i_S(\u0393)$ in $O(n^2)$ time, and $\u0393'$ in $O(n^4)$ time if $\u0393$ is a single closed curve. Our result is more general since we can put an arbitrary number of closed curves in minimal position. Also, our algorithms are quasi-linear in $n$ instead of quadratic and quartic, and our proofs are simpler and shorter. We use techniques from two-dimensional topology and from the theory of hyperbolic surfaces. Most notably, we prove a new property of the reducing triangulations introduced by Colin de Verdi\u00e8re, Despr\u00e9, and Dubois [SODA 2024], reducing our problem to the case of surfaces with boundary. As a key subroutine, we rely on an algorithm of Fulek and T\u00f3th [JCO 2020].",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04798",
        "abstract url": "https://arxiv.org/abs/2402.04798",
        "title": "Spiking-PhysFormer: Camera-Based Remote Photoplethysmography with Parallel Spike-driven Transformer",
        "rating": -1,
        "keywords": [
            [
                "facial",
                "cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Artificial neural networks (ANNs) can help camera-based remote photoplethysmography (rPPG) in measuring cardiac activity and physiological signals from facial videos, such as pulse wave, heart rate and respiration rate with better accuracy. However, most existing ANN-based methods require substantial computing resources, which poses challenges for effective deployment on mobile devices. Spiking neural networks (SNNs), on the other hand, hold immense potential for energy-efficient deep learning owing to their binary and event-driven architecture. To the best of our knowledge, we are the first to introduce SNNs into the realm of rPPG, proposing a hybrid neural network (HNN) model, the Spiking-PhysFormer, aimed at reducing power consumption. Specifically, the proposed Spiking-PhyFormer consists of an ANN-based patch embedding block, SNN-based transformer blocks, and an ANN-based predictor head. First, to simplify the transformer block while preserving its capacity to aggregate local and global spatio-temporal features, we design a parallel spike transformer block to replace sequential sub-blocks. Additionally, we propose a simplified spiking self-attention mechanism that omits the value parameter without compromising the model's performance. Experiments conducted on four datasets-PURE, UBFC-rPPG, UBFC-Phys, and MMPD demonstrate that the proposed model achieves a 12.4\\% reduction in power consumption compared to PhysFormer. Additionally, the power consumption of the transformer block is reduced by a factor of 12.2, while maintaining decent performance as PhysFormer and other ANN-based models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Mingxuan Liu and Jiankai Tang are co-first authors of the article"
    },
    {
        "paper id": "2402.04884",
        "abstract url": "https://arxiv.org/abs/2402.04884",
        "title": "Topological relations in water quality monitoring",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The Alqueva Multi-Purpose Project (EFMA) is a massive abduction and storage infrastructure system in the Alentejo, which has a water quality monitoring network with almost thousands of water quality stations distributed across three subsystems: Alqueva, Pedrog\u00e3o, and Ardila. Identification of pollution sources in complex infrastructure systems, such as the EFMA, requires recognition of water flow direction and delimitation of areas being drained to specific sampling points. The transfer channels in the EFMA infrastructure artificially connect several water bodies that do not share drainage basins, which further complicates the interpretation of water quality data because the water does not flow exclusively downstream and is not restricted to specific basins. The existing user-friendly GIS tools do not facilitate the exploration and visualisation of water quality data in spatial-temporal dimensions, such as defining temporal relationships between monitoring campaigns, nor do they allow the establishment of topological and hydrological relationships between different sampling points. This thesis work proposes a framework capable of aggregating many types of information in a GIS environment, visualising large water quality-related datasets and, a graph data model to integrate and relate water quality between monitoring stations and land use. The graph model allows to exploit the relationship between water quality in a watercourse and reservoirs associated with infrastructures. The graph data model and the developed framework demonstrated encouraging results and has proven to be preferred when compared to relational databases.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04909",
        "abstract url": "https://arxiv.org/abs/2402.04909",
        "title": "Entanglement Definitions for Tethered Robots: Exploration and Analysis",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "In this article we consider the problem of tether entanglement for tethered robots. In many applications, such as maintenance of underwater structures, aerial inspection, and underground exploration, tethered robots are often used in place of standalone (i.e., untethered) ones. However, the presence of a tether also introduces the risk for it to get entangled with obstacles present in the environment or with itself. To avoid these situations, a non-entanglement constraint can be considered in the motion planning problem for tethered robots. This constraint can be expressed either as a set of specific tether configurations that must be avoided, or as a quantitative measure of a `level of entanglement' that can be minimized. However, the literature lacks a generally accepted definition of entanglement, with existing definitions being limited and partial. Namely, the existing entanglement definitions either require a taut tether to come into contact with an obstacle or with another tether, or they require for the tether to do a full loop around an obstacle. In practice, this means that the existing definitions do not effectively cover all instances of tether entanglement. Our goal in this article is to bridge this gap and provide new definitions of entanglement, which, together with the existing ones, can be effectively used to qualify the entanglement state of a tethered robot in diverse situations. The new definitions find application mainly in motion planning for tethered robot systems, where they can be used to obtain more safe and robust entanglement-free trajectories. The present article focuses exclusively on the presentation and analysis of the entanglement definitions. The application of the definitions to the motion planning problem is left for future work.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "30 pages, 19 figures"
    },
    {
        "paper id": "2402.04916",
        "abstract url": "https://arxiv.org/abs/2402.04916",
        "title": "Simple inexpensive vertex and edge invariants distinguishing dataset strongly regular graphs",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "While standard Weisfeiler-Leman vertex labels are not able to distinguish even vertices of regular graphs, there is proposed and tested family of inexpensive polynomial time vertex and edge invariants, distinguishing much more difficult SRGs (strongly regular graphs), also often their vertices. Among 43717 SRGs from dataset by Edward Spence, proposed vertex invariants alone were able to distinguish all but 4 pairs of graphs, which were easily distinguished by further application of proposed edge invariants. Specifically, proposed vertex invariants are traces or sorted diagonals of $(A|_{N_a})^p$ adjacency matrix $A$ restricted to $N_a$ neighborhood of vertex $a$, already for $p=3$ distinguishing all SRGs from 6 out of 13 sets in this dataset, 8 if adding $p=4$. Proposed edge invariants are analogously traces or diagonals of powers of $\\bar{A}_{ab,cd}=A_{ab} A_{ac} A_{bd}$, nonzero for $(a,b)$ being edges. As SRGs are considered the most difficult cases for graph isomorphism problem, such algebraic-combinatorial invariants bring hope that this problem is polynomial time.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2402.04921",
        "abstract url": "https://arxiv.org/abs/2402.04921",
        "title": "Is Two-shot All You Need? A Label-efficient Approach for Video Segmentation in Breast Ultrasound",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "diagnosis"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Breast lesion segmentation from breast ultrasound (BUS) videos could assist in early diagnosis and treatment. Existing video object segmentation (VOS) methods usually require dense annotation, which is often inaccessible for medical datasets. Furthermore, they suffer from accumulative errors and a lack of explicit space-time awareness. In this work, we propose a novel two-shot training paradigm for BUS video segmentation. It not only is able to capture free-range space-time consistency but also utilizes a source-dependent augmentation scheme. This label-efficient learning framework is validated on a challenging in-house BUS video dataset. Results showed that it gained comparable performance to the fully annotated ones given only 1.9% training labels.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "5 pages, 4 figure, 2 tables, accepted by ISBI 2024"
    },
    {
        "paper id": "2402.04931",
        "abstract url": "https://arxiv.org/abs/2402.04931",
        "title": "Complexity of the (Connected) Cluster Vertex Deletion problem on $H$-free graphs",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The well-known Cluster Vertex Deletion problem (CVD) asks for a given graph $G$ and an integer $k$ whether it is possible to delete a set $S$ of at most $k$ vertices of $G$ such that the resulting graph $G-S$ is a cluster graph (a disjoint union of cliques). We give a complete characterization of graphs $H$ for which CVD on $H$-free graphs is polynomially solvable and for which it is NP-complete. Moreover, in the NP-completeness cases, CVD cannot be solved in sub-exponential time in the vertex number of the $H$-free input graphs unless the Exponential-Time Hypothesis fails. We also consider the connected variant of CVD, the Connected Cluster Vertex Deletion problem (CCVD), in which the set $S$ has to induce a connected subgraph of $G$. It turns out that CCVD admits the same complexity dichotomy for $H$-free graphs. Our results enlarge a list of rare dichotomy theorems for well-studied problems on $H$-free graphs.",
        "subjects": [
            "cs.DM"
        ],
        "comment": "Extended version of a MFCS 2022 paper. To appear in Theory of Computing Systems"
    },
    {
        "paper id": "2402.04958",
        "abstract url": "https://arxiv.org/abs/2402.04958",
        "title": "Channel-Selective Normalization for Label-Shift Robust Test-Time Adaptation",
        "rating": -1,
        "keywords": [
            [
                "biomedical",
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks have useful applications in many different tasks, however their performance can be severely affected by changes in the data distribution. For example, in the biomedical field, their performance can be affected by changes in the data (different machines, populations) between training and test datasets. To ensure robustness and generalization to real-world scenarios, test-time adaptation has been recently studied as an approach to adjust models to a new data distribution during inference. Test-time batch normalization is a simple and popular method that achieved compelling performance on domain shift benchmarks. It is implemented by recalculating batch normalization statistics on test batches. Prior work has focused on analysis with test data that has the same label distribution as the training data. However, in many practical applications this technique is vulnerable to label distribution shifts, sometimes producing catastrophic failure. This presents a risk in applying test time adaptation methods in deployment. We propose to tackle this challenge by only selectively adapting channels in a deep network, minimizing drastic adaptation that is sensitive to label shifts. Our selection scheme is based on two principles that we empirically motivate: (1) later layers of networks are more sensitive to label shift (2) individual features can be sensitive to specific classes. We apply the proposed technique to three classification tasks, including CIFAR10-C, Imagenet-C, and diagnosis of fatty liver, where we explore both covariate and label distribution shifts. We find that our method allows to bring the benefits of TTA while significantly reducing the risk of failure common in other methods, while being robust to choice in hyperparameters.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages including references, 7 figures, 2 tables, Appendix"
    },
    {
        "paper id": "2402.04964",
        "abstract url": "https://arxiv.org/abs/2402.04964",
        "title": "ConvLoRA and AdaBN based Domain Adaptation via Self-Training",
        "rating": -1,
        "keywords": [
            [
                "MRI"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing domain adaptation (DA) methods often involve pre-training on the source domain and fine-tuning on the target domain. For multi-target domain adaptation, having a dedicated/separate fine-tuned network for each target domain, that retain all the pre-trained model parameters, is prohibitively expensive. To address this limitation, we propose Convolutional Low-Rank Adaptation (ConvLoRA). ConvLoRA freezes pre-trained model weights, adds trainable low-rank decomposition matrices to convolutional layers, and backpropagates the gradient through these matrices thus greatly reducing the number of trainable parameters. To further boost adaptation, we utilize Adaptive Batch Normalization (AdaBN) which computes target-specific running statistics and use it along with ConvLoRA. Our method has fewer trainable parameters and performs better or on-par with large independent fine-tuned networks (with less than 0.9% trainable parameters of the total base model) when tested on the segmentation of Calgary-Campinas dataset containing brain MRI images. Our approach is simple, yet effective and can be applied to any deep learning-based architecture which uses convolutional and batch normalization layers. Code is available at: https://github.com/aleemsidra/ConvLoRA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04972",
        "abstract url": "https://arxiv.org/abs/2402.04972",
        "title": "Distributed Fair Assignment and Rebalancing for Mobility-on-Demand Systems via an Auction-based Method",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "In this paper, we consider fair assignment of complex requests for Mobility-On-Demand systems. We model the transportation requests as temporal logic formulas that must be satisfied by a fleet of vehicles. We require that the assignment of requests to vehicles is performed in a distributed manner based only on communication between vehicles while ensuring fair allocation. Our approach to the vehicle-request assignment problem is based on a distributed auction scheme with no centralized bidding that leverages utility history correction of bids to improve fairness. Complementarily, we propose a rebalancing scheme that employs rerouting vehicles to more rewarding areas to increase the potential future utility and ensure a fairer utility distribution. We adopt the max-min and deviation of utility as the two criteria for fairness. We demonstrate the methods in the mid-Manhattan map with a large number of requests generated in different probability settings. We show that we increase the fairness between vehicles based on the fairness criteria without degenerating the servicing quality.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04997",
        "abstract url": "https://arxiv.org/abs/2402.04997",
        "title": "Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design",
        "rating": -1,
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "Combining discrete and continuous data is an important capability for generative models. We present Discrete Flow Models (DFMs), a new flow-based model of discrete data that provides the missing link in enabling flow-based generative models to be applied to multimodal continuous and discrete data problems. Our key insight is that the discrete equivalent of continuous space flow matching can be realized using Continuous Time Markov Chains. DFMs benefit from a simple derivation that includes discrete diffusion models as a specific instance while allowing improved performance over existing diffusion-based approaches. We utilize our DFMs method to build a multimodal flow-based modeling framework. We apply this capability to the task of protein co-design, wherein we learn a model for jointly generating protein structure and sequence. Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or structure.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "52 pages, 11 figures, 5 tables"
    },
    {
        "paper id": "2402.05003",
        "abstract url": "https://arxiv.org/abs/2402.05003",
        "title": "Efficient Invariant Kalman Filter for Inertial-based Odometry with Large-sample Environmental Measurements",
        "rating": -1,
        "keywords": [
            [
                "SLAM"
            ]
        ],
        "abstract": "A filter for inertial-based odometry is a recursive method used to estimate the pose from measurements of ego-motion and relative pose. Currently, there is no known filter that guarantees the computation of a globally optimal solution for the non-linear measurement model. In this paper, we demonstrate that an innovative filter, with the state being $SE_2(3)$ and the $\\sqrt{n}$-\\textit{consistent} pose as the initialization, efficiently achieves \\textit{asymptotic optimality} in terms of minimum mean square error. This approach is tailored for real-time SLAM and inertial-based odometry applications. Our first contribution is that we propose an iterative filtering method based on the Gauss-Newton method on Lie groups which is numerically to solve the estimation of states from a priori and non-linear measurements. The filtering stands out due to its iterative mechanism and adaptive initialization. Second, when dealing with environmental measurements of the surroundings, we utilize a $\\sqrt{n}$-consistent pose as the initial value for the update step in a single iteration. The solution is closed in form and has computational complexity $O(n)$. Third, we theoretically show that the approach can achieve asymptotic optimality in the sense of minimum mean square error from the a priori and virtual relative pose measurements (see Problem~\\ref{prob:new update problem}). Finally, to validate our method, we carry out extensive numerical and experimental evaluations. Our results consistently demonstrate that our approach outperforms other state-of-the-art filter-based methods, including the iterated extended Kalman filter and the invariant extended Kalman filter, in terms of accuracy and running time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05010",
        "abstract url": "https://arxiv.org/abs/2402.05010",
        "title": "Exhaust Gas Optimization of Modern Scooters by Velocity Control",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "This paper investigates the optimization of the exhaust gas composition by applying a velocity-controlled Throttle-by-Wire-System on modern 50 cc scooters (Euro 5). Nowadays combustion-powered scooters are still inefficiently restricted, resulting in an unreasonably high fuel consumption and unfavorable exhaust emissions. The velocity control prevents restriction by negatively shifting the ignition timing and regulates the throttle valve opening instead. Injection quantity, engine speed, ignition timing, cylinder wall temperature, exhaust gas temperature, oxygen sensor data, crankshaft position and in-cylinder pressure were acquired to measure engine parameters. At the same time, vehicle data on the CAN bus, such as throttle opening angle, the rider's acceleration command and vehicle velocity were recorded. For determination of the exhaust gas composition, five probes were sensing CO, CO2, NOx, O2 and HC in addition to the temperature and mass flow. A Peugeot Kisbee 50 4T (Euro 5) serves as test vehicle. The original and the optimized restriction were subjected to various gradients on a roller dynamometer at top speed. Thus, a statement can be made about all operating points of restriction. The resistance parameters required, were previously determined in a coast down test. When driving on level ground, a difference of 50% in the throttle opening leads to a 17% improvement in fuel economy. By measuring the engine parameters, optimum ignition timing could be proven with increasing internal cylinder pressure. Further, 17% reduction in exhaust gas flow was demonstrated. CO emissions decreased by a factor of 8.4, CO2 by 1.17 and HC by 2.1 while NOx increased by a factor of 3.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05027",
        "abstract url": "https://arxiv.org/abs/2402.05027",
        "title": "Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Graph-based environments pose unique challenges to multi-agent reinforcement learning. In decentralized approaches, agents operate within a given graph and make decisions based on partial or outdated observations. The size of the observed neighborhood limits the generalizability to different graphs and affects the reactivity of agents, the quality of the selected actions, and the communication overhead. This work focuses on generalizability and resolves the trade-off in observed neighborhood size with a continuous information flow in the whole graph. We propose a recurrent message-passing model that iterates with the environment's steps and allows nodes to create a global representation of the graph by exchanging messages with their neighbors. Agents receive the resulting learned graph observations based on their location in the graph. Our approach can be used in a decentralized manner at runtime and in combination with a reinforcement learning algorithm of choice. We evaluate our method across 1000 diverse graphs in the context of routing in communication networks and find that it enables agents to generalize and adapt to changes in the graph.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "Accepted at AAMAS 2024, version with appendix; revised sections 1 and 7, corrected table 1, final results unchanged"
    },
    {
        "paper id": "2402.05035",
        "abstract url": "https://arxiv.org/abs/2402.05035",
        "title": "A Survey on Domain Generalization for Medical Image Analysis",
        "rating": -1,
        "keywords": [
            [
                "Medical",
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical Image Analysis (MedIA) has emerged as a crucial tool in computer-aided diagnosis systems, particularly with the advancement of deep learning (DL) in recent years. However, well-trained deep models often experience significant performance degradation when deployed in different medical sites, modalities, and sequences, known as a domain shift issue. In light of this, Domain Generalization (DG) for MedIA aims to address the domain shift challenge by generalizing effectively and performing robustly across unknown data distributions. This paper presents the a comprehensive review of substantial developments in this area. First, we provide a formal definition of domain shift and domain generalization in medical field, and discuss several related settings. Subsequently, we summarize the recent methods from three viewpoints: data manipulation level, feature representation level, and model training level, and present some algorithms in detail for each viewpoints. Furthermore, we introduce the commonly used datasets. Finally, we summarize existing literature and present some potential research topics for the future. For this survey, we also created a GitHub project by collecting the supporting resources, at the link: https://github.com/Ziwei-Niu/DG_for_MedIA",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This is a withdrawn submission and will be considered invalid. Due to some errors and overlap with published papers, we have chosen to withdraw it"
    },
    {
        "paper id": "2402.05045",
        "abstract url": "https://arxiv.org/abs/2402.05045",
        "title": "Efficient Multi-Resolution Fusion for Remote Sensing Data with Label Uncertainty",
        "rating": -1,
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal sensor data fusion takes advantage of complementary or reinforcing information from each sensor and can boost overall performance in applications such as scene classification and target detection. This paper presents a new method for fusing multi-modal and multi-resolution remote sensor data without requiring pixel-level training labels, which can be difficult to obtain. Previously, we developed a Multiple Instance Multi-Resolution Fusion (MIMRF) framework that addresses label uncertainty for fusion, but it can be slow to train due to the large search space for the fuzzy measures used to integrate sensor data sources. We propose a new method based on binary fuzzy measures, which reduces the search space and significantly improves the efficiency of the MIMRF framework. We present experimental results on synthetic data and a real-world remote sensing detection task and show that the proposed MIMRF-BFM algorithm can effectively and efficiently perform multi-resolution fusion given remote sensing data with uncertainty.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "4 pages, 3 figures, 2 tables; Accepted to International Geoscience and Remote Sensing Symposium (IGARSS) 2023; Code available at https://github.com/hvak/MIMRF-BFM"
    },
    {
        "paper id": "2402.05054",
        "abstract url": "https://arxiv.org/abs/2402.05054",
        "title": "LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D content creation has achieved significant progress in terms of both quality and speed. Although current feed-forward models can produce 3D objects in seconds, their resolution is constrained by the intensive computation required during training. In this paper, we introduce Large Multi-View Gaussian Model (LGM), a novel framework designed to generate high-resolution 3D models from text prompts or single-view images. Our key insights are two-fold: 1) 3D Representation: We propose multi-view Gaussian features as an efficient yet powerful representation, which can then be fused together for differentiable rendering. 2) 3D Backbone: We present an asymmetric U-Net as a high-throughput backbone operating on multi-view images, which can be produced from text or single-view image input by leveraging multi-view diffusion models. Extensive experiments demonstrate the high fidelity and efficiency of our approach. Notably, we maintain the fast speed to generate 3D objects within 5 seconds while boosting the training resolution to 512, thereby achieving high-resolution 3D content generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://me.kiui.moe/lgm/"
    },
    {
        "paper id": "2402.05061",
        "abstract url": "https://arxiv.org/abs/2402.05061",
        "title": "$H_{\\infty}$-Optimal Estimator Synthesis for Coupled Linear 2D PDEs using Convex Optimization",
        "rating": -1,
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "Any suitably well-posed PDE in two spatial dimensions can be represented as a Partial Integral Equation (PIE) -- with system dynamics parameterized using Partial Integral (PI) operators. Furthermore, $L_2$-gain analysis of PDEs with a PIE representation can be posed as a linear operator inequality, which can be solved using convex optimization. In this paper, we use these results to derive a convex-optimization-based test for constructing an $H_{\\infty}$-optimal estimator for 2D PDEs. In particular, we first use PIEs to represent an arbitrary well-posed 2D PDE where sensor measurements occur along some boundary of the domain. We then parameterize an associated Luenberger-type estimator using a PI operator $\\mathcal{L}$ as the observer gain. Examining the error dynamics of this estimator, we prove that an upper bound on the $H_{\\infty}$-norm of these error dynamics can be minimized by solving a linear operator inequality on PI operator variables. Finally, we propose an analytical formula for inversion of 2D PI operators and use this formula to reconstruct the Luenberger gain $\\mathcal{L}$. We implement these results in the PIETOOLS software suite -- applying the methodology and simulating the resulting observer for an unstable 2D heat equation with boundary observations.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05064",
        "abstract url": "https://arxiv.org/abs/2402.05064",
        "title": "Tuning the feedback controller gains is a simple way to improve autonomous driving performance",
        "rating": -1,
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ]
        ],
        "abstract": "Typical autonomous driving systems are a combination of machine learning algorithms (often involving neural networks) and classical feedback controllers. Whilst significant progress has been made in recent years on the neural network side of these systems, only limited progress has been made on the feedback controller side. Often, the feedback control gains are simply passed from paper to paper with little re-tuning taking place, even though the changes to the neural networks can alter the vehicle's closed loop dynamics. The aim of this paper is to highlight the limitations of this approach; it is shown that re-tuning the feedback controller can be a simple way to improve autonomous driving performance. To demonstrate this, the PID gains of the longitudinal controller in the TCP autonomous vehicle algorithm are tuned. This causes the driving score in CARLA to increase from 73.21 to 77.38, with the results averaged over 16 driving scenarios. Moreover, it was observed that the performance benefits were most apparent during challenging driving scenarios, such as during rain or night time, as the tuned controller led to a more assertive driving style. These results demonstrate the value of developing both the neural network and feedback control policies of autonomous driving systems simultaneously, as this can be a simple and methodical way to improve autonomous driving system performance and robustness.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05066",
        "abstract url": "https://arxiv.org/abs/2402.05066",
        "title": "Exploration Without Maps via Zero-Shot Out-of-Distribution Deep Reinforcement Learning",
        "rating": -1,
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Operation of Autonomous Mobile Robots (AMRs) of all forms that include wheeled ground vehicles, quadrupeds and humanoids in dynamically changing GPS denied environments without a-priori maps, exclusively using onboard sensors, is an unsolved problem that has potential to transform the economy, and vastly improve humanity's capabilities with improvements to agriculture, manufacturing, disaster response, military and space exploration. Conventional AMR automation approaches are modularized into perception, motion planning and control which is computationally inefficient, and requires explicit feature extraction and engineering, that inhibits generalization, and deployment at scale. Few works have focused on real-world end-to-end approaches that directly map sensor inputs to control outputs due to the large amount of well curated training data required for supervised Deep Learning (DL) which is time consuming and labor intensive to collect and label, and sample inefficiency and challenges to bridging the simulation to reality gap using Deep Reinforcement Learning (DRL). This paper presents a novel method to efficiently train DRL for robust end-to-end AMR exploration, in a constrained environment at physical limits in simulation, transferred zero-shot to the real-world. The representation learned in a compact parameter space with 2 fully connected layers with 64 nodes each is demonstrated to exhibit emergent behavior for out-of-distribution generalization to navigation in new environments that include unstructured terrain without maps, and dynamic obstacle avoidance. The learned policy outperforms conventional navigation algorithms while consuming a fraction of the computation resources, enabling execution on a range of AMR forms with varying embedded computer payloads.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05079",
        "abstract url": "https://arxiv.org/abs/2402.05079",
        "title": "Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation",
        "rating": -1,
        "keywords": [
            [
                "Medical",
                "MRI",
                "CT",
                "Cardiac"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "In recent advancements in medical image analysis, Convolutional Neural Networks (CNN) and Vision Transformers (ViT) have set significant benchmarks. While the former excels in capturing local features through its convolution operations, the latter achieves remarkable global context understanding by leveraging self-attention mechanisms. However, both architectures exhibit limitations in efficiently modeling long-range dependencies within medical images, which is a critical aspect for precise segmentation. Inspired by the Mamba architecture, known for its proficiency in handling long sequences and global contextual information with enhanced computational efficiency as a State Space Model (SSM), we propose Mamba-UNet, a novel architecture that synergizes the U-Net in medical image segmentation with Mamba's capability. Mamba-UNet adopts a pure Visual Mamba (VMamba)-based encoder-decoder structure, infused with skip connections to preserve spatial information across different scales of the network. This design facilitates a comprehensive feature learning process, capturing intricate details and broader semantic contexts within medical images. We introduce a novel integration mechanism within the VMamba blocks to ensure seamless connectivity and information flow between the encoder and decoder paths, enhancing the segmentation performance. We conducted experiments on publicly available ACDC MRI Cardiac segmentation dataset, and Synapse CT Abdomen segmentation dataset. The results show that Mamba-UNet outperforms several types of UNet in medical image segmentation under the same hyper-parameter setting. The source code and baseline implementations are available.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05088",
        "abstract url": "https://arxiv.org/abs/2402.05088",
        "title": "Domination and packing in graphs",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Given a graph~$G$, the domination number, denoted by~$\u03b3(G)$, is the minimum cardinality of a dominating set in~$G$. Dual to the notion of domination number is the packing number of a graph. A packing of~$G$ is a set of vertices whose pairwise distance is at least three. The packing number~$\u03c1(G)$ of~$G$ is the maximum cardinality of one such set. Furthermore, the inequality~$\u03c1(G) \\leq \u03b3(G)$ is well-known. Henning et al.\\ conjectured that~$\u03b3(G) \\leq 2\u03c1(G)+1$ if~$G$ is subcubic. In this paper, we progress towards this conjecture by showing that~${\u03b3(G) \\leq \\frac{120}{49}\u03c1(G)}$ if~$G$ is a bipartite cubic graph. We also show that $\u03b3(G) \\leq 3\u03c1(G)$ if~$G$ is a maximal outerplanar graph, and that~$\u03b3(G) \\leq 2\u03c1(G)$ if~$G$ is a biconvex graph. Moreover, in the last case, we show that this upper bound is tight.",
        "subjects": [
            "math.CO"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2402.05159",
        "abstract url": "https://arxiv.org/abs/2402.05159",
        "title": "Threats and Limitations of Terrestrial Broadcast Attacks",
        "rating": -1,
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "The DVB standard does not mandate the use of authentication and integrity protection for transport streams. This allows malicious third parties to replace legitimate broadcasts by overpowering terrestrial transmissions. The rogue signal can then deliver a malicious broadcast stream to exploit security vulnerabilities on Smart TVs (STVs) in range. We implemented a proof-of-concept attack based on a malicious Hybrid Broadcast Broadband TV app, able to acquire permanent system-level access to an STV over the air, in less than 10 s. These attacks, however, are severely limited in range due to required co-channel protection ratios (CCPRs), which is in direct contradiction to previous publications. We present evidence for these limitations in form of laboratory experiments, extensive simulations, and field measurements. To this end, we developed an automated, low-cost method for CCPR determination, as well as a method for non-disruptive attack range measurements based on a gap filler and the resulting channel impulse response.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2402.05164",
        "abstract url": "https://arxiv.org/abs/2402.05164",
        "title": "A Resource Model For Neural Scaling Law",
        "rating": -1.0,
        "keywords": [
            [
                "diagnosing"
            ],
            [
                "cs.LG"
            ],
            [
                "workshop",
                "ICLR"
            ]
        ],
        "abstract": "Neural scaling laws characterize how model performance improves as the model size scales up. Inspired by empirical observations, we introduce a resource model of neural scaling. A task is usually composite hence can be decomposed into many subtasks, which compete for resources (measured by the number of neurons allocated to subtasks). On toy problems, we empirically find that: (1) The loss of a subtask is inversely proportional to its allocated neurons. (2) When multiple subtasks are present in a composite task, the resources acquired by each subtask uniformly grow as models get larger, keeping the ratios of acquired resources constants. We hypothesize these findings to be generally true and build a model to predict neural scaling laws for general composite tasks, which successfully replicates the neural scaling law of Chinchilla models reported in arXiv:2203.15556. We believe that the notion of resource used in this paper will be a useful tool for characterizing and diagnosing neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 8 figures, Under review as a workshop paper at ICLR 2024"
    },
    {
        "paper id": "2402.05187",
        "abstract url": "https://arxiv.org/abs/2402.05187",
        "title": "Meta-learning the mirror map in policy mirror descent",
        "rating": -1,
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. By applying a meta-learning approach, we identify more efficient mirror maps that enhance performance, both on average and in terms of best performance achieved along the training trajectory. We analyze the characteristics of these learned mirror maps and reveal shared traits among certain settings. Our results suggest that mirror maps have the potential to be adaptable across various environments, raising questions about how to best match a mirror map to an environment's structure and characteristics.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05206",
        "abstract url": "https://arxiv.org/abs/2402.05206",
        "title": "Giving Robots a Voice: Human-in-the-Loop Voice Creation and open-ended Labeling",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Speech is a natural interface for humans to interact with robots. Yet, aligning a robot's voice to its appearance is challenging due to the rich vocabulary of both modalities. Previous research has explored a few labels to describe robots and tested them on a limited number of robots and existing voices. Here, we develop a robot-voice creation tool followed by large-scale behavioral human experiments (N=2,505). First, participants collectively tune robotic voices to match 175 robot images using an adaptive human-in-the-loop pipeline. Then, participants describe their impression of the robot or their matched voice using another human-in-the-loop paradigm for open-ended labeling. The elicited taxonomy is then used to rate robot attributes and to predict the best voice for an unseen robot. We offer a web interface to aid engineers in customizing robot voices, demonstrating the synergy between cognitive science and machine learning for engineering tools.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to CHI 2024, May 11 to 16, 2024, Honolulu, HI, USA"
    },
    {
        "paper id": "2402.05211",
        "abstract url": "https://arxiv.org/abs/2402.05211",
        "title": "A Maturity Model for Urban Dataset Meta-data",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In the current environment of data generation and publication, there is an ever-growing number of datasets available for download. This growth precipitates an existing challenge: sourcing and integrating relevant datasets for analysis is becoming more complex. Despite efforts by open data platforms, obstacles remain, predominantly rooted in inadequate metadata, unsuitable data presentation, complications in pinpointing desired data, and data integration. This paper delves into the intricacies of dataset retrieval, emphasizing the pivotal role of metadata in aligning datasets with user queries. Through an exploration of existing literature, it underscores prevailing issues such as the identification of valuable metadata and the development of tools to maintain and annotate them effectively. The central contribution of this research is the proposition of a dataset metadata maturity model. Deriving inspiration from software engineering maturity models, this framework delineates a progression from rudimentary metadata documentation to advanced levels, aiding dataset creators in their documentation efforts. The model encompasses seven pivotal dimensions, spanning content to quality information, each stratified across six maturity levels to guide the optimal documentation of datasets, ensuring ease of discovery, relevance assessment, and comprehensive dataset understanding. This paper also incorporates the maturity model into a data cataloguing tool called CKAN through a custom plugin, CKANext-udc. The plugin introduces custom fields based on different maturity levels, allows for user interface customisation, and integrates with a graph database, converting catalogue data into a knowledge graph based on the Maturity Model ontology.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05224",
        "abstract url": "https://arxiv.org/abs/2402.05224",
        "title": "VerAs: Verify then Assess STEM Lab Reports",
        "rating": -1,
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "With an increasing focus in STEM education on critical thinking skills, science writing plays an ever more important role in curricula that stress inquiry skills. A recently published dataset of two sets of college level lab reports from an inquiry-based physics curriculum relies on analytic assessment rubrics that utilize multiple dimensions, specifying subject matter knowledge and general components of good explanations. Each analytic dimension is assessed on a 6-point scale, to provide detailed feedback to students that can help them improve their science writing skills. Manual assessment can be slow, and difficult to calibrate for consistency across all students in large classes. While much work exists on automated assessment of open-ended questions in STEM subjects, there has been far less work on long-form writing such as lab reports. We present an end-to-end neural architecture that has separate verifier and assessment modules, inspired by approaches to Open Domain Question Answering (OpenQA). VerAs first verifies whether a report contains any content relevant to a given rubric dimension, and if so, assesses the relevant sentences. On the lab reports, VerAs outperforms multiple baselines based on OpenQA systems or Automated Essay Scoring (AES). VerAs also performs well on an analytic rubric for middle school physics essays.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "It is accepted to AIED2024!"
    },
    {
        "paper id": "2402.05235",
        "abstract url": "https://arxiv.org/abs/2402.05235",
        "title": "SPAD : Spatially Aware Multiview Diffusers",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present SPAD, a novel approach for creating consistent multi-view images from text prompts or single images. To enable multi-view generation, we repurpose a pretrained 2D diffusion model by extending its self-attention layers with cross-view interactions, and fine-tune it on a high quality subset of Objaverse. We find that a naive extension of the self-attention proposed in prior work (e.g. MVDream) leads to content copying between views. Therefore, we explicitly constrain the cross-view attention based on epipolar geometry. To further enhance 3D consistency, we utilize Plucker coordinates derived from camera rays and inject them as positional encoding. This enables SPAD to reason over spatial proximity in 3D well. In contrast to recent works that can only generate views at fixed azimuth and elevation, SPAD offers full camera control and achieves state-of-the-art results in novel view synthesis on unseen objects from the Objaverse and Google Scanned Objects datasets. Finally, we demonstrate that text-to-3D generation using SPAD prevents the multi-face Janus issue. See more details at our webpage: https://yashkant.github.io/spad",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Webpage: https://yashkant.github.io/spad"
    },
    {
        "paper id": "2402.05239",
        "abstract url": "https://arxiv.org/abs/2402.05239",
        "title": "Efficient approximate unitary designs from random Pauli rotations",
        "rating": -1,
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "We construct random walks on simple Lie groups that quickly converge to the Haar measure for all moments up to order $t$. Specifically, a step of the walk on the unitary or orthognoal group of dimension $2^{\\mathsf n}$ is a random Pauli rotation $e^{\\mathrm i \u03b8P /2}$. The spectral gap of this random walk is shown to be $\u03a9(1/t)$, which coincides with the best previously known bound for a random walk on the permutation group on $\\{0,1\\}^{\\mathsf n}$. This implies that the walk gives an $\\varepsilon$-approximate unitary $t$-design in depth $O(\\mathsf n t^2 + t \\log 1/\\varepsilon)d$ where $d=O(\\log \\mathsf n)$ is the circuit depth to implement $e^{\\mathrm i \u03b8P /2}$. Our simple proof uses quadratic Casimir operators of Lie algebras.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "21 pages, 1 figure"
    },
    {
        "paper id": "2402.05254",
        "abstract url": "https://arxiv.org/abs/2402.05254",
        "title": "Online and Certifiably Correct Visual Odometry and Mapping",
        "rating": -1,
        "keywords": [
            [
                "RGBD"
            ]
        ],
        "abstract": "This paper proposes two new algorithms for certified perception in safety-critical robotic applications. The first is a Certified Visual Odometry algorithm, which uses a RGBD camera with bounded sensor noise to construct a visual odometry estimate with provable error bounds. The second is a Certified Mapping algorithm which, using the same RGBD images, constructs a Signed Distance Field of the obstacle environment, always safely underestimating the distance to the nearest obstacle. This is required to avoid errors due to VO drift. The algorithms are demonstrated in hardware experiments, where we demonstrate both running online at 30FPS. The methods are also compared to state-of-the-art techniques for odometry and mapping.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2402.05276",
        "abstract url": "https://arxiv.org/abs/2402.05276",
        "title": "Spreading Information via Social Networks: An Irrelevance Result",
        "rating": -1,
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "An informed planner wishes to spread information among a group of agents in order to induce efficient coordination -- say the adoption of a new technology with positive externalities. The agents are connected via a social network. The planner informs a seed and then the information spreads via the network. While the structure of the network affects the rate of diffusion, we show that the rate of adoption is the same for all acyclic networks.",
        "subjects": [
            "econ.TH"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05305",
        "abstract url": "https://arxiv.org/abs/2402.05305",
        "title": "Knowledge Distillation for Road Detection based on cross-model Semi-Supervised Learning",
        "rating": -1,
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The advancement of knowledge distillation has played a crucial role in enabling the transfer of knowledge from larger teacher models to smaller and more efficient student models, and is particularly beneficial for online and resource-constrained applications. The effectiveness of the student model heavily relies on the quality of the distilled knowledge received from the teacher. Given the accessibility of unlabelled remote sensing data, semi-supervised learning has become a prevalent strategy for enhancing model performance. However, relying solely on semi-supervised learning with smaller models may be insufficient due to their limited capacity for feature extraction. This limitation restricts their ability to exploit training data. To address this issue, we propose an integrated approach that combines knowledge distillation and semi-supervised learning methods. This hybrid approach leverages the robust capabilities of large models to effectively utilise large unlabelled data whilst subsequently providing the small student model with rich and informative features for enhancement. The proposed semi-supervised learning-based knowledge distillation (SSLKD) approach demonstrates a notable improvement in the performance of the student model, in the application of road segmentation, surpassing the effectiveness of traditional semi-supervised learning methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05317",
        "abstract url": "https://arxiv.org/abs/2402.05317",
        "title": "Emerging Results on Automated Support for Searching and Selecting Evidence for Systematic Literature Review Updates",
        "rating": -1,
        "keywords": [
            [
                "Support Vector Machine"
            ]
        ],
        "abstract": "Context: The constant growth of primary evidence and Systematic Literature Reviews (SLRs) publications in the Software Engineering (SE) field leads to the need for SLR Updates. However, searching and selecting evidence for SLR updates demands significant effort from SE researchers. Objective: We present emerging results on an automated approach to support searching and selecting studies for SLR updates in SE. Method: We developed an automated tool prototype to perform the snowballing search technique and support selecting relevant studies for SLR updates using Machine Learning (ML) algorithms. We evaluated our automation proposition through a small-scale evaluation with a reliable dataset from an SLR replication and its update. Results: Effectively automating snowballing-based search strategies showed feasibility with minor losses, specifically related to papers without Digital Object Identifier (DOI). The ML algorithm giving the highest performance to select studies for SLR updates was Linear Support Vector Machine, with approximately 74% recall and 15% precision. Using such algorithms with conservative thresholds to minimize the risk of missing papers can significantly reduce evidence selection efforts. Conclusion: The preliminary results of our evaluation point in promising directions, indicating the potential of automating snowballing search efforts and of reducing the number of papers to be manually analyzed by about 2.5 times when selecting evidence for updating SLRs in SE.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05318",
        "abstract url": "https://arxiv.org/abs/2402.05318",
        "title": "Navigating the Knowledge Sea: Planet-scale answer retrieval using LLMs",
        "rating": -1,
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Information retrieval is a rapidly evolving field of information retrieval, which is characterized by a continuous refinement of techniques and technologies, from basic hyperlink-based navigation to sophisticated algorithm-driven search engines. This paper aims to provide a comprehensive overview of the evolution of Information Retrieval Technology, with a particular focus on the role of Large Language Models (LLMs) in bridging the gap between traditional search methods and the emerging paradigm of answer retrieval. The integration of LLMs in the realms of response retrieval and indexing signifies a paradigm shift in how users interact with information systems. This paradigm shift is driven by the integration of large language models (LLMs) like GPT-4, which are capable of understanding and generating human-like text, thus enabling them to provide more direct and contextually relevant answers to user queries. Through this exploration, we seek to illuminate the technological milestones that have shaped this journey and the potential future directions in this rapidly changing field.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05357",
        "abstract url": "https://arxiv.org/abs/2402.05357",
        "title": "Dynamic Geometric Connectivity in the Plane with Constant Query Time",
        "rating": -1,
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We present the first fully dynamic connectivity data structures for geometric intersection graphs achieving constant query time and sublinear amortized update time for most types of geometric objects in 2D. Our data structures can answer connectivity queries between two objects, as well as \"global\" connectivity queries (e.g., deciding whether the entire graph is connected). Previously, the data structure by Afshani and Chan (ESA'06) achieved such bounds only in the special case of axis-aligned line segments or rectangles but did not work for arbitrary line segments or disks, whereas the data structures by Chan, P\u0103tra\u015fcu and Roditty (FOCS'08) worked for more general classes of geometric objects but required $n^{\u03a9(1)}$ query time and could not handle global connectivity queries. Specifically, we obtain new data structures with $O(1)$ query time and amortized update time near $n^{4/5}$, $n^{7/8}$, and $n^{20/21}$ for axis-aligned line segments, disks, and arbitrary line segments respectively. Besides greatly reducing the query time, our data structures also improve the previous update times for axis-aligned line segments by Afshani and Chan (from near $n^{10/11}$ to $n^{4/5}$) and for disks by Chan, P\u0103tra\u015fcu, and Roditty (from near $n^{20/21}$ to $n^{7/8}$).",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05373",
        "abstract url": "https://arxiv.org/abs/2402.05373",
        "title": "Unleashing the Infinity Power of Geometry: A Novel Geometry-Aware Transformer (GOAT) for Whole Slide Histopathology Image Analysis",
        "rating": -1,
        "keywords": [
            [
                "diagnosis",
                "Whole Slide",
                "disease",
                "tumor",
                "pathological"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The histopathology analysis is of great significance for the diagnosis and prognosis of cancers, however, it has great challenges due to the enormous heterogeneity of gigapixel whole slide images (WSIs) and the intricate representation of pathological features. However, recent methods have not adequately exploited geometrical representation in WSIs which is significant in disease diagnosis. Therefore, we proposed a novel weakly-supervised framework, Geometry-Aware Transformer (GOAT), in which we urge the model to pay attention to the geometric characteristics within the tumor microenvironment which often serve as potent indicators. In addition, a context-aware attention mechanism is designed to extract and enhance the morphological features within WSIs.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "5 pages, 3 figures. Accepted by 21st IEEE International Symposium on Biomedical Imaging (ISBI 2024)"
    },
    {
        "paper id": "2402.05378",
        "abstract url": "https://arxiv.org/abs/2402.05378",
        "title": "Graph Neural Networks for Physical-Layer Security in Multi-User Flexible-Duplex Networks",
        "rating": -1,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ]
        ],
        "abstract": "This paper explores Physical-Layer Security (PLS) in Flexible Duplex (FlexD) networks, considering scenarios involving eavesdroppers. Our investigation revolves around the intricacies of the sum secrecy rate maximization problem, particularly when faced with coordinated and distributed eavesdroppers employing a Minimum Mean Square Error (MMSE) receiver. Our contributions include an iterative classical optimization solution and an unsupervised learning strategy based on Graph Neural Networks (GNNs). To the best of our knowledge, this work marks the initial exploration of GNNs for PLS applications. Additionally, we extend the GNN approach to address the absence of eavesdroppers' channel knowledge. Extensive numerical simulations highlight FlexD's superiority over Half-Duplex (HD) communications and the GNN approach's superiority over the classical method in both performance and time complexity.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05387",
        "abstract url": "https://arxiv.org/abs/2402.05387",
        "title": "Can Channels be Fully Inferred Between Two Antenna Panels?",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This letter considers a two-panel massive multiple-input multiple-output (MIMO) communication system, where the base station (BS) is equipped with two antenna panels that may use different frequency bands for communication. By exploiting the geometric relationships between antenna panels, efficient channel inference methods across antenna panels are proposed to reduce the overhead of real-time channel estimation. Four scenarios are considered, namely far-field free-space, near-field free-space, multi-path sharing far-field scatterers, and multi-path sharing near-field scatterers. For both far-field and near-field free-space scenarios, we show that the channel of one panel can be fully inferred from that of the other panel, as long as the multi-path components (MPCs) composing the channel can be resolved. On the other hand, for the multi-path scenarios sharing far-field or near-field scatterers, only the angles or range of angles of the MPCs can be inferred, respectively. Simulation results based on commercial 3D ray-tracing software are presented to validate our developed channel inference techniques.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "5 pages, 6figures, IEEE Communications Letters"
    },
    {
        "paper id": "2402.05399",
        "abstract url": "https://arxiv.org/abs/2402.05399",
        "title": "CURE: Simulation-Augmented Auto-Tuning in Robotics",
        "rating": -1,
        "keywords": [
            [
                "Robotics",
                "robot",
                "navigation"
            ]
        ],
        "abstract": "Robotic systems are typically composed of various subsystems, such as localization and navigation, each encompassing numerous configurable components (e.g., selecting different planning algorithms). Once an algorithm has been selected for a component, its associated configuration options must be set to the appropriate values. Configuration options across the system stack interact non-trivially. Finding optimal configurations for highly configurable robots to achieve desired performance poses a significant challenge due to the interactions between configuration options across software and hardware that result in an exponentially large and complex configuration space. These challenges are further compounded by the need for transferability between different environments and robotic platforms. Data efficient optimization algorithms (e.g., Bayesian optimization) have been increasingly employed to automate the tuning of configurable parameters in cyber-physical systems. However, such optimization algorithms converge at later stages, often after exhausting the allocated budget (e.g., optimization steps, allotted time) and lacking transferability. This paper proposes CURE -- a method that identifies causally relevant configuration options, enabling the optimization process to operate in a reduced search space, thereby enabling faster optimization of robot performance. CURE abstracts the causal relationships between various configuration options and robot performance objectives by learning a causal model in the source (a low-cost environment such as the Gazebo simulator) and applying the learned knowledge to perform optimization in the target (e.g., Turtlebot 3 physical robot). We demonstrate the effectiveness and transferability of CURE by conducting experiments that involve varying degrees of deployment changes in both physical robots and simulation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted in IEEE Transactions on Robotics (T-RO), 2024"
    },
    {
        "paper id": "2402.05402",
        "abstract url": "https://arxiv.org/abs/2402.05402",
        "title": "A State-of-the-art Survey on Full-duplex Network Design",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Full-duplex (FD) technology is gaining popularity for integration into a wide range of wireless networks due to its demonstrated potential in recent studies. In contrast to half-duplex (HD) technology, the implementation of FD in networks necessitates considering inter-node interference (INI) from various network perspectives. When deploying FD technology in networks, several critical factors must be taken into account. These include self-interference (SI) and the requisite SI cancellation (SIC) processes, as well as the selection of multiple user equipment (UE) per time slot. Additionally, inter-node interference (INI), including cross-link interference (CLI) and inter-cell interference (ICI), become crucial issues during concurrent uplink (UL) and downlink (DL) transmission and reception, similar to SI. Since most INI is challenging to eliminate, a comprehensive investigation that covers radio resource control (RRC), medium access control (MAC), and the physical layer (PHY) is essential in the context of FD network design, rather than focusing on individual network layers and types. This paper covers state-of-the-art studies, including protocols and documents from 3GPP for FD, MAC protocol, user scheduling, and CLI handling. The methods are also compared through a network-level system simulation based on 3D ray-tracing.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "23 pages, 10 figures, To appear in Proceedings of the IEEE"
    },
    {
        "paper id": "2402.06674",
        "abstract url": "https://arxiv.org/abs/2402.06674",
        "title": "Understanding Practical Membership Privacy of Deep Learning",
        "rating": -1,
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "We apply a state-of-the-art membership inference attack (MIA) to systematically test the practical privacy vulnerability of fine-tuning large image classification models.We focus on understanding the properties of data sets and samples that make them vulnerable to membership inference. In terms of data set properties, we find a strong power law dependence between the number of examples per class in the data and the MIA vulnerability, as measured by true positive rate of the attack at a low false positive rate. For an individual sample, large gradients at the end of training are strongly correlated with MIA vulnerability.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "21 pages, 8 figures"
    },
    {
        "paper id": "2402.10100",
        "abstract url": "https://arxiv.org/abs/2402.10100",
        "title": "Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data",
        "rating": -1,
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "This study assesses deep learning models for audio classification in a clinical setting with the constraint of small datasets reflecting real-world prospective data collection. We analyze CNNs, including DenseNet and ConvNeXt, alongside transformer models like ViT, SWIN, and AST, and compare them against pre-trained audio models such as YAMNet and VGGish. Our method highlights the benefits of pre-training on large datasets before fine-tuning on specific clinical data. We prospectively collected two first-of-their-kind patient audio datasets from stroke patients. We investigated various preprocessing techniques, finding that RGB and grayscale spectrogram transformations affect model performance differently based on the priors they learn from pre-training. Our findings indicate CNNs can match or exceed transformer models in small dataset contexts, with DenseNet-Contrastive and AST models showing notable performance. This study highlights the significance of incremental marginal gains through model selection, pre-training, and preprocessing in sound classification; this offers valuable insights for clinical diagnostics that rely on audio classification.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "CHIL 2024"
    },
    {
        "paper id": "2402.10940",
        "abstract url": "https://arxiv.org/abs/2402.10940",
        "title": "Neural machine translation of clinical procedure codes for medical diagnosis and uncertainty quantification",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "diagnosis",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "A Clinical Decision Support System (CDSS) is designed to enhance clinician decision-making by combining system-generated recommendations with medical expertise. Given the high costs, intensive labor, and time-sensitive nature of medical treatments, there is a pressing need for efficient decision support, especially in complex emergency scenarios. In these scenarios, where information can be limited, an advanced CDSS framework that leverages AI (artificial intelligence) models to effectively reduce diagnostic uncertainty has utility. Such an AI-enabled CDSS framework with quantified uncertainty promises to be practical and beneficial in the demanding context of real-world medical care. In this study, we introduce the concept of Medical Entropy, quantifying uncertainties in patient outcomes predicted by neural machine translation based on the ICD-9 code of procedures. Our experimental results not only show strong correlations between procedure and diagnosis sequences based on the simple ICD-9 code but also demonstrate the promising capacity to model trends of uncertainties during hospitalizations through a data-driven approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.15391",
        "abstract url": "https://arxiv.org/abs/2403.15391",
        "title": "CapsF: Capsule Fusion for Extracting psychiatric stressors for suicide from twitter",
        "rating": -1,
        "keywords": [
            [
                "cancer",
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Along with factors such as cancer, blood pressure, street accidents and stroke, suicide has been one of Iran main causes of death. One of the main reasons for suicide is psychological stressors. Identifying psychological stressors in an at risk population can help in the early prevention of suicidal and suicidal behaviours. In recent years, the widespread popularity and flow of real time information sharing of social media have allowed for potential early intervention in large scale and even small scale populations. However, some automated approaches to extract psychiatric stressors from Twitter have been presented, but most of this research has been for non Persian languages. This study aims to investigate the techniques of detecting psychological stress related to suicide from Persian tweets using learning based methods. The proposed capsule based approach achieved a binary classification accuracy of 0.83.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02292",
        "abstract url": "https://arxiv.org/abs/2405.02292",
        "title": "ALOHA 2: An Enhanced Low-Cost Hardware for Bimanual Teleoperation",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Diverse demonstration datasets have powered significant advances in robot learning, but the dexterity and scale of such data can be limited by the hardware cost, the hardware robustness, and the ease of teleoperation. We introduce ALOHA 2, an enhanced version of ALOHA that has greater performance, ergonomics, and robustness compared to the original design. To accelerate research in large-scale bimanual manipulation, we open source all hardware designs of ALOHA 2 with a detailed tutorial, together with a MuJoCo model of ALOHA 2 with system identification. See the project website at aloha-2.github.io.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Project website: aloha-2.github.io"
    },
    {
        "paper id": "2402.04668",
        "abstract url": "https://arxiv.org/abs/2402.04668",
        "title": "A Perspective on Individualized Treatment Effects Estimation from Time-series Health Data",
        "rating": -1.5,
        "keywords": [
            [
                "medical",
                "Health",
                "Healthcare",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The burden of diseases is rising worldwide, with unequal treatment efficacy for patient populations that are underrepresented in clinical trials. Healthcare, however, is driven by the average population effect of medical treatments and, therefore, operates in a \"one-size-fits-all\" approach, not necessarily what best fits each patient. These facts suggest a pressing need for methodologies to study individualized treatment effects (ITE) to drive personalized treatment. Despite the increased interest in machine-learning-driven ITE estimation models, the vast majority focus on tabular data with limited review and understanding of methodologies proposed for time-series electronic health records (EHRs). To this end, this work provides an overview of ITE works for time-series data and insights into future research. The work summarizes the latest work in the literature and reviews it in light of theoretical assumptions, types of treatment settings, and computational frameworks. Furthermore, this work discusses challenges and future research directions for ITEs in a time-series setting. We hope this work opens new directions and serves as a resource for understanding one of the exciting yet under-studied research areas.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04676",
        "abstract url": "https://arxiv.org/abs/2402.04676",
        "title": "Group Distributionally Robust Dataset Distillation with Risk Minimization",
        "rating": -1.5,
        "keywords": [
            [
                "federated learning"
            ],
            [
                "architecture search"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Dataset distillation (DD) has emerged as a widely adopted technique for crafting a synthetic dataset that captures the essential information of a training dataset, facilitating the training of accurate neural models. Its applications span various domains, including transfer learning, federated learning, and neural architecture search. The most popular methods for constructing the synthetic data rely on matching the convergence properties of training the model with the synthetic dataset and the training dataset. However, targeting the training dataset must be thought of as auxiliary in the same sense that the training set is an approximate substitute for the population distribution, and the latter is the data of interest. Yet despite its popularity, an aspect that remains unexplored is the relationship of DD to its generalization, particularly across uncommon subgroups. That is, how can we ensure that a model trained on the synthetic dataset performs well when faced with samples from regions with low population density? Here, the representativeness and coverage of the dataset become salient over the guaranteed training error at inference. Drawing inspiration from distributionally robust optimization, we introduce an algorithm that combines clustering with the minimization of a risk measure on the loss to conduct DD. We provide a theoretical rationale for our approach and demonstrate its effective generalization and robustness across subgroups through numerical experiments. The source code is available in https://github.com/Mming11/RobustDatasetDistillation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04717",
        "abstract url": "https://arxiv.org/abs/2402.04717",
        "title": "InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior",
        "rating": -1.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "Synthesis"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Comprehending natural language instructions is a charming property for 3D indoor scene synthesis systems. Existing methods directly model object joint distributions and express object relations implicitly within a scene, thereby hindering the controllability of generation. We introduce InstructScene, a novel generative framework that integrates a semantic graph prior and a layout decoder to improve controllability and fidelity for 3D scene synthesis. The proposed semantic graph prior jointly learns scene appearances and layout distributions, exhibiting versatility across various downstream tasks in a zero-shot manner. To facilitate the benchmarking for text-driven 3D scene synthesis, we curate a high-quality dataset of scene-instruction pairs with large language and multimodal models. Extensive experimental results reveal that the proposed method surpasses existing state-of-the-art approaches by a large margin. Thorough ablation studies confirm the efficacy of crucial design components. Project page: https://chenguolin.github.io/projects/InstructScene.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2024 for spotlight presentation; Project page: https://chenguolin.github.io/projects/InstructScene"
    },
    {
        "paper id": "2402.04821",
        "abstract url": "https://arxiv.org/abs/2402.04821",
        "title": "E(3)-Equivariant Mesh Neural Networks",
        "rating": -1.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Triangular meshes are widely used to represent three-dimensional objects. As a result, many recent works have address the need for geometric deep learning on 3D mesh. However, we observe that the complexities in many of these architectures does not translate to practical performance, and simple deep models for geometric graphs are competitive in practice. Motivated by this observation, we minimally extend the update equations of E(n)-Equivariant Graph Neural Networks (EGNNs) (Satorras et al., 2021) to incorporate mesh face information, and further improve it to account for long-range interactions through hierarchy. The resulting architecture, Equivariant Mesh Neural Network (EMNN), outperforms other, more complicated equivariant methods on mesh tasks, with a fast run-time and no expensive pre-processing. Our implementation is available at https://github.com/HySonLab/EquiMesh",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04830",
        "abstract url": "https://arxiv.org/abs/2402.04830",
        "title": "Closing the Gap Between SGP4 and High-Precision Propagation via Differentiable Programming",
        "rating": -1.5,
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Simplified General Perturbations 4 (SGP4) orbital propagation method is widely used for predicting the positions and velocities of Earth-orbiting objects rapidly and reliably. Despite continuous refinement, SGP models still lack the precision of numerical propagators, which offer significantly smaller errors. This study presents dSGP4, a novel differentiable version of SGP4 implemented using PyTorch. By making SGP4 differentiable, dSGP4 facilitates various space-related applications, including spacecraft orbit determination, state conversion, covariance transformation, state transition matrix computation, and covariance propagation. Additionally, dSGP4's PyTorch implementation allows for embarrassingly parallel orbital propagation across batches of Two-Line Element Sets (TLEs), leveraging the computational power of CPUs, GPUs, and advanced hardware for distributed prediction of satellite positions at future times. Furthermore, dSGP4's differentiability enables integration with modern machine learning techniques. Thus, we propose a novel orbital propagation paradigm, ML-dSGP4, where neural networks are integrated into the orbital propagator. Through stochastic gradient descent, this combined model's inputs, outputs, and parameters can be iteratively refined, surpassing SGP4's precision. Neural networks act as identity operators by default, adhering to SGP4's behavior. However, dSGP4's differentiability allows fine-tuning with ephemeris data, enhancing precision while maintaining computational speed. This empowers satellite operators and researchers to train the model using specific ephemeris or high-precision numerical propagation data, significantly advancing orbital prediction capabilities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04852",
        "abstract url": "https://arxiv.org/abs/2402.04852",
        "title": "Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning",
        "rating": -1.5,
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we present aLLM4TS, an innovative framework that adapts Large Language Models (LLMs) for time-series representation learning. Central to our approach is that we reconceive time-series forecasting as a self-supervised, multi-patch prediction task, which, compared to traditional contrastive learning or mask-and-reconstruction methods, captures temporal dynamics in patch representations more effectively. Our strategy encompasses two-stage training: (i). a causal continual pre-training phase on various time-series datasets, anchored on next patch prediction, effectively syncing LLM capabilities with the intricacies of time-series data; (ii). fine-tuning for multi-patch prediction in the targeted time-series context. A distinctive element of our framework is the patch-wise decoding layer, which departs from previous methods reliant on sequence-level decoding. Such a design directly transposes individual patches into temporal sequences, thereby significantly bolstering the model's proficiency in mastering temporal patch-based representations. aLLM4TS demonstrates superior performance in several downstream tasks, proving its effectiveness in deriving temporal representations with enhanced transferability and marking a pivotal advancement in the adaptation of LLMs for time-series analysis.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04924",
        "abstract url": "https://arxiv.org/abs/2402.04924",
        "title": "Two Trades is not Baffled: Condensing Graph via Crafting Rational Gradient Matching",
        "rating": -1.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have raised growing concerns. As one of the most promising directions, graph condensation methods address these issues by employing gradient matching, aiming to condense the full graph into a more concise yet information-rich synthetic set. Though encouraging, these strategies primarily emphasize matching directions of the gradients, which leads to deviations in the training trajectories. Such deviations are further magnified by the differences between the condensation and evaluation phases, culminating in accumulated errors, which detrimentally affect the performance of the condensed graphs. In light of this, we propose a novel graph condensation method named \\textbf{C}raf\\textbf{T}ing \\textbf{R}ationa\\textbf{L} trajectory (\\textbf{CTRL}), which offers an optimized starting point closer to the original dataset's feature distribution and a more refined strategy for gradient matching. Theoretically, CTRL can effectively neutralize the impact of accumulated errors on the performance of condensed graphs. We provide extensive experiments on various graph datasets and downstream tasks to support the effectiveness of CTRL. Code is released at https://github.com/NUS-HPC-AI-Lab/CTRL.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "An effective method for graph condensation"
    },
    {
        "paper id": "2402.04933",
        "abstract url": "https://arxiv.org/abs/2402.04933",
        "title": "A Bayesian Approach to Online Learning for Contextual Restless Bandits with Applications to Public Health",
        "rating": -1.5,
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Restless multi-armed bandits (RMABs) are used to model sequential resource allocation in public health intervention programs. In these settings, the underlying transition dynamics are often unknown a priori, requiring online reinforcement learning (RL). However, existing methods in online RL for RMABs cannot incorporate properties often present in real-world public health applications, such as contextual information and non-stationarity. We present Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs that novelly combines techniques in Bayesian modeling with Thompson sampling to flexibly model a wide range of complex RMAB settings, such as contextual and non-stationary RMABs. A key contribution of our approach is its ability to leverage shared information within and between arms to learn unknown RMAB transition dynamics quickly in budget-constrained settings with relatively short time horizons. Empirically, we show that BCoR achieves substantially higher finite-sample performance than existing approaches over a range of experimental settings, including one constructed from a real-world public health campaign in India.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "26 pages, 18 figures"
    },
    {
        "paper id": "2402.05145",
        "abstract url": "https://arxiv.org/abs/2402.05145",
        "title": "Online Learning Approach for Survival Analysis",
        "rating": -1.5,
        "keywords": [
            [
                "Survival"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce an online mathematical framework for survival analysis, allowing real time adaptation to dynamic environments and censored data. This framework enables the estimation of event time distributions through an optimal second order online convex optimization algorithm-Online Newton Step (ONS). This approach, previously unexplored, presents substantial advantages, including explicit algorithms with non-asymptotic convergence guarantees. Moreover, we analyze the selection of ONS hyperparameters, which depends on the exp-concavity property and has a significant influence on the regret bound. We propose a stochastic approach that guarantees logarithmic stochastic regret for ONS. Additionally, we introduce an adaptive aggregation method that ensures robustness in hyperparameter selection while maintaining fast regret bounds. The findings of this paper can extend beyond the survival analysis field, and are relevant for any case characterized by poor exp-concavity and unstable ONS. Finally, these assertions are illustrated by simulation experiments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05153",
        "abstract url": "https://arxiv.org/abs/2402.05153",
        "title": "Estimating On-road Transportation Carbon Emissions from Open Data of Road Network and Origin-destination Flow Data",
        "rating": -1.5,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accounting for over 20% of the total carbon emissions, the precise estimation of on-road transportation carbon emissions is crucial for carbon emission monitoring and efficient mitigation policy formulation. However, existing estimation methods typically depend on hard-to-collect individual statistics of vehicle miles traveled to calculate emissions, thereby suffering from high data collection difficulty. To relieve this issue by utilizing the strong pattern recognition of artificial intelligence, we incorporate two sources of open data representative of the transportation demand and capacity factors, the origin-destination (OD) flow data and the road network data, to build a hierarchical heterogeneous graph learning method for on-road carbon emission estimation (HENCE). Specifically, a hierarchical graph consisting of the road network level, community level, and region level is constructed to model the multi-scale road network-based connectivity and travel connection between spatial areas. Heterogeneous graphs consisting of OD links and spatial links are further built at both the community level and region level to capture the intrinsic interactions between travel demand and road network accessibility. Extensive experiments on two large-scale real-world datasets demonstrate HENCE's effectiveness and superiority with R-squared exceeding 0.75 and outperforming baselines by 9.60% on average, validating its success in pioneering the use of artificial intelligence to empower carbon emission management and sustainability development. The implementation codes are available at this link: https://github.com/tsinghua-fib-lab/HENCE.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05203",
        "abstract url": "https://arxiv.org/abs/2402.05203",
        "title": "Bellman Conformal Inference: Calibrating Prediction Intervals For Time Series",
        "rating": -1.5,
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce Bellman Conformal Inference (BCI), a framework that wraps around any time series forecasting models and provides approximately calibrated prediction intervals. Unlike existing methods, BCI is able to leverage multi-step ahead forecasts and explicitly optimize the average interval lengths by solving a one-dimensional stochastic control problem (SCP) at each time step. In particular, we use the dynamic programming algorithm to find the optimal policy for the SCP. We prove that BCI achieves long-term coverage under arbitrary distribution shifts and temporal dependence, even with poor multi-step ahead forecasts. We find empirically that BCI avoids uninformative intervals that have infinite lengths and generates substantially shorter prediction intervals in multiple applications when compared with existing methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 4 figures"
    },
    {
        "paper id": "2402.05252",
        "abstract url": "https://arxiv.org/abs/2402.05252",
        "title": "Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages",
        "rating": -1.5,
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning to Rank (LTR) is one of the most widely used machine learning applications. It is a key component in platforms with profound societal impacts, including job search, healthcare information retrieval, and social media content feeds. Conventional LTR models have been shown to produce biases results, stimulating a discourse on how to address the disparities introduced by ranking systems that solely prioritize user relevance. However, while several models of fair learning to rank have been proposed, they suffer from deficiencies either in accuracy or efficiency, thus limiting their applicability to real-world ranking platforms. This paper shows how efficiently-solvable fair ranking models, based on the optimization of Ordered Weighted Average (OWA) functions, can be integrated into the training loop of an LTR model to achieve favorable balances between fairness, user utility, and runtime efficiency. In particular, this paper is the first to show how to backpropagate through constrained optimizations of OWA objectives, enabling their use in integrated prediction and decision models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05295",
        "abstract url": "https://arxiv.org/abs/2402.05295",
        "title": "An information theoretic approach to quantify the stability of feature selection and ranking algorithms",
        "rating": -1.5,
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Feature selection is a key step when dealing with high dimensional data. In particular, these techniques simplify the process of knowledge discovery from the data by selecting the most relevant features out of the noisy, redundant and irrelevant features. A problem that arises in many of these practical applications is that the outcome of the feature selection algorithm is not stable. Thus, small variations in the data may yield very different feature rankings. Assessing the stability of these methods becomes an important issue in the previously mentioned situations. We propose an information theoretic approach based on the Jensen Shannon divergence to quantify this robustness. Unlike other stability measures, this metric is suitable for different algorithm outcomes: full ranked lists, feature subsets as well as the lesser studied partial ranked lists. This generalized metric quantifies the difference among a whole set of lists with the same size, following a probabilistic approach and being able to give more importance to the disagreements that appear at the top of the list. Moreover, it possesses desirable properties including correction for change, upper lower bounds and conditions for a deterministic selection. We illustrate the use of this stability metric with data generated in a fully controlled way and compare it with popular metrics including the Spearmans rank correlation and the Kunchevas index on feature ranking and selection outcomes, respectively. Additionally, experimental validation of the proposed approach is carried out on a real-world problem of food quality assessment showing its potential to quantify stability from different perspectives.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05306",
        "abstract url": "https://arxiv.org/abs/2402.05306",
        "title": "Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making",
        "rating": -1.5,
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data. While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability. Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression. This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships. Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task. Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision. Its distinctive ability to manage the complexity of expression trees and perform precise step-wise updates significantly enhances flexibility and efficiency. Our results demonstrate that Sym-Q excels not only in recovering underlying mathematical structures but also uniquely learns to efficiently refine the output expression based on reward signals, thereby discovering underlying expressions. Sym-Q paves the way for more intuitive and impactful discoveries in physical science, marking a substantial advancement in the field of symbolic regression.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05350",
        "abstract url": "https://arxiv.org/abs/2402.05350",
        "title": "Descanning: From Scanned to the Original Images with a Color Correction Diffusion Model",
        "rating": -1.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "A significant volume of analog information, i.e., documents and images, have been digitized in the form of scanned copies for storing, sharing, and/or analyzing in the digital world. However, the quality of such contents is severely degraded by various distortions caused by printing, storing, and scanning processes in the physical world. Although restoring high-quality content from scanned copies has become an indispensable task for many products, it has not been systematically explored, and to the best of our knowledge, no public datasets are available. In this paper, we define this problem as Descanning and introduce a new high-quality and large-scale dataset named DESCAN-18K. It contains 18K pairs of original and scanned images collected in the wild containing multiple complex degradations. In order to eliminate such complex degradations, we propose a new image restoration model called DescanDiffusion consisting of a color encoder that corrects the global color degradation and a conditional denoising diffusion probabilistic model (DDPM) that removes local degradations. To further improve the generalization ability of DescanDiffusion, we also design a synthetic data generation scheme by reproducing prominent degradations in scanned images. We demonstrate that our DescanDiffusion outperforms other baselines including commercial restoration products, objectively and subjectively, via comprehensive experiments and analyses.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to AAAI 2024"
    },
    {
        "paper id": "2402.05355",
        "abstract url": "https://arxiv.org/abs/2402.05355",
        "title": "A Survey on Safe Multi-Modal Learning System",
        "rating": -1.5,
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of artificial intelligence, multimodal learning systems (MMLS) have gained traction for their ability to process and integrate information from diverse modality inputs. Their expanding use in vital sectors such as healthcare has made safety assurance a critical concern. However, the absence of systematic research into their safety is a significant barrier to progress in this field. To bridge the gap, we present the first taxonomy that systematically categorizes and assesses MMLS safety. This taxonomy is structured around four fundamental pillars that are critical to ensuring the safety of MMLS: robustness, alignment, monitoring, and controllability. Leveraging this taxonomy, we review existing methodologies, benchmarks, and the current state of research, while also pinpointing the principal limitations and gaps in knowledge. Finally, we discuss unique challenges in MMLS safety. In illuminating these challenges, we aim to pave the way for future research, proposing potential directions that could lead to significant advancements in the safety protocols of MMLS.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05367",
        "abstract url": "https://arxiv.org/abs/2402.05367",
        "title": "Principled Preferential Bayesian Optimization",
        "rating": -1.5,
        "keywords": [
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of preferential Bayesian optimization (BO), where we aim to optimize a black-box function with only preference feedback over a pair of candidate solutions. Inspired by the likelihood ratio idea, we construct a confidence set of the black-box function using only the preference feedback. An optimistic algorithm with an efficient computational method is then developed to solve the problem, which enjoys an information-theoretic bound on the cumulative regret, a first-of-its-kind for preferential BO. This bound further allows us to design a scheme to report an estimated best solution, with a guaranteed convergence rate. Experimental results on sampled instances from Gaussian processes, standard test functions, and a thermal comfort optimization problem all show that our method stably achieves better or competitive performance as compared to the existing state-of-the-art heuristics, which, however, do not have theoretical guarantees on regret bounds or convergence.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05370",
        "abstract url": "https://arxiv.org/abs/2402.05370",
        "title": "Attention as Robust Representation for Time Series Forecasting",
        "rating": -1.5,
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Time series forecasting is essential for many practical applications, with the adoption of transformer-based models on the rise due to their impressive performance in NLP and CV. Transformers' key feature, the attention mechanism, dynamically fusing embeddings to enhance data representation, often relegating attention weights to a byproduct role. Yet, time series data, characterized by noise and non-stationarity, poses significant forecasting challenges. Our approach elevates attention weights as the primary representation for time series, capitalizing on the temporal relationships among data points to improve forecasting accuracy. Our study shows that an attention map, structured using global landmarks and local windows, acts as a robust kernel representation for data points, withstanding noise and shifts in distribution. Our method outperforms state-of-the-art models, reducing mean squared error (MSE) in multivariate time series forecasting by a notable 3.6% without altering the core neural network architecture. It serves as a versatile component that can readily replace recent patching based embedding schemes in transformer-based models, boosting their performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06673",
        "abstract url": "https://arxiv.org/abs/2402.06673",
        "title": "Advancing Explainable AI Toward Human-Like Intelligence: Forging the Path to Artificial Brain",
        "rating": -1.5,
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The intersection of Artificial Intelligence (AI) and neuroscience in Explainable AI (XAI) is pivotal for enhancing transparency and interpretability in complex decision-making processes. This paper explores the evolution of XAI methodologies, ranging from feature-based to human-centric approaches, and delves into their applications in diverse domains, including healthcare and finance. The challenges in achieving explainability in generative models, ensuring responsible AI practices, and addressing ethical implications are discussed. The paper further investigates the potential convergence of XAI with cognitive sciences, the development of emotionally intelligent AI, and the quest for Human-Like Intelligence (HLI) in AI systems. As AI progresses towards Artificial General Intelligence (AGI), considerations of consciousness, ethics, and societal impact become paramount. The ongoing pursuit of deciphering the mysteries of the brain with AI and the quest for HLI represent transformative endeavors, bridging technical advancements with multidisciplinary explorations of human cognition.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06675",
        "abstract url": "https://arxiv.org/abs/2402.06675",
        "title": "A Masked language model for multi-source EHR trajectories contextual representation learning",
        "rating": -1.5,
        "keywords": [
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Using electronic health records data and machine learning to guide future decisions needs to address challenges, including 1) long/short-term dependencies and 2) interactions between diseases and interventions. Bidirectional transformers have effectively addressed the first challenge. Here we tackled the latter challenge by masking one source (e.g., ICD10 codes) and training the transformer to predict it using other sources (e.g., ATC codes).",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Presented at Proceedings of MIE 2023"
    },
    {
        "paper id": "2402.07936",
        "abstract url": "https://arxiv.org/abs/2402.07936",
        "title": "The Design and Organization of Educational Competitions with Anonymous and Real-Time Leaderboards in Academic and Industrial Settings",
        "rating": -1.5,
        "keywords": [
            [
                "Industrial"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "The goal of this paper is to share our experience in designing and organizing educational competitions with anonymous and (near) real-time leaderboards in both academic and industrial settings. While such competitions serve as a great educational tool and provide participants with hands-on experience, they require significant planning, technical setup, and administration from organizers. In this paper, we first outline several important areas including team registration, data access, submission systems, rules and conditions that organizers should consider when planning such events. We then present a high-level system design that can support (near) real-time evaluation of submissions to power anonymous leaderboards and provide immediate feedback for participants. Finally, we share our experience applying this abstract system in academic and industrial settings. We hope the set of guidelines and the high-level system design proposed here help others in their organization of similar educational events.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "AAAI-EAAI 2023"
    },
    {
        "paper id": "2402.10101",
        "abstract url": "https://arxiv.org/abs/2402.10101",
        "title": "Deep Learning Based Situation Awareness for Multiple Missiles Evasion",
        "rating": -1.5,
        "keywords": [
            [
                "UAV"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As the effective range of air-to-air missiles increases, it becomes harder for human operators to maintain the situational awareness needed to keep a UAV safe. In this work, we propose a decision support tool to help UAV operators in Beyond Visual Range (BVR) air combat scenarios assess the risks of different options and make decisions based on those. Earlier work focused on the threat posed by a single missile, and in this work, we extend the ideas to several missile threats. The proposed method uses Deep Neural Networks (DNN) to learn from high-fidelity simulations to provide the operator with an outcome estimate for a set of different strategies. Our results demonstrate that the proposed system can manage multiple incoming missiles, evaluate a family of options, and recommend the least risky course of action.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04620",
        "abstract url": "https://arxiv.org/abs/2402.04620",
        "title": "CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients",
        "rating": -2,
        "keywords": [
            [
                "health",
                "healthcare",
                "surgery"
            ]
        ],
        "abstract": "The healthcare landscape is evolving, with patients seeking more reliable information about their health conditions, treatment options, and potential risks. Despite the abundance of information sources, the digital age overwhelms individuals with excess, often inaccurate information. Patients primarily trust doctors and hospital staff, highlighting the need for expert-endorsed health information. However, the pressure on experts has led to reduced communication time, impacting information sharing. To address this gap, we propose CataractBot, an experts-in-the-loop chatbot powered by large language models (LLMs). Developed in collaboration with a tertiary eye hospital in India, CataractBot answers cataract surgery related questions instantly by querying a curated knowledge base, and provides expert-verified responses asynchronously. CataractBot features multimodal support and multilingual capabilities. In an in-the-wild deployment study with 49 participants, CataractBot proved valuable, providing anytime accessibility, saving time, and accommodating diverse literacy levels. Trust was established through expert verification. Broadly, our results could inform future work on designing expert-mediated LLM bots.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04671",
        "abstract url": "https://arxiv.org/abs/2402.04671",
        "title": "V2VSSC: A 3D Semantic Scene Completion Benchmark for Perception with Vehicle to Vehicle Communication",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "Vehicle"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semantic scene completion (SSC) has recently gained popularity because it can provide both semantic and geometric information that can be used directly for autonomous vehicle navigation. However, there are still challenges to overcome. SSC is often hampered by occlusion and short-range perception due to sensor limitations, which can pose safety risks. This paper proposes a fundamental solution to this problem by leveraging vehicle-to-vehicle (V2V) communication. We propose the first generalized collaborative SSC framework that allows autonomous vehicles to share sensing information from different sensor views to jointly perform SSC tasks. To validate the proposed framework, we further build V2VSSC, the first V2V SSC benchmark, on top of the large-scale V2V perception dataset OPV2V. Extensive experiments demonstrate that by leveraging V2V communication, the SSC performance can be increased by 8.3% on geometric metric IoU and 6.0% mIOU.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04681",
        "abstract url": "https://arxiv.org/abs/2402.04681",
        "title": "Architectural Design Decisions for Self-Serve Data Platforms in Data Meshes",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Data mesh is an emerging decentralized approach to managing and generating value from analytical enterprise data at scale. It shifts the ownership of the data to the business domains closest to the data, promotes sharing and managing data as autonomous products, and uses a federated and automated data governance model. The data mesh relies on a managed data platform that offers services to domain and governance teams to build, share, and manage data products efficiently. However, designing and implementing a self-serve data platform is challenging, and the platform engineers and architects must understand and choose the appropriate design options to ensure the platform will enhance the experience of domain and governance teams. For these reasons, this paper proposes a catalog of architectural design decisions and their corresponding decision options by systematically reviewing 43 industrial gray literature articles on self-serve data platforms in data mesh. Moreover, we used semi-structured interviews with six data engineering experts with data mesh experience to validate, refine, and extend the findings from the literature. Such a catalog of design decisions and options drawn from the state of practice shall aid practitioners in building data meshes while providing a baseline for further research on data mesh architectures.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "21st IEEE International Conference on Software Architecture (ICSA 2024), 13 pages"
    },
    {
        "paper id": "2402.04727",
        "abstract url": "https://arxiv.org/abs/2402.04727",
        "title": "Data-driven Bayesian estimation of Monod kinetics",
        "rating": -2,
        "keywords": [
            [
                "bioprocesses"
            ]
        ],
        "abstract": "In this paper, we consider the well known problem of non-linear identification of the rates of the reactions involved in cells with Monod functions. In bioprocesses, generating data is very expensive and long and so it is important to incorporate prior knowledge on the Monod kinetic parameters. Bayesian estimation is an elegant estimation technique which deals with parameter estimation with prior knowledge modeled as probability density functions. However, we might not have an accurate knowledge of the kinetic parameters such as interval bounds, especially for newly developed cell lines. Hence, we consider the case when there is no accurate prior information on the kinetic parameters except qualitative knowledge such that their non-negativity. A log-Gaussian prior distribution is considered for the parameters and the mean and variances of these distribution are tuned using the Expectation Maximization algorithm. The algorithm requires to use Metropolis Hastings within Gibbs sampling which can be computationally expensive. We develop a novel variant of the Metropolis-Hastings within Gibbs sampling sampling scheme in order to accelerate and improve on the hyperparameter tuning. We show that it can give better modeling performances on a relatively large-scale simulation example compared to available methods in the literature.",
        "subjects": [
            "stat.ME"
        ],
        "comment": "Preprint submitted to Automatica"
    },
    {
        "paper id": "2402.04730",
        "abstract url": "https://arxiv.org/abs/2402.04730",
        "title": "Model Predictive Trajectory Optimization With Dynamically Changing Waypoints for Serial Manipulators",
        "rating": -2,
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Systematically including dynamically changing waypoints as desired discrete actions, for instance, resulting from superordinate task planning, has been challenging for online model predictive trajectory optimization with short planning horizons. This paper presents a novel waypoint model predictive control (wMPC) concept for online replanning tasks. The main idea is to split the planning horizon at the waypoint when it becomes reachable within the current planning horizon and reduce the horizon length towards the waypoints and goal points. This approach keeps the computational load low and provides flexibility in adapting to changing conditions in real time. The presented approach achieves competitive path lengths and trajectory durations compared to (global) offline RRT-type planners in a multi-waypoint scenario. Moreover, the ability of wMPC to dynamically replan tasks online is experimentally demonstrated on a KUKA LBR iiwa 14 R820 robot in a dynamic pick-and-place scenario.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2402.04760",
        "abstract url": "https://arxiv.org/abs/2402.04760",
        "title": "Subjective performance evaluation of bitrate allocation strategies for MPEG and JPEG Pleno point cloud compression",
        "rating": -2,
        "keywords": [
            [
                "point cloud"
            ],
            [
                "quality assessment"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The recent rise in interest in point clouds as an imaging modality has motivated standardization groups such as MPEG and JPEG Pleno to launch activities aiming at developing compression standards for point clouds. Lossy compression usually introduces visual artifacts that negatively impact the perceived quality of media, which can only be reliably measured through subjective visual quality assessment experiments. While MPEG standards have been subjectively evaluated in previous studies on multiple occasions, no work has yet assessed the performance of the recent JPEG Pleno standard in comparison to them. In this study, a comprehensive performance evaluation of MPEG and JPEG Pleno standards for point cloud compression is conducted. The impact of different configuration parameters on the performance of the codecs is first analyzed with the help of objective quality metrics. The results from this analysis are used to define three rate allocation strategies for each codec, which are employed to compress a set of point clouds at four target rates. The set of distorted point clouds is then subjectively evaluated following two subjective quality assessment protocols. Finally, the obtained results are used to compare the performance of these compression standards and draw insights about best coding practices.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04796",
        "abstract url": "https://arxiv.org/abs/2402.04796",
        "title": "Mesh-based Gaussian Splatting for Real-time Large-scale Deformation",
        "rating": -2,
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "Radiance Fields"
            ],
            [
                "synthesis"
            ]
        ],
        "abstract": "Neural implicit representations, including Neural Distance Fields and Neural Radiance Fields, have demonstrated significant capabilities for reconstructing surfaces with complicated geometry and topology, and generating novel views of a scene. Nevertheless, it is challenging for users to directly deform or manipulate these implicit representations with large deformations in the real-time fashion. Gaussian Splatting(GS) has recently become a promising method with explicit geometry for representing static scenes and facilitating high-quality and real-time synthesis of novel views. However,it cannot be easily deformed due to the use of discrete Gaussians and lack of explicit topology. To address this, we develop a novel GS-based method that enables interactive deformation. Our key idea is to design an innovative mesh-based GS representation, which is integrated into Gaussian learning and manipulation. 3D Gaussians are defined over an explicit mesh, and they are bound with each other: the rendering of 3D Gaussians guides the mesh face split for adaptive refinement, and the mesh face split directs the splitting of 3D Gaussians. Moreover, the explicit mesh constraints help regularize the Gaussian distribution, suppressing poor-quality Gaussians(e.g. misaligned Gaussians,long-narrow shaped Gaussians), thus enhancing visual quality and avoiding artifacts during deformation. Based on this representation, we further introduce a large-scale Gaussian deformation technique to enable deformable GS, which alters the parameters of 3D Gaussians according to the manipulation of the associated mesh. Our method benefits from existing mesh deformation datasets for more realistic data-driven Gaussian deformation. Extensive experiments show that our approach achieves high-quality reconstruction and effective deformation, while maintaining the promising rendering results at a high frame rate(65 FPS on average).",
        "subjects": [
            "cs.GR"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2402.04797",
        "abstract url": "https://arxiv.org/abs/2402.04797",
        "title": "Offline Deep Model Predictive Control (MPC) for Visual Navigation",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "In this paper, we propose a new visual navigation method based on a single RGB perspective camera. Using the Visual Teach & Repeat (VT&R) methodology, the robot acquires a visual trajectory consisting of multiple subgoal images in the teaching step. In the repeat step, we propose two network architectures, namely ViewNet and VelocityNet. The combination of the two networks allows the robot to follow the visual trajectory. ViewNet is trained to generate a future image based on the current view and the velocity command. The generated future image is combined with the subgoal image for training VelocityNet. We develop an offline Model Predictive Control (MPC) policy within VelocityNet with the dual goals of (1) reducing the difference between current and subgoal images and (2) ensuring smooth trajectories by mitigating velocity discontinuities. Offline training conserves computational resources, making it a more suitable option for scenarios with limited computational capabilities, such as embedded systems. We validate our experiments in a simulation environment, demonstrating that our model can effectively minimize the metric error between real and played trajectories.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at ROBOVIS 2024 : 4th International Conference on Robotics, Computer Vision and Intelligent Systems"
    },
    {
        "paper id": "2402.04820",
        "abstract url": "https://arxiv.org/abs/2402.04820",
        "title": "Kinematic Motion Retargeting for Contact-Rich Anthropomorphic Manipulations",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Hand motion capture data is now relatively easy to obtain, even for complicated grasps; however this data is of limited use without the ability to retarget it onto the hands of a specific character or robot. The target hand may differ dramatically in geometry, number of degrees of freedom (DOFs), or number of fingers. We present a simple, but effective framework capable of kinematically retargeting multiple human hand-object manipulations from a publicly available dataset to a wide assortment of kinematically and morphologically diverse target hands through the exploitation of contact areas. We do so by formulating the retarget operation as a non-isometric shape matching problem and use a combination of both surface contact and marker data to progressively estimate, refine, and fit the final target hand trajectory using inverse kinematics (IK). Foundational to our framework is the introduction of a novel shape matching process, which we show enables predictable and robust transfer of contact data over full manipulations while providing an intuitive means for artists to specify correspondences with relatively few inputs. We validate our framework through thirty demonstrations across five different hand shapes and six motions of different objects. We additionally compare our method against existing hand retargeting approaches. Finally, we demonstrate our method enabling novel capabilities such as object substitution and the ability to visualize the impact of design choices over full trajectories.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04829",
        "abstract url": "https://arxiv.org/abs/2402.04829",
        "title": "NeRF as a Non-Distant Environment Emitter in Physics-based Inverse Rendering",
        "rating": -2,
        "keywords": [
            [
                "NeRF"
            ],
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Physics-based inverse rendering enables joint optimization of shape, material, and lighting based on captured 2D images. To ensure accurate reconstruction, using a light model that closely resembles the captured environment is essential. Although the widely adopted distant environmental lighting model is adequate in many cases, we demonstrate that its inability to capture spatially varying illumination can lead to inaccurate reconstructions in many real-world inverse rendering scenarios. To address this limitation, we incorporate NeRF as a non-distant environment emitter into the inverse rendering pipeline. Additionally, we introduce an emitter importance sampling technique for NeRF to reduce the rendering variance. Through comparisons on both real and synthetic datasets, our results demonstrate that our NeRF-based emitter offers a more precise representation of scene lighting, thereby improving the accuracy of inverse rendering.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "SIGGRAPH 2024. Project page and video: https://nerfemitterpbir.github.io/"
    },
    {
        "paper id": "2402.04844",
        "abstract url": "https://arxiv.org/abs/2402.04844",
        "title": "Reconfigurable Intelligent Surface for Industrial Automation: mmWave Propagation Measurement, Simulation, and Control Algorithm Requirements",
        "rating": -2,
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "Reconfigurable intelligent surfaces (RISs) enable reliable low-latency millimeter wave (mmWave) communication links in cases of a blocked line-of-sight (LoS) between the base station (BS) and the user equipment (UE), i.e. a RIS mounted on a wall or the ceiling provides a bypass for the radio communication link. We present an active RIS with 127 patch antenna elements arranged in a hexagonal grid for a center frequency of 23.8 GHz. Each RIS element uses an orthogonal polarization transformation to enable amplification using a field-effect transistor (FET). The source and drain voltages of each FET is controlled using two bits. We assume that the coordinates of the UE in an industrial control scenario are known to the RIS. We measure the received power on a 2D grid of 60 cm by 100 cm with the RIS working in reflective and active mode. The results show that the RIS can successfully focus the radio signal at the desired target points. The half-power beam width is characterized in axial and radial directions with respect to the RIS position, obtaining a practical RIS configuration update criterion for a mobile UE. These results clearly show that RISs are prominent solutions for enabling reliable wireless communication in indoor industrial scenarios.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "submitted to IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), Valencia, Spain, September 2024"
    },
    {
        "paper id": "2402.04901",
        "abstract url": "https://arxiv.org/abs/2402.04901",
        "title": "Research on Mobile Network High-precision Absolute Time Synchronization based on TAP",
        "rating": -2,
        "keywords": [
            [
                "5G",
                "industrial"
            ]
        ],
        "abstract": "With the development of mobile communication and industrial internet technologies, the demand for robust absolute time synchronization based on network for diverse scenarios is significantly growing. TAP is a novel network timing method that aims to achieve sub-microsecond synchronization over air interface. This paper investigates the improvement and end-to-end realization of TAP. This paper first analyzes the effectiveness and deficiencies of TAP by establishing an equivalent clock model which evaluates TAP from timing error composition and allan variance. Second, this paper proposes a detailed base station and terminal design and the corresponding improvement of TAP. Both hardware compensation and protocol software design are taken into account so as to minimize timing error and system cost while maximizing compatibility with 3GPP. Finally, this paper presents a TAP end-to-end 5G prototype system developed based on software defined radio base station and COTS baseband module. The field test results show that the proposed scheme effectively solves the problems of TAP in application and robustly achieves 200ns level timing accuracy in various situations. The average accuracy with long observations can reach 1 nanosecond. It is 2$\\sim$3 orders of magnitude better than common network timing methods, including NTP, PTP and the original TAP.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04912",
        "abstract url": "https://arxiv.org/abs/2402.04912",
        "title": "Towards Biologically Plausible and Private Gene Expression Data Generation",
        "rating": -2,
        "keywords": [
            [
                "Biologically"
            ]
        ],
        "abstract": "Generative models trained with Differential Privacy (DP) are becoming increasingly prominent in the creation of synthetic data for downstream applications. Existing literature, however, primarily focuses on basic benchmarking datasets and tends to report promising results only for elementary metrics and relatively simple data distributions. In this paper, we initiate a systematic analysis of how DP generative models perform in their natural application scenarios, specifically focusing on real-world gene expression data. We conduct a comprehensive analysis of five representative DP generation methods, examining them from various angles, such as downstream utility, statistical properties, and biological plausibility. Our extensive evaluation illuminates the unique characteristics of each DP generation method, offering critical insights into the strengths and weaknesses of each approach, and uncovering intriguing possibilities for future developments. Perhaps surprisingly, our analysis reveals that most methods are capable of achieving seemingly reasonable downstream utility, according to the standard evaluation metrics considered in existing literature. Nevertheless, we find that none of the DP methods are able to accurately capture the biological characteristics of the real dataset. This observation suggests a potential over-optimistic assessment of current methodologies in this field and underscores a pressing need for future enhancements in model design.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04937",
        "abstract url": "https://arxiv.org/abs/2402.04937",
        "title": "Charting the COVID Long Haul Experience -- A Longitudinal Exploration of Symptoms, Activity, and Clinical Adherence",
        "rating": -2,
        "keywords": [
            [
                "health",
                "Clinical"
            ]
        ],
        "abstract": "COVID Long Haul (CLH) is an emerging chronic illness with varied patient experiences. Our understanding of CLH is often limited to data from electronic health records (EHRs), such as diagnoses or problem lists, which do not capture the volatility and severity of symptoms or their impact. To better understand the unique presentation of CLH, we conducted a 3-month long cohort study with 14 CLH patients, collecting objective (EHR, daily Fitbit logs) and subjective (weekly surveys, interviews) data. Our findings reveal a complex presentation of symptoms, associated uncertainty, and the ensuing impact CLH has on patients' personal and professional lives. We identify patient needs, practices, and challenges around adhering to clinical recommendations, engaging with health data, and establishing \"new normals\" post COVID. We reflect on the potential found at the intersection of these various data streams and the persuasive heuristics possible when designing for this new population and their specific needs.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "21 pages, 4 figures, 7 tables, ACM Conference CHI Conference on Human Factors in Computing Systems"
    },
    {
        "paper id": "2402.04975",
        "abstract url": "https://arxiv.org/abs/2402.04975",
        "title": "ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12",
        "rating": -2,
        "keywords": [
            [
                "CT"
            ]
        ],
        "abstract": "As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children's autonomous Scratch learning: artist's block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist's block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "29 pages, 7 figures, accepted by CHI 2024"
    },
    {
        "paper id": "2402.05029",
        "abstract url": "https://arxiv.org/abs/2402.05029",
        "title": "Quantifying Population Exposure to Long-term PM10: A City-wide Agent-based Assessment",
        "rating": -2,
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "This study evaluates the health effects of long-term exposure to PM10 in Seoul. Building on the preliminary model Shin and Bithell (2019), an in-silico agent-based model (ABM) is used to simulate the travel patterns of individuals according to their origins and destinations. During the simulation, each person, with their inherent socio-economic attributes and allocated origin and destination location, is assumed to commute to and from the same places for 10 consecutive years. A nominal measure of their health is set to decrease whenever the concentration of PM10 exceeds the national standard. Sensitivity analysis on calibrated parameters reveals increased vulnerability among certain demographic groups, particularly those aged over 65 and under 15, with a significant health decline associated with road proximity. The study reveals a substantial health disparity after 7,000 simulation ticks (equivalent to 10 years), especially under scenarios of a 3% annual increase in pollution levels. Long-term exposure to PM10 has a significant impact on health vulnerabilities, despite initial resilience being minimal. The study emphasises the importance of future research that takes into account different pollution thresholds as well as more detailed models of population dynamics and pollution generation in order to better understand and mitigate the health effects of air pollution on diverse urban populations.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "14 pages, 7 figures"
    },
    {
        "paper id": "2402.05037",
        "abstract url": "https://arxiv.org/abs/2402.05037",
        "title": "Smooth real-time motion planning based on a cascade dual-quaternion screw-geometry MPC",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "This paper investigates the tracking problem of a smooth coordinate-invariant trajectory using dual quaternion algebra. The proposed architecture consists of a cascade structure in which the outer-loop MPC performs real-time smoothing of the manipulator's end-effector twist while an inner-loop kinematic controller ensures tracking of the instantaneous desired end-effector pose. Experiments on a $7$-DoF Franka Emika Panda robotic manipulator validate the proposed method demonstrating its application to constraint the robot twists, accelerations and jerks within prescribed bounds.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05067",
        "abstract url": "https://arxiv.org/abs/2402.05067",
        "title": "A Novel Paradigm in Solving Multiscale Problems",
        "rating": -2,
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "Multiscale phenomena manifest across various scientific domains, presenting a ubiquitous challenge in accurately and effectively simulating multiscale dynamics in complex systems. In this paper, a novel decoupling solving paradigm is proposed through modelling large-scale dynamics independently and treating small-scale dynamics as a slaved system. A Spectral Physics-informed Neural Network (PINN) is developed to characterize the small-scale system in an efficient and accurate way, addressing the challenges posed by the representation of multiscale dynamics in neural networks. The effectiveness of the method is demonstrated through extensive numerical experiments, including one-dimensional Kuramot-Sivashinsky equation, two- and three-dimensional Navier-Stokes equations, showcasing its versatility in addressing problems of fluid dynamics. Furthermore, we also delve into the application of the proposed approach to more complex problems, including non-uniform meshes, complex geometries, large-scale data with noise, and high-dimensional small-scale dynamics. The discussions about these scenarios contribute to a comprehensive understanding of the method's capabilities and limitations. By enabling the acquisition of large-scale data with minimal computational demands, coupled with the efficient and accurate characterization of small-scale dynamics via Spectral PINN, our approach offers a valuable and promising approach for researchers seeking to tackle multiscale phenomena effectively.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05068",
        "abstract url": "https://arxiv.org/abs/2402.05068",
        "title": "Arbitrary Scale Super-Resolution Assisted Lunar Crater Detection in Satellite Images",
        "rating": -2,
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "Satellite"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Craters are one of the most studied planetary features used for different scientific analyses, such as estimation of surface age and surface processes. Satellite images utilized for crater detection often have low resolution (LR) due to hardware constraints and transmission time. Super-resolution (SR) is a practical and cost-effective solution; however, most SR approaches work on fixed integer scale factors, i.e., a single model can generate images of a specific resolution. In practical applications, SR on multiple scales provides various levels of detail, but training for each scale is resource-intensive. Therefore, this paper proposes a system for crater detection assisted with an arbitrary scale super-resolution approach (i.e., a single model can be used for multiple scale factors) for the lunar surface. Our work is composed of two subsystems. The first sub-system employs an arbitrary scale SR approach to generate super-resolved images of multiple resolutions. Subsequently, the second sub-system passes super-resolved images of multiple resolutions to a deep learning-based crater detection framework for identifying craters on the lunar surface. Employed arbitrary scale SR approach is based on a combination of convolution and transformer modules. For the crater detection sub-system, we utilize the Mask-RCNN framework. Using SR images of multiple resolutions, the proposed system detects 13.47% more craters from the ground truth than the craters detected using only the LR images. Further, in complex crater settings, specifically in overlapping and degraded craters, 11.84% and 15.01% more craters are detected as compared to the crater detection networks using only the LR images. The proposed system also leads to better localization performance, 3.19% IoU increment compared to the LR images",
        "subjects": [
            "eess.IV"
        ],
        "comment": "15 pages, 8 figures, 8 Tables"
    },
    {
        "paper id": "2402.05080",
        "abstract url": "https://arxiv.org/abs/2402.05080",
        "title": "Designing three-way entangled and nonlocal two-way entangled single particle states via alternate quantum walks",
        "rating": -2,
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Entanglement with single-particle states is advantageous in quantum technology because of their ability to encode and process information more securely than their multi-particle analogs. Three-way and nonlocal two-way entangled single-particle states are desirable in this context. Herein, we generate three-way entanglement from an initially separable state involving three degrees of freedom of a quantum particle, which evolves via a 2D alternate quantum walk employing a resource-saving single-qubit coin. We achieve maximum possible values for the three-way entanglement quantified by the $\u03c0$-tangle between the three degrees of freedom. We also generate optimal two-way nonlocal entanglement, quantified by the negativity between the nonlocal position degrees of freedom of the particle. This prepared architecture using quantum walks can be experimentally realized with a photon.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "13 pages, 10 figures"
    },
    {
        "paper id": "2402.05176",
        "abstract url": "https://arxiv.org/abs/2402.05176",
        "title": "cecilia: A Machine Learning-Based Pipeline for Measuring Metal Abundances of Helium-rich Polluted White Dwarfs",
        "rating": -2,
        "keywords": [
            [
                "chemistry"
            ]
        ],
        "abstract": "Over the past several decades, conventional spectral analysis techniques of polluted white dwarfs have become powerful tools to learn about the geology and chemistry of extrasolar bodies. Despite their proven capabilities and extensive legacy of scientific discoveries, these techniques are however still limited by their manual, time-intensive, and iterative nature. As a result, they are susceptible to human errors and are difficult to scale up to population-wide studies of metal pollution. This paper seeks to address this problem by presenting cecilia, the first Machine Learning (ML)-powered spectral modeling code designed to measure the metal abundances of intermediate-temperature (10,000$\\leq T_{\\rm eff} \\leq$20,000 K), Helium-rich polluted white dwarfs. Trained with more than 22,000 randomly drawn atmosphere models and stellar parameters, our pipeline aims to overcome the limitations of classical methods by replacing the generation of synthetic spectra from computationally expensive codes and uniformly spaced model grids, with a fast, automated, and efficient neural-network-based interpolator. More specifically, cecilia combines state-of-the-art atmosphere models, powerful artificial intelligence tools, and robust statistical techniques to rapidly generate synthetic spectra of polluted white dwarfs in high-dimensional space, and enable accurate ($\\lesssim$0.1 dex) and simultaneous measurements of 14 stellar parameters -- including 11 elemental abundances -- from real spectroscopic observations. As massively multiplexed astronomical surveys begin scientific operations, cecilia's performance has the potential to unlock large-scale studies of extrasolar geochemistry and propel the field of white dwarf science into the era of Big Data. In doing so, we aspire to uncover new statistical insights that were previously impractical with traditional white dwarf characterisation techniques.",
        "subjects": [
            "astro-ph.IM"
        ],
        "comment": "28 pages, 16 figures, 5 tables. Accepted for publication in MNRAS"
    },
    {
        "paper id": "2402.05197",
        "abstract url": "https://arxiv.org/abs/2402.05197",
        "title": "Geometric Slosh-Free Tracking for Robotic Manipulators",
        "rating": -2,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "This work focuses on the agile transportation of liquids with robotic manipulators. In contrast to existing methods that are either computationally heavy, system/container specific or dependant on a singularity-prone pendulum model, we present a real-time slosh-free tracking technique. This method solely requires the reference trajectory and the robot's kinematic constraints to output kinematically feasible joint space commands. The crucial element underlying this approach consists on mimicking the end-effector's motion through a virtual quadrotor, which is inherently slosh-free and differentially flat, thereby allowing us to calculate a slosh-free reference orientation. Through the utilization of a cascaded proportional-derivative (PD) controller, this slosh-free reference is transformed into task space acceleration commands, which, following the resolution of a Quadratic Program (QP) based on Resolved Acceleration Control (RAC), are translated into a feasible joint configuration. The validity of the proposed approach is demonstrated by simulated and real-world experiments on a 7 DoF Franka Emika Panda robot. Code: https://github.com/jonarriza96/gsft Video: https://youtu.be/4kitqYVS9n8",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Yokohama, Japan, May 2024. Copyright @ IEEE"
    },
    {
        "paper id": "2402.05208",
        "abstract url": "https://arxiv.org/abs/2402.05208",
        "title": "Measurement Methodology for Determining the Optimal Frequency Domain Configuration to Accurately Record WiFi Exposure Levels",
        "rating": -2,
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "Radiofrequency fields are usually measured in order to be compared with electromagnetic exposure limits defined by international standardization organizations with the aim of preserving the human health. However, in the case of WiFi technology, accurate measurement of the radiation coming from user terminals and access points is a great challenge due to the nature of these emissions, which are noncontinuous signals transmitted in the form of pulses of short duration. Most of the methodologies defined up to now for determining WiFi exposure levels use or take as reference exposimeters, broadband probes, and spectrum analyzers without taking into account that WiFi signals are not continuously transmitted. This leads to an overestimation of the radiation level that cannot be considered negligible when data of the actual exposure are needed. To avoid this, other procedures apply empirical weighting factors that account for the actual duration of burst transmissions. However, this implies the implementation of additional measurements for calculating the weighting factors, and thus, increases the complexity of the work. According to this, it was still necessary to define the frequency domain measurement setup that is optimal for obtaining realistic WiFi signal values, without requiring the performance of additional recordings. Thus, the definition of an appropriate methodology to achieve this goal was established as the main objective of this paper. The set of tasks carried out to identify such a configuration, as well as the limitations obtained for other measurement settings, are deeply explained in this paper.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2402.05210",
        "abstract url": "https://arxiv.org/abs/2402.05210",
        "title": "Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models",
        "rating": -2,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Medical",
                "MRI",
                "CT"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Diffusion models have enabled remarkably high-quality medical image generation, yet it is challenging to enforce anatomical constraints in generated images. This hampers many useful applications, including pre-registered image generation, counterfactual scenarios, and others. To this end, we propose a diffusion model-based method that supports anatomically-controllable medical image generation, by following a multi-class anatomical segmentation mask at each sampling step. We additionally introduce a random mask ablation training algorithm to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. We compare our model (\"Seg-Diff\") to existing methods on breast MRI and abdominal/neck-to-pelvis CT datasets with a wide range of anatomical objects. Results show that it reaches a new state-of-the-art in the faithfulness of generated images to input anatomical masks on both datasets, and is on par for general anatomical realism. Finally, our model also enjoys the extra benefit of being able to adjust the anatomical similarity of generated images to real images of choice through interpolation in its latent space.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Code and synthetic dataset: https://github.com/mazurowski-lab/segmentation-guided-diffusion"
    },
    {
        "paper id": "2402.05218",
        "abstract url": "https://arxiv.org/abs/2402.05218",
        "title": "Self-calibrated convolution towards glioma segmentation",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "disease",
                "tumor"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Accurate brain tumor segmentation in the early stages of the disease is crucial for the treatment's effectiveness, avoiding exhaustive visual inspection of a qualified specialist on 3D MR brain images of multiple protocols (e.g., T1, T2, T2-FLAIR, T1-Gd). Several networks exist for Glioma segmentation, being nnU-Net one of the best. In this work, we evaluate self-calibrated convolutions in different parts of the nnU-Net network to demonstrate that self-calibrated modules in skip connections can significantly improve the enhanced-tumor and tumor-core segmentation accuracy while preserving the wholetumor segmentation accuracy.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05223",
        "abstract url": "https://arxiv.org/abs/2402.05223",
        "title": "Taming Timeout Flakiness: An Empirical Study of SAP HANA",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Regression testing aims to prevent code changes from breaking existing features. Flaky tests negatively affect regression testing because they result in test failures that are not necessarily caused by code changes, thus providing an ambiguous signal. Test timeouts are one contributing factor to such flaky test failures. With the goal of reducing test flakiness in SAP HANA, we empirically study the impact of test timeouts on flakiness in system tests. We evaluate different approaches to automatically adjust timeout values, assessing their suitability for reducing execution time costs and improving build turnaround times. We collect metadata on SAP HANA's test executions by repeatedly executing tests on the same code revision over a period of six months. We analyze the test flakiness rate, investigate the evolution of test timeout values, and evaluate different approaches for optimizing timeout values. The test flakiness rate ranges from 49% to 70%, depending on the number of repeated test executions. Test timeouts account for 70% of flaky test failures. Developers typically react to flaky timeouts by manually increasing timeout values or splitting long-running tests. However, manually adjusting timeout values is a tedious task. Our approach for timeout optimization reduces timeout-related flaky failures by 80% and reduces the overall median timeout value by 25%, i.e., blocked tests are identified faster. Test timeouts are a major contributing factor to flakiness in system tests. It is challenging for developers to effectively mitigate this problem manually. Our technique for optimizing timeout values reduces flaky failures while minimizing test costs. Practitioners working on large-scale industrial software systems can use our findings to increase the effectiveness of their system tests while reducing the burden on developers to manually maintain appropriate timeout values.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "12 pages, 9 figures, 3 tables, Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE SEIP 2024)"
    },
    {
        "paper id": "2402.05226",
        "abstract url": "https://arxiv.org/abs/2402.05226",
        "title": "A Comprehensive Analysis of Secondary Coexistence in a Real-World CBRS Deployment",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "The Federal Communications Commission (FCC) in the U.S. has made the Citizens Broadband Radio Service (CBRS) band (3.55 - 3.7 GHz) available for commercial wireless usage under a shared approach using a three-tier hierarchical architecture, where the federal incumbent is the highest priority Tier 1 user, Priority Access License (PAL) holders, who have paid for licenses, are Tier 2 users and Tier 3 users operate under General Authorized Access (GAA), without license fees or protection from higher priority users. The Spectrum Access System (SAS) ensures that higher priority users are protected from interference from lower priority users. However, the lowest priority GAA users are not given any protection from each other by the SAS and are expected to not cause any harmful interference to Tier 1 and Tier 2 users. As the deployments of GAA devices grow, the potential for secondary interference between GAA users increases, especially since the SAS architecture does not allow dynamic channel switching when faced with interference. In this paper, we present a first-of-its-kind extensive measurement campaign of a commercial CBRS network deployed in the city of South Bend, IN, that quantifies both co-channel interference (CCI) and adjacent channel interference (ACI) caused by competing GAA devices and C-band 5G, respectively. We (i) identify a particular CCI scenario and improve performance by changing the frequency allocation based on our study of other allocations in the vicinity and (ii) quantify ACI from 5G in C-band (3.7 GHz) on CBRS throughput. We conclude that (i) CCI and ACI for GAA users is not handled well by the SAS, (ii) proper frequency allocation for GAA requires additional analysis of interference from other GAA users followed by dynamical channel selection, and (iii) utilization of immediate adjacent channels by high power 5G deployments limits the performance of CBRS.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05255",
        "abstract url": "https://arxiv.org/abs/2402.05255",
        "title": "An Overview of Machine Learning-Enabled Network Softwarization for the Internet of Things",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The Internet of Things (IoT) has evolved from a novel technology to an integral part of our everyday lives. It encompasses a multitude of heterogeneous devices that collect valuable data through various sensors. The sheer volume of these interconnected devices poses significant challenges as IoT provides complex network services with diverse requirements on a shared infrastructure. Network softwarization could help address these issues as it has emerged as a paradigm that enhances traditional networking by decoupling hardware from software and leveraging enabling technologies such as Software Defined Networking (SDN) and Network Function Virtualization (NFV). In networking, Machine Learning (ML) has demonstrated impressive results across multiple domains. By smoothly integrating with network softwarization, ML plays a pivotal role in building efficient and intelligent IoT networks. This paper explores the fundamentals of IoT, network softwarization, and ML, while reviewing the latest advances in ML-enabled network softwarization for IoT.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05266",
        "abstract url": "https://arxiv.org/abs/2402.05266",
        "title": "A computational approach to visual ecology with deep reinforcement learning",
        "rating": -2,
        "keywords": [
            [
                "survival"
            ]
        ],
        "abstract": "Animal vision is thought to optimize various objectives from metabolic efficiency to discrimination performance, yet its ultimate objective is to facilitate the survival of the animal within its ecological niche. However, modeling animal behavior in complex environments has been challenging. To study how environments shape and constrain visual processing, we developed a deep reinforcement learning framework in which an agent moves through a 3-d environment that it perceives through a vision model, where its only goal is to survive. Within this framework we developed a foraging task where the agent must gather food that sustains it, and avoid food that harms it. We first established that the complexity of the vision model required for survival on this task scaled with the variety and visual complexity of the food in the environment. Moreover, we showed that a recurrent network architecture was necessary to fully exploit complex vision models on the most visually demanding tasks. Finally, we showed how different network architectures learned distinct representations of the environment and task, and lead the agent to exhibit distinct behavioural strategies. In summary, this paper lays the foundation for a computational approach to visual ecology, provides extensive benchmarks for future work, and demonstrates how representations and behaviour emerge from an agent's drive for survival.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05270",
        "abstract url": "https://arxiv.org/abs/2402.05270",
        "title": "Review and Analysis of Recent Advances in Intelligent Network Softwarization for the Internet of Things",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The Internet of Things (IoT) is an emerging technology that aims to connect heterogeneous and constrained objects to each other and to the Internet. It has grown significantly in a wide variety of applications such as smart homes, smart cities, smart vehicles, etc. The huge number of connected devices increases the challenges, as IoT provides diverse and complex network services with different requirements on a common infrastructure. Network Softwarization is the latest network paradigm that transforms traditional network processes to the separation of hardware and software by using some enabling network technologies such as Software Defined Networking (SDN) and Network Function Virtualization (NFV). Machine Learning (ML) plays an essential role in creating smarter IoT networks, as it has shown remarkable results in various domains. Given that the network softwarization allows it to be easily integrated, ML can play a crucial role in efficient and self-adaptive IoT networks. In this paper, we provide a detailed overview of the concepts of IoT, network softwarization, and ML, and we study and discuss the state of the art of intelligent ML-enabled network softwarization for IoT. We also identify the most prominent future research directions to be considered.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05319",
        "abstract url": "https://arxiv.org/abs/2402.05319",
        "title": "Optimal energy-aware task scheduling for batteryless IoT devices",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Today's IoT devices rely on batteries, which offer stable energy storage but contain harmful chemicals. Having billions of IoT devices powered by batteries is not sustainable for the future. As an alternative, batteryless devices run on long-lived capacitors charged using energy harvesters. The small energy storage capacity of capacitors results in intermittent on-off behaviour. Traditional computing schedulers can not handle this intermittency, and in this paper we propose a first step towards an energy-aware task scheduler for constrained batteryless devices. We present a new energy-aware task scheduling algorithm that is able to optimally schedule application tasks to avoid power failures, and that will allow us to provide insights on the optimal look-ahead time for energy prediction. Our insights can be used as a basis for practical energy-aware scheduling and energy availability prediction algorithms. We formulate the scheduling problem as a Mixed Integer Linear Program. We evaluate its performance improvement when comparing it with state-of-the-art schedulers for batteryless IoT devices. Our results show that making the task scheduler energy aware avoids power failures and allows more tasks to successfully execute. Moreover, we conclude that a relatively short look-ahead energy prediction time of 8 future task executions is enough to achieve optimality.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05328",
        "abstract url": "https://arxiv.org/abs/2402.05328",
        "title": "Two Simple Proofs of M\u00fcller's Theorem",
        "rating": -2,
        "keywords": [
            [
                "quantum",
                "physics"
            ]
        ],
        "abstract": "Due to M\u00fcller's theorem, the Kolmogorov complexity of a string was shown to be equal to its quantum Kolmogorov complexity. Thus there are no benefits to using quantum mechanics to compress classical information. The quantitative amount of information in classical sources is invariant to the physical model used. These consequences make this theorem arguably the most important result in the intersection of algorithmic information theory and physics. The original proof is quite extensive. This paper contains two simple proofs of this theorem.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05332",
        "abstract url": "https://arxiv.org/abs/2402.05332",
        "title": "Domain-Agnostic Hardware Fingerprinting-Based Device Identifier for Zero-Trust IoT Security",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Next-generation networks aim for comprehensive connectivity, interconnecting humans, machines, devices, and systems seamlessly. This interconnectivity raises concerns about privacy and security, given the potential network-wide impact of a single compromise. To address this challenge, the Zero Trust (ZT) paradigm emerges as a key method for safeguarding network integrity and data confidentiality. This work introduces EPS-CNN, a novel deep-learning-based wireless device identification framework designed to serve as the device authentication layer within the ZT architecture, with a focus on resource-constrained IoT devices. At the core of EPS-CNN, a Convolutional Neural Network (CNN) is utilized to generate the device identity from a unique RF signal representation, known as the Double-Sided Envelope Power Spectrum (EPS), which effectively captures the device-specific hardware characteristics while ignoring device-unrelated information. Experimental evaluations show that the proposed framework achieves over 99%, 93%, and 95% testing accuracy when tested in same-domain (day, location, and channel), cross-day, and cross-location scenarios, respectively. Our findings demonstrate the superiority of the proposed framework in enhancing the accuracy, robustness, and adaptability of deep learning-based methods, thus offering a pioneering solution for enabling ZT IoT device identification.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This paper to be published in IEEE Wireless Communications Magazine 2024. arXiv admin note: substantial text overlap with arXiv:2308.04467"
    },
    {
        "paper id": "2402.05333",
        "abstract url": "https://arxiv.org/abs/2402.05333",
        "title": "ML-Enabled Systems Model Deployment and Monitoring: Status Quo and Problems",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "[Context] Systems incorporating Machine Learning (ML) models, often called ML-enabled systems, have become commonplace. However, empirical evidence on how ML-enabled systems are engineered in practice is still limited, especially for activities surrounding ML model dissemination. [Goal] We investigate contemporary industrial practices and problems related to ML model dissemination, focusing on the model deployment and the monitoring of ML life cycle phases. [Method] We conducted an international survey to gather practitioner insights on how ML-enabled systems are engineered. We gathered a total of 188 complete responses from 25 countries. We analyze the status quo and problems reported for the model deployment and monitoring phases. We analyzed contemporary practices using bootstrapping with confidence intervals and conducted qualitative analyses on the reported problems applying open and axial coding procedures. [Results] Practitioners perceive the model deployment and monitoring phases as relevant and difficult. With respect to model deployment, models are typically deployed as separate services, with limited adoption of MLOps principles. Reported problems include difficulties in designing the architecture of the infrastructure for production deployment and legacy application integration. Concerning model monitoring, many models in production are not monitored. The main monitored aspects are inputs, outputs, and decisions. Reported problems involve the absence of monitoring practices, the need to create custom monitoring tools, and the selection of suitable metrics. [Conclusion] Our results help provide a better understanding of the adopted practices and problems in practice and support guiding ML deployment and monitoring research in a problem-driven manner.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2310.06726"
    },
    {
        "paper id": "2402.05337",
        "abstract url": "https://arxiv.org/abs/2402.05337",
        "title": "Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "[Context] Applying design principles has long been acknowledged as beneficial for understanding and maintainability in traditional software projects. These benefits may similarly hold for Machine Learning (ML) projects, which involve iterative experimentation with data, models, and algorithms. However, ML components are often developed by data scientists with diverse educational backgrounds, potentially resulting in code that doesn't adhere to software design best practices. [Goal] In order to better understand this phenomenon, we investigated the impact of the SOLID design principles on ML code understanding. [Method] We conducted a controlled experiment with three independent trials involving 100 data scientists. We restructured real industrial ML code that did not use SOLID principles. Within each trial, one group was presented with the original ML code, while the other was presented with ML code incorporating SOLID principles. Participants of both groups were asked to analyze the code and fill out a questionnaire that included both open-ended and closed-ended questions on their understanding. [Results] The study results provide statistically significant evidence that the adoption of the SOLID design principles can improve code understanding within the realm of ML projects. [Conclusion] We put forward that software engineering design principles should be spread within the data science community and considered for enhancing the maintainability of ML code.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05340",
        "abstract url": "https://arxiv.org/abs/2402.05340",
        "title": "POLARIS: A framework to guide the development of Trustworthy AI systems",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "In the ever-expanding landscape of Artificial Intelligence (AI), where innovation thrives and new products and services are continuously being delivered, ensuring that AI systems are designed and developed responsibly throughout their entire lifecycle is crucial. To this end, several AI ethics principles and guidelines have been issued to which AI systems should conform. Nevertheless, relying solely on high-level AI ethics principles is far from sufficient to ensure the responsible engineering of AI systems. In this field, AI professionals often navigate by sight. Indeed, while recommendations promoting Trustworthy AI (TAI) exist, these are often high-level statements that are difficult to translate into concrete implementation strategies. There is a significant gap between high-level AI ethics principles and low-level concrete practices for AI professionals. To address this challenge, our work presents an experience report where we develop a novel holistic framework for Trustworthy AI - designed to bridge the gap between theory and practice - and report insights from its application in an industrial case study. The framework is built on the result of a systematic review of the state of the practice, a survey, and think-aloud interviews with 34 AI practitioners. The framework, unlike most of those already in the literature, is designed to provide actionable guidelines and tools to support different types of stakeholders throughout the entire Software Development Life Cycle (SDLC). Our goal is to empower AI professionals to confidently navigate the ethical dimensions of TAI through practical insights, ensuring that the vast potential of AI is exploited responsibly for the benefit of society as a whole.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05348",
        "abstract url": "https://arxiv.org/abs/2402.05348",
        "title": "Are We Asking the Right Questions?: Designing for Community Stakeholders' Interactions with AI in Policing",
        "rating": -2,
        "keywords": [
            [
                "crime"
            ]
        ],
        "abstract": "Research into recidivism risk prediction in the criminal legal system has garnered significant attention from HCI, critical algorithm studies, and the emerging field of human-AI decision-making. This study focuses on algorithmic crime mapping, a prevalent yet underexplored form of algorithmic decision support (ADS) in this context. We conducted experiments and follow-up interviews with 60 participants, including community members, technical experts, and law enforcement agents (LEAs), to explore how lived experiences, technical knowledge, and domain expertise shape interactions with the ADS, impacting human-AI decision-making. Surprisingly, we found that domain experts (LEAs) often exhibited anchoring bias, readily accepting and engaging with the first crime map presented to them. Conversely, community members and technical experts were more inclined to engage with the tool, adjust controls, and generate different maps. Our findings highlight that all three stakeholders were able to provide critical feedback regarding AI design and use - community members questioned the core motivation of the tool, technical experts drew attention to the elastic nature of data science practice, and LEAs suggested redesign pathways such that the tool could complement their domain expertise.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05368",
        "abstract url": "https://arxiv.org/abs/2402.05368",
        "title": "Bounded-Confidence Models of Opinion Dynamics with Neighborhood Effects",
        "rating": -2,
        "keywords": [
            [
                "disease"
            ]
        ],
        "abstract": "As people's opinions change, their social networks typically coevolve with them. People are often more susceptible to influence by people with similar opinions than by people with dissimilar opinions. In a bounded-confidence model (BCM) of opinion dynamics, interacting individuals influence each other through dyadic influence if and only if their opinions are sufficiently similar to each other. We introduce `neighborhood BCMs' (NBCMs) that include both the usual dyadic influence and a transitive influence, which models the effect of friends of a friend when determining whether or not an interaction with a friend influences an individual. In this transitive influence, an individual's opinion is influenced by a neighbor when, on average, the opinions of the neighbor's neighbors are sufficiently similar to their own opinion. We formulate neighborhood Deffuant--Weisbuch (NDW) and neighborhood Hegselmann--Krause (NHK) BCMs. We simulate our NDW model on time-independent networks and observe interesting opinion states that cannot occur in an associated baseline DW model. We also simulate our NDW model on adaptive networks that coevolve with opinions by changing its structure through `transitive homophily'. An individual that breaks a tie to one of its neighbors and then rewires that tie to a new individual, with a preference for individuals with a mean neighbor opinion that is closer to that individual's opinion. We explore how the qualitative opinion dynamics and network properties of our time-independent and adaptive NDWM models change as we adjust the relative proportions of dyadic and transitive influence. Finally, we study a two-layer opinion--disease model in which we couple our NDW model with disease spread through a shared adaptive network that can change both on the opinion layer and on the disease layer and we examine how the opinion dynamics affect disease spread.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "21 pages, 6 figures; the abstract on the arXiv page is abbreviated in parts because of character-count limitations"
    },
    {
        "paper id": "2402.05372",
        "abstract url": "https://arxiv.org/abs/2402.05372",
        "title": "Reduced-order modeling of unsteady fluid flow using neural network ensembles",
        "rating": -2,
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "The use of deep learning has become increasingly popular in reduced-order models (ROMs) to obtain low-dimensional representations of full-order models. Convolutional autoencoders (CAEs) are often used to this end as they are adept at handling data that are spatially distributed, including solutions to partial differential equations. When applied to unsteady physics problems, ROMs also require a model for time-series prediction of the low-dimensional latent variables. Long short-term memory (LSTM) networks, a type of recurrent neural network useful for modeling sequential data, are frequently employed in data-driven ROMs for autoregressive time-series prediction. When making predictions at unseen design points over long time horizons, error propagation is a frequently encountered issue, where errors made early on can compound over time and lead to large inaccuracies. In this work, we propose using bagging, a commonly used ensemble learning technique, to develop a fully data-driven ROM framework referred to as the CAE-eLSTM ROM that uses CAEs for spatial reconstruction of the full-order model and LSTM ensembles for time-series prediction. When applied to two unsteady fluid dynamics problems, our results show that the presented framework effectively reduces error propagation and leads to more accurate time-series prediction of latent variables at unseen points.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05390",
        "abstract url": "https://arxiv.org/abs/2402.05390",
        "title": "Integrated Sensing and Communication Driven Digital Twin for Intelligent Machine Network",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Intelligent machines (IMs), including industrial machines, unmanned aerial vehicles (UAVs), and unmanned vehicles, etc., could perform effective cooperation in complex environment when they form IM network. The efficient environment sensing and communication are crucial for IM network, enabling the real-time and stable control of IMs. With the emergence of integrated sensing and communication (ISAC) technology, IM network is empowered with ubiquitous sensing capabilities, which is helpful in improving the efficiency of communication and sensing with the mutual benefit of them. However, the massive amount of sensing information brings challenges for the processing, storage and application of sensing information. In this article, ISAC driven digital twin (DT) is proposed for IM network, and the architecture and enabling technologies are revealed. ISAC driven DT structurally stores the sensing information, which is further applied to optimize communication, networking and control schemes of IMs, promoting the widespread applications of IMs.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "9 pages, 5 figures, 1 Table"
    },
    {
        "paper id": "2402.05972",
        "abstract url": "https://arxiv.org/abs/2402.05972",
        "title": "Gaussian-process-regression-based method for the localization of exceptional points in complex resonance spectra",
        "rating": -2,
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Resonances in open quantum systems depending on at least two controllable parameters can show the phenomenon of exceptional points (EPs), where not only the eigenvalues but also the eigenvectors of two or more resonances coalesce. Their exact localization in the parameter space is challenging, in particular in systems, where the computation of the quantum spectra and resonances is numerically very expensive. We introduce an efficient machine learning algorithm to find exceptional points based on Gaussian process regression (GPR). The GPR-model is trained with an initial set of eigenvalue pairs belonging to an EP and used for a first estimation of the EP position via a numerically cheap root search. The estimate is then improved iteratively by adding selected exact eigenvalue pairs as training points to the GPR-model. The GPR-based method is developed and tested on a simple low-dimensional matrix model and then applied to a challenging real physical system, viz., the localization of EPs in the resonance spectra of excitons in cuprous oxide in external electric and magnetic fields. The precise computation of EPs, by taking into account the complete valence band structure and central-cell corrections of the crystal, can be the basis for the experimental observation of EPs in this system.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "28 pages, 10 figures, submitted to Machine Learning: Science and Technology"
    },
    {
        "paper id": "2402.06669",
        "abstract url": "https://arxiv.org/abs/2402.06669",
        "title": "Compression effects and scene details on the source camera identification of digital videos",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "The continuous growth of technologies like 4G or 5G has led to a massive use of mobile devices such as smartphones and tablets. This phenomenon, combined with the fact that people use mobile phones for a longer period of time, results in mobile phones becoming the main source of creation of visual information. However, its reliability as a true representation of reality cannot be taken for granted due to the constant increase in editing software. This makes it easier to alter original content without leaving a noticeable trace in the modification. Therefore, it is essential to introduce forensic analysis mechanisms to guarantee the authenticity or integrity of a certain digital video, particularly if it may be considered as evidence in legal proceedings. This paper explains the branch of multimedia forensic analysis that allows to determine the identification of the source of acquisition of a certain video by exploiting the unique traces left by the camera sensor of the mobile device in visual content. To do this, a technique that performs the identification of the source of acquisition of digital videos from mobile devices is presented. It involves 3 stages: (1) Extraction of the sensor fingerprint by applying the block-based technique. (2) Filtering the strong component of the PRNU signal to improve the quality of the sensor fingerprint. (3) Classification of digital videos in an open scenario, that is, where the forensic analyst does not need to have access to the device that recorded the video to find out the origin of the video. The main contribution of the proposed technique eliminates the details of the scene to improve the PRNU fingerprint. It should be noted that these techniques are applied to digital images and not to digital videos.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.14023",
        "abstract url": "https://arxiv.org/abs/2402.14023",
        "title": "25-Fold Resolution Enhancement of X-ray Microscopy Using Multipixel Ghost Imaging",
        "rating": -2,
        "keywords": [
            [
                "CT",
                "X-ray"
            ]
        ],
        "abstract": "Hard x-ray imaging is indispensable across diverse fields owing to its high penetrability. However, the resolution of traditional x-ray imaging modalities, such as computed tomography (CT) systems, is constrained by factors including beam properties, the absence of optical components, and detection resolution. As a result, typical resolution in commercial imaging systems is limited to a few hundred microns. This study advances high-photon-energy imaging by extending the concept of computational ghost imaging to multipixel ghost imaging with x-rays. We demonstrate a remarkable enhancement in resolution from 500 microns to approximately 20 microns for an image spanning 0.9 by 1 cm^2, comprised of 400,000 pixels and involving only 1000 realizations. Furthermore, we present a high-resolution CT reconstruction using our method, revealing enhanced visibility and resolution. Our achievement is facilitated by an innovative x-ray lithography technique and the computed tiling of images captured by each detector pixel. Importantly, this method can be scaled up for larger images without sacrificing the short measurement time, thereby opening intriguing possibilities for noninvasive high-resolution imaging of small features that are invisible with the present modalities.",
        "subjects": [
            "physics.med-ph"
        ],
        "comment": "9 pages, 4 figures"
    },
    {
        "paper id": "2402.16875",
        "abstract url": "https://arxiv.org/abs/2402.16875",
        "title": "Can we predict QPP? An approach based on multivariate outliers",
        "rating": -2,
        "keywords": [
            [
                "forecast"
            ]
        ],
        "abstract": "Query performance prediction (QPP) aims to forecast the effectiveness of a search engine across a range of queries and documents. While state-of-the-art predictors offer a certain level of precision, their accuracy is not flawless. Prior research has recognized the challenges inherent in QPP but often lacks a thorough qualitative analysis. In this paper, we delve into QPP by examining the factors that influence the predictability of query performance accuracy. We propose the working hypothesis that while some queries are readily predictable, others present significant challenges. By focusing on outliers, we aim to identify the queries that are particularly challenging to predict. To this end, we employ multivariate outlier detection method. Our results demonstrate the effectiveness of this approach in identifying queries on which QPP do not perform well, yielding less reliable predictions. Moreover, we provide evidence that excluding these hard-to-predict queries from the analysis significantly enhances the overall accuracy of QPP.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.16886",
        "abstract url": "https://arxiv.org/abs/2402.16886",
        "title": "Using text embedding models and vector databases as text classifiers with the example of medical data",
        "rating": -2,
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "The advent of Large Language Models (LLMs) is promising and has found application in numerous fields, but as it often is with the medical field, the bar is typically quite high [5]. In tandem with LLMs, vector embedding models and vector databases provide a robust way of expressing numerous modes of data that are easily digestible by typical machine learning models. Along with the ease of adding information, knowledge, and data to these vector databases, they provide a compelling reason to apply them in numerous fields where the task of retrieving information is typically done by humans. Researchers at Google have developed a clear alternative model, Med-PaLM [6] specifically designed to match a clinician's level of accuracy when it comes to medical knowledge. When training classifiers, and developing models, it is imperative to maintain factuality and reduce bias [4]. Here, we explore the use of vector databases and embedding models as a means of encoding, and classifying text with the example and application in the field of medicine. We show the robustness of these tools depends heavily on the sparsity of the data presented, and even with low amounts of data in the vector database itself, the vector database does a good job at classifying data [9]. Using various LLMs to generate the medical data, we also understand the limitations of the medical knowledge of these models and encourage further expert medical review of our testing data. By using vector databases to classify a clinician's notes on a patient presented with a certain ailment, we understand the limitations of such methods, but also the promise of their prospective use and with continued testing and experimentation, hope to explore a unique use case of vector databases and embedding models.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "11 pages, 8 figures, All robustness tests are in a linked pdf"
    },
    {
        "paper id": "2403.08810",
        "abstract url": "https://arxiv.org/abs/2403.08810",
        "title": "Comparison of edge computing methods in Internet of Things architectures for efficient estimation of indoor environmental parameters with Machine Learning",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The large increase in the number of Internet of Things (IoT) devices have revolutionised the way data is processed, which added to the current trend from cloud to edge computing has resulted in the need for efficient and reliable data processing near the data sources using energy-efficient devices. Two methods based on low-cost edge-IoT architectures are proposed to implement lightweight Machine Learning (ML) models that estimate indoor environmental quality (IEQ) parameters, such as Artificial Neural Networks of Multilayer Perceptron type. Their implementation is based on centralised and distributed parallel IoT architectures, connected via wireless, which share commercial off-the-self modules for data acquisition and sensing, such as sensors for temperature, humidity, illuminance, CO2, and other gases. The centralised method uses a Graphics Processing Unit and the Message Queuing Telemetry Transport protocol, but the distributed method utilises low performance ARM-based devices and the Message Passing Interface protocol. Although multiple IEQ parameters are measured, the training and testing of ML models is accomplished with experiments focused on small temperature and illuminance datasets to reduce data processing load, obtained from sudden spikes, square profiles and sawteeth test cases. The results show a high estimation performance with F-score and Accuracy values close to 0.95, and an almost theorical Speedup with a reduction in power consumption close to 37% in the distributed parallel approach. In addition, similar or slightly better performance is achieved compared to equivalent IoT architectures from related research, but error reduction of 35 to 76% is accomplished with an adequate balance between performance and energy efficiency.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.09682",
        "abstract url": "https://arxiv.org/abs/2403.09682",
        "title": "On the Theory of Quantum and Towards Practical Computation",
        "rating": -2,
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum computing exposes the brilliance of quantum mechanics through computer science and, as such, gives oneself a marvelous and exhilarating journey to go through. This article leads along that journey with a historical and current outlook on quantum computation that is geared toward computer experts but also to experts from other disciplines as well. It is an article that will bridge the vast gap between classical and quantum computation and open an entering wedge through which one will be able to both bring himself up to speed on quantum computation and, intrinsically, in a straightforward manner, become acquainted with it. We are indeed in luck to be living in an age where computing is being reinvented, and not only seeing history in the making firsthand but, in fact, having the opportunity to be the ones who are reinventing--and that is quite a thought.",
        "subjects": [
            "physics.pop-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2405.00012",
        "abstract url": "https://arxiv.org/abs/2405.00012",
        "title": "A quantum neural network framework for scalable quantum circuit approximation of unitary matrices",
        "rating": -2,
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "In this paper, we develop a Lie group theoretic approach for parametric representation of unitary matrices. This leads to develop a quantum neural network framework for quantum circuit approximation of multi-qubit unitary gates. Layers of the neural networks are defined by product of exponential of certain elements of the Standard Recursive Block Basis, which we introduce as an alternative to Pauli string basis for matrix algebra of complex matrices of order $2^n$. The recursive construction of the neural networks implies that the quantum circuit approximation is scalable i.e. quantum circuit for an $(n+1)$-qubit unitary can be constructed from the circuit of $n$-qubit system by adding a few CNOT gates and single-qubit gates.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "58 pages. arXiv admin note: substantial text overlap with arXiv:2304.14096"
    },
    {
        "paper id": "2402.05011",
        "abstract url": "https://arxiv.org/abs/2402.05011",
        "title": "Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching",
        "rating": -2.5,
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "trajectory"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph condensation aims to reduce the size of a large-scale graph dataset by synthesizing a compact counterpart without sacrificing the performance of Graph Neural Networks (GNNs) trained on it, which has shed light on reducing the computational cost for training GNNs. Nevertheless, existing methods often fall short of accurately replicating the original graph for certain datasets, thereby failing to achieve the objective of lossless condensation. To understand this phenomenon, we investigate the potential reasons and reveal that the previous state-of-the-art trajectory matching method provides biased and restricted supervision signals from the original graph when optimizing the condensed one. This significantly limits both the scale and efficacy of the condensed graph. In this paper, we make the first attempt toward \\textit{lossless graph condensation} by bridging the previously neglected supervision signals. Specifically, we employ a curriculum learning strategy to train expert trajectories with more diverse supervision signals from the original graph, and then effectively transfer the information into the condensed graph with expanding window matching. Moreover, we design a loss function to further extract knowledge from the expert trajectories. Theoretical analysis justifies the design of our method and extensive experiments verify its superiority across different datasets. Code is released at https://github.com/NUS-HPC-AI-Lab/GEOM.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Lossless graph condensation method"
    },
    {
        "paper id": "2402.05039",
        "abstract url": "https://arxiv.org/abs/2402.05039",
        "title": "PAC Learnability under Explanation-Preserving Graph Perturbations",
        "rating": -2.5,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "biology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graphical models capture relations between entities in a wide range of applications including social networks, biology, and natural language processing, among others. Graph neural networks (GNN) are neural models that operate over graphs, enabling the model to leverage the complex relationships and dependencies in graph-structured data. A graph explanation is a subgraph which is an `almost sufficient' statistic of the input graph with respect to its classification label. Consequently, the classification label is invariant, with high probability, to perturbations of graph edges not belonging to its explanation subgraph. This work considers two methods for leveraging such perturbation invariances in the design and training of GNNs. First, explanation-assisted learning rules are considered. It is shown that the sample complexity of explanation-assisted learning can be arbitrarily smaller than explanation-agnostic learning. Next, explanation-assisted data augmentation is considered, where the training set is enlarged by artificially producing new training samples via perturbation of the non-explanation edges in the original training set. It is shown that such data augmentation methods may improve performance if the augmented data is in-distribution, however, it may also lead to worse sample complexity compared to explanation-agnostic learning rules if the augmented data is out-of-distribution. Extensive empirical evaluations are provided to verify the theoretical analysis.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 6 figures, 4 tables"
    },
    {
        "paper id": "2402.05293",
        "abstract url": "https://arxiv.org/abs/2402.05293",
        "title": "A comparative study on feature selection for a risk prediction model for colorectal cancer",
        "rating": -2.5,
        "keywords": [
            [
                "SVM"
            ],
            [
                "cancer",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Background and objective Risk prediction models aim at identifying people at higher risk of developing a target disease. Feature selection is particularly important to improve the prediction model performance avoiding overfitting and to identify the leading cancer risk (and protective) factors. Assessing the stability of feature selection/ranking algorithms becomes an important issue when the aim is to analyze the features with more prediction power. Methods This work is focused on colorectal cancer, assessing several feature ranking algorithms in terms of performance for a set of risk prediction models (Neural Networks, Support Vector Machines (SVM), Logistic Regression, k-Nearest Neighbors and Boosted Trees). Additionally, their robustness is evaluated following a conventional approach with scalar stability metrics and a visual approach proposed in this work to study both similarity among feature ranking techniques as well as their individual stability. A comparative analysis is carried out between the most relevant features found out in this study and features provided by the experts according to the state-of-the-art knowledge. Results The two best performance results in terms of Area Under the ROC Curve (AUC) are achieved with a SVM classifier using the top-41 features selected by the SVM wrapper approach (AUC=0.693) and Logistic Regression with the top-40 features selected by the Pearson (AUC=0.689). Experiments showed that performing feature selection contributes to classification performance with a 3.9% and 1.9% improvement in AUC for the SVM and Logistic Regression classifier, respectively, with respect to the results using the full feature set. The visual approach proposed in this work allows to see that the Neural Network-based wrapper ranking is the most unstable while the Random Forest is the most stable.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05294",
        "abstract url": "https://arxiv.org/abs/2402.05294",
        "title": "Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection",
        "rating": -2.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Medical",
                "X-Ray",
                "Disease",
                "radiology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart. However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked. This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients. We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL. Furthermore, we examine three potential routes of addressing this issue. Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL. Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem. Thirdly, we assess the capability of client-level and server-level regularization techniques towards mitigating modality incongruity effects. Experiments are conducted under several MMFL settings on two publicly available real-world datasets, MIMIC-CXR and Open-I, with Chest X-Ray and radiology reports.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "42 pages"
    },
    {
        "paper id": "2402.05322",
        "abstract url": "https://arxiv.org/abs/2402.05322",
        "title": "Learning on Multimodal Graphs: A Survey",
        "rating": -2.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multimodal data pervades various domains, including healthcare, social media, and transportation, where multimodal graphs play a pivotal role. Machine learning on multimodal graphs, referred to as multimodal graph learning (MGL), is essential for successful artificial intelligence (AI) applications. The burgeoning research in this field encompasses diverse graph data types and modalities, learning techniques, and application scenarios. This survey paper conducts a comparative analysis of existing works in multimodal graph learning, elucidating how multimodal learning is achieved across different graph types and exploring the characteristics of prevalent learning techniques. Additionally, we delineate significant applications of multimodal graph learning and offer insights into future directions in this domain. Consequently, this paper serves as a foundational resource for researchers seeking to comprehend existing MGL techniques and their applicability across diverse scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 1 figure"
    },
    {
        "paper id": "2402.05396",
        "abstract url": "https://arxiv.org/abs/2402.05396",
        "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning",
        "rating": -2.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated state-of-the-art performance in various high-impact applications, including fraud detection and content recommendation. Despite the success of TGNNs, they are prone to the prevalent noise found in real-world dynamic graphs like time-deprecated links and skewed interaction distribution. The noise causes two critical issues that significantly compromise the accuracy of TGNNs: (1) models are supervised by inferior interactions, and (2) noisy input induces high variance in the aggregated messages. However, current TGNN denoising techniques do not consider the diverse and dynamic noise pattern of each node. In addition, they also suffer from the excessive mini-batch generation overheads caused by traversing more neighbors. We believe the remedy for fast and accurate TGNNs lies in temporal adaptive sampling. In this work, we propose TASER, the first adaptive sampling method for TGNNs optimized for accuracy, efficiency, and scalability. TASER adapts its mini-batch selection based on training dynamics and temporal neighbor selection based on the contextual, structural, and temporal properties of past interactions. To alleviate the bottleneck in mini-batch generation, TASER implements a pure GPU-based temporal neighbor finder and a dedicated GPU feature cache. We evaluate the performance of TASER using two state-of-the-art backbone TGNNs. On five popular datasets, TASER outperforms the corresponding baselines by an average of 2.3% in Mean Reciprocal Rank (MRR) while achieving an average of 5.1x speedup in training time.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "IPDPS 2024"
    },
    {
        "paper id": "2402.14596",
        "abstract url": "https://arxiv.org/abs/2402.14596",
        "title": "The Role of LLMs in Sustainable Smart Cities: Applications, Challenges, and Future Directions",
        "rating": -2.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "IoT"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Smart cities stand as pivotal components in the ongoing pursuit of elevating urban living standards, facilitating the rapid expansion of urban areas while efficiently managing resources through sustainable and scalable innovations. In this regard, as emerging technologies like Artificial Intelligence (AI), the Internet of Things (IoT), big data analytics, and fog and edge computing have become increasingly prevalent, smart city applications grapple with various challenges, including the potential for unauthorized disclosure of confidential and sensitive data. The seamless integration of emerging technologies has played a vital role in sustaining the dynamic pace of their development. This paper explores the substantial potential and applications of Deep Learning (DL), Federated Learning (FL), IoT, Blockchain, Natural Language Processing (NLP), and large language models (LLMs) in optimizing ICT processes within smart cities. We aim to spotlight the vast potential of these technologies as foundational elements that technically strengthen the realization and advancement of smart cities, underscoring their significance in driving innovation within this transformative urban milieu. Our discourse culminates with an exploration of the formidable challenges that DL, FL, IoT, Blockchain, NLP, and LLMs face within these contexts, and we offer insights into potential future directions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.12060",
        "abstract url": "https://arxiv.org/abs/2403.12060",
        "title": "Blockchain-Empowered Immutable and Reliable Delivery Service (BIRDS) Using UAV Networks",
        "rating": -2.5,
        "keywords": [
            [
                "UAV"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Exploiting unmanned aerial vehicles (UAVs) for delivery services is expected to reduce delivery time and human resource costs. However, the proximity of these UAVs to the ground can make them an ideal target for opportunistic criminals. Consequently, UAVs may be hacked, diverted from their destinations, or used for malicious purposes. Furthermore, as a decentralized (peer-to-peer) technology, the blockchain has immense potential to enable secure, decentralized, and cooperative communication among UAVs. With this goal in mind, we propose the Blockchain-Empowered, Immutable, and Reliable Delivery Service (BIRDS) framework to address data security challenges. BIRDS deploys communication hubs across a scalable network. Following the registration phase of BIRDS, UAV node selection is carried out based on a specific consensus proof-of-competence (PoC), where UAVs are evaluated solely on their credibility. The chosen finalist is awarded a certificate for the BIRDS global order fulfillment system. The simulation results demonstrate that BIRDS requires fewer UAVs compared to conventional solutions, resulting in reduced costs and emissions. The proposed BIRDS framework caters to the requirements of numerous users while necessitating less network traffic and consuming low energy.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "6 pages, 6 figures,2023 IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (IEEE CAMAD), Edinburgh, UK"
    },
    {
        "paper id": "2402.04704",
        "abstract url": "https://arxiv.org/abs/2402.04704",
        "title": "Device Activity Detection and Channel Estimation for Millimeter-Wave Massive MIMO",
        "rating": -3,
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Millimeter-Wave Massive MIMO is important for beyond 5G or 6G wireless communication networks. The goal of this paper is to establish successful communication between the cellular base stations and devices, focusing on the problem of joint user activity detection and channel estimation. Different from traditional compressed sensing (CS) methods that only use the sparsity of user activities, we develop several Approximate Message Passing (AMP) based CS algorithms by exploiting the sparsity of user activities and mmWave channels. First, a group soft-thresholding AMP is presented to utilize only the user activity sparsity. Second, a hard-thresholding AMP is proposed based on the on-grid CS approach. Third, a super-resolution AMP algorithm is proposed based on atomic norm, in which a greedy method is proposed as a super-resolution denoiser. And we smooth the denoiser based on Monte Carlo sampling to have Lipschitz continuity and present state evolution results. Extensive simulation results show that the proposed method outperforms the previous state-of-the-art methods.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Published in: IEEE Transactions on Communications, 2023"
    },
    {
        "paper id": "2402.04865",
        "abstract url": "https://arxiv.org/abs/2402.04865",
        "title": "Collaborative Computing in Non-Terrestrial Networks: A Multi-Time-Scale Deep Reinforcement Learning Approach",
        "rating": -3,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "Constructing earth-fixed cells with low-earth orbit (LEO) satellites in non-terrestrial networks (NTNs) has been the most promising paradigm to enable global coverage. The limited computing capabilities on LEO satellites however render tackling resource optimization within a short duration a critical challenge. Although the sufficient computing capabilities of the ground infrastructures can be utilized to assist the LEO satellite, different time-scale control cycles and coupling decisions between the space- and ground-segments still obstruct the joint optimization design for computing agents at different segments. To address the above challenges, in this paper, a multi-time-scale deep reinforcement learning (DRL) scheme is developed for achieving the radio resource optimization in NTNs, in which the LEO satellite and user equipment (UE) collaborate with each other to perform individual decision-making tasks with different control cycles. Specifically, the UE updates its policy toward improving value functions of both the satellite and UE, while the LEO satellite only performs finite-step rollout for decision-makings based on the reference decision trajectory provided by the UE. Most importantly, rigorous analysis to guarantee the performance convergence of the proposed scheme is provided. Comprehensive simulations are conducted to justify the effectiveness of the proposed scheme in balancing the transmission performance and computational complexity.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04878",
        "abstract url": "https://arxiv.org/abs/2402.04878",
        "title": "STAR: Shape-focused Texture Agnostic Representations for Improved Object Detection and 6D Pose Estimation",
        "rating": -3,
        "keywords": [
            [
                "6D"
            ],
            [
                "robotics"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in machine learning have greatly benefited object detection and 6D pose estimation for robotic grasping. However, textureless and metallic objects still pose a significant challenge due to fewer visual cues and the texture bias of CNNs. To address this issue, we propose a texture-agnostic approach that focuses on learning from CAD models and emphasizes object shape features. To achieve a focus on learning shape features, the textures are randomized during the rendering of the training data. By treating the texture as noise, the need for real-world object instances or their final appearance during training data generation is eliminated. The TLESS and ITODD datasets, specifically created for industrial settings in robotics and featuring textureless and metallic objects, were used for evaluation. Texture agnosticity also increases the robustness against image perturbations such as imaging noise, motion blur, and brightness changes, which are common in robotics applications. Code and datasets are publicly available at github.com/hoenigpeter/randomized_texturing.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to IEEE Robotics and Automation Letters"
    },
    {
        "paper id": "2402.05042",
        "abstract url": "https://arxiv.org/abs/2402.05042",
        "title": "Sticky Fingers: Resilience of Satellite Fingerprinting against Jamming Attacks",
        "rating": -3,
        "keywords": [
            [
                "Attacks"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "In the wake of increasing numbers of attacks on radio communication systems, a range of techniques are being deployed to increase the security of these systems. One such technique is radio fingerprinting, in which the transmitter can be identified and authenticated by observing small hardware differences expressed in the signal. Fingerprinting has been explored in particular in the defense of satellite systems, many of which are insecure and cannot be retrofitted with cryptographic security. In this paper, we evaluate the effectiveness of radio fingerprinting techniques under interference and jamming attacks, usually intended to deny service. By taking a pre-trained fingerprinting model and gathering a new dataset in which different levels of Gaussian noise and tone jamming have been added to the legitimate signal, we assess the attacker power required in order to disrupt the transmitter fingerprint such that it can no longer be recognized. We compare this to Gaussian jamming on the data portion of the signal, obtaining the remarkable result that transmitter fingerprints are still recognizable even in the presence of moderate levels of noise. Through deeper analysis of the results, we conclude that it takes a similar amount of jamming power in order to disrupt the fingerprint as it does to jam the message contents itself, so it is safe to include a fingerprinting system to authenticate satellite communication without opening up the system to easier denial-of-service attacks.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "9 pages, 12 figures"
    },
    {
        "paper id": "2402.05075",
        "abstract url": "https://arxiv.org/abs/2402.05075",
        "title": "ARCollab: Towards Multi-User Interactive Cardiovascular Surgical Planning in Mobile Augmented Reality",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "Surgical"
            ]
        ],
        "abstract": "Surgical planning for congenital heart diseases requires a collaborative approach, traditionally involving the 3D-printing of physical heart models for inspection by surgeons and cardiologists. Recent advancements in mobile augmented reality (AR) technologies have offered a promising alternative, noted for their ease-of-use and portability. Despite this progress, there remains a gap in research exploring the use of multi-user mobile AR environments for facilitating collaborative cardiovascular surgical planning. We are developing ARCollab, an iOS AR application designed to allow multiple surgeons and cardiologists to interact with patient-specific 3D heart models in a shared environment. ARCollab allows surgeons and cardiologists to import heart models, perform gestures to manipulate the heart, and collaborate with other users without having to produce a physical heart model. We are excited by the potential for ARCollab to make long-term real-world impact, thanks to the ubiquity of iOS devices that will allow for ARCollab's easy distribution, deployment and adoption.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05188",
        "abstract url": "https://arxiv.org/abs/2402.05188",
        "title": "InCoRo: In-Context Learning for Robotics Control with Feedback Loops",
        "rating": -3,
        "keywords": [
            [
                "Robotics",
                "robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "One of the challenges in robotics is to enable robotic units with the reasoning capability that would be robust enough to execute complex tasks in dynamic environments. Recent advances in LLMs have positioned them as go-to tools for simple reasoning tasks, motivating the pioneering work of Liang et al. [35] that uses an LLM to translate natural language commands into low-level static execution plans for robotic units. Using LLMs inside robotics systems brings their generalization to a new level, enabling zero-shot generalization to new tasks. This paper extends this prior work to dynamic environments. We propose InCoRo, a system that uses a classical robotic feedback loop composed of an LLM controller, a scene understanding unit, and a robot. Our system continuously analyzes the state of the environment and provides adapted execution commands, enabling the robot to adjust to changing environmental conditions and correcting for controller errors. Our system does not require any iterative optimization to learn to accomplish a task as it leverages in-context learning with an off-the-shelf LLM model. Through an extensive validation process involving two standardized industrial robotic units -- SCARA and DELTA types -- we contribute knowledge about these robots, not popular in the community, thereby enriching it. We highlight the generalization capabilities of our system and show that (1) in-context learning in combination with the current state-of-the-art LLMs is an effective way to implement a robotic controller; (2) in static environments, InCoRo surpasses the prior art in terms of the success rate; (3) in dynamic environments, we establish new state-of-the-art for the SCARA and DELTA units, respectively. This research paves the way towards building reliable, efficient, intelligent autonomous systems that adapt to dynamic environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05259",
        "abstract url": "https://arxiv.org/abs/2402.05259",
        "title": "Enabling Architecture for Distributed Intelligent Network Softwarization for the Internet of Things",
        "rating": -3,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "The Internet of Things (IoT) is becoming a part of everyday life through its various sensing devices that collect valuable information. The huge number of interconnected heterogeneous IoT devices poses immense challenges, and network softwarization techniques are an adequate solution to these concerns. Software Defined Networking (SDN) and Network Function Virtualization (NFV) are two key softwarization techniques that enable the realization of efficient, agile IoT networks, especially when combined with Machine Learning (ML), mainly Federated Learning (FL). Unfortunately, existing solutions do not take advantage of such a combination to strengthen IoT networks in terms of efficiency and scalability. In this paper, we propose a novel architecture to achieve distributed intelligent network softwarization for IoT, in which SDN, NFV, and ML combine forces to enhance IoT constrained networks.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05371",
        "abstract url": "https://arxiv.org/abs/2402.05371",
        "title": "Learning to Control Emulated Muscles in Real Robots: Towards Exploiting Bio-Inspired Actuator Morphology",
        "rating": -3,
        "keywords": [
            [
                "robot"
            ],
            [
                "Bio-Inspired"
            ]
        ],
        "abstract": "Recent studies have demonstrated the immense potential of exploiting muscle actuator morphology for natural and robust movement -- in simulation. A validation on real robotic hardware is yet missing. In this study, we emulate muscle actuator properties on hardware in real-time, taking advantage of modern and affordable electric motors. We demonstrate that our setup can emulate a simplified muscle model on a real robot while being controlled by a learned policy. We improve upon an existing muscle model by deriving a damping rule that ensures that the model is not only performant and stable but also tuneable for the real hardware. Our policies are trained by reinforcement learning entirely in simulation, where we show that previously reported benefits of muscles extend to the case of quadruped locomotion and hopping: the learned policies are more robust and exhibit more regular gaits. Finally, we confirm that the learned policies can be executed on real hardware and show that sim-to-real transfer with real-time emulated muscles on a quadruped robot is possible. These results show that artificial muscles can be highly beneficial actuators for future generations of robust legged robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06680",
        "abstract url": "https://arxiv.org/abs/2402.06680",
        "title": "Social Physics Informed Diffusion Model for Crowd Simulation",
        "rating": -3,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Physics"
            ]
        ],
        "abstract": "Crowd simulation holds crucial applications in various domains, such as urban planning, architectural design, and traffic arrangement. In recent years, physics-informed machine learning methods have achieved state-of-the-art performance in crowd simulation but fail to model the heterogeneity and multi-modality of human movement comprehensively. In this paper, we propose a social physics-informed diffusion model named SPDiff to mitigate the above gap. SPDiff takes both the interactive and historical information of crowds in the current timeframe to reverse the diffusion process, thereby generating the distribution of pedestrian movement in the subsequent timeframe. Inspired by the well-known social physics model, i.e., Social Force, regarding crowd dynamics, we design a crowd interaction module to guide the denoising process and further enhance this module with the equivariant properties of crowd interactions. To mitigate error accumulation in long-term simulations, we propose a multi-frame rollout training algorithm for diffusion modeling. Experiments conducted on two real-world datasets demonstrate the superior performance of SPDiff in terms of macroscopic and microscopic evaluation metrics. Code and appendix are available at https://github.com/tsinghua-fib-lab/SPDiff.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.16876",
        "abstract url": "https://arxiv.org/abs/2402.16876",
        "title": "Advanced Academic Team Worker Recommendation Models",
        "rating": -3,
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Collaborator recommendation is an important task in academic domain. Most of the existing approaches have the assumption that the recommendation system only need to recommend a specific researcher for the task. However, academic successes can be owed to productive collaboration of a whole academic team. In this work, we propose a new task: academic team worker recommendation: with a given status: student, assistant professor or prime professor, research interests and specific task, we can recommend an academic team formed as (prime professor, assistant professor, student). For this task, we propose a model CQBG-R(Citation-Query Blended Graph-Ranking). The key ideas is to combine the context of the query and the papers with the graph topology to form a new graph(CQBG), which can target at the research interests and the specific research task for this time. The experiment results show the effectiveness of the proposed method.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04722",
        "abstract url": "https://arxiv.org/abs/2402.04722",
        "title": "Ten simple rules for teaching sustainable software engineering",
        "rating": -3.5,
        "keywords": [
            [
                "biological"
            ],
            [
                "industrial"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Computational methods and associated software implementations are central to every field of scientific investigation. Modern biological research, particularly within systems biology, has relied heavily on the development of software tools to process and organize increasingly large datasets, simulate complex mechanistic models, provide tools for the analysis and management of data, and visualize and organize outputs. However, developing high-quality research software requires scientists to develop a host of software development skills, and teaching these skills to students is challenging. There has been a growing importance placed on ensuring reproducibility and good development practices in computational research. However, less attention has been devoted to informing the specific teaching strategies which are effective at nurturing in researchers the complex skillset required to produce high-quality software that, increasingly, is required to underpin both academic and industrial biomedical research. Recent articles in the Ten Simple Rules collection have discussed the teaching of foundational computer science and coding techniques to biology students. We advance this discussion by describing the specific steps for effectively teaching the necessary skills scientists need to develop sustainable software packages which are fit for (re-)use in academic research or more widely. Although our advice is likely to be applicable to all students and researchers hoping to improve their software development skills, our guidelines are directed towards an audience of students that have some programming literacy but little formal training in software development or engineering, typical of early doctoral students. These practices are also applicable outside of doctoral training environments, and we believe they should form a key part of postgraduate training schemes more generally in the life sciences.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Prepared for submission to PLOS Computational Biology's 10 Simple Rules collection"
    },
    {
        "paper id": "2402.04768",
        "abstract url": "https://arxiv.org/abs/2402.04768",
        "title": "Robot Interaction Behavior Generation based on Social Motion Forecasting for Human-Robot Interaction",
        "rating": -4,
        "keywords": [
            [
                "synthesize"
            ],
            [
                "Robot"
            ],
            [
                "Forecasting"
            ]
        ],
        "abstract": "Integrating robots into populated environments is a complex challenge that requires an understanding of human social dynamics. In this work, we propose to model social motion forecasting in a shared human-robot representation space, which facilitates us to synthesize robot motions that interact with humans in social scenarios despite not observing any robot in the motion training. We develop a transformer-based architecture called ECHO, which operates in the aforementioned shared space to predict the future motions of the agents encountered in social scenarios. Contrary to prior works, we reformulate the social motion problem as the refinement of the predicted individual motions based on the surrounding agents, which facilitates the training while allowing for single-motion forecasting when only one human is in the scene. We evaluate our model in multi-person and human-robot motion forecasting tasks and obtain state-of-the-art performance by a large margin while being efficient and performing in real-time. Additionally, our qualitative results showcase the effectiveness of our approach in generating human-robot interaction behaviors that can be controlled via text commands. Webpage: https://evm7.github.io/ECHO/",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at ICRA 2024. Webpage: https://evm7.github.io/ECHO/"
    },
    {
        "paper id": "2402.04770",
        "abstract url": "https://arxiv.org/abs/2402.04770",
        "title": "Continuous-Variable QKD with key rates far above Devetak-Winter",
        "rating": -4,
        "keywords": [
            [
                "watermarking"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Continuous-Variable Quantum Key Distribution (CVQKD) at large distances has such high noise levels that the employed error-correcting codes must have very low rate. In this regime it becomes feasible to implement random-codebook error correction, which is known to perform close to capacity. We propose a random-codebook reverse reconciliation scheme for CVQKD that is inspired by spread-spectrum watermarking. Our scheme has a novel way of achieving statistical decoupling between the publicly sent reconciliation data and the secret key. We provide a theoretical analysis of the secret key rate and we present numerical results. The best performance is obtained when the message size exceeds the mutual information I(X;Y) between Alice and Bob's measurements. This somewhat counter-intuitive result is understood from a tradeoff between code rate and frame rejection rate, combined with the fact that error correction for QKD needs to reconcile only random data. We obtain secret key lengths that lie far above the Devetak-Winter value I(X;Y)-I(E;Y).",
        "subjects": [
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04845",
        "abstract url": "https://arxiv.org/abs/2402.04845",
        "title": "AlphaFold Meets Flow Matching for Generating Protein Ensembles",
        "rating": -4,
        "keywords": [
            [
                "biological"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "The biological functions of proteins often depend on dynamic structural ensembles. In this work, we develop a flow-based generative modeling approach for learning and sampling the conformational landscapes of proteins. We repurpose highly accurate single-state predictors such as AlphaFold and ESMFold and fine-tune them under a custom flow matching framework to obtain sequence-conditoned generative models of protein structure called AlphaFlow and ESMFlow. When trained and evaluated on the PDB, our method provides a superior combination of precision and diversity compared to AlphaFold with MSA subsampling. When further trained on ensembles from all-atom MD, our method accurately captures conformational flexibility, positional distributions, and higher-order ensemble observables for unseen proteins. Moreover, our method can diversify a static PDB structure with faster wall-clock convergence to certain equilibrium properties than replicate MD trajectories, demonstrating its potential as a proxy for expensive physics-based simulations. Code is available at https://github.com/bjing2016/alphaflow.",
        "subjects": [
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04848",
        "abstract url": "https://arxiv.org/abs/2402.04848",
        "title": "Nonlinear behavior of memristive devices for hardware security primitives and neuromorphic computing systems",
        "rating": -4,
        "keywords": [
            [
                "chemical"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Nonlinearity is a crucial characteristic for implementing hardware security primitives or neuromorphic computing systems. The main feature of all memristive devices is this nonlinear behavior observed in their current-voltage characteristics. To comprehend the nonlinear behavior, we have to understand the coexistence of resistive, capacitive, and inertia (virtual inductive) effects in these devices. These effects originate from corresponding physical and chemical processes in memristive devices. A physics-inspired compact model is employed to model and simulate interface-type RRAMs such as Au/BiFeO$_{3}$/Pt/Ti, Au/Nb$_{\\rm x}$O$_{\\rm y}$/Al$_{2}$O$_{3}$/Nb, while accounting for the modeling of capacitive and inertia effects. The simulated current-voltage characteristics align well with experimental data and accurately capture the non-zero crossing hysteresis generated by capacitive and inductive effects. This study examines the response of two devices to increasing frequencies, revealing a shift in their nonlinear behavior characterized by a reduced hysteresis range and increased chaotic behavior, as observed through internal state attractors. Fourier series analysis utilizing a sinusoidal input voltage of varying amplitudes and frequencies indicates harmonics or frequency components that considerably influence the functioning of RRAMs. Moreover, we propose and demonstrate the use of the frequency spectra as one of the fingerprints for memristive devices.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04854",
        "abstract url": "https://arxiv.org/abs/2402.04854",
        "title": "Hierarchical Tree-structured Knowledge Graph For Academic Insight Survey",
        "rating": -4,
        "keywords": [
            [
                "navigation"
            ],
            [
                "Graph"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "Research surveys have always posed a challenge for beginner researchers who lack of research training. These researchers struggle to understand the directions within their research topic, and the discovery of new research findings within a short time. One way to provide intuitive assistance to beginner researchers is by offering relevant knowledge graphs(KG) and recommending related academic papers. However, existing navigation knowledge graphs primarily rely on keywords in the research field and often fail to present the logical hierarchy among multiple related papers clearly. Moreover, most recommendation systems for academic papers simply rely on high text similarity, which can leave researchers confused as to why a particular article is being recommended. They may lack of grasp important information about the insight connection between \"Issue resolved\" and \"Issue finding\" that they hope to obtain. To address these issues, this study aims to support research insight surveys for beginner researchers by establishing a hierarchical tree-structured knowledge graph that reflects the inheritance insight of research topics and the relevance insight among the academic papers.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04862",
        "abstract url": "https://arxiv.org/abs/2402.04862",
        "title": "Tactile Ergodic Control Using Diffusion and Geometric Algebra",
        "rating": -4,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Continuous physical interaction between robots and their environment is a requirement in many industrial and household tasks, such as sanding and cleaning. Due to the complex tactile information, these tasks are notoriously difficult to model and to sense. In this article, we introduce a closed-loop control method that is constrained to surfaces. The applications that we target have in common that they can be represented by probability distributions on the surface that correlate to the time the robot should spend in a region. These surfaces can easily be captured jointly with the target distributions using coloured point clouds. We present the extension of an ergodic control approach that can be used with point clouds, based on heat equation-driven area coverage (HEDAC). Our method enables closed-loop exploration by measuring the actual coverage using vision. Unlike existing approaches, we approximate the potential field from non-stationary diffusion using spectral acceleration, which does not require complex preprocessing steps and achieves real-time closed-loop control frequencies. We exploit geometric algebra to stay in contact with the target surface by tracking a line while simultaneously exerting a desired force along that line. Our approach is suitable for fully autonomous and human-robot interaction settings where the robot can either directly measure the coverage of the target with its sensors or by being guided online by markings or annotations of a human expert. We tested the performance of the approach in kinematic simulation using point clouds, ranging from the Stanford bunny to a variety of kitchen utensils. Our real-world experiments demonstrate that the proposed approach can successfully be used to wash kitchenware with curved surfaces, by cleaning the dirt detected by vision in an online manner. Website: https://geometric-algebra.tobiloew.ch/tactile_ergodic_control",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to the special issue for IEEE Transactions on Robotics (T-RO) on Tactile Robotics"
    },
    {
        "paper id": "2402.04894",
        "abstract url": "https://arxiv.org/abs/2402.04894",
        "title": "Deep Reinforcement Learning with Dynamic Graphs for Adaptive Informative Path Planning",
        "rating": -4,
        "keywords": [
            [
                "3D"
            ],
            [
                "vehicle"
            ],
            [
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Autonomous robots are often employed for data collection due to their efficiency and low labour costs. A key task in robotic data acquisition is planning paths through an initially unknown environment to collect observations given platform-specific resource constraints, such as limited battery life. Adaptive online path planning in 3D environments is challenging due to the large set of valid actions and the presence of unknown occlusions. To address these issues, we propose a novel deep reinforcement learning approach for adaptively replanning robot paths to map targets of interest in unknown 3D environments. A key aspect of our approach is a dynamically constructed graph that restricts planning actions local to the robot, allowing us to quickly react to newly discovered obstacles and targets of interest. For replanning, we propose a new reward function that balances between exploring the unknown environment and exploiting online-collected data about the targets of interest. Our experiments show that our method enables more efficient target detection compared to state-of-the-art learning and non-learning baselines. We also show the applicability of our approach for orchard monitoring using an unmanned aerial vehicle in a photorealistic simulator.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2402.05273",
        "abstract url": "https://arxiv.org/abs/2402.05273",
        "title": "ASCENT: A Context-Aware Spectrum Coexistence Design and Implementation Toolset for Policymakers in Satellite Bands",
        "rating": -4,
        "keywords": [
            [
                "5G"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "This paper introduces ASCENT (context Aware Spectrum Coexistence Design and Implementation) toolset, an advanced context-aware terrestrial satellite spectrum sharing toolset designed for researchers, policymakers, and regulators. It serves two essential purposes (a) evaluating the potential for harmful interference to primary users in satellite bands and (b) facilitating the analysis, design, and implementation of diverse regulatory policies on spectrum usage and sharing. Notably, ASCENT implements a closed-loop feedback system that allows dynamic adaptation of policies according to a wide range of contextual factors (e.g., weather, buildings, summer/winter foliage, etc.) and feedback on the impact of these policies through realistic simulation. Specifically, ASCENT comprises the following components (i) interference evaluation tool for evaluating interference at the incumbents in a spectrum-sharing environment while taking the underlying contexts, (ii) dynamic spectrum access (DSA) framework for providing context-aware instructions to adapt networking parameters and control secondary terrestrial network's access to the shared spectrum band according to context aware prioritization, (iii) Context broker to acquire essential and relevant contexts from external context information providers; and (iv) DSA Database to store dynamic and static contexts and the regulator's policy information. The closed-loop feedback system of ASCENT is implemented by integrating these components in a modular software architecture. A case study of sharing the lower 12 GHz Ku band (12.2-12.7 GHz) with the 5G terrestrial cellular network is considered, and the usability of ASCENT is demonstrated by dynamically changing exclusion zone's radius in different weather conditions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05281",
        "abstract url": "https://arxiv.org/abs/2402.05281",
        "title": "Physics Informed and Data Driven Simulation of Underwater Images via Residual Learning",
        "rating": -4,
        "keywords": [
            [
                "depth"
            ],
            [
                "dehazing"
            ],
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In general, underwater images suffer from color distortion and low contrast, because light is attenuated and backscattered as it propagates through water (differently depending on wavelength and on the properties of the water body). An existing simple degradation model (similar to atmospheric image \"hazing\" effects), though helpful, is not sufficient to properly represent the underwater image degradation because there are unaccounted for and non-measurable factors e.g. scattering of light due to turbidity of water, reflective characteristics of turbid medium etc. We propose a deep learning-based architecture to automatically simulate the underwater effects where only a dehazing-like image formation equation is known to the network, and the additional degradation due to the other unknown factors if inferred in a data-driven way. We only use RGB images (because in real-time scenario depth image is not available) to estimate the depth image. For testing, we have proposed (due to the lack of real underwater image datasets) a complex image formation model/equation to manually generate images that resemble real underwater images (used as ground truth). However, only the classical image formation equation (the one used for image dehazing) is informed to the network. This mimics the fact that in a real scenario, the physics are never completely known and only simplified models are known. Thanks to the ground truth, generated by a complex image formation equation, we could successfully perform a qualitative and quantitative evaluation of proposed technique, compared to other purely data driven approaches",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05330",
        "abstract url": "https://arxiv.org/abs/2402.05330",
        "title": "Classification under Nuisance Parameters and Generalized Label Shift in Likelihood-Free Inference",
        "rating": -4,
        "keywords": [
            [
                "biology"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "An open scientific challenge is how to classify events with reliable measures of uncertainty, when we have a mechanistic model of the data-generating process but the distribution over both labels and latent nuisance parameters is different between train and target data. We refer to this type of distributional shift as generalized label shift (GLS). Direct classification using observed data $\\mathbf{X}$ as covariates leads to biased predictions and invalid uncertainty estimates of labels $Y$. We overcome these biases by proposing a new method for robust uncertainty quantification that casts classification as a hypothesis testing problem under nuisance parameters. The key idea is to estimate the classifier's receiver operating characteristic (ROC) across the entire nuisance parameter space, which allows us to devise cutoffs that are invariant under GLS. Our method effectively endows a pre-trained classifier with domain adaptation capabilities and returns valid prediction sets while maintaining high power. We demonstrate its performance on two challenging scientific problems in biology and astroparticle physics with data from realistic mechanistic models.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "25 pages, 18 figures"
    },
    {
        "paper id": "2402.05979",
        "abstract url": "https://arxiv.org/abs/2402.05979",
        "title": "On the Standardization of Behavioral Use Clauses and Their Adoption for Responsible Licensing of AI",
        "rating": -4,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robotics"
            ],
            [
                "medical"
            ]
        ],
        "abstract": "Growing concerns over negligent or malicious uses of AI have increased the appetite for tools that help manage the risks of the technology. In 2018, licenses with behaviorial-use clauses (commonly referred to as Responsible AI Licenses) were proposed to give developers a framework for releasing AI assets while specifying their users to mitigate negative applications. As of the end of 2023, on the order of 40,000 software and model repositories have adopted responsible AI licenses licenses. Notable models licensed with behavioral use clauses include BLOOM (language) and LLaMA2 (language), Stable Diffusion (image), and GRID (robotics). This paper explores why and how these licenses have been adopted, and why and how they have been adapted to fit particular use cases. We use a mixed-methods methodology of qualitative interviews, clustering of license clauses, and quantitative analysis of license adoption. Based on this evidence we take the position that responsible AI licenses need standardization to avoid confusing users or diluting their impact. At the same time, customization of behavioral restrictions is also appropriate in some contexts (e.g., medical domains). We advocate for ``standardized customization'' that can meet users' needs and can be supported via tooling.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05973",
        "abstract url": "https://arxiv.org/abs/2402.05973",
        "title": "Blockchain-enabled Clustered and Scalable Federated Learning (BCS-FL) Framework in UAV Networks",
        "rating": -5.0,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Federated Learning"
            ],
            [
                "graph"
            ],
            [
                "UAV"
            ],
            [
                "cs.LG"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Privacy, scalability, and reliability are significant challenges in unmanned aerial vehicle (UAV) networks as distributed systems, especially when employing machine learning (ML) technologies with substantial data exchange. Recently, the application of federated learning (FL) to UAV networks has improved collaboration, privacy, resilience, and adaptability, making it a promising framework for UAV applications. However, implementing FL for UAV networks introduces drawbacks such as communication overhead, synchronization issues, scalability limitations, and resource constraints. To address these challenges, this paper presents the Blockchain-enabled Clustered and Scalable Federated Learning (BCS-FL) framework for UAV networks. This improves the decentralization, coordination, scalability, and efficiency of FL in large-scale UAV networks. The framework partitions UAV networks into separate clusters, coordinated by cluster head UAVs (CHs), to establish a connected graph. Clustering enables efficient coordination of updates to the ML model. Additionally, hybrid inter-cluster and intra-cluster model aggregation schemes generate the global model after each training round, improving collaboration and knowledge sharing among clusters. The numerical findings illustrate the achievement of convergence while also emphasizing the trade-offs between the effectiveness of training and communication efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "6 pages, 7 figures, 2023 IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (IEEE CAMAD), Edinburgh UK"
    },
    {
        "paper id": "2402.04586",
        "abstract url": "https://arxiv.org/abs/2402.04586",
        "title": "Efficient anytime algorithms to solve the bi-objective Next Release Problem",
        "rating": -10,
        "keywords": [],
        "abstract": "The Next Release Problem consists in selecting a subset of requirements to develop in the next release of a software product. The selection should be done in a way that maximizes the satisfaction of the stakeholders while the development cost is minimized and the constraints of the requirements are fulfilled. Recent works have solved the problem using exact methods based on Integer Linear Programming. In practice, there is no need to compute all the efficient solutions of the problem; a well-spread set in the objective space is more convenient for the decision maker. The exact methods used in the past to find the complete Pareto front explore the objective space in a lexicographic order or use a weighted sum of the objectives to solve a single-objective problem, finding only supported solutions. In this work, we propose five new methods that maintain a well-spread set of solutions at any time during the search, so that the decision maker can stop the algorithm when a large enough set of solutions is found. The methods are called anytime due to this feature. They find both supported and non-supported solutions, and can complete the whole Pareto front if the time provided is long enough.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04590",
        "abstract url": "https://arxiv.org/abs/2402.04590",
        "title": "Concurrent Strategies on Games with Algebras",
        "rating": -10,
        "keywords": [],
        "abstract": "Probabilistic concurrent/distributed strategies have so far not been investigated thoroughly in the context of imperfect information, where the Player has only partial knowledge of the moves made by the Opponent. In a situation where the Player and Opponent can make concurrent moves according to the game, and the Player cannot see the move of the Opponent, the move of the Player should be probabilistically independent of the move of the Opponent. What has been achieved is showing a bijection between strategies on a game with algebra and strategies on a regular (albeit more complex) game. We also succeeded in showing the results holds with neutral events. However it is still unclear if a well-formed bicategory of concurrent games with algebras can be defined. Our attempts to compose these strategies while managing the added structure didn't pan out. Concerning the other classic extensions of concurrent games the first results we presented show promise of a more general usage of games with algebra.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "20 pages report as part of a master's degree internship"
    },
    {
        "paper id": "2402.04602",
        "abstract url": "https://arxiv.org/abs/2402.04602",
        "title": "Online Quantile Regression",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper addresses the challenge of integrating sequentially arriving data within the quantile regression framework, where the number of features is allowed to grow with the number of observations, the horizon is unknown, and memory is limited. We employ stochastic sub-gradient descent to minimize the empirical check loss and study its statistical properties and regret performance. In our analysis, we unveil the delicate interplay between updating iterates based on individual observations versus batches of observations, revealing distinct regularity properties in each scenario. Our method ensures long-term optimal estimation irrespective of the chosen update strategy. Importantly, our contributions go beyond prior works by achieving exponential-type concentration inequalities and attaining optimal regret and error rates that exhibit only \\textsf{ short-term} sensitivity to initial errors. A key insight from our study is the delicate statistical analyses and the revelation that appropriate stepsize schemes significantly mitigate the impact of initial errors on subsequent errors and regrets. This underscores the robustness of stochastic sub-gradient descent in handling initial uncertainties, emphasizing its efficacy in scenarios where the sequential arrival of data introduces uncertainties regarding both the horizon and the total number of observations. Additionally, when the initial error rate is well-controlled, there is a trade-off between short-term error rate and long-term optimality. Due to the lack of delicate statistical analysis for squared loss, we also briefly discuss its properties and proper schemes. Extensive simulations support our theoretical findings.",
        "subjects": [
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04607",
        "abstract url": "https://arxiv.org/abs/2402.04607",
        "title": "Google Scholar is manipulatable",
        "rating": -10,
        "keywords": [],
        "abstract": "Citations are widely considered in scientists' evaluation. As such, scientists may be incentivized to inflate their citation counts. While previous literature has examined self-citations and citation cartels, it remains unclear whether scientists can purchase citations. Here, we compile a dataset of ~1.6 million profiles on Google Scholar to examine instances of citation fraud on the platform. We survey faculty at highly-ranked universities, and confirm that Google Scholar is widely used when evaluating scientists. Intrigued by a citation-boosting service that we unravelled during our investigation, we contacted the service while undercover as a fictional author, and managed to purchase 50 citations. These findings provide conclusive evidence that citations can be bought in bulk, and highlight the need to look beyond citation counts.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04613",
        "abstract url": "https://arxiv.org/abs/2402.04613",
        "title": "Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces",
        "rating": -10,
        "keywords": [],
        "abstract": "Most commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy consists of regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. In this paper, we use the so-called kernel mean embedding to show that the corresponding regularization can be rewritten as the Moreau envelope of some function in the reproducing kernel Hilbert space associated with $K$. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to prove properties of the MMD-regularized $f$-divergences and, in particular, their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. Finally, we consider Wasserstein gradient flows starting from empirical measures. We provide proof-of-the-concept numerical examples for $f$-divergences with both infinite and finite recession constant.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "46 pages, 13 figures"
    },
    {
        "paper id": "2402.04623",
        "abstract url": "https://arxiv.org/abs/2402.04623",
        "title": "Validity-Preserving Delta Debugging via Generator",
        "rating": -10,
        "keywords": [],
        "abstract": "Reducing test inputs that trigger bugs is crucial for efficient debugging. Delta debugging is the most popular approach for this purpose. When test inputs need to conform to certain specifications, existing delta debugging practice encounters a validity problem: it blindly applies reduction rules, producing a large number of invalid test inputs that do not satisfy the required specifications. This overall diminishing effectiveness and efficiency becomes even more pronounced when the specifications extend beyond syntactical structures. Our key insight is that we should leverage input generators, which are aware of these specifications, to generate valid reduced inputs, rather than straightforwardly performing reduction on test inputs. In this paper, we propose a generator-based delta debugging method, namely GReduce, which derives validity-preserving reducers. Specifically, given a generator and its execution, demonstrating how the bug-inducing test input is generated, GReduce searches for other executions on the generator that yield reduced, valid test inputs. To evaluate the effectiveness, efficiency, and versatility of GReduce, we apply GReduce and the state-of-the-art reducer Perses in three domains: graphs, deep learning models, and JavaScript programs. The results of GReduce are 28.5%, 34.6%, 75.6% in size of those from Perses, and GReduce takes 17.5%, 0.6%, 65.4% time taken by Perses.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04634",
        "abstract url": "https://arxiv.org/abs/2402.04634",
        "title": "No Transaction Fees? No Problem! Achieving Fairness in Transaction Fee Mechanism Design",
        "rating": -10,
        "keywords": [],
        "abstract": "The recently proposed Transaction Fee Mechanism (TFM) literature studies the strategic interaction between the miner of a block and the transaction creators (or users) in a blockchain. In a TFM, the miner includes transactions that maximize its utility while users submit fees for a slot in the block. The existing TFM literature focuses on satisfying standard incentive properties -- which may limit widespread adoption. We argue that a TFM is \"fair\" to the transaction creators if it satisfies specific notions, namely Zero-fee Transaction Inclusion and Monotonicity. First, we prove that one generally cannot ensure both these properties and prevent a miner's strategic manipulation. We also show that existing TFMs either do not satisfy these notions or do so at a high cost to the miners' utility. As such, we introduce a novel TFM using on-chain randomness -- rTFM. We prove that rTFM guarantees incentive compatibility for miners and users while satisfying our novel fairness constraints.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "Extended Abstract (AAMAS '24)"
    },
    {
        "paper id": "2402.04645",
        "abstract url": "https://arxiv.org/abs/2402.04645",
        "title": "Capacity Modification in the Stable Matching Problem",
        "rating": -10,
        "keywords": [],
        "abstract": "We study the problem of capacity modification in the many-to-one stable matching of workers and firms. Our goal is to systematically study how the set of stable matchings changes when some seats are added to or removed from the firms. We make three main contributions: First, we examine whether firms and workers can improve or worsen upon changing the capacities under worker-proposing and firm-proposing deferred acceptance algorithms. Second, we study the computational problem of adding or removing seats to either match a fixed worker-firm pair in some stable matching or make a fixed matching stable with respect to the modified problem. We develop polynomial-time algorithms for these problems when only the overall change in the firms' capacities is restricted, and show NP-hardness when there are additional constraints for individual firms. Lastly, we compare capacity modification with the classical model of preference manipulation by firms and identify scenarios under which one mode of manipulation outperforms the other. We find that a threshold on a given firm's capacity, which we call its peak, crucially determines the effectiveness of different manipulation actions.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04660",
        "abstract url": "https://arxiv.org/abs/2402.04660",
        "title": "Adversarial Robustness Through Artifact Design",
        "rating": -10,
        "keywords": [],
        "abstract": "Adversarial examples arose as a challenge for machine learning. To hinder them, most defenses alter how models are trained (e.g., adversarial training) or inference is made (e.g., randomized smoothing). Still, while these approaches markedly improve models' adversarial robustness, models remain highly susceptible to adversarial examples. Identifying that, in certain domains such as traffic-sign recognition, objects are implemented per standards specifying how artifacts (e.g., signs) should be designed, we propose a novel approach for improving adversarial robustness. Specifically, we offer a method to redefine standards, making minor changes to existing ones, to defend against adversarial examples. We formulate the problem of artifact design as a robust optimization problem, and propose gradient-based and greedy search methods to solve it. We evaluated our approach in the domain of traffic-sign recognition, allowing it to alter traffic-sign pictograms (i.e., symbols within the signs) and their colors. We found that, combined with adversarial training, our approach led to up to 25.18\\% higher robust accuracy compared to state-of-the-art methods against two adversary types, while further increasing accuracy on benign inputs.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04663",
        "abstract url": "https://arxiv.org/abs/2402.04663",
        "title": "CLIF: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Spiking neural networks (SNNs) are promising brain-inspired energy-efficient models. Compared to conventional deep Artificial Neural Networks (ANNs), SNNs exhibit superior efficiency and capability to process temporal information. However, it remains a challenge to train SNNs due to their undifferentiable spiking mechanism. The surrogate gradients method is commonly used to train SNNs, but often comes with an accuracy disadvantage over ANNs counterpart. We link the degraded accuracy to the vanishing of gradient on the temporal dimension through the analytical and experimental study of the training process of Leaky Integrate-and-Fire (LIF) Neuron-based SNNs. Moreover, we propose the Complementary Leaky Integrate-and-Fire (CLIF) Neuron. CLIF creates extra paths to facilitate the backpropagation in computing temporal gradient while keeping binary output. CLIF is hyperparameter-free and features broad applicability. Extensive experiments on a variety of datasets demonstrate CLIF's clear performance advantage over other neuron models. Moreover, the CLIF's performance even slightly surpasses superior ANNs with identical network structure and training conditions.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04665",
        "abstract url": "https://arxiv.org/abs/2402.04665",
        "title": "Gaussian Process-Based Nonlinear Moving Horizon Estimation",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we propose a novel Gaussian process-based moving horizon estimation (MHE) framework for unknown nonlinear systems. In the proposed scheme, we take advantage of the properties of Gaussian processes. On the one hand, we approximate the system dynamics by the posterior means of the learned Gaussian processes (GPs). On the other hand, we exploit the posterior variances of the Gaussian processes to design the weighting matrices in the MHE cost function and account for the uncertainty in the learned system dynamics. The data collection and the tuning of the hyperparameters are done offline. We prove robust stability of the GP-based MHE scheme using a Lyapunov-based proof technique. Furthermore, as additional contribution, we analyze under which conditions incremental input/output-to-state stability (a nonlinear detectability notion) is preserved when approximating the system dynamics using, e.g., machine learning techniques. Finally, we illustrate the performance of the GP-based MHE scheme in a simulation case study and show how the chosen weighting matrices can lead to an improved performance compared to standard cost functions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2402.04667",
        "abstract url": "https://arxiv.org/abs/2402.04667",
        "title": "A Comparative Study of Sensitivity Computations in ESDIRK-Based Optimal Control Problems",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we compare the impact of iterated and direct approaches to sensitivity computation in fixed-step explicit singly diagonally-implicit Runge-Kutta (ESDIRK) methods when applied to optimal control problems (OCPs). We use the principle of internal numerical differentiation (IND) strictly for the iterated approach, i.e., reusing the iteration matrix factorizations, the number of Newton-type iterations, and Newton iterates, to compute the sensitivities. The direct method computes the sensitivities without using the Newton schemes. We compare the impact of the iterated and direct sensitivity computations in OCPs for the quadruple tank system. We benchmark the iterated and direct approaches with a base case. This base case is an OCP that applies an ESDIRK method that refactorizes the iteration matrix in every Newton iteration and uses a direct approach for sensitivity computations. In these OCPs, we vary the number of integration steps between control intervals and we evaluate the performance based on the number of SQP and QPs iterations, KKT violations, and the total number of function evaluations, Jacobian updates, and iteration matrix factorizations. The results indicate that the iterated approach outperforms the direct approach but yields similar performance to the base case.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 5 figures, 2 tables. Submitted for European Control Conference 2024 (ECC2024). Stockholm, Sweden"
    },
    {
        "paper id": "2402.04684",
        "abstract url": "https://arxiv.org/abs/2402.04684",
        "title": "Towards a Parallel Summation Algorithm",
        "rating": -10,
        "keywords": [],
        "abstract": "We propose a summation analog of the paradigm of parallel integration. Using this paradigm, we make some first steps towards an indefinite summation algorithm applicable to summands that rationally depend on the summation index and a P-recursive sequence and its shifts. Under the assumption that the corresponding difference field has no unnatural constants, we are able to compute a bound on the normal part of the denominator of a potential closed form. We can also handle the numerator. Our algorithm is incomplete so far as we cannot predict the special part of the denominator. However, we do have some structural results about special polynomials for the setting under consideration.",
        "subjects": [
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04685",
        "abstract url": "https://arxiv.org/abs/2402.04685",
        "title": "Robust Symbol-Level Precoding for Massive MIMO Communication Under Channel Aging",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper investigates the robust design of symbol-level precoding (SLP) for multiuser multiple-input multiple-output (MIMO) downlink transmission with imperfect channel state information (CSI) caused by channel aging. By utilizing the a posteriori channel model based on the widely adopted jointly correlated channel model, the imperfect CSI is modeled as the statistical CSI incorporating the channel mean and channel variance information with spatial correlation. With the signal model in the presence of channel aging, we formulate the signal-to-noise-plus-interference ratio (SINR) balancing and minimum mean square error (MMSE) problems for robust SLP design. The former targets to maximize the minimum SINR across users, while the latter minimizes the mean square error between the received signal and the target constellation point. When it comes to massive MIMO scenarios, the increment in the number of antennas poses a computational complexity challenge, limiting the deployment of SLP schemes. To address such a challenge, we simplify the objective function of the SINR balancing problem and further derive a closed-form SLP scheme. Besides, by approximating the matrix involved in the computation, we modify the proposed algorithm and develop an MMSE-based SLP scheme with lower computation complexity. Simulation results confirm the superiority of the proposed schemes over the state-of-the-art SLP schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04691",
        "abstract url": "https://arxiv.org/abs/2402.04691",
        "title": "Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces",
        "rating": -10,
        "keywords": [],
        "abstract": "This study investigates leveraging stochastic gradient descent (SGD) to learn operators between general Hilbert spaces. We propose weak and strong regularity conditions for the target operator to depict its intrinsic structure and complexity. Under these conditions, we establish upper bounds for convergence rates of the SGD algorithm and conduct a minimax lower bound analysis, further illustrating that our convergence analysis and regularity conditions quantitatively characterize the tractability of solving operator learning problems using the SGD algorithm. It is crucial to highlight that our convergence analysis is still valid for nonlinear operator learning. We show that the SGD estimator will converge to the best linear approximation of the nonlinear target operator. Moreover, applying our analysis to operator learning problems based on vector-valued and real-valued reproducing kernel Hilbert spaces yields new convergence results, thereby refining the conclusions of existing literature.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "56 pages"
    },
    {
        "paper id": "2402.04692",
        "abstract url": "https://arxiv.org/abs/2402.04692",
        "title": "From explained variance of correlated components to PCA without orthogonality constraints",
        "rating": -10,
        "keywords": [],
        "abstract": "Block Principal Component Analysis (Block PCA) of a data matrix A, where loadings Z are determined by maximization of AZ 2 over unit norm orthogonal loadings, is difficult to use for the design of sparse PCA by 1 regularization, due to the difficulty of taking care of both the orthogonality constraint on loadings and the non differentiable 1 penalty. Our objective in this paper is to relax the orthogonality constraint on loadings by introducing new objective functions expvar(Y) which measure the part of the variance of the data matrix A explained by correlated components Y = AZ. So we propose first a comprehensive study of mathematical and numerical properties of expvar(Y) for two existing definitions Zou et al. [2006], Shen and Huang [2008] and four new definitions. Then we show that only two of these explained variance are fit to use as objective function in block PCA formulations for A rid of orthogonality constraints.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04701",
        "abstract url": "https://arxiv.org/abs/2402.04701",
        "title": "Exhaustive Classification and Quantification of Coupling Modes in Power Systems with Power Electronics",
        "rating": -10,
        "keywords": [],
        "abstract": "Due to the energy transition, today's electrical networks include synchronous machines and inverter-based resources interfacing renewable energies such as wind turbines, solar panels, and Battery Energy Storage Systems to the grid. In such systems, interactions known as coupling modes or dynamic interactions, between synchronous machines and inverter-based resources may arise. This paper conducts a clear and exhaustive study on a proposed benchmark, in order to analyze, quantify and classify these new types of modes. Detailed models representing electromagnetic transient phenomena are developed and linearized, then used for conducting modal analysis to fully characterize the small-signal stability of the system. Also, a sensitivity analysis is presented to evaluate the impact of key parameters on the detected modes of oscillation. Besides the exhaustive classification of the possible coupling modes, the proposed benchmark and methodology can be used to study any given power system in a minimal order modeling. The case of a fully detailed power grid based on the IEEE 39 bus system was studied as an illustrative example.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04718",
        "abstract url": "https://arxiv.org/abs/2402.04718",
        "title": "Adaptive Smooth Control via Nonsingular Fast Terminal Sliding Mode for Distributed Space Telescope Demonstration Mission by CubeSat Formation Flying",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper investigates the efficiency of nonsingular fast terminal sliding mode and adaptive smooth control method for the distributed space telescope demonstration mission. The distributed space telescope has a flexible focal length that corresponds to the relative position of the formation flying concept. The precise formation flying technology by CubeSats enhances the utility of distributed space systems with low costs. The propulsion systems for CubeSats usually have restricted degrees of freedom. Since the scientific mission requires continuous orbit control, the attitude and orbit control system mutually affect the control performance. The nonsingular fast terminal sliding mode has the advantage of a fast convergence rate and is able to improve the control performance. The adaptive smooth controller designed for the SISO system is expanded and applied to the attitude and orbit control system. The simulation results verify the efficiency of the adaptive smooth controller based on the nonsingular fast terminal sliding mode.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04728",
        "abstract url": "https://arxiv.org/abs/2402.04728",
        "title": "Detection Schemes with Low-Resolution ADCs and Spatial Oversampling for Transmission with Higher-Order Constellations in the Terahertz Band",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we consider Terahertz (THz) communications with low-resolution uniform quantization and spatial oversampling at the receiver side. We compare different analog-to-digital converter (ADC) parametrizations in a fair manner by keeping the ADC power consumption constant. Here, 1-, 2-, and 3-bit quantization is investigated with different oversampling factors. We analytically compute the statistics of the detection variable, and we propose the optimal as well as several suboptimal detection schemes for arbitrary quantization resolutions. Then, we evaluate the symbol error rate (SER) of the different detectors for a 16- and a 64-ary quadrature amplitude modulation (QAM) constellation. The results indicate that there is a noticeable performance degradation of the suboptimal detection schemes compared to the optimal scheme when the constellation size is larger than the number of quantization levels. Furthermore, at low signal-to-noise ratios (SNRs), 1-bit quantization outperforms 2- and 3-bit quantization, respectively, even when employing higher-order constellations. We confirm our analytical results by Monte Carlo simulations. Both a pure line-of-sight (LoS) and a more realistically modeled indoor THz channel are considered. Then, we optimize the input signal constellation with respect to SER for 1-bit quantization. The results show that the minimum SER can be lowered significantly for 16-QAM by increasing the distance between the inner and outer points of the input constellation. For larger constellations, however, the achievable reduction of the minimum SER is much smaller compared to 16-QAM.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "14 pages, 19 figures, submitted for possible journal publication"
    },
    {
        "paper id": "2402.04740",
        "abstract url": "https://arxiv.org/abs/2402.04740",
        "title": "Non-Parametric Estimation of Multi-dimensional Marked Hawkes Processes",
        "rating": -10,
        "keywords": [],
        "abstract": "An extension of the Hawkes process, the Marked Hawkes process distinguishes itself by featuring variable jump size across each event, in contrast to the constant jump size observed in a Hawkes process without marks. While extensive literature has been dedicated to the non-parametric estimation of both the linear and non-linear Hawkes process, there remains a significant gap in the literature regarding the marked Hawkes process. In response to this, we propose a methodology for estimating the conditional intensity of the marked Hawkes process. We introduce two distinct models: \\textit{Shallow Neural Hawkes with marks}- for Hawkes processes with excitatory kernels and \\textit{Neural Network for Non-Linear Hawkes with Marks}- for non-linear Hawkes processes. Both these approaches take the past arrival times and their corresponding marks as the input to obtain the arrival intensity. This approach is entirely non-parametric, preserving the interpretability associated with the marked Hawkes process. To validate the efficacy of our method, we subject the method to synthetic datasets with known ground truth. Additionally, we apply our method to model cryptocurrency order book data, demonstrating its applicability to real-world scenarios.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04742",
        "abstract url": "https://arxiv.org/abs/2402.04742",
        "title": "Interference Simulator for the Whole HF Band: Application to CW-Morse",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we use jointly a model of narrow band interference and a congestion model to model and implement an interference simulator for the whole HF band. The result is a model to generate interfering signals that could be found in a given frequency allocation, at a given time (past, present, or future) and for a given location. Our model does not require measurements and it is characterized by its ease of use and the freedom it offers to choose scene (modulation, location, week, year, etc.). In addition, we have defined a generic modulating function and the conditions to model a contact continuous wave (CW)-Morse, which meets the usual standards of contest. Consequently, our interference model in conjunction with the CW-Morse modulating function designed results in a specific CW-Morse model for amateur contests. As an example of the simulation model, we simulate the CW-Morse communications on the contest ARR ARRL Field Day 2011.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2402.04746",
        "abstract url": "https://arxiv.org/abs/2402.04746",
        "title": "Black Hole Search in Dynamic Tori",
        "rating": -10,
        "keywords": [],
        "abstract": "We investigate the black hole search problem by a set of mobile agents in a dynamic torus. Black hole is defined to be a dangerous stationary node which has the capability to destroy any number of incoming agents without leaving any trace of its existence. A torus of size $n\\times m$ ($3\\leq n \\leq m$) is a collection of $n$ row rings and $m$ column rings, and the dynamicity is such that each ring is considered to be 1-interval connected, i.e., in other words at most one edge can be missing from each ring at any round. The parameters which define the efficiency of any black hole search algorithm are: the number of agents and the number of rounds (or \\textit{time}) for termination. We consider two initial configurations of mobile agents: first, the agents are co-located and second, the agents are scattered. In each case, we establish lower and upper bounds on the number of agents and on the amount of time required to solve the black hole search problem.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04763",
        "abstract url": "https://arxiv.org/abs/2402.04763",
        "title": "Emergence of specialized Collective Behaviors in Evolving Heterogeneous Swarms",
        "rating": -10,
        "keywords": [],
        "abstract": "Natural groups of animals, such as swarms of social insects, exhibit astonishing degrees of task specialization, useful to address complex tasks and to survive. This is supported by phenotypic plasticity: individuals sharing the same genotype that is expressed differently for different classes of individuals, each specializing in one task. In this work, we evolve a swarm of simulated robots with phenotypic plasticity to study the emergence of specialized collective behavior during an emergent perception task. Phenotypic plasticity is realized in the form of heterogeneity of behavior by dividing the genotype into two components, with one different neural network controller associated to each component. The whole genotype, expressing the behavior of the whole group through the two components, is subject to evolution with a single fitness function. We analyse the obtained behaviors and use the insights provided by these results to design an online regulatory mechanism. Our experiments show three main findings: 1) The sub-groups evolve distinct emergent behaviors. 2) The effectiveness of the whole swarm depends on the interaction between the two sub-groups, leading to a more robust performance than with singular sub-group behavior. 3) The online regulatory mechanism enhances overall performance and scalability.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04782",
        "abstract url": "https://arxiv.org/abs/2402.04782",
        "title": "From fuzzy information to community detection: an approach to social networks analysis with soft information",
        "rating": -10,
        "keywords": [],
        "abstract": "On the basis of network analysis, and within the context of modeling imprecision or vague information with fuzzy sets, we propose an innovative way to analyze, aggregate and apply this uncertain knowledge into community detection of real-life problems. This work is set on the existence of one (or multiple) soft information sources, independent of the network considered, assuming this extra knowledge is modeled by a vector of fuzzy sets (or a family of vectors). This information may represent, for example, how much some people agree with a specific law, or their position against several politicians. We emphasize the importance of being able to manage the vagueness which usually appears in real life because of the common use of linguistic terms. Then, we propose a constructive method to build fuzzy measures from fuzzy sets. These measures are the basis of a new representation model which combines the information of a network with that of fuzzy sets, specifically when it comes to linguistic terms. We propose a specific application of that model in terms of finding communities in a network with additional soft information. To do so, we propose an efficient algorithm and measure its performance by means of a benchmarking process, obtaining high-quality results.",
        "subjects": [
            "math.ST"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2402.04785",
        "abstract url": "https://arxiv.org/abs/2402.04785",
        "title": "Shadowheart SGD: Distributed Asynchronous SGD with Optimal Time Complexity Under Arbitrary Computation and Communication Heterogeneity",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider nonconvex stochastic optimization problems in the asynchronous centralized distributed setup where the communication times from workers to a server can not be ignored, and the computation and communication times are potentially different for all workers. Using an unbiassed compression technique, we develop a new method-Shadowheart SGD-that provably improves the time complexities of all previous centralized methods. Moreover, we show that the time complexity of Shadowheart SGD is optimal in the family of centralized methods with compressed communication. We also consider the bidirectional setup, where broadcasting from the server to the workers is non-negligible, and develop a corresponding method.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04799",
        "abstract url": "https://arxiv.org/abs/2402.04799",
        "title": "Strongly Polynomial Frame Scaling to High Precision",
        "rating": -10,
        "keywords": [],
        "abstract": "The frame scaling problem is: given vectors $U := \\{u_{1}, ..., u_{n} \\} \\subseteq \\mathbb{R}^{d}$, marginals $c \\in \\mathbb{R}^{n}_{++}$, and precision $\\varepsilon > 0$, find left and right scalings $L \\in \\mathbb{R}^{d \\times d}, r \\in \\mathbb{R}^n$ such that $(v_1,\\dots,v_n) := (Lu_1 r_1,\\dots,Lu_nr_n)$ simultaneously satisfies $\\sum_{i=1}^n v_i v_i^{\\mathsf{T}} = I_d$ and $\\|v_{j}\\|_{2}^{2} = c_{j}, \\forall j \\in [n]$, up to error $\\varepsilon$. This problem has appeared in a variety of fields throughout linear algebra and computer science. In this work, we give a strongly polynomial algorithm for frame scaling with $\\log(1/\\varepsilon)$ convergence. This answers a question of Diakonikolas, Tzamos and Kane (STOC 2023), who gave the first strongly polynomial randomized algorithm with poly$(1/\\varepsilon)$ convergence for the special case $c = \\frac{d}{n} 1_{n}$. Our algorithm is deterministic, applies for general $c \\in \\mathbb{R}^{n}_{++}$, and requires $O(n^{3} \\log(n/\\varepsilon))$ iterations as compared to $O(n^{5} d^{11}/\\varepsilon^{5})$ iterations of DTK. By lifting the framework of Linial, Samorodnitsky and Wigderson (Combinatorica 2000) for matrix scaling to frames, we are able to simplify both the algorithm and analysis. Our main technical contribution is to generalize the potential analysis of LSW to the frame setting and compute an update step in strongly polynomial time that achieves geometric progress in each iteration. In fact, we can adapt our results to give an improved analysis of strongly polynomial matrix scaling, reducing the $O(n^{5} \\log(n/\\varepsilon))$ iteration bound of LSW to $O(n^{3} \\log(n/\\varepsilon))$. Additionally, we prove a novel bound on the size of approximate frame scaling solutions, involving the condition measure $\\bar\u03c7$ studied in the linear programming literature, which may be of independent interest.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "Comments welcome"
    },
    {
        "paper id": "2402.04811",
        "abstract url": "https://arxiv.org/abs/2402.04811",
        "title": "Accurate Coverage Metrics for Compiler-Generated Debugging Information",
        "rating": -10,
        "keywords": [],
        "abstract": "Many debugging tools rely on compiler-produced metadata to present a source-language view of program states, such as variable values and source line numbers. While this tends to work for unoptimised programs, current compilers often generate only partial debugging information in optimised programs. Current approaches for measuring the extent of coverage of local variables are based on crude assumptions (for example, assuming variables could cover their whole parent scope) and are not comparable from one compilation to another. In this work, we propose some new metrics, computable by our tools, which could serve as motivation for language implementations to improve debugging quality.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04818",
        "abstract url": "https://arxiv.org/abs/2402.04818",
        "title": "An advanced scheme for queue management inTCP/IP networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Active Queue Management (AQM) is a key congestion control scheme that aims to find a balance between keeping high link utilization, minimizing queuing delays, and ensuring a fair share of the bandwidth between the competing flows. Traditional AQM mechanisms use only information that is present at the intermediate nodes (routers). They do not take into account the particularities of the flows composing the traffic. In this paper, we make use of a mechanism, called Explicit RTT Notification (ERN), that shares with routers information about the Round Trip Times (RTTs) of the flows. We propose a new fuzzy logic based AQM controller that relies on the RTTs of the flows to improve fairness between them. The performances of the new proposed method, FuzzyRTT, is examined and compared to existing schemes via simulation experiments.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04831",
        "abstract url": "https://arxiv.org/abs/2402.04831",
        "title": "Novel Phase Detector Measurement Procedure Using Quasi-Synchronized RF Generator",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper presents a new procedure for phase detector measurements that allows the use of generators that share a 10 MHz reference oscillator but do not synchronize in phase, in other words, quasi-synchronized RF generators. The objectives are taking advantage of the benefits of using two generators but recovering lower-cost generators that have worse synchronization performance and opening the door to the possibility of using a very simple control element based in Arduino Uno and cheaper instruments. The new procedure is characterized by continuously alternating calibration and measurement sequences to make up for the phase drift of quasisynchronized generators and guarantee a maximum phase error specification (+-1 grade in this paper). Data acquisition has been divided in two stages: measurement of detector curves without phase reference (in-phase and phase-shifted) and measurement of reference data. All the data is later combined to obtain correctly referenced in-phase detector curves. The technique can be reproduced with other equivalent instrumentation. The novel procedure that allows compensation for errors (amplitude, phase shift, mismatching, etc.) is detailed, and its relation to the required measurement accuracy is amply discussed. The proposed technique is applied to characterize a phase detector based on in-phase and phase-shifted multiplication from 3 to 8 GHz with 1 GHz step. Measurements have a final maximum error of +-2 grade for both frequency and calibrated input power, according to the accuracy specifications of the VNA used to calibrate the signal distribution network, added to the +-1 grade specified in this new procedure.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2402.04834",
        "abstract url": "https://arxiv.org/abs/2402.04834",
        "title": "A blockBP decoder for the surface code",
        "rating": -10,
        "keywords": [],
        "abstract": "We present a new decoder for the surface code, which combines the accuracy of the tensor-network decoders with the efficiency and parallelism of the belief-propagation algorithm. Our main idea is to replace the expensive tensor-network contraction step in the tensor-network decoders with the blockBP algorithm - a recent approximate contraction algorithm, based on belief propagation. Our decoder is therefore a belief-propagation decoder that works in the degenerate maximal likelihood decoding framework. Unlike conventional tensor-network decoders, our algorithm can run efficiently in parallel, and may therefore be suitable for real-time decoding. We numerically test our decoder and show that for a large range of lattice sizes and noise levels it delivers a logical error probability that outperforms the Minimal-Weight-Perfect-Matching (MWPM) decoder, sometimes by more than an order of magnitude.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "13 pages, 7 figures. Comments are welcome. Version2: minor modifications + typos"
    },
    {
        "paper id": "2402.04851",
        "abstract url": "https://arxiv.org/abs/2402.04851",
        "title": "Grand zigzag knight's paths",
        "rating": -10,
        "keywords": [],
        "abstract": "We study the enumeration of different classes of grand knight's paths in the plane. In particular, we focus on the subsets of zigzag knight's paths subject to constraints. These constraints include ending at ordinate 0, bounded by a horizontal line, confined within a tube, among other considerations. We present our results using generating functions or direct closed-form expressions. We derive asymptotic results, finding approximations for quantities such as the probability that a zigzag knight's path stays in some area of the plane, or for the average of the final height of such a path. Additionally, we exhibit some bijections between grand zigzag knight's paths and some pairs of compositions.",
        "subjects": [
            "math.CO"
        ],
        "comment": "21 pages, 9 figures"
    },
    {
        "paper id": "2402.04853",
        "abstract url": "https://arxiv.org/abs/2402.04853",
        "title": "Leveraging LLMs for Unsupervised Dense Retriever Ranking",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper introduces a novel unsupervised technique that utilizes large language models (LLMs) to determine the most suitable dense retriever for a specific test(target) corpus. Selecting the appropriate dense retriever is vital for numerous IR applications that employ these retrievers, trained on public datasets, to encode or conduct searches within a new private target corpus. The effectiveness of a dense retriever can significantly diminish when applied to a target corpus that diverges in domain or task from the original training set. The problem becomes more pronounced in cases where the target corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation of the model's effectiveness on the target corpus unattainable. Therefore, the unsupervised selection of an optimally pre-trained dense retriever, especially under conditions of domain shift, emerges as a critical challenge. Existing methodologies for ranking dense retrievers fall short in addressing these domain shift scenarios. To tackle this, our method capitalizes on LLMs to create pseudo-relevant queries, labels, and reference lists by analyzing a subset of documents from the target corpus. This allows for the ranking of dense retrievers based on their performance with these pseudo-relevant signals. Significantly, this strategy is the first to depend exclusively on the target corpus data, removing the necessity for training data and test labels. We assessed the effectiveness of our approach by compiling a comprehensive pool of cutting-edge dense retrievers and comparing our method against traditional dense retriever selection benchmarks. The findings reveal that our proposed solution surpasses the existing benchmarks in both the selection and ranking of dense retrievers.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04863",
        "abstract url": "https://arxiv.org/abs/2402.04863",
        "title": "Automated Smart Contract Summarization via LLMs",
        "rating": -10,
        "keywords": [],
        "abstract": "Automatic code Summarization generation technology is widely used in the development and maintenance of smart contracts. In recent years, with the advent of Large Language Models (LLMs), Gemini has received a lot of attention as the first Large Multimodal Models (LMMs) to support multimodal input. However, it is unclear how LMMs can generate contract code summarization from multimodal inputs. In this paper, we focus on evaluating Gemini on real-world smart contracts, comparing it to the MMTrans, and exploring how to combine multimodal prompts to generate a contract code summarization. We adopt several widely used metrics (BLEU, METEOR, and ROUGE-L) to measure the quality of the generated summarization. Our experiments show that Gemini-Pro-Vision achieves 21.17\\% and 21.05\\% scores for code comments generated by three-shot prompts under METEOR and ROUGE-L metrics. The above scores are better than those generated by one-shot and five-shot prompts.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04867",
        "abstract url": "https://arxiv.org/abs/2402.04867",
        "title": "Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback",
        "rating": -10,
        "keywords": [],
        "abstract": "In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement compared to the best existing approach. Moreover, the MMQS has been transferred into real-world search engine products, which yield enhanced user engagement. Our research advances query suggestion systems and provides a new perspective on multimodal information retrieval.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "This paper has been accepted by WWW 2024"
    },
    {
        "paper id": "2402.04881",
        "abstract url": "https://arxiv.org/abs/2402.04881",
        "title": "Epistral Network: Revolutionizing Media Curation and Consumption through Decentralization",
        "rating": -10,
        "keywords": [],
        "abstract": "Blockchain technology has revolutionized media consumption and distribution in the digital age, allowing creators, consumers, and regulators to participate in a decentralized, fair, and engaging media environment. Epistral, an innovative media network that leverages blockchain technology, aims to be the world's first anti-mimetic media curation and consumption network, addressing the core challenges facing today's digital media landscape: unfair treatment of creators and manipulative consumer algorithms, and the complex task of effective regulation. This paper delves into the conceptualization, design, and potential impact of epistral and explores how it embodies McLuhan's and Girard's theories within the realm of blockchain technology and draws from Hayden's critique of democratic representation. The paper analyzes the challenges and opportunities presented by this new network, providing a broader discourse on the future of media consumption, distribution, and regulation.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04889",
        "abstract url": "https://arxiv.org/abs/2402.04889",
        "title": "Detecting Generated Native Ads in Conversational Search",
        "rating": -10,
        "keywords": [],
        "abstract": "Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate responses to queries. It is only a small step to also let the same technology insert ads within the generated responses - instead of separately placing ads next to a response. Inserted ads would be reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. Considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models, users of conversational search engines may very well be confronted with generated native ads in the near future. In this paper, we thus take a first step to investigate whether LLMs can also be used as a countermeasure, i.e., to block generated native ads. We compile the Webis Generated Native Ads 2024 dataset of queries and generated responses with automatically inserted ads, and evaluate whether LLMs or fine-tuned sentence transformers can detect the ads. In our experiments, the investigated LLMs struggle with the task but sentence transformers achieve precision and recall values above 0.9.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "WWW'24 Short Papers Track; 4 pages"
    },
    {
        "paper id": "2402.04890",
        "abstract url": "https://arxiv.org/abs/2402.04890",
        "title": "Marker+Codeword+Marker: A Coding Structure for Segmented Single-Insdel/-Edit Channels",
        "rating": -10,
        "keywords": [],
        "abstract": "An insdel refers to a deletion or an insertion, and an edit refers to an insdel or a substitution. In this paper, we consider the segmented single-insdel (resp. single-edit) channel, where the channel's input bit stream is partitioned into segments of length $n$ and each segment can suffer from at most a single insdel (resp. edit) error. The value of $n$ is known to the receiver but the boundaries of segments are not. We propose to encode each segment following a marker+codeword+marker structure, where the two markers are carefully selected and the codewords are chosen from Varshamov-Tenegolts (VT) codes. In this way, we are able to construct a new class of binary codes that can correct segmented single-insdel errors. Our codes have the lowest redundancy of $\\log_2(n-6)+7$ bits and are the first one that has linear-time encoder/decoder in the literature. Moreover, by enhancing the VT codes and one of the markers, we are able to construct the first class of binary codes that can correct segmented single-edit errors. This class of codes has redundancy $\\log_2(n-9)+10$ bits and has linear-time encoder/decoder.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2402.04891",
        "abstract url": "https://arxiv.org/abs/2402.04891",
        "title": "Leveraging knowledge-as-a-service (KaaS) for QoS-aware resource management in multi-user video transcoding",
        "rating": -10,
        "keywords": [],
        "abstract": "The coexistence of parallel applications in shared computing nodes, each one featuring different Quality of Service (QoS) requirements, carries out new challenges to improve resource occupation while keeping acceptable rates in terms of QoS. As more application-specific and system-wide metrics are included as QoS dimensions, or under situations in which resource-usage limits are strict, building and serving the most appropriate set of actions (application control knobs and system resource assignment) to concurrent applications in an automatic and optimal fashion becomes mandatory. In this paper, we propose strategies to build and serve this type of knowledge to concurrent applications by leveraging Reinforcement Learning techniques. Taking multi-user video transcoding as a driving example, our experimental results reveal an excellent adaptation of resource and knob management to heterogeneous QoS requests, and increases in the amount of concurrently served users up to 1.24x compared with alternative approaches considering homogeneous QoS requests.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04893",
        "abstract url": "https://arxiv.org/abs/2402.04893",
        "title": "The Category of Iterative Sets in Homotopy Type Theory and Univalent Foundations",
        "rating": -10,
        "keywords": [],
        "abstract": "When working in Homotopy Type Theory and Univalent Foundations, the traditional role of the category of sets, Set, is replaced by the category hSet of homotopy sets (h-sets); types with h-propositional identity types. Many of the properties of Set hold for hSet ((co)completeness, exactness, local cartesian closure, etc.). Notably, however, the univalence axiom implies that Ob(hSet) is not itself an h-set, but an h-groupoid. This is expected in univalent foundations, but it is sometimes useful to also have a stricter universe of sets, for example when constructing internal models of type theory. In this work, we equip the type of iterative sets V0, due to Gylterud (2018) as a refinement of the pioneering work of Aczel (1978) on universes of sets in type theory, with the structure of a Tarski universe and show that it satisfies many of the good properties of h-sets. In particular, we organize V0 into a (non-univalent strict) category and prove that it is locally cartesian closed. This enables us to organize it into a category with families with the structure necessary to model extensional type theory internally in HoTT/UF. We do this in a rather minimal univalent type theory with W-types, in particular we do not rely on any HITs, or other complex extensions of type theory. Furthermore, the construction of V0 and the model is fully constructive and predicative, while still being very convenient to work with as the decoding from V0 into h-sets commutes definitionally for all type constructors. Almost all of the paper has been formalized in Agda using the agda-unimath library of univalent mathematics.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04907",
        "abstract url": "https://arxiv.org/abs/2402.04907",
        "title": "On a Combinatorial Problem Arising in Machine Teaching",
        "rating": -10,
        "keywords": [],
        "abstract": "We study a model of machine teaching where the teacher mapping is constructed from a size function on both concepts and examples. The main question in machine teaching is the minimum number of examples needed for any concept, the so-called teaching dimension. A recent paper [7] conjectured that the worst case for this model, as a function of the size of the concept class, occurs when the consistency matrix contains the binary representations of numbers from zero and up. In this paper we prove their conjecture. The result can be seen as a generalization of a theorem resolving the edge isoperimetry problem for hypercubes [12], and our proof is based on a lemma of [10].",
        "subjects": [
            "math.CO"
        ],
        "comment": "14 pages, 1 figure"
    },
    {
        "paper id": "2402.04913",
        "abstract url": "https://arxiv.org/abs/2402.04913",
        "title": "Hashing Beam Training for Near-Field Integrated Sensing and Communication Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "In millimeter-wave (mmWave) integrated sensing and communication networks, users may be within the coverage of multiple access points (AP), which typically employ large-scale antenna arrays to mitigate obstacle occlusion and path loss. However, large-scale arrays generate pencil-shaped beams, which necessitate a higher number of training beams to cover the desired space. Furthermore, as the antenna aperture increases, users are more likely to be situated in the near-field region of the AP antenna array. This motivates our investigation into the near-field beam training problem to achieve effective positioning services. To address the high complexity and low identification accuracy of existing beam training techniques, we propose an efficient hashing multi-arm beam (HMB) training scheme for the near-field scenario. Specifically, we first construct a near-field single-beam training codebook for the uniform planar arrays. Then, the hash functions are chosen independently to construct the multi-arm beam training codebooks for each AP. All APs traverse the predefined multi-arm beam training codeword simultaneously and the multi-AP superimposed signals at the user are recorded. Finally, the soft decision and voting methods are applied to obtain the correctly aligned beams only based on the signal powers. In addition, we logically prove that the traversal complexity is at the logarithmic level. Simulation results show that our proposed near-field HMB training method can achieve 96.4% identification accuracy of the exhaustive beam training method and greatly reduce the training overhead. Furthermore, we verify its applicability under the far-field scenario as well.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04922",
        "abstract url": "https://arxiv.org/abs/2402.04922",
        "title": "Voronoi Candidates for Bayesian Optimization",
        "rating": -10,
        "keywords": [],
        "abstract": "Bayesian optimization (BO) offers an elegant approach for efficiently optimizing black-box functions. However, acquisition criteria demand their own challenging inner-optimization, which can induce significant overhead. Many practical BO methods, particularly in high dimension, eschew a formal, continuous optimization of the acquisition function and instead search discretely over a finite set of space-filling candidates. Here, we propose to use candidates which lie on the boundary of the Voronoi tessellation of the current design points, so they are equidistant to two or more of them. We discuss strategies for efficient implementation by directly sampling the Voronoi boundary without explicitly generating the tessellation, thus accommodating large designs in high dimension. On a battery of test problems optimized via Gaussian processes with expected improvement, our proposed approach significantly improves the execution time of a multi-start continuous search without a loss in accuracy.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "comments very welcome"
    },
    {
        "paper id": "2402.04935",
        "abstract url": "https://arxiv.org/abs/2402.04935",
        "title": "Convergence of Approximate and Packet Routing Equilibria to Nash Flows Over Time",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider a dynamic model of traffic that has received a lot of attention in the past few years. Infinitesimally small agents aim to travel from a source to a destination as quickly as possible. Flow patterns vary over time, and congestion effects are modeled via queues, which form based on the deterministic queueing model whenever the inflow into a link exceeds its capacity. Are equilibria in this model meaningful as a prediction of traffic behavior? For this to be the case, a certain notion of stability under ongoing perturbations is needed. Real traffic consists of discrete, atomic ''packets'', rather than being a continuous flow of non-atomic agents. Users may not choose an absolutely quickest route available, if there are multiple routes with very similar travel times. We would hope that in both these situations -- a discrete packet model, with packet size going to 0, and $\u03b5$-equilibria, with $\u03b5$ going to 0 -- equilibria converge to dynamic equilibria in the flow over time model. No such convergence results were known. We show that such a convergence result does hold in single-commodity instances for both of these settings, in a unified way. More precisely, we introduce a notion of ''strict'' $\u03b5$-equilibria, and show that these must converge to the exact dynamic equilibrium in the limit as $\u03b5\\to 0$. We then show that results for the two settings mentioned can be deduced from this with only moderate further technical effort.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "An extended abstract of this work appeared at FOCS 2023"
    },
    {
        "paper id": "2402.04942",
        "abstract url": "https://arxiv.org/abs/2402.04942",
        "title": "Achieving Gaussian Vector Broadcast Channel Capacity with Scalar Lattices",
        "rating": -10,
        "keywords": [],
        "abstract": "A coding scheme with scalar lattices is applied to K-receiver, Gaussian, vector broadcast channels with K independent messages, one for each receiver. The method decomposes each receiver channel into parallel scalar channels with known interference and applies dirty paper coding with a modulo interval, amplitude shift keying (ASK), and probabilistic shaping to each scalar channel. The achievable rate tuples include all points inside the capacity region by choosing truncated Gaussian shaping, large ASK alphabets, and large modulo intervals.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04943",
        "abstract url": "https://arxiv.org/abs/2402.04943",
        "title": "Cayley hashing with cookies",
        "rating": -10,
        "keywords": [],
        "abstract": "Cayley hash functions are based on a simple idea of using a pair of semigroup elements, A and B, to hash the 0 and 1 bit, respectively, and then to hash an arbitrary bit string in the natural way, by using multiplication of elements in the semigroup. The main advantage of Cayley hash functions compared to, say, hash functions in the SHA family is that when an already hashed document is amended, one does not have to hash the whole amended document all over again, but rather hash just the amended part and then multiply the result by the hash of the original document. Some authors argued that this may be a security hazard, specifically that this property may facilitate finding a second preimage by splitting a long bit string into shorter pieces. In this paper, we offer a way to get rid of this alleged disadvantage and keep the advantages at the same time. We call this method ``Cayley hashing with cookies\" using terminology borrowed from the theory of random walks in a random environment. For the platform semigroup, we use 2x2 matrices over F_p.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2402.04955",
        "abstract url": "https://arxiv.org/abs/2402.04955",
        "title": "Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Cognitive assistants (CA) are chatbots that provide context-aware support to human workers in knowledge-intensive tasks. Traditionally, cognitive assistants respond in specific ways to predefined user intents and conversation patterns. However, this rigidness does not handle the diversity of natural language well. Recent advances in natural language processing (NLP), powering large language models (LLM) such as GPT-4, Llama2, and Gemini, could enable CAs to converse in a more flexible, human-like manner. However, the additional degrees of freedom may have unforeseen consequences, especially in knowledge-intensive contexts where accuracy is crucial. As a preliminary step to assessing the potential of using LLMs in these contexts, we conducted a user study comparing an LLM-based CA to an intent-based system regarding interaction efficiency, user experience, workload, and usability. This revealed that LLM-based CAs exhibited better user experience, task completion rate, usability, and perceived performance than intent-based systems, suggesting that switching NLP techniques should be investigated further.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "10 pages, 7 figures, under review at an ACM venue"
    },
    {
        "paper id": "2402.04959",
        "abstract url": "https://arxiv.org/abs/2402.04959",
        "title": "Margin Propagation based XOR-SAT Solvers for Decoding of LDPC Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "Decoding of Low-Density Parity Check (LDPC) codes can be viewed as a special case of XOR-SAT problems, for which low-computational complexity bit-flipping algorithms have been proposed in the literature. However, a performance gap exists between the bit-flipping LDPC decoding algorithms and the benchmark LDPC decoding algorithms, such as the Sum-Product Algorithm (SPA). In this paper, we propose an XOR-SAT solver using log-sum-exponential functions and demonstrate its advantages for LDPC decoding. This is then approximated using the Margin Propagation formulation to attain a low-complexity LDPC decoder. The proposed algorithm uses soft information to decide the bit-flips that maximize the number of parity check constraints satisfied over an optimization function. The proposed solver can achieve results that are within $0.1$dB of the Sum-Product Algorithm for the same number of code iterations. It is also at least 10x lesser than other Gradient-Descent Bit Flipping decoding algorithms, which are also bit-flipping algorithms based on optimization functions. The approximation using the Margin Propagation formulation does not require any multipliers, resulting in significantly lower computational complexity than other soft-decision Bit-Flipping LDPC decoders.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "12 pages, 7 figures, Paper submitted to IEEE Transactions on Communications"
    },
    {
        "paper id": "2402.04980",
        "abstract url": "https://arxiv.org/abs/2402.04980",
        "title": "Asymptotics of feature learning in two-layer networks after one gradient-step",
        "rating": -10,
        "keywords": [],
        "abstract": "In this manuscript we investigate the problem of how two-layer neural networks learn features from data, and improve over the kernel regime, after being trained with a single gradient descent step. Leveraging a connection from (Ba et al., 2022) with a non-linear spiked matrix model and recent progress on Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic description of the generalization error in the high-dimensional limit where the number of samples $n$, the width $p$ and the input dimension $d$ grow at a proportional rate. We characterize exactly how adapting to the data is crucial for the network to efficiently learn non-linear functions in the direction of the gradient -- where at initialization it can only express linear functions in this regime. To our knowledge, our results provides the first tight description of the impact of feature learning in the generalization of two-layer neural networks in the large learning rate regime $\u03b7=\u0398_{d}(d)$, beyond perturbative finite width corrections of the conjugate and neural tangent kernels.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.04991",
        "abstract url": "https://arxiv.org/abs/2402.04991",
        "title": "Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults Explore and Learn Smartphone Applications",
        "rating": -10,
        "keywords": [],
        "abstract": "The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults' smartphone app exploration remains insufficiently explored. Therefore, we conducted a two-phase study: (1) a workshop with 18 older adults to identify app exploration challenges and potential AR interventions, and (2) tech-probe participatory design sessions with 15 participants to co-create AR support tools. Our research highlights AR's effectiveness in reducing physical and cognitive strain among older adults during app exploration, especially during multi-app usage and the trial-and-error learning process. We also examined their interactional experiences with AR, yielding design considerations on tailoring AR tools for smartphone app exploration. Ultimately, our study unveils the prospective landscape of AR in supporting the older demographic, both presently and in future scenarios.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05004",
        "abstract url": "https://arxiv.org/abs/2402.05004",
        "title": "Near-Optimal Generalized Decoding of Polar-like Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "We present a framework that can exploit the tradeoff between the undetected error rate (UER) and block error rate (BLER) of polar-like codes. It is compatible with all successive cancellation (SC)-based decoding methods and relies on a novel approximation that we call codebook probability. This approximation is based on an auxiliary distribution that mimics the dynamics of decoding algorithms following an SC decoding schedule. Simulation results demonstrates that, in the case of SC list (SCL) decoding, the proposed framework outperforms the state-of-art approximations from Forney's generalized decoding rule for polar-like codes with dynamic frozen bits. In addition, dynamic Reed-Muller (RM) codes using the proposed generalized decoding significantly outperform CRC-concatenated polar codes decoded using SCL in both BLER and UER. Finally, we briefly discuss three potential applications of the approximated codebook probability: coded pilot-free channel estimation; bitwise soft-output decoding; and improved turbo product decoding.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "being published at IEEE ISIT 2024"
    },
    {
        "paper id": "2402.05012",
        "abstract url": "https://arxiv.org/abs/2402.05012",
        "title": "Information Theoretically Secure Encryption Key Generation over Wireless Networks by Exploiting Packet Errors",
        "rating": -10,
        "keywords": [],
        "abstract": "This article presents a novel method for establishing an information theoretically secure encryption key over wireless channels. It exploits the fact that data transmission over wireless links is accompanied by packet error, while noise terms, and thereby the error events observed by two separate receivers are independent of each other. A number of data packets, with random data, are transmitted from a first legitimate node, say Alice, to a second legitimate node, say Bob. Bob identifies all packets that are received error-free in the first transmission attempt and sends their indices to Alice over a public channel. Then, both Alice and Bob mix the contents of identified packets, e.g., using a hash function, and thereby derive an identical encryption key. Since error events from Alice to Bob is independent of error events from Alice to Eve, the chances that Eve has successfully received all packets used in key generation error-free diminishes as the number of packet increases. In many wireless standards, the first stage in error detection and Automatic Repeat Request (ARQ) is deployed at the PHY/MAC (Physical Layer/Medium Access Control) layer. In such setups, the first re-transmission is manged by the PHY/MAC layer without informing higher layers. This makes it impossible to directly access the information related to packet errors through high-level programming interfaces available to an end-user. A method is presented for determining packets received error-free in first transmission attempts through high-level programming. Examples are presented in conjunction with an LTE cellular network.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05014",
        "abstract url": "https://arxiv.org/abs/2402.05014",
        "title": "When the Body Became Data: Historical Data Cultures and Anatomical Illustration",
        "rating": -10,
        "keywords": [],
        "abstract": "With changing attitudes around knowledge, medicine, art, and technology, the human body has become a source of information and, ultimately, shareable and analyzable data. Centuries of illustrations and visualizations of the body occur within particular historical, social, and political contexts. These contexts are enmeshed in different so-called data cultures: ways that data, knowledge, and information are conceptualized and collected, structured and shared. In this work, we explore how information about the body was collected as well as the circulation, impact, and persuasive force of the resulting images. We show how mindfulness of data cultural influences remain crucial for today's designers, researchers, and consumers of visualizations. We conclude with a call for the field to reflect on how visualizations are not timeless and contextless mirrors on objective data, but as much a product of our time and place as the visualizations of the past.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05024",
        "abstract url": "https://arxiv.org/abs/2402.05024",
        "title": "Does the Use of Unusual Combinations of Datasets Contribute to Greater Scientific Impact?",
        "rating": -10,
        "keywords": [],
        "abstract": "Scientific datasets play a crucial role in contemporary data-driven research, as they allow for the progress of science by facilitating the discovery of new patterns and phenomena. This mounting demand for empirical research raises important questions on how strategic data utilization in research projects can stimulate scientific advancement. In this study, we examine the hypothesis inspired by the recombination theory, which suggests that innovative combinations of existing knowledge, including the use of unusual combinations of datasets, can lead to high-impact discoveries. We investigate the scientific outcomes of such atypical data combinations in more than 30,000 publications that leverage over 6,000 datasets curated within one of the largest social science databases, ICPSR. This study offers four important insights. First, combining datasets, particularly those infrequently paired, significantly contributes to both scientific and broader impacts (e.g., dissemination to the general public). Second, the combination of datasets with atypically combined topics has the opposite effect -- the use of such data is associated with fewer citations. Third, younger and less experienced research teams tend to use atypical combinations of datasets in research at a higher frequency than their older and more experienced counterparts. Lastly, despite the benefits of data combination, papers that amalgamate data remain infrequent. This finding suggests that the unconventional combination of datasets is an under-utilized but powerful strategy correlated with the scientific and broader impact of scientific discoveries.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05057",
        "abstract url": "https://arxiv.org/abs/2402.05057",
        "title": "Approximate Integrity Constraints in Incomplete Databases With Limited Domains",
        "rating": -10,
        "keywords": [],
        "abstract": "In case of incomplete database tables, a possible world is obtained by replacing any missing value by a value from the corresponding attribute's domain that can be infinite. A possible key or possible functional dependency constraint is satisfied by an incomplete table if we can obtain a possible world that satisfies the given key or functional dependency. On the other hand, a certain key or certain functional dependency holds if all possible worlds satisfy the constraint, A strongly possible constraint is an intermediate concept between possible and certain constraints, based on the strongly possible world approach (a strongly possible world is obtained by replacing \\nul's by a value from the ones appearing in the corresponding attribute of the table). A strongly possible key or functional dependency holds in an incomplete table if there exists a strongly possible world that satisfies the given constraint. In the present paper, we introduce strongly possible versions of multivalued dependencies and cross joins, and we analyse the complexity of checking the validity of a given strongly possible cross joins. We also study approximation measures of strongly possible keys (spKeys), functional dependencies (spFDs), multivalued dependencies (spMVDs) and cross joins (spCJs). We also treat complexity questions of determination of the approximation values.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05059",
        "abstract url": "https://arxiv.org/abs/2402.05059",
        "title": "Connecting Kani's Lemma and path-finding in the Bruhat-Tits tree to compute supersingular endomorphism rings",
        "rating": -10,
        "keywords": [],
        "abstract": "We give a deterministic polynomial time algorithm to compute the endomorphism ring of a supersingular elliptic curve in characteristic p, provided that we are given two noncommuting endomorphisms and the factorization of the discriminant of the ring $\\mathcal{O}_0$ they generate. At each prime $q$ for which $\\mathcal{O}_0$ is not maximal, we compute the endomorphism ring locally by computing a q-maximal order containing it and, when $q \\neq p$, recovering a path to $\\text{End}(E) \\otimes \\mathbb{Z}_q$ in the Bruhat-Tits tree. We use techniques of higher-dimensional isogenies to navigate towards the local endomorphism ring. Our algorithm improves on a previous algorithm which requires a restricted input and runs in subexponential time under certain heuristics. Page and Wesolowski give a probabilistic polynomial time algorithm to compute the endomorphism ring on input of a single non-scalar endomorphism. Beyond using techniques of higher-dimensional isogenies to divide endomorphisms by a scalar, our methods are completely different.",
        "subjects": [
            "math.NT"
        ],
        "comment": "32 pages. 5 figures. Submitted"
    },
    {
        "paper id": "2402.05071",
        "abstract url": "https://arxiv.org/abs/2402.05071",
        "title": "Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity",
        "rating": -10,
        "keywords": [],
        "abstract": "We focus on constrained, $L$-smooth, nonconvex-nonconcave min-max problems either satisfying $\u03c1$-cohypomonotonicity or admitting a solution to the $\u03c1$-weakly Minty Variational Inequality (MVI), where larger values of the parameter $\u03c1>0$ correspond to a greater degree of nonconvexity. These problem classes include examples in two player reinforcement learning, interaction dominant min-max problems, and certain synthetic test problems on which classical min-max algorithms fail. It has been conjectured that first-order methods can tolerate value of $\u03c1$ no larger than $\\frac{1}{L}$, but existing results in the literature have stagnated at the tighter requirement $\u03c1< \\frac{1}{2L}$. With a simple argument, we obtain optimal or best-known complexity guarantees with cohypomonotonicity or weak MVI conditions for $\u03c1< \\frac{1}{L}$. The algorithms we analyze are inexact variants of Halpern and Krasnosel'ski\u012d-Mann (KM) iterations. We also provide algorithms and complexity guarantees in the stochastic case with the same range on $\u03c1$. Our main insight for the improvements in the convergence analyses is to harness the recently proposed \"conic nonexpansiveness\" property of operators. As byproducts, we provide a refined analysis for inexact Halpern iteration and propose a stochastic KM iteration with a multilevel Monte Carlo estimator.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05083",
        "abstract url": "https://arxiv.org/abs/2402.05083",
        "title": "Measurements and Analysis of Temporal and Spatial Variability of WiFi Exposure Levels in the 2.4 GHz Frequency Band",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper presents an evaluation of the WiFi exposure levels inside the university in the 2.4 GHz frequency band. The selected environment is the typical scenario where WiFi exposure concerns have increased in the last years, since a Wireless Local Area Network is deployed close to the users. Measurements of 1 h and 24 h of duration were performed to assess the temporal and spatial variability of the signal. Two instruments were employed, a spectrum analyzer appropriate configured for recording accurate and realistic samples and an exposimeter. A detailed description of the equipment, the measurement procedure and data analysis is provided in order to allow the reproducibility of these types of measurements. Finally, a comparison of the WiFi levels obtained by other authors is presented, concluding that all these methods are useful for determining WiFi exposure distribution, but if more accurate results are required, professional equipment appropriately configured should be used.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2402.05101",
        "abstract url": "https://arxiv.org/abs/2402.05101",
        "title": "Tighter Generalisation Bounds via Interpolation",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper contains a recipe for deriving new PAC-Bayes generalisation bounds based on the $(f, \u0393)$-divergence, and, in addition, presents PAC-Bayes generalisation bounds where we interpolate between a series of probability divergences (including but not limited to KL, Wasserstein, and total variation), making the best out of many worlds depending on the posterior distributions properties. We explore the tightness of these bounds and connect them to earlier results from statistical learning, which are specific cases. We also instantiate our bounds as training objectives, yielding non-trivial guarantees and practical performances.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05102",
        "abstract url": "https://arxiv.org/abs/2402.05102",
        "title": "You Can REST Now: Automated Specification Inference and Black-Box Testing of RESTful APIs with Large Language Models",
        "rating": -10,
        "keywords": [],
        "abstract": "RESTful APIs are popular web services, requiring documentation to ease their comprehension, reusability and testing practices. The OpenAPI Specification (OAS) is a widely adopted and machine-readable format used to document such APIs. However, manually documenting RESTful APIs is a time-consuming and error-prone task, resulting in unavailable, incomplete, or imprecise documentation. As RESTful API testing tools require an OpenAPI specification as input, insufficient or informal documentation hampers testing quality. Recently, Large Language Models (LLMs) have demonstrated exceptional abilities to automate tasks based on their colossal training data. Accordingly, such capabilities could be utilized to assist the documentation and testing process of RESTful APIs. In this paper, we present RESTSpecIT, the first automated RESTful API specification inference and black-box testing approach leveraging LLMs. The approach requires minimal user input compared to state-of-the-art RESTful API inference and testing tools; Given an API name and an LLM key, HTTP requests are generated and mutated with data returned by the LLM. By sending the requests to the API endpoint, HTTP responses can be analyzed for inference and testing purposes. RESTSpecIT utilizes an in-context prompt masking strategy, requiring no model fine-tuning. Our evaluation demonstrates that RESTSpecIT is capable of: (1) inferring specifications with 85.05% of GET routes and 81.05% of query parameters found on average, (2) discovering undocumented and valid routes and parameters, and (3) uncovering server errors in RESTful APIs. Inferred specifications can also be used as testing tool inputs.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05144",
        "abstract url": "https://arxiv.org/abs/2402.05144",
        "title": "A Bandit Approach with Evolutionary Operators for Model Selection",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper formulates model selection as an infinite-armed bandit problem. The models are arms, and picking an arm corresponds to a partial training of the model (resource allocation). The reward is the accuracy of the selected model after its partial training. In this best arm identification problem, regret is the gap between the expected accuracy of the optimal model and that of the model finally chosen. We first consider a straightforward generalization of UCB-E to the stochastic infinite-armed bandit problem and show that, under basic assumptions, the expected regret order is $T^{-\u03b1}$ for some $\u03b1\\in (0,1/5)$ and $T$ the number of resources to allocate. From this vanilla algorithm, we introduce the algorithm Mutant-UCB that incorporates operators from evolutionary algorithms. Tests carried out on three open source image classification data sets attest to the relevance of this novel combining approach, which outperforms the state-of-the-art for a fixed budget.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05148",
        "abstract url": "https://arxiv.org/abs/2402.05148",
        "title": "Cost Optimized Scheduling in Modular Electrolysis Plants",
        "rating": -10,
        "keywords": [],
        "abstract": "In response to the global shift towards renewable energy resources, the production of green hydrogen through electrolysis is emerging as a promising solution. Modular electrolysis plants, designed for flexibility and scalability, offer a dynamic response to the increasing demand for hydrogen while accommodating the fluctuations inherent in renewable energy sources. However, optimizing their operation is challenging, especially when a large number of electrolysis modules needs to be coordinated, each with potentially different characteristics. To address these challenges, this paper presents a decentralized scheduling model to optimize the operation of modular electrolysis plants using the Alternating Direction Method of Multipliers. The model aims to balance hydrogen production with fluctuating demand, to minimize the marginal Levelized Cost of Hydrogen (mLCOH), and to ensure adaptability to operational disturbances. A case study validates the accuracy of the model in calculating mLCOH values under nominal load conditions and demonstrates its responsiveness to dynamic changes, such as electrolyzer module malfunctions and scale-up scenarios.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05155",
        "abstract url": "https://arxiv.org/abs/2402.05155",
        "title": "Non-convergence to global minimizers for Adam and stochastic gradient descent optimization and constructions of local minimizers in the training of artificial neural networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Stochastic gradient descent (SGD) optimization methods such as the plain vanilla SGD method and the popular Adam optimizer are nowadays the method of choice in the training of artificial neural networks (ANNs). Despite the remarkable success of SGD methods in the ANN training in numerical simulations, it remains in essentially all practical relevant scenarios an open problem to rigorously explain why SGD methods seem to succeed to train ANNs. In particular, in most practically relevant supervised learning problems, it seems that SGD methods do with high probability not converge to global minimizers in the optimization landscape of the ANN training problem. Nevertheless, it remains an open problem of research to disprove the convergence of SGD methods to global minimizers. In this work we solve this research problem in the situation of shallow ANNs with the rectified linear unit (ReLU) and related activations with the standard mean square error loss by disproving in the training of such ANNs that SGD methods (such as the plain vanilla SGD, the momentum SGD, the AdaGrad, the RMSprop, and the Adam optimizers) can find a global minimizer with high probability. Even stronger, we reveal in the training of such ANNs that SGD methods do with high probability fail to converge to global minimizers in the optimization landscape. The findings of this work do, however, not disprove that SGD methods succeed to train ANNs since they do not exclude the possibility that SGD methods find good local minimizers whose risk values are close to the risk values of the global minimizers. In this context, another key contribution of this work is to establish the existence of a hierarchical structure of local minimizers with distinct risk values in the optimization landscape of ANN training problems with ReLU and related activations.",
        "subjects": [
            "math.OC"
        ],
        "comment": "36 pages"
    },
    {
        "paper id": "2402.05156",
        "abstract url": "https://arxiv.org/abs/2402.05156",
        "title": "What About the Data? A Mapping Study on Data Engineering for AI Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "AI systems cannot exist without data. Now that AI models (data science and AI) have matured and are readily available to apply in practice, most organizations struggle with the data infrastructure to do so. There is a growing need for data engineers that know how to prepare data for AI systems or that can setup enterprise-wide data architectures for analytical projects. But until now, the data engineering part of AI engineering has not been getting much attention, in favor of discussing the modeling part. In this paper we aim to change this by perform a mapping study on data engineering for AI systems, i.e., AI data engineering. We found 25 relevant papers between January 2019 and June 2023, explaining AI data engineering activities. We identify which life cycle phases are covered, which technical solutions or architectures are proposed and which lessons learned are presented. We end by an overall discussion of the papers with implications for practitioners and researchers. This paper creates an overview of the body of knowledge on data engineering for AI. This overview is useful for practitioners to identify solutions and best practices as well as for researchers to identify gaps.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "Preprint, accepted for CAIN24"
    },
    {
        "paper id": "2402.05160",
        "abstract url": "https://arxiv.org/abs/2402.05160",
        "title": "What's documented in AI? Systematic Analysis of 32K AI Model Cards",
        "rating": -10,
        "keywords": [],
        "abstract": "The rapid proliferation of AI models has underscored the importance of thorough documentation, as it enables users to understand, trust, and effectively utilize these models in various applications. Although developers are encouraged to produce model cards, it's not clear how much information or what information these cards contain. In this study, we conduct a comprehensive analysis of 32,111 AI model documentations on Hugging Face, a leading platform for distributing and deploying AI models. Our investigation sheds light on the prevailing model card documentation practices. Most of the AI models with substantial downloads provide model cards, though the cards have uneven informativeness. We find that sections addressing environmental impact, limitations, and evaluation exhibit the lowest filled-out rates, while the training section is the most consistently filled-out. We analyze the content of each section to characterize practitioners' priorities. Interestingly, there are substantial discussions of data, sometimes with equal or even greater emphasis than the model itself. To evaluate the impact of model cards, we conducted an intervention study by adding detailed model cards to 42 popular models which had no or sparse model cards previously. We find that adding model cards is moderately correlated with an increase weekly download rates. Our study opens up a new perspective for analyzing community norms and practices for model documentation through large-scale data science and linguistics analysis.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05161",
        "abstract url": "https://arxiv.org/abs/2402.05161",
        "title": "Approximate Keys and Functional Dependencies in Incomplete Databases With Limited Domains-Algorithmic Perspective",
        "rating": -10,
        "keywords": [],
        "abstract": "A possible world of an incomplete database table is obtained by imputing values from the attributes (infinite) domain to the place of \\texttt{NULL} s. A table satisfies a possible key or possible functional dependency constraint if there exists a possible world of the table that satisfies the given key or functional dependency constraint. A certain key or functional dependency is satisfied by a table if all of its possible worlds satisfy the constraint. Recently, an intermediate concept was introduced. A strongly possible key or functional dependency is satisfied by a table if there exists a strongly possible world that satisfies the key or functional dependency. A strongly possible world is obtained by imputing values from the active domain of the attributes, that is from the values appearing in the table. In the present paper, we study approximation measures of strongly possible keys and FDs. Measure $g_3$ is the ratio of the minimum number of tuples to be removed in order that the remaining table satisfies the constraint. We introduce a new measure $g_5$, the ratio of the minimum number of tuples to be added to the table so the result satisfies the constraint. $g_5$ is meaningful because the addition of tuples may extend the active domains. We prove that if $g_5$ can be defined for a table and a constraint, then the $g_3$ value is always an upper bound of the $g_5$ value. However, the two measures are independent of each other in the sense that for any rational number $0\\le\\frac{p}{q}<1$ there are tables of an arbitrarily large number of rows and a constant number of columns that satisfy $g_3-g_5=\\frac{p}{q}$. A possible world is obtained usually by adding many new values not occurring in the table before. The measure $g_5$ measures the smallest possible distortion of the active domains. We study complexity of determining these approximate measures.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2402.05057"
    },
    {
        "paper id": "2402.05193",
        "abstract url": "https://arxiv.org/abs/2402.05193",
        "title": "JAX-Fluids 2.0: Towards HPC for Differentiable CFD of Compressible Two-phase Flows",
        "rating": -10,
        "keywords": [],
        "abstract": "In our effort to facilitate machine learning-assisted computational fluid dynamics (CFD), we introduce the second iteration of JAX-Fluids. JAX-Fluids is a Python-based fully-differentiable CFD solver designed for compressible single- and two-phase flows. In this work, the first version is extended to incorporate high-performance computing (HPC) capabilities. We introduce a parallelization strategy utilizing JAX primitive operations that scales efficiently on GPU (up to 512 NVIDIA A100 graphics cards) and TPU (up to 1024 TPU v3 cores) HPC systems. We further demonstrate the stable parallel computation of automatic differentiation gradients across extended integration trajectories. The new code version offers enhanced two-phase flow modeling capabilities. In particular, a five-equation diffuse-interface model is incorporated which complements the level-set sharp-interface model. Additional algorithmic improvements include positivity-preserving limiters for increased robustness, support for stretched Cartesian meshes, refactored I/O handling, comprehensive post-processing routines, and an updated list of state-of-the-art high-order numerical discretization schemes. We verify newly added numerical models by showcasing simulation results for single- and two-phase flows, including turbulent boundary layer and channel flows, air-helium shock bubble interactions, and air-water shock drop interactions.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05200",
        "abstract url": "https://arxiv.org/abs/2402.05200",
        "title": "Are LLMs Ready for Real-World Materials Discovery?",
        "rating": -10,
        "keywords": [],
        "abstract": "Large Language Models (LLMs) create exciting possibilities for powerful language processing tools to accelerate research in materials science. While LLMs have great potential to accelerate materials understanding and discovery, they currently fall short in being practical materials science tools. In this position paper, we show relevant failure cases of LLMs in materials science that reveal current limitations of LLMs related to comprehending and reasoning over complex, interconnected materials science knowledge. Given those shortcomings, we outline a framework for developing Materials Science LLMs (MatSci-LLMs) that are grounded in materials science knowledge and hypothesis generation followed by hypothesis testing. The path to attaining performant MatSci-LLMs rests in large part on building high-quality, multi-modal datasets sourced from scientific literature where various information extraction challenges persist. As such, we describe key materials science information extraction challenges which need to be overcome in order to build large-scale, multi-modal datasets that capture valuable materials science knowledge. Finally, we outline a roadmap for applying future MatSci-LLMs for real-world materials discovery via: 1. Automated Knowledge Base Generation; 2. Automated In-Silico Material Design; and 3. MatSci-LLM Integrated Self-Driving Materials Laboratories.",
        "subjects": [
            "cond-mat.mtrl-sci"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05209",
        "abstract url": "https://arxiv.org/abs/2402.05209",
        "title": "Stochastic modeling of Random Access Memories reset transitions",
        "rating": -10,
        "keywords": [],
        "abstract": "Resistive Random Access Memories (RRAMs) are being studied by the industry and academia because it is widely accepted that they are promising candidates for the next generation of high density nonvolatile memories. Taking into account the stochastic nature of mechanisms behind resistive switching, a new technique based on the use of functional data analysis has been developed to accurately model resistive memory device characteristics. Functional principal component analysis (FPCA) based on Karhunen-Loeve expansion is applied to obtain an orthogonal decomposition of the reset process in terms of uncorrelated scalar random variables. Then, the device current has been accurately described making use of just one variable presenting a modeling approach that can be very attractive from the circuit simulation viewpoint. The new method allows a comprehensive description of the stochastic variability of these devices by introducing a probability distribution that allows the simulation of the main parameter that is employed for the model implementation. A rigorous description of the mathematical theory behind the technique is given and its application for a broad set of experimental measurements is explained.",
        "subjects": [
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05212",
        "abstract url": "https://arxiv.org/abs/2402.05212",
        "title": "An Investigation of Patch Porting Practices of the Linux Kernel Ecosystem",
        "rating": -10,
        "keywords": [],
        "abstract": "Open-source software is increasingly reused, complicating the process of patching to repair bugs. In the case of Linux, a distinct ecosystem has formed, with Linux mainline serving as the upstream, stable or long-term-support (LTS) systems forked from mainline, and Linux distributions, such as Ubuntu and Android, as downstreams forked from stable or LTS systems for end-user use. Ideally, when a patch is committed in the Linux upstream, it should not introduce new bugs and be ported to all the applicable downstream branches in a timely fashion. However, several concerns have been expressed in prior work about the responsiveness of patch porting in this Linux ecosystem. In this paper, we mine the software repositories to investigate a range of Linux distributions in combination with Linux stable and LTS, and find diverse patch porting strategies and competence levels that help explain the phenomenon. Furthermore, we show concretely using three metrics, i.e., patch delay, patch rate, and bug inheritance ratio, that different porting strategies have different tradeoffs. We find that hinting tags(e.g., Cc stable tags and fixes tags) are significantly important to the prompt patch porting, but it is noteworthy that a substantial portion of patches remain devoid of these indicative tags. Finally, we offer recommendations based on our analysis of the general patch flow, e.g., interactions among various stakeholders in the ecosystem and automatic generation of hinting tags, as well as tailored suggestions for specific porting strategies.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05220",
        "abstract url": "https://arxiv.org/abs/2402.05220",
        "title": "On Parameter Estimation in Deviated Gaussian Mixture of Experts",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \u03bb^{\\ast}) g_0(Y| X)+ \u03bb^{\\ast} \\sum_{i = 1}^{k_{\\ast}} p_{i}^{\\ast} f(Y|(a_{i}^{\\ast})^{\\top}X+b_i^{\\ast},\u03c3_{i}^{\\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\u03bb^{\\ast} \\in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\\ast}, a_{i}^{\\ast}, b_{i}^{\\ast}, \u03c3_{i}^{\\ast})$ for $1 \\leq i \\leq k^{\\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the convergence rates of maximum likelihood estimation (MLE) for our models. We further demonstrate that our proposed loss functions characterize the local convergence rates of parameter estimation more accurately than the generalized Wasserstein, a loss function being commonly used for estimating parameters in the Gaussian mixture of experts.",
        "subjects": [
            "stat.ML"
        ],
        "comment": "34 pages, 3 figures"
    },
    {
        "paper id": "2402.05236",
        "abstract url": "https://arxiv.org/abs/2402.05236",
        "title": "Real-Time Line-Based Room Segmentation and Continuous Euclidean Distance Fields",
        "rating": -10,
        "keywords": [],
        "abstract": "Continuous maps representations, as opposed to traditional discrete ones such as grid maps, have been gaining traction in the research community. However, current approaches still suffer from high computation costs, making them unable to be used in large environments without sacrificing precision. In this paper, a scalable method building upon Gaussian Process-based Euclidean Distance Fields (GP-EDFs) is proposed. By leveraging structure inherent to indoor environments, namely walls and rooms, we achieve an accurate continuous map representation that is fast enough to be updated and used in real-time. This is possible thanks to a novel line-based room segmentation algorithm, enabling the creation of smaller local GP-EDFs for each room, which in turn also use line segments as its shape priors, thus representing the map more efficiently with fewer data points. We evaluate this method in simulation experiments, and make the code available open-source.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Open-source code: https://github.com/EricssonResearch/Line-Based-Room-Segmentation-and-EDF"
    },
    {
        "paper id": "2402.05238",
        "abstract url": "https://arxiv.org/abs/2402.05238",
        "title": "Automated Data-Driven Discovery of Material Models Based on Symbolic Regression: A Case Study on Human Brain Cortex",
        "rating": -10,
        "keywords": [],
        "abstract": "We introduce a data-driven framework to automatically identify interpretable and physically meaningful hyperelastic constitutive models from sparse data. Leveraging symbolic regression, an algorithm based on genetic programming, our approach generates elegant hyperelastic models that achieve accurate data fitting through parsimonious mathematic formulae, while strictly adhering to hyperelasticity constraints such as polyconvexity. Our investigation spans three distinct hyperelastic models -- invariant-based, principal stretch-based, and normal strain-based -- and highlights the versatility of symbolic regression. We validate our new approach using synthetic data from five classic hyperelastic models and experimental data from the human brain to demonstrate algorithmic efficacy. Our results suggest that our symbolic regression robustly discovers accurate models with succinct mathematic expressions in invariant-based, stretch-based, and strain-based scenarios. Strikingly, the strain-based model exhibits superior accuracy, while both stretch- and strain-based models effectively capture the nonlinearity and tension-compression asymmetry inherent to human brain tissue. Polyconvexity examinations affirm the rigor of convexity within the training regime and demonstrate excellent extrapolation capabilities beyond this regime for all three models. However, the stretch-based models raise concerns regarding potential convexity loss under large deformations. Finally, robustness tests on noise-embedded data underscore the reliability of our symbolic regression algorithms. Our study confirms the applicability and accuracy of symbolic regression in the automated discovery of hyperelastic models for the human brain and gives rise to a wide variety of applications in other soft matter systems.",
        "subjects": [
            "cs.SC"
        ],
        "comment": "53 pages, 17 figures, and 6 tables"
    },
    {
        "paper id": "2402.05244",
        "abstract url": "https://arxiv.org/abs/2402.05244",
        "title": "CRIU -- Checkpoint Restore in Userspace for computational simulations and scientific applications",
        "rating": -10,
        "keywords": [],
        "abstract": "Creating new materials, discovering new drugs, and simulating systems are essential processes for research and innovation and require substantial computational power. While many applications can be split into many smaller independent tasks, some cannot and may take hours or weeks to run to completion. To better manage those longer-running jobs, it would be desirable to stop them at any arbitrary point in time and later continue their computation on another compute resource; this is usually referred to as checkpointing. While some applications can manage checkpointing programmatically, it would be preferable if the batch scheduling system could do that independently. This paper evaluates the feasibility of using CRIU (Checkpoint Restore in Userspace), an open-source tool for the GNU/Linux environments, emphasizing the OSG's OSPool HTCondor setup. CRIU allows checkpointing the process state into a disk image and can deal with both open files and established network connections seamlessly. Furthermore, it can checkpoint traditional Linux processes and containerized workloads. The functionality seems adequate for many scenarios supported in the OSPool. However, some limitations prevent it from being usable in all circumstances.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "26TH INTERNATIONAL CONFERENCE ON COMPUTING IN HIGH ENERGY & NUCLEAR PHYSICS - 2023"
    },
    {
        "paper id": "2402.05245",
        "abstract url": "https://arxiv.org/abs/2402.05245",
        "title": "On the Outcome Equivalence of Extensive-Form and Behavioral Correlated Equilibria",
        "rating": -10,
        "keywords": [],
        "abstract": "We investigate two notions of correlated equilibrium for extensive-form games: extensive-form correlated equilibrium (EFCE) and behavioral correlated equilibrium (BCE). We show that the two are outcome-equivalent, in the sense that every outcome distribution achievable under one notion is achievable under the other. Our result implies, to our knowledge, the first polynomial-time algorithm for computing a BCE.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05256",
        "abstract url": "https://arxiv.org/abs/2402.05256",
        "title": "IRFuzzer: Specialized Fuzzing for LLVM Backend Code Generation",
        "rating": -10,
        "keywords": [],
        "abstract": "Modern compilers, such as LLVM, are complex pieces of software. Due to their complexity, manual testing is unlikely to suffice, yet formal verification is difficult to scale. End-to-end fuzzing can be used, but it has difficulties in achieving high coverage of some components of LLVM. In this paper, we implement IRFuzzer to investigate the effectiveness of specialized fuzzing of the LLVM compiler backend. We focus on two approaches to improve the fuzzer: guaranteed input validity using constrained mutations and improved feedback quality. The mutator in IRFuzzer is capable of generating a wide range of LLVM IR inputs, including structured control flow, vector types, and function definitions. The system instruments coding patterns in the compiler to monitor the execution status of instruction selection. The instrumentation not only provides a new coverage feedback called matcher table coverage, but also provides an architecture specific guidance to the mutator. We show that IRFuzzer is more effective than existing fuzzers by fuzzing on 29 mature LLVM backend targets. In the process, we reported 74 confirmed new bugs in LLVM upstream, out of which 49 have been fixed, five have been back ported to LLVM 15, showing that specialized fuzzing provides useful and actionable insights to LLVM developers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05263",
        "abstract url": "https://arxiv.org/abs/2402.05263",
        "title": "Position and Speed Control of Brushless DC Motors Using Sensorless Techniques and Application Trends",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper provides a technical review of position and speed sensorless methods for controlling Brushless Direct Current (BLDC) motor drives, including the background analysis using sensors, limitations and advances. The performance and reliability of BLDC motor drivers have been improved because the conventional control and sensing techniques have been improved through sensorless technology. Then, in this paper sensorless advances are reviewed and recent developments in this area are introduced with their inherent advantages and drawbacks, including the analysis of practical implementation issues and applications. The study includes a deep overview of state-of-the-art back-EMF sensing methods, which includes Terminal Voltage Sensing, Third Harmonic Voltage Integration, Terminal Current Sensing, Back-EMF Integration and PWM strategies. Also, the most relevant techniques based on estimation and models are briefly analysed, such as Sliding-mode Observer, Extended Kalman Filter, Model Reference Adaptive System, Adaptive observers (Full-order and Pseudoreduced-order) and Artificial Neural Networks.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05271",
        "abstract url": "https://arxiv.org/abs/2402.05271",
        "title": "Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of simple statistics of the inputs and labels. Finally, we introduce a simple intervention to increase NFA correlation at any given layer, which dramatically improves the quality of features learned.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05277",
        "abstract url": "https://arxiv.org/abs/2402.05277",
        "title": "Safe Human-UAS Collaboration Abstraction",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper studies the problem of safe humanuncrewed aerial system (UAS) collaboration in a shared work environment. By considering human and UAS as co-workers, we use Petri Nets to abstractly model evolution of shared tasks assigned to human and UAS co-workers. Particularly, the Petri Nets places represent work stations; therefore, the Petri Nets transitions can formally specify displacements between the work stations. The first objective is to incorporate uncertainty regarding the intentions of human co-workers into motion planning for UAS, when UAS co-workers closely interact with human co-workers. To this end, the proposed Petri Nets model uses conflict constructs to represent situations at which UAS deals with incomplete knowledge about human co-worker intention. The second objective is then to plan the motion of the UAS in a resilient and safe manner, in the presence of non-cooperative human co-workers. In order to achieve this objective, UAS equipped with onboard perception and decision-making capabilities are able to, through real-time processing of in-situ observation, predict human intention, quantify human distraction, and apply a non-stationary Markov Decision model to safely plan UAS motion in the presence of uncertainty.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05300",
        "abstract url": "https://arxiv.org/abs/2402.05300",
        "title": "Multi-Player Resource-Sharing Games with Fair Reward Allocation",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper considers a multi-player resource-sharing game with a fair reward allocation model. Multiple players choose from a collection of resources. Each resource brings a random reward equally divided among the players who choose it. We consider two settings. The first setting is a one-slot game where the mean rewards of the resources are known to all the players, and the objective of player 1 is to maximize their worst-case expected utility. Certain special cases of this setting have explicit solutions. These cases provide interesting yet non-intuitive insights into the problem. The second setting is an online setting, where the game is played over a finite time horizon, where the mean rewards are unknown to the first player. Instead, the first player receives, as feedback, the rewards of the resources they chose after the action. We develop a novel Upper Confidence Bound (UCB) algorithm that minimizes the worst-case regret of the first player using the feedback received.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05302",
        "abstract url": "https://arxiv.org/abs/2402.05302",
        "title": "Training DNN Models over Heterogeneous Clusters with Optimal Performance",
        "rating": -10,
        "keywords": [],
        "abstract": "Adjusting batch sizes and adaptively tuning other hyperparameters can significantly speed up deep neural network (DNN) training. Despite the ubiquity of heterogeneous clusters, existing adaptive DNN training techniques solely consider homogeneous environments. Optimizing distributed DNN training over heterogeneous clusters is technically challenging, and directly adapting existing techniques results in low utilization and poor performance. To solve this problem, we introduce Cannikin -- a novel data-parallel distributed training system. Cannikin achieves efficient and near-optimal performance by accurately modeling the optimal system performance and predicting adaptive batch size training metrics for DNNs in heterogeneous clusters. We implemented Cannikin in PyTorch and conducted experiments over 16 GPUs in Chameleon. Empirical results show that Cannikin reduces DNN training in heterogeneous clusters by up to $52\\%$ compared to the state-of-the-art adaptive training system and up to $85\\%$ compared to native PyTorch DistributedDataParallel.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05303",
        "abstract url": "https://arxiv.org/abs/2402.05303",
        "title": "Control of AC-AC interlinking converters for multi-grids",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper considers the control of AC-AC inter-linking converters (ILCs) in a multi-grid network. We overview the control schemes in the literature and propose a passivity framework for the stabilization of multi-grid networks, considering both AC grid-following and AC grid-forming behavior for the ILC connections. We then analyze a range of AC/AC interlinking converter control methods derived from the literature and propose suitable controllers for this purpose including both AC grid-forming and grid-following behavior. The controller we propose is partially grid-forming; in particular, it is based on a combination of a grid-following and a grid-forming converter to improve the stability properties of the network. Simulation results and theoretical analysis confirm that the proposed ILC control designs are appropriate for the multi-grid network.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "11 pages, 11 figures"
    },
    {
        "paper id": "2402.05312",
        "abstract url": "https://arxiv.org/abs/2402.05312",
        "title": "SplitSim: Large-Scale Simulations for Evaluating Network Systems Research",
        "rating": -10,
        "keywords": [],
        "abstract": "When physical testbeds are out of reach for evaluating a networked system, we frequently turn to simulation. In today's datacenter networks, bottlenecks are rarely at the network protocol level, but instead in end-host software or hardware components, thus current protocol-level simulations are inadequate means of evaluation. End-to-end simulations covering these components on the other hand, simply cannot achieve the required scale with feasible simulation performance and computational resources. In this paper, we address this with SplitSim, a simulation framework for end-to-end evaluation for large-scale network and distributed systems. To this end, SplitSim builds on prior work on modular end-to-end simulations and combines this with key elements to achieve scalability. First, mixed fidelity simulations judiciously reduce detail in simulation of parts of the system where this can be tolerated, while retaining the necessary detail elsewhere. SplitSim then parallelizes bottleneck simulators by decomposing them into multiple parallel but synchronized processes. Next, SplitSim provides a profiler to help users understand simulation performance and where the bottlenecks are, so users can adjust the configuration. Finally SplitSim provides abstractions to make it easy for users to build complex large-scale simulations. Our evaluation demonstrates SplitSim in multiple large-scale case studies.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "12 pages, under submission to peer-reviewed conference"
    },
    {
        "paper id": "2402.05314",
        "abstract url": "https://arxiv.org/abs/2402.05314",
        "title": "Barriers to device longevity and reuse: A vintage device empirical study",
        "rating": -10,
        "keywords": [],
        "abstract": "This extended paper contributes a methodology and a detailed analysis of app installation and functionality on a 'vintage' device. Experimental results are presented that demonstrate barriers to the reuse of vintage Apple devices. and solutions are posited. 230 apps across 23 unique app categories were tested to determine if they could be downloaded, installed, and opened, and whether they appeared functional on a vintage Apple device. Only 29 (12.6%) of the apps could be downloaded directly, and in contrast 140 (60.9%) of the apps were downloadable with the aid of another Apple device. In total, 141 (61.3%) of applications downloaded either directly or indirectly were considered functional and capable of running on the device. We discuss measures Apple and developers could take to support legacy device users, prolong device use, enable reuse and, potentially, prevent functional devices from becoming e-waste.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "To be published in the Journal of Systems and Software - Elsevier"
    },
    {
        "paper id": "2402.05334",
        "abstract url": "https://arxiv.org/abs/2402.05334",
        "title": "On the Interaction between Software Engineers and Data Scientists when building Machine Learning-Enabled Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "In recent years, Machine Learning (ML) components have been increasingly integrated into the core systems of organizations. Engineering such systems presents various challenges from both a theoretical and practical perspective. One of the key challenges is the effective interaction between actors with different backgrounds who need to work closely together, such as software engineers and data scientists. This paper presents an exploratory case study to understand the current interaction and collaboration dynamics between these roles in ML projects. We conducted semi-structured interviews with four practitioners with experience in software engineering and data science of a large ML-enabled system project and analyzed the data using reflexive thematic analysis. Our findings reveal several challenges that can hinder collaboration between software engineers and data scientists, including differences in technical expertise, unclear definitions of each role's duties, and the lack of documents that support the specification of the ML-enabled system. We also indicate potential solutions to address these challenges, such as fostering a collaborative culture, encouraging team communication, and producing concise system documentation. This study contributes to understanding the complex dynamics between software engineers and data scientists in ML projects and provides insights for improving collaboration and communication in this context. We encourage future studies investigating this interaction in other projects.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05336",
        "abstract url": "https://arxiv.org/abs/2402.05336",
        "title": "Treatment Effect Estimation Amidst Dynamic Network Interference in Online Gaming Experiments",
        "rating": -10,
        "keywords": [],
        "abstract": "The evolving landscape of online multiplayer gaming presents unique challenges in assessing the causal impacts of game features. Traditional A/B testing methodologies fall short due to complex player interactions, leading to violations of fundamental assumptions like the Stable Unit Treatment Value Assumption (SUTVA). Unlike traditional social networks with stable and long-term connections, networks in online games are often dynamic and short-lived. Players are temporarily teamed up for the duration of a game, forming transient networks that dissolve once the game ends. This fleeting nature of interactions presents a new challenge compared with running experiments in a stable social network. This study introduces a novel framework for treatment effect estimation in online gaming environments, considering the dynamic and ephemeral network interference that occurs among players. We propose an innovative estimator tailored for scenarios where a completely randomized experimental design is implemented without explicit knowledge of network structures. Notably, our method facilitates post-hoc interference adjustment on experimental data, significantly reducing the complexities and costs associated with intricate experimental designs and randomization strategies. The proposed framework stands out for its ability to accommodate varying levels of interference, thereby yielding more accurate and robust estimations. Through comprehensive simulations set against a variety of interference scenarios, along with empirical validation using real-world data from a mobile gaming environment, we demonstrate the efficacy of our approach. This study represents a pioneering effort in exploring causal inference in user-randomized experiments impacted by dynamic network effects.",
        "subjects": [
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05339",
        "abstract url": "https://arxiv.org/abs/2402.05339",
        "title": "Can participation in a hackathon impact the motivation of software engineering students? A preliminary case study analysis",
        "rating": -10,
        "keywords": [],
        "abstract": "[Background] Hackathons are increasingly gaining prominence in Software Engineering (SE) education, lauded for their ability to elevate students' skill sets. [Objective] This paper investigates whether hackathons can impact the motivation of SE students. [Method] We conducted an evaluative case study assessing students' motivations before and after a hackathon, combining quantitative analysis using the Academic Motivation Scale (AMS) and qualitative coding of open-ended responses. [Results] Pre-hackathon findings reveal a diverse range of motivations with an overall acceptance, while post-hackathon responses highlight no statistically significant shift in participants' perceptions. Qualitative findings uncovered themes related to networking, team dynamics, and skill development. From a practical perspective, our findings highlight the potential of hackathons to impact participants' motivation. [Conclusion] While our study enhances the comprehension of hackathons as a motivational tool, it also underscores the need for further exploration of psychometric dimensions in SE educational research.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05388",
        "abstract url": "https://arxiv.org/abs/2402.05388",
        "title": "Form-From: A Design Space of Social Media Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Social media systems are as varied as they are pervasive. They have been almost universally adopted for a broad range of purposes including work, entertainment, activism, and decision making. As a result, they have also diversified, with many distinct designs differing in content type, organization, delivery mechanism, access control, and many other dimensions. In this work, we aim to characterize and then distill a concise design space of social media systems that can help us understand similarities and differences, recognize potential consequences of design choices, and identify spaces for innovation. Our model, which we call Form-From, characterizes social media based on (1) the form of the content, either threaded or flat, and (2) from where or from whom one might receive content, ranging from spaces to networks to the commons. We derive Form-From inductively from a larger set of 62 dimensions organized into 10 categories. To demonstrate the utility of our model, we trace the history of social media systems as they traverse the Form-From space over time, and we identify common design patterns within cells of the model.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05404",
        "abstract url": "https://arxiv.org/abs/2402.05404",
        "title": "The Computation for Reversibility of Arbitrary One-dimensional Finite Cellular Automata Becomes Efficient",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we completely solve the reversibility of one-dimensional finite cellular automata (FCA). This means that we will have an efficient method to determine the reversibility of any FCA with all numbers (n) of cells. The complexity of this algorithm is independent of n. We perform calculations on two new kinds of graphs and discover that the reversibility of any FCA exhibits periodicity as n increases. We successfully provide a method to compute the reversibility sequence that encompasses the reversibility of FCA with any number of cells. Additionally, the calculations in this paper are applicable to FCA with various types of boundaries.",
        "subjects": [
            "nlin.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2402.05856",
        "abstract url": "https://arxiv.org/abs/2402.05856",
        "title": "Structure-Informed Protein Language Model",
        "rating": -10,
        "keywords": [],
        "abstract": "Protein language models are a powerful tool for learning protein representations through pre-training on vast protein sequence datasets. However, traditional protein language models lack explicit structural supervision, despite its relevance to protein function. To address this issue, we introduce the integration of remote homology detection to distill structural information into protein language models without requiring explicit protein structures as input. We evaluate the impact of this structure-informed training on downstream protein function prediction tasks. Experimental results reveal consistent improvements in function annotation accuracy for EC number and GO term prediction. Performance on mutant datasets, however, varies based on the relationship between targeted properties and protein structures. This underscores the importance of considering this relationship when applying structure-aware training to protein function prediction tasks. Code and model weights are available at https://github.com/DeepGraphLearning/esm-s.",
        "subjects": [
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2402.06678",
        "abstract url": "https://arxiv.org/abs/2402.06678",
        "title": "Can machine learning predict citizen-reported angler behavior?",
        "rating": -10,
        "keywords": [],
        "abstract": "Prediction of angler behaviors, such as catch rates and angler pressure, is essential to maintaining fish populations and ensuring angler satisfaction. Angler behavior can partly be tracked by online platforms and mobile phone applications that provide fishing activities reported by recreational anglers. Moreover, angler behavior is known to be driven by local site attributes. Here, the prediction of citizen-reported angler behavior was investigated by machine-learning methods using auxiliary data on the environment, socioeconomics, fisheries management objectives, and events at a freshwater body. The goal was to determine whether auxiliary data alone could predict the reported behavior. Different spatial and temporal extents and temporal resolutions were considered. Accuracy scores averaged 88% for monthly predictions at single water bodies and 86% for spatial predictions on a day in a specific region across Canada. At other resolutions and scales, the models only achieved low prediction accuracy of around 60%. The study represents a first attempt at predicting angler behavior in time and space at a large scale and establishes a foundation for potential future expansions in various directions.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "36 pages, 10 figures, 4 tables (including supplementary information)"
    },
    {
        "paper id": "2402.07938",
        "abstract url": "https://arxiv.org/abs/2402.07938",
        "title": "Large Language User Interfaces: Voice Interactive User Interfaces powered by LLMs",
        "rating": -10,
        "keywords": [],
        "abstract": "The evolution of Large Language Models (LLMs) has showcased remarkable capacities for logical reasoning and natural language comprehension. These capabilities can be leveraged in solutions that semantically and textually model complex problems. In this paper, we present our efforts toward constructing a framework that can serve as an intermediary between a user and their user interface (UI), enabling dynamic and real-time interactions. We employ a system that stands upon textual semantic mappings of UI components, in the form of annotations. These mappings are stored, parsed, and scaled in a custom data structure, supplementary to an agent-based prompting backend engine. Employing textual semantic mappings allows each component to not only explain its role to the engine but also provide expectations. By comprehending the needs of both the user and the components, our LLM engine can classify the most appropriate application, extract relevant parameters, and subsequently execute precise predictions of the user's expected actions. Such an integration evolves static user interfaces into highly dynamic and adaptable solutions, introducing a new frontier of intelligent and responsive user experiences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted as peer-reviewed publication"
    },
    {
        "paper id": "2402.09457",
        "abstract url": "https://arxiv.org/abs/2402.09457",
        "title": "Self-Healing Effects in OAM Beams Observed on a 28 GHz Experimental Link",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper we document for the first time some of the effects of self-healing, a property of orbital-angular-momentum (OAM) or vortex beams, as observed on a millimeter-wave experimental communications link in an outdoors line-of-sight (LOS) scenario. The OAM beams have a helical phase and polarization structure and have conical amplitude shape in the far field. The Poynting vectors of the OAM beams also possess helical structures, orthogonal to the corresponding helical phase-fronts. Due to such non-planar structure in the direction orthogonal to the beam axis, OAM beams are a subset of structured light beams. Such structured beams are known to possess self-healing properties when partially obstructed along their propagation axis, especially in their near fields, resulting in partial reconstruction of their structures at larger distances along their beam axis. Various theoretical rationales have been proposed to explain, model and experimentally verify the self-healing physical effects in structured optical beams, using various types of obstructions and experimental techniques. Based on these models, we hypothesize that any self-healing observed will be greater as the OAM order increases. Here we observe the self-healing effects for the first time in structured OAM radio beams, in terms of communication signals and channel parameters rather than beam structures. We capture the effects of partial near-field obstructions of OAM beams of different orders on the communications signals and provide a physical rationale to substantiate that the self-healing effect was observed to increase with the order of OAM, agreeing with our hypothesis.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "9 pages, 10 figures, pending submission to IEEE Access journal"
    },
    {
        "paper id": "2402.09458",
        "abstract url": "https://arxiv.org/abs/2402.09458",
        "title": "Relative consistency of Set Matrix Theory with ZF",
        "rating": -10,
        "keywords": [],
        "abstract": "Set Matrix Theory (SMT) has been introduced in Log. Anal. 225: 59-82 (2014) as a generalization of ZF, in which matrices constructed from sets are treated as urelements, that is, as objects that are not sets but that can be elements of sets. Here we prove that SMT is relatively consistent with ZF.",
        "subjects": [
            "math.LO"
        ],
        "comment": "5 pages; to appear in Logique et Analyse"
    },
    {
        "paper id": "2402.10937",
        "abstract url": "https://arxiv.org/abs/2402.10937",
        "title": "A Lightweight Inception Boosted U-Net Neural Network for Routability Prediction",
        "rating": -10,
        "keywords": [],
        "abstract": "As the modern CPU, GPU, and NPU chip design complexity and transistor counts keep increasing, and with the relentless shrinking of semiconductor technology nodes to nearly 1 nanometer, the placement and routing have gradually become the two most pivotal processes in modern very-large-scale-integrated (VLSI) circuit back-end design. How to evaluate routability efficiently and accurately in advance (at the placement and global routing stages) has grown into a crucial research area in the field of artificial intelligence (AI) assisted electronic design automation (EDA). In this paper, we propose a novel U-Net variant model boosted by an Inception embedded module to predict Routing Congestion (RC) and Design Rule Checking (DRC) hotspots. Experimental results on the recently published CircuitNet dataset benchmark show that our proposed method achieves up to 5% (RC) and 20% (DRC) rate reduction in terms of Avg-NRMSE (Average Normalized Root Mean Square Error) compared to the classic architecture. Furthermore, our approach consistently outperforms the prior model on the SSIM (Structural Similarity Index Measure) metric.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "The paper is submitted to the International Symposium of EDA (2024, XiAn, China)"
    },
    {
        "paper id": "2402.14583",
        "abstract url": "https://arxiv.org/abs/2402.14583",
        "title": "Dataset Artefacts are the Hidden Drivers of the Declining Disruptiveness in Science",
        "rating": -10,
        "keywords": [],
        "abstract": "Park et al. [1] reported a decline in the disruptiveness of scientific and technological knowledge over time. Their main finding is based on the computation of CD indices, a measure of disruption in citation networks [2], across almost 45 million papers and 3.9 million patents. Due to a factual plotting mistake, database entries with zero references were omitted in the CD index distributions, hiding a large number of outliers with a maximum CD index of one, while keeping them in the analysis [1]. Our reanalysis shows that the reported decline in disruptiveness can be attributed to a relative decline of these database entries with zero references. Notably, this was not caught by the robustness checks included in the manuscript. The regression adjustment fails to control for the hidden outliers as they correspond to a discontinuity in the CD index. Proper evaluation of the Monte-Carlo simulations reveals that, because of the preservation of the hidden outliers, even random citation behaviour replicates the observed decline in disruptiveness. Finally, while these papers and patents with supposedly zero references are the hidden drivers of the reported decline, their source documents predominantly do make references, exposing them as pure dataset artefacts.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "3 pages, 2 figures, 3 extended data figures, and Supplementary Information. In submission to Nature"
    },
    {
        "paper id": "2402.14590",
        "abstract url": "https://arxiv.org/abs/2402.14590",
        "title": "Scaling Up LLM Reviews for Google Ads Content Moderation",
        "rating": -10,
        "keywords": [],
        "abstract": "Large language models (LLMs) are powerful tools for content moderation, but their inference costs and latency make them prohibitive for casual use on large datasets, such as the Google Ads repository. This study proposes a method for scaling up LLM reviews for content moderation in Google Ads. First, we use heuristics to select candidates via filtering and duplicate removal, and create clusters of ads for which we select one representative ad per cluster. We then use LLMs to review only the representative ads. Finally, we propagate the LLM decisions for the representative ads back to their clusters. This method reduces the number of reviews by more than 3 orders of magnitude while achieving a 2x recall compared to a baseline non-LLM model. The success of this approach is a strong function of the representations used in clustering and label propagation; we found that cross-modal similarity representations yield better results than uni-modal representations.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.07894",
        "abstract url": "https://arxiv.org/abs/2403.07894",
        "title": "Auctions: a new method for selling bbjects with bimodal density functions",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper we define a new auction, called the Draw auction. It is based on the implementation of a draw when a minimum price of sale is not reached. We find that a Bayesian Nash equilibrium is reached in the Draw auction when each player bids his true personal valuation of the object. Furthermore, we show that the expected profit for the seller in the Draw auction is greater than in second price auctions, with or without minimum price of sale. We make this affirmation for objects whose valuation can be modeled as a bimodal density function in which the first mode is much greater than the second one. Regarding the Myerson auction, we show that the expected profit for the seller in the Draw auction is nearly as good as the expected profit in the optimal auction, with the difference that our method is much more simple to implement than Myerson's one. All these results are shown by computational tests, for whose development we have defined an algorithm to calculate Myerson auction.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "37 pages, 5 figures, 5 tables"
    },
    {
        "paper id": "2403.09680",
        "abstract url": "https://arxiv.org/abs/2403.09680",
        "title": "Pre-Sorted Tsetlin Machine (The Genetic K-Medoid Method)",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper proposes a machine learning pre-sort stage to traditional supervised learning using Tsetlin Machines. Initially, K data-points are identified from the dataset using an expedited genetic algorithm to solve the maximum dispersion problem. These are then used as the initial placement to run the K-Medoid clustering algorithm. Finally, an expedited genetic algorithm is used to align K independent Tsetlin Machines by maximising hamming distance. For MNIST level classification problems, results demonstrate up to 10% improvement in accuracy, approx. 383X reduction in training time and approx. 86X reduction in inference time.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "6 pages, 12 figures, 3 tables"
    },
    {
        "paper id": "2403.12061",
        "abstract url": "https://arxiv.org/abs/2403.12061",
        "title": "Design-Space Exploration of SNN Models using Application-Specific Multi-Core Architectures",
        "rating": -10,
        "keywords": [],
        "abstract": "With the motivation and the difficulties that currently exist in comprehending and utilizing the promising features of SNNs, we proposed a novel run-time multi-core architecture-based simulator called \"RAVSim\" (Runtime Analysis and Visualization Simulator), a cutting-edge SNN simulator, developed using LabVIEW and it is publicly available on their website as an official module. RAVSim is a runtime virtual simulation environment tool that enables the user to interact with the model, observe its behavior of output concentration, and modify the set of parametric values at any time while the simulation is in execution. Recently some popular tools have been presented, but we believe that none of the tools allow users to interact with the model simulation in run time.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "Abstract Presentation in 2023 Neuro-Inspired Computing Elements (NICE) Conference"
    },
    {
        "paper id": "2403.18833",
        "abstract url": "https://arxiv.org/abs/2403.18833",
        "title": "A New Method for Sensorless Estimation of the Speed and Position in Brushed DC Motors Using Support Vector Machines",
        "rating": -10,
        "keywords": [],
        "abstract": "Currently, for many applications, it is necessary to know the speed and position of motors. This can be achieved using mechanical sensors coupled to the motor shaft or using sensorless techniques. The sensorless techniques in brushed dc motors can be classified into two types: 1) techniques based on the dynamic brushed dc motor model and 2) techniques based on the ripple component of the current. This paper presents a new method, based on the ripple component, for speed and position estimation in brushed dc motors, using support vector machines. The proposed method only measures the current and detects the pulses in this signal. The motor speed is estimated by using the inverse distance between the detected pulses, and the position is estimated by counting all detected pulses. The ability to detect ghost pulses and to discard false pulses is the main advantage of this method over other sensorless methods. The performed tests on two fractional horsepower brushed dc motors indicate that the method works correctly in a wide range of speeds and situations, in which the speed is constant or varies dynamically.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    }
]