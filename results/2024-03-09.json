[
    {
        "paper id": "2403.06075",
        "abstract url": "https://arxiv.org/abs/2403.06075",
        "title": "Multisize Dataset Condensation",
        "rating": 2.5,
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "While dataset condensation effectively enhances training efficiency, its application in on-device scenarios brings unique challenges. 1) Due to the fluctuating computational resources of these devices, there's a demand for a flexible dataset size that diverges from a predefined size. 2) The limited computational power on devices often prevents additional condensation operations. These two challenges connect to the \"subset degradation problem\" in traditional dataset condensation: a subset from a larger condensed dataset is often unrepresentative compared to directly condensing the whole dataset to that smaller size. In this paper, we propose Multisize Dataset Condensation (MDC) by compressing N condensation processes into a single condensation process to obtain datasets with multiple sizes. Specifically, we introduce an \"adaptive subset loss\" on top of the basic condensation loss to mitigate the \"subset degradation problem\". Our MDC method offers several benefits: 1) No additional condensation process is required; 2) reduced storage requirement by reusing condensed images. Experiments validate our findings on networks including ConvNet, ResNet and DenseNet, and datasets including SVHN, CIFAR-10, CIFAR-100 and ImageNet. For example, we achieved 5.22%-6.40% average accuracy gains on condensing CIFAR-10 to ten images per class. Code is available at: https://github.com/he-y/Multisize-Dataset-Condensation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2024 Oral"
    },
    {
        "paper id": "2403.05854",
        "abstract url": "https://arxiv.org/abs/2403.05854",
        "title": "LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Long-tail recognition is challenging because it requires the model to learn good representations from tail categories and address imbalances across all categories. In this paper, we propose a novel generative and fine-tuning framework, LTGC, to handle long-tail recognition via leveraging generated content. Firstly, inspired by the rich implicit knowledge in large-scale models (e.g., large language models, LLMs), LTGC leverages the power of these models to parse and reason over the original tail data to produce diverse tail-class content. We then propose several novel designs for LTGC to ensure the quality of the generated data and to efficiently fine-tune the model using both the generated and original data. The visualization demonstrates the effectiveness of the generation module in LTGC, which produces accurate and diverse tail data. Additionally, the experimental results demonstrate that our LTGC outperforms existing state-of-the-art methods on popular long-tailed benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2403.05894",
        "abstract url": "https://arxiv.org/abs/2403.05894",
        "title": "Frequency Attention for Knowledge Distillation",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Knowledge distillation is an attractive approach for learning compact deep neural networks, which learns a lightweight student model by distilling knowledge from a complex teacher model. Attention-based knowledge distillation is a specific form of intermediate feature-based knowledge distillation that uses attention mechanisms to encourage the student to better mimic the teacher. However, most of the previous attention-based distillation approaches perform attention in the spatial domain, which primarily affects local regions in the input image. This may not be sufficient when we need to capture the broader context or global information necessary for effective knowledge transfer. In frequency domain, since each frequency is determined from all pixels of the image in spatial domain, it can contain global information about the image. Inspired by the benefits of the frequency domain, we propose a novel module that functions as an attention mechanism in the frequency domain. The module consists of a learnable global filter that can adjust the frequencies of student's features under the guidance of the teacher's features, which encourages the student's features to have patterns similar to the teacher's features. We then propose an enhanced knowledge review-based distillation model by leveraging the proposed frequency attention module. The extensive experiments with various teacher and student architectures on image classification and object detection benchmark datasets show that the proposed approach outperforms other knowledge distillation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Appear to WACV 2024"
    },
    {
        "paper id": "2403.05924",
        "abstract url": "https://arxiv.org/abs/2403.05924",
        "title": "CSCNET: Class-Specified Cascaded Network for Compositional Zero-Shot Learning",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Attribute and object (A-O) disentanglement is a fundamental and critical problem for Compositional Zero-shot Learning (CZSL), whose aim is to recognize novel A-O compositions based on foregone knowledge. Existing methods based on disentangled representation learning lose sight of the contextual dependency between the A-O primitive pairs. Inspired by this, we propose a novel A-O disentangled framework for CZSL, namely Class-specified Cascaded Network (CSCNet). The key insight is to firstly classify one primitive and then specifies the predicted class as a priori for guiding another primitive recognition in a cascaded fashion. To this end, CSCNet constructs Attribute-to-Object and Object-to-Attribute cascaded branches, in addition to a composition branch modeling the two primitives as a whole. Notably, we devise a parametric classifier (ParamCls) to improve the matching between visual and semantic embeddings. By improving the A-O disentanglement, our framework achieves superior results than previous competitive methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICASSP 2024"
    },
    {
        "paper id": "2403.05802",
        "abstract url": "https://arxiv.org/abs/2403.05802",
        "title": "UniSparse: An Intermediate Language for General Sparse Format Customization",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The ongoing trend of hardware specialization has led to a growing use of custom data formats when processing sparse workloads, which are typically memory-bound. These formats facilitate optimized software/hardware implementations by utilizing sparsity pattern- or target-aware data structures and layouts to enhance memory access latency and bandwidth utilization. However, existing sparse tensor programming models and compilers offer little or no support for productively customizing the sparse formats. Additionally, because these frameworks represent formats using a limited set of per-dimension attributes, they lack the flexibility to accommodate numerous new variations of custom sparse data structures and layouts. To overcome this deficiency, we propose UniSparse, an intermediate language that provides a unified abstraction for representing and customizing sparse formats. Unlike the existing attribute-based frameworks, UniSparse decouples the logical representation of the sparse tensor (i.e., the data structure) from its low-level memory layout, enabling the customization of both. As a result, a rich set of format customizations can be succinctly expressed in a small set of well-defined query, mutation, and layout primitives. We also develop a compiler leveraging the MLIR infrastructure, which supports adaptive customization of formats, and automatic code generation of format conversion and compute operations for heterogeneous architectures. We demonstrate the efficacy of our approach through experiments running commonly-used sparse linear algebra operations with specialized formats on multiple different hardware targets, including an Intel CPU, an NVIDIA GPU, an AMD Xilinx FPGA, and a simulated processing-in-memory (PIM) device.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "to be published in OOPSLA'24"
    },
    {
        "paper id": "2403.05807",
        "abstract url": "https://arxiv.org/abs/2403.05807",
        "title": "A self-supervised CNN for image watermark removal",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Popular convolutional neural networks mainly use paired images in a supervised way for image watermark removal. However, watermarked images do not have reference images in the real world, which results in poor robustness of image watermark removal techniques. In this paper, we propose a self-supervised convolutional neural network (CNN) in image watermark removal (SWCNN). SWCNN uses a self-supervised way to construct reference watermarked images rather than given paired training samples, according to watermark distribution. A heterogeneous U-Net architecture is used to extract more complementary structural information via simple components for image watermark removal. Taking into account texture information, a mixed loss is exploited to improve visual effects of image watermark removal. Besides, a watermark dataset is conducted. Experimental results show that the proposed SWCNN is superior to popular CNNs in image watermark removal.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05812",
        "abstract url": "https://arxiv.org/abs/2403.05812",
        "title": "Algorithmic progress in language models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We investigate the rate at which algorithms for pre-training language models have improved since the advent of deep learning. Using a dataset of over 200 language model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore's Law. We estimate augmented scaling laws, which enable us to quantify algorithmic progress and determine the relative contributions of scaling models versus innovations in training algorithms. Despite the rapid pace of algorithmic progress and the development of new architectures such as the transformer, our analysis reveals that the increase in compute made an even larger contribution to overall performance improvements over this time period. Though limited by noisy benchmark data, our analysis quantifies the rapid progress in language modeling, shedding light on the relative contributions from compute and algorithms.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05845",
        "abstract url": "https://arxiv.org/abs/2403.05845",
        "title": "Reverse That Number! Decoding Order Matters in Arithmetic Learning",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in pretraining have demonstrated that modern Large Language Models (LLMs) possess the capability to effectively learn arithmetic operations. However, despite acknowledging the significance of digit order in arithmetic computation, current methodologies predominantly rely on sequential, step-by-step approaches for teaching LLMs arithmetic, resulting in a conclusion where obtaining better performance involves fine-grained step-by-step. Diverging from this conventional path, our work introduces a novel strategy that not only reevaluates the digit order by prioritizing output from the least significant digit but also incorporates a step-by-step methodology to substantially reduce complexity. We have developed and applied this method in a comprehensive set of experiments. Compared to the previous state-of-the-art (SOTA) method, our findings reveal an overall improvement of in accuracy while requiring only a third of the tokens typically used during training. For the purpose of facilitating replication and further research, we have made our code and dataset publicly available at \\url{https://anonymous.4open.science/r/RAIT-9FB7/}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05852",
        "abstract url": "https://arxiv.org/abs/2403.05852",
        "title": "SSF-Net: Spatial-Spectral Fusion Network with Spectral Angle Awareness for Hyperspectral Object Tracking",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Hyperspectral video (HSV) offers valuable spatial, spectral, and temporal information simultaneously, making it highly suitable for handling challenges such as background clutter and visual similarity in object tracking. However, existing methods primarily focus on band regrouping and rely on RGB trackers for feature extraction, resulting in limited exploration of spectral information and difficulties in achieving complementary representations of object features. In this paper, a spatial-spectral fusion network with spectral angle awareness (SST-Net) is proposed for hyperspectral (HS) object tracking. Firstly, to address the issue of insufficient spectral feature extraction in existing networks, a spatial-spectral feature backbone ($S^2$FB) is designed. With the spatial and spectral extraction branch, a joint representation of texture and spectrum is obtained. Secondly, a spectral attention fusion module (SAFM) is presented to capture the intra- and inter-modality correlation to obtain the fused features from the HS and RGB modalities. It can incorporate the visual information into the HS spectral context to form a robust representation. Thirdly, to ensure a more accurate response of the tracker to the object position, a spectral angle awareness module (SAAM) investigates the region-level spectral similarity between the template and search images during the prediction stage. Furthermore, we develop a novel spectral angle awareness loss (SAAL) to offer guidance for the SAAM based on similar regions. Finally, to obtain the robust tracking results, a weighted prediction method is considered to combine the HS and RGB predicted motions of objects to leverage the strengths of each modality. Extensive experiments on the HOTC dataset demonstrate the effectiveness of the proposed SSF-Net, compared with state-of-the-art trackers.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05856",
        "abstract url": "https://arxiv.org/abs/2403.05856",
        "title": "POV: Prompt-Oriented View-Agnostic Learning for Egocentric Hand-Object Interaction in the Multi-View World",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We humans are good at translating third-person observations of hand-object interactions (HOI) into an egocentric view. However, current methods struggle to replicate this ability of view adaptation from third-person to first-person. Although some approaches attempt to learn view-agnostic representation from large-scale video datasets, they ignore the relationships among multiple third-person views. To this end, we propose a Prompt-Oriented View-agnostic learning (POV) framework in this paper, which enables this view adaptation with few egocentric videos. Specifically, We introduce interactive masking prompts at the frame level to capture fine-grained action information, and view-aware prompts at the token level to learn view-agnostic representation. To verify our method, we establish two benchmarks for transferring from multiple third-person views to the egocentric view. Our extensive experiments on these benchmarks demonstrate the efficiency and effectiveness of our POV framework and prompt tuning techniques in terms of view adaptation and view generalization. Our code is available at \\url{https://github.com/xuboshen/pov_acmmm2023}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ACM MM 2023. Project page: https://xuboshen.github.io/"
    },
    {
        "paper id": "2403.05887",
        "abstract url": "https://arxiv.org/abs/2403.05887",
        "title": "Aligning Speech to Languages to Enhance Code-switching Speech Recognition",
        "rating": 1,
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Code-switching (CS) refers to the switching of languages within a speech signal and results in language confusion for automatic speech recognition (ASR). To address language confusion, we propose the language alignment loss that performs frame-level language identification using pseudo language labels learned from the ASR decoder. This eliminates the need for frame-level language annotations. To further tackle the complex token alternatives for language modeling in bilingual scenarios, we propose to employ large language models via a generative error correction method. A linguistic hint that incorporates language information (derived from the proposed language alignment loss and decoded hypotheses) is introduced to guide the prompting of large language models. The proposed methods are evaluated on the SEAME dataset and data from the ASRU 2019 Mandarin-English code-switching speech recognition challenge. The incorporation of the proposed language alignment loss demonstrates a higher CS-ASR performance with only a negligible increase in the number of parameters on both datasets compared to the baseline model. This work also highlights the efficacy of language alignment loss in balancing primary-language-dominant bilingual data during training, with an 8.6% relative improvement on the ASRU dataset compared to the baseline model. Performance evaluation using large language models reveals the advantage of the linguistic hint by achieving 14.1% and 5.5% relative improvement on test sets of the ASRU and SEAME datasets, respectively.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Manuscript submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing"
    },
    {
        "paper id": "2403.05931",
        "abstract url": "https://arxiv.org/abs/2403.05931",
        "title": "Thread Detection and Response Generation using Transformers with Prompt Optimisation",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Conversational systems are crucial for human-computer interaction, managing complex dialogues by identifying threads and prioritising responses. This is especially vital in multi-party conversations, where precise identification of threads and strategic response prioritisation ensure efficient dialogue management. To address these challenges an end-to-end model that identifies threads and prioritises their response generation based on the importance was developed, involving a systematic decomposition of the problem into discrete components - thread detection, prioritisation, and performance optimisation which was meticulously analysed and optimised. These refined components seamlessly integrate into a unified framework, in conversational systems. Llama2 7b is used due to its high level of generalisation but the system can be updated with any open source Large Language Model(LLM). The computational capabilities of the Llama2 model was augmented by using fine tuning methods and strategic prompting techniques to optimise the model's performance, reducing computational time and increasing the accuracy of the model. The model achieves up to 10x speed improvement, while generating more coherent results compared to existing models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "6 pages, 4 figures, submitted to 2024 IEEE International Conference on Signal Processing and Communications (SPCOM)"
    },
    {
        "paper id": "2403.05937",
        "abstract url": "https://arxiv.org/abs/2403.05937",
        "title": "Wavelet-Like Transform-Based Technology in Response to the Call for Proposals on Neural Network-Based Image Coding",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural network-based image coding has been developing rapidly since its birth. Until 2022, its performance has surpassed that of the best-performing traditional image coding framework -- H.266/VVC. Witnessing such success, the IEEE 1857.11 working subgroup initializes a neural network-based image coding standard project and issues a corresponding call for proposals (CfP). In response to the CfP, this paper introduces a novel wavelet-like transform-based end-to-end image coding framework -- iWaveV3. iWaveV3 incorporates many new features such as affine wavelet-like transform, perceptual-friendly quality metric, and more advanced training and online optimization strategies into our previous wavelet-like transform-based framework iWave++. While preserving the features of supporting lossy and lossless compression simultaneously, iWaveV3 also achieves state-of-the-art compression efficiency for objective quality and is very competitive for perceptual quality. As a result, iWaveV3 is adopted as a candidate scheme for developing the IEEE Standard for neural-network-based image coding.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05966",
        "abstract url": "https://arxiv.org/abs/2403.05966",
        "title": "Can Generative Models Improve Self-Supervised Representation Learning?",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement in self-supervised learning (SSL) has highlighted its potential to leverage unlabeled data for learning powerful visual representations. However, existing SSL approaches, particularly those employing different views of the same image, often rely on a limited set of predefined data augmentations. This constrains the diversity and quality of transformations, which leads to sub-optimal representations. In this paper, we introduce a novel framework that enriches the SSL paradigm by utilizing generative models to produce semantically consistent image augmentations. By directly conditioning generative models on a source image representation, our method enables the generation of diverse augmentations while maintaining the semantics of the source image, thus offering a richer set of data for self-supervised learning. Our experimental results demonstrate that our framework significantly enhances the quality of learned visual representations. This research demonstrates that incorporating generative models into the SSL workflow opens new avenues for exploring the potential of unlabeled visual data. This development paves the way for more robust and versatile representation learning techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05973",
        "abstract url": "https://arxiv.org/abs/2403.05973",
        "title": "Calibrating Large Language Models Using Their Generations Only",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model's confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs - especially when the only interface to the models is their generated text - remains a challenge. We propose APRICOT (auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that predicts an LLM's confidence based on its textual input and output alone. This approach has several advantages: It is conceptually simple, does not require access to the target model beyond its output, does not interfere with the language generation, and has a multitude of potential usages, for instance by verbalizing the predicted confidence or adjusting the given answer based on the confidence. We show how our approach performs competitively in terms of calibration error for white-box and black-box LLMs on closed-book question-answering to detect incorrect LLM answers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05975",
        "abstract url": "https://arxiv.org/abs/2403.05975",
        "title": "Measuring Bias in a Ranked List using Term-based Representations",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In most recent studies, gender bias in document ranking is evaluated with the NFaiRR metric, which measures bias in a ranked list based on an aggregation over the unbiasedness scores of each ranked document. This perspective in measuring the bias of a ranked list has a key limitation: individual documents of a ranked list might be biased while the ranked list as a whole balances the groups' representations. To address this issue, we propose a novel metric called TExFAIR (term exposure-based fairness), which is based on two new extensions to a generic fairness evaluation framework, attention-weighted ranking fairness (AWRF). TExFAIR assesses fairness based on the term-based representation of groups in a ranked list: (i) an explicit definition of associating documents to groups based on probabilistic term-level associations, and (ii) a rank-biased discounting factor (RBDF) for counting non-representative documents towards the measurement of the fairness of a ranked list. We assess TExFAIR on the task of measuring gender bias in passage ranking, and study the relationship between TExFAIR and NFaiRR. Our experiments show that there is no strong correlation between TExFAIR and NFaiRR, which indicates that TExFAIR measures a different dimension of fairness than NFaiRR. With TExFAIR, we extend the AWRF framework to allow for the evaluation of fairness in settings with term-based representations of groups in documents in a ranked list.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at the 46th European Conference on Information Retrieval (ECIR 2024)"
    },
    {
        "paper id": "2403.05982",
        "abstract url": "https://arxiv.org/abs/2403.05982",
        "title": "Enhanced Auto Language Prediction with Dictionary Capsule -- A Novel Approach",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The paper presents a novel Auto Language Prediction Dictionary Capsule (ALPDC) framework for language prediction and machine translation. The model uses a combination of neural networks and symbolic representations to predict the language of a given input text and then translate it to a target language using pre-built dictionaries. This research work also aims to translate the text of various languages to its literal meaning in English. The proposed model achieves state-of-the-art results on several benchmark datasets and significantly improves translation accuracy compared to existing methods. The results show the potential of the proposed method for practical use in multilingual communication and natural language processing tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "21 Pages"
    },
    {
        "paper id": "2403.05989",
        "abstract url": "https://arxiv.org/abs/2403.05989",
        "title": "HAM-TTS: Hierarchical Acoustic Modeling for Token-Based Zero-Shot Text-to-Speech with Model and Data Scaling",
        "rating": 1,
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Token-based text-to-speech (TTS) models have emerged as a promising avenue for generating natural and realistic speech, yet they grapple with low pronunciation accuracy, speaking style and timbre inconsistency, and a substantial need for diverse training data. In response, we introduce a novel hierarchical acoustic modeling approach complemented by a tailored data augmentation strategy and train it on the combination of real and synthetic data, scaling the data size up to 650k hours, leading to the zero-shot TTS model with 0.8B parameters. Specifically, our method incorporates a latent variable sequence containing supplementary acoustic information based on refined self-supervised learning (SSL) discrete units into the TTS model by a predictor. This significantly mitigates pronunciation errors and style mutations in synthesized speech. During training, we strategically replace and duplicate segments of the data to enhance timbre uniformity. Moreover, a pretrained few-shot voice conversion model is utilized to generate a plethora of voices with identical content yet varied timbres. This facilitates the explicit learning of utterance-level one-to-many mappings, enriching speech diversity and also ensuring consistency in timbre. Comparative experiments (Demo page: https://anonymous.4open.science/w/ham-tts/)demonstrate our model's superiority over VALL-E in pronunciation precision and maintaining speaking style, as well as timbre continuity.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06018",
        "abstract url": "https://arxiv.org/abs/2403.06018",
        "title": "Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large pre-trained language models (PLMs) are at the forefront of advances in Natural Language Processing. One widespread use case of PLMs is \"prompting\" - or in-context learning - where a user provides a description of a task and some completed examples of the task to a PLM as context before prompting the PLM to perform the task on a new example. Only the largest, most capable PLMs are able to perform in-context learning effectively, and these models are typically trained with a predominantly English corpus, leaving all other languages behind. The data limitations in most languages preclude the training of language-specific PLMs capable of prompting. Albeit the surge in work of prompting settings, it is still unclear how PLMs should be adapted cross-lingually specifically for prompting. We evaluate the possible methods to adapt LLaMa, a 7B parameter open-source PLM mainly trained in English, for prompting in low-resource languages, namely for Kinyarwanda, Hausa, and Luganda. We consider three methods: few-shot prompting (prompt), language-adaptive fine-tuning (LAFT), and neural machine translation (translate), and evaluate on abstractive summarization, multi-class topic classification, and named-entity recognition. Although LAFT carries the greatest compute cost and intuitively should lead to the best results, our experiments exhibit that LAFT is only occasionally the optimal choice for adapting PLMs for prompting. Rather, the translate and prompt settings are a compute-efficient and cost-effective method of few-shot prompting for the selected low-resource languages. We find that the results are task and language dependent but find that the prompting method is the best on average across all tasks and languages. Results show that the prompt setting performs better than both translating and LAFT with statistical significance for all shots when aggregated across all tasks and languages.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "47 pages, 26 figures; a thesis submitted in partial satisfaction of the requirements for the degree of Bachelor of Science in Computer Science at the University of California - Santa Cruz"
    },
    {
        "paper id": "2403.06023",
        "abstract url": "https://arxiv.org/abs/2403.06023",
        "title": "Persian Slang Text Conversion to Formal and Deep Learning of Persian Short Texts on Social Media for Sentiment Classification",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The lack of a suitable tool for the analysis of conversational texts in the Persian language has made various analyses of these texts, including Sentiment Analysis, difficult. In this research, we tried to make the understanding of these texts easier for the machine by providing PSC, Persian Slang Converter, a tool for converting conversational texts into formal ones, and by using the most up-to-date and best deep learning methods along with the PSC, the sentiment learning of short Persian language texts for the machine in a better way. be made More than 10 million unlabeled texts from various social networks and movie subtitles (as Conversational texts) and about 10 million news texts (as formal texts) have been used for training unsupervised models and formal implementation of the tool. 60,000 texts from the comments of Instagram social network users with positive, negative, and neutral labels are considered supervised data for training the emotion classification model of short texts. Using the formal tool, 57% of the words of the corpus of conversation were converted. Finally, by using the formalizer, FastText model, and deep LSTM network, an accuracy of 81.91 was obtained on the test data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2403.06048",
        "abstract url": "https://arxiv.org/abs/2403.06048",
        "title": "Texture image retrieval using a classification and contourlet-based features",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we propose a new framework for improving Content Based Image Retrieval (CBIR) for texture images. This is achieved by using a new image representation based on the RCT-Plus transform which is a novel variant of the Redundant Contourlet transform that extracts a richer directional information in the image. Moreover, the process of image search is improved through a learning-based approach where the images of the database are classified using an adapted similarity metric to the statistical modeling of the RCT-Plus transform. A query is then first classified to select the best texture class after which the retained class images are ranked to select top ones. By this, we have achieved significant improvements in the retrieval rates compared to previous CBIR schemes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 6 figures, The 25th International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV'21: July 26-29, 2021, USA)"
    },
    {
        "paper id": "2403.06060",
        "abstract url": "https://arxiv.org/abs/2403.06060",
        "title": "Ensemble Language Models for Multilingual Sentiment Analysis",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of social media enables us to analyze user opinions. In recent times, sentiment analysis has shown a prominent research gap in understanding human sentiment based on the content shared on social media. Although sentiment analysis for commonly spoken languages has advanced significantly, low-resource languages like Arabic continue to get little research due to resource limitations. In this study, we explore sentiment analysis on tweet texts from SemEval-17 and the Arabic Sentiment Tweet dataset. Moreover, We investigated four pretrained language models and proposed two ensemble language models. Our findings include monolingual models exhibiting superior performance and ensemble models outperforming the baseline while the majority voting ensemble outperforms the English language.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This is one of my graduate course project reports and currently, I'm not planning to submit to any conferences"
    },
    {
        "paper id": "2403.06063",
        "abstract url": "https://arxiv.org/abs/2403.06063",
        "title": "Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Target-oriented proactive dialogue systems aim to lead conversations from a dialogue context toward a pre-determined target, such as making recommendations on designated items or introducing new specific topics. To this end, it is critical for such dialogue systems to plan reasonable actions to drive the conversation proactively, and meanwhile, to plan appropriate topics to move the conversation forward to the target topic smoothly. In this work, we mainly focus on effective dialogue planning for target-oriented dialogue generation. Inspired by decision-making theories in cognitive science, we propose a novel target-constrained bidirectional planning (TRIP) approach, which plans an appropriate dialogue path by looking ahead and looking back. By formulating the planning as a generation task, our TRIP bidirectionally generates a dialogue path consisting of a sequence of <action, topic> pairs using two Transformer decoders. They are expected to supervise each other and converge on consistent actions and topics by minimizing the decision gap and contrastive generation of targets. Moreover, we propose a target-constrained decoding algorithm with a bidirectional agreement to better control the planning process. Subsequently, we adopt the planned dialogue paths to guide dialogue generation in a pipeline manner, where we explore two variants: prompt-based generation and plan-controlled generation. Extensive experiments are conducted on two challenging dialogue datasets, which are re-purposed for exploring target-oriented dialogue. Our automatic and human evaluations demonstrate that the proposed methods significantly outperform various baseline models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ACM Transactions on Information Systems (TOIS)"
    },
    {
        "paper id": "2403.06066",
        "abstract url": "https://arxiv.org/abs/2403.06066",
        "title": "CausalCellSegmenter: Causal Inference inspired Diversified Aggregation Convolution for Pathology Image Segmentation",
        "rating": 1,
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning models have shown promising performance for cell nucleus segmentation in the field of pathology image analysis. However, training a robust model from multiple domains remains a great challenge for cell nucleus segmentation. Additionally, the shortcomings of background noise, highly overlapping between cell nucleus, and blurred edges often lead to poor performance. To address these challenges, we propose a novel framework termed CausalCellSegmenter, which combines Causal Inference Module (CIM) with Diversified Aggregation Convolution (DAC) techniques. The DAC module is designed which incorporates diverse downsampling features through a simple, parameter-free attention module (SimAM), aiming to overcome the problems of false-positive identification and edge blurring. Furthermore, we introduce CIM to leverage sample weighting by directly removing the spurious correlations between features for every input sample and concentrating more on the correlation between features and labels. Extensive experiments on the MoNuSeg-2018 dataset achieves promising results, outperforming other state-of-the-art methods, where the mIoU and DSC scores growing by 3.6% and 2.65%.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "10 pages, 5 figures, 2 tables, MICCAI"
    },
    {
        "paper id": "2403.06071",
        "abstract url": "https://arxiv.org/abs/2403.06071",
        "title": "Bit-mask Robust Contrastive Knowledge Distillation for Unsupervised Semantic Hashing",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised semantic hashing has emerged as an indispensable technique for fast image search, which aims to convert images into binary hash codes without relying on labels. Recent advancements in the field demonstrate that employing large-scale backbones (e.g., ViT) in unsupervised semantic hashing models can yield substantial improvements. However, the inference delay has become increasingly difficult to overlook. Knowledge distillation provides a means for practical model compression to alleviate this delay. Nevertheless, the prevailing knowledge distillation approaches are not explicitly designed for semantic hashing. They ignore the unique search paradigm of semantic hashing, the inherent necessities of the distillation process, and the property of hash codes. In this paper, we propose an innovative Bit-mask Robust Contrastive knowledge Distillation (BRCD) method, specifically devised for the distillation of semantic hashing models. To ensure the effectiveness of two kinds of search paradigms in the context of semantic hashing, BRCD first aligns the semantic spaces between the teacher and student models through a contrastive knowledge distillation objective. Additionally, to eliminate noisy augmentations and ensure robust optimization, a cluster-based method within the knowledge distillation process is introduced. Furthermore, through a bit-level analysis, we uncover the presence of redundancy bits resulting from the bit independence property. To mitigate these effects, we introduce a bit mask mechanism in our knowledge distillation objective. Finally, extensive experiments not only showcase the noteworthy performance of our BRCD method in comparison to other knowledge distillation methods but also substantiate the generality of our methods across diverse semantic hashing models and backbones. The code for BRCD is available at https://github.com/hly1998/BRCD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 19 figures, Proceedings of the ACM Web Conference 2024 (WWW '24)"
    },
    {
        "paper id": "2403.09709",
        "abstract url": "https://arxiv.org/abs/2403.09709",
        "title": "Exploratory Data Analysis on Code-mixed Misogynistic Comments",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The problems of online hate speech and cyberbullying have significantly worsened since the increase in popularity of social media platforms such as YouTube and Twitter (X). Natural Language Processing (NLP) techniques have proven to provide a great advantage in automatic filtering such toxic content. Women are disproportionately more likely to be victims of online abuse. However, there appears to be a lack of studies that tackle misogyny detection in under-resourced languages. In this short paper, we present a novel dataset of YouTube comments in mix-code Hinglish collected from YouTube videos which have been weak labelled as `Misogynistic' and `Non-misogynistic'. Pre-processing and Exploratory Data Analysis (EDA) techniques have been applied on the dataset to gain insights on its characteristics. The process has provided a better understanding of the dataset through sentiment scores, word clouds, etc.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper is accepted in the 16th ISDSI-Global Conference 2023 https://isdsi2023.iimranchi.ac.in/"
    },
    {
        "paper id": "2403.05805",
        "abstract url": "https://arxiv.org/abs/2403.05805",
        "title": "And Then the Hammer Broke: Reflections on Machine Ethics from Feminist Philosophy of Science",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Vision is an important metaphor in ethical and political questions of knowledge. The feminist philosopher Donna Haraway points out the ``perverse'' nature of an intrusive, alienating, all-seeing vision (to which we might cry out ``stop looking at me!''), but also encourages us to embrace the embodied nature of sight and its promises for genuinely situated knowledge. Current technologies of machine vision -- surveillance cameras, drones (for war or recreation), iPhone cameras -- are usually construed as instances of the former rather than the latter, and for good reasons. However, although in no way attempting to diminish the real suffering these technologies have brought about in the world, I make the case for understanding technologies of computer vision as material instances of embodied seeing and situated knowing. Furthermore, borrowing from Iris Murdoch's concept of moral vision, I suggest that these technologies direct our labor towards self-reflection in ethically significant ways. My approach draws upon paradigms in computer vision research, phenomenology, and feminist epistemology. Ultimately, this essay is an argument for directing more philosophical attention from merely criticizing technologies of vision as ethically deficient towards embracing them as complex, methodologically and epistemologically important objects.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Pacific University Philosophy Conference"
    },
    {
        "paper id": "2403.05821",
        "abstract url": "https://arxiv.org/abs/2403.05821",
        "title": "Optimizing LLM Queries in Relational Workloads",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Analytical database providers (e.g., Redshift, Databricks, BigQuery) have rapidly added support for invoking Large Language Models (LLMs) through native user-defined functions (UDFs) to help users perform natural language tasks, such as classification, entity extraction, and translation, inside analytical workloads. For instance, an analyst might want to extract customer sentiments on millions of product reviews. However, LLM inference is highly expensive in both computational and economic terms: for example, an NVIDIA L4 GPU running Llama2-7B can only process 6 KB of text per second. In this paper, we explore how to optimize LLM inference for analytical workloads that invoke LLMs within relational queries. We show that relational queries present novel opportunities for accelerating LLM inference, including reordering rows to maximize key-value (KV) cache reuse within the LLM inference engine, reordering columns within a row to further increase cache reuse, and deduplicating redundant inference requests. We implement these optimizations in Apache Spark, with vLLM as the model serving backend and achieve up to 4.4x improvement in end-to-end latency on a benchmark of diverse LLM-based queries on real datasets. To the best of our knowledge, this is the first work to explicitly address the problem of optimizing LLM invocations within SQL queries.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05824",
        "abstract url": "https://arxiv.org/abs/2403.05824",
        "title": "Mid-career pitfall of consecutive success in science",
        "rating": 0.5,
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The creativity of scientists often manifests as localized hot streaks of significant success. Understanding the underlying mechanisms of these influential phases can enhance the effectiveness of support systems and funding allocation, fostering groundbreaking discoveries worthy of accolades. Historically, analyses have suggested that hot streaks occur randomly over time. However, our research, through meticulous examination, reveals that these phases are not flatly distributed but are more frequent at the early and late stages of scientists' careers. Notably, both early and late hot streaks are marked by dense tie collaborations, with the former typically involving close partnerships with particular authors and the latter being characterized by involvement in large-scale projects compared with single-top or ordinary papers. This pattern indicates that mid-career researchers lack both intimate relations and resources to keep big projects, leading to``mid-career pitfal'' of consecutive success. This insight holds profound implications for the development of policies and initiatives aimed at bolstering innovative research and discovery.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "23 pages, 20 figures"
    },
    {
        "paper id": "2403.05848",
        "abstract url": "https://arxiv.org/abs/2403.05848",
        "title": "tLaSDI: Thermodynamics-informed latent space dynamics identification",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a latent space dynamics identification method, namely tLaSDI, that embeds the first and second principles of thermodynamics. The latent variables are learned through an autoencoder as a nonlinear dimension reduction model. The latent dynamics are constructed by a neural network-based model that precisely preserves certain structures for the thermodynamic laws through the GENERIC formalism. An abstract error estimate is established, which provides a new loss formulation involving the Jacobian computation of autoencoder. The autoencoder and the latent dynamics are simultaneously trained to minimize the new loss. Computational examples demonstrate the effectiveness of tLaSDI, which exhibits robust generalization ability, even in extrapolation. In addition, an intriguing correlation is empirically observed between a quantity from tLaSDI in the latent space and the behaviors of the full-state solution.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "32 pages, 8 figures"
    },
    {
        "paper id": "2403.05864",
        "abstract url": "https://arxiv.org/abs/2403.05864",
        "title": "PAPER-HILT: Personalized and Adaptive Privacy-Aware Early-Exit for Reinforcement Learning in Human-in-the-Loop Systems",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) has increasingly become a preferred method over traditional rule-based systems in diverse human-in-the-loop (HITL) applications due to its adaptability to the dynamic nature of human interactions. However, integrating RL in such settings raises significant privacy concerns, as it might inadvertently expose sensitive user information. Addressing this, our paper focuses on developing PAPER-HILT, an innovative, adaptive RL strategy through exploiting an early-exit approach designed explicitly for privacy preservation in HITL environments. This approach dynamically adjusts the tradeoff between privacy protection and system utility, tailoring its operation to individual behavioral patterns and preferences. We mainly highlight the challenge of dealing with the variable and evolving nature of human behavior, which renders static privacy models ineffective. PAPER-HILT's effectiveness is evaluated through its application in two distinct contexts: Smart Home environments and Virtual Reality (VR) Smart Classrooms. The empirical results demonstrate PAPER-HILT's capability to provide a personalized equilibrium between user privacy and application utility, adapting effectively to individual user needs and preferences. On average for both experiments, utility (performance) drops by 24%, and privacy (state prediction) improves by 31%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2403.05882",
        "abstract url": "https://arxiv.org/abs/2403.05882",
        "title": "DiffRed: Dimensionality Reduction guided by stable rank",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we propose a novel dimensionality reduction technique, DiffRed, which first projects the data matrix, A, along first $k_1$ principal components and the residual matrix $A^{*}$ (left after subtracting its $k_1$-rank approximation) along $k_2$ Gaussian random vectors. We evaluate M1, the distortion of mean-squared pair-wise distance, and Stress, the normalized value of RMS of distortion of the pairwise distances. We rigorously prove that DiffRed achieves a general upper bound of $O\\left(\\sqrt{\\frac{1-p}{k_2}}\\right)$ on Stress and $O\\left(\\frac{(1-p)}{\\sqrt{k_2*\u03c1(A^{*})}}\\right)$ on M1 where $p$ is the fraction of variance explained by the first $k_1$ principal components and $\u03c1(A^{*})$ is the stable rank of $A^{*}$. These bounds are tighter than the currently known results for Random maps. Our extensive experiments on a variety of real-world datasets demonstrate that DiffRed achieves near zero M1 and much lower values of Stress as compared to the well-known dimensionality reduction techniques. In particular, DiffRed can map a 6 million dimensional dataset to 10 dimensions with 54% lower Stress than PCA.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05996",
        "abstract url": "https://arxiv.org/abs/2403.05996",
        "title": "Dissecting Deep RL with High Update Ratios: Combatting Value Overestimation and Divergence",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We show that deep reinforcement learning can maintain its ability to learn without resetting network parameters in settings where the number of gradient updates greatly exceeds the number of environment samples. Under such large update-to-data ratios, a recent study by Nikishin et al. (2022) suggested the emergence of a primacy bias, in which agents overfit early interactions and downplay later experience, impairing their ability to learn. In this work, we dissect the phenomena underlying the primacy bias. We inspect the early stages of training that ought to cause the failure to learn and find that a fundamental challenge is a long-standing acquaintance: value overestimation. Overinflated Q-values are found not only on out-of-distribution but also in-distribution data and can be traced to unseen action prediction propelled by optimizer momentum. We employ a simple unit-ball normalization that enables learning under large update ratios, show its efficacy on the widely used dm_control suite, and obtain strong performance on the challenging dog tasks, competitive with model-based approaches. Our results question, in parts, the prior explanation for sub-optimal learning due to overfitting on early data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06009",
        "abstract url": "https://arxiv.org/abs/2403.06009",
        "title": "Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) are susceptible to a variety of risks, from non-faithful output to biased and toxic generations. Due to several limiting factors surrounding LLMs (training cost, API access, data availability, etc.), it may not always be feasible to impose direct safety constraints on a deployed model. Therefore, an efficient and reliable alternative is required. To this end, we present our ongoing efforts to create and deploy a library of detectors: compact and easy-to-build classification models that provide labels for various harms. In addition to the detectors themselves, we discuss a wide range of uses for these detector models - from acting as guardrails to enabling effective AI governance. We also deep dive into inherent challenges in their development and discuss future work aimed at making the detectors more reliable and broadening their scope.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06011",
        "abstract url": "https://arxiv.org/abs/2403.06011",
        "title": "Reinforcement Learning Paycheck Optimization for Multivariate Financial Goals",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study paycheck optimization, which examines how to allocate income in order to achieve several competing financial goals. For paycheck optimization, a quantitative methodology is missing, due to a lack of a suitable problem formulation. To deal with this issue, we formulate the problem as a utility maximization problem. The proposed formulation is able to (i) unify different financial goals; (ii) incorporate user preferences regarding the goals; (iii) handle stochastic interest rates. The proposed formulation also facilitates an end-to-end reinforcement learning solution, which is implemented on a variety of problem settings.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06013",
        "abstract url": "https://arxiv.org/abs/2403.06013",
        "title": "Are Classification Robustness and Explanation Robustness Really Strongly Correlated? An Analysis Through Input Loss Landscape",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper delves into the critical area of deep learning robustness, challenging the conventional belief that classification robustness and explanation robustness in image classification systems are inherently correlated. Through a novel evaluation approach leveraging clustering for efficient assessment of explanation robustness, we demonstrate that enhancing explanation robustness does not necessarily flatten the input loss landscape with respect to explanation loss - contrary to flattened loss landscapes indicating better classification robustness. To deeply investigate this contradiction, a groundbreaking training method designed to adjust the loss landscape with respect to explanation loss is proposed. Through the new training method, we uncover that although such adjustments can impact the robustness of explanations, they do not have an influence on the robustness of classification. These findings not only challenge the prevailing assumption of a strong correlation between the two forms of robustness but also pave new pathways for understanding relationship between loss landscape and explanation loss.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06031",
        "abstract url": "https://arxiv.org/abs/2403.06031",
        "title": "FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning requires defining one's target variable for predictions or decisions, a process that can have profound implications on fairness: biases are often encoded in target variable definition itself, before any data collection or training. We present an interactive simulator, FairTargetSim (FTS), that illustrates how target variable definition impacts fairness. FTS is a valuable tool for algorithm developers, researchers, and non-technical stakeholders. FTS uses a case study of algorithmic hiring, using real-world data and user-defined target variables. FTS is open-source and available at: http://tinyurl.com/ftsinterface. The video accompanying this paper is here: http://tinyurl.com/ijcaifts.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06059",
        "abstract url": "https://arxiv.org/abs/2403.06059",
        "title": "Test-time Distribution Learning Adapter for Cross-modal Visual Reasoning",
        "rating": 0.5,
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "DNA"
            ],
            [
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Vision-Language Pre-Trained (VLP) models, such as CLIP, have demonstrated remarkable effectiveness in learning generic visual representations. Several approaches aim to efficiently adapt VLP models to downstream tasks with limited supervision, aiming to leverage the acquired knowledge from VLP models. However, these methods suffer from either introducing biased representations or requiring high computational complexity, which hinders their effectiveness in fine-tuning the CLIP model. Moreover, when a model is trained on data specific to a particular domain, its ability to generalize to uncharted domains diminishes. In this work, we propose Test-Time Distribution LearNing Adapter (TT-DNA) which directly works during the testing period. Specifically, we estimate Gaussian distributions to model visual features of the few-shot support images to capture the knowledge from the support set. The cosine similarity between query image and the feature distribution of support images is used as the prediction of visual adapter. Subsequently, the visual adapter's prediction merges with the original CLIP prediction via a residual connection, resulting in the final prediction. Our extensive experimental results on visual reasoning for human object interaction demonstrate that our proposed TT-DNA outperforms existing state-of-the-art methods by large margins.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2403.06082",
        "abstract url": "https://arxiv.org/abs/2403.06082",
        "title": "FrameQuant: Flexible Low-Bit Quantization for Transformers",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformers are the backbone of powerful foundation models for many Vision and Natural Language Processing tasks. But their compute and memory/storage footprint is large, and so, serving such models is expensive often requiring high-end hardware. To mitigate this difficulty, Post-Training Quantization seeks to modify a pre-trained model and quantize it to eight bits or lower, significantly boosting compute/memory/latency efficiency. Such models have been successfully quantized to four bits with some performance loss. In this work, we outline a simple scheme to quantize Transformer-based models to just two bits (plus some overhead) with only a small drop in accuracy. Key to our formulation is a concept borrowed from Harmonic analysis called Fusion Frames. Our main finding is that the quantization must take place not in the original weight space, but instead in the Fusion Frame representations. If quantization is interpreted as the addition of noise, our casting of the problem allows invoking an extensive body of known consistent recovery and noise robustness guarantees. Further, if desired, de-noising filters are known in closed form. We show empirically, via a variety of experiments, that (almost) two-bit quantization for Transformer models promises sizable efficiency gains.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "25 pages, 15 figures"
    },
    {
        "paper id": "2403.06086",
        "abstract url": "https://arxiv.org/abs/2403.06086",
        "title": "Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Estimating the potential behavior of the surrounding human-driven vehicles is crucial for the safety of autonomous vehicles in a mixed traffic flow. Recent state-of-the-art achieved accurate prediction using deep neural networks. However, these end-to-end models are usually black boxes with weak interpretability and generalizability. This paper proposes the Goal-based Neural Variational Agent (GNeVA), an interpretable generative model for motion prediction with robust generalizability to out-of-distribution cases. For interpretability, the model achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations with a variational mixture of Gaussians. We identify a causal structure among maps and agents' histories and derive a variational posterior to enhance generalizability. Experiments on motion prediction datasets validate that the fitted model can be interpretable and generalizable and can achieve comparable performance to state-of-the-art results.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted at AISTATS 2024"
    },
    {
        "paper id": "2403.06093",
        "abstract url": "https://arxiv.org/abs/2403.06093",
        "title": "Enhancing 3D Object Detection with 2D Detection-Guided Query Anchors",
        "rating": 0.5,
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Multi-camera-based 3D object detection has made notable progress in the past several years. However, we observe that there are cases (e.g. faraway regions) in which popular 2D object detectors are more reliable than state-of-the-art 3D detectors. In this paper, to improve the performance of query-based 3D object detectors, we present a novel query generating approach termed QAF2D, which infers 3D query anchors from 2D detection results. A 2D bounding box of an object in an image is lifted to a set of 3D anchors by associating each sampled point within the box with depth, yaw angle, and size candidates. Then, the validity of each 3D anchor is verified by comparing its projection in the image with its corresponding 2D box, and only valid anchors are kept and used to construct queries. The class information of the 2D bounding box associated with each query is also utilized to match the predicted boxes with ground truth for the set-based loss. The image feature extraction backbone is shared between the 3D detector and 2D detector by adding a small number of prompt parameters. We integrate QAF2D into three popular query-based 3D object detectors and carry out comprehensive evaluations on the nuScenes dataset. The largest improvement that QAF2D can bring about on the nuScenes validation subset is $2.3\\%$ NDS and $2.7\\%$ mAP. Code is available at https://github.com/nullmax-vision/QAF2D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2403.07022",
        "abstract url": "https://arxiv.org/abs/2403.07022",
        "title": "A Unified Model for Spatio-Temporal Prediction Queries with Arbitrary Modifiable Areal Units",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spatio-Temporal (ST) prediction is crucial for making informed decisions in urban location-based applications like ride-sharing. However, existing ST models often require region partition as a prerequisite, resulting in two main pitfalls. Firstly, location-based services necessitate ad-hoc regions for various purposes, requiring multiple ST models with varying scales and zones, which can be costly to support. Secondly, different ST models may produce conflicting outputs, resulting in confusing predictions. In this paper, we propose One4All-ST, a framework that can conduct ST prediction for arbitrary modifiable areal units using only one model. To reduce the cost of getting multi-scale predictions, we design an ST network with hierarchical spatial modeling and scale normalization modules to efficiently and equally learn multi-scale representations. To address prediction inconsistencies across scales, we propose a dynamic programming scheme to solve the formulated optimal combination problem, minimizing predicted error through theoretical analysis. Besides, we suggest using an extended quad-tree to index the optimal combinations for quick response to arbitrary modifiable areal units in practical online scenarios. Extensive experiments on two real-world datasets verify the efficiency and effectiveness of One4All-ST in ST prediction for arbitrary modifiable areal units. The source codes and data of this work are available at https://github.com/uctb/One4All-ST.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by ICDE 2024"
    },
    {
        "paper id": "2403.14675",
        "abstract url": "https://arxiv.org/abs/2403.14675",
        "title": "Investigating the Impact of Project Risks on Employee Turnover Intentions in the IT Industry of Pakistan",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Employee turnover remains a pressing issue within high-tech sectors such as IT firms and research centers, where organizational success heavily relies on the skills of their workforce. Intense competition and a scarcity of skilled professionals in the industry contribute to a perpetual demand for highly qualified employees, posing challenges for organizations to retain talent. While numerous studies have explored various factors affecting employee turnover in these industries, their focus often remains on overarching trends rather than specific organizational contexts. In particular, within the software industry, where projectspecific risks can significantly impact project success and timely delivery, understanding their influence on job satisfaction and turnover intentions is crucial. This study aims to investigate the influence of project risks in the IT industry on job satisfaction and employee turnover intentions. Furthermore, it examines the role of both external and internal social links in shaping perceptions of job satisfaction.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05814",
        "abstract url": "https://arxiv.org/abs/2403.05814",
        "title": "MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs",
        "rating": 0,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite advancements in on-topic dialogue systems, effectively managing topic shifts within dialogues remains a persistent challenge, largely attributed to the limited availability of training datasets. To address this issue, we propose Multi-Passage to Dialogue (MP2D), a data generation framework that automatically creates conversational question-answering datasets with natural topic transitions. By leveraging the relationships between entities in a knowledge graph, MP2D maps the flow of topics within a dialogue, effectively mirroring the dynamics of human conversation. It retrieves relevant passages corresponding to the topics and transforms them into dialogues through the passage-to-dialogue method. Through quantitative and qualitative experiments, we demonstrate MP2D's efficacy in generating dialogue with natural topic shifts. Furthermore, this study introduces a novel benchmark for topic shift dialogues, TS-WikiDialog. Utilizing the dataset, we demonstrate that even Large Language Models (LLMs) struggle to handle topic shifts in dialogue effectively, and we showcase the performance improvements of models trained on datasets generated by MP2D across diverse topic shift dialogue tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2403.05846",
        "abstract url": "https://arxiv.org/abs/2403.05846",
        "title": "Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by generating images from its intermediate representations. Using the Diffusion Lens, we perform an extensive analysis of two recent T2I models. Exploring compound prompts, we find that complex scenes describing multiple objects are composed progressively and more slowly compared to simple scenes; Exploring knowledge retrieval, we find that representation of uncommon concepts requires further computation compared to common concepts, and that knowledge retrieval is gradual across layers. Overall, our findings provide valuable insights into the text encoder component in T2I pipelines.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project webpage: tokeron.github.io/DiffusionLensWeb"
    },
    {
        "paper id": "2403.05874",
        "abstract url": "https://arxiv.org/abs/2403.05874",
        "title": "SPAFormer: Sequential 3D Part Assembly with Transformers",
        "rating": 0,
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce SPAFormer, an innovative model designed to overcome the combinatorial explosion challenge in the 3D Part Assembly (3D-PA) task. This task requires accurate prediction of each part's pose and shape in sequential steps, and as the number of parts increases, the possible assembly combinations increase exponentially, leading to a combinatorial explosion that severely hinders the efficacy of 3D-PA. SPAFormer addresses this problem by leveraging weak constraints from assembly sequences, effectively reducing the solution space's complexity. Since assembly part sequences convey construction rules similar to sentences being structured through words, our model explores both parallel and autoregressive generation. It further enhances assembly through knowledge enhancement strategies that utilize the attributes of parts and their sequence information, enabling it to capture the inherent assembly pattern and relationships among sequentially ordered parts. We also construct a more challenging benchmark named PartNet-Assembly covering 21 varied categories to more comprehensively validate the effectiveness of SPAFormer. Extensive experiments demonstrate the superior generalization capabilities of SPAFormer, particularly with multi-tasking and in scenarios requiring long-horizon assembly. Codes and model weights will be released at \\url{https://github.com/xuboshen/SPAFormer}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Code will be released at https://github.com/xuboshen/SPAFormer"
    },
    {
        "paper id": "2403.05955",
        "abstract url": "https://arxiv.org/abs/2403.05955",
        "title": "IOI: Invisible One-Iteration Adversarial Attack on No-Reference Image- and Video-Quality Metrics",
        "rating": 0,
        "keywords": [
            [
                "Attack"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "No-reference image- and video-quality metrics are widely used in video processing benchmarks. The robustness of learning-based metrics under video attacks has not been widely studied. In addition to having success, attacks that can be employed in video processing benchmarks must be fast and imperceptible. This paper introduces an Invisible One-Iteration (IOI) adversarial attack on no reference image and video quality metrics. We compared our method alongside eight prior approaches using image and video datasets via objective and subjective tests. Our method exhibited superior visual quality across various attacked metric architectures while maintaining comparable attack success and speed. We made the code available on GitHub.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05963",
        "abstract url": "https://arxiv.org/abs/2403.05963",
        "title": "Robust Emotion Recognition in Context Debiasing",
        "rating": 0,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Context-aware emotion recognition (CAER) has recently boosted the practical applications of affective computing techniques in unconstrained environments. Mainstream CAER methods invariably extract ensemble representations from diverse contexts and subject-centred characteristics to perceive the target person's emotional state. Despite advancements, the biggest challenge remains due to context bias interference. The harmful bias forces the models to rely on spurious correlations between background contexts and emotion labels in likelihood estimation, causing severe performance bottlenecks and confounding valuable context priors. In this paper, we propose a counterfactual emotion inference (CLEF) framework to address the above issue. Specifically, we first formulate a generalized causal graph to decouple the causal relationships among the variables in CAER. Following the causal graph, CLEF introduces a non-invasive context branch to capture the adverse direct effect caused by the context bias. During the inference, we eliminate the direct context effect from the total causal effect by comparing factual and counterfactual outcomes, resulting in bias mitigation and robust prediction. As a model-agnostic framework, CLEF can be readily integrated into existing methods, bringing consistent performance gains.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06070",
        "abstract url": "https://arxiv.org/abs/2403.06070",
        "title": "Reframe Anything: LLM Agent for Open World Video Reframing",
        "rating": 0,
        "keywords": [
            [
                "video editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The proliferation of mobile devices and social media has revolutionized content dissemination, with short-form video becoming increasingly prevalent. This shift has introduced the challenge of video reframing to fit various screen aspect ratios, a process that highlights the most compelling parts of a video. Traditionally, video reframing is a manual, time-consuming task requiring professional expertise, which incurs high production costs. A potential solution is to adopt some machine learning models, such as video salient object detection, to automate the process. However, these methods often lack generalizability due to their reliance on specific training data. The advent of powerful large language models (LLMs) open new avenues for AI capabilities. Building on this, we introduce Reframe Any Video Agent (RAVA), a LLM-based agent that leverages visual foundation models and human instructions to restructure visual content for video reframing. RAVA operates in three stages: perception, where it interprets user instructions and video content; planning, where it determines aspect ratios and reframing strategies; and execution, where it invokes the editing tools to produce the final video. Our experiments validate the effectiveness of RAVA in video salient object detection and real-world reframing tasks, demonstrating its potential as a tool for AI-powered video editing.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 6 figures"
    },
    {
        "paper id": "2403.05890",
        "abstract url": "https://arxiv.org/abs/2403.05890",
        "title": "Towards Efficient Replay in Federated Incremental Learning",
        "rating": -0.5,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In Federated Learning (FL), the data in each client is typically assumed fixed or static. However, data often comes in an incremental manner in real-world applications, where the data domain may increase dynamically. In this work, we study catastrophic forgetting with data heterogeneity in Federated Incremental Learning (FIL) scenarios where edge clients may lack enough storage space to retain full data. We propose to employ a simple, generic framework for FIL named Re-Fed, which can coordinate each client to cache important samples for replay. More specifically, when a new task arrives, each client first caches selected previous samples based on their global and local importance. Then, the client trains the local model with both the cached samples and the samples from the new task. Theoretically, we analyze the ability of Re-Fed to discover important samples for replay thus alleviating the catastrophic forgetting problem. Moreover, we empirically show that Re-Fed achieves competitive performance compared to state-of-the-art methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05918",
        "abstract url": "https://arxiv.org/abs/2403.05918",
        "title": "SEMRes-DDPM: Residual Network Based Diffusion Modelling Applied to Imbalanced Data",
        "rating": -0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the field of data mining and machine learning, commonly used classification models cannot effectively learn in unbalanced data. In order to balance the data distribution before model training, oversampling methods are often used to generate data for a small number of classes to solve the problem of classifying unbalanced data. Most of the classical oversampling methods are based on the SMOTE technique, which only focuses on the local information of the data, and therefore the generated data may have the problem of not being realistic enough. In the current oversampling methods based on generative networks, the methods based on GANs can capture the true distribution of data, but there is the problem of pattern collapse and training instability in training; in the oversampling methods based on denoising diffusion probability models, the neural network of the inverse diffusion process using the U-Net is not applicable to tabular data, and although the MLP can be used to replace the U-Net, the problem exists due to the simplicity of the structure and the poor effect of removing noise. problem of poor noise removal. In order to overcome the above problems, we propose a novel oversampling method SEMRes-DDPM.In the SEMRes-DDPM backward diffusion process, a new neural network structure SEMST-ResNet is used, which is suitable for tabular data and has good noise removal effect, and it can generate tabular data with higher quality. Experiments show that the SEMResNet network removes noise better than MLP; SEMRes-DDPM generates data distributions that are closer to the real data distributions than TabDDPM with CWGAN-GP; on 20 real unbalanced tabular datasets with 9 classification models, SEMRes-DDPM improves the quality of the generated tabular data in terms of three evaluation metrics (F1, G-mean, AUC) with better classification performance than other SOTA oversampling methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "None"
    },
    {
        "paper id": "2403.05921",
        "abstract url": "https://arxiv.org/abs/2403.05921",
        "title": "OntoChat: a Framework for Conversational Ontology Engineering using Language Models",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Ontology engineering (OE) in large projects poses a number of challenges arising from the heterogeneous backgrounds of the various stakeholders, domain experts, and their complex interactions with ontology designers. This multi-party interaction often creates systematic ambiguities and biases from the elicitation of ontology requirements, which directly affect the design, evaluation and may jeopardise the target reuse. Meanwhile, current OE methodologies strongly rely on manual activities (e.g., interviews, discussion pages). After collecting evidence on the most crucial OE activities, we introduce OntoChat, a framework for conversational ontology engineering that supports requirement elicitation, analysis, and testing. By interacting with a conversational agent, users can steer the creation of user stories and the extraction of competency questions, while receiving computational support to analyse the overall requirements and test early versions of the resulting ontologies. We evaluate OntoChat by replicating the engineering of the Music Meta Ontology, and collecting preliminary metrics on the effectiveness of each component from users. We release all code at https://github.com/King-s-Knowledge-Graph-Lab/OntoChat.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06014",
        "abstract url": "https://arxiv.org/abs/2403.06014",
        "title": "Hard-label based Small Query Black-box Adversarial Attack",
        "rating": -0.5,
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the hard label based black box adversarial attack setting which solely observes predicted classes from the target model. Most of the attack methods in this setting suffer from impractical number of queries required to achieve a successful attack. One approach to tackle this drawback is utilising the adversarial transferability between white box surrogate models and black box target model. However, the majority of the methods adopting this approach are soft label based to take the full advantage of zeroth order optimisation. Unlike mainstream methods, we propose a new practical setting of hard label based attack with an optimisation process guided by a pretrained surrogate model. Experiments show the proposed method significantly improves the query efficiency of the hard label based black-box attack across various target model architectures. We find the proposed method achieves approximately 5 times higher attack success rate compared to the benchmarks, especially at the small query budgets as 100 and 250.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "11 pages, 3 figures"
    },
    {
        "paper id": "2403.06017",
        "abstract url": "https://arxiv.org/abs/2403.06017",
        "title": "Addressing Shortcomings in Fair Graph Learning Datasets: Towards a New Benchmark",
        "rating": -0.5,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fair graph learning plays a pivotal role in numerous practical applications. Recently, many fair graph learning methods have been proposed; however, their evaluation often relies on poorly constructed semi-synthetic datasets or substandard real-world datasets. In such cases, even a basic Multilayer Perceptron (MLP) can outperform Graph Neural Networks (GNNs) in both utility and fairness. In this work, we illustrate that many datasets fail to provide meaningful information in the edges, which may challenge the necessity of using graph structures in these problems. To address these issues, we develop and introduce a collection of synthetic, semi-synthetic, and real-world datasets that fulfill a broad spectrum of requirements. These datasets are thoughtfully designed to include relevant graph structures and bias information crucial for the fair evaluation of models. The proposed synthetic and semi-synthetic datasets offer the flexibility to create data with controllable bias parameters, thereby enabling the generation of desired datasets with user-defined bias values with ease. Moreover, we conduct systematic evaluations of these proposed datasets and establish a unified evaluation approach for fair graph learning models. Our extensive experimental results with fair graph learning methods across our datasets demonstrate their effectiveness in benchmarking the performance of these methods. Our datasets and the code for reproducing our experiments are available at https://github.com/XweiQ/Benchmark-GraphFairness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06026",
        "abstract url": "https://arxiv.org/abs/2403.06026",
        "title": "Towards a Generic Representation of Combinatorial Problems for Learning-Based Approaches",
        "rating": -0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, there has been a growing interest in using learning-based approaches for solving combinatorial problems, either in an end-to-end manner or in conjunction with traditional optimization algorithms. In both scenarios, the challenge lies in encoding the targeted combinatorial problems into a structure compatible with the learning algorithm. Many existing works have proposed problem-specific representations, often in the form of a graph, to leverage the advantages of \\textit{graph neural networks}. However, these approaches lack generality, as the representation cannot be easily transferred from one combinatorial problem to another one. While some attempts have been made to bridge this gap, they still offer a partial generality only. In response to this challenge, this paper advocates for progress toward a fully generic representation of combinatorial problems for learning-based approaches. The approach we propose involves constructing a graph by breaking down any constraint of a combinatorial problem into an abstract syntax tree and expressing relationships (e.g., a variable involved in a constraint) through the edges. Furthermore, we introduce a graph neural network architecture capable of efficiently learning from this representation. The tool provided operates on combinatorial problems expressed in the XCSP3 format, handling all the constraints available in the 2023 mini-track competition. Experimental results on four combinatorial problems demonstrate that our architecture achieves performance comparable to dedicated architectures while maintaining generality. Our code and trained models are publicly available at \\url{https://github.com/corail-research/learning-generic-csp}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06064",
        "abstract url": "https://arxiv.org/abs/2403.06064",
        "title": "L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Linear Graph Convolutional Networks (GCNs) are used to classify the node in the graph data. However, we note that most existing linear GCN models perform neural network operations in Euclidean space, which do not explicitly capture the tree-like hierarchical structure exhibited in real-world datasets that modeled as graphs. In this paper, we attempt to introduce hyperbolic space into linear GCN and propose a novel framework for Lorentzian linear GCN. Specifically, we map the learned features of graph nodes into hyperbolic space, and then perform a Lorentzian linear feature transformation to capture the underlying tree-like structure of data. Experimental results on standard citation networks datasets with semi-supervised learning show that our approach yields new state-of-the-art results of accuracy 74.7$\\%$ on Citeseer and 81.3$\\%$ on PubMed datasets. Furthermore, we observe that our approach can be trained up to two orders of magnitude faster than other nonlinear GCN models on PubMed dataset. Our code is publicly available at https://github.com/llqy123/LLGC-master.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by LREC-COLING 2024"
    },
    {
        "paper id": "2403.06079",
        "abstract url": "https://arxiv.org/abs/2403.06079",
        "title": "Generalization of Graph Neural Networks through the Lens of Homomorphism",
        "rating": -0.5,
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the celebrated popularity of Graph Neural Networks (GNNs) across numerous applications, the ability of GNNs to generalize remains less explored. In this work, we propose to study the generalization of GNNs through a novel perspective - analyzing the entropy of graph homomorphism. By linking graph homomorphism with information-theoretic measures, we derive generalization bounds for both graph and node classifications. These bounds are capable of capturing subtleties inherent in various graph structures, including but not limited to paths, cycles and cliques. This enables a data-dependent generalization analysis with robust theoretical guarantees. To shed light on the generality of of our proposed bounds, we present a unifying framework that can characterize a broad spectrum of GNN models through the lens of graph homomorphism. We validate the practical applicability of our theoretical findings by showing the alignment between the proposed bounds and the empirically observed generalization gaps over both real-world and synthetic datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 3 figures"
    },
    {
        "paper id": "2403.06092",
        "abstract url": "https://arxiv.org/abs/2403.06092",
        "title": "Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View Synthesis?",
        "rating": -0.5,
        "keywords": [
            [
                "NeRF"
            ],
            [
                "Synthesis"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Neural Radiance Field (NeRF) has achieved superior performance for novel view synthesis by modeling the scene with a Multi-Layer Perception (MLP) and a volume rendering procedure, however, when fewer known views are given (i.e., few-shot view synthesis), the model is prone to overfit the given views. To handle this issue, previous efforts have been made towards leveraging learned priors or introducing additional regularizations. In contrast, in this paper, we for the first time provide an orthogonal method from the perspective of network structure. Given the observation that trivially reducing the number of model parameters alleviates the overfitting issue, but at the cost of missing details, we propose the multi-input MLP (mi-MLP) that incorporates the inputs (i.e., location and viewing direction) of the vanilla MLP into each layer to prevent the overfitting issue without harming detailed synthesis. To further reduce the artifacts, we propose to model colors and volume density separately and present two regularization terms. Extensive experiments on multiple datasets demonstrate that: 1) although the proposed mi-MLP is easy to implement, it is surprisingly effective as it boosts the PSNR of the baseline from $14.73$ to $24.23$. 2) the overall framework achieves state-of-the-art results on a wide range of benchmarks. We will release the code upon publication.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2403.05794",
        "abstract url": "https://arxiv.org/abs/2403.05794",
        "title": "Privacy-Preserving Diffusion Model Using Homomorphic Encryption",
        "rating": -1,
        "keywords": [
            [
                "Diffusion"
            ]
        ],
        "abstract": "In this paper, we introduce a privacy-preserving stable diffusion framework leveraging homomorphic encryption, called HE-Diffusion, which primarily focuses on protecting the denoising phase of the diffusion process. HE-Diffusion is a tailored encryption framework specifically designed to align with the unique architecture of stable diffusion, ensuring both privacy and functionality. To address the inherent computational challenges, we propose a novel min-distortion method that enables efficient partial image encryption, significantly reducing the overhead without compromising the model's output quality. Furthermore, we adopt a sparse tensor representation to expedite computational operations, enhancing the overall efficiency of the privacy-preserving diffusion process. We successfully implement HE-based privacy-preserving stable diffusion inference. The experimental results show that HE-Diffusion achieves 500 times speedup compared with the baseline method, and reduces time cost of the homomorphically encrypted inference to the minute level. Both the performance and accuracy of the HE-Diffusion are on par with the plaintext counterpart. Our approach marks a significant step towards integrating advanced cryptographic techniques with state-of-the-art generative models, paving the way for privacy-preserving and efficient image generation in critical applications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05795",
        "abstract url": "https://arxiv.org/abs/2403.05795",
        "title": "ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "healthcare",
                "Clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The advancement of natural language processing (NLP) systems in healthcare hinges on language model ability to interpret the intricate information contained within clinical notes. This process often requires integrating information from various time points in a patient's medical history. However, most earlier clinical language models were pretrained with a context length limited to roughly one clinical document. In this study, We introduce ClinicalMamba, a specialized version of the Mamba language model, pretrained on a vast corpus of longitudinal clinical notes to address the unique linguistic characteristics and information processing needs of the medical domain. ClinicalMamba, with 130 million and 2.8 billion parameters, demonstrates a superior performance in modeling clinical language across extended text lengths compared to Mamba and clinical Llama. With few-shot learning, ClinicalMamba achieves notable benchmarks in speed and accuracy, outperforming existing clinical language models and general domain large models like GPT-4 in longitudinal clinical notes information extraction tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05796",
        "abstract url": "https://arxiv.org/abs/2403.05796",
        "title": "Weakly Supervised Change Detection via Knowledge Distillation and Multiscale Sigmoid Inference",
        "rating": -1,
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Change detection, which aims to detect spatial changes from a pair of multi-temporal images due to natural or man-made causes, has been widely applied in remote sensing, disaster management, urban management, etc. Most existing change detection approaches, however, are fully supervised and require labor-intensive pixel-level labels. To address this, we develop a novel weakly supervised change detection technique via Knowledge Distillation and Multiscale Sigmoid Inference (KD-MSI) that leverages image-level labels. In our approach, the Class Activation Maps (CAM) are utilized not only to derive a change probability map but also to serve as a foundation for the knowledge distillation process. This is done through a joint training strategy of the teacher and student networks, enabling the student network to highlight potential change areas more accurately than teacher network based on image-level labels. Moreover, we designed a Multiscale Sigmoid Inference (MSI) module as a post processing step to further refine the change probability map from the trained student network. Empirical results on three public datasets, i.e., WHU-CD, DSIFN-CD, and LEVIR-CD, demonstrate that our proposed technique, with its integrated training strategy, significantly outperforms the state-of-the-art.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "code is available: https://github.com/BinghaoLu/KD-MSI"
    },
    {
        "paper id": "2403.05808",
        "abstract url": "https://arxiv.org/abs/2403.05808",
        "title": "Adaptive Multi-modal Fusion of Spatially Variant Kernel Refinement with Diffusion Model for Blind Image Super-Resolution",
        "rating": -1,
        "keywords": [
            [
                "Depth"
            ],
            [
                "Diffusion",
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Pre-trained diffusion models utilized for image generation encapsulate a substantial reservoir of a priori knowledge pertaining to intricate textures. Harnessing the potential of leveraging this a priori knowledge in the context of image super-resolution presents a compelling avenue. Nonetheless, prevailing diffusion-based methodologies presently overlook the constraints imposed by degradation information on the diffusion process. Furthermore, these methods fail to consider the spatial variability inherent in the estimated blur kernel, stemming from factors such as motion jitter and out-of-focus elements in open-environment scenarios. This oversight results in a notable deviation of the image super-resolution effect from fundamental realities. To address these concerns, we introduce a framework known as Adaptive Multi-modal Fusion of \\textbf{S}patially Variant Kernel Refinement with Diffusion Model for Blind Image \\textbf{S}uper-\\textbf{R}esolution (SSR). Within the SSR framework, we propose a Spatially Variant Kernel Refinement (SVKR) module. SVKR estimates a Depth-Informed Kernel, which takes the depth information into account and is spatially variant. Additionally, SVKR enhance the accuracy of depth information acquired from LR images, allowing for mutual enhancement between the depth map and blur kernel estimates. Finally, we introduce the Adaptive Multi-Modal Fusion (AMF) module to align the information from three modalities: low-resolution images, depth maps, and blur kernels. This alignment can constrain the diffusion model to generate more authentic SR results. Quantitative and qualitative experiments affirm the superiority of our approach, while ablation experiments corroborate the effectiveness of the modules we have proposed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05810",
        "abstract url": "https://arxiv.org/abs/2403.05810",
        "title": "Recurrent Aligned Network for Generalized Pedestrian Trajectory Prediction",
        "rating": -1,
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Pedestrian trajectory prediction is a crucial component in computer vision and robotics, but remains challenging due to the domain shift problem. Previous studies have tried to tackle this problem by leveraging a portion of the trajectory data from the target domain to adapt the model. However, such domain adaptation methods are impractical in real-world scenarios, as it is infeasible to collect trajectory data from all potential target domains. In this paper, we study a task named generalized pedestrian trajectory prediction, with the aim of generalizing the model to unseen domains without accessing their trajectories. To tackle this task, we introduce a Recurrent Aligned Network~(RAN) to minimize the domain gap through domain alignment. Specifically, we devise a recurrent alignment module to effectively align the trajectory feature spaces at both time-state and time-sequence levels by the recurrent alignment strategy.Furthermore, we introduce a pre-aligned representation module to combine social interactions with the recurrent alignment strategy, which aims to consider social interactions during the alignment process instead of just target trajectories. We extensively evaluate our method and compare it with state-of-the-art methods on three widely used benchmarks. The experimental results demonstrate the superior generalization capability of our method. Our work not only fills the gap in the generalization setting for practical pedestrian trajectory prediction but also sets strong baselines in this field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05815",
        "abstract url": "https://arxiv.org/abs/2403.05815",
        "title": "N-QR: Natural Quick Response Codes for Multi-Robot Instance Correspondence",
        "rating": -1,
        "keywords": [
            [
                "robotics",
                "Robot"
            ]
        ],
        "abstract": "Image correspondence serves as the backbone for many tasks in robotics, such as visual fusion, localization, and mapping. However, existing correspondence methods do not scale to large multi-robot systems, and they struggle when image features are weak, ambiguous, or evolving. In response, we propose Natural Quick Response codes, or N-QR, which enables rapid and reliable correspondence between large-scale teams of heterogeneous robots. Our method works like a QR code, using keypoint-based alignment, rapid encoding, and error correction via ensembles of image patches of natural patterns. We deploy our algorithm in a production-scale robotic farm, where groups of growing plants must be matched across many robots. We demonstrate superior performance compared to several baselines, obtaining a retrieval accuracy of 88.2%. Our method generalizes to a farm with 100 robots, achieving a 12.5x reduction in bandwidth and a 20.5x speedup. We leverage our method to correspond 700k plants and confirm a link between a robotic seeding policy and germination.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "IEEE International Conference on Robotics and Automation (ICRA), 2024"
    },
    {
        "paper id": "2403.05838",
        "abstract url": "https://arxiv.org/abs/2403.05838",
        "title": "LEO- and RIS-Empowered User Tracking: A Riemannian Manifold Approach",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Low Earth orbit (LEO) satellites and reconfigurable intelligent surfaces (RISs) have recently drawn significant attention as two transformative technologies, and the synergy between them emerges as a promising paradigm for providing cross-environment communication and positioning services. This paper investigates an integrated terrestrial and non-terrestrial wireless network that leverages LEO satellites and RISs to achieve simultaneous tracking of the 3D position, 3D velocity, and 3D orientation of user equipment (UE). To address inherent challenges including nonlinear observation function, constrained UE state, and unknown observation statistics, we develop a Riemannian manifold-based unscented Kalman filter (UKF) method. This method propagates statistics over nonlinear functions using generated sigma points and maintains state constraints through projection onto the defined manifold space. Additionally, by employing Fisher information matrices (FIMs) of the sigma points, a belief assignment principle is proposed to approximate the unknown observation covariance matrix, thereby ensuring accurate measurement updates in the UKF procedure. Numerical results demonstrate a substantial enhancement in tracking accuracy facilitated by RIS integration, despite urban signal reception challenges from LEO satellites. In addition, extensive simulations underscore the superior performance of the proposed tracking method and FIM-based belief assignment over the adopted benchmarks. Furthermore, the robustness of the proposed UKF is verified across various uncertainty levels.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05858",
        "abstract url": "https://arxiv.org/abs/2403.05858",
        "title": "On constructive extractability of measurable selectors of set-valued maps",
        "rating": -1,
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper investigates the possibility of constructive extraction of measurable selector from set-valued maps which may commonly arise in viability theory, optimal control, discontinuous systems etc. For instance, existence of solutions to certain differential inclusions, often requires iterative extraction of measurable selectors. Next, optimal controls are in general non-unique which naturally leads to an optimal set-valued function. Finally, a viable control law can be seen, in general, as a selector. It is known that selector theorems are non-constructive and so selectors cannot always be extracted. In this work, we analyze under which particular conditions selectors are constructively extractable. An algorithm is derived from the theorem and applied in a computational study with a three-wheel robot model.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Published in IEEE Transactions on Automatic Control"
    },
    {
        "paper id": "2403.05895",
        "abstract url": "https://arxiv.org/abs/2403.05895",
        "title": "DO3D: Self-supervised Learning of Decomposed Object-aware 3D Motion and Depth from Monocular Videos",
        "rating": -1,
        "keywords": [
            [
                "3D",
                "6-DoF",
                "Depth"
            ],
            [
                "synthesize"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Although considerable advancements have been attained in self-supervised depth estimation from monocular videos, most existing methods often treat all objects in a video as static entities, which however violates the dynamic nature of real-world scenes and fails to model the geometry and motion of moving objects. In this paper, we propose a self-supervised method to jointly learn 3D motion and depth from monocular videos. Our system contains a depth estimation module to predict depth, and a new decomposed object-wise 3D motion (DO3D) estimation module to predict ego-motion and 3D object motion. Depth and motion networks work collaboratively to faithfully model the geometry and dynamics of real-world scenes, which, in turn, benefits both depth and 3D motion estimation. Their predictions are further combined to synthesize a novel video frame for self-supervised training. As a core component of our framework, DO3D is a new motion disentanglement module that learns to predict camera ego-motion and instance-aware 3D object motion separately. To alleviate the difficulties in estimating non-rigid 3D object motions, they are decomposed to object-wise 6-DoF global transformations and a pixel-wise local 3D motion deformation field. Qualitative and quantitative experiments are conducted on three benchmark datasets, including KITTI, Cityscapes, and VKITTI2, where our model delivers superior performance in all evaluated settings. For the depth estimation task, our model outperforms all compared research works in the high-resolution setting, attaining an absolute relative depth error (abs rel) of 0.099 on the KITTI benchmark. Besides, our optical flow estimation results (an overall EPE of 7.09 on KITTI) also surpass state-of-the-art methods and largely improve the estimation of dynamic regions, demonstrating the effectiveness of our motion model. Our code will be available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "24 pages, 14 figures, Tech Report"
    },
    {
        "paper id": "2403.05896",
        "abstract url": "https://arxiv.org/abs/2403.05896",
        "title": "Fast Kernel Scene Flow",
        "rating": -1,
        "keywords": [
            [
                "autonomous driving",
                "lidar"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In contrast to current state-of-the-art methods, such as NSFP [25], which employ deep implicit neural functions for modeling scene flow, we present a novel approach that utilizes classical kernel representations. This representation enables our approach to effectively handle dense lidar points while demonstrating exceptional computational efficiency -- compared to recent deep approaches -- achieved through the solution of a linear system. As a runtime optimization-based method, our model exhibits impressive generalizability across various out-of-distribution scenarios, achieving competitive performance on large-scale lidar datasets. We propose a new positional encoding-based kernel that demonstrates state-of-the-art performance in efficient lidar scene flow estimation on large-scale point clouds. An important highlight of our method is its near real-time performance (~150-170 ms) with dense lidar data (~8k-144k points), enabling a variety of practical applications in robotics and autonomous driving scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages, 8 figures, 3 tables"
    },
    {
        "paper id": "2403.05902",
        "abstract url": "https://arxiv.org/abs/2403.05902",
        "title": "MaiBaam Annotation Guidelines",
        "rating": -1,
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This document provides the annotation guidelines for MaiBaam, a Bavarian corpus annotated with part-of-speech (POS) tags and syntactic dependencies. MaiBaam belongs to the Universal Dependencies (UD) project, and our annotations elaborate on the general and German UD version 2 guidelines. In this document, we detail how to preprocess and tokenize Bavarian data, provide an overview of the POS tags and dependencies we use, explain annotation decisions that would also apply to closely related languages like German, and lastly we introduce and motivate decisions that are specific to Bavarian grammar.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05906",
        "abstract url": "https://arxiv.org/abs/2403.05906",
        "title": "Segmentation Guided Sparse Transformer for Under-Display Camera Image Restoration",
        "rating": -1,
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Under-Display Camera (UDC) is an emerging technology that achieves full-screen display via hiding the camera under the display panel. However, the current implementation of UDC causes serious degradation. The incident light required for camera imaging undergoes attenuation and diffraction when passing through the display panel, leading to various artifacts in UDC imaging. Presently, the prevailing UDC image restoration methods predominantly utilize convolutional neural network architectures, whereas Transformer-based methods have exhibited superior performance in the majority of image restoration tasks. This is attributed to the Transformer's capability to sample global features for the local reconstruction of images, thereby achieving high-quality image restoration. In this paper, we observe that when using the Vision Transformer for UDC degraded image restoration, the global attention samples a large amount of redundant information and noise. Furthermore, compared to the ordinary Transformer employing dense attention, the Transformer utilizing sparse attention can alleviate the adverse impact of redundant information and noise. Building upon this discovery, we propose a Segmentation Guided Sparse Transformer method (SGSFormer) for the task of restoring high-quality images from UDC degraded images. Specifically, we utilize sparse self-attention to filter out redundant information and noise, directing the model's attention to focus on the features more relevant to the degraded regions in need of reconstruction. Moreover, we integrate the instance segmentation map as prior information to guide the sparse self-attention in filtering and focusing on the correct regions.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "13 pages, 10 figures, conference or other essential info"
    },
    {
        "paper id": "2403.05916",
        "abstract url": "https://arxiv.org/abs/2403.05916",
        "title": "GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing",
        "rating": -1,
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal large language models (MLLMs) are designed to process and integrate information from multiple sources, such as text, speech, images, and videos. Despite its success in language understanding, it is critical to evaluate the performance of downstream tasks for better human-centric applications. This paper assesses the application of MLLMs with 5 crucial abilities for affective computing, spanning from visual affective tasks and reasoning tasks. The results show that \\gpt has high accuracy in facial action unit recognition and micro-expression detection while its general facial expression recognition performance is not accurate. We also highlight the challenges of achieving fine-grained micro-expression recognition and the potential for further study and demonstrate the versatility and potential of \\gpt for handling advanced tasks in emotion recognition and related fields by integrating with task-related agents for more complex tasks, such as heart rate estimation through signal processing. In conclusion, this paper provides valuable insights into the potential applications and challenges of MLLMs in human-centric computing. Our interesting examples are at https://github.com/EnVision-Research/GPT4Affectivity.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05920",
        "abstract url": "https://arxiv.org/abs/2403.05920",
        "title": "High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models",
        "rating": -1,
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Deep phenotyping is the detailed description of patient signs and symptoms using concepts from an ontology. The deep phenotyping of the numerous physician notes in electronic health records requires high throughput methods. Over the past thirty years, progress toward making high throughput phenotyping feasible. In this study, we demonstrate that a large language model and a hybrid NLP model (combining word vectors with a machine learning classifier) can perform high throughput phenotyping on physician notes with high accuracy. Large language models will likely emerge as the preferred method for high throughput deep phenotyping of physician notes.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Submitted to IEEE EMBS Summer conference 2024"
    },
    {
        "paper id": "2403.05930",
        "abstract url": "https://arxiv.org/abs/2403.05930",
        "title": "Deep learning for multi-label classification of coral conditions in the Indo-Pacific via underwater photogrammetry",
        "rating": -1,
        "keywords": [
            [
                "health",
                "disease",
                "face"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Since coral reef ecosystems face threats from human activities and climate change, coral conservation programs are implemented worldwide. Monitoring coral health provides references for guiding conservation activities. However, current labor-intensive methods result in a backlog of unsorted images, highlighting the need for automated classification. Few studies have simultaneously utilized accurate annotations along with updated algorithms and datasets. This study aimed to create a dataset representing common coral conditions and associated stressors in the Indo-Pacific. Concurrently, it assessed existing classification algorithms and proposed a new multi-label method for automatically detecting coral conditions and extracting ecological information. A dataset containing over 20,000 high-resolution coral images of different health conditions and stressors was constructed based on the field survey. Seven representative deep learning architectures were tested on this dataset, and their performance was quantitatively evaluated using the F1 metric and the match ratio. Based on this evaluation, a new method utilizing the ensemble learning approach was proposed. The proposed method accurately classified coral conditions as healthy, compromised, dead, and rubble; it also identified corresponding stressors, including competition, disease, predation, and physical issues. This method can help develop the coral image archive, guide conservation activities, and provide references for decision-making for reef managers and conservationists. The proposed ensemble learning approach outperforms others on the dataset, showing State-Of-The-Art (SOTA) performance. Future research should improve its generalizability and accuracy to support global coral conservation efforts.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05943",
        "abstract url": "https://arxiv.org/abs/2403.05943",
        "title": "Hamiltonicity, Path Cover, and Independence Number: An FPT Perspective",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "The connection between Hamiltonicity and the independence numbers of graphs has been a fundamental aspect of Graph Theory since the seminal works of the 1960s. This paper presents a novel algorithmic perspective on these classical problems. Our contributions are twofold. First, we establish that a wide array of problems in undirected graphs, encompassing problems such as Hamiltonian Path and Cycle, Path Cover, Largest Linkage, and Topological Minor Containment are fixed-parameter tractable (FPT) parameterized by the independence number of a graph. To the best of our knowledge, these results mark the first instances of FPT problems for such parameterization. Second, we extend the algorithmic scope of the Gallai-Milgram theorem. The original theorem by Gallai and Milgram, asserts that for a graph G with the independence number \u03b1(G), the vertex set of G can be covered by at most \u03b1(G) vertex-disjoint paths. We show that determining whether a graph can be covered by fewer than \u03b1(G) - k vertex-disjoint paths is FPT parameterized by k. Notably, the independence number parameterization, which describes graph's density, departs from the typical flow of research in parameterized complexity, which focuses on parameters describing graph's sparsity, like treewidth or vertex cover.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05949",
        "abstract url": "https://arxiv.org/abs/2403.05949",
        "title": "General surgery vision transformer: A video pre-trained foundation model for general surgery",
        "rating": -1,
        "keywords": [
            [
                "surgical",
                "surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The absence of openly accessible data and specialized foundation models is a major barrier for computational research in surgery. Toward this, (i) we open-source the largest dataset of general surgery videos to-date, consisting of 680 hours of surgical videos, including data from robotic and laparoscopic techniques across 28 procedures; (ii) we propose a technique for video pre-training a general surgery vision transformer (GSViT) on surgical videos based on forward video prediction that can run in real-time for surgical applications, toward which we open-source the code and weights of GSViT; (iii) we also release code and weights for procedure-specific fine-tuned versions of GSViT across 10 procedures; (iv) we demonstrate the performance of GSViT on the Cholec80 phase annotation task, displaying improved performance over state-of-the-art single frame predictors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05950",
        "abstract url": "https://arxiv.org/abs/2403.05950",
        "title": "Classifying Objects in 3D Point Clouds Using Recurrent Neural Network: A GRU LSTM Hybrid Approach",
        "rating": -1,
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate classification of objects in 3D point clouds is a significant problem in several applications, such as autonomous navigation and augmented/virtual reality scenarios, which has become a research hot spot. In this paper, we presented a deep learning strategy for 3D object classification in augmented reality. The proposed approach is a combination of the GRU and LSTM. LSTM networks learn longer dependencies well, but due to the number of gates, it takes longer to train; on the other hand, GRU networks have a weaker performance than LSTM, but their training speed is much higher than GRU, which is The speed is due to its fewer gates. The proposed approach used the combination of speed and accuracy of these two networks. The proposed approach achieved an accuracy of 0.99 in the 4,499,0641 points dataset, which includes eight classes (unlabeled, man-made terrain, natural terrain, high vegetation, low vegetation, buildings, hardscape, scanning artifacts, cars). Meanwhile, the traditional machine learning approaches could achieve a maximum accuracy of 0.9489 in the best case. Keywords: Point Cloud Classification, Virtual Reality, Hybrid Model, GRULSTM, GRU, LSTM",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05962",
        "abstract url": "https://arxiv.org/abs/2403.05962",
        "title": "Multi-Robot Communication-Aware Cooperative Belief Space Planning with Inconsistent Beliefs: An Action-Consistent Approach",
        "rating": -1,
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Multi-robot belief space planning (MR-BSP) is essential for reliable and safe autonomy. While planning, each robot maintains a belief over the state of the environment and reasons how the belief would evolve in the future for different candidate actions. Yet, existing MR-BSP works have a common assumption that the beliefs of different robots are consistent at planning time. Such an assumption is often highly unrealistic, as it requires prohibitively extensive and frequent communication capabilities. In practice, each robot may have a different belief about the state of the environment. Crucially, when the beliefs of different robots are inconsistent, state-of-the-art MR-BSP approaches could result in a lack of coordination between the robots, and in general, could yield dangerous, unsafe and sub-optimal decisions. In this paper, we tackle this crucial gap. We develop a novel decentralized algorithm that is guaranteed to find a consistent joint action. For a given robot, our algorithm reasons for action preferences about 1) its local information, 2) what it perceives about the reasoning of the other robot, and 3) what it perceives about the reasoning of itself perceived by the other robot. This algorithm finds a consistent joint action whenever these steps yield the same best joint action obtained by reasoning about action preferences; otherwise, it self-triggers communication between the robots. Experimental results show efficacy of our algorithm in comparison with two baseline algorithms.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05970",
        "abstract url": "https://arxiv.org/abs/2403.05970",
        "title": "Electromagnetic Hybrid Beamforming for Holographic Communications",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "It is well known that there is inherent radiation pattern distortion for the commercial base station antenna array, which usually needs three antenna sectors to cover the whole space. To eliminate pattern distortion and further enhance beamforming performance, we propose an electromagnetic hybrid beamforming (EHB) scheme based on a three-dimensional (3D) superdirective holographic antenna array. Specifically, EHB consists of antenna excitation current vectors (analog beamforming) and digital precoding matrices, where the implementation of analog beamforming involves the real-time adjustment of the radiation pattern to adapt it to the dynamic wireless environment. Meanwhile, the digital beamforming is optimized based on the channel characteristics of analog beamforming to further improve the achievable rate of communication systems. An electromagnetic channel model incorporating array radiation patterns and the mutual coupling effect is also developed to evaluate the benefits of our proposed scheme. Simulation results demonstrate that our proposed EHB scheme with a 3D holographic array achieves a relatively flat superdirective beamforming gain and allows for programmable focusing directions throughout the entire spatial domain. Furthermore, they also verify that the proposed scheme achieves a sum rate gain of over 150% compared to traditional beamforming algorithms.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2403.05977",
        "abstract url": "https://arxiv.org/abs/2403.05977",
        "title": "An Event-Based Approach for the Conservative Compression of Covariance Matrices",
        "rating": -1,
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "This work introduces a flexible and versatile method for the data-efficient yet conservative transmission of covariance matrices, where a matrix element is only transmitted if a so-called triggering condition is satisfied for the element. Here, triggering conditions can be parametrized on a per-element basis, applied simultaneously to yield combined triggering conditions or applied only to certain subsets of elements. This allows, e.g., to specify transmission accuracies for individual elements or to constrain the bandwidth available for the transmission of subsets of elements. Additionally, a methodology for learning triggering condition parameters from an application-specific dataset is presented. The performance of the proposed approach is quantitatively assessed in terms of data reduction and conservativeness using estimate data derived from real-world vehicle trajectories from the InD-dataset, demonstrating substantial data reduction ratios with minimal over-conservativeness. The feasibility of learning triggering condition parameters is demonstrated.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "12 pages, 9 figures, submitted to: IEEE Transactions on Automatic Control"
    },
    {
        "paper id": "2403.05991",
        "abstract url": "https://arxiv.org/abs/2403.05991",
        "title": "Fault Classification in Electrical Distribution Systems using Grassmann Manifold",
        "rating": -1,
        "keywords": [
            [
                "support vector machine"
            ]
        ],
        "abstract": "Electrical fault classification is vital for ensuring the reliability and safety of power systems. Accurate and efficient fault classification methods are essential for timely and effective maintenance. In this paper, we propose a novel approach for effective fault classification through Grassmann manifolds, which is a non-Euclidean space that captures the intrinsic structure of high-dimensional data and offers a robust framework for feature extraction. We use simulated data for electrical distribution systems with various types of electrical faults. The proposed method involves transforming the measurement fault data into Grassmann manifold space using techniques from differential geometry. This transformation aids in uncovering the underlying fault patterns and reducing the computational complexity of subsequent classification steps. To achieve fault classification, we employ a machine learning technique optimized for the Grassmann manifold. The support vector machine classifier is adapted to operate within the Grassmann manifold space, enabling effective discrimination between different fault classes. The results illustrate the efficacy of the proposed Grassmann manifold-based approach for electrical fault classification which showcases its ability to accurately differentiate between various fault types.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06024",
        "abstract url": "https://arxiv.org/abs/2403.06024",
        "title": "Semi-Supervised Multimodal Multi-Instance Learning for Aortic Stenosis Diagnosis",
        "rating": -1,
        "keywords": [
            [
                "Diagnosis",
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automated interpretation of ultrasound imaging of the heart (echocardiograms) could improve the detection and treatment of aortic stenosis (AS), a deadly heart disease. However, existing deep learning pipelines for assessing AS from echocardiograms have two key limitations. First, most methods rely on limited 2D cineloops, thereby ignoring widely available Doppler imaging that contains important complementary information about pressure gradients and blood flow abnormalities associated with AS. Second, obtaining labeled data is difficult. There are often far more unlabeled echocardiogram recordings available, but these remain underutilized by existing methods. To overcome these limitations, we introduce Semi-supervised Multimodal Multiple-Instance Learning (SMMIL), a new deep learning framework for automatic interpretation for structural heart diseases like AS. When deployed, SMMIL can combine information from two input modalities, spectral Dopplers and 2D cineloops, to produce a study-level AS diagnosis. During training, SMMIL can combine a smaller labeled set and an abundant unlabeled set of both modalities to improve its classifier. Experiments demonstrate that SMMIL outperforms recent alternatives at 3-level AS severity classification as well as several clinically relevant AS detection tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Echocardiography; Multimodal; Semi-supervised Learning; Multiple-Instance Learning"
    },
    {
        "paper id": "2403.06025",
        "abstract url": "https://arxiv.org/abs/2403.06025",
        "title": "CarbonNet: How Computer Vision Plays a Role in Climate Change? Application: Learning Geomechanics from Subsurface Geometry of CCS to Mitigate Global Warming",
        "rating": -1,
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a new approach using computer vision to predict the land surface displacement from subsurface geometry images for Carbon Capture and Sequestration (CCS). CCS has been proved to be a key component for a carbon neutral society. However, scientists see there are challenges along the way including the high computational cost due to the large model scale and limitations to generalize a pre-trained model with complex physics. We tackle those challenges by training models directly from the subsurface geometry images. The goal is to understand the respons of land surface displacement due to carbon injection and utilize our trained models to inform decision making in CCS projects. We implement multiple models (CNN, ResNet, and ResNetUNet) for static mechanics problem, which is a image prediction problem. Next, we use the LSTM and transformer for transient mechanics scenario, which is a video prediction problem. It shows ResNetUNet outperforms the others thanks to its architecture in static mechanics problem, and LSTM shows comparable performance to transformer in transient problem. This report proceeds by outlining our dataset in detail followed by model descriptions in method section. Result and discussion state the key learning, observations, and conclusion with future work rounds out the paper.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06090",
        "abstract url": "https://arxiv.org/abs/2403.06090",
        "title": "Diffusion Models Trained with Large Data Are Transferable Visual Models",
        "rating": -1,
        "keywords": [
            [
                "depth"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We show that, simply initializing image understanding models using a pre-trained UNet (or transformer) of diffusion models, it is possible to achieve remarkable transferable performance on fundamental vision perception tasks using a moderate amount of target data (even synthetic data only), including monocular depth, surface normal, image segmentation, matting, human pose estimation, among virtually many others. Previous works have adapted diffusion models for various perception tasks, often reformulating these tasks as generation processes to align with the diffusion process. In sharp contrast, we demonstrate that fine-tuning these models with minimal adjustments can be a more effective alternative, offering the advantages of being embarrassingly simple and significantly faster. As the backbone network of Stable Diffusion models is trained on giant datasets comprising billions of images, we observe very robust generalization capabilities of the diffusion backbone. Experimental results showcase the remarkable transferability of the backbone of diffusion models across diverse tasks and real-world datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06091",
        "abstract url": "https://arxiv.org/abs/2403.06091",
        "title": "Fish-inspired tracking of underwater turbulent plumes",
        "rating": -1,
        "keywords": [
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "Autonomous ocean-exploring vehicles have begun to take advantage of onboard sensor measurements of water properties such as salinity and temperature to locate oceanic features in real time. Such targeted sampling strategies enable more rapid study of ocean environments by actively steering towards areas of high scientific value. Inspired by the ability of aquatic animals to navigate via flow sensing, this work investigates hydrodynamic cues for accomplishing targeted sampling using a palm-sized robotic swimmer. As proof-of-concept analogy for tracking hydrothermal vent plumes in the ocean, the robot is tasked with locating the center of turbulent jet flows in a 13,000-liter water tank using data from onboard pressure sensors. To learn a navigation strategy, we first implemented Reinforcement Learning (RL) on a simulated version of the robot navigating in proximity to turbulent jets. After training, the RL algorithm discovered an effective strategy for locating the jets by following transverse velocity gradients sensed by pressure sensors located on opposite sides of the robot. When implemented on the physical robot, this gradient following strategy enabled the robot to successfully locate the turbulent plumes at more than twice the rate of random searching. Additionally, we found that navigation performance improved as the distance between the pressure sensors increased, which can inform the design of distributed flow sensors in ocean robots. Our results demonstrate the effectiveness and limits of flow-based navigation for autonomously locating hydrodynamic features of interest.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06094",
        "abstract url": "https://arxiv.org/abs/2403.06094",
        "title": "SecureRights: A Blockchain-Powered Trusted DRM Framework for Robust Protection and Asserting Digital Rights",
        "rating": -1,
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In the dynamic realm of digital content, safeguarding intellectual property rights poses critical challenges. This paper presents \"SecureRights,\" an innovative Blockchain-based Trusted Digital Rights Management (DRM) framework. It strengthens the defence against unauthorized use and streamlines the claim of digital rights. Utilizing blockchain, digital watermarking, perceptual hashing, Quick Response (QR) codes, and the Interplanetary File System (IPFS), SecureRights securely stores watermark information on the blockchain with timestamp authentication. Incorporating perceptual hashing generates robust hash tokens based on image structure. The addition of QR codes enhances the watermarking, offering a comprehensive solution for resilient intellectual property rights protection. Rigorous evaluations affirm SecureRights' resilience against various attacks, establishing its efficacy in safeguarding digital content and simplifying rightful ownership assertion.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.07011",
        "abstract url": "https://arxiv.org/abs/2403.07011",
        "title": "Automatic Detection and Classification of Corona Infection (COVID-19) from X-ray Images Using Convolution Neural Network",
        "rating": -1,
        "keywords": [
            [
                "diagnosis",
                "X-ray",
                "disease"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The novel coronavirus universally known as the COVID-19 outbreak arises at the end of 2019 in one of the East Asian countries and it is subjected to widespread discussion and debate. There are almost 200 countries affected across the globe by COVID-19 and it has ruined many lives and the global economy. The virus is spreading very rapidly at the pace of around 10 fold in less than a month. Also, in the case of COVID- 19 it is critical to detect the infection as it employs various symptoms which may differ from person to person. Hence, diagnosis in starting stage and treatment are very much important for such type of infectious disease. The chest x-ray is one of the primary techniques among blood tests and Computed Tomography contributes a major role in the early diagnosis of COVID-19. There is a rising need for automated and auxiliary diagnostic tools for early diagnosis, as there are no accurate and truthful automated tool kits on hand. In this research study, we have designed a Convolution Neural Network architecture a deep net for the classification of x-ray images of chest among two classes: COVID-19 or Non-COVID- 19 infection. The anticipated model is expected to provide accurate diagnostic results and produced classification accuracy of 99%, 100%, and 100% with 70%-30%,75%-25% and 80%-20% train-test data split respectively, for the binary classification of the x-ray image to be COVID-19 or Non-COVID-19 infection category. We have designed the CNN with optimized parameters with 3 convolution layers and optimized number of filters in each layer.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.07942",
        "abstract url": "https://arxiv.org/abs/2403.07942",
        "title": "Attacking Transformers with Feature Diversity Adversarial Perturbation",
        "rating": -1,
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Understanding the mechanisms behind Vision Transformer (ViT), particularly its vulnerability to adversarial perturba tions, is crucial for addressing challenges in its real-world applications. Existing ViT adversarial attackers rely on la bels to calculate the gradient for perturbation, and exhibit low transferability to other structures and tasks. In this paper, we present a label-free white-box attack approach for ViT-based models that exhibits strong transferability to various black box models, including most ViT variants, CNNs, and MLPs, even for models developed for other modalities. Our inspira tion comes from the feature collapse phenomenon in ViTs, where the critical attention mechanism overly depends on the low-frequency component of features, causing the features in middle-to-end layers to become increasingly similar and eventually collapse. We propose the feature diversity attacker to naturally accelerate this process and achieve remarkable performance and transferability.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.09708",
        "abstract url": "https://arxiv.org/abs/2403.09708",
        "title": "Institutional-Level Monitoring of Immune Checkpoint Inhibitor IrAEs Using a Novel Natural Language Processing Algorithmic Pipeline",
        "rating": -1,
        "keywords": [
            [
                "Medical",
                "survival",
                "cancer",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Background: Immune checkpoint inhibitors (ICIs) have revolutionized cancer treatment but can result in severe immune-related adverse events (IrAEs). Monitoring IrAEs on a large scale is essential for personalized risk profiling and assisting in treatment decisions. Methods: In this study, we conducted an analysis of clinical notes from patients who received ICIs at the Tel Aviv Sourasky Medical Center. By employing a Natural Language Processing algorithmic pipeline, we systematically identified seven common or severe IrAEs. We examined the utilization of corticosteroids, treatment discontinuation rates following IrAEs, and constructed survival curves to visualize the occurrence of adverse events during treatment. Results: Our analysis encompassed 108,280 clinical notes associated with 1,635 patients who had undergone ICI therapy. The detected incidence of IrAEs was consistent with previous reports, exhibiting substantial variation across different ICIs. Treatment with corticosteroids varied depending on the specific IrAE, ranging from 17.3% for thyroiditis to 57.4% for myocarditis. Our algorithm demonstrated high accuracy in identifying IrAEs, as indicated by an area under the curve (AUC) of 0.89 for each suspected note and F1 scores of 0.87 or higher for five out of the seven IrAEs examined at the patient level. Conclusions: This study presents a novel, large-scale monitoring approach utilizing deep neural networks for IrAEs. Our method provides accurate results, enhancing understanding of detrimental consequences experienced by ICI-treated patients. Moreover, it holds potential for monitoring other medications, enabling comprehensive post-marketing surveillance to identify susceptible populations and establish personalized drug safety profiles.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05798",
        "abstract url": "https://arxiv.org/abs/2403.05798",
        "title": "$\\textbf{S}^2$IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting",
        "rating": -1.5,
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, there has been a growing interest in leveraging pre-trained large language models (LLMs) for various time series applications. However, the semantic space of LLMs, established through the pre-training, is still underexplored and may help yield more distinctive and informative representations to facilitate time series forecasting. To this end, we propose Semantic Space Informed Prompt learning with LLM ($S^2$IP-LLM) to align the pre-trained semantic space with time series embeddings space and perform time series forecasting based on learned prompts from the joint space. We first design a tokenization module tailored for cross-modality alignment, which explicitly concatenates patches of decomposed time series components to create embeddings that effectively encode the temporal dynamics. Next, we leverage the pre-trained word token embeddings to derive semantic anchors and align selected anchors with time series embeddings by maximizing the cosine similarity in the joint space. This way, $S^2$IP-LLM can retrieve relevant semantic anchors as prompts to provide strong indicators (context) for time series that exhibit different temporal dynamics. With thorough empirical studies on multiple benchmark datasets, we demonstrate that the proposed $S^2$IP-LLM can achieve superior forecasting performance over state-of-the-art baselines. Furthermore, our ablation studies and visualizations verify the necessity of prompt learning informed by semantic space.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05817",
        "abstract url": "https://arxiv.org/abs/2403.05817",
        "title": "SAFDNet: A Simple and Effective Network for Fully Sparse 3D Object Detection",
        "rating": -1.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "LiDAR-based 3D object detection plays an essential role in autonomous driving. Existing high-performing 3D object detectors usually build dense feature maps in the backbone network and prediction head. However, the computational costs introduced by the dense feature maps grow quadratically as the perception range increases, making these models hard to scale up to long-range detection. Some recent works have attempted to construct fully sparse detectors to solve this issue; nevertheless, the resulting models either rely on a complex multi-stage pipeline or exhibit inferior performance. In this work, we propose SAFDNet, a straightforward yet highly effective architecture, tailored for fully sparse 3D object detection. In SAFDNet, an adaptive feature diffusion strategy is designed to address the center feature missing problem. We conducted extensive experiments on Waymo Open, nuScenes, and Argoverse2 datasets. SAFDNet performed slightly better than the previous SOTA on the first two datasets but much better on the last dataset, which features long-range detection, verifying the efficacy of SAFDNet in scenarios where long-range detection is required. Notably, on Argoverse2, SAFDNet surpassed the previous best hybrid detector HEDNet by 2.6% mAP while being 2.1x faster, and yielded 2.1% mAP gains over the previous best sparse detector FSDv2 while being 1.3x faster. The code will be available at https://github.com/zhanggang001/HEDNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024 (Oral)"
    },
    {
        "paper id": "2403.05818",
        "abstract url": "https://arxiv.org/abs/2403.05818",
        "title": "PR-NET: Leveraging Pathway Refined Network Structures for Prostate Cancer Patient Condition Prediction",
        "rating": -1.5,
        "keywords": [
            [
                "biomarkers",
                "diagnosis",
                "Cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The diagnosis and monitoring of Castrate Resistant Prostate Cancer (CRPC) are crucial for cancer patients, but the current models (such as P-NET) have limitations in terms of parameter count, generalization, and cost. To address the issue, we develop a more accurate and efficient Prostate Cancer patient condition prediction model, named PR-NET. By compressing and optimizing the network structure of P-NET, the model complexity is reduced while maintaining high accuracy and interpretability. The PR-NET demonstrated superior performance in predicting prostate cancer patient outcomes, outshining P-NET and six other traditional models with a significant margin. In our rigorous evaluation, PR-NET not only achieved impressive average AUC and Recall scores of 0.94 and 0.83, respectively, on known data but also maintained robust generalizability on five unknown datasets with a higher average AUC of 0.73 and Recall of 0.72, compared to P-NET's 0.68 and 0.5. PR-NET's efficiency was evidenced by its shorter average training and inference times, and its gene-level analysis revealed 46 key genes, demonstrating its enhanced predictive power and efficiency in identifying critical biomarkers for prostate cancer. Future research can further expand its application domains and optimize the model's performance and reliability.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05820",
        "abstract url": "https://arxiv.org/abs/2403.05820",
        "title": "An Audio-textual Diffusion Model For Converting Speech Signals Into Ultrasound Tongue Imaging Data",
        "rating": -1.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "clinical"
            ],
            [
                "cs.SD"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Acoustic-to-articulatory inversion (AAI) is to convert audio into articulator movements, such as ultrasound tongue imaging (UTI) data. An issue of existing AAI methods is only using the personalized acoustic information to derive the general patterns of tongue motions, and thus the quality of generated UTI data is limited. To address this issue, this paper proposes an audio-textual diffusion model for the UTI data generation task. In this model, the inherent acoustic characteristics of individuals related to the tongue motion details are encoded by using wav2vec 2.0, while the ASR transcriptions related to the universality of tongue motions are encoded by using BERT. UTI data are then generated by using a diffusion module. Experimental results showed that the proposed diffusion model could generate high-quality UTI data with clear tongue contour that is crucial for the linguistic analysis and clinical assessment. The project can be found on the website\\footnote{https://yangyudong2020.github.io/wav2uti/",
        "subjects": [
            "cs.SD"
        ],
        "comment": "ICASSP2024 Accept"
    },
    {
        "paper id": "2403.05822",
        "abstract url": "https://arxiv.org/abs/2403.05822",
        "title": "TrafficGPT: Breaking the Token Barrier for Efficient Long Traffic Analysis and Generation",
        "rating": -1.5,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the years, network traffic analysis and generation have advanced significantly. From traditional statistical methods, the field has progressed to sophisticated deep learning techniques. This progress has improved the ability to detect complex patterns and security threats, as well as to test and optimize network performance. However, obstacles persist, such as the dependence on labeled data for analysis and the difficulty of generating traffic samples that follow realistic patterns. Pre-trained deep neural networks have emerged as powerful tools to resolve these issues, offering improved performance by learning robust data representations from large unlabeled datasets. Despite their benefits, existing pre-trained models face challenges like token length limitation, which restricts their usefulness in comprehensive traffic analysis and realistic traffic generation. To address these challenges, we introduce TrafficGPT, a deep learning model that can tackle complex challenges related to long flow classification and generation tasks. This model uses generative pre-training with the linear attention mechanism, which allows for a substantially increased capacity of up to 12,032 tokens from the previous limit of only 512 tokens. TrafficGPT demonstrates superior performance in classification tasks, reaching state-of-the-art levels. In generation tasks, it closely resembles real traffic flows, with low JS divergence and an F1 score close to 0.5 (representing a random guess) in discriminating generated data. These advancements hold promise for future applications in both traffic flow classification and generation tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05979",
        "abstract url": "https://arxiv.org/abs/2403.05979",
        "title": "Enhancing Classification Performance via Reinforcement Learning for Feature Selection",
        "rating": -1.5,
        "keywords": [
            [
                "Cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Feature selection plays a crucial role in improving predictive accuracy by identifying relevant features while filtering out irrelevant ones. This study investigates the importance of effective feature selection in enhancing the performance of classification models. By employing reinforcement learning (RL) algorithms, specifically Q-learning (QL) and SARSA learning, this paper addresses the feature selection challenge. Using the Breast Cancer Coimbra dataset (BCCDS) and three normalization methods (Min-Max, l1, and l2), the study evaluates the performance of these algorithms. Results show that QL@Min-Max and SARSA@l2 achieve the highest classification accuracies, reaching 87% and 88%, respectively. This highlights the effectiveness of RL-based feature selection methods in optimizing classification tasks, contributing to improved model accuracy and efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2403.06027",
        "abstract url": "https://arxiv.org/abs/2403.06027",
        "title": "Multimodal deep learning approach to predicting neurological recovery from coma after cardiac arrest",
        "rating": -1.5,
        "keywords": [
            [
                "medical",
                "clinical",
                "cardiac"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work showcases our team's (The BEEGees) contributions to the 2023 George B. Moody PhysioNet Challenge. The aim was to predict neurological recovery from coma following cardiac arrest using clinical data and time-series such as multi-channel EEG and ECG signals. Our modelling approach is multimodal, based on two-dimensional spectrogram representations derived from numerous EEG channels, alongside the integration of clinical data and features extracted directly from EEG recordings. Our submitted model achieved a Challenge score of $0.53$ on the hidden test set for predictions made $72$ hours after return of spontaneous circulation. Our study shows the efficacy and limitations of employing transfer learning in medical classification. With regard to prospective implementation, our analysis reveals that the performance of the model is strongly linked to the selection of a decision threshold and exhibits strong variability across data splits.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 figures, 2 tables"
    },
    {
        "paper id": "2403.06033",
        "abstract url": "https://arxiv.org/abs/2403.06033",
        "title": "Predicting Depression and Anxiety: A Multi-Layer Perceptron for Analyzing the Mental Health Impact of COVID-19",
        "rating": -1.5,
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a multi-layer perceptron (MLP) called the COVID-19 Depression and Anxiety Predictor (CoDAP) to predict mental health trends, particularly anxiety and depression, during the COVID-19 pandemic. Our method utilizes a comprehensive dataset, which tracked mental health symptoms weekly over ten weeks during the initial COVID-19 wave (April to June 2020) in a diverse cohort of U.S. adults. This period, characterized by a surge in mental health symptoms and conditions, offers a critical context for our analysis. Our focus was to extract and analyze patterns of anxiety and depression through a unique lens of qualitative individual attributes using CoDAP. This model not only predicts patterns of anxiety and depression during the pandemic but also unveils key insights into the interplay of demographic factors, behavioral changes, and social determinants of mental health. These findings contribute to a more nuanced understanding of the complexity of mental health issues in times of global health crises, potentially guiding future early interventions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06076",
        "abstract url": "https://arxiv.org/abs/2403.06076",
        "title": "Sistemas de informaci\u00f3n de salud en contextos extremos: Uso de tel\u00e9fonos m\u00f3viles para combatir el sida en Uganda",
        "rating": -1.5,
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The HIV/AIDS pandemic is a global issue that has unequally affected several countries. Due to the complexity of this condition and the human drama it represents to those most affected by it, several fields have contributed to solving or at least alleviating this situation, and the information systems (IS) field has not been absent from these efforts. With the importance of antiretroviral therapy (ART) as a starting point, several initiatives in the IS field have focused on ways to improve the adherence and effectiveness of this therapy: mobile phone reminders (for pill intake and appointments), and mobile interfaces between patients and health workers are popular contributions. However, many of these solutions have been difficult to implement or deploy in some countries in the Global South, which are among the most affected by this pandemic. This paper presents one such case. Using a case-study approach with an extreme-case selection technique, the paper studies an m-health system for HIV patients in the Kalangala region of Uganda. Using Heeks' design-reality gap model for data analysis, the paper shows that the rich interaction between social context and technology should be considered a central concern when designing or deploying such systems.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "30 pages, in Spanish"
    },
    {
        "paper id": "2403.06080",
        "abstract url": "https://arxiv.org/abs/2403.06080",
        "title": "Local Vertex Colouring Graph Neural Networks",
        "rating": -1.5,
        "keywords": [
            [
                "depth"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, there has been a significant amount of research focused on expanding the expressivity of Graph Neural Networks (GNNs) beyond the Weisfeiler-Lehman (1-WL) framework. While many of these studies have yielded advancements in expressivity, they have frequently come at the expense of decreased efficiency or have been restricted to specific types of graphs. In this study, we investigate the expressivity of GNNs from the perspective of graph search. Specifically, we propose a new vertex colouring scheme and demonstrate that classical search algorithms can efficiently compute graph representations that extend beyond the 1-WL. We show the colouring scheme inherits useful properties from graph search that can help solve problems like graph biconnectivity. Furthermore, we show that under certain conditions, the expressivity of GNNs increases hierarchically with the radius of the search neighbourhood. To further investigate the proposed scheme, we develop a new type of GNN based on two search strategies, breadth-first search and depth-first search, highlighting the graph properties they can capture on top of 1-WL. Our code is available at https://github.com/seanli3/lvc.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "22 pages, 8 figures"
    },
    {
        "paper id": "2403.07012",
        "abstract url": "https://arxiv.org/abs/2403.07012",
        "title": "Non-Intrusive Load Monitoring with Missing Data Imputation Based on Tensor Decomposition",
        "rating": -1.5,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the widespread adoption of Non-Intrusive Load Monitoring (NILM) in building energy management, ensuring the high quality of NILM data has become imperative. However, practical applications of NILM face challenges associated with data loss, significantly impacting accuracy and reliability in energy management. This paper addresses the issue of NILM data loss by introducing an innovative tensor completion(TC) model- Proportional-Integral-Derivative (PID)-incorporated Non-negative Latent Factorization of Tensors (PNLFT) with twofold ideas: 1) To tackle the issue of slow convergence in Latent Factorization of Tensors (LFT) using Stochastic Gradient Descent (SGD), a Proportional-Integral-Derivative controller is introduced during the learning process. The PID controller utilizes historical and current information to control learning residuals. 2) Considering the characteristics of NILM data, non-negative update rules are proposed in the model's learning scheme. Experimental results on three datasets demonstrate that, compared to state-of-the-art models, the proposed model exhibits noteworthy enhancements in both convergence speed and accuracy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.07015",
        "abstract url": "https://arxiv.org/abs/2403.07015",
        "title": "Adaptive Hyperparameter Optimization for Continual Learning Scenarios",
        "rating": -1.5,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hyperparameter selection in continual learning scenarios is a challenging and underexplored aspect, especially in practical non-stationary environments. Traditional approaches, such as grid searches with held-out validation data from all tasks, are unrealistic for building accurate lifelong learning systems. This paper aims to explore the role of hyperparameter selection in continual learning and the necessity of continually and automatically tuning them according to the complexity of the task at hand. Hence, we propose leveraging the nature of sequence task learning to improve Hyperparameter Optimization efficiency. By using the functional analysis of variance-based techniques, we identify the most crucial hyperparameters that have an impact on performance. We demonstrate empirically that this approach, agnostic to continual scenarios and strategies, allows us to speed up hyperparameters optimization continually across tasks and exhibit robustness even in the face of varying sequential task orders. We believe that our findings can contribute to the advancement of continual learning methodologies towards more efficient, robust and adaptable models for real-world applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.13834",
        "abstract url": "https://arxiv.org/abs/2403.13834",
        "title": "Few-shot Learning on Heterogeneous Graphs: Challenges, Progress, and Prospects",
        "rating": -1.5,
        "keywords": [
            [
                "face"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Few-shot learning on heterogeneous graphs (FLHG) is attracting more attention from both academia and industry because prevailing studies on heterogeneous graphs often suffer from label sparsity. FLHG aims to tackle the performance degradation in the face of limited annotated data and there have been numerous recent studies proposing various methods and applications. In this paper, we provide a comprehensive review of existing FLHG methods, covering challenges, research progress, and future prospects. Specifically, we first formalize FLHG and categorize its methods into three types: single-heterogeneity FLHG, dual-heterogeneity FLHG, and multi-heterogeneity FLHG. Then, we analyze the research progress within each category, highlighting the most recent and representative developments. Finally, we identify and discuss promising directions for future research in FLHG. To the best of our knowledge, this paper is the first systematic and comprehensive review of FLHG.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2403.14676",
        "abstract url": "https://arxiv.org/abs/2403.14676",
        "title": "Unified Uncertainty Estimation for Cognitive Diagnosis Models",
        "rating": -1.5,
        "keywords": [
            [
                "Diagnosis"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Cognitive diagnosis models have been widely used in different areas, especially intelligent education, to measure users' proficiency levels on knowledge concepts, based on which users can get personalized instructions. As the measurement is not always reliable due to the weak links of the models and data, the uncertainty of measurement also offers important information for decisions. However, the research on the uncertainty estimation lags behind that on advanced model structures for cognitive diagnosis. Existing approaches have limited efficiency and leave an academic blank for sophisticated models which have interaction function parameters (e.g., deep learning-based models). To address these problems, we propose a unified uncertainty estimation approach for a wide range of cognitive diagnosis models. Specifically, based on the idea of estimating the posterior distributions of cognitive diagnosis model parameters, we first provide a unified objective function for mini-batch based optimization that can be more efficiently applied to a wide range of models and large datasets. Then, we modify the reparameterization approach in order to adapt to parameters defined on different domains. Furthermore, we decompose the uncertainty of diagnostic parameters into data aspect and model aspect, which better explains the source of uncertainty. Extensive experiments demonstrate that our method is effective and can provide useful insights into the uncertainty of cognitive diagnosis.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05828",
        "abstract url": "https://arxiv.org/abs/2403.05828",
        "title": "Multi-GPU-Enabled Hybrid Quantum-Classical Workflow in Quantum-HPC Middleware: Applications in Quantum Simulations",
        "rating": -2,
        "keywords": [
            [
                "Quantum",
                "physics"
            ]
        ],
        "abstract": "Achieving high-performance computation on quantum systems presents a formidable challenge that necessitates bridging the capabilities between quantum hardware and classical computing resources. This study introduces an innovative distribution-aware Quantum-Classical-Quantum (QCQ) architecture, which integrates cutting-edge quantum software framework works with high-performance classical computing resources to address challenges in quantum simulation for materials and condensed matter physics. At the heart of this architecture is the seamless integration of VQE algorithms running on QPUs for efficient quantum state preparation, Tensor Network states, and QCNNs for classifying quantum states on classical hardware. For benchmarking quantum simulators, the QCQ architecture utilizes the cuQuantum SDK to leverage multi-GPU acceleration, integrated with PennyLane's Lightning plugin, demonstrating up to tenfold increases in computational speed for complex phase transition classification tasks compared to traditional CPU-based methods. This significant acceleration enables models such as the transverse field Ising and XXZ systems to accurately predict phase transitions with a 99.5% accuracy. The architecture's ability to distribute computation between QPUs and classical resources addresses critical bottlenecks in Quantum-HPC, paving the way for scalable quantum simulation. The QCQ framework embodies a synergistic combination of quantum algorithms, machine learning, and Quantum-HPC capabilities, enhancing its potential to provide transformative insights into the behavior of quantum systems across different scales. As quantum hardware continues to improve, this hybrid distribution-aware framework will play a crucial role in realizing the full potential of quantum computing by seamlessly integrating distributed quantum resources with the state-of-the-art classical computing infrastructure.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2403.05829",
        "abstract url": "https://arxiv.org/abs/2403.05829",
        "title": "Measuring Robustness in Cyber-Physical Systems under Sensor Attacks",
        "rating": -2,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "This paper contributes a formal framework for quantitative analysis of bounded sensor attacks on cyber-physical systems, using the formalism of differential dynamic logic. Given a precondition and postcondition of a system, we formalize two quantitative safety notions, quantitative forward and backward safety, which respectively express (1) how strong the strongest postcondition of the system is with respect to the specified postcondition, and (2) how strong the specified precondition is with respect to the weakest precondition of the system needed to ensure the specified postcondition holds. We introduce two notions, forward and backward robustness, to characterize the robustness of a system against sensor attacks as the loss of safety. To reason about robustness, we introduce two simulation distances, forward and backward simulation distances, which are defined based on the behavioral distances between the original system and the system with compromised sensors. Forward and backward distances, respectively, characterize upper bounds of the degree of forward and backward safety loss caused by the sensor attacks. We verify the two simulation distances by expressing them as modalities, i.e., formulas of differential dynamic logic, and develop an ad-hoc proof system to reason with such formulas. We showcase our formal notions and reasoning techniques on two non-trivial case studies: an autonomous vehicle that needs to avoid collision and a water tank system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Preprint submitted to Elsevier"
    },
    {
        "paper id": "2403.05839",
        "abstract url": "https://arxiv.org/abs/2403.05839",
        "title": "Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline",
        "rating": -2,
        "keywords": [
            [
                "Depth"
            ],
            [
                "Thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current event-/frame-event based trackers undergo evaluation on short-term tracking datasets, however, the tracking of real-world scenarios involves long-term tracking, and the performance of existing tracking algorithms in these scenarios remains unclear. In this paper, we first propose a new long-term and large-scale frame-event single object tracking dataset, termed FELT. It contains 742 videos and 1,594,474 RGB frames and event stream pairs and has become the largest frame-event tracking dataset to date. We re-train and evaluate 15 baseline trackers on our dataset for future works to compare. More importantly, we find that the RGB frames and event streams are naturally incomplete due to the influence of challenging factors and spatially sparse event flow. In response to this, we propose a novel associative memory Transformer network as a unified backbone by introducing modern Hopfield layers into multi-head self-attention blocks to fuse both RGB and event data. Extensive experiments on RGB-Event (FELT), RGB-Thermal (RGBT234, LasHeR), and RGB-Depth (DepthTrack) datasets fully validated the effectiveness of our model. The dataset and source code can be found at \\url{https://github.com/Event-AHU/FELT_SOT_Benchmark}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "In Peer Review"
    },
    {
        "paper id": "2403.05847",
        "abstract url": "https://arxiv.org/abs/2403.05847",
        "title": "MirrorAttack: Backdoor Attack on 3D Point Cloud with a Distorting Mirror",
        "rating": -2,
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "The widespread deployment of Deep Neural Networks (DNNs) for 3D point cloud processing starkly contrasts with their susceptibility to security breaches, notably backdoor attacks. These attacks hijack DNNs during training, embedding triggers in the data that, once activated, cause the network to make predetermined errors while maintaining normal performance on unaltered data. This vulnerability poses significant risks, especially given the insufficient research on robust defense mechanisms for 3D point cloud networks against such sophisticated threats. Existing attacks either struggle to resist basic point cloud pre-processing methods, or rely on delicate manual design. Exploring simple, effective, imperceptible, and difficult-to-defend triggers in 3D point clouds is still challenging.To address these challenges, we introduce MirrorAttack, a novel effective 3D backdoor attack method, which implants the trigger by simply reconstructing a clean point cloud with an auto-encoder. The data-driven nature of the MirrorAttack obviates the need for complex manual design. Minimizing the reconstruction loss automatically improves imperceptibility. Simultaneously, the reconstruction network endows the trigger with pronounced nonlinearity and sample specificity, rendering traditional preprocessing techniques ineffective in eliminating it. A trigger smoothing module based on spherical harmonic transformation is also attached to regulate the intensity of the attack.Both quantitive and qualitative results verify the effectiveness of our method. We achieve state-of-the-art ASR on different types of victim models with the intervention of defensive techniques. Moreover, the minimal perturbation introduced by our trigger, as assessed by various metrics, attests to the method's stealth, ensuring its imperceptibility.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2403.05851",
        "abstract url": "https://arxiv.org/abs/2403.05851",
        "title": "Interest-Aware Joint Caching, Computing, and Communication Optimization for Mobile VR Delivery in MEC Networks",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "In the upcoming B5G/6G era, virtual reality (VR) over wireless has become a typical application, which is an inevitable trend in the development of video. However, in immersive and interactive VR experiences, VR services typically exhibit high delay, while simultaneously posing challenges for the energy consumption of local devices. To address these issues, this paper aims to improve the performance of the VR service in the edge-terminal cooperative system. Specifically, we formulate a problem of joint caching, computing, and communication VR service policy, by optimizing the weighted sum of overall VR delivery delay and energy consumption of local devices. For the purpose of designing the optimal VR service policy, the optimization problem is decoupled into three independent subproblems to be solved separately. To enhance the caching efficiency within the network, a bidirectional encoder representations from transformers (Bert)-based user interest analysis method is first proposed to characterize the content requesting behavior accurately. On the basis of this, a service cost minimum-maximization problem is formulated with consideration of performance fairness among users. Thereafter, the joint caching and computing scheme is derived for each user with given allocation of communication resources while a bisection-based communication scheme is acquired with the given information on joint caching and computing policy. With alternative optimization, an optimal policy for joint caching, computing and communication based on user interest can be finally obtained. Simulation results are presented to demonstrate the superiority of the proposed user interest-aware caching scheme and the effective of the joint caching, computing and communication optimization policy with consideration of user fairness.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05873",
        "abstract url": "https://arxiv.org/abs/2403.05873",
        "title": "LEGION: Harnessing Pre-trained Language Models for GitHub Topic Recommendations with Distribution-Balance Loss",
        "rating": -2,
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Open-source development has revolutionized the software industry by promoting collaboration, transparency, and community-driven innovation. Today, a vast amount of various kinds of open-source software, which form networks of repositories, is often hosted on GitHub - a popular software development platform. To enhance the discoverability of the repository networks, i.e., groups of similar repositories, GitHub introduced repository topics in 2017 that enable users to more easily explore relevant projects by type, technology, and more. It is thus crucial to accurately assign topics for each GitHub repository. Current methods for automatic topic recommendation rely heavily on TF-IDF for encoding textual data, presenting challenges in understanding semantic nuances. This paper addresses the limitations of existing techniques by proposing Legion, a novel approach that leverages Pre-trained Language Models (PTMs) for recommending topics for GitHub repositories. The key novelty of Legion is three-fold. First, Legion leverages the extensive capabilities of PTMs in language understanding to capture contextual information and semantic meaning in GitHub repositories. Second, Legion overcomes the challenge of long-tailed distribution, which results in a bias toward popular topics in PTMs, by proposing a Distribution-Balanced Loss (DB Loss) to better train the PTMs. Third, Legion employs a filter to eliminate vague recommendations, thereby improving the precision of PTMs. Our empirical evaluation on a benchmark dataset of real-world GitHub repositories shows that Legion can improve vanilla PTMs by up to 26% on recommending GitHubs topics. Legion also can suggest GitHub topics more precisely and effectively than the state-of-the-art baseline with an average improvement of 20% and 5% in terms of Precision and F1-score, respectively.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted to EASE'24"
    },
    {
        "paper id": "2403.05881",
        "abstract url": "https://arxiv.org/abs/2403.05881",
        "title": "KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques",
        "rating": -2,
        "keywords": [
            [
                "graph"
            ],
            [
                "Medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have significantly advanced healthcare innovation on generation capabilities. However, their application in real clinical settings is challenging due to potential deviations from medical facts and inherent biases. In this work, we develop an augmented LLM framework, KG-Rank, which leverages a medical knowledge graph (KG) with ranking and re-ranking techniques, aiming to improve free-text question-answering (QA) in the medical domain. Specifically, upon receiving a question, we initially retrieve triplets from a medical KG to gather factual information. Subsequently, we innovatively apply ranking methods to refine the ordering of these triplets, aiming to yield more precise answers. To the best of our knowledge, KG-Rank is the first application of ranking models combined with KG in medical QA specifically for generating long answers. Evaluation of four selected medical QA datasets shows that KG-Rank achieves an improvement of over 18% in the ROUGE-L score. Moreover, we extend KG-Rank to open domains, where it realizes a 14% improvement in ROUGE-L, showing the effectiveness and potential of KG-Rank.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05892",
        "abstract url": "https://arxiv.org/abs/2403.05892",
        "title": "Stacked Intelligent Metasurface Enabled LEO Satellite Communications Relying on Statistical CSI",
        "rating": -2,
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "Low earth orbit (LEO) satellite communication systems have gained increasing attention as a crucial supplement to terrestrial wireless networks due to their extensive coverage area. This letter presents a novel system design for LEO satellite systems by leveraging stacked intelligent metasurface (SIM) technology. Specifically, the lightweight and energy-efficient SIM is mounted on a satellite to achieve multiuser beamforming directly in the electromagnetic wave domain, which substantially reduces the processing delay and computational load of the satellite compared to the traditional digital beamforming scheme. To overcome the challenges of obtaining instantaneous channel state information (CSI) at the transmitter and maximize the system's performance, a joint power allocation and SIM phase shift optimization problem for maximizing the ergodic sum rate is formulated based on statistical CSI, and an alternating optimization (AO) algorithm is customized to solve it efficiently. Additionally, a user grouping method based on channel correlation and an antenna selection algorithm are proposed to further improve the system performance. Simulation results demonstrate the effectiveness of the proposed SIM-based LEO satellite system design and statistical CSI-based AO algorithm.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "14 pages, 4 figures, accepted by IEEE WCL"
    },
    {
        "paper id": "2403.05901",
        "abstract url": "https://arxiv.org/abs/2403.05901",
        "title": "Unleashing the Power of T1-cells in SFQ Arithmetic Circuits",
        "rating": -2,
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Rapid single-flux quantum (RSFQ), a leading cryogenic superconductive electronics (SCE) technology, offers extremely low power dissipation and high speed. However, implementing RSFQ systems at VLSI complexity faces challenges, such as substantial area overhead from gate-level pipelining and path balancing, exacerbated by RSFQ's limited layout density. T1 flip-flop (T1-FF) is an RSFQ logic cell operating as a pulse counter. Using T1-FF the full adder function can be realized with only 40% of the area required by the conventional realization. This cell however imposes complex constraints on input signal timing, complicating its use. Multiphase clocking has been recently proposed to alleviate gate-level pipelining overhead. The fanin signals can be efficiently controlled using multiphase clocking. We present the novel two-stage SFQ technology mapping methodology supporting the T1-FF. Compatible parts of the SFQ network are first replaced by the efficient T1-FFs. Multiphase retiming is next applied to assign clock phases to each logic gate and insert DFFs to satisfy the input timing. Using our flow, the area of the SFQ networks is reduced, on average, by 6% with up to 25% reduction in optimizing the 128-bit adder.",
        "subjects": [
            "cs.ET"
        ],
        "comment": "To appear at the 2024 ACM/IEEE Design Automation and Test in Europe, Valencia, Spain, 25-27 March 2024. 2 pages, 1 figure, 1 table"
    },
    {
        "paper id": "2403.05907",
        "abstract url": "https://arxiv.org/abs/2403.05907",
        "title": "Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving",
        "rating": -2,
        "keywords": [
            [
                "NeRF"
            ],
            [
                "synthesis"
            ],
            [
                "Autonomous Driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent studies have highlighted the promising application of NeRF in autonomous driving contexts. However, the complexity of outdoor environments, combined with the restricted viewpoints in driving scenarios, complicates the task of precisely reconstructing scene geometry. Such challenges often lead to diminished quality in reconstructions and extended durations for both training and rendering. To tackle these challenges, we present Lightning NeRF. It uses an efficient hybrid scene representation that effectively utilizes the geometry prior from LiDAR in autonomous driving scenarios. Lightning NeRF significantly improves the novel view synthesis performance of NeRF and reduces computational overheads. Through evaluations on real-world datasets, such as KITTI-360, Argoverse2, and our private dataset, we demonstrate that our approach not only exceeds the current state-of-the-art in novel view synthesis quality but also achieves a five-fold increase in training speed and a ten-fold improvement in rendering speed. Codes are available at https://github.com/VISION-SJTU/Lightning-NeRF .",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ICRA 2024"
    },
    {
        "paper id": "2403.05912",
        "abstract url": "https://arxiv.org/abs/2403.05912",
        "title": "Mask-Enhanced Segment Anything Model for Tumor Lesion Semantic Segmentation",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "diagnosis",
                "MRI",
                "CT",
                "cancer",
                "Tumor"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Tumor lesion segmentation on CT or MRI images plays a critical role in cancer diagnosis and treatment planning. Considering the inherent differences in tumor lesion segmentation data across various medical imaging modalities and equipment, integrating medical knowledge into the Segment Anything Model (SAM) presents promising capability due to its versatility and generalization potential. Recent studies have attempted to enhance SAM with medical expertise by pre-training on large-scale medical segmentation datasets. However, challenges still exist in 3D tumor lesion segmentation owing to tumor complexity and the imbalance in foreground and background regions. Therefore, we introduce Mask-Enhanced SAM (M-SAM), an innovative architecture tailored for 3D tumor lesion segmentation. We propose a novel Mask-Enhanced Adapter (MEA) within M-SAM that enriches the semantic information of medical images with positional data from coarse segmentation masks, facilitating the generation of more precise segmentation masks. Furthermore, an iterative refinement scheme is implemented in M-SAM to refine the segmentation masks progressively, leading to improved performance. Extensive experiments on seven tumor lesion segmentation datasets indicate that our M-SAM not only achieves high segmentation accuracy but also exhibits robust generalization.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05961",
        "abstract url": "https://arxiv.org/abs/2403.05961",
        "title": "Blockchain-Enhanced Offloading in Mobile Edge Computing: A Systematic Review and Survey of Current Trends and Future Directions",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "With the rapid growth of Internet of Things (IoT) applications, there's a big demand for more processing power and resources in devices. Mobile Edge Computing (MEC) looks promising for enhancing performance and reducing costs by offloading the computing work of IoT to MEC servers. However, the current methods for offloading have issues with privacy and security during the transfer of data and programs. To tackle this, recent developments have introduced secure offloading methods using Blockchain technology, which helps to make MEC more secure by building trust between nodes, improving how edges are authenticated and accessed, and stopping unauthorized access to devices. This paper reviews these Blockchain-based offloading methods for different MEC settings. It starts by explaining the key ideas in offloading and Blockchain, then it sorts the Blockchain-based offloading methods by the algorithms they use. It also compares the offloading methods in each group and ends with a discussion and comparison of the different techniques, tools, and metrics used in these methods.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05968",
        "abstract url": "https://arxiv.org/abs/2403.05968",
        "title": "IMU as an Input vs. a Measurement of the State in Inertial-Aided State Estimation",
        "rating": -2,
        "keywords": [
            [
                "lidar"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "In this technical report, we compare treating an IMU as an input to a motion model against treating it as a measurement of the state in a continuous-time state estimation framework. Treating IMU measurements as inputs to a motion model and then preintegrating these measurements has almost become a de-facto standard in many robotics applications. However, this approach has a few shortcomings. First, it conflates the IMU measurement noise with the underlying process noise. Second, it is unclear how the state will be propagated in the case of IMU measurement dropout. Third, it does not lend itself well to dealing with multiple high-rate sensors such as a lidar and an IMU or multiple IMUs. In this work, we methodically compare the performance of these two approaches on a 1D simulation and show that they perform identically, assuming that each method's hyperparameters have been tuned on a training set. We show how to preintegrate heterogeneous factors using Gaussian process interpolation. We also provide results for our continuous-time lidar-inertial odometry in simulation and on the Newer College Dataset. Code for our lidar-inertial odometry can be found at: https://github.com/utiasASRL/steam_icp",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to Robotica March 9th, 2024"
    },
    {
        "paper id": "2403.06003",
        "abstract url": "https://arxiv.org/abs/2403.06003",
        "title": "A Generalized Acquisition Function for Preference-based Reward Learning",
        "rating": -2,
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Preference-based reward learning is a popular technique for teaching robots and autonomous systems how a human user wants them to perform a task. Previous works have shown that actively synthesizing preference queries to maximize information gain about the reward function parameters improves data efficiency. The information gain criterion focuses on precisely identifying all parameters of the reward function. This can potentially be wasteful as many parameters may result in the same reward, and many rewards may result in the same behavior in the downstream tasks. Instead, we show that it is possible to optimize for learning the reward function up to a behavioral equivalence class, such as inducing the same ranking over behaviors, distribution over choices, or other related definitions of what makes two rewards similar. We introduce a tractable framework that can capture such definitions of similarity. Our experiments in a synthetic environment, an assistive robotics environment with domain transfer, and a natural language processing problem with real datasets demonstrate the superior performance of our querying method over the state-of-the-art information gain method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06012",
        "abstract url": "https://arxiv.org/abs/2403.06012",
        "title": "A Tool for Automated Reasoning About Traces Based on Configurable Formal Semantics",
        "rating": -2,
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "We present Tarski, a tool for specifying configurable trace semantics to facilitate automated reasoning about traces. Software development projects require that various types of traces be modeled between and within development artifacts. For any given artifact (e.g., requirements, architecture models and source code), Tarski allows the user to specify new trace types and their configurable semantics, while, using the semantics, it automatically infers new traces based on existing traces provided by the user, and checks the consistency of traces. It has been evaluated on three industrial case studies in the automotive domain (https://modelwriter.github.io/Tarski/).",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Published in ESEC/FSE 2017: Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering"
    },
    {
        "paper id": "2403.06019",
        "abstract url": "https://arxiv.org/abs/2403.06019",
        "title": "Comparing the physical characteristics of ultrasound and magnetic resonance imaging to diagnose ovarian cysts",
        "rating": -2,
        "keywords": [
            [
                "diagnosis",
                "MRI"
            ]
        ],
        "abstract": "Background, For the purpose of determining the appropriate course of therapy to maintain fertility, a correct diagnosis of ovarian cysts is crucial. Objective, To contrast the results of magnetic resonance imaging and ultrasonography in individuals with ovarian cysts . Methods: research was carried out in the radiology division of Al-Hilla General Teaching hospital and Marjan Teaching Hospital in province Babil in the period of November 2023 and march 2024, Seventy-five Following a physical and ultrasonography examination, the female patient was assessed using magnetic resonance imaging. Women in the over-18 age group exhibit a range of symptoms, such as irregular menstruation, abdominal pain, sensoria, and menorrhagia. Results: Adnexal lesions on US imaging included chocolate cysts (14.6%), dermoid cysts (13.8%), hemorrhagic cysts (HC) (11.6%), simple cysts (32.4%), complicated cysts (21.2%), and multilocular cysts (MC) (6.4%).Simple cysts (SC) made up 29%, complex cysts (6.9%), dermoid cysts (10.9%), chocolate cysts (19.1%), hemorrhagic cysts (HC) 11.3%, multilocular cysts (6.8%), and malignant cysts (MC) 16% of the adnexal lesions on MRI. The USG results show 100% sensitivity, 78.3% specificity, and 89.3% accuracy when compared to the MRI results. Conclusions: Magnetic resonance imaging, which is quite accurate in determining the mass's origin and characterizing its tissue content, may be beneficial in further evaluating monographically vague ovarian cysts with solid or complicated content",
        "subjects": [
            "physics.med-ph"
        ],
        "comment": "accepted for publication in the Kuwait Journal of Science. The authors would like to acknowledge the support of AL-Ameen University, Iraq for their valuable support"
    },
    {
        "paper id": "2403.06041",
        "abstract url": "https://arxiv.org/abs/2403.06041",
        "title": "MATRIX: Multi-Agent Trajectory Generation with Diverse Contexts",
        "rating": -2,
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Data-driven methods have great advantages in modeling complicated human behavioral dynamics and dealing with many human-robot interaction applications. However, collecting massive and annotated real-world human datasets has been a laborious task, especially for highly interactive scenarios. On the other hand, algorithmic data generation methods are usually limited by their model capacities, making them unable to offer realistic and diverse data needed by various application users. In this work, we study trajectory-level data generation for multi-human or human-robot interaction scenarios and propose a learning-based automatic trajectory generation model, which we call Multi-Agent TRajectory generation with dIverse conteXts (MATRIX). MATRIX is capable of generating interactive human behaviors in realistic diverse contexts. We achieve this goal by modeling the explicit and interpretable objectives so that MATRIX can generate human motions based on diverse destinations and heterogeneous behaviors. We carried out extensive comparison and ablation studies to illustrate the effectiveness of our approach across various metrics. We also presented experiments that demonstrate the capability of MATRIX to serve as data augmentation for imitation-based motion planning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "IEEE International Conference on Robotics and Automation (ICRA 2024)"
    },
    {
        "paper id": "2403.06054",
        "abstract url": "https://arxiv.org/abs/2403.06054",
        "title": "Decoupled Data Consistency with Diffusion Purification for Image Restoration",
        "rating": -2,
        "keywords": [
            [
                "Diffusion",
                "inpainting",
                "super-resolution"
            ],
            [
                "Image Restoration"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Diffusion models have recently gained traction as a powerful class of deep generative priors, excelling in a wide range of image restoration tasks due to their exceptional ability to model data distributions. To solve image restoration problems, many existing techniques achieve data consistency by incorporating additional likelihood gradient steps into the reverse sampling process of diffusion models. However, the additional gradient steps pose a challenge for real-world practical applications as they incur a large computational overhead, thereby increasing inference time. They also present additional difficulties when using accelerated diffusion model samplers, as the number of data consistency steps is limited by the number of reverse sampling steps. In this work, we propose a novel diffusion-based image restoration solver that addresses these issues by decoupling the reverse process from the data consistency steps. Our method involves alternating between a reconstruction phase to maintain data consistency and a refinement phase that enforces the prior via diffusion purification. Our approach demonstrates versatility, making it highly adaptable for efficient problem-solving in latent space. Additionally, it reduces the necessity for numerous sampling steps through the integration of consistency models. The efficacy of our approach is validated through comprehensive experiments across various image restoration tasks, including image denoising, deblurring, inpainting, and super-resolution.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06067",
        "abstract url": "https://arxiv.org/abs/2403.06067",
        "title": "Federated Learning: Attacks, Defenses, Opportunities, and Challenges",
        "rating": -2,
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "Using dispersed data and training, federated learning (FL) moves AI capabilities to edge devices or does tasks locally. Many consider FL the start of a new era in AI, yet it is still immature. FL has not garnered the community's trust since its security and privacy implications are controversial. FL's security and privacy concerns must be discovered, analyzed, and recorded before widespread usage and adoption. A solid comprehension of risk variables allows an FL practitioner to construct a secure environment and provide researchers with a clear perspective of potential study fields, making FL the best solution in situations where security and privacy are primary issues. This research aims to deliver a complete overview of FL's security and privacy features to help bridge the gap between current federated AI and broad adoption in the future. In this paper, we present a comprehensive overview of the attack surface to investigate FL's existing challenges and defense measures to evaluate its robustness and reliability. According to our study, security concerns regarding FL are more frequent than privacy issues. Communication bottlenecks, poisoning, and backdoor attacks represent FL's privacy's most significant security threats. In the final part, we detail future research that will assist FL in adapting to real-world settings.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06072",
        "abstract url": "https://arxiv.org/abs/2403.06072",
        "title": "Channel Estimation Considerate Precoder Design for Multi-user Massive MIMO-OFDM Systems: The Concept and Fast Algorithms",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "The sixth-generation (6G) communication networks target peak data rates exceeding 1Tbps, necessitating base stations (BS) to support up to 100 simultaneous data streams. However, sparse pilot allocation to accommodate such streams poses challenges for users' channel estimation. This paper presents Channel Estimation Considerate Precoding (CECP), where BS precoders prioritize facilitating channel estimation alongside maximizing transmission rate. To address the computational complexity of 6G large-scale multi-input multi-output (MIMO) systems, we propose a computationally-efficient space-time block diagonal channel shortening (ST-BDCS) precoding scheme. By leveraging the sparse Toeplitz property of orthogonal frequency division multiplexing (OFDM) channels, this time-domain precoding design effectively mitigates multi-user interference in the downlink and shortens the effective channel's temporal length. Consequently, users can estimate the channels using sparse pilots. To enable fast implementation, we develop a generalized complex-valued Toeplitz matrix QR decomposition algorithm applicable to various space-time signal processing problems. Simulation results demonstrate that the ST-BDCS precoding method approximates the rate performance of conventional subcarrier-by-subcarrier precoding schemes. However, it offers the advantages of easier channel estimation for users and significantly reduced computational complexity for the BS.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "The work is supported by HUAWEI cooperation, which is related to the current HUAWEI project. HUAWEI cooperation requires to withdraw the paper"
    },
    {
        "paper id": "2403.06088",
        "abstract url": "https://arxiv.org/abs/2403.06088",
        "title": "Towards In-Vehicle Multi-Task Facial Attribute Recognition: Investigating Synthetic Data and Vision Foundation Models",
        "rating": -2,
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the burgeoning field of intelligent transportation systems, enhancing vehicle-driver interaction through facial attribute recognition, such as facial expression, eye gaze, age, etc., is of paramount importance for safety, personalization, and overall user experience. However, the scarcity of comprehensive large-scale, real-world datasets poses a significant challenge for training robust multi-task models. Existing literature often overlooks the potential of synthetic datasets and the comparative efficacy of state-of-the-art vision foundation models in such constrained settings. This paper addresses these gaps by investigating the utility of synthetic datasets for training complex multi-task models that recognize facial attributes of passengers of a vehicle, such as gaze plane, age, and facial expression. Utilizing transfer learning techniques with both pre-trained Vision Transformer (ViT) and Residual Network (ResNet) models, we explore various training and adaptation methods to optimize performance, particularly when data availability is limited. We provide extensive post-evaluation analysis, investigating the effects of synthetic data distributions on model performance in in-distribution data and out-of-distribution inference. Our study unveils counter-intuitive findings, notably the superior performance of ResNet over ViTs in our specific multi-task context, which is attributed to the mismatch in model complexity relative to task complexity. Our results highlight the challenges and opportunities for enhancing the use of synthetic data and vision foundation models in practical applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Manuscript under peer review"
    },
    {
        "paper id": "2403.06089",
        "abstract url": "https://arxiv.org/abs/2403.06089",
        "title": "Knowledge Distillation of Convolutional Neural Networks through Feature Map Transformation using Decision Trees",
        "rating": -2,
        "keywords": [
            [
                "depth"
            ],
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The interpretation of reasoning by Deep Neural Networks (DNN) is still challenging due to their perceived black-box nature. Therefore, deploying DNNs in several real-world tasks is restricted by the lack of transparency of these models. We propose a distillation approach by extracting features from the final layer of the convolutional neural network (CNN) to address insights to its reasoning. The feature maps in the final layer of a CNN are transformed into a one-dimensional feature vector using a fully connected layer. Subsequently, the extracted features are used to train a decision tree to achieve the best accuracy under constraints of depth and nodes. We use the medical images of dermaMNIST, octMNIST, and pneumoniaMNIST from the medical MNIST datasets to demonstrate our proposed work. We observed that performance of the decision tree is as good as a CNN with minimum complexity. The results encourage interpreting decisions made by the CNNs using decision trees.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.07013",
        "abstract url": "https://arxiv.org/abs/2403.07013",
        "title": "AdaNovo: Adaptive \\emph{De Novo} Peptide Sequencing with Conditional Mutual Information",
        "rating": -2,
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Tandem mass spectrometry has played a pivotal role in advancing proteomics, enabling the analysis of protein composition in biological samples. Despite the development of various deep learning methods for identifying amino acid sequences (peptides) responsible for observed spectra, challenges persist in \\emph{de novo} peptide sequencing. Firstly, prior methods struggle to identify amino acids with post-translational modifications (PTMs) due to their lower frequency in training data compared to canonical amino acids, further resulting in decreased peptide-level identification precision. Secondly, diverse types of noise and missing peaks in mass spectra reduce the reliability of training data (peptide-spectrum matches, PSMs). To address these challenges, we propose AdaNovo, a novel framework that calculates conditional mutual information (CMI) between the spectrum and each amino acid/peptide, using CMI for adaptive model training. Extensive experiments demonstrate AdaNovo's state-of-the-art performance on a 9-species benchmark, where the peptides in the training set are almost completely disjoint from the peptides of the test sets. Moreover, AdaNovo excels in identifying amino acids with PTMs and exhibits robustness against data noise. The supplementary materials contain the official code.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2403.08824",
        "abstract url": "https://arxiv.org/abs/2403.08824",
        "title": "Measuring Non-Typical Emotions for Mental Health: A Survey of Computational Approaches",
        "rating": -2,
        "keywords": [
            [
                "Health"
            ]
        ],
        "abstract": "Analysis of non-typical emotions, such as stress, depression and engagement is less common and more complex compared to that of frequently discussed emotions like happiness, sadness, fear, and anger. The importance of these non-typical emotions has been increasingly recognized due to their implications on mental health and well-being. Stress and depression impact the engagement in daily tasks, highlighting the need to understand their interplay. This survey is the first to simultaneously explore computational methods for analyzing stress, depression, and engagement. We discuss the most commonly used datasets, input modalities, data processing techniques, and information fusion methods used for the computational analysis of stress, depression and engagement. A timeline and taxonomy of non-typical emotion analysis approaches along with their generic pipeline and categories are presented. Subsequently, we describe state-of-the-art computational approaches for non-typical emotion analysis, including a performance summary on the most commonly used datasets. Following this, we explore the applications, along with the associated challenges, limitations, and future research directions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Under review in IEEE Transactions on Affective Computing"
    },
    {
        "paper id": "2403.05801",
        "abstract url": "https://arxiv.org/abs/2403.05801",
        "title": "Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques",
        "rating": -2.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "Medical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the realm of computational knowledge representation, Knowledge Graph Reasoning (KG-R) stands at the forefront of facilitating sophisticated inferential capabilities across multifarious domains. The quintessence of this research elucidates the employment of reinforcement learning (RL) strategies, notably the REINFORCE algorithm, to navigate the intricacies inherent in multi-hop KG-R. This investigation critically addresses the prevalent challenges introduced by the inherent incompleteness of Knowledge Graphs (KGs), which frequently results in erroneous inferential outcomes, manifesting as both false negatives and misleading positives. By partitioning the Unified Medical Language System (UMLS) benchmark dataset into rich and sparse subsets, we investigate the efficacy of pre-trained BERT embeddings and Prompt Learning methodologies to refine the reward shaping process. This approach not only enhances the precision of multi-hop KG-R but also sets a new precedent for future research in the field, aiming to improve the robustness and accuracy of knowledge inference within complex KG frameworks. Our work contributes a novel perspective to the discourse on KG reasoning, offering a methodological advancement that aligns with the academic rigor and scholarly aspirations of the Natural journal, promising to invigorate further advancements in the realm of computational knowledge representation.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "This paper has been accepted by the 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT 2024)"
    },
    {
        "paper id": "2403.06020",
        "abstract url": "https://arxiv.org/abs/2403.06020",
        "title": "Multi-conditioned Graph Diffusion for Neural Architecture Search",
        "rating": -2.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural architecture search automates the design of neural network architectures usually by exploring a large and thus complex architecture search space. To advance the architecture search, we present a graph diffusion-based NAS approach that uses discrete conditional graph diffusion processes to generate high-performing neural network architectures. We then propose a multi-conditioned classifier-free guidance approach applied to graph diffusion networks to jointly impose constraints such as high accuracy and low hardware latency. Unlike the related work, our method is completely differentiable and requires only a single model training. In our evaluations, we show promising results on six standard benchmarks, yielding novel and unique architectures at a fast speed, i.e. less than 0.2 seconds per architecture. Furthermore, we demonstrate the generalisability and efficiency of our method through experiments on ImageNet dataset.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at Transactions on Machine Learning Research (TMLR)"
    },
    {
        "paper id": "2403.06087",
        "abstract url": "https://arxiv.org/abs/2403.06087",
        "title": "Learning the irreversible progression trajectory of Alzheimer's disease",
        "rating": -2.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "MRI",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Alzheimer's disease (AD) is a progressive and irreversible brain disorder that unfolds over the course of 30 years. Therefore, it is critical to capture the disease progression in an early stage such that intervention can be applied before the onset of symptoms. Machine learning (ML) models have been shown effective in predicting the onset of AD. Yet for subjects with follow-up visits, existing techniques for AD classification only aim for accurate group assignment, where the monotonically increasing risk across follow-up visits is usually ignored. Resulted fluctuating risk scores across visits violate the irreversibility of AD, hampering the trustworthiness of models and also providing little value to understanding the disease progression. To address this issue, we propose a novel regularization approach to predict AD longitudinally. Our technique aims to maintain the expected monotonicity of increasing disease risk during progression while preserving expressiveness. Specifically, we introduce a monotonicity constraint that encourages the model to predict disease risk in a consistent and ordered manner across follow-up visits. We evaluate our method using the longitudinal structural MRI and amyloid-PET imaging data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our model outperforms existing techniques in capturing the progressiveness of disease risk, and at the same time preserves prediction accuracy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "accepted by ISBI 2024"
    },
    {
        "paper id": "2403.05879",
        "abstract url": "https://arxiv.org/abs/2403.05879",
        "title": "Deep Learning based acoustic measurement approach for robotic applications on orthopedics",
        "rating": -3,
        "keywords": [
            [
                "robotics",
                "navigation"
            ],
            [
                "surgical",
                "surgery",
                "CT"
            ]
        ],
        "abstract": "In Total Knee Replacement Arthroplasty (TKA), surgical robotics can provide image-guided navigation to fit implants with high precision. Its tracking approach highly relies on inserting bone pins into the bones tracked by the optical tracking system. This is normally done by invasive, radiative manners (implantable markers and CT scans), which introduce unnecessary trauma and prolong the preparation time for patients. To tackle this issue, ultrasound-based bone tracking could offer an alternative. In this study, we proposed a novel deep learning structure to improve the accuracy of bone tracking by an A-mode ultrasound (US). We first obtained a set of ultrasound dataset from the cadaver experiment, where the ground truth locations of bones were calculated using bone pins. These data were used to train the proposed CasAtt-UNet to predict bone location automatically and robustly. The ground truth bone locations and those locations of US were recorded simultaneously. Therefore, we could label bone peaks in the raw US signals. As a result, our method achieved sub millimeter precision across all eight bone areas with the only exception of one channel in the ankle. This method enables the robust measurement of lower extremity bone positions from 1D raw ultrasound signals. It shows great potential to apply A-mode ultrasound in orthopedic surgery from safe, convenient, and efficient perspectives.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05884",
        "abstract url": "https://arxiv.org/abs/2403.05884",
        "title": "Towards Multiphase Clocking in Single-Flux Quantum Systems",
        "rating": -3,
        "keywords": [
            [
                "depth"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Rapid single-flux quantum (RSFQ) is one of the most advanced superconductive electronics technologies. SFQ systems operate at tens of gigahertz with up to three orders of magnitude smaller power as compared to CMOS. In conventional SFQ systems, most gates require clock signal. Each gate should have the fanins with equal logic depth, necessitating insertion of path-balancing (PB) DFFs, incurring prohibitive area penalty. Multiphase clocking is the effective method for reducing the path-balancing overhead at the cost of reduced throughput. However, existing tools are not directly applicable for technology mapping of multiphase systems. To overcome this limitation, in this work, we propose a technology mapping tool for multiphase systems. Our contribution is threefold. First, we formulate a phase assignment as a Constraint Programming with Satisfiability (CP-SAT) problem, to determine the phase of each element within the network. Second, we formulate the path balancing problem as a CP-SAT to optimize the number of DFFs within an asynchronous datapath. Finally, we integrate these methods into a technology mapping flow to convert a logic network into a multiphase SFQ circuit. In our case studies, by using seven phases, the size of the circuit (expressed as the number of Josephson junctions) is reduced, on average, by 59.94 % as compared to the dual (fast-slow) clocking method, while outperforming the state-of-the-art single-phase SFQ mapping tools.",
        "subjects": [
            "cs.ET"
        ],
        "comment": "Best Paper Award nominee at the ACM/IEEE Asia South Pacific Design Automation Conference, Incheon, South Korea, 2024. 6 pages, 6 figures"
    },
    {
        "paper id": "2403.05886",
        "abstract url": "https://arxiv.org/abs/2403.05886",
        "title": "Generalizing to Out-of-Sample Degradations via Model Reprogramming",
        "rating": -3,
        "keywords": [
            [
                "image restoration"
            ],
            [
                "quantum"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing image restoration models are typically designed for specific tasks and struggle to generalize to out-of-sample degradations not encountered during training. While zero-shot methods can address this limitation by fine-tuning model parameters on testing samples, their effectiveness relies on predefined natural priors and physical models of specific degradations. Nevertheless, determining out-of-sample degradations faced in real-world scenarios is always impractical. As a result, it is more desirable to train restoration models with inherent generalization ability. To this end, this work introduces the Out-of-Sample Restoration (OSR) task, which aims to develop restoration models capable of handling out-of-sample degradations. An intuitive solution involves pre-translating out-of-sample degradations to known degradations of restoration models. However, directly translating them in the image space could lead to complex image translation issues. To address this issue, we propose a model reprogramming framework, which translates out-of-sample degradations by quantum mechanic and wave functions. Specifically, input images are decoupled as wave functions of amplitude and phase terms. The translation of out-of-sample degradation is performed by adapting the phase term. Meanwhile, the image content is maintained and enhanced in the amplitude term. By taking these two terms as inputs, restoration models are able to handle out-of-sample degradations without fine-tuning. Through extensive experiments across multiple evaluation cases, we demonstrate the effectiveness and flexibility of our proposed framework. Our codes are available at \\href{https://github.com/ddghjikle/Out-of-sample-restoration}{Github}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05944",
        "abstract url": "https://arxiv.org/abs/2403.05944",
        "title": "Model-Predictive Trajectory Generation for Autonomous Aerial Search and Coverage",
        "rating": -3,
        "keywords": [
            [
                "Trajectory",
                "Vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "This paper addresses the trajectory planning problem for search and coverage missions with an Unmanned Aerial Vehicle (UAV). The objective is to devise optimal coverage trajectories based on a utility map describing prior region information, assumed to be effectively approximated by a Gaussian Mixture Model (GMM). We introduce a Model Predictive Control (MPC) algorithm employing a relaxed formulation that promotes the exploration of the map by preventing the UAV from revisiting previously covered areas. This is achieved by penalizing intersections between the UAV's visibility regions along its trajectory. The algorithm is assessed in MATLAB and validated in Gazebo, as well as in outdoor experimental tests. The results show that the proposed strategy can generate efficient and smooth trajectories for search and coverage missions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.07939",
        "abstract url": "https://arxiv.org/abs/2404.07939",
        "title": "Distributed Record Linkage in Healthcare Data with Apache Spark",
        "rating": -3,
        "keywords": [
            [
                "SVM"
            ],
            [
                "medical",
                "Healthcare"
            ]
        ],
        "abstract": "Healthcare data is a valuable resource for research, analysis, and decision-making in the medical field. However, healthcare data is often fragmented and distributed across various sources, making it challenging to combine and analyze effectively. Record linkage, also known as data matching, is a crucial step in integrating and cleaning healthcare data to ensure data quality and accuracy. Apache Spark, a powerful open-source distributed big data processing framework, provides a robust platform for performing record linkage tasks with the aid of its machine learning library. In this study, we developed a new distributed data-matching model based on the Apache Spark Machine Learning library. To ensure the correct functioning of our model, the validation phase has been performed on the training data. The main challenge is data imbalance because a large amount of data is labeled false, and a small number of records are labeled true. By utilizing SVM and Regression algorithms, our results demonstrate that research data was neither over-fitted nor under-fitted, and this shows that our distributed model works well on the data.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2403.05878",
        "abstract url": "https://arxiv.org/abs/2403.05878",
        "title": "Frequency Domain Auto-tuning of Structured LPV Controllers for High-Precision Motion Control",
        "rating": -4,
        "keywords": [
            [
                "CT"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Motion systems are a vital part of many industrial processes. However, meeting the increasingly stringent demands of these systems, especially concerning precision and throughput, requires novel control design methods that can go beyond the capabilities of traditional solutions. Traditional control methods often struggle with the complexity and position-dependent effects inherent in modern motion systems, leading to compromises in performance and a laborious task of controller design. This paper addresses these challenges by introducing a novel structured feedback control auto-tuning approach for multiple-input multiple-output (MIMO) motion systems. By leveraging frequency response function (FRF) estimates and the linear-parameter-varying (LPV) control framework, the proposed approach automates the controller design, while providing local stability and performance guarantees. Key innovations include norm-based magnitude optimization of the sensitivity functions, an automated stability check through a novel extended factorized Nyquist criterion, a modular structured MIMO LPV controller parameterization, and a controller discretization approach which preserves the continuous-time (CT) controller parameterization. The proposed approach is validated through experiments using a state-of-the-art moving-magnet planar actuator prototype.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 4 Figures"
    },
    {
        "paper id": "2403.06069",
        "abstract url": "https://arxiv.org/abs/2403.06069",
        "title": "Implicit Image-to-Image Schrodinger Bridge for CT Super-Resolution and Denoising",
        "rating": -4,
        "keywords": [
            [
                "diffusion",
                "Super-Resolution"
            ],
            [
                "medical",
                "CT"
            ],
            [
                "image restoration"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Conditional diffusion models have gained recognition for their effectiveness in image restoration tasks, yet their iterative denoising process, starting from Gaussian noise, often leads to slow inference speeds. As a promising alternative, the Image-to-Image Schr\u00f6dinger Bridge (I2SB) initializes the generative process from corrupted images and integrates training techniques from conditional diffusion models. In this study, we extended the I2SB method by introducing the Implicit Image-to-Image Schrodinger Bridge (I3SB), transitioning its generative process to a non-Markovian process by incorporating corrupted images in each generative step. This enhancement empowers I3SB to generate images with better texture restoration using a small number of generative steps. The proposed method was validated on CT super-resolution and denoising tasks and outperformed existing methods, including the conditional denoising diffusion probabilistic model (cDDPM) and I2SB, in both visual quality and quantitative metrics. These findings underscore the potential of I3SB in improving medical image restoration by providing fast and accurate generative modeling.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05897",
        "abstract url": "https://arxiv.org/abs/2403.05897",
        "title": "RealNet: A Feature Selection Network with Realistic Synthetic Anomaly for Anomaly Detection",
        "rating": -4.5,
        "keywords": [
            [
                "Diffusion",
                "synthesizing"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "face"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Self-supervised feature reconstruction methods have shown promising advances in industrial image anomaly detection and localization. Despite this progress, these methods still face challenges in synthesizing realistic and diverse anomaly samples, as well as addressing the feature redundancy and pre-training bias of pre-trained feature. In this work, we introduce RealNet, a feature reconstruction network with realistic synthetic anomaly and adaptive feature selection. It is incorporated with three key innovations: First, we propose Strength-controllable Diffusion Anomaly Synthesis (SDAS), a diffusion process-based synthesis strategy capable of generating samples with varying anomaly strengths that mimic the distribution of real anomalous samples. Second, we develop Anomaly-aware Features Selection (AFS), a method for selecting representative and discriminative pre-trained feature subsets to improve anomaly detection performance while controlling computational costs. Third, we introduce Reconstruction Residuals Selection (RRS), a strategy that adaptively selects discriminative residuals for comprehensive identification of anomalous regions across multiple levels of granularity. We assess RealNet on four benchmark datasets, and our results demonstrate significant improvements in both Image AUROC and Pixel AUROC compared to the current state-o-the-art methods. The code, data, and models are available at https://github.com/cnulab/RealNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to CVPR 2024"
    },
    {
        "paper id": "2403.05964",
        "abstract url": "https://arxiv.org/abs/2403.05964",
        "title": "RadCloud: Real-Time High-Resolution Point Cloud Generation Using Low-Cost Radars for Aerial and Ground Vehicles",
        "rating": -5,
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "lidar",
                "radar"
            ],
            [
                "robotics"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this work, we present RadCloud, a novel real time framework for directly obtaining higher-resolution lidar-like 2D point clouds from low-resolution radar frames on resource-constrained platforms commonly used in unmanned aerial and ground vehicles (UAVs and UGVs, respectively); such point clouds can then be used for accurate environmental mapping, navigating unknown environments, and other robotics tasks. While high-resolution sensing using radar data has been previously reported, existing methods cannot be used on most UAVs, which have limited computational power and energy; thus, existing demonstrations focus on offline radar processing. RadCloud overcomes these challenges by using a radar configuration with 1/4th of the range resolution and employing a deep learning model with 2.25x fewer parameters. Additionally, RadCloud utilizes a novel chirp-based approach that makes obtained point clouds resilient to rapid movements (e.g., aggressive turns or spins), which commonly occur during UAV flights. In real-world experiments, we demonstrate the accuracy and applicability of RadCloud on commercially available UAVs and UGVs, with off-the-shelf radar platforms on-board.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "$\u00a9$ 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2403.05932",
        "abstract url": "https://arxiv.org/abs/2403.05932",
        "title": "Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis",
        "rating": -6,
        "keywords": [
            [
                "3D"
            ],
            [
                "CT"
            ],
            [
                "remote sensing"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Significant uncertainty in climate prediction and cloud physics is tied to observational gaps relating to shallow scattered clouds. Addressing these challenges requires remote sensing of their three-dimensional (3D) heterogeneous volumetric scattering content. This calls for passive scattering computed tomography (CT). We design a learning-based model (ProbCT) to achieve CT of such clouds, based on noisy multi-view spaceborne images. ProbCT infers - for the first time - the posterior probability distribution of the heterogeneous extinction coefficient, per 3D location. This yields arbitrary valuable statistics, e.g., the 3D field of the most probable extinction and its uncertainty. ProbCT uses a neural-field representation, making essentially real-time inference. ProbCT undergoes supervised training by a new labeled multi-class database of physics-based volumetric fields of clouds and their corresponding images. To improve out-of-distribution inference, we incorporate self-supervised learning through differential rendering. We demonstrate the approach in simulations and on real-world data, and indicate the relevance of 3D recovery and uncertainty to precipitation and renewable energy.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05809",
        "abstract url": "https://arxiv.org/abs/2403.05809",
        "title": "Shallow ReLU neural networks and finite elements",
        "rating": -10,
        "keywords": [],
        "abstract": "We point out that (continuous or discontinuous) piecewise linear functions on a convex polytope mesh can be represented by two-hidden-layer ReLU neural networks in a weak sense. In addition, the numbers of neurons of the two hidden layers required to weakly represent are accurately given based on the numbers of polytopes and hyperplanes involved in this mesh. The results naturally hold for constant and linear finite element functions. Such weak representation establishes a bridge between shallow ReLU neural networks and finite element functions, and leads to a perspective for analyzing approximation capability of ReLU neural networks in $L^p$ norm via finite element functions. Moreover, we discuss the strict representation for tensor finite element functions via the recent tensor neural networks.",
        "subjects": [
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05811",
        "abstract url": "https://arxiv.org/abs/2403.05811",
        "title": "Near Minimax-Optimal Distributional Temporal Difference Algorithms and The Freedman Inequality in Hilbert Spaces",
        "rating": -10,
        "keywords": [],
        "abstract": "Distributional reinforcement learning (DRL) has achieved empirical success in various domains. One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\u03b7^\u03c0$ for a given policy $\u03c0$. The distributional temporal difference (TD) algorithm has been accordingly proposed, which is an extension of the temporal difference algorithm in the classic RL literature. In the tabular case, \\citet{rowland2018analysis} and \\citet{rowland2023analysis} proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference algorithm (CTD) and quantile temporal difference algorithm (QTD), respectively. In this paper, we go a step further and analyze the finite-sample performance of distributional TD. To facilitate theoretical analysis, we propose a non-parametric distributional TD algorithm (NTD). For a $\u03b3$-discounted infinite-horizon tabular Markov decision process, we show that for NTD we need $\\tilde{O}\\left(\\frac{1}{\\varepsilon^{2p}(1-\u03b3)^{2p+1}}\\right)$ iterations to achieve an $\\varepsilon$-optimal estimator with high probability, when the estimation error is measured by the $p$-Wasserstein distance. This sample complexity bound is minimax optimal (up to logarithmic factors) in the case of the $1$-Wasserstein distance. To achieve this, we establish a novel Freedman's inequality in Hilbert spaces, which would be of independent interest. In addition, we revisit CTD, showing that the same non-asymptotic convergence bounds hold for CTD in the case of the $p$-Wasserstein distance.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05816",
        "abstract url": "https://arxiv.org/abs/2403.05816",
        "title": "LEVA: Using Large Language Models to Enhance Visual Analytics",
        "rating": -10,
        "keywords": [],
        "abstract": "Visual analytics supports data analysis tasks within complex domain problems. However, due to the richness of data types, visual designs, and interaction designs, users need to recall and process a significant amount of information when they visually analyze data. These challenges emphasize the need for more intelligent visual analytics methods. Large language models have demonstrated the ability to interpret various forms of textual data, offering the potential to facilitate intelligent support for visual analytics. We propose LEVA, a framework that uses large language models to enhance users' VA workflows at multiple stages: onboarding, exploration, and summarization. To support onboarding, we use large language models to interpret visualization designs and view relationships based on system specifications. For exploration, we use large language models to recommend insights based on the analysis of system status and data to facilitate mixed-initiative exploration. For summarization, we present a selective reporting strategy to retrace analysis history through a stream visualization and generate insight reports with the help of large language models. We demonstrate how LEVA can be integrated into existing visual analytics systems. Two usage scenarios and a user study suggest that LEVA effectively aids users in conducting visual analytics.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to IEEE TVCG 2024"
    },
    {
        "paper id": "2403.05826",
        "abstract url": "https://arxiv.org/abs/2403.05826",
        "title": "Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space-air-ground Integrated Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Space-air-ground integrated networks (SAGINs) enable worldwide network coverage beyond geographical limitations for users to access ubiquitous intelligence services. {\\color{black}Facing global coverage and complex environments in SAGINs, edge intelligence can provision AI agents based on large language models (LLMs) for users via edge servers at ground base stations (BSs) or cloud data centers relayed by satellites.} As LLMs with billions of parameters are pre-trained on vast datasets, LLM agents have few-shot learning capabilities, e.g., chain-of-thought (CoT) prompting for complex tasks, which are challenged by limited resources in SAGINs. In this paper, we propose a joint caching and inference framework for edge intelligence to provision sustainable and ubiquitous LLM agents in SAGINs. We introduce \"cached model-as-a-resource\" for offering LLMs with limited context windows and propose a novel optimization framework, i.e., joint model caching and inference, to utilize cached model resources for provisioning LLM agent services along with communication, computing, and storage resources. We design \"age of thought\" (AoT) considering the CoT prompting of LLMs, and propose the least AoT cached model replacement algorithm for optimizing the provisioning cost. We propose a deep Q-network-based modified second-bid (DQMSB) auction to incentivize these network operators, which can enhance allocation efficiency while guaranteeing strategy-proofness and free from adverse selection.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05832",
        "abstract url": "https://arxiv.org/abs/2403.05832",
        "title": "Research progress on intelligent optimization techniques for energy-efficient design of ship hull forms",
        "rating": -10,
        "keywords": [],
        "abstract": "The design optimization of ship hull form based on hydrodynamics theory and simulation-based design (SBD) technologies generally considers ship performance and energy efficiency performance as the design objective, which plays an important role in smart design and manufacturing of green ship. An optimal design of sustainable energy system requires multidisciplinary tools to build ships with the least resistance and energy consumption. Through a systematic approach, this paper presents the research progress of energy-efficient design of ship hull forms based on intelligent optimization techniques. We discuss different methods involved in the optimization procedure, especially the latest developments of intelligent optimization algorithms and surrogate models. Moreover, current development trends and technical challenges of multidisciplinary design optimization and surrogate-assisted evolutionary algorithms for ship design are further analyzed. We explore the gaps and potential future directions, so as to paving the way towards the design of the next generation of more energy-efficient ship hull form.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "30 pages, 8 figures"
    },
    {
        "paper id": "2403.05834",
        "abstract url": "https://arxiv.org/abs/2403.05834",
        "title": "Enhancing Expressiveness in Dance Generation via Integrating Frequency and Music Style Information",
        "rating": -10,
        "keywords": [],
        "abstract": "Dance generation, as a branch of human motion generation, has attracted increasing attention. Recently, a few works attempt to enhance dance expressiveness, which includes genre matching, beat alignment, and dance dynamics, from certain aspects. However, the enhancement is quite limited as they lack comprehensive consideration of the aforementioned three factors. In this paper, we propose ExpressiveBailando, a novel dance generation method designed to generate expressive dances, concurrently taking all three factors into account. Specifically, we mitigate the issue of speed homogenization by incorporating frequency information into VQ-VAE, thus improving dance dynamics. Additionally, we integrate music style information by extracting genre- and beat-related features with a pre-trained music model, hence achieving improvements in the other two factors. Extensive experimental results demonstrate that our proposed method can generate dances with high expressiveness and outperforms existing methods both qualitatively and quantitatively.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05842",
        "abstract url": "https://arxiv.org/abs/2403.05842",
        "title": "Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance",
        "rating": -10,
        "keywords": [],
        "abstract": "With the blossom of deep learning models and services, it has become an imperative concern to safeguard the valuable model parameters from being stolen. Watermarking is considered an important tool for ownership verification. However, current watermarking schemes are customized for different models and tasks, hard to be integrated as an integrated intellectual protection service. We propose Hufu, a modality-agnostic watermarking system for pre-trained Transformer-based models, relying on the permutation equivariance property of Transformers. Hufu embeds watermark by fine-tuning the pre-trained model on a set of data samples specifically permuted, and the embedded model essentially contains two sets of weights -- one for normal use and the other for watermark extraction which is triggered on permuted inputs. The permutation equivariance ensures minimal interference between these two sets of model weights and thus high fidelity on downstream tasks. Since our method only depends on the model itself, it is naturally modality-agnostic, task-independent, and trigger-sample-free. Extensive experiments on the state-of-the-art vision Transformers, BERT, and GPT2 have demonstrated Hufu's superiority in meeting watermarking requirements including effectiveness, efficiency, fidelity, and robustness, showing its great potential to be deployed as a uniform ownership verification service for various Transformers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05855",
        "abstract url": "https://arxiv.org/abs/2403.05855",
        "title": "Assessing User Apprehensions About Mixed Reality Artifacts and Applications: The Mixed Reality Concerns (MRC) Questionnaire",
        "rating": -10,
        "keywords": [],
        "abstract": "Current research in Mixed Reality (MR) presents a wide range of novel use cases for blending virtual elements with the real world. This yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. While offering many potential advantages, MR technologies introduce new security, safety, and privacy challenges. Thus, it is relevant to understand users' apprehensions towards MR technologies, ranging from security concerns to social acceptance. To address this challenge, we present the Mixed Reality Concerns (MRC) Questionnaire, designed to assess users' concerns towards MR artifacts and applications systematically. The development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. The MRC Questionnaire offers a new method of assessing users' critical opinions to compare and assess novel MR artifacts and applications regarding security, privacy, social implications, and trust.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05860",
        "abstract url": "https://arxiv.org/abs/2403.05860",
        "title": "On the equivalence of direct and indirect data-driven predictive control approaches",
        "rating": -10,
        "keywords": [],
        "abstract": "Recently, several direct Data-Driven Predictive Control (DDPC) methods have been proposed, advocating the possibility of designing predictive controllers from historical input-output trajectories without the need to identify a model. In this work, we show that these approaches are equivalent to an indirect approach. Reformulating the direct methods in terms of estimated parameters and covariance matrices allows us to give new insights into how they work in comparison with, for example, Subspace Predictive Control (SPC). In particular, we show that for unconstrained problems the direct methods are equivalent to SPC with a reduced weight on the tracking cost. Via a numerical experiment, motivated by the reformulation, we also illustrate why the performance of direct DDPC methods with fixed regularization tends to degrade as the number of training samples increases.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2403.05861",
        "abstract url": "https://arxiv.org/abs/2403.05861",
        "title": "DeepVM: Integrating Spot and On-Demand VMs for Cost-Efficient Deep Learning Clusters in the Cloud",
        "rating": -10,
        "keywords": [],
        "abstract": "Distributed Deep Learning (DDL), as a paradigm, dictates the use of GPU-based clusters as the optimal infrastructure for training large-scale Deep Neural Networks (DNNs). However, the high cost of such resources makes them inaccessible to many users. Public cloud services, particularly Spot Virtual Machines (VMs), offer a cost-effective alternative, but their unpredictable availability poses a significant challenge to the crucial checkpointing process in DDL. To address this, we introduce DeepVM, a novel solution that recommends cost-effective cluster configurations by intelligently balancing the use of Spot and On-Demand VMs. DeepVM leverages a four-stage process that analyzes instance performance using the FLOPP (FLoating-point Operations Per Price) metric, performs architecture-level analysis with linear programming, and identifies the optimal configuration for the user-specific needs. Extensive simulations and real-world deployments in the AWS environment demonstrate that DeepVM consistently outperforms other policies, reducing training costs and overall makespan. By enabling cost-effective checkpointing with Spot VMs, DeepVM opens up DDL to a wider range of users and facilitates a more efficient training of complex DNNs.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "14 pages, 8 figures"
    },
    {
        "paper id": "2403.05868",
        "abstract url": "https://arxiv.org/abs/2403.05868",
        "title": "Toward Understanding Key Estimation in Learning Robust Humanoid Locomotion",
        "rating": -10,
        "keywords": [],
        "abstract": "Accurate state estimation plays a critical role in ensuring the robust control of humanoid robots, particularly in the context of learning-based control policies for legged robots. However, there is a notable gap in analytical research concerning estimations. Therefore, we endeavor to further understand how various types of estimations influence the decision-making processes of policies. In this paper, we provide quantitative insight into the effectiveness of learned state estimations, employing saliency analysis to identify key estimation variables and optimize their combination for humanoid locomotion tasks. Evaluations assessing tracking precision and robustness are conducted on comparative groups of policies with varying estimation combinations in both simulated and real-world environments. Results validated that the proposed policy is capable of crossing the sim-to-real gap and demonstrating superior performance relative to alternative policy configurations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05870",
        "abstract url": "https://arxiv.org/abs/2403.05870",
        "title": "Channel Estimation for Stacked Intelligent Metasurface-Assisted Wireless Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Emerging technologies, such as holographic multiple-input multiple-output (HMIMO) and stacked intelligent metasurface (SIM), are driving the development of wireless communication systems. Specifically, the SIM is physically constructed by stacking multiple layers of metasurfaces and has an architecture similar to an artificial neural network (ANN), which can flexibly manipulate the electromagnetic waves that propagate through it at the speed of light. This architecture enables the SIM to achieve HMIMO precoding and combining in the wave domain, thus significantly reducing the hardware cost and energy consumption. In this letter, we investigate the channel estimation problem in SIM-assisted multi-user HMIMO communication systems. Since the number of antennas at the base station (BS) is much smaller than the number of meta-atoms per layer of the SIM, it is challenging to acquire the channel state information (CSI) in SIM-assisted multi-user systems. To address this issue, we collect multiple copies of the uplink pilot signals that propagate through the SIM. Furthermore, we leverage the array geometry to identify the subspace that spans arbitrary spatial correlation matrices. Based on partial CSI about the channel statistics, a pair of subspace-based channel estimators are proposed. Additionally, we compute the mean square error (MSE) of the proposed channel estimators and optimize the phase shifts of the SIM to minimize the MSE. Numerical results are illustrated to analyze the effectiveness of the proposed channel estimation schemes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages, 3 figures, accepted by IEEE WCL"
    },
    {
        "paper id": "2403.05876",
        "abstract url": "https://arxiv.org/abs/2403.05876",
        "title": "The rise and fall of WallStreetBets: social roles and opinion leaders across the GameStop saga",
        "rating": -10,
        "keywords": [],
        "abstract": "Nowadays human interactions largely take place on social networks, with online users' behavior often falling into a few general typologies or \"social roles\". Among these, opinion leaders are of crucial importance as they have the ability to spread an idea or opinion on a large scale across the network, with possible tangible consequences in the real world. In this work we extract and characterize the different social roles of users within the Reddit WallStreetBets community, around the time of the GameStop short squeeze of January 2021 -- when a handful of committed users led the whole community to engage in a large and risky financial operation. We identify the profiles of both average users and of relevant outliers, including opinion leaders, using an iterative, semi-supervised classification algorithm, which allows us to discern the characteristics needed to play a particular social role. The key features of opinion leaders are large risky investments and constant updates on a single stock, which allowed them to attract a large following and, in the case of GameStop, ignite the interest of the community. Finally, we observe a substantial change in the behavior and attitude of users after the short squeeze event: no new opinion leaders are found and the community becomes less focused on investments. Overall, this work sheds light on the users' roles and dynamics that led to the GameStop short squeeze, while also suggesting why WallStreetBets no longer wielded such large influence on financial markets, in the aftermath of this event.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "main text: 15 pages, 4 figures. supplementary materials: 15 pages, 12 figures"
    },
    {
        "paper id": "2403.05877",
        "abstract url": "https://arxiv.org/abs/2403.05877",
        "title": "A Performance Analysis of Basin Hopping Compared to Established Metaheuristics for Global Optimization",
        "rating": -10,
        "keywords": [],
        "abstract": "During the last decades many metaheuristics for global numerical optimization have been proposed. Among them, Basin Hopping is very simple and straightforward to implement, although rarely used outside its original Physical Chemistry community. In this work, our aim is to compare Basin Hopping, and two population variants of it, with readily available implementations of the well known metaheuristics Differential Evolution, Particle Swarm Optimization, and Covariance Matrix Adaptation Evolution Strategy. We perform numerical experiments using the IOH profiler environment with the BBOB test function set and two difficult real-world problems. The experiments were carried out in two different but complementary ways: by measuring the performance under a fixed budget of function evaluations and by considering a fixed target value. The general conclusion is that Basin Hopping and its newly introduced population variant are almost as good as Covariance Matrix Adaptation on the synthetic benchmark functions and better than it on the two hard cluster energy minimization problems. Thus, the proposed analyses show that Basin Hopping can be considered a good candidate for global numerical optimization problems along with the more established metaheuristics, especially if one wants to obtain quick and reliable results on an unknown problem.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "32 pages, 7 figures"
    },
    {
        "paper id": "2403.05893",
        "abstract url": "https://arxiv.org/abs/2403.05893",
        "title": "Estimating the Weight Enumerators of Reed-Muller Codes via Sampling",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper develops an algorithmic approach for obtaining estimates of the weight enumerators of Reed-Muller (RM) codes. Our algorithm is based on a technique for estimating the partition functions of spin systems, which in turn employs a sampler that produces codewords according to a suitably defined Gibbs distribution. We apply our method to moderate-blocklength RM codes and derive approximate values of their weight enumerators. We observe that the rates of the weight enumerator estimates returned by our method are close to the true rates when these rates are either known or computable by brute-force search; in other cases, our computations provide provably robust estimates. As a byproduct, our sampling algorithm also allows us to obtain estimates of the weight spectra of RM codes. We illustrate our methods by providing estimates of the hitherto unknown weight enumerators of the RM$(11,5)$ code and the exact weight spectra of the RM$(10,3)$ and RM$(10,4)$ codes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "8 pages, 1 figure, 4 tables; submitted to the IEEE for possible publication. arXiv admin note: substantial text overlap with arXiv:2309.08907"
    },
    {
        "paper id": "2403.05899",
        "abstract url": "https://arxiv.org/abs/2403.05899",
        "title": "Online Identification of Stochastic Continuous-Time Wiener Models Using Sampled Data",
        "rating": -10,
        "keywords": [],
        "abstract": "It is well known that ignoring the presence of stochastic disturbances in the identification of stochastic Wiener models leads to asymptotically biased estimators. On the other hand, optimal statistical identification, via likelihood-based methods, is sensitive to the assumptions on the data distribution and is usually based on relatively complex sequential Monte Carlo algorithms. We develop a simple recursive online estimation algorithm based on an output-error predictor, for the identification of continuous-time stochastic parametric Wiener models through stochastic approximation. The method is applicable to generic model parameterizations and, as demonstrated in the numerical simulation examples, it is robust with respect to the assumptions on the spectrum of the disturbance process.",
        "subjects": [
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05911",
        "abstract url": "https://arxiv.org/abs/2403.05911",
        "title": "Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "Imagine if AI decision-support tools not only complemented our ability to make accurate decisions, but also improved our skills, boosted collaboration, and elevated the joy we derive from our tasks. Despite the potential to optimize a broad spectrum of such human-centric objectives, the design of current AI tools remains focused on decision accuracy alone. We propose offline reinforcement learning (RL) as a general approach for modeling human-AI decision-making to optimize human-AI interaction for diverse objectives. RL can optimize such objectives by tailoring decision support, providing the right type of assistance to the right person at the right time. We instantiated our approach with two objectives: human-AI accuracy on the decision-making task and human learning about the task and learned decision support policies from previous human-AI interaction data. We compared the optimized policies against several baselines in AI-assisted decision-making. Across two experiments (N=316 and N=964), our results demonstrated that people interacting with policies optimized for accuracy achieve significantly better accuracy -- and even human-AI complementarity -- compared to those interacting with any other type of AI support. Our results further indicated that human learning was more difficult to optimize than accuracy, with participants who interacted with learning-optimized policies showing significant learning improvement only at times. Our research (1) demonstrates offline RL to be a promising approach to model human-AI decision-making, leading to policies that may optimize human-centric objectives and provide novel insights about the AI-assisted decision-making space, and (2) emphasizes the importance of considering human-centric objectives beyond decision accuracy in AI-assisted decision-making, opening up the novel research challenge of optimizing human-AI interaction for such objectives.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05925",
        "abstract url": "https://arxiv.org/abs/2403.05925",
        "title": "BEACON: A Bayesian Evolutionary Approach for Counterexample Generation of Control Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "The rigorous safety verification of control systems in critical applications is essential, given their increasing complexity and integration into everyday life. Simulation-based falsification approaches play a pivotal role in the safety verification of control systems, particularly within critical applications. These methods systematically explore the operational space of systems to identify configurations that result in violations of safety specifications. However, the effectiveness of traditional simulation-based falsification is frequently limited by the high dimensionality of the search space and the substantial computational resources required for exhaustive exploration. This paper presents BEACON, a novel framework that enhances the falsification process through a combination of Bayesian optimization and covariance matrix adaptation evolutionary strategy. By exploiting quantitative metrics to evaluate how closely a system adheres to safety specifications, BEACON advances the state-of-the-art in testing methodologies. It employs a model-based test point selection approach, designed to facilitate exploration across dynamically evolving search zones to efficiently uncover safety violations. Our findings demonstrate that BEACON not only locates a higher percentage of counterexamples compared to standalone BO but also achieves this with significantly fewer simulations than required by CMA-ES, highlighting its potential to optimize the verification process of control systems. This framework offers a promising direction for achieving thorough and resource-efficient safety evaluations, ensuring the reliability of control systems in critical applications.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05928",
        "abstract url": "https://arxiv.org/abs/2403.05928",
        "title": "Local Computing By Partial Quantifier Elimination",
        "rating": -10,
        "keywords": [],
        "abstract": "Localization of computations plays a crucial role in solving hard problems efficiently. We will refer to the techniques implementing such localization as ${\\mathit local}$ ${\\mathit computing}$. We relate local computing with $\\mathit{partial}$ $\\mathit{quantifier}$ $\\mathit{elimination}$ (PQE). The latter is a generalization of regular quantifier elimination where one can take a $\\mathit{part}$ of the formula out of the scope of quantifiers. The objective of this paper is to show that PQE can be viewed as a language of local computing and hence building efficient PQE solvers is of great importance. We describe application of local computing by PQE to three different problems of hardware verification: property generation, equivalence checking and model checking. Besides, we discuss using local computing by PQE for SAT solving. Finally, we relate PQE and interpolation, a form of local computing.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05939",
        "abstract url": "https://arxiv.org/abs/2403.05939",
        "title": "A Novel Refactoring and Semantic Aware Abstract Syntax Tree Differencing Tool and a Benchmark for Evaluating the Accuracy of Diff Tools",
        "rating": -10,
        "keywords": [],
        "abstract": "Software undergoes constant changes to support new requirements, address bugs, enhance performance, and ensure maintainability. Thus, developers spend a great portion of their workday trying to understand and review the code changes of their teammates. Abstract Syntax Tree (AST) diff tools were developed to overcome the limitations of line-based diff tools, which are used by the majority of developers. Despite the notable improvements brought by AST diff tools in understanding complex changes, they still suffer from serious limitations, such as (1) lacking multi-mapping support, (2) matching semantically incompatible AST nodes, (3) ignoring language clues to guide the matching process, (4) lacking refactoring awareness, and (5) lacking commit-level diff support. We propose a novel AST diff tool based on RefactoringMiner that resolves all aforementioned limitations. First, we improved RefactoringMiner to increase its statement mapping accuracy, and then we developed an algorithm that generates AST diff for a given commit or pull request based on the refactoring instances and pairs of matched program element declarations provided by RefactoringMiner. To evaluate the accuracy of our tool and compare it with the state-of-the-art tools, we created the first benchmark of AST node mappings, including 800 bug-fixing commits and 188 refactoring commits. Our evaluation showed that our tool achieved a considerably higher precision and recall, especially for refactoring commits, with an execution time that is comparable with that of the faster tools.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "ACM Transactions on Software Engineering and Methodology (TOSEM)"
    },
    {
        "paper id": "2403.05957",
        "abstract url": "https://arxiv.org/abs/2403.05957",
        "title": "What Motivates People to Trust 'AI' Systems?",
        "rating": -10,
        "keywords": [],
        "abstract": "Companies, organizations, and governments across the world are eager to employ so-called 'AI' (artificial intelligence) technology in a broad range of different products and systems. The promise of this cause c\u00e9l\u00e8bre is that the technologies offer increased automation, efficiency, and productivity - meanwhile, critics sound warnings of illusions of objectivity, pollution of our information ecosystems, and reproduction of biases and discriminatory outcomes. This paper explores patterns of motivation in the general population for trusting (or distrusting) 'AI' systems. Based on a survey with more than 450 respondents from more than 30 different countries (and about 3000 open text answers), this paper presents a qualitative analysis of current opinions and thoughts about 'AI' technology, focusing on reasons for trusting such systems. The different reasons are synthesized into four rationales (lines of reasoning): the Human favoritism rationale, the Black box rationale, the OPSEC rationale, and the 'Wicked world, tame computers' rationale. These rationales provide insights into human motivation for trusting 'AI' which could be relevant for developers and designers of such systems, as well as for scholars developing measures of trust in technological systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05972",
        "abstract url": "https://arxiv.org/abs/2403.05972",
        "title": "C3D: Cascade Control with Change Point Detection and Deep Koopman Learning for Autonomous Surface Vehicles",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we discuss the development and deployment of a robust autonomous system capable of performing various tasks in the maritime domain under unknown dynamic conditions. We investigate a data-driven approach based on modular design for ease of transfer of autonomy across different maritime surface vessel platforms. The data-driven approach alleviates issues related to a priori identification of system models that may become deficient under evolving system behaviors or shifting, unanticipated, environmental influences. Our proposed learning-based platform comprises a deep Koopman system model and a change point detector that provides guidance on domain shifts prompting relearning under severe exogenous and endogenous perturbations. Motion control of the autonomous system is achieved via an optimal controller design. The Koopman linearized model naturally lends itself to a linear-quadratic regulator (LQR) control design. We propose the C3D control architecture Cascade Control with Change Point Detection and Deep Koopman Learning. The framework is verified in station keeping task on an ASV in both simulation and real experiments. The approach achieved at least 13.9 percent improvement in mean distance error in all test cases compared to the methods that do not consider system changes.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2403.05974",
        "abstract url": "https://arxiv.org/abs/2403.05974",
        "title": "Deep Reinforcement Learning Enhanced Rate-Splitting Multiple Access for Interference Mitigation",
        "rating": -10,
        "keywords": [],
        "abstract": "This study explores the application of the rate-splitting multiple access (RSMA) technique, vital for interference mitigation in modern communication systems. It investigates the use of precoding methods in RSMA, especially in complex multiple-antenna interference channels, employing deep reinforcement learning. The aim is to optimize precoders and power allocation for common and private data streams involving multiple decision-makers. A multi-agent deep deterministic policy gradient (MADDPG) framework is employed to address this complexity, where decentralized agents collectively learn to optimize actions in a continuous policy space. We also explore the challenges posed by imperfect channel side information at the transmitter. Additionally, decoding order estimation is addressed to determine the optimal decoding sequence for common and private data sequences. Simulation results demonstrate the effectiveness of the proposed RSMA method based on MADDPG, achieving the upper bound in single-antenna scenarios and closely approaching theoretical limits in multi-antenna scenarios. Comparative analysis shows superiority over other techniques such as MADDPG without rate-splitting, maximal ratio transmission (MRT), zero-forcing (ZF), and leakage-based precoding methods. These findings highlight the potential of deep reinforcement learning-driven RSMA in reducing interference and enhancing system performance in communication systems.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05986",
        "abstract url": "https://arxiv.org/abs/2403.05986",
        "title": "Integrating Static Code Analysis Toolchains",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper proposes an approach for a tool-agnostic and heterogeneous static code analysis toolchain in combination with an exchange format. This approach enhances both traceability and comparability of analysis results. State of the art toolchains support features for either test execution and build automation or traceability between tests, requirements and design information. Our approach combines all those features and extends traceability to the source code level, incorporating static code analysis. As part of our approach we introduce the \"ASSUME Static Code Analysis tool exchange format\" that facilitates the comparability of different static code analysis results. We demonstrate how this approach enhances the usability and efficiency of static code analysis in a development process. On the one hand, our approach enables the exchange of results and evaluations between static code analysis tools. On the other hand, it enables a complete traceability between requirements, designs, implementation, and the results of static code analysis. Within our approach we also propose an OSLC specification for static code analysis tools and an OSLC communication framework.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Published in IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)"
    },
    {
        "paper id": "2403.05994",
        "abstract url": "https://arxiv.org/abs/2403.05994",
        "title": "Evaluation and improvement of ETSI ITS Contention-Based Forwarding (CBF) of warning messages in highway scenarios",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper evaluates the performance of the ETSI Contention-Based Forwarding (CBF) GeoNetworking protocol for distributing warning messages in highway scenarios, including its interaction with the Decentralized Congestion Control (DCC) mechanism. Several shortcomings of the standard ETSI CBF algorithm are identified, and we propose different solutions to these problems, which are able to reduce the number of transmissions by an order of magnitude, while reducing the message end-to-end delay and providing a reliability close to 100% in a large area of interest.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2403.05995",
        "abstract url": "https://arxiv.org/abs/2403.05995",
        "title": "Efficient Fault Detection and Categorization in Electrical Distribution Systems Using Hessian Locally Linear Embedding on Measurement Data",
        "rating": -10,
        "keywords": [],
        "abstract": "Faults on electrical power lines could severely compromise both the reliability and safety of power systems, leading to unstable power delivery and increased outage risks. They pose significant safety hazards, necessitating swift detection and mitigation to maintain electrical infrastructure integrity and ensure continuous power supply. Hence, accurate detection and categorization of electrical faults are pivotal for optimized power system maintenance and operation. In this work, we propose a novel approach for detecting and categorizing electrical faults using the Hessian locally linear embedding (HLLE) technique and subsequent clustering with t-SNE (t-distributed stochastic neighbor embedding) and Gaussian mixture model (GMM). First, we employ HLLE to transform high-dimensional (HD) electrical data into low-dimensional (LD) embedding coordinates. This technique effectively captures the inherent variations and patterns in the data, enabling robust feature extraction. Next, we perform the Mann-Whitney U test based on the feature space of the embedding coordinates for fault detection. This statistical approach allows us to detect electrical faults providing an efficient means of system monitoring and control. Furthermore, to enhance fault categorization, we employ t-SNE with GMM to cluster the detected faults into various categories. To evaluate the performance of the proposed method, we conduct extensive simulations on an electrical system integrated with solar farm. Our results demonstrate that the proposed approach exhibits effective fault detection and clustering across a range of fault types with different variations of the same fault. Overall, this research presents an effective methodology for robust fault detection and categorization in electrical systems, contributing to the advancement of fault management practices and the prevention of system failures.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06007",
        "abstract url": "https://arxiv.org/abs/2403.06007",
        "title": "Invariant Properties of Linear-Iterative Distributed Averaging Algorithms and Application to Error Detection",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider the problem of average consensus in a distributed system comprising a set of nodes that can exchange information among themselves. We focus on a class of algorithms for solving such a problem whereby each node maintains a state and updates it iteratively as a linear combination of the states maintained by its in-neighbors, i.e., nodes from which it receives information directly. Averaging algorithms within this class can be thought of as discrete-time linear time-varying systems without external driving inputs and whose state matrix is column stochastic. As a result, the algorithms exhibit a global invariance property in that the sum of the state variables remains constant at all times. In this paper, we report on another invariance property for the aforementioned class of averaging algorithms. This property is local to each node and reflects the conservation of certain quantities capturing an aggregate of all the values received by a node from its in-neighbors and all the values sent by said node to its out-neighbors (i.e., nodes to which it sends information directly) throughout the execution of the averaging algorithm. We show how this newly-discovered invariant can be leveraged for detecting errors while executing the averaging algorithm.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "7 pages, this is an expanded version of a conference paper that appears in 2024 European Control Conference"
    },
    {
        "paper id": "2403.06015",
        "abstract url": "https://arxiv.org/abs/2403.06015",
        "title": "Grafting: Making Random Forests Consistent",
        "rating": -10,
        "keywords": [],
        "abstract": "Despite their performance and widespread use, little is known about the theory of Random Forests. A major unanswered question is whether, or when, the Random Forest algorithm is consistent. The literature explores various variants of the classic Random Forest algorithm to address this question and known short-comings of the method. This paper is a contribution to this literature. Specifically, the suitability of grafting consistent estimators onto a shallow CART is explored. It is shown that this approach has a consistency guarantee and performs well in empirical settings.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06016",
        "abstract url": "https://arxiv.org/abs/2403.06016",
        "title": "End-to-end solution for linked open data query logs analytics",
        "rating": -10,
        "keywords": [],
        "abstract": "Important advances in pillar domains are derived from exploiting query-logs which represents users interest and preferences. Deep understanding of users provides useful knowledge which can influence strongly decision-making. In this work, we want to extract valuable information from Linked Open Data (LOD) query-logs. LOD logs have experienced significant growth due to the large exploitation of LOD datasets. However, exploiting these logs is a difficult task because of their complex structure. Moreover, these logs suffer from many risks related to their Quality and Provenance, impacting their trust. To tackle these issues, we start by clearly defining the ecosystem of LOD query-logs. Then, we provide an end-to-end solution to exploit these logs. At the end, real LOD logs are used and a set of experiments are conducted to validate the proposed solution.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06021",
        "abstract url": "https://arxiv.org/abs/2403.06021",
        "title": "Hierarchical Query Classification in E-commerce Search",
        "rating": -10,
        "keywords": [],
        "abstract": "E-commerce platforms typically store and structure product information and search data in a hierarchy. Efficiently categorizing user search queries into a similar hierarchical structure is paramount in enhancing user experience on e-commerce platforms as well as news curation and academic research. The significance of this task is amplified when dealing with sensitive query categorization or critical information dissemination, where inaccuracies can lead to considerable negative impacts. The inherent complexity of hierarchical query classification is compounded by two primary challenges: (1) the pronounced class imbalance that skews towards dominant categories, and (2) the inherent brevity and ambiguity of search queries that hinder accurate classification. To address these challenges, we introduce a novel framework that leverages hierarchical information through (i) enhanced representation learning that utilizes the contrastive loss to discern fine-grained instance relationships within the hierarchy, called ''instance hierarchy'', and (ii) a nuanced hierarchical classification loss that attends to the intrinsic label taxonomy, named ''label hierarchy''. Additionally, based on our observation that certain unlabeled queries share typographical similarities with labeled queries, we propose a neighborhood-aware sampling technique to intelligently select these unlabeled queries to boost the classification performance. Extensive experiments demonstrate that our proposed method is better than state-of-the-art (SOTA) on the proprietary Amazon dataset, and comparable to SOTA on the public datasets of Web of Science and RCV1-V2. These results underscore the efficacy of our proposed solution, and pave the path toward the next generation of hierarchy-aware query classification systems.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Published at: the ACM Web Conference 2024 in the industry track (WWW'24)"
    },
    {
        "paper id": "2403.06032",
        "abstract url": "https://arxiv.org/abs/2403.06032",
        "title": "Matrix Concentration Inequalities for Sensor Selection",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we address the problem of sensor selection for state estimation via Kalman filtering. We consider a linear time-invariant (LTI) dynamical system subject to process and measurement noise, where the sensors we use to perform state estimation are randomly drawn according to a sampling with replacement policy. Since our selection of sensors is randomly chosen, the estimation error covariance of the Kalman filter is also a stochastic quantity. Fortunately, concentration inequalities (CIs) for the estimation error covariance allow us to gauge the estimation performance we intend to achieve when our sensors are randomly drawn with replacement. To obtain a non-trivial improvement on existing CIs for the estimation error covariance, we first present novel matrix CIs for a sum of independent and identically-distributed (i.i.d.) and positive semi-definite (p.s.d.) random matrices, whose support is finite. Next, we show that our guarantees generalize an existing matrix CI. Also, we show that our generalized guarantees require significantly fewer number of sampled sensors to be applicable. Lastly, we show through a numerical study that our guarantees significantly outperform existing ones in terms of their ability to bound (in the semi-definite sense) the steady-state estimation error covariance of the Kalman filter.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06034",
        "abstract url": "https://arxiv.org/abs/2403.06034",
        "title": "Content Moderation Justice and Fairness on Social Media: Comparisons Across Different Contexts and Platforms",
        "rating": -10,
        "keywords": [],
        "abstract": "Social media users may perceive moderation decisions by the platform differently, which can lead to frustration and dropout. This study investigates users' perceived justice and fairness of online moderation decisions when they are exposed to various illegal versus legal scenarios, retributive versus restorative moderation strategies, and user-moderated versus commercially moderated platforms. We conduct an online experiment on 200 American social media users of Reddit and Twitter. Results show that retributive moderation delivers higher justice and fairness for commercially moderated than for user-moderated platforms in illegal violations; restorative moderation delivers higher fairness for legal violations than illegal ones. We discuss the opportunities for platform policymaking to improve moderation system design.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted by CHI LBW 2024"
    },
    {
        "paper id": "2403.06036",
        "abstract url": "https://arxiv.org/abs/2403.06036",
        "title": "Deciphering Crypto Twitter",
        "rating": -10,
        "keywords": [],
        "abstract": "Cryptocurrency is a fast-moving space, with a continuous influx of new projects every year. However, an increasing number of incidents in the space, such as hacks and security breaches, threaten the growth of the community and the development of technology. This dynamic and often tumultuous landscape is vividly mirrored and shaped by discussions within Crypto Twitter, a key digital arena where investors, enthusiasts, and skeptics converge, revealing real-time sentiments and trends through social media interactions. We present our analysis on a Twitter dataset collected during a formative period of the cryptocurrency landscape. We collected 40 million tweets using cryptocurrency-related keywords and performed a nuanced analysis that involved grouping the tweets by semantic similarity and constructing a tweet and user network. We used sentence-level embeddings and autoencoders to create K-means clusters of tweets and identified six groups of tweets and their topics to examine different cryptocurrency-related interests and the change in sentiment over time. Moreover, we discovered sentiment indicators that point to real-life incidents in the crypto world, such as the FTX incident of November 2022. We also constructed and analyzed different networks of tweets and users in our dataset by considering the reply and quote relationships and analyzed the largest components of each network. Our networks reveal a structure of bot activity in Crypto Twitter and suggest that they can be detected and handled using a network-based approach. Our work sheds light on the potential of social media signals to detect and understand crypto events, benefiting investors, regulators, and curious observers alike, as well as the potential for bot detection in Crypto Twitter using a network-based approach.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06037",
        "abstract url": "https://arxiv.org/abs/2403.06037",
        "title": "The Flow Game: Leximin and Leximax Core Imputations",
        "rating": -10,
        "keywords": [],
        "abstract": "Recently [Vaz24] gave mechanisms for finding leximin and leximax core imputations for the assignment game and remarked, \"Within the area of algorithm design, the \"right\" technique for solving several types of algorithmic questions was first discovered in the context of matching and later these insights were applied to other problems. We expect a similar phenomenon here.\" One of the games explicitly mentioned in this context was the flow game of Kalai and Zemel [KZ82]. In this paper, we give strongly polynomial time mechanisms for computing the leximin and leximax core imputations for the flow game, among the set of core imputations that are captured as optimal solutions to the dual LP. We address two versions: 1. The imputations are leximin and leximax with respect to the distance labels of edges. 2. The imputations are leximin and leximax with respect to the product of capacities of edges and their distance labels.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2403.06039",
        "abstract url": "https://arxiv.org/abs/2403.06039",
        "title": "A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation",
        "rating": -10,
        "keywords": [],
        "abstract": "Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs). Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process. This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted at CHI LBW 2024"
    },
    {
        "paper id": "2403.06045",
        "abstract url": "https://arxiv.org/abs/2403.06045",
        "title": "Sample-Optimal Zero-Violation Safety For Continuous Control",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we study the problem of ensuring safety with a few shots of samples for partially unknown systems. We first characterize a fundamental limit when producing safe actions is not possible due to insufficient information or samples. Then, we develop a technique that can generate provably safe actions and recovery behaviors using a minimum number of samples. In the performance analysis, we also establish Nagumos theorem - like results with relaxed assumptions, which is potentially useful in other contexts. Finally, we discuss how the proposed method can be integrated into a policy gradient algorithm to assure safety and stability with a handful of samples without stabilizing initial policies or generative models to probe safe actions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2403.06050",
        "abstract url": "https://arxiv.org/abs/2403.06050",
        "title": "Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills",
        "rating": -10,
        "keywords": [],
        "abstract": "Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with ``Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to ITiCSE 2024"
    },
    {
        "paper id": "2403.06056",
        "abstract url": "https://arxiv.org/abs/2403.06056",
        "title": "Absence of spurious solutions far from ground truth: A low-rank analysis with high-order losses",
        "rating": -10,
        "keywords": [],
        "abstract": "Matrix sensing problems exhibit pervasive non-convexity, plaguing optimization with a proliferation of suboptimal spurious solutions. Avoiding convergence to these critical points poses a major challenge. This work provides new theoretical insights that help demystify the intricacies of the non-convex landscape. In this work, we prove that under certain conditions, critical points sufficiently distant from the ground truth matrix exhibit favorable geometry by being strict saddle points rather than troublesome local minima. Moreover, we introduce the notion of higher-order losses for the matrix sensing problem and show that the incorporation of such losses into the objective function amplifies the negative curvature around those distant critical points. This implies that increasing the complexity of the objective function via high-order losses accelerates the escape from such critical points and acts as a desirable alternative to increasing the complexity of the optimization problem via over-parametrization. By elucidating key characteristics of the non-convex optimization landscape, this work makes progress towards a comprehensive framework for tackling broader machine learning objectives plagued by non-convexity.",
        "subjects": [
            "math.OC"
        ],
        "comment": "Accepted by AISTATS 2024"
    },
    {
        "paper id": "2403.06073",
        "abstract url": "https://arxiv.org/abs/2403.06073",
        "title": "Stochastic Geometry Analysis for Distributed RISs-Assisted mmWave Communications",
        "rating": -10,
        "keywords": [],
        "abstract": "Millimeter wave (mmWave) has attracted considerable attention due to its wide bandwidth and high frequency. However, it is highly susceptible to blockages, resulting in significant degradation of the coverage and the sum rate. A promising approach is deploying distributed reconfigurable intelligent surfaces (RISs), which can establish extra communication links. In this paper, we investigate the impact of distributed RISs on the coverage probability and the sum rate in mmWave wireless communication systems. Specifically, we first introduce the system model, which includes the blockage, the RIS and the user distribution models, leveraging the Poisson point process. Then, we define the association criterion and derive the conditional coverage probabilities for the two cases of direct association and reflective association through RISs. Finally, we combine the two cases using Campbell's theorem and the total probability theorem to obtain the closed-form expressions for the ergodic coverage probability and the sum rate. Simulation results validate the effectiveness of the proposed analytical approach, demonstrating that the deployment of distributed RISs significantly improves the ergodic coverage probability by 45.4% and the sum rate by over 1.5 times.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2402.06154"
    },
    {
        "paper id": "2403.06074",
        "abstract url": "https://arxiv.org/abs/2403.06074",
        "title": "Hashing Beam Training for Near-Field Communications",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we investigate the millimeter-wave (mmWave) near-field beam training problem to find the correct beam direction. In order to address the high complexity and low identification accuracy of existing beam training techniques, we propose an efficient hashing multi-arm beam (HMB) training scheme for the near-field scenario. Specifically, we first design a set of sparse bases based on the polar domain sparsity of the near-field channel. Then, the random hash functions are chosen to construct the near-field multi-arm beam training codebook. Each multi-arm beam codeword is scanned in a time slot until all the predefined codewords are traversed. Finally, the soft decision and voting methods are applied to distinguish the signal from different base stations and obtain correctly aligned beams. Simulation results show that our proposed near-field HMB training method can reduce the beam training overhead to the logarithmic level, and achieve 96.4% identification accuracy of exhaustive beam training. Moreover, we also verify applicability under the far-field scenario.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2402.04913"
    },
    {
        "paper id": "2403.06077",
        "abstract url": "https://arxiv.org/abs/2403.06077",
        "title": "Steering a Fleet: Adaptation for Large-Scale, Workflow-Based Experiments",
        "rating": -10,
        "keywords": [],
        "abstract": "Experimental science is increasingly driven by instruments that produce vast volumes of data and thus a need to manage, compute, describe, and index this data. High performance and distributed computing provide the means of addressing the computing needs; however, in practice, the variety of actions required and the distributed set of resources involved, requires sophisticated \"flows\" defining the steps to be performed on data. As each scan or measurement is performed by an instrument, a new instance of the flow is initiated resulting in a \"fleet\" of concurrently running flows, with the overall goal to process all the data collected during a potentially long-running experiment. During the course of the experiment, each flow may need to adapt its execution due to changes in the environment, such as computational or storage resource availability, or based on the progress of the fleet as a whole such as completion or discovery of an intermediate result leading to a change in subsequent flow's behavior. We introduce a cloud-based decision engine, Braid, which flows consult during execution to query their run-time environment and coordinate with other flows within their fleet. Braid accepts streams of measurements taken from the run-time environment or from within flow runs which can then be statistically aggregated and compared to other streams to determine a strategy to guide flow execution. For example, queue lengths in execution environments can be used to direct a flow to run computations in one environment or another, or experiment progress as measured by individual flows can be aggregated to determine the progress and subsequent direction of the flows within a fleet. We describe Braid, its interface, implementation and performance characteristics. We further show through examples and experience modifying an existing scientific flow how Braid is used to make adaptable flows.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2403.07017",
        "abstract url": "https://arxiv.org/abs/2403.07017",
        "title": "Mathematics of multi-agent learning systems at the interface of game theory and artificial intelligence",
        "rating": -10,
        "keywords": [],
        "abstract": "Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two fields that, at first glance, might seem distinct, but they have notable connections and intersections. The former focuses on the evolution of behaviors (or strategies) in a population, where individuals interact with others and update their strategies based on imitation (or social learning). The more successful a strategy is, the more prevalent it becomes over time. The latter, meanwhile, is centered on machine learning algorithms and (deep) neural networks. It is often from a single-agent perspective but increasingly involves multi-agent environments, in which intelligent agents adjust their strategies based on feedback and experience, somewhat akin to the evolutionary process yet distinct in their self-learning capacities. In light of the key components necessary to address real-world problems, including (i) learning and adaptation, (ii) cooperation and competition, (iii) robustness and stability, and altogether (iv) population dynamics of individual agents whose strategies evolve, the cross-fertilization of ideas between both fields will contribute to the advancement of mathematics of multi-agent learning systems, in particular, to the nascent domain of ``collective cooperative intelligence'' bridging evolutionary dynamics and multi-agent reinforcement learning.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "8 pages, 1 figure"
    },
    {
        "paper id": "2403.07018",
        "abstract url": "https://arxiv.org/abs/2403.07018",
        "title": "Contemplating Secure and Optimal Design Practices for Information Infrastructure From a Human Factors Perspective",
        "rating": -10,
        "keywords": [],
        "abstract": "Designing secure information infrastructure is a function of design and usability. However, security is seldom given priority when systems are being developed. Secure design practices should balance between functionality (i.e., proper design) to meet minimum requirements and user-friendliness. Design recommendations such as those with a user-centric approach (i.e., inclusive of only relevant information, user liberty) and presenting information within its proper context in a clear and engaging manner has been scientifically shown to improve user response and experience.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This version is one of the final drafts and is being revised. Newer versions will be uploaded as major changes are incorporated"
    }
]