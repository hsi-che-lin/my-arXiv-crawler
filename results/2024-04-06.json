[
    {
        "paper id": "2404.04522",
        "abstract url": "https://arxiv.org/abs/2404.04522",
        "title": "Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models",
        "rating": 2,
        "keywords": [
            [
                "Parameter Efficient",
                "PEFT",
                "Efficient Fine-tuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have been extensively utilized in Large Language Models (LLMs) to improve the down-streaming tasks without the cost of fine-tuing the whole LLMs. Recent studies have shown how to effectively use PEFT for fine-tuning LLMs in ranking tasks with convincing performance; there are some limitations, including the learned prompt being fixed for different documents, overfitting to specific tasks, and low adaptation ability. In this paper, we introduce a query-dependent parameter efficient fine-tuning (Q-PEFT) approach for text reranking to leak the information of the true queries to LLMs and then make the generation of true queries from input documents much easier. Specifically, we utilize the query to extract the top-$k$ tokens from concatenated documents, serving as contextual clues. We further augment Q-PEFT by substituting the retrieval mechanism with a multi-head attention layer to achieve end-to-end training and cover all the tokens in the documents, guiding the LLMs to generate more document-specific synthetic queries, thereby further improving the reranking performance. Extensive experiments are conducted on four public datasets, demonstrating the effectiveness of our proposed approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04763",
        "abstract url": "https://arxiv.org/abs/2404.04763",
        "title": "GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling",
        "rating": 2,
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal event argument role labeling (EARL), a task that assigns a role for each event participant (object) in an image is a complex challenge. It requires reasoning over the entire image, the depicted event, and the interactions between various objects participating in the event. Existing models heavily rely on high-quality event-annotated training data to understand the event semantics and structures, and they fail to generalize to new event types and domains. In this paper, we propose GenEARL, a training-free generative framework that harness the power of the modern generative models to understand event task descriptions given image contexts to perform the EARL task. Specifically, GenEARL comprises two stages of generative prompting with a frozen vision-language model (VLM) and a frozen large language model (LLM). First, a generative VLM learns the semantics of the event argument roles and generates event-centric object descriptions based on the image. Subsequently, a LLM is prompted with the generated object descriptions with a predefined template for EARL (i.e., assign an object with an event argument role). We show that GenEARL outperforms the contrastive pretraining (CLIP) baseline by 9.4% and 14.2% accuracy for zero-shot EARL on the M2E2 and SwiG datasets, respectively. In addition, we outperform CLIP-Event by 22% precision on M2E2 dataset. The framework also allows flexible adaptation and generalization to unseen domains.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "20 pages, 15 Figures, 13 figures"
    },
    {
        "paper id": "2404.04624",
        "abstract url": "https://arxiv.org/abs/2404.04624",
        "title": "Bridging the Gap Between End-to-End and Two-Step Text Spotting",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Modularity plays a crucial role in the development and maintenance of complex systems. While end-to-end text spotting efficiently mitigates the issues of error accumulation and sub-optimal performance seen in traditional two-step methodologies, the two-step methods continue to be favored in many competitions and practical settings due to their superior modularity. In this paper, we introduce Bridging Text Spotting, a novel approach that resolves the error accumulation and suboptimal performance issues in two-step methods while retaining modularity. To achieve this, we adopt a well-trained detector and recognizer that are developed and trained independently and then lock their parameters to preserve their already acquired capabilities. Subsequently, we introduce a Bridge that connects the locked detector and recognizer through a zero-initialized neural network. This zero-initialized neural network, initialized with weights set to zeros, ensures seamless integration of the large receptive field features in detection into the locked recognizer. Furthermore, since the fixed detector and recognizer cannot naturally acquire end-to-end optimization features, we adopt the Adapter to facilitate their efficient learning of these features. We demonstrate the effectiveness of the proposed method through extensive experiments: Connecting the latest detector and recognizer through Bridging Text Spotting, we achieved an accuracy of 83.3% on Total-Text, 69.8% on CTW1500, and 89.5% on ICDAR 2015. The code is available at https://github.com/mxin262/Bridging-Text-Spotting.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR2024"
    },
    {
        "paper id": "2404.04627",
        "abstract url": "https://arxiv.org/abs/2404.04627",
        "title": "Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement",
        "rating": 1.5,
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Synthesis"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Visual program synthesis is a promising approach to exploit the reasoning abilities of large language models for compositional computer vision tasks. Previous work has used few-shot prompting with frozen LLMs to synthesize visual programs. Training an LLM to write better visual programs is an attractive prospect, but it is unclear how to accomplish this. No dataset of visual programs for training exists, and acquisition of a visual program dataset cannot be easily crowdsourced due to the need for expert annotators. To get around the lack of direct supervision, we explore improving the program synthesis abilities of an LLM using feedback from interactive experience. We propose a method where we exploit existing annotations for a vision-language task to improvise a coarse reward signal for that task, treat the LLM as a policy, and apply reinforced self-training to improve the visual program synthesis ability of the LLM for that task. We describe a series of experiments on object detection, compositional visual question answering, and image-text retrieval, and show that in each case, the self-trained LLM outperforms or performs on par with few-shot frozen LLMs that are an order of magnitude larger. Website: https://zaidkhan.me/ViReP",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2404.04647",
        "abstract url": "https://arxiv.org/abs/2404.04647",
        "title": "Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Gradient-based saliency maps have been widely used to explain the decisions of deep neural network classifiers. However, standard gradient-based interpretation maps, including the simple gradient and integrated gradient algorithms, often lack desired structures such as sparsity and connectedness in their application to real-world computer vision models. A frequently used approach to inducing sparsity structures into gradient-based saliency maps is to alter the simple gradient scheme using sparsification or norm-based regularization. A drawback with such post-processing methods is their frequently-observed significant loss in fidelity to the original simple gradient map. In this work, we propose to apply adversarial training as an in-processing scheme to train neural networks with structured simple gradient maps. We show a duality relation between the regularized norms of the adversarial perturbations and gradient-based maps, based on which we design adversarial training loss functions promoting sparsity and group-sparsity properties in simple gradient maps. We present several numerical results to show the influence of our proposed norm-based adversarial training methods on the standard gradient-based maps of standard neural network architectures on benchmark image datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at CVPR 2024"
    },
    {
        "paper id": "2404.04759",
        "abstract url": "https://arxiv.org/abs/2404.04759",
        "title": "What Happens When Small Is Made Smaller? Exploring the Impact of Compression on Small Data Pretrained Language Models",
        "rating": 1.5,
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "workshop",
                "ICLR"
            ]
        ],
        "abstract": "Compression techniques have been crucial in advancing machine learning by enabling efficient training and deployment of large-scale language models. However, these techniques have received limited attention in the context of low-resource language models, which are trained on even smaller amounts of data and under computational constraints, a scenario known as the \"low-resource double-bind.\" This paper investigates the effectiveness of pruning, knowledge distillation, and quantization on an exclusively low-resourced, small-data language model, AfriBERTa. Through a battery of experiments, we assess the effects of compression on performance across several metrics beyond accuracy. Our study provides evidence that compression techniques significantly improve the efficiency and effectiveness of small-data language models, confirming that the prevailing beliefs regarding the effects of compression on large, heavily parameterized models hold true for less-parameterized, small-data models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "AfricaNLP workshop at ICLR 2024"
    },
    {
        "paper id": "2404.04511",
        "abstract url": "https://arxiv.org/abs/2404.04511",
        "title": "Cluster-based Video Summarization with Temporal Context Awareness",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present TAC-SUM, a novel and efficient training-free approach for video summarization that addresses the limitations of existing cluster-based models by incorporating temporal context. Our method partitions the input video into temporally consecutive segments with clustering information, enabling the injection of temporal awareness into the clustering process, setting it apart from prior cluster-based summarization methods. The resulting temporal-aware clusters are then utilized to compute the final summary, using simple rules for keyframe selection and frame importance scoring. Experimental results on the SumMe dataset demonstrate the effectiveness of our proposed approach, outperforming existing unsupervised methods and achieving comparable performance to state-of-the-art supervised summarization techniques. Our source code is available for reference at \\url{https://github.com/hcmus-thesis-gulu/TAC-SUM}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 6 figures, accepted in PSIVT 2023"
    },
    {
        "paper id": "2404.04513",
        "abstract url": "https://arxiv.org/abs/2404.04513",
        "title": "IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper describes our system developed for the SemEval-2024 Task 1: Semantic Textual Relatedness. The challenge is focused on automatically detecting the degree of relatedness between pairs of sentences for 14 languages including both high and low-resource Asian and African languages. Our team participated in two subtasks consisting of Track A: supervised and Track B: unsupervised. This paper focuses on a BERT-based contrastive learning and similarity metric based approach primarily for the supervised track while exploring autoencoders for the unsupervised track. It also aims on the creation of a bigram relatedness corpus using negative sampling strategy, thereby producing refined word embeddings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at SemEval 2024, NAACL 2024; 6 pages"
    },
    {
        "paper id": "2404.04514",
        "abstract url": "https://arxiv.org/abs/2404.04514",
        "title": "Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) such as GPT-4V and Gemini Pro face challenges in achieving human-level perception in Visual Question Answering (VQA), particularly in object-oriented perception tasks which demand fine-grained understanding of object identities, locations or attributes, as indicated by empirical findings. This is mainly due to their limited capability to effectively integrate complex visual cues with textual information and potential object hallucinations. In this paper, we present a novel approach, Joint Visual and Text Prompting (VTPrompt), that employs fine-grained visual information to enhance the capability of MLLMs in VQA, especially for object-oriented perception. VTPrompt merges visual and text prompts to extract key concepts from textual questions and employs a detection model to highlight relevant objects as visual prompts in images. The processed images alongside text prompts are subsequently fed into MLLMs to produce more accurate answers. Our experiments with GPT-4V and Gemini Pro, on three benchmarks, i.e., MME , MMB and POPE, demonstrate significant improvements. Particularly, our method led to a score improvement of up to 183.5 for GPT-4V on MME and enhanced MMB performance by 8.17\\% for GPT-4V and 15.69\\% for Gemini Pro.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04525",
        "abstract url": "https://arxiv.org/abs/2404.04525",
        "title": "IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents our approach for the SemEval-2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversations. For the Emotion Recognition in Conversations (ERC) task, we utilize a masked-memory network along with speaker participation. We propose a transformer-based speaker-centric model for the Emotion Flip Reasoning (EFR) task. We also introduce Probable Trigger Zone, a region of the conversation that is more likely to contain the utterances causing the emotion to flip. For sub-task 3, the proposed approach achieves a 5.9 (F1 score) improvement over the task baseline. The ablation study results highlight the significance of various design choices in the proposed method.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at SemEval 2024, NAACL 2024; 10 Pages"
    },
    {
        "paper id": "2404.04530",
        "abstract url": "https://arxiv.org/abs/2404.04530",
        "title": "A Morphology-Based Investigation of Positional Encodings",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "How does the importance of positional encoding in pre-trained language models (PLMs) vary across languages with different morphological complexity? In this paper, we offer the first study addressing this question, encompassing 23 morphologically diverse languages and 5 different downstream tasks. We choose two categories of tasks: syntactic tasks (part-of-speech tagging, named entity recognition, dependency parsing) and semantic tasks (natural language inference, paraphrasing). We consider language-specific BERT models trained on monolingual corpus for our investigation. The main experiment consists of nullifying the effect of positional encoding during fine-tuning and investigating its impact across various tasks and languages. Our findings demonstrate that the significance of positional encoding diminishes as the morphological complexity of a language increases. Across all experiments, we observe clustering of languages according to their morphological typology - with analytic languages at one end and synthetic languages at the opposite end.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in Progress"
    },
    {
        "paper id": "2404.04564",
        "abstract url": "https://arxiv.org/abs/2404.04564",
        "title": "Enhancing Video Summarization with Context Awareness",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video summarization is a crucial research area that aims to efficiently browse and retrieve relevant information from the vast amount of video content available today. With the exponential growth of multimedia data, the ability to extract meaningful representations from videos has become essential. Video summarization techniques automatically generate concise summaries by selecting keyframes, shots, or segments that capture the video's essence. This process improves the efficiency and accuracy of various applications, including video surveillance, education, entertainment, and social media. Despite the importance of video summarization, there is a lack of diverse and representative datasets, hindering comprehensive evaluation and benchmarking of algorithms. Existing evaluation metrics also fail to fully capture the complexities of video summarization, limiting accurate algorithm assessment and hindering the field's progress. To overcome data scarcity challenges and improve evaluation, we propose an unsupervised approach that leverages video data structure and information for generating informative summaries. By moving away from fixed annotations, our framework can produce representative summaries effectively. Moreover, we introduce an innovative evaluation pipeline tailored specifically for video summarization. Human participants are involved in the evaluation, comparing our generated summaries to ground truth summaries and assessing their informativeness. This human-centric approach provides valuable insights into the effectiveness of our proposed techniques. Experimental results demonstrate that our training-free framework outperforms existing unsupervised approaches and achieves competitive results compared to state-of-the-art supervised methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "115 pages, 1 supplementary paper, undergraduate thesis report at US-VNUHCM"
    },
    {
        "paper id": "2404.04580",
        "abstract url": "https://arxiv.org/abs/2404.04580",
        "title": "SDFR: Synthetic Data for Face Recognition Competition",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale face recognition datasets are collected by crawling the Internet and without individuals' consent, raising legal, ethical, and privacy concerns. With the recent advances in generative models, recently several works proposed generating synthetic face recognition datasets to mitigate concerns in web-crawled face recognition datasets. This paper presents the summary of the Synthetic Data for Face Recognition (SDFR) Competition held in conjunction with the 18th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2024) and established to investigate the use of synthetic data for training face recognition models. The SDFR competition was split into two tasks, allowing participants to train face recognition systems using new synthetic datasets and/or existing ones. In the first task, the face recognition backbone was fixed and the dataset size was limited, while the second task provided almost complete freedom on the model backbone, the dataset, and the training pipeline. The submitted models were trained on existing and also new synthetic datasets and used clever methods to improve training with synthetic data. The submissions were evaluated and ranked on a diverse set of seven benchmarking datasets. The paper gives an overview of the submitted face recognition models and reports achieved performance compared to baseline models trained on real and synthetic datasets. Furthermore, the evaluation of submissions is extended to bias assessment across different demography groups. Lastly, an outlook on the current state of the research in training face recognition models using synthetic data is presented, and existing problems as well as potential future directions are also discussed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The 18th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2024)"
    },
    {
        "paper id": "2404.04584",
        "abstract url": "https://arxiv.org/abs/2404.04584",
        "title": "D$^3$: Scaling Up Deepfake Detection by Learning from Discrepancy",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The boom of Generative AI brings opportunities entangled with risks and concerns. In this work, we seek a step toward a universal deepfake detection system with better generalization and robustness, to accommodate the responsible deployment of diverse image generative models. We do so by first scaling up the existing detection task setup from the one-generator to multiple-generators in training, during which we disclose two challenges presented in prior methodological designs. Specifically, we reveal that the current methods tailored for training on one specific generator either struggle to learn comprehensive artifacts from multiple generators or tend to sacrifice their ability to identify fake images from seen generators (i.e., In-Domain performance) to exchange the generalization for unseen generators (i.e., Out-Of-Domain performance). To tackle the above challenges, we propose our Discrepancy Deepfake Detector (D$^3$) framework, whose core idea is to learn the universal artifacts from multiple generators by introducing a parallel network branch that takes a distorted image as extra discrepancy signal to supplement its original counterpart. Extensive scaled-up experiments on the merged UFD and GenImage datasets with six detection models demonstrate the effectiveness of our framework, achieving a 5.3% accuracy improvement in the OOD testing compared to the current SOTA methods while maintaining the ID performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 3 figures"
    },
    {
        "paper id": "2404.04626",
        "abstract url": "https://arxiv.org/abs/2404.04626",
        "title": "Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Direct Preference Optimization (DPO), which derives reward signals directly from pairwise preference data, has shown its effectiveness on aligning Large Language Models (LLMs) with human preferences. Despite its widespread use across various tasks, DPO has been criticized for its sensitivity to the SFT's effectiveness and its hindrance to the learning capacity towards human-preferred responses, leading to less satisfactory performance. To overcome those limitations, the theoretical understanding of DPO are indispensable but still lacking. To this end, we take a step towards theoretically analyzing and understanding the limitations of DPO. Specifically, we provide an analytical framework using the field theory to analyze the optimization process of DPO. By analyzing the gradient vector field of the DPO loss function, we find that the DPO loss function decreases the probability of producing human dispreferred data at a faster rate than it increases the probability of producing preferred data. This provides theoretical insights for understanding the limitations of DPO discovered in the related research experiments, thereby setting the foundation for its improvement.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Draft version"
    },
    {
        "paper id": "2404.04631",
        "abstract url": "https://arxiv.org/abs/2404.04631",
        "title": "On the Limitations of Large Language Models (LLMs): False Attribution",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we provide insight into one important limitation of large language models (LLMs), i.e. false attribution, and introduce a new hallucination metric - Simple Hallucination Index (SHI). The task of automatic author attribution for relatively small chunks of text is an important NLP task but can be challenging. We empirically evaluate the power of 3 open SotA LLMs in zero-shot setting (LLaMA-2-13B, Mixtral 8x7B, and Gemma-7B), especially as human annotation can be costly. We collected the top 10 most popular books, according to Project Gutenberg, divided each one into equal chunks of 400 words, and asked each LLM to predict the author. We then randomly sampled 162 chunks for human evaluation from each of the annotated books, based on the error margin of 7% and a confidence level of 95% for the book with the most chunks (Great Expectations by Charles Dickens, having 922 chunks). The average results show that Mixtral 8x7B has the highest prediction accuracy, the lowest SHI, and a Pearson's correlation (r) of 0.737, 0.249, and -0.9996, respectively, followed by LLaMA-2-13B and Gemma-7B. However, Mixtral 8x7B suffers from high hallucinations for 3 books, rising as high as an SHI of 0.87 (in the range 0-1, where 1 is the worst). The strong negative correlation of accuracy and SHI, given by r, demonstrates the fidelity of the new hallucination metric, which is generalizable to other tasks. We publicly release the annotated chunks of data and our codes to aid the reproducibility and evaluation of other models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2404.04633",
        "abstract url": "https://arxiv.org/abs/2404.04633",
        "title": "Context versus Prior Knowledge in Language Models",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "To answer a question, language models often need to integrate prior knowledge learned during pretraining and new information presented in context. We hypothesize that models perform this integration in a predictable way across different questions and contexts: models will rely more on prior knowledge for questions about entities (e.g., persons, places, etc.) that they are more familiar with due to higher exposure in the training corpus, and be more easily persuaded by some contexts than others. To formalize this problem, we propose two mutual information-based metrics to measure a model's dependency on a context and on its prior about an entity: first, the persuasion score of a given context represents how much a model depends on the context in its decision, and second, the susceptibility score of a given entity represents how much the model can be swayed away from its original answer distribution about an entity. Following well-established measurement modeling methods, we empirically test for the validity and reliability of these metrics. Finally, we explore and find a relationship between the scores and the model's expected familiarity with an entity, and provide two use cases to illustrate their benefits.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04645",
        "abstract url": "https://arxiv.org/abs/2404.04645",
        "title": "HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks",
        "rating": 1,
        "keywords": [
            [
                "Parameter Efficient"
            ],
            [
                "synthesis"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Neural speech synthesis, or text-to-speech (TTS), aims to transform a signal from the text domain to the speech domain. While developing TTS architectures that train and test on the same set of speakers has seen significant improvements, out-of-domain speaker performance still faces enormous limitations. Domain adaptation on a new set of speakers can be achieved by fine-tuning the whole model for each new domain, thus making it parameter-inefficient. This problem can be solved by Adapters that provide a parameter-efficient alternative to domain adaptation. Although famous in NLP, speech synthesis has not seen much improvement from Adapters. In this work, we present HyperTTS, which comprises a small learnable network, \"hypernetwork\", that generates parameters of the Adapter blocks, allowing us to condition Adapters on speaker representations and making them dynamic. Extensive evaluations of two domain adaptation settings demonstrate its effectiveness in achieving state-of-the-art performance in the parameter-efficient regime. We also compare different variants of HyperTTS, comparing them with baselines in different studies. Promising results on the dynamic adaptation of adapter parameters using hypernetworks open up new avenues for domain-generic multi-speaker TTS systems. The audio samples and code are available at https://github.com/declare-lab/HyperTTS.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04659",
        "abstract url": "https://arxiv.org/abs/2404.04659",
        "title": "Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite their strong ability to retrieve knowledge in English, current large language models show imbalance abilities in different languages. Two approaches are proposed to address this, i.e., multilingual pretraining and multilingual instruction tuning. However, whether and how do such methods contribute to the cross-lingual knowledge alignment inside the models is unknown. In this paper, we propose CLiKA, a systematic framework to assess the cross-lingual knowledge alignment of LLMs in the Performance, Consistency and Conductivity levels, and explored the effect of multilingual pretraining and instruction tuning on the degree of alignment. Results show that: while both multilingual pretraining and instruction tuning are beneficial for cross-lingual knowledge alignment, the training strategy needs to be carefully designed. Namely, continued pretraining improves the alignment of the target language at the cost of other languages, while mixed pretraining affect other languages less. Also, the overall cross-lingual knowledge alignment, especially in the conductivity level, is unsatisfactory for all tested LLMs, and neither multilingual pretraining nor instruction tuning can substantially improve the cross-lingual knowledge conductivity.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04665",
        "abstract url": "https://arxiv.org/abs/2404.04665",
        "title": "Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The memory dictionary-based contrastive learning method has achieved remarkable results in the field of unsupervised person Re-ID. However, The method of updating memory based on all samples does not fully utilize the hardest sample to improve the generalization ability of the model, and the method based on hardest sample mining will inevitably introduce false-positive samples that are incorrectly clustered in the early stages of the model. Clustering-based methods usually discard a significant number of outliers, leading to the loss of valuable information. In order to address the issues mentioned before, we propose an adaptive intra-class variation contrastive learning algorithm for unsupervised Re-ID, called AdaInCV. And the algorithm quantitatively evaluates the learning ability of the model for each class by considering the intra-class variations after clustering, which helps in selecting appropriate samples during the training process of the model. To be more specific, two new strategies are proposed: Adaptive Sample Mining (AdaSaM) and Adaptive Outlier Filter (AdaOF). The first one gradually creates more reliable clusters to dynamically refine the memory, while the second can identify and filter out valuable outliers as negative samples.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04671",
        "abstract url": "https://arxiv.org/abs/2404.04671",
        "title": "Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces PhyloLM, a method applying phylogenetic algorithms to Large Language Models to explore their finetuning relationships, and predict their performance characteristics. By leveraging the phylogenetic distance metric, we construct dendrograms, which satisfactorily capture distinct LLM families (across a set of 77 open-source and 22 closed models). Furthermore, phylogenetic distance predicts performances in benchmarks (we test MMLU and ARC), thus enabling a time and cost-effective estimation of LLM capabilities. The approach translates genetic concepts to machine learning, offering tools to infer LLM development, relationships, and capabilities, even in the absence of transparent training information.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04676",
        "abstract url": "https://arxiv.org/abs/2404.04676",
        "title": "Order-Based Pre-training Strategies for Procedural Text Understanding",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we propose sequence-based pretraining methods to enhance procedural understanding in natural language processing. Procedural text, containing sequential instructions to accomplish a task, is difficult to understand due to the changing attributes of entities in the context. We focus on recipes, which are commonly represented as ordered instructions, and use this order as a supervision signal. Our work is one of the first to compare several 'order as-supervision' transformer pre-training methods, including Permutation Classification, Embedding Regression, and Skip-Clip, and shows that these methods give improved results compared to the baselines and SoTA LLMs on two downstream Entity-Tracking datasets: NPN-Cooking dataset in recipe domain and ProPara dataset in open domain. Our proposed methods address the non-trivial Entity Tracking Task that requires prediction of entity states across procedure steps, which requires understanding the order of steps. These methods show an improvement over the best baseline by 1.6% and 7-9% on NPN-Cooking and ProPara Datasets respectively across metrics.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages (Accepted for publication at NAACL 2024 (Main Conference))"
    },
    {
        "paper id": "2404.04682",
        "abstract url": "https://arxiv.org/abs/2404.04682",
        "title": "Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Offline reinforcement learning (RL) is a compelling framework for learning optimal policies from past experiences without additional interaction with the environment. Nevertheless, offline RL inevitably faces the problem of distributional shifts, where the states and actions encountered during policy execution may not be in the training dataset distribution. A common solution involves incorporating conservatism into the policy or the value function to safeguard against uncertainties and unknowns. In this work, we focus on achieving the same objectives of conservatism but from a different perspective. We propose COmpositional COnservatism with Anchor-seeking (COCOA) for offline RL, an approach that pursues conservatism in a compositional manner on top of the transductive reparameterization (Netanyahu et al., 2023), which decomposes the input variable (the state in our case) into an anchor and its difference from the original input. Our COCOA seeks both in-distribution anchors and differences by utilizing the learned reverse dynamics model, encouraging conservatism in the compositional input space for the policy or value function. Such compositional conservatism is independent of and agnostic to the prevalent behavioral conservatism in offline RL. We apply COCOA to four state-of-the-art offline RL algorithms and evaluate them on the D4RL benchmark, where COCOA generally improves the performance of each algorithm. The code is available at https://github.com/runamu/compositional-conservatism.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2404.04728",
        "abstract url": "https://arxiv.org/abs/2404.04728",
        "title": "Navigating the Landscape of Hint Generation Research: From the Past to the Future",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Digital education has gained popularity in the last decade, especially after the COVID-19 pandemic. With the improving capabilities of large language models to reason and communicate with users, envisioning intelligent tutoring systems (ITSs) that can facilitate self-learning is not very far-fetched. One integral component to fulfill this vision is the ability to give accurate and effective feedback via hints to scaffold the learning process. In this survey article, we present a comprehensive review of prior research on hint generation, aiming to bridge the gap between research in education and cognitive science, and research in AI and Natural Language Processing. Informed by our findings, we propose a formal definition of the hint generation task, and discuss the roadmap of building an effective hint generation system aligned with the formal definition, including open challenges, future directions and ethical considerations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Submitted to TACL'24"
    },
    {
        "paper id": "2404.04734",
        "abstract url": "https://arxiv.org/abs/2404.04734",
        "title": "Towards Generalized Entropic Sparsification for Convolutional Neural Networks",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Convolutional neural networks (CNNs) are reported to be overparametrized. The search for optimal (minimal) and sufficient architecture is an NP-hard problem as the hyperparameter space for possible network configurations is vast. Here, we introduce a layer-by-layer data-driven pruning method based on the mathematical idea aiming at a computationally-scalable entropic relaxation of the pruning problem. The sparse subnetwork is found from the pre-trained (full) CNN using the network entropy minimization as a sparsity constraint. This allows deploying a numerically scalable algorithm with a sublinear scaling cost. The method is validated on several benchmarks (architectures): (i) MNIST (LeNet) with sparsity 55%-84% and loss in accuracy 0.1%-0.5%, and (ii) CIFAR-10 (VGG-16, ResNet18) with sparsity 73-89% and loss in accuracy 0.1%-0.5%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04748",
        "abstract url": "https://arxiv.org/abs/2404.04748",
        "title": "Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have ushered in a new era in Natural Language Processing, but their massive size demands effective compression techniques for practicality. Although numerous model compression techniques have been investigated, they typically rely on a calibration set that overlooks the multilingual context and results in significant accuracy degradation for low-resource languages. This paper introduces Multilingual Brain Surgeon (MBS), a novel calibration data sampling method for multilingual LLMs compression. MBS overcomes the English-centric limitations of existing methods by sampling calibration data from various languages proportionally to the language distribution of the model training datasets. Our experiments, conducted on the BLOOM multilingual LLM, demonstrate that MBS improves the performance of existing English-centric compression methods, especially for low-resource languages. We also uncover the dynamics of language interaction during compression, revealing that the larger the proportion of a language in the training set and the more similar the language is to the calibration language, the better performance the language retains after compression. In conclusion, MBS presents an innovative approach to compressing multilingual LLMs, addressing the performance disparities and improving the language inclusivity of existing compression techniques.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "22 pages, 8 figures, 13 tables. Accepted by LREC-COLING 2024"
    },
    {
        "paper id": "2404.04770",
        "abstract url": "https://arxiv.org/abs/2404.04770",
        "title": "Generating Uncontextualized and Contextualized Questions for Document-Level Event Argument Extraction",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents multiple question generation strategies for document-level event argument extraction. These strategies do not require human involvement and result in uncontextualized questions as well as contextualized questions grounded on the event and document of interest. Experimental results show that combining uncontextualized and contextualized questions is beneficial, especially when event triggers and arguments appear in different sentences. Our approach does not have corpus-specific components, in particular, the question generation strategies transfer across corpora. We also present a qualitative analysis of the most common errors made by our best model.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at NAACL 2024"
    },
    {
        "paper id": "2404.04799",
        "abstract url": "https://arxiv.org/abs/2404.04799",
        "title": "Few-Shot Object Detection: Research Advances and Challenges",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Object detection as a subfield within computer vision has achieved remarkable progress, which aims to accurately identify and locate a specific object from images or videos. Such methods rely on large-scale labeled training samples for each object category to ensure accurate detection, but obtaining extensive annotated data is a labor-intensive and expensive process in many real-world scenarios. To tackle this challenge, researchers have explored few-shot object detection (FSOD) that combines few-shot learning and object detection techniques to rapidly adapt to novel objects with limited annotated samples. This paper presents a comprehensive survey to review the significant advancements in the field of FSOD in recent years and summarize the existing challenges and solutions. Specifically, we first introduce the background and definition of FSOD to emphasize potential value in advancing the field of computer vision. We then propose a novel FSOD taxonomy method and survey the plentifully remarkable FSOD algorithms based on this fact to report a comprehensive overview that facilitates a deeper understanding of the FSOD problem and the development of innovative solutions. Finally, we discuss the advantages and limitations of these algorithms to summarize the challenges, potential research direction, and development trend of object detection in the data scarcity scenario.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04807",
        "abstract url": "https://arxiv.org/abs/2404.04807",
        "title": "D2SL: Decouple Defogging and Semantic Learning for Foggy Domain-Adaptive Segmentation",
        "rating": 1,
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We investigated domain adaptive semantic segmentation in foggy weather scenarios, which aims to enhance the utilization of unlabeled foggy data and improve the model's adaptability to foggy conditions. Current methods rely on clear images as references, jointly learning defogging and segmentation for foggy images. Despite making some progress, there are still two main drawbacks: (1) the coupling of segmentation and defogging feature representations, resulting in a decrease in semantic representation capability, and (2) the failure to leverage real fog priors in unlabeled foggy data, leading to insufficient model generalization ability. To address these issues, we propose a novel training framework, Decouple Defogging and Semantic learning, called D2SL, aiming to alleviate the adverse impact of defogging tasks on the final segmentation task. In this framework, we introduce a domain-consistent transfer strategy to establish a connection between defogging and segmentation tasks. Furthermore, we design a real fog transfer strategy to improve defogging effects by fully leveraging the fog priors from real foggy images. Our approach enhances the semantic representations required for segmentation during the defogging learning process and maximizes the representation capability of fog invariance by effectively utilizing real fog data. Comprehensive experiments validate the effectiveness of the proposed method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05765",
        "abstract url": "https://arxiv.org/abs/2404.05765",
        "title": "A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music",
        "rating": 1,
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Introduction: Music generation is a complex task that has received significant attention in recent years, and deep learning techniques have shown promising results in this field. Objectives: While extensive work has been carried out on generating Piano and other Western music, there is limited research on generating classical Indian music due to the scarcity of Indian music in machine-encoded formats. In this technical paper, methods for generating classical Indian music, specifically tabla music, is proposed. Initially, this paper explores piano music generation using deep learning architectures. Then the fundamentals are extended to generating tabla music. Methods: Tabla music in waveform (.wav) files are pre-processed using the librosa library in Python. A novel Bi-LSTM with an Attention approach and a transformer model are trained on the extracted features and labels. Results: The models are then used to predict the next sequences of tabla music. A loss of 4.042 and MAE of 1.0814 are achieved with the Bi-LSTM model. With the transformer model, a loss of 55.9278 and MAE of 3.5173 are obtained for tabla music generation. Conclusion: The resulting music embodies a harmonious fusion of novelty and familiarity, pushing the limits of music composition to new horizons.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2404.07999",
        "abstract url": "https://arxiv.org/abs/2404.07999",
        "title": "A Multi-Level Framework for Accelerating Training Transformer Models",
        "rating": 1.0,
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The fast growing capabilities of large-scale deep learning models, such as Bert, GPT and ViT, are revolutionizing the landscape of NLP, CV and many other domains. Training such models, however, poses an unprecedented demand for computing power, which incurs exponentially increasing energy cost and carbon dioxide emissions. It is thus critical to develop efficient training solutions to reduce the training costs. Motivated by a set of key observations of inter- and intra-layer similarities among feature maps and attentions that can be identified from typical training processes, we propose a multi-level framework for training acceleration. Specifically, the framework is based on three basic operators, Coalescing, De-coalescing and Interpolation, which can be orchestrated to build a multi-level training framework. The framework consists of a V-cycle training process, which progressively down- and up-scales the model size and projects the parameters between adjacent levels of models via coalescing and de-coalescing. The key idea is that a smaller model that can be trained for fast convergence and the trained parameters provides high-qualities intermediate solutions for the next level larger network. The interpolation operator is designed to break the symmetry of neurons incurred by de-coalescing for better convergence performance. Our experiments on transformer-based language models (e.g. Bert, GPT) as well as a vision model (e.g. DeiT) prove that the proposed framework reduces the computational cost by about 20% on training BERT/GPT-Base models and up to 51.6% on training the BERT-Large model while preserving the performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR 2024"
    },
    {
        "paper id": "2404.08676",
        "abstract url": "https://arxiv.org/abs/2404.08676",
        "title": "ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming",
        "rating": 1,
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "When building Large Language Models (LLMs), it is paramount to bear safety in mind and protect them with guardrails. Indeed, LLMs should never generate content promoting or normalizing harmful, illegal, or unethical behavior that may contribute to harm to individuals or society. This principle applies to both normal and adversarial use. In response, we introduce ALERT, a large-scale benchmark to assess safety based on a novel fine-grained risk taxonomy. It is designed to evaluate the safety of LLMs through red teaming methodologies and consists of more than 45k instructions categorized using our novel taxonomy. By subjecting LLMs to adversarial testing scenarios, ALERT aims to identify vulnerabilities, inform improvements, and enhance the overall safety of the language models. Furthermore, the fine-grained taxonomy enables researchers to perform an in-depth evaluation that also helps one to assess the alignment with various policies. In our experiments, we extensively evaluate 10 popular open- and closed-source LLMs and demonstrate that many of them still struggle to attain reasonable levels of safety.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "19 pages, preprint"
    },
    {
        "paper id": "2404.04509",
        "abstract url": "https://arxiv.org/abs/2404.04509",
        "title": "Distributed No-Regret Learning for Multi-Stage Systems with End-to-End Bandit Feedback",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper studies multi-stage systems with end-to-end bandit feedback. In such systems, each job needs to go through multiple stages, each managed by a different agent, before generating an outcome. Each agent can only control its own action and learn the final outcome of the job. It has neither knowledge nor control on actions taken by agents in the next stage. The goal of this paper is to develop distributed online learning algorithms that achieve sublinear regret in adversarial environments. The setting of this paper significantly expands the traditional multi-armed bandit problem, which considers only one agent and one stage. In addition to the exploration-exploitation dilemma in the traditional multi-armed bandit problem, we show that the consideration of multiple stages introduces a third component, education, where an agent needs to choose its actions to facilitate the learning of agents in the next stage. To solve this newly introduced exploration-exploitation-education trilemma, we propose a simple distributed online learning algorithm, $\u03b5-$EXP3. We theoretically prove that the $\u03b5-$EXP3 algorithm is a no-regret policy that achieves sublinear regret. Simulation results show that the $\u03b5-$EXP3 algorithm significantly outperforms existing no-regret online learning algorithms for the traditional multi-armed bandit problem.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04517",
        "abstract url": "https://arxiv.org/abs/2404.04517",
        "title": "Latent-based Diffusion Model for Long-tailed Recognition",
        "rating": 0.5,
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Long-tailed imbalance distribution is a common issue in practical computer vision applications. Previous works proposed methods to address this problem, which can be categorized into several classes: re-sampling, re-weighting, transfer learning, and feature augmentation. In recent years, diffusion models have shown an impressive generation ability in many sub-problems of deep computer vision. However, its powerful generation has not been explored in long-tailed problems. We propose a new approach, the Latent-based Diffusion Model for Long-tailed Recognition (LDMLR), as a feature augmentation method to tackle the issue. First, we encode the imbalanced dataset into features using the baseline model. Then, we train a Denoising Diffusion Implicit Model (DDIM) using these encoded features to generate pseudo-features. Finally, we train the classifier using the encoded and pseudo-features from the previous two steps. The model's accuracy shows an improvement on the CIFAR-LT and ImageNet-LT datasets by using the proposed method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 3 figures. Accepted by L3DIVU-CVPR2024"
    },
    {
        "paper id": "2404.04534",
        "abstract url": "https://arxiv.org/abs/2404.04534",
        "title": "Impact of Fairness Regulations on Institutions' Policies and Population Qualifications",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The proliferation of algorithmic systems has fueled discussions surrounding the regulation and control of their social impact. Herein, we consider a system whose primary objective is to maximize utility by selecting the most qualified individuals. To promote demographic parity in the selection algorithm, we consider penalizing discrimination across social groups. We examine conditions under which a discrimination penalty can effectively reduce disparity in the selection. Additionally, we explore the implications of such a penalty when individual qualifications may evolve over time in response to the imposed penalizing policy. We identify scenarios where the penalty could hinder the natural attainment of equity within the population. Moreover, we propose certain conditions that can counteract this undesirable outcome, thus ensuring fairness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04540",
        "abstract url": "https://arxiv.org/abs/2404.04540",
        "title": "The Case for Developing a Foundation Model for Planning-like Tasks from Scratch",
        "rating": 0.5,
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Foundation Models (FMs) have revolutionized many areas of computing, including Automated Planning and Scheduling (APS). For example, a recent study found them useful for planning problems: plan generation, language translation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. Besides APS, there are many seemingly related tasks involving the generation of a series of actions with varying guarantees of their executability to achieve intended goals, which we collectively call planning-like (PL) tasks like business processes, programs, workflows, and guidelines, where researchers have considered using FMs. However, previous works have primarily focused on pre-trained, off-the-shelf FMs and optionally fine-tuned them. This paper discusses the need for a comprehensive FM for PL tasks from scratch and explores its design considerations. We argue that such an FM will open new and efficient avenues for PL problem-solving, just like LLMs are creating for APS.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04565",
        "abstract url": "https://arxiv.org/abs/2404.04565",
        "title": "SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos",
        "rating": 0.5,
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Video-based visual relation detection tasks, such as video scene graph generation, play important roles in fine-grained video understanding. However, current video visual relation detection datasets have two main limitations that hinder the progress of research in this area. First, they do not explore complex human-human interactions in multi-person scenarios. Second, the relation types of existing datasets have relatively low-level semantics and can be often recognized by appearance or simple prior information, without the need for detailed spatio-temporal context reasoning. Nevertheless, comprehending high-level interactions between humans is crucial for understanding complex multi-person videos, such as sports and surveillance videos. To address this issue, we propose a new video visual relation detection task: video human-human interaction detection, and build a dataset named SportsHHI for it. SportsHHI contains 34 high-level interaction classes from basketball and volleyball sports. 118,075 human bounding boxes and 50,649 interaction instances are annotated on 11,398 keyframes. To benchmark this, we propose a two-stage baseline method and conduct extensive experiments to reveal the key factors for a successful human-human interaction detector. We hope that SportsHHI can stimulate research on human interaction understanding in videos and promote the development of spatio-temporal context modeling techniques in video visual relation detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04575",
        "abstract url": "https://arxiv.org/abs/2404.04575",
        "title": "To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The temperature parameter plays a profound role during training and/or inference with large foundation models (LFMs) such as large language models (LLMs) and CLIP models. Particularly, it adjusts the logits in the softmax function in LLMs, which is crucial for next token generation, and it scales the similarities in the contrastive loss for training CLIP models. A significant question remains: Is it viable to learn a neural network to predict a personalized temperature of any input data for enhancing LFMs\"? In this paper, we present a principled framework for learning a small yet generalizable temperature prediction network (TempNet) to improve LFMs. Our solution is composed of a novel learning framework with a robust loss underpinned by constrained distributionally robust optimization (DRO), and a properly designed TempNet with theoretical inspiration. TempNet can be trained together with a large foundation model from scratch or learned separately given a pretrained foundation model. It is not only useful for predicting personalized temperature to promote the training of LFMs but also generalizable and transferable to new tasks. Our experiments on LLMs and CLIP models demonstrate that TempNet greatly improves the performance of existing solutions or models, e.g. Table 1. The code to reproduce the experimental results in this paper can be found at https://github.com/zhqiu/TempNet.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "41 pages, 10 figures"
    },
    {
        "paper id": "2404.04623",
        "abstract url": "https://arxiv.org/abs/2404.04623",
        "title": "An Automated Machine Learning Approach to Inkjet Printed Component Analysis: A Step Toward Smart Additive Manufacturing",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present a machine learning based architecture for microwave characterization of inkjet printed components on flexible substrates. Our proposed architecture uses several machine learning algorithms and automatically selects the best algorithm to extract the material parameters (ink conductivity and dielectric properties) from on-wafer measurements. Initially, the mutual dependence between material parameters of the inkjet printed coplanar waveguides (CPWs) and EM-simulated propagation constants is utilized to train the machine learning models. Next, these machine learning models along with measured propagation constants are used to extract the ink conductivity and dielectric properties of the test prototypes. To demonstrate the applicability of our proposed approach, we compare and contrast four heuristic based machine learning models. It is shown that eXtreme Gradient Boosted Trees Regressor (XGB) and Light Gradient Boosting (LGB) algorithms perform best for the characterization problem under study.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "2024 IEEE Texas Symposium on Wireless & Micrwowave Circuits and Systems"
    },
    {
        "paper id": "2404.04650",
        "abstract url": "https://arxiv.org/abs/2404.04650",
        "title": "InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization",
        "rating": 0.5,
        "keywords": [
            [
                "Diffusion",
                "synthesizing",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Recent strides in the development of diffusion models, exemplified by advancements such as Stable Diffusion, have underscored their remarkable prowess in generating visually compelling images. However, the imperative of achieving a seamless alignment between the generated image and the provided prompt persists as a formidable challenge. This paper traces the root of these difficulties to invalid initial noise, and proposes a solution in the form of Initial Noise Optimization (InitNO), a paradigm that refines this noise. Considering text prompts, not all random noises are effective in synthesizing semantically-faithful images. We design the cross-attention response score and the self-attention conflict score to evaluate the initial noise, bifurcating the initial latent space into valid and invalid sectors. A strategically crafted noise optimization pipeline is developed to guide the initial noise towards valid regions. Our method, validated through rigorous experimentation, shows a commendable proficiency in generating images in strict accordance with text prompts. Our code is available at https://github.com/xiefan-guo/initno.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04656",
        "abstract url": "https://arxiv.org/abs/2404.04656",
        "title": "Binary Classifier Optimization for Large Language Model Alignment",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Aligning Large Language Models (LLMs) to human preferences through preference optimization has been crucial but labor-intensive, necessitating for each prompt a comparison of both a chosen and a rejected text completion by evaluators. Recently, Kahneman-Tversky Optimization (KTO) has demonstrated that LLMs can be aligned using merely binary \"thumbs-up\" or \"thumbs-down\" signals on each prompt-completion pair. In this paper, we present theoretical foundations to explain the successful alignment achieved through these binary signals. Our analysis uncovers a new perspective: optimizing a binary classifier, whose logit is a reward, implicitly induces minimizing the Direct Preference Optimization (DPO) loss. In the process of this discovery, we identified two techniques for effective alignment: reward shift and underlying distribution matching. Consequently, we propose a new algorithm, \\textit{Binary Classifier Optimization}, that integrates the techniques. We validate our methodology in two settings: first, on a paired preference dataset, where our method performs on par with DPO and KTO; and second, on binary signal datasets simulating real-world conditions with divergent underlying distributions between thumbs-up and thumbs-down data. Our model consistently demonstrates effective and robust alignment across two base LLMs and three different binary signal datasets, showcasing the strength of our approach to learning from binary feedback.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "18 pages, 9 figures"
    },
    {
        "paper id": "2404.04662",
        "abstract url": "https://arxiv.org/abs/2404.04662",
        "title": "Learning Minimal NAP Specifications for Neural Network Verification",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Specifications play a crucial role in neural network verification. They define the precise input regions we aim to verify, typically represented as L-infinity norm balls. While recent research suggests using neural activation patterns (NAPs) as specifications for verifying unseen test set data, it focuses on computing the most refined NAPs, often limited to very small regions in the input space. In this paper, we study the following problem: Given a neural network, find a minimal (coarsest) NAP that is sufficient for formal verification of the network's robustness. Finding the minimal NAP specification not only expands verifiable bounds but also provides insights into which neurons contribute to the model's robustness. To address this problem, we propose several exact and approximate approaches. Our exact approaches leverage the verification tool to find minimal NAP specifications in either a deterministic or statistical manner. Whereas the approximate methods efficiently estimate minimal NAPs using adversarial examples and local gradients, without making calls to the verification tool. This allows us to inspect potential causal links between neurons and the robustness of state-of-the-art neural networks, a task for which existing verification frameworks fail to scale. Our experimental results suggest that minimal NAP specifications require much smaller fractions of neurons compared to the most refined NAP specifications, yet they can significantly expand the verifiable boundaries to several orders of magnitude larger.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "29 pages,8 figures"
    },
    {
        "paper id": "2404.04678",
        "abstract url": "https://arxiv.org/abs/2404.04678",
        "title": "Automatic Gradient Estimation for Calibrating Crowd Models with Discrete Decision Making",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently proposed gradient estimators enable gradient descent over stochastic programs with discrete jumps in the response surface, which are not covered by automatic differentiation (AD) alone. Although these estimators' capability to guide a swift local search has been shown for certain problems, their applicability to models relevant to real-world applications remains largely unexplored. As the gradients governing the choice in candidate solutions are calculated from sampled simulation trajectories, the optimization procedure bears similarities to metaheuristics such as particle swarm optimization, which puts the focus on the different methods' calibration progress per function evaluation. Here, we consider the calibration of force-based crowd evacuation models based on the popular Social Force model augmented by discrete decision making. After studying the ability of an AD-based estimator for branching programs to capture the simulation's rugged response surface, calibration problems are tackled using gradient descent and two metaheuristics. As our main insights, we find 1) that the estimation's fidelity benefits from disregarding jumps of large magnitude inherent to the Social Force model, and 2) that the common problem of calibration by adjusting a simulation input distribution obviates the need for AD across the Social Force calculations, allowing gradient descent to excel.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at International Conference on Computational Science (ICCS'24)"
    },
    {
        "paper id": "2404.04684",
        "abstract url": "https://arxiv.org/abs/2404.04684",
        "title": "Algorithmic Misjudgement in Google Search Results: Evidence from Auditing the US Online Electoral Information Environment",
        "rating": 0.5,
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Google Search is an important way that people seek information about politics, and Google states that it is ``committed to providing timely and authoritative information on Google Search to help voters understand, navigate, and participate in democratic processes''. In this paper, we interrogate the extent to which government-maintained web domains are represented in the online environment of electoral information of the 2022 US midterm elections, as captured through Google Search results in 3.45 million SERPs for 786 locations across the United States between October and November 2022. Although we find that almost 40% of organic results are contributed by the 40% of government domains, this proportional equilibrium hides the fact that most results either belong to a small number of popular domains or are mistargeted (at a rate of 71.18%) with respect to the location of the search. We consider the frequent omission and mistargeting of non-federal websites a form of algorithmic misjudgement that contributes to civic harm, by obscuring the important role that these institutions play in the election information environment.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04793",
        "abstract url": "https://arxiv.org/abs/2404.04793",
        "title": "SqueezeAttention: 2D Management of KV-Cache in LLM Inference via Layer-wise Optimal Budget",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Optimizing the Key-Value (KV) cache of the Large Language Model (LLM) has been considered critical to saving the cost of inference. Most of the existing KV-cache compression algorithms attempted to sparsify the sequence of tokens by taking advantage of the different importance of tokens. In this work, we found that by identifying the importance of attention layers, we could optimize the KV-cache jointly from two dimensions. Based on our observations regarding layer-wise importance in inference, we propose SqueezeAttention to precisely optimize the allocation of KV-cache budget among layers on-the-fly and then incorporate three representative token sparsification algorithms to compress the KV-cache for each layer with its very own budget. By optimizing the KV-cache from both sequence's and layer's dimensions, SqueezeAttention achieves around 30% to 70% of the memory reductions and up to 2.2 times of throughput improvements in a wide range of LLMs and benchmarks. The code is available at https://github.com/hetailang/SqueezeAttention.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04800",
        "abstract url": "https://arxiv.org/abs/2404.04800",
        "title": "Coordinated Sparse Recovery of Label Noise",
        "rating": 0.5,
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Label noise is a common issue in real-world datasets that inevitably impacts the generalization of models. This study focuses on robust classification tasks where the label noise is instance-dependent. Estimating the transition matrix accurately in this task is challenging, and methods based on sample selection often exhibit confirmation bias to varying degrees. Sparse over-parameterized training (SOP) has been theoretically effective in estimating and recovering label noise, offering a novel solution for noise-label learning. However, this study empirically observes and verifies a technical flaw of SOP: the lack of coordination between model predictions and noise recovery leads to increased generalization error. To address this, we propose a method called Coordinated Sparse Recovery (CSR). CSR introduces a collaboration matrix and confidence weights to coordinate model predictions and noise recovery, reducing error leakage. Based on CSR, this study designs a joint sample selection strategy and constructs a comprehensive and powerful learning framework called CSR+. CSR+ significantly reduces confirmation bias, especially for datasets with more classes and a high proportion of instance-specific noise. Experimental results on simulated and real-world noisy datasets demonstrate that both CSR and CSR+ achieve outstanding performance compared to methods at the same level.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Pre-print prior to submission to journal"
    },
    {
        "paper id": "2404.04527",
        "abstract url": "https://arxiv.org/abs/2404.04527",
        "title": "VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA",
        "rating": 0,
        "keywords": [
            [
                "Radar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) is a key technique used in military applications like remote-sensing image recognition. Vision Transformers (ViTs) are the current state-of-the-art in various computer vision applications, outperforming their CNN counterparts. However, using ViTs for SAR ATR applications is challenging due to (1) standard ViTs require extensive training data to generalize well due to their low locality; the standard SAR datasets, however, have a limited number of labeled training data which reduces the learning capability of ViTs; (2) ViTs have a high parameter count and are computation intensive which makes their deployment on resource-constrained SAR platforms difficult. In this work, we develop a lightweight ViT model that can be trained directly on small datasets without any pre-training by utilizing the Shifted Patch Tokenization (SPT) and Locality Self-Attention (LSA) modules. We directly train this model on SAR datasets which have limited training samples to evaluate its effectiveness for SAR ATR applications. We evaluate our proposed model, that we call VTR (ViT for SAR ATR), on three widely used SAR datasets: MSTAR, SynthWakeSAR, and GBSAR. Further, we propose a novel FPGA accelerator for VTR, in order to enable deployment for real-time SAR ATR applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "SPIE DCS 2024"
    },
    {
        "paper id": "2404.04544",
        "abstract url": "https://arxiv.org/abs/2404.04544",
        "title": "BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion",
        "rating": 0,
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating higher-resolution human-centric scenes with details and controls remains a challenge for existing text-to-image diffusion models. This challenge stems from limited training image size, text encoder capacity (limited tokens), and the inherent difficulty of generating complex scenes involving multiple humans. While current methods attempted to address training size limit only, they often yielded human-centric scenes with severe artifacts. We propose BeyondScene, a novel framework that overcomes prior limitations, generating exquisite higher-resolution (over 8K) human-centric scenes with exceptional text-image correspondence and naturalness using existing pretrained diffusion models. BeyondScene employs a staged and hierarchical approach to initially generate a detailed base image focusing on crucial elements in instance creation for multiple humans and detailed descriptions beyond token limit of diffusion model, and then to seamlessly convert the base image to a higher-resolution output, exceeding training image size and incorporating details aware of text and instances via our novel instance-aware hierarchical enlargement process that consists of our proposed high-frequency injected forward diffusion and adaptive joint diffusion. BeyondScene surpasses existing methods in terms of correspondence with detailed text descriptions and naturalness, paving the way for advanced applications in higher-resolution human-centric scene creation beyond the capacity of pretrained diffusion models without costly retraining. Project page: https://janeyeon.github.io/beyond-scene.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://janeyeon.github.io/beyond-scene"
    },
    {
        "paper id": "2404.04557",
        "abstract url": "https://arxiv.org/abs/2404.04557",
        "title": "Learning Instance-Aware Correspondences for Robust Multi-Instance Point Cloud Registration in Cluttered Scenes",
        "rating": 0,
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-instance point cloud registration estimates the poses of multiple instances of a model point cloud in a scene point cloud. Extracting accurate point correspondence is to the center of the problem. Existing approaches usually treat the scene point cloud as a whole, overlooking the separation of instances. Therefore, point features could be easily polluted by other points from the background or different instances, leading to inaccurate correspondences oblivious to separate instances, especially in cluttered scenes. In this work, we propose MIRETR, Multi-Instance REgistration TRansformer, a coarse-to-fine approach to the extraction of instance-aware correspondences. At the coarse level, it jointly learns instance-aware superpoint features and predicts per-instance masks. With instance masks, the influence from outside of the instance being concerned is minimized, such that highly reliable superpoint correspondences can be extracted. The superpoint correspondences are then extended to instance candidates at the fine level according to the instance masks. At last, an efficient candidate selection and refinement algorithm is devised to obtain the final registrations. Extensive experiments on three public benchmarks demonstrate the efficacy of our approach. In particular, MIRETR outperforms the state of the arts by 16.6 points on F1 score on the challenging ROBI benchmark. Code and models are available at https://github.com/zhiyuanYU134/MIRETR.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04673",
        "abstract url": "https://arxiv.org/abs/2404.04673",
        "title": "Neural-ABC: Neural Parametric Models for Articulated Body with Clothes",
        "rating": 0,
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce Neural-ABC, a novel parametric model based on neural implicit functions that can represent clothed human bodies with disentangled latent spaces for identity, clothing, shape, and pose. Traditional mesh-based representations struggle to represent articulated bodies with clothes due to the diversity of human body shapes and clothing styles, as well as the complexity of poses. Our proposed model provides a unified framework for parametric modeling, which can represent the identity, clothing, shape and pose of the clothed human body. Our proposed approach utilizes the power of neural implicit functions as the underlying representation and integrates well-designed structures to meet the necessary requirements. Specifically, we represent the underlying body as a signed distance function and clothing as an unsigned distance function, and they can be uniformly represented as unsigned distance fields. Different types of clothing do not require predefined topological structures or classifications, and can follow changes in the underlying body to fit the body. Additionally, we construct poses using a controllable articulated structure. The model is trained on both open and newly constructed datasets, and our decoupling strategy is carefully designed to ensure optimal performance. Our model excels at disentangling clothing and identity in different shape and poses while preserving the style of the clothing. We demonstrate that Neural-ABC fits new observations of different types of clothing. Compared to other state-of-the-art parametric models, Neural-ABC demonstrates powerful advantages in the reconstruction of clothed human bodies, as evidenced by fitting raw scans, depth maps and images. We show that the attributes of the fitted results can be further edited by adjusting their identities, clothing, shape and pose codes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE Transactions on Visualization and Computer Graphics. Project page: https://ustc3dv.github.io/NeuralABC/"
    },
    {
        "paper id": "2404.04677",
        "abstract url": "https://arxiv.org/abs/2404.04677",
        "title": "Salient Sparse Visual Odometry With Pose-Only Supervision",
        "rating": 0,
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual Odometry (VO) is vital for the navigation of autonomous systems, providing accurate position and orientation estimates at reasonable costs. While traditional VO methods excel in some conditions, they struggle with challenges like variable lighting and motion blur. Deep learning-based VO, though more adaptable, can face generalization problems in new environments. Addressing these drawbacks, this paper presents a novel hybrid visual odometry (VO) framework that leverages pose-only supervision, offering a balanced solution between robustness and the need for extensive labeling. We propose two cost-effective and innovative designs: a self-supervised homographic pre-training for enhancing optical flow learning from pose-only labels and a random patch-based salient point detection strategy for more accurate optical flow patch extraction. These designs eliminate the need for dense optical flow labels for training and significantly improve the generalization capability of the system in diverse and challenging environments. Our pose-only supervised method achieves competitive performance on standard datasets and greater robustness and generalization ability in extreme and unseen scenarios, even compared to dense optical flow-supervised state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE Robotics and Automation Letters"
    },
    {
        "paper id": "2404.04720",
        "abstract url": "https://arxiv.org/abs/2404.04720",
        "title": "On Exploring PDE Modeling for Point Cloud Video Representation Learning",
        "rating": 0,
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Point cloud video representation learning is challenging due to complex structures and unordered spatial arrangement. Traditional methods struggle with frame-to-frame correlations and point-wise correspondence tracking. Recently, partial differential equations (PDE) have provided a new perspective in uniformly solving spatial-temporal data information within certain constraints. While tracking tangible point correspondence remains challenging, we propose to formalize point cloud video representation learning as a PDE-solving problem. Inspired by fluid analysis, where PDEs are used to solve the deformation of spatial shape over time, we employ PDE to solve the variations of spatial points affected by temporal information. By modeling spatial-temporal correlations, we aim to regularize spatial variations with temporal features, thereby enhancing representation learning in point cloud videos. We introduce Motion PointNet composed of a PointNet-like encoder and a PDE-solving module. Initially, we construct a lightweight yet effective encoder to model an initial state of the spatial variations. Subsequently, we develop our PDE-solving module in a parameterized latent space, tailored to address the spatio-temporal correlations inherent in point cloud video. The process of solving PDE is guided and refined by a contrastive learning structure, which is pivotal in reshaping the feature distribution, thereby optimizing the feature representation within point cloud video data. Remarkably, our Motion PointNet achieves an impressive accuracy of 97.52% on the MSRAction-3D dataset, surpassing the current state-of-the-art in all aspects while consuming minimal resources (only 0.72M parameters and 0.82G FLOPs).",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04739",
        "abstract url": "https://arxiv.org/abs/2404.04739",
        "title": "Mathematics of the MML functional quantizer modules for VCV Rack software synthesizer",
        "rating": 0,
        "keywords": [
            [
                "synthesizer"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "We detail the mathematical formulation of the line of \"functional quantizer\" modules developed by the Mathematics and Music Lab (MML) at Michigan Technological University, for the VCV Rack software modular synthesizer platform, which allow synthesizer players to tune oscillators to new musical scales based on mathematical functions. For example, we describe the recently-released MML Logarithmic Quantizer (LOG QNT) module that tunes synthesizer oscillators to the non-Pythagorean musical scale introduced by indie band The Apples in Stereo.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "4 pages, published in Infinite Loop: an online journal for undergraduate research and applied computing projects (2024)"
    },
    {
        "paper id": "2404.04745",
        "abstract url": "https://arxiv.org/abs/2404.04745",
        "title": "Collaborative Feedback Discriminative Propagation for Video Super-Resolution",
        "rating": 0,
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The key success of existing video super-resolution (VSR) methods stems mainly from exploring spatial and temporal information, which is usually achieved by a recurrent propagation module with an alignment module. However, inaccurate alignment usually leads to aligned features with significant artifacts, which will be accumulated during propagation and thus affect video restoration. Moreover, propagation modules only propagate the same timestep features forward or backward that may fail in case of complex motion or occlusion, limiting their performance for high-quality frame restoration. To address these issues, we propose a collaborative feedback discriminative (CFD) method to correct inaccurate aligned features and model long -range spatial and temporal information for better video reconstruction. In detail, we develop a discriminative alignment correction (DAC) method to adaptively explore information and reduce the influences of the artifacts caused by inaccurate alignment. Then, we propose a collaborative feedback propagation (CFP) module that employs feedback and gating mechanisms to better explore spatial and temporal information of different timestep features from forward and backward propagation simultaneously. Finally, we embed the proposed DAC and CFP into commonly used VSR networks to verify the effectiveness of our method. Quantitative and qualitative experiments on several benchmarks demonstrate that our method can improve the performance of existing VSR models while maintaining a lower model complexity. The source code and pre-trained models will be available at \\url{https://github.com/House-Leo/CFDVSR}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project website: https://github.com/House-Leo/CFDVSR"
    },
    {
        "paper id": "2404.04538",
        "abstract url": "https://arxiv.org/abs/2404.04538",
        "title": "Soft-Prompting with Graph-of-Thought for Multi-modal Representation Learning",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The chain-of-thought technique has been received well in multi-modal tasks. It is a step-by-step linear reasoning process that adjusts the length of the chain to improve the performance of generated prompts. However, human thought processes are predominantly non-linear, as they encompass multiple aspects simultaneously and employ dynamic adjustment and updating mechanisms. Therefore, we propose a novel Aggregation-Graph-of-Thought (AGoT) mechanism for soft-prompt tuning in multi-modal representation learning. The proposed AGoT models the human thought process not only as a chain but also models each step as a reasoning aggregation graph to cope with the overlooked multiple aspects of thinking in single-step reasoning. This turns the entire reasoning process into prompt aggregation and prompt flow operations. Experiments show that our multi-modal model enhanced with AGoT soft-prompting achieves good results in several tasks such as text-image retrieval, visual question answering, and image recognition. In addition, we demonstrate that it has good domain generalization performance due to better reasoning.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "This paper is accepted to LREC-COLING 2024"
    },
    {
        "paper id": "2404.04559",
        "abstract url": "https://arxiv.org/abs/2404.04559",
        "title": "Spectral GNN via Two-dimensional (2-D) Graph Convolution",
        "rating": -0.5,
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spectral Graph Neural Networks (GNNs) have achieved tremendous success in graph learning. As an essential part of spectral GNNs, spectral graph convolution extracts crucial frequency information in graph data, leading to superior performance of spectral GNNs in downstream tasks. However, in this paper, we show that existing spectral GNNs remain critical drawbacks in performing the spectral graph convolution. Specifically, considering the spectral graph convolution as a construction operation towards target output, we prove that existing popular convolution paradigms cannot construct the target output with mild conditions on input graph signals, causing spectral GNNs to fall into suboptimal solutions. To address the issues, we rethink the spectral graph convolution from a more general two-dimensional (2-D) signal convolution perspective and propose a new convolution paradigm, named 2-D graph convolution. We prove that 2-D graph convolution unifies existing graph convolution paradigms, and is capable to construct arbitrary target output. Based on the proposed 2-D graph convolution, we further propose ChebNet2D, an efficient and effective GNN implementation of 2-D graph convolution through applying Chebyshev interpolation. Extensive experiments on benchmark datasets demonstrate both effectiveness and efficiency of the ChebNet2D.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2404.04562",
        "abstract url": "https://arxiv.org/abs/2404.04562",
        "title": "Diffusion Time-step Curriculum for One Image to 3D Generation",
        "rating": -0.5,
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Score distillation sampling~(SDS) has been widely adopted to overcome the absence of unseen views in reconstructing 3D objects from a \\textbf{single} image. It leverages pre-trained 2D diffusion models as teacher to guide the reconstruction of student 3D models. Despite their remarkable success, SDS-based methods often encounter geometric artifacts and texture saturation. We find out the crux is the overlooked indiscriminate treatment of diffusion time-steps during optimization: it unreasonably treats the student-teacher knowledge distillation to be equal at all time-steps and thus entangles coarse-grained and fine-grained modeling. Therefore, we propose the Diffusion Time-step Curriculum one-image-to-3D pipeline (DTC123), which involves both the teacher and student models collaborating with the time-step curriculum in a coarse-to-fine manner. Extensive experiments on NeRF4, RealFusion15, GSO and Level50 benchmark demonstrate that DTC123 can produce multi-view consistent, high-quality, and diverse 3D assets. Codes and more generation demos will be released in https://github.com/yxymessi/DTC123.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to CVPR 2024"
    },
    {
        "paper id": "2404.04612",
        "abstract url": "https://arxiv.org/abs/2404.04612",
        "title": "Spectral Graph Pruning Against Over-Squashing and Over-Smoothing",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Message Passing Graph Neural Networks are known to suffer from two problems that are sometimes believed to be diametrically opposed: over-squashing and over-smoothing. The former results from topological bottlenecks that hamper the information flow from distant nodes and are mitigated by spectral gap maximization, primarily, by means of edge additions. However, such additions often promote over-smoothing that renders nodes of different classes less distinguishable. Inspired by the Braess phenomenon, we argue that deleting edges can address over-squashing and over-smoothing simultaneously. This insight explains how edge deletions can improve generalization, thus connecting spectral gap optimization to a seemingly disconnected objective of reducing computational resources by pruning graphs for lottery tickets. To this end, we propose a more effective spectral gap optimization framework to add or delete edges and demonstrate its effectiveness on large heterophilic datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04616",
        "abstract url": "https://arxiv.org/abs/2404.04616",
        "title": "Vanishing Variance Problem in Fully Decentralized Neural-Network Systems",
        "rating": -0.5,
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning and gossip learning are emerging methodologies designed to mitigate data privacy concerns by retaining training data on client devices and exclusively sharing locally-trained machine learning (ML) models with others. The primary distinction between the two lies in their approach to model aggregation: federated learning employs a centralized parameter server, whereas gossip learning adopts a fully decentralized mechanism, enabling direct model exchanges among nodes. This decentralized nature often positions gossip learning as less efficient compared to federated learning. Both methodologies involve a critical step: computing a representation of received ML models and integrating this representation into the existing model. Conventionally, this representation is derived by averaging the received models, exemplified by the FedAVG algorithm. Our findings suggest that this averaging approach inherently introduces a potential delay in model convergence. We identify the underlying cause and refer to it as the \"vanishing variance\" problem, where averaging across uncorrelated ML models undermines the optimal variance established by the Xavier weight initialization. Unlike federated learning where the central server ensures model correlation, and unlike traditional gossip learning which circumvents this problem through model partitioning and sampling, our research introduces a variance-corrected model averaging algorithm. This novel algorithm preserves the optimal variance needed during model averaging, irrespective of network topology or non-IID data distributions. Our extensive simulation results demonstrate that our approach enables gossip learning to achieve convergence efficiency comparable to that of federated learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2404.04619",
        "abstract url": "https://arxiv.org/abs/2404.04619",
        "title": "Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model",
        "rating": -0.5,
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the power of large language models (LLMs), open-ended embodied agents can flexibly understand human instructions, generate interpretable guidance strategies, and output executable actions. Nowadays, Multi-modal Language Models~(MLMs) integrate multi-modal signals into LLMs, further bringing richer perception to entity agents and allowing embodied agents to perceive world-understanding tasks more delicately. However, existing works: 1) operate independently by agents, each containing multiple LLMs, from perception to action, resulting in gaps between complex tasks and execution; 2) train MLMs on static data, struggling with dynamics in open-ended scenarios; 3) input prior knowledge directly as prompts, suppressing application flexibility. We propose STEVE-2, a hierarchical knowledge distillation framework for open-ended embodied tasks, characterized by 1) a hierarchical system for multi-granular task division, 2) a mirrored distillation method for parallel simulation data, and 3) an extra expert model for bringing additional knowledge into parallel simulation. After distillation, embodied agents can complete complex, open-ended tasks without additional expert guidance, utilizing the performance and knowledge of a versatile MLM. Extensive evaluations on navigation and creation tasks highlight the superior performance of STEVE-2 in open-ended tasks, with $1.4 \\times$ - $7.3 \\times$ in performance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2403.08282"
    },
    {
        "paper id": "2404.04735",
        "abstract url": "https://arxiv.org/abs/2404.04735",
        "title": "MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems",
        "rating": -0.5,
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advancements in large language models, such as GPT-4, have demonstrated remarkable capabilities in processing standard queries. Despite these advancements, their performance substantially declines in \\textbf{advanced mathematical problems requiring complex, multi-step logical reasoning}. To enhance their inferential capabilities, current research has delved into \\textit{prompting engineering}, exemplified by methodologies such as the Tree of Thought and Graph of Thought. Nonetheless, these existing approaches encounter two significant limitations. Firstly, their effectiveness in tackling complex mathematical problems is somewhat constrained. Secondly, the necessity to design distinct prompts for individual problems hampers their generalizability. In response to these limitations, this paper introduces the \\textit{Multi-Agent System for conditional Mining} (\\textbf{MACM}) prompting method. It not only resolves intricate mathematical problems but also demonstrates strong generalization capabilities across various mathematical contexts. With the assistance of MACM, the accuracy of GPT-4 Turbo on the most challenging level five mathematical problems in the MATH dataset increase from $\\mathbf{54.68\\%} \\text{ to } \\mathbf{76.73\\%}$. The code is available in \\url{https://github.com/bin123apple/MACM}.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04740",
        "abstract url": "https://arxiv.org/abs/2404.04740",
        "title": "Fifth Generation IMC: Expanding the scope to Profit, People, and the Planet",
        "rating": -0.5,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "This editorial outlines an expanded scope for the next (fifth) generation of integrated marketing communication. It identifies key market forces that gave rise to this evolution and describes a trajectory of where Integrated Marketing Communication (IMC) has been and where it is going. The central shift is moving from primarily focusing on one stakeholder to multiple ones, including people (employees and society), the planet (environment), and profits. It identifies examples from industry that exemplify multi-stakeholder decision-making and uses the examples to suggest research questions that academics and practitioners should address. Examples and research directions are organized around marketing strategy, communication media and messages, and measurement systems.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04752",
        "abstract url": "https://arxiv.org/abs/2404.04752",
        "title": "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking",
        "rating": -0.5,
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Flocking is a behavior where multiple agents in a system attempt to stay close to each other while avoiding collision and maintaining a desired formation. This is observed in the natural world and has applications in robotics, including natural disaster search and rescue, wild animal tracking, and perimeter surveillance and patrol. Recently, large language models (LLMs) have displayed an impressive ability to solve various collaboration tasks as individual decision-makers. Solving multi-agent flocking with LLMs would demonstrate their usefulness in situations requiring spatial and decentralized decision-making. Yet, when LLM-powered agents are tasked with implementing multi-agent flocking, they fall short of the desired behavior. After extensive testing, we find that agents with LLMs as individual decision-makers typically opt to converge on the average of their initial positions or diverge from each other. After breaking the problem down, we discover that LLMs cannot understand maintaining a shape or keeping a distance in a meaningful way. Solving multi-agent flocking with LLMs would enhance their ability to understand collaborative spatial reasoning and lay a foundation for addressing more complex multi-agent tasks. This paper discusses the challenges LLMs face in multi-agent flocking and suggests areas for future improvement and research.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04510",
        "abstract url": "https://arxiv.org/abs/2404.04510",
        "title": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials",
        "rating": -1,
        "keywords": [
            [
                "Biomedical",
                "cancer",
                "Clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language models (LLMs) have demonstrated state-of-the-art performance in various natural language processing (NLP) tasks across multiple domains, yet they are prone to shortcut learning and factual inconsistencies. This research investigates LLMs' robustness, consistency, and faithful reasoning when performing Natural Language Inference (NLI) on breast cancer Clinical Trial Reports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials. We examine the reasoning capabilities of LLMs and their adeptness at logical problem-solving. A comparative analysis is conducted on pre-trained language models (PLMs), GPT-3.5, and Gemini Pro under zero-shot settings using Retrieval-Augmented Generation (RAG) framework, integrating various reasoning chains. The evaluation yields an F1 score of 0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test dataset.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at SemEval 2024, NAACL 2024; 8 Pages"
    },
    {
        "paper id": "2404.04520",
        "abstract url": "https://arxiv.org/abs/2404.04520",
        "title": "IITK at SemEval-2024 Task 4: Hierarchical Embeddings for Detection of Persuasion Techniques in Memes",
        "rating": -1,
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Memes are one of the most popular types of content used in an online disinformation campaign. They are primarily effective on social media platforms since they can easily reach many users. Memes in a disinformation campaign achieve their goal of influencing the users through several rhetorical and psychological techniques, such as causal oversimplification, name-calling, and smear. The SemEval 2024 Task 4 \\textit{Multilingual Detection of Persuasion Technique in Memes} on identifying such techniques in the memes is divided across three sub-tasks: ($\\mathbf{1}$) Hierarchical multi-label classification using only textual content of the meme, ($\\mathbf{2}$) Hierarchical multi-label classification using both, textual and visual content of the meme and ($\\mathbf{3}$) Binary classification of whether the meme contains a persuasion technique or not using it's textual and visual content. This paper proposes an ensemble of Class Definition Prediction (CDP) and hyperbolic embeddings-based approaches for this task. We enhance meme classification accuracy and comprehensiveness by integrating HypEmo's hierarchical label embeddings (Chen et al., 2023) and a multi-task learning framework for emotion prediction. We achieve a hierarchical F1-score of 0.60, 0.67, and 0.48 on the respective sub-tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at SemEval 2024, NAACL 2024; 9 pages"
    },
    {
        "paper id": "2404.04526",
        "abstract url": "https://arxiv.org/abs/2404.04526",
        "title": "DATENeRF: Depth-Aware Text-based Editing of NeRFs",
        "rating": -1,
        "keywords": [
            [
                "Depth",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in diffusion models have shown remarkable proficiency in editing 2D images based on text prompts. However, extending these techniques to edit scenes in Neural Radiance Fields (NeRF) is complex, as editing individual 2D frames can result in inconsistencies across multiple views. Our crucial insight is that a NeRF scene's geometry can serve as a bridge to integrate these 2D edits. Utilizing this geometry, we employ a depth-conditioned ControlNet to enhance the coherence of each 2D image modification. Moreover, we introduce an inpainting approach that leverages the depth information of NeRF scenes to distribute 2D edits across different images, ensuring robustness against errors and resampling challenges. Our results reveal that this methodology achieves more consistent, lifelike, and detailed edits than existing leading methods for text-driven NeRF scene editing.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, Conference paper, 3D Scene Editing, Neural Rendering, Diffusion Models"
    },
    {
        "paper id": "2404.04531",
        "abstract url": "https://arxiv.org/abs/2404.04531",
        "title": "Frequency Decomposition-Driven Unsupervised Domain Adaptation for Remote Sensing Image Semantic Segmentation",
        "rating": -1,
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cross-domain semantic segmentation of remote sensing (RS) imagery based on unsupervised domain adaptation (UDA) techniques has significantly advanced deep-learning applications in the geosciences. Recently, with its ingenious and versatile architecture, the Transformer model has been successfully applied in RS-UDA tasks. However, existing UDA methods mainly focus on domain alignment in the high-level feature space. It is still challenging to retain cross-domain local spatial details and global contextual semantics simultaneously, which is crucial for the RS image semantic segmentation task. To address these problems, we propose novel high/low-frequency decomposition (HLFD) techniques to guide representation alignment in cross-domain semantic segmentation. Specifically, HLFD attempts to decompose the feature maps into high- and low-frequency components before performing the domain alignment in the corresponding subspaces. Secondly, to further facilitate the alignment of decomposed features, we propose a fully global-local generative adversarial network, namely GLGAN, to learn domain-invariant detailed and semantic features across domains by leveraging global-local transformer blocks (GLTBs). By integrating HLFD techniques and the GLGAN, a novel UDA framework called FD-GLGAN is developed to improve the cross-domain transferability and generalization capability of semantic segmentation models. Extensive experiments on two fine-resolution benchmark datasets, namely ISPRS Potsdam and ISPRS Vaihingen, highlight the effectiveness and superiority of the proposed approach as compared to the state-of-the-art UDA methods. The source code for this work will be accessible at https://github.com/sstary/SSRS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "28 pages, 13 figures"
    },
    {
        "paper id": "2404.04549",
        "abstract url": "https://arxiv.org/abs/2404.04549",
        "title": "Efficient Learning Using Spiking Neural Networks Equipped With Affine Encoders and Decoders",
        "rating": -1,
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "We study the learning problem associated with spiking neural networks. Specifically, we consider hypothesis sets of spiking neural networks with affine temporal encoders and decoders and simple spiking neurons having only positive synaptic weights. We demonstrate that the positivity of the weights continues to enable a wide range of expressivity results, including rate-optimal approximation of smooth functions or approximation without the curse of dimensionality. Moreover, positive-weight spiking neural networks are shown to depend continuously on their parameters which facilitates classical covering number-based generalization statements. Finally, we observe that from a generalization perspective, contrary to feedforward neural networks or previous results for general spiking neural networks, the depth has little to no adverse effect on the generalization capabilities.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04550",
        "abstract url": "https://arxiv.org/abs/2404.04550",
        "title": "NPB-REC: A Non-parametric Bayesian Deep-learning Approach for Undersampled MRI Reconstruction with Uncertainty Estimation",
        "rating": -1,
        "keywords": [
            [
                "MRI",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The ability to reconstruct high-quality images from undersampled MRI data is vital in improving MRI temporal resolution and reducing acquisition times. Deep learning methods have been proposed for this task, but the lack of verified methods to quantify the uncertainty in the reconstructed images hampered clinical applicability. We introduce \"NPB-REC\", a non-parametric fully Bayesian framework, for MRI reconstruction from undersampled data with uncertainty estimation. We use Stochastic Gradient Langevin Dynamics during training to characterize the posterior distribution of the network parameters. This enables us to both improve the quality of the reconstructed images and quantify the uncertainty in the reconstructed images. We demonstrate the efficacy of our approach on a multi-coil MRI dataset from the fastMRI challenge and compare it to the baseline End-to-End Variational Network (E2E-VarNet). Our approach outperforms the baseline in terms of reconstruction accuracy by means of PSNR and SSIM ($34.55$, $0.908$ vs. $33.08$, $0.897$, $p<0.01$, acceleration rate $R=8$) and provides uncertainty measures that correlate better with the reconstruction error (Pearson correlation, $R=0.94$ vs. $R=0.91$). Additionally, our approach exhibits better generalization capabilities against anatomical distribution shifts (PSNR and SSIM of $32.38$, $0.849$ vs. $31.63$, $0.836$, $p<0.01$, training on brain data, inference on knee data, acceleration rate $R=8$). NPB-REC has the potential to facilitate the safe utilization of deep learning-based methods for MRI reconstruction from undersampled data. Code and trained models are available at \\url{https://github.com/samahkh/NPB-REC}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published in Artificial Intelligence in Medicine, DOI: https://doi.org/10.1016/j.artmed.2024.102798 This is an extension representing a more comprehensive work extending preliminary work presented at arXiv:2208.03966"
    },
    {
        "paper id": "2404.04556",
        "abstract url": "https://arxiv.org/abs/2404.04556",
        "title": "Rethinking Self-training for Semi-supervised Landmark Detection: A Selection-free Approach",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Self-training is a simple yet effective method for semi-supervised learning, during which pseudo-label selection plays an important role for handling confirmation bias. Despite its popularity, applying self-training to landmark detection faces three problems: 1) The selected confident pseudo-labels often contain data bias, which may hurt model performance; 2) It is not easy to decide a proper threshold for sample selection as the localization task can be sensitive to noisy pseudo-labels; 3) coordinate regression does not output confidence, making selection-based self-training infeasible. To address the above issues, we propose Self-Training for Landmark Detection (STLD), a method that does not require explicit pseudo-label selection. Instead, STLD constructs a task curriculum to deal with confirmation bias, which progressively transitions from more confident to less confident tasks over the rounds of self-training. Pseudo pretraining and shrink regression are two essential components for such a curriculum, where the former is the first task of the curriculum for providing a better model initialization and the latter is further added in the later rounds to directly leverage the pseudo-labels in a coarse-to-fine manner. Experiments on three facial and one medical landmark detection benchmark show that STLD outperforms the existing methods consistently in both semi- and omni-supervised settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2404.04561",
        "abstract url": "https://arxiv.org/abs/2404.04561",
        "title": "Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction",
        "rating": -1,
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D semantic occupancy prediction is a pivotal task in the field of autonomous driving. Recent approaches have made great advances in 3D semantic occupancy predictions on a single modality. However, multi-modal semantic occupancy prediction approaches have encountered difficulties in dealing with the modality heterogeneity, modality misalignment, and insufficient modality interactions that arise during the fusion of different modalities data, which may result in the loss of important geometric and semantic information. This letter presents a novel multi-modal, i.e., LiDAR-camera 3D semantic occupancy prediction framework, dubbed Co-Occ, which couples explicit LiDAR-camera feature fusion with implicit volume rendering regularization. The key insight is that volume rendering in the feature space can proficiently bridge the gap between 3D LiDAR sweeps and 2D images while serving as a physical regularization to enhance LiDAR-camera fused volumetric representation. Specifically, we first propose a Geometric- and Semantic-aware Fusion (GSFusion) module to explicitly enhance LiDAR features by incorporating neighboring camera features through a K-nearest neighbors (KNN) search. Then, we employ volume rendering to project the fused feature back to the image planes for reconstructing color and depth maps. These maps are then supervised by input images from the camera and depth estimations derived from LiDAR, respectively. Extensive experiments on the popular nuScenes and SemanticKITTI benchmarks verify the effectiveness of our Co-Occ for 3D semantic occupancy prediction. The project page is available at https://rorisis.github.io/Co-Occ_project-page/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04579",
        "abstract url": "https://arxiv.org/abs/2404.04579",
        "title": "TeleAware Robot: Designing Awareness-augmented Telepresence Robot for Remote Collaborative Locomotion",
        "rating": -1,
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Telepresence robots can be used to support users to navigate an environment remotely and share the visiting experience with their social partners. Although such systems allow users to see and hear the remote environment and communicate with their partners via live video feed, this does not provide enough awareness of the environment and their remote partner's activities. In this paper, we introduce an awareness framework for collaborative locomotion in scenarios of onsite and remote users visiting a place together. From an observational study of small groups of people visiting exhibitions, we derived four design goals for enhancing the environmental and social awareness between social partners, and developed a set of awareness-enhancing techniques to add to a standard telepresence robot - named TeleAware robot. Through a controlled experiment simulating a guided exhibition visiting task, TeleAware robot showed the ability to lower the workload, facilitate closer social proximity, and improve mutual awareness and social presence compared with the standard one. We discuss the impact of mobility and roles of local and remote users, and provide insights for the future design of awareness-enhancing telepresence robot systems that facilitate collaborative locomotion.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "33 pages, 12 figures"
    },
    {
        "paper id": "2404.04601",
        "abstract url": "https://arxiv.org/abs/2404.04601",
        "title": "Exploiting Sequence Number Leakage: TCP Hijacking in NAT-Enabled Wi-Fi Networks",
        "rating": -1,
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "In this paper, we uncover a new side-channel vulnerability in the widely used NAT port preservation strategy and an insufficient reverse path validation strategy of Wi-Fi routers, which allows an off-path attacker to infer if there is one victim client in the same network communicating with another host on the Internet using TCP. After detecting the presence of TCP connections between the victim client and the server, the attacker can evict the original NAT mapping and reconstruct a new mapping at the router by sending fake TCP packets due to the routers' vulnerability of disabling TCP window tracking strategy, which has been faithfully implemented in most of the routers for years. In this way, the attacker can intercept TCP packets from the server and obtain the current sequence and acknowledgment numbers, which in turn allows the attacker to forcibly close the connection, poison the traffic in plain text, or reroute the server's incoming packets to the attacker. We test 67 widely used routers from 30 vendors and discover that 52 of them are affected by this attack. Also, we conduct an extensive measurement study on 93 real-world Wi-Fi networks. The experimental results show that 75 of these evaluated Wi-Fi networks (81%) are fully vulnerable to our attack. Our case study shows that it takes about 17.5, 19.4, and 54.5 seconds on average to terminate an SSH connection, download private files from FTP servers, and inject fake HTTP response packets with success rates of 87.4%, 82.6%, and 76.1%. We responsibly disclose the vulnerability and suggest mitigation strategies to all affected vendors and have received positive feedback, including acknowledgments, CVEs, rewards, and adoption of our suggestions.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted by Network and Distributed System Security (NDSS) Symposium 2024"
    },
    {
        "paper id": "2404.04608",
        "abstract url": "https://arxiv.org/abs/2404.04608",
        "title": "Panoptic Perception: A Novel Task and Fine-grained Dataset for Universal Remote Sensing Image Interpretation",
        "rating": -1,
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current remote-sensing interpretation models often focus on a single task such as detection, segmentation, or caption. However, the task-specific designed models are unattainable to achieve the comprehensive multi-level interpretation of images. The field also lacks support for multi-task joint interpretation datasets. In this paper, we propose Panoptic Perception, a novel task and a new fine-grained dataset (FineGrip) to achieve a more thorough and universal interpretation for RSIs. The new task, 1) integrates pixel-level, instance-level, and image-level information for universal image perception, 2) captures image information from coarse to fine granularity, achieving deeper scene understanding and description, and 3) enables various independent tasks to complement and enhance each other through multi-task learning. By emphasizing multi-task interactions and the consistency of perception results, this task enables the simultaneous processing of fine-grained foreground instance segmentation, background semantic segmentation, and global fine-grained image captioning. Concretely, the FineGrip dataset includes 2,649 remote sensing images, 12,054 fine-grained instance segmentation masks belonging to 20 foreground things categories, 7,599 background semantic masks for 5 stuff classes and 13,245 captioning sentences. Furthermore, we propose a joint optimization-based panoptic perception model. Experimental results on FineGrip demonstrate the feasibility of the panoptic perception task and the beneficial effect of multi-task joint optimization on individual tasks. The dataset will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04617",
        "abstract url": "https://arxiv.org/abs/2404.04617",
        "title": "Empowering Image Recovery_ A Multi-Attention Approach",
        "rating": -1,
        "keywords": [
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose Diverse Restormer (DART), a novel image restoration method that effectively integrates information from various sources (long sequences, local and global regions, feature dimensions, and positional dimensions) to address restoration challenges. While Transformer models have demonstrated excellent performance in image restoration due to their self-attention mechanism, they face limitations in complex scenarios. Leveraging recent advancements in Transformers and various attention mechanisms, our method utilizes customized attention mechanisms to enhance overall performance. DART, our novel network architecture, employs windowed attention to mimic the selective focusing mechanism of human eyes. By dynamically adjusting receptive fields, it optimally captures the fundamental features crucial for image resolution reconstruction. Efficiency and performance balance are achieved through the LongIR attention mechanism for long sequence image restoration. Integration of attention mechanisms across feature and positional dimensions further enhances the recovery of fine details. Evaluation across five restoration tasks consistently positions DART at the forefront. Upon acceptance, we commit to providing publicly accessible code and models to ensure reproducibility and facilitate further research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 10 figures, 12 tables"
    },
    {
        "paper id": "2404.04635",
        "abstract url": "https://arxiv.org/abs/2404.04635",
        "title": "A Deep Look Into -- Automated Lung X-Ray Abnormality Detection System",
        "rating": -1,
        "keywords": [
            [
                "X-Ray",
                "disease"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Introduction: Automated Lung X-Ray Abnormality Detection System is the application which distinguish the normal x-ray images from infected x-ray images and highlight area considered for prediction, with the recent pandemic a need to have a non-conventional method and faster detecting diseases, for which X ray serves the purpose. Obectives: As of current situation any viral disease that is infectious is potential pandemic, so there is need for cheap and early detection system. Methods: This research will help to eases the work of expert to do further analysis. Accuracy of three different preexisting models such as DenseNet, MobileNet and VGG16 were high but models over-fitted primarily due to black and white images. Results: This led to building up new method such as as V-BreathNet which gave more than 96% percent accuracy. Conclusion: Thus, it can be stated that not all state-of art CNN models can be used on B/W images. In conclusion not all state-of-art CNN models can be used on B/W images.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04663",
        "abstract url": "https://arxiv.org/abs/2404.04663",
        "title": "Focused Active Learning for Histopathological Image Classification",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "cancer"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Active Learning (AL) has the potential to solve a major problem of digital pathology: the efficient acquisition of labeled data for machine learning algorithms. However, existing AL methods often struggle in realistic settings with artifacts, ambiguities, and class imbalances, as commonly seen in the medical field. The lack of precise uncertainty estimations leads to the acquisition of images with a low informative value. To address these challenges, we propose Focused Active Learning (FocAL), which combines a Bayesian Neural Network with Out-of-Distribution detection to estimate different uncertainties for the acquisition function. Specifically, the weighted epistemic uncertainty accounts for the class imbalance, aleatoric uncertainty for ambiguous images, and an OoD score for artifacts. We perform extensive experiments to validate our method on MNIST and the real-world Panda dataset for the classification of prostate cancer. The results confirm that other AL methods are 'distracted' by ambiguities and artifacts which harm the performance. FocAL effectively focuses on the most informative images, avoiding ambiguities and artifacts during acquisition. For both experiments, FocAL outperforms existing AL approaches, reaching a Cohen's kappa of 0.764 with only 0.69% of the labeled Panda data.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04722",
        "abstract url": "https://arxiv.org/abs/2404.04722",
        "title": "PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics",
        "rating": -1,
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite tremendous advancements in large language models (LLMs) over recent years, a notably urgent challenge for their practical deployment is the phenomenon of hallucination, where the model fabricates facts and produces non-factual statements. In response, we propose PoLLMgraph, a Polygraph for LLMs, as an effective model-based white-box detection and forecasting approach. PoLLMgraph distinctly differs from the large body of existing research that concentrates on addressing such challenges through black-box evaluations. In particular, we demonstrate that hallucination can be effectively detected by analyzing the LLM's internal state transition dynamics during generation via tractable probabilistic models. Experimental results on various open-source LLMs confirm the efficacy of PoLLMgraph, outperforming state-of-the-art methods by a considerable margin, evidenced by over 20% improvement in AUC-ROC on common benchmarking datasets like TruthfulQA. Our work paves a new way for model-based white-box analysis of LLMs, motivating the research community to further explore, understand, and refine the intricate dynamics of LLM behaviors.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2404.04731",
        "abstract url": "https://arxiv.org/abs/2404.04731",
        "title": "SAT-DIFF: A Tree Diffing Framework Using SAT Solving",
        "rating": -1,
        "keywords": [
            [
                "synthesize"
            ]
        ],
        "abstract": "Computing differences between tree-structured data is a critical but challenging problem in software analysis. In this paper, we propose a novel tree diffing approach called SatDiff, which reformulates the structural diffing problem into a MaxSAT problem. By encoding the necessary transformations from the source tree to the target tree, SatDiff generates correct, minimal, and type safe low-level edit scripts with formal guarantees. We then synthesize concise high-level edit scripts by effectively merging low-level edits in the appropriate topological order. Our empirical results demonstrate that SatDiff outperforms existing heuristic-based approaches by a significant margin in terms of conciseness while maintaining a reasonable runtime.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "23 pages, 7 figures"
    },
    {
        "paper id": "2404.04736",
        "abstract url": "https://arxiv.org/abs/2404.04736",
        "title": "ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging",
        "rating": -1,
        "keywords": [
            [
                "medical",
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The adoption of Deep Learning algorithms in the medical imaging field is a prominent area of research, with high potential for advancing AI-based Computer-aided diagnosis (AI-CAD) solutions. However, current solutions face challenges due to a lack of interpretability features and high data demands, prompting recent efforts to address these issues. In this study, we propose the ProtoAL method, where we integrate an interpretable DL model into the Deep Active Learning (DAL) framework. This approach aims to address both challenges by focusing on the medical imaging context and utilizing an inherently interpretable model based on prototypes. We evaluated ProtoAL on the Messidor dataset, achieving an area under the precision-recall curve of 0.79 while utilizing only 76.54\\% of the available labeled data. These capabilities can enhances the practical usability of a DL model in the medical field, providing a means of trust calibration in domain experts and a suitable solution for learning in the data scarcity context often found.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04743",
        "abstract url": "https://arxiv.org/abs/2404.04743",
        "title": "From Batch to Stream: Automatic Generation of Online Algorithms",
        "rating": -1,
        "keywords": [
            [
                "synthesizing"
            ]
        ],
        "abstract": "Online streaming algorithms, tailored for continuous data processing, offer substantial benefits but are often more intricate to design than their offline counterparts. This paper introduces a novel approach for automatically synthesizing online streaming algorithms from their offline versions. In particular, we propose a novel methodology, based on the notion of relational function signature (RFS), for deriving an online algorithm given its offline version. Then, we propose a concrete synthesis algorithm that is an instantiation of the proposed methodology. Our algorithm uses the RFS to decompose the synthesis problem into a set of independent subtasks and uses a combination of symbolic reasoning and search to solve each subproblem. We implement the proposed technique in a new tool called Opera and evaluate it on over 50 tasks spanning two domains: statistical computations and online auctions. Our results show that Opera can automatically derive the online version of the original algorithm for 98% of the tasks. Our experiments also demonstrate that Opera significantly outperforms alternative approaches, including adaptations of SyGuS solvers to this problem as well as two of Opera's own ablations.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04782",
        "abstract url": "https://arxiv.org/abs/2404.04782",
        "title": "The Church Synthesis Problem over Continuous Time",
        "rating": -1,
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "The Church Problem asks for the construction of a procedure which, given a logical specification A(I,O) between input omega-strings I and output omega-strings O, determines whether there exists an operator F that implements the specification in the sense that A(I, F(I)) holds for all inputs I. Buchi and Landweber provided a procedure to solve the Church problem for MSO specifications and operators computable by finite-state automata. We investigate a generalization of the Church synthesis problem to the continuous time of the non-negative reals. We show that in the continuous time there are phenomena which are very different from the canonical discrete time domain of the natural numbers.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04783",
        "abstract url": "https://arxiv.org/abs/2404.04783",
        "title": "Fourier Transform-based Wavenumber Domain 3D Imaging in RIS-aided Communication Systems",
        "rating": -1,
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Radio imaging is rapidly gaining prominence in the design of future communication systems, with the potential to utilize reconfigurable intelligent surfaces (RISs) as imaging apertures. Although the sparsity of targets in three-dimensional (3D) space has led most research to adopt compressed sensing (CS)-based imaging algorithms, these often require substantial computational and memory burdens. Drawing inspiration from conventional Fourier transform (FT)-based imaging methods, our research seeks to accelerate radio imaging in RIS-aided communication systems. To begin, we introduce a two-stage wavenumber domain 3D imaging technique: first, we modify RIS phase shifts to recover the equivalent channel response from the user equipment to the RIS array, subsequently employing traditional FT-based wavenumber domain methods to produce target images. We also determine the diffraction resolution limits of the system through k-space analysis, taking into account factors including system bandwidth, transmission direction, operating frequency, and the angle subtended by the RIS. Addressing the challenge of limited pilots in communication systems, we unveil an innovative algorithm that merges the strengths of both FT- and CS-based techniques by substituting the expansive sensing matrix with FT-based operators. Our simulation outcomes confirm that our proposed FT-based methods achieve high-quality images while demanding few time, memory, and communication resources.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "16 pages, 11 figures, submitted to IEEE for possible publication"
    },
    {
        "paper id": "2404.04792",
        "abstract url": "https://arxiv.org/abs/2404.04792",
        "title": "GDR-HGNN: A Heterogeneous Graph Neural Networks Accelerator Frontend with Graph Decoupling and Recoupling",
        "rating": -1,
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) have broadened the applicability of graph representation learning to heterogeneous graphs. However, the irregular memory access pattern of HGNNs leads to the buffer thrashing issue in HGNN accelerators. In this work, we identify an opportunity to address buffer thrashing in HGNN acceleration through an analysis of the topology of heterogeneous graphs. To harvest this opportunity, we propose a graph restructuring method and map it into a hardware frontend named GDR-HGNN. GDR-HGNN dynamically restructures the graph on the fly to enhance data locality for HGNN accelerators. Experimental results demonstrate that, with the assistance of GDR-HGNN, a leading HGNN accelerator achieves an average speedup of 14.6 times and 1.78 times compared to the state-of-the-art software framework running on A100 GPU and itself, respectively.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "6 pages, 10 figures, accepted by DAC'61"
    },
    {
        "paper id": "2404.05764",
        "abstract url": "https://arxiv.org/abs/2404.05764",
        "title": "Study of the effect of Sharpness on Blind Video Quality Assessment",
        "rating": -1,
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Introduction: Video Quality Assessment (VQA) is one of the important areas of study in this modern era, where video is a crucial component of communication with applications in every field. Rapid technology developments in mobile technology enabled anyone to create videos resulting in a varied range of video quality scenarios. Objectives: Though VQA was present for some time with the classical metrices like SSIM and PSNR, the advent of machine learning has brought in new techniques of VQAs which are built upon Convolutional Neural Networks (CNNs) or Deep Neural Networks (DNNs). Methods: Over the past years various research studies such as the BVQA which performed video quality assessment of nature-based videos using DNNs exposed the powerful capabilities of machine learning algorithms. BVQA using DNNs explored human visual system effects such as content dependency and time-related factors normally known as temporal effects. Results: This study explores the sharpness effect on models like BVQA. Sharpness is the measure of the clarity and details of the video image. Sharpness typically involves analyzing the edges and contrast of the image to determine the overall level of detail and sharpness. Conclusion: This study uses the existing video quality databases such as CVD2014. A comparative study of the various machine learning parameters such as SRCC and PLCC during the training and testing are presented along with the conclusion.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.07234",
        "abstract url": "https://arxiv.org/abs/2404.07234",
        "title": "Goal-guided Generative Prompt Injection Attack on Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "Current large language models (LLMs) provide a strong foundation for large-scale user-oriented natural language tasks. A large number of users can easily inject adversarial text or instructions through the user interface, thus causing LLMs model security challenges. Although there is currently a large amount of research on prompt injection attacks, most of these black-box attacks use heuristic strategies. It is unclear how these heuristic strategies relate to the success rate of attacks and thus effectively improve model robustness. To solve this problem, we redefine the goal of the attack: to maximize the KL divergence between the conditional probabilities of the clean text and the adversarial text. Furthermore, we prove that maximizing the KL divergence is equivalent to maximizing the Mahalanobis distance between the embedded representation $x$ and $x'$ of the clean text and the adversarial text when the conditional probability is a Gaussian distribution and gives a quantitative relationship on $x$ and $x'$. Then we designed a simple and effective goal-guided generative prompt injection strategy (G2PIA) to find an injection text that satisfies specific constraints to achieve the optimal attack effect approximately. It is particularly noteworthy that our attack method is a query-free black-box attack method with low computational cost. Experimental results on seven LLM models and four datasets show the effectiveness of our attack method.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "22 pages, 8 figures"
    },
    {
        "paper id": "2404.08677",
        "abstract url": "https://arxiv.org/abs/2404.08677",
        "title": "PMG : Personalized Multimodal Generation with Large Language Models",
        "rating": -1,
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "The emergence of large language models (LLMs) has revolutionized the capabilities of text comprehension and generation. Multi-modal generation attracts great attention from both the industry and academia, but there is little work on personalized generation, which has important applications such as recommender systems. This paper proposes the first method for personalized multimodal generation using LLMs, showcases its applications and validates its performance via an extensive experimental study on two datasets. The proposed method, Personalized Multimodal Generation (PMG for short) first converts user behaviors (e.g., clicks in recommender systems or conversations with a virtual assistant) into natural language to facilitate LLM understanding and extract user preference descriptions. Such user preferences are then fed into a generator, such as a multimodal LLM or diffusion model, to produce personalized content. To capture user preferences comprehensively and accurately, we propose to let the LLM output a combination of explicit keywords and implicit embeddings to represent user preferences. Then the combination of keywords and embeddings are used as prompts to condition the generator. We optimize a weighted sum of the accuracy and preference scores so that the generated content has a good balance between them. Compared to a baseline method without personalization, PMG has a significant improvement on personalization for up to 8% in terms of LPIPS while retaining the accuracy of generation.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.15327",
        "abstract url": "https://arxiv.org/abs/2404.15327",
        "title": "A Low-Complexity Design for IRS-Assisted Secure Dual-Function Radar-Communication System",
        "rating": -1,
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "In dual-function radar-communication (DFRC) systems the probing signal contains information intended for the communication users, which makes that information vulnerable to eavesdropping by the targets. We study the security of a DFRC system aided by an intelligent reflecting surface (IRS) from the physical layer security (PLS) perspective. The IRS helps overcome path loss or blockage and introduces more degrees of freedom for system design, however, it also makes the design problem more challenging. In the system considered, the radar embeds artificial noise (AN) in the probing waveform, and the radar waveform, the AN noise and the IRS parameters are designed to optimize the communication secrecy rate while meeting radar signal-to-noise ratio (SNR) constraints. The contribution of the paper is a novel, low complexity approach to solve the underlying optimization problem and obtain the design parameters. In particular, we consider an alternating optimization approach, where in each iteration, the problem is decomposed into two sub-problems, namely, one that designs the IRS parameters, and another that jointly designs the radar waveform and the AN. The challenges in those sub-problems are the fractional objective, the SNR being a quartic function of the IRS parameters, and the unit-modulus constraint on the IRS parameters. A fractional programming technique is used to transform the fractional form objective into a more tractable non-fractional polynomial form. A closed-form based approach is proposed for the IRS design problem, which results in low complexity IRS design. Numerical results are provided to demonstrate the convergence properties of the proposed system design method, the secrecy rate and beamforming performance of the designed system.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to IEEE Journal, under review. arXiv admin note: text overlap with arXiv:2310.00555"
    },
    {
        "paper id": "2404.04615",
        "abstract url": "https://arxiv.org/abs/2404.04615",
        "title": "PointSAGE: Mesh-independent superresolution approach to fluid flow predictions",
        "rating": -1.5,
        "keywords": [
            [
                "point cloud"
            ],
            [
                "superresolution"
            ],
            [
                "Workshop",
                "ICLR"
            ]
        ],
        "abstract": "Computational Fluid Dynamics (CFD) serves as a powerful tool for simulating fluid flow across diverse industries. High-resolution CFD simulations offer valuable insights into fluid behavior and flow patterns, aiding in optimizing design features or enhancing system performance. However, as resolution increases, computational data requirements and time increase proportionately. This presents a persistent challenge in CFD. Recently, efforts have been directed towards accurately predicting fine-mesh simulations using coarse-mesh simulations, with geometry and boundary conditions as input. Drawing inspiration from models designed for super-resolution, deep learning techniques like UNets have been applied to address this challenge. However, these existing methods are limited to structured data and fail if the mesh is unstructured due to its inability to convolute. Additionally, incorporating geometry/mesh information in the training process introduces drawbacks such as increased data requirements, challenges in generalizing to unseen geometries for the same physical phenomena, and issues with robustness to mesh distortions. To address these concerns, we propose a novel framework, PointSAGE a mesh-independent network that leverages the unordered, mesh-less nature of Pointcloud to learn the complex fluid flow and directly predict fine simulations, completely neglecting mesh information. Utilizing an adaptable framework, the model accurately predicts the fine data across diverse point cloud sizes, regardless of the training dataset's dimension. We have evaluated the effectiveness of PointSAGE on diverse datasets in different scenarios, demonstrating notable results and a significant acceleration in computational time in generating fine simulations compared to standard CFD techniques.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": "Accepted at Data-Centric Machine Learning Workshop (DMLR) at ICLR, 2024"
    },
    {
        "paper id": "2404.04661",
        "abstract url": "https://arxiv.org/abs/2404.04661",
        "title": "Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning",
        "rating": -1.5,
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many complex problems encountered in both production and daily life can be conceptualized as combinatorial optimization problems (COPs) over graphs. Recent years, reinforcement learning (RL) based models have emerged as a promising direction, which treat the COPs solving as a heuristic learning problem. However, current finite-horizon-MDP based RL models have inherent limitations. They are not allowed to explore adquately for improving solutions at test time, which may be necessary given the complexity of NP-hard optimization tasks. Some recent attempts solve this issue by focusing on reward design and state feature engineering, which are tedious and ad-hoc. In this work, we instead propose a much simpler but more effective technique, named gauge transformation (GT). The technique is originated from physics, but is very effective in enabling RL agents to explore to continuously improve the solutions during test. Morever, GT is very simple, which can be implemented with less than 10 lines of Python codes, and can be applied to a vast majority of RL models. Experimentally, we show that traditional RL models with GT technique produce the state-of-the-art performances on the MaxCut problem. Furthermore, since GT is independent of any RL models, it can be seamlessly integrated into various RL frameworks, paving the way of these models for more effective explorations in the solving of general COPs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04669",
        "abstract url": "https://arxiv.org/abs/2404.04669",
        "title": "Domain Generalisation via Imprecise Learning",
        "rating": -1.5,
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) generalisation is challenging because it involves not only learning from empirical data, but also deciding among various notions of generalisation, e.g., optimising the average-case risk, worst-case risk, or interpolations thereof. While this choice should in principle be made by the model operator like medical doctors, this information might not always be available at training time. The institutional separation between machine learners and model operators leads to arbitrary commitments to specific generalisation strategies by machine learners due to these deployment uncertainties. We introduce the Imprecise Domain Generalisation framework to mitigate this, featuring an imprecise risk optimisation that allows learners to stay imprecise by optimising against a continuous spectrum of generalisation strategies during training, and a model framework that allows operators to specify their generalisation preference at deployment. Supported by both theoretical and empirical evidence, our work showcases the benefits of integrating imprecision into domain generalisation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04686",
        "abstract url": "https://arxiv.org/abs/2404.04686",
        "title": "Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI",
        "rating": -1.5,
        "keywords": [
            [
                "Medical",
                "Diagnosing",
                "Cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Breast cancer has rapidly increased in prevalence in recent years, making it one of the leading causes of mortality worldwide. Among all cancers, it is by far the most common. Diagnosing this illness manually requires significant time and expertise. Since detecting breast cancer is a time-consuming process, preventing its further spread can be aided by creating machine-based forecasts. Machine learning and Explainable AI are crucial in classification as they not only provide accurate predictions but also offer insights into how the model arrives at its decisions, aiding in the understanding and trustworthiness of the classification results. In this study, we evaluate and compare the classification accuracy, precision, recall, and F-1 scores of five different machine learning methods using a primary dataset (500 patients from Dhaka Medical College Hospital). Five different supervised machine learning techniques, including decision tree, random forest, logistic regression, naive bayes, and XGBoost, have been used to achieve optimal results on our dataset. Additionally, this study applied SHAP analysis to the XGBoost model to interpret the model's predictions and understand the impact of each feature on the model's output. We compared the accuracy with which several algorithms classified the data, as well as contrasted with other literature in this field. After final evaluation, this study found that XGBoost achieved the best model accuracy, which is 97%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted for the Scientific Reports (Nature) journal. 32 pages, 12 figures"
    },
    {
        "paper id": "2404.04690",
        "abstract url": "https://arxiv.org/abs/2404.04690",
        "title": "The Identification and Categorization of Anemia Through Artificial Neural Networks: A Comparative Analysis of Three Models",
        "rating": -1.5,
        "keywords": [
            [
                "diagnosing",
                "disease",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents different neural network-based classifier algorithms for diagnosing and classifying Anemia. The study compares these classifiers with established models such as Feed Forward Neural Network (FFNN), Elman network, and Non-linear Auto-Regressive Exogenous model (NARX). Experimental evaluations were conducted using data from clinical laboratory test results for 230 patients. The proposed neural network features nine inputs (age, gender, RBC, HGB, HCT, MCV, MCH, MCHC, WBCs) and one output. The simulation outcomes for diverse patients demonstrate that the suggested artificial neural network rapidly and accurately detects the presence of the disease. Consequently, the network could be seamlessly integrated into clinical laboratories for automatic generation of Anemia patients' reports Additionally, the suggested method is affordable and can be deployed on hardware at low costs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04750",
        "abstract url": "https://arxiv.org/abs/2404.04750",
        "title": "Now, Later, and Lasting: Ten Priorities for AI Research, Policy, and Practice",
        "rating": -1.5,
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Advances in artificial intelligence (AI) will transform many aspects of our lives and society, bringing immense opportunities but also posing significant risks and challenges. The next several decades may well be a turning point for humanity, comparable to the industrial revolution. We write to share a set of recommendations for moving forward from the perspective of the founder and leaders of the One Hundred Year Study on AI. Launched a decade ago, the project is committed to a perpetual series of studies by multidisciplinary experts to evaluate the immediate, longer-term, and far-reaching effects of AI on people and society, and to make recommendations about AI research, policy, and practice. As we witness new capabilities emerging from neural models, it is crucial that we engage in efforts to advance our scientific understanding of these models and their behaviors. We must address the impact of AI on people and society through technical, social, and sociotechnical lenses, incorporating insights from a diverse range of experts including voices from engineering, social, behavioral, and economic disciplines. By fostering dialogue, collaboration, and action among various stakeholders, we can strategically guide the development and deployment of AI in ways that maximize its potential for contributing to human flourishing. Despite the growing divide in the field between focusing on short-term versus long-term implications, we think both are of critical importance. As Alan Turing, one of the pioneers of AI, wrote in 1950, \"We can only see a short distance ahead, but we can see plenty there that needs to be done.\" We offer ten recommendations for action that collectively address both the short- and long-term potential impacts of AI technologies.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Four pages. To appear in Communications of the Association for Computing Machinery (CACM), June 2024"
    },
    {
        "paper id": "2404.04785",
        "abstract url": "https://arxiv.org/abs/2404.04785",
        "title": "Rethinking Diffusion Model for Multi-Contrast MRI Super-Resolution",
        "rating": -1.5,
        "keywords": [
            [
                "Diffusion",
                "Super-Resolution"
            ],
            [
                "MRI",
                "clinical"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Recently, diffusion models (DM) have been applied in magnetic resonance imaging (MRI) super-resolution (SR) reconstruction, exhibiting impressive performance, especially with regard to detailed reconstruction. However, the current DM-based SR reconstruction methods still face the following issues: (1) They require a large number of iterations to reconstruct the final image, which is inefficient and consumes a significant amount of computational resources. (2) The results reconstructed by these methods are often misaligned with the real high-resolution images, leading to remarkable distortion in the reconstructed MR images. To address the aforementioned issues, we propose an efficient diffusion model for multi-contrast MRI SR, named as DiffMSR. Specifically, we apply DM in a highly compact low-dimensional latent space to generate prior knowledge with high-frequency detail information. The highly compact latent space ensures that DM requires only a few simple iterations to produce accurate prior knowledge. In addition, we design the Prior-Guide Large Window Transformer (PLWformer) as the decoder for DM, which can extend the receptive field while fully utilizing the prior knowledge generated by DM to ensure that the reconstructed MR image remains undistorted. Extensive experiments on public and clinical datasets demonstrate that our DiffMSR outperforms state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 12 figures, Accepted by CVPR2024"
    },
    {
        "paper id": "2404.04518",
        "abstract url": "https://arxiv.org/abs/2404.04518",
        "title": "MedIAnomaly: A comparative study of anomaly detection in medical images",
        "rating": -2,
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "medical",
                "health",
                "whole slide",
                "retinal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Anomaly detection (AD) aims at detecting abnormal samples that deviate from the expected normal patterns. Generally, it can be trained on merely normal data without the requirement for abnormal samples, and thereby plays an important role in the recognition of rare diseases and health screening in the medical domain. Despite numerous related studies, we observe a lack of a fair and comprehensive evaluation, which causes some ambiguous conclusions and hinders the development of this field. This paper focuses on building a benchmark with unified implementation and comparison to address this problem. In particular, seven medical datasets with five image modalities, including chest X-rays, brain MRIs, retinal fundus images, dermatoscopic images, and histopathology whole slide images are organized for extensive evaluation. Twenty-seven typical AD methods, including reconstruction and self-supervised learning-based methods, are involved in comparison of image-level anomaly classification and pixel-level anomaly segmentation. Furthermore, we for the first time formally explore the effect of key components in existing methods, clearly revealing unresolved challenges and potential future directions. The datasets and code are available at \\url{https://github.com/caiyu6666/MedIAnomaly}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under submission"
    },
    {
        "paper id": "2404.04535",
        "abstract url": "https://arxiv.org/abs/2404.04535",
        "title": "Quantum Speedup for Some Geometric 3SUM-Hard Problems and Beyond",
        "rating": -2,
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The classical 3SUM conjecture states that the class of 3SUM-hard problems does not admit a truly subquadratic $O(n^{2-\u03b4})$-time algorithm, where $\u03b4>0$, in classical computing. The geometric 3SUM-hard problems have widely been studied in computational geometry and recently, these problems have been examined under the quantum computing model. For example, Ambainis and Larka [TQC'20] designed a quantum algorithm that can solve many geometric 3SUM-hard problems in $O(n^{1+o(1)})$-time, whereas Buhrman [ITCS'22] investigated lower bounds under quantum 3SUM conjecture that claims there does not exist any sublinear $O(n^{1-\u03b4})$-time quantum algorithm for the 3SUM problem. The main idea of Ambainis and Larka is to formulate a 3SUM-hard problem as a search problem, where one needs to find a point with a certain property over a set of regions determined by a line arrangement in the plane. The quantum speed-up then comes from the application of the well-known quantum search technique called Grover search over all regions. This paper further generalizes the technique of Ambainis and Larka for some 3SUM-hard problems when a solution may not necessarily correspond to a single point or the search regions do not immediately correspond to the subdivision determined by a line arrangement. Given a set of $n$ points and a positive number $q$, we design $O(n^{1+o(1)})$-time quantum algorithms to determine whether there exists a triangle among these points with an area at most $q$ or a unit disk that contains at least $q$ points. We also give an $O(n^{1+o(1)})$-time quantum algorithm to determine whether a given set of intervals can be translated so that it becomes contained in another set of given intervals and discuss further generalizations.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04546",
        "abstract url": "https://arxiv.org/abs/2404.04546",
        "title": "A self-attention model for robust rigid slice-to-volume registration of functional MRI",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "MRI"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Functional Magnetic Resonance Imaging (fMRI) is vital in neuroscience, enabling investigations into brain disorders, treatment monitoring, and brain function mapping. However, head motion during fMRI scans, occurring between shots of slice acquisition, can result in distortion, biased analyses, and increased costs due to the need for scan repetitions. Therefore, retrospective slice-level motion correction through slice-to-volume registration (SVR) is crucial. Previous studies have utilized deep learning (DL) based models to address the SVR task; however, they overlooked the uncertainty stemming from the input stack of slices and did not assign weighting or scoring to each slice. In this work, we introduce an end-to-end SVR model for aligning 2D fMRI slices with a 3D reference volume, incorporating a self-attention mechanism to enhance robustness against input data variations and uncertainties. It utilizes independent slice and volume encoders and a self-attention module to assign pixel-wise scores for each slice. We conducted evaluation experiments on 200 images involving synthetic rigid motion generated from 27 subjects belonging to the test set, from the publicly available Healthy Brain Network (HBN) dataset. Our experimental results demonstrate that our model achieves competitive performance in terms of alignment accuracy compared to state-of-the-art deep learning-based methods (Euclidean distance of $0.93$ [mm] vs. $1.86$ [mm]). Furthermore, our approach exhibits significantly faster registration speed compared to conventional iterative methods ($0.096$ sec. vs. $1.17$ sec.). Our end-to-end SVR model facilitates real-time head motion tracking during fMRI acquisition, ensuring reliability and robustness against uncertainties in inputs. source code, which includes the training and evaluations, will be available soon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Currently under review"
    },
    {
        "paper id": "2404.04547",
        "abstract url": "https://arxiv.org/abs/2404.04547",
        "title": "Exhaustive Exploitation of Nature-inspired Computation for Cancer Screening in an Ensemble Manner",
        "rating": -2,
        "keywords": [
            [
                "biomarker",
                "Cancer"
            ]
        ],
        "abstract": "Accurate screening of cancer types is crucial for effective cancer detection and precise treatment selection. However, the association between gene expression profiles and tumors is often limited to a small number of biomarker genes. While computational methods using nature-inspired algorithms have shown promise in selecting predictive genes, existing techniques are limited by inefficient search and poor generalization across diverse datasets. This study presents a framework termed Evolutionary Optimized Diverse Ensemble Learning (EODE) to improve ensemble learning for cancer classification from gene expression data. The EODE methodology combines an intelligent grey wolf optimization algorithm for selective feature space reduction, guided random injection modeling for ensemble diversity enhancement, and subset model optimization for synergistic classifier combinations. Extensive experiments were conducted across 35 gene expression benchmark datasets encompassing varied cancer types. Results demonstrated that EODE obtained significantly improved screening accuracy over individual and conventionally aggregated models. The integrated optimization of advanced feature selection, directed specialized modeling, and cooperative classifier ensembles helps address key challenges in current nature-inspired approaches. This provides an effective framework for robust and generalized ensemble learning with gene expression biomarkers. Specifically, we have opened EODE source code on Github at https://github.com/wangxb96/EODE.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04554",
        "abstract url": "https://arxiv.org/abs/2404.04554",
        "title": "A quantum algorithm for the Kalman filter using block encoding",
        "rating": -2,
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Quantum algorithms offer significant speed-ups over their classical counterparts in various applications. In this paper, we develop quantum algorithms for the Kalman filter widely used in classical control engineering using the block encoding method. The entire calculation process is achieved by performing matrix operations on Hamiltonians based on the block encoding framework, including addition, multiplication, and inversion, which can be completed in a unified framework compared to previous quantum algorithms for solving control problems. We demonstrate that the quantum algorithm exponentially accelerates the computation of the Kalman filter compared to traditional methods. The time complexity can be reduced from $O(n^3)$ to $O(\u03bapoly\\log(n/\u03b5)\\log(1/\u03b5'))$, where $n$ represents the matrix dimension, $\u03ba$ denotes the condition number for the matrix to be inverted, $\u03b5$ indicates desired precision in block encoding, $\u03b5'$ signifies desired precision in matrix inversion. This paper provides a comprehensive quantum solution for implementing the Kalman filter and serves as an attempt to broaden the scope of quantum computation applications. Finally, we present an illustrative example implemented in Qiskit (a Python-based open-source toolkit) as a proof-of-concept.",
        "subjects": [
            "math.QA"
        ],
        "comment": "23 pages, 20 figures, 3 tables"
    },
    {
        "paper id": "2404.04567",
        "abstract url": "https://arxiv.org/abs/2404.04567",
        "title": "Optimization of Lightweight Malware Detection Models For AIoT Devices",
        "rating": -2,
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Malware intrusion is problematic for Internet of Things (IoT) and Artificial Intelligence of Things (AIoT) devices as they often reside in an ecosystem of connected devices, such as a smart home. If any devices are infected, the whole ecosystem can be compromised. Although various Machine Learning (ML) models are deployed to detect malware and network intrusion, generally speaking, robust high-accuracy models tend to require resources not found in all IoT devices, compared to less robust models defined by weak learners. In order to combat this issue, Fadhilla proposed a meta-learner ensemble model comprised of less robust prediction results inherent with weak learner ML models to produce a highly robust meta-learning ensemble model. The main problem with the prior research is that it cannot be deployed in low-end AIoT devices due to the limited resources comprising processing power, storage, and memory (the required libraries quickly exhaust low-end AIoT devices' resources.) Hence, this research aims to optimize the proposed super learner meta-learning ensemble model to make it viable for low-end AIoT devices. We show the library and ML model memory requirements associated with each optimization stage and emphasize that optimization of current ML models is necessitated for low-end AIoT devices. Our results demonstrate that we can obtain similar accuracy and False Positive Rate (FPR) metrics from high-end AIoT devices running the derived ML model, with a lower inference duration and smaller memory footprint.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted by WF-IOT 2023, 7 pages, 4 figures"
    },
    {
        "paper id": "2404.04578",
        "abstract url": "https://arxiv.org/abs/2404.04578",
        "title": "GLCM-Based Feature Combination for Extraction Model Optimization in Object Detection Using Machine Learning",
        "rating": -2,
        "keywords": [
            [
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the era of modern technology, object detection using the Gray Level Co-occurrence Matrix (GLCM) extraction method plays a crucial role in object recognition processes. It finds applications in real-time scenarios such as security surveillance and autonomous vehicle navigation, among others. Computational efficiency becomes a critical factor in achieving real-time object detection. Hence, there is a need for a detection model with low complexity and satisfactory accuracy. This research aims to enhance computational efficiency by selecting appropriate features within the GLCM framework. Two classification models, namely K-Nearest Neighbours (K-NN) and Support Vector Machine (SVM), were employed, with the results indicating that K-Nearest Neighbours (K-NN) outperforms SVM in terms of computational complexity. Specifically, K-NN, when utilizing a combination of Correlation, Energy, and Homogeneity features, achieves a 100% accuracy rate with low complexity. Moreover, when using a combination of Energy and Homogeneity features, K-NN attains an almost perfect accuracy level of 99.9889%, while maintaining low complexity. On the other hand, despite SVM achieving 100% accuracy in certain feature combinations, its high or very high complexity can pose challenges, particularly in real-time applications. Therefore, based on the trade-off between accuracy and complexity, the K-NN model with a combination of Correlation, Energy, and Homogeneity features emerges as a more suitable choice for real-time applications that demand high accuracy and low complexity. This research provides valuable insights for optimizing object detection in various applications requiring both high accuracy and rapid responsiveness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04589",
        "abstract url": "https://arxiv.org/abs/2404.04589",
        "title": "ars548_ros. An ARS 548 RDI radar driver for ROS2",
        "rating": -2,
        "keywords": [
            [
                "LiDAR",
                "radar"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "The ARS 548 RDI Radar is a premium model of the fifth generation of 77 GHz long range radar sensors with new RF antenna arrays, which offer digital beam forming. This radar measures independently the distance, speed and angle of objects without any reflectors in one measurement cycle based on Pulse Compression with New Frequency Modulation [1]. Unfortunately, there were not any drivers available for Linux systems to make the user able to analyze the data acquired from this sensor to the best of our knowledge. In this paper, we present a driver that is able to interpret the data from the ARS 548 RDI sensor and produce data in Robot Operation System version 2 (ROS2). Thus, this data can be stored, represented and analyzed by using the powerful tools offered by ROS2. Besides, our driver offers advanced object features provided by the sensor, such as relative estimated velocity and acceleration of each object, its orientation and angular velocity. We focus on the configuration of the sensor and the use of our driver and advanced filtering and representation tools, offering a video tutorial for these purposes. Finally, a dataset acquired with this sensor and an Ouster OS1-32 LiDAR sensor for baseline purposes is available, so that the user can check the correctness of our driver.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 6 figures and 17 references"
    },
    {
        "paper id": "2404.04593",
        "abstract url": "https://arxiv.org/abs/2404.04593",
        "title": "Evaluation and Optimization of Positional Accuracy for Maritime Positioning Systems",
        "rating": -2,
        "keywords": [
            [
                "radar"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Navigation and trajectorial estimation of maritime vessels are contingent upon the context of positional accuracy. Even the smallest deviations in the estimation of a given vessel may result in detrimental consequences in terms of economic and ecologic quotients. To ensure an agile and precise environment for maritime vessel positional estimation, preexisting marine radar technologies can be utilized in a way that ensures a higher level of precision compared to GNSS-based identification and positioning. In this paper, we present a positional optimization for radarbased vessel navigation systems that utilize the installment of vessel detection sensors. The main objective of this research is to employ as fewer sensors as possible while preserving the attainable error threshold for positioning that is defined by International Maritime Organization (IMO). Our approach leads most of the time to a positioning error of up to 5 m along shorelines and rivers and up to 50 m along open coastal regions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "9 pages, 7 figures, 3 tables, WoWMoM 2024"
    },
    {
        "paper id": "2404.04599",
        "abstract url": "https://arxiv.org/abs/2404.04599",
        "title": "Local Test for Unitarily Invariant Properties of Bipartite Quantum States",
        "rating": -2,
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We study the power of local test for bipartite quantum states. Our central result is that, for properties of bipartite pure states, unitary invariance on one part implies an optimal (over all global testers) local tester acting only on the other part. This suggests a canonical local tester for entanglement spectra (i.e., Schmidt coefficients), and reveals that purified samples offer no advantage in property testing of mixed states. As applications, we show new sample lower bounds, e.g.: - The first general lower bound $\u03a9(r/\u03b5^2)$ for testing whether the Schmidt rank of a bipartite state is at most $r$ or $\u03b5$-far, settling an open question raised in Montanaro and de Wolf (ToC 2016). - A lower bound $\u03a9((\\sqrt n+\\sqrt r)\\cdot\\sqrt r/\u03b5^2)$ for testing whether an $n$-partite state is a matrix product state of bond dimension $r$ or $\u03b5$-far, improving the prior lower bound $\u03a9(\\sqrt n/\u03b5^2)$ by Soleimanifar and Wright (SODA 2022) and $\u03a9(\\sqrt r)$ by Aaronson et al. (ITCS 2024). Further, when perfect completeness is required, we provide a matching lower bound $\u03a9(r^2/\u03b5^2)$ with respect to $r$ and $\u03b5$. - A matching lower bound $\u03a9(d/\u03b5^2)$ for testing whether a $d$-dimensional bipartite state is maximally entangled or $\u03b5$-far, showing that the algorithm of O'Donnell and Wright (STOC 2015) is optimal for this task. Beyond sample complexity, we also contribute new query lower bounds: - A query lower bound $\\tilde\u03a9(\\sqrt{d/\u0394})$ for the $d$-dimensional entanglement entropy problem with gap $\u0394$, improving the prior best $\u03a9(\\sqrt[4]{d})$ by She and Yuen (ITCS 2023) and $\\tilde\u03a9(1/\\sqrt\u0394)$ by Wang and Zhang (2023) and Weggemans (2024). Further, our central result can be extended when the tested state is mixed: one-way LOCC is sufficient to realize the optimal tester.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "51 pages. Compared to [v1], we (i) extended testers with parameterized completeness and soundness, (ii) added new lower bounds for testing the bond dimension of matrix product states (MPS), and (iii) improved the lower bounds for testing Schmidt rank"
    },
    {
        "paper id": "2404.04638",
        "abstract url": "https://arxiv.org/abs/2404.04638",
        "title": "Designing for Complementarity: A Conceptual Framework to Go Beyond the Current Paradigm of Using XAI in Healthcare",
        "rating": -2,
        "keywords": [
            [
                "Healthcare"
            ]
        ],
        "abstract": "The widespread use of Artificial Intelligence-based tools in the healthcare sector raises many ethical and legal problems, one of the main reasons being their black-box nature and therefore the seemingly opacity and inscrutability of their characteristics and decision-making process. Literature extensively discusses how this can lead to phenomena of over-reliance and under-reliance, ultimately limiting the adoption of AI. We addressed these issues by building a theoretical framework based on three concepts: Feature Importance, Counterexample Explanations, and Similar-Case Explanations. Grounded in the literature, the model was deployed within a case study in which, using a participatory design approach, we designed and developed a high-fidelity prototype. Through the co-design and development of the prototype and the underlying model, we advanced the knowledge on how to design AI-based systems for enabling complementarity in the decision-making process in the healthcare domain. Our work aims at contributing to the current discourse on designing AI systems to support clinicians' decision-making processes.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04642",
        "abstract url": "https://arxiv.org/abs/2404.04642",
        "title": "Power-Efficient Image Storage: Leveraging Super Resolution Generative Adversarial Network for Sustainable Compression and Reduced Carbon Footprint",
        "rating": -2,
        "keywords": [
            [
                "Super Resolution"
            ],
            [
                "industrial"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, large-scale adoption of cloud storage solutions has revolutionized the way we think about digital data storage. However, the exponential increase in data volume, especially images, has raised environmental concerns regarding power and resource consumption, as well as the rising digital carbon footprint emissions. The aim of this research is to propose a methodology for cloud-based image storage by integrating image compression technology with SuperResolution Generative Adversarial Networks (SRGAN). Rather than storing images in their original format directly on the cloud, our approach involves initially reducing the image size through compression and downsizing techniques before storage. Upon request, these compressed images will be retrieved and processed by SRGAN to generate images. The efficacy of the proposed method is evaluated in terms of PSNR and SSIM metrics. Additionally, a mathematical analysis is given to calculate power consumption and carbon footprint assesment. The proposed data compression technique provides a significant solution to achieve a reasonable trade off between environmental sustainability and industrial efficiency.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "5 pages, 5 figures"
    },
    {
        "paper id": "2404.04643",
        "abstract url": "https://arxiv.org/abs/2404.04643",
        "title": "Constrained 6-DoF Grasp Generation on Complex Shapes for Improved Dual-Arm Manipulation",
        "rating": -2,
        "keywords": [
            [
                "6-DoF"
            ],
            [
                "Diffusion"
            ]
        ],
        "abstract": "Efficiently generating grasp poses tailored to specific regions of an object is vital for various robotic manipulation tasks, especially in a dual-arm setup. This scenario presents a significant challenge due to the complex geometries involved, requiring a deep understanding of the local geometry to generate grasps efficiently on the specified constrained regions. Existing methods only explore settings involving table-top/small objects and require augmented datasets to train, limiting their performance on complex objects. We propose CGDF: Constrained Grasp Diffusion Fields, a diffusion-based grasp generative model that generalizes to objects with arbitrary geometries, as well as generates dense grasps on the target regions. CGDF uses a part-guided diffusion approach that enables it to get high sample efficiency in constrained grasping without explicitly training on massive constraint-augmented datasets. We provide qualitative and quantitative comparisons using analytical metrics and in simulation, in both unconstrained and constrained settings to show that our method can generalize to generate stable grasps on complex objects, especially useful for dual-arm manipulation settings, while existing methods struggle to do so.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Project Page: https://constrained-grasp-diffusion.github.io/"
    },
    {
        "paper id": "2404.04648",
        "abstract url": "https://arxiv.org/abs/2404.04648",
        "title": "CANEDERLI: On The Impact of Adversarial Training and Transferability on CAN Intrusion Detection Systems",
        "rating": -2,
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "The growing integration of vehicles with external networks has led to a surge in attacks targeting their Controller Area Network (CAN) internal bus. As a countermeasure, various Intrusion Detection Systems (IDSs) have been suggested in the literature to prevent and mitigate these threats. With the increasing volume of data facilitated by the integration of Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication networks, most of these systems rely on data-driven approaches such as Machine Learning (ML) and Deep Learning (DL) models. However, these systems are susceptible to adversarial evasion attacks. While many researchers have explored this vulnerability, their studies often involve unrealistic assumptions, lack consideration for a realistic threat model, and fail to provide effective solutions. In this paper, we present CANEDERLI (CAN Evasion Detection ResiLIence), a novel framework for securing CAN-based IDSs. Our system considers a realistic threat model and addresses the impact of adversarial attacks on DL-based detection systems. Our findings highlight strong transferability properties among diverse attack methodologies by considering multiple state-of-the-art attacks and model architectures. We analyze the impact of adversarial training in addressing this threat and propose an adaptive online adversarial training technique outclassing traditional fine-tuning methodologies with F1 scores up to 0.941. By making our framework publicly available, we aid practitioners and researchers in assessing the resilience of IDSs to a varied adversarial landscape.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted at WiseML 2024"
    },
    {
        "paper id": "2404.04653",
        "abstract url": "https://arxiv.org/abs/2404.04653",
        "title": "HawkDrive: A Transformer-driven Visual Perception System for Autonomous Driving in Night Scene",
        "rating": -2,
        "keywords": [
            [
                "depth"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "Robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Many established vision perception systems for autonomous driving scenarios ignore the influence of light conditions, one of the key elements for driving safety. To address this problem, we present HawkDrive, a novel perception system with hardware and software solutions. Hardware that utilizes stereo vision perception, which has been demonstrated to be a more reliable way of estimating depth information than monocular vision, is partnered with the edge computing device Nvidia Jetson Xavier AGX. Our software for low light enhancement, depth estimation, and semantic segmentation tasks, is a transformer-based neural network. Our software stack, which enables fast inference and noise reduction, is packaged into system modules in Robot Operating System 2 (ROS2). Our experimental results have shown that the proposed end-to-end system is effective in improving the depth estimation and semantic segmentation performance. Our dataset and codes will be released at https://github.com/ZionGo6/HawkDrive.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IEEE IV 2024"
    },
    {
        "paper id": "2404.04687",
        "abstract url": "https://arxiv.org/abs/2404.04687",
        "title": "Z-Splat: Z-Axis Gaussian Splatting for Camera-Sonar Fusion",
        "rating": -2,
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth"
            ],
            [
                "synthesis"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Differentiable 3D-Gaussian splatting (GS) is emerging as a prominent technique in computer vision and graphics for reconstructing 3D scenes. GS represents a scene as a set of 3D Gaussians with varying opacities and employs a computationally efficient splatting operation along with analytical derivatives to compute the 3D Gaussian parameters given scene images captured from various viewpoints. Unfortunately, capturing surround view ($360^{\\circ}$ viewpoint) images is impossible or impractical in many real-world imaging scenarios, including underwater imaging, rooms inside a building, and autonomous navigation. In these restricted baseline imaging scenarios, the GS algorithm suffers from a well-known 'missing cone' problem, which results in poor reconstruction along the depth axis. In this manuscript, we demonstrate that using transient data (from sonars) allows us to address the missing cone problem by sampling high-frequency data along the depth axis. We extend the Gaussian splatting algorithms for two commonly used sonars and propose fusion algorithms that simultaneously utilize RGB camera data and sonar data. Through simulations, emulations, and hardware experiments across various imaging scenarios, we show that the proposed fusion algorithms lead to significantly better novel view synthesis (5 dB improvement in PSNR) and 3D geometry reconstruction (60% lower Chamfer distance).",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04693",
        "abstract url": "https://arxiv.org/abs/2404.04693",
        "title": "OmniColor: A Global Camera Pose Optimization Approach of LiDAR-360Camera Fusion for Colorizing Point Clouds",
        "rating": -2,
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A Colored point cloud, as a simple and efficient 3D representation, has many advantages in various fields, including robotic navigation and scene reconstruction. This representation is now commonly used in 3D reconstruction tasks relying on cameras and LiDARs. However, fusing data from these two types of sensors is poorly performed in many existing frameworks, leading to unsatisfactory mapping results, mainly due to inaccurate camera poses. This paper presents OmniColor, a novel and efficient algorithm to colorize point clouds using an independent 360-degree camera. Given a LiDAR-based point cloud and a sequence of panorama images with initial coarse camera poses, our objective is to jointly optimize the poses of all frames for mapping images onto geometric reconstructions. Our pipeline works in an off-the-shelf manner that does not require any feature extraction or matching process. Instead, we find optimal poses by directly maximizing the photometric consistency of LiDAR maps. In experiments, we show that our method can overcome the severe visual distortion of omnidirectional images and greatly benefit from the wide field of view (FOV) of 360-degree cameras to reconstruct various scenarios with accuracy and stability. The code will be released at https://github.com/liubonan123/OmniColor/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "2024 IEEE International Conference on Robotics and Automation"
    },
    {
        "paper id": "2404.04718",
        "abstract url": "https://arxiv.org/abs/2404.04718",
        "title": "Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment",
        "rating": -2,
        "keywords": [
            [
                "graph"
            ],
            [
                "Health",
                "clinical",
                "cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Pulmonary Arterial Wedge Pressure (PAWP) is an essential cardiovascular hemodynamics marker to detect heart failure. In clinical practice, Right Heart Catheterization is considered a gold standard for assessing cardiac hemodynamics while non-invasive methods are often needed to screen high-risk patients from a large population. In this paper, we propose a multimodal learning pipeline to predict PAWP marker. We utilize complementary information from Cardiac Magnetic Resonance Imaging (CMR) scans (short-axis and four-chamber) and Electronic Health Records (EHRs). We extract spatio-temporal features from CMR scans using tensor-based learning. We propose a graph attention network to select important EHR features for prediction, where we model subjects as graph nodes and feature relationships as graph edges using the attention mechanism. We design four feature fusion strategies: early, intermediate, late, and hybrid fusion. With a linear classifier and linear fusion strategies, our pipeline is interpretable. We validate our pipeline on a large dataset of $2,641$ subjects from our ASPIRE registry. The comparative study against state-of-the-art methods confirms the superiority of our pipeline. The decision curve analysis further validates that our pipeline can be applied to screen a large population. The code is available at https://github.com/prasunc/hemodynamics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04753",
        "abstract url": "https://arxiv.org/abs/2404.04753",
        "title": "RIS in Cellular Networks -- Challenges and Issues",
        "rating": -2,
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Reconfigurable intelligent surface (RIS) has been suggested to be a key 6G feature and was suggested to be considered as a study-item in both 3GPP Releases 18 and 19. However, in both releases, it has been decided not to continue with it as a study-item, and to leave it for possible future specification. In this paper, we present the rationale for such a decision. Particularly, we demonstrate the practical issues which may affect the feasibility or usefulness of RIS in cellular networks, and present open problems to be addressed before RIS can be used in practice. Moreover, we compare the performance of RIS with network-controlled repeater, the node with the most similar characteristics to RIS and which has been standardized in 3GPP Release 18. Finally, different simulations are presented to evaluate the performance of RIS-assisted networks.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted to IEEE Open Journal of Communications Society"
    },
    {
        "paper id": "2404.05762",
        "abstract url": "https://arxiv.org/abs/2404.05762",
        "title": "Evaluating the Effectiveness of Artificial Intelligence in Predicting Adverse Drug Reactions among Cancer Patients: A Systematic Review and Meta-Analysis",
        "rating": -2,
        "keywords": [
            [
                "Biomarkers",
                "healthcare",
                "Cancer",
                "clinical"
            ]
        ],
        "abstract": "Adverse drug reactions considerably impact patient outcomes and healthcare costs in cancer therapy. Using artificial intelligence to predict adverse drug reactions in real time could revolutionize oncology treatment. This study aims to assess the performance of artificial intelligence models in predicting adverse drug reactions in patients with cancer. This is the first systematic review and meta-analysis. Scopus, PubMed, IEEE Xplore, and ACM Digital Library databases were searched for studies in English, French, and Arabic from January 1, 2018, to August 20, 2023. The inclusion criteria were: (1) peer-reviewed research articles; (2) use of artificial intelligence algorithms (machine learning, deep learning, knowledge graphs); (3) study aimed to predict adverse drug reactions (cardiotoxicity, neutropenia, nephrotoxicity, hepatotoxicity); (4) study was on cancer patients. The data were extracted and evaluated by three reviewers for study quality. Of the 332 screened articles, 17 studies (5%) involving 93,248 oncology patients from 17 countries were included in the systematic review, of which ten studies synthesized the meta-analysis. A random-effects model was created to pool the sensitivity, specificity, and AUC of the included studies. The pooled results were 0.82 (95% CI:0.69, 0.9), 0.84 (95% CI:0.75, 0.9), and 0.83 (95% CI:0.77, 0.87) for sensitivity, specificity, and AUC, respectively, of ADR predictive models. Biomarkers proved their effectiveness in predicting ADRs, yet they were adopted by only half of the reviewed studies. The use of AI in cancer treatment shows great potential, with models demonstrating high specificity and sensitivity in predicting ADRs. However, standardized research and multicenter studies are needed to improve the quality of evidence. AI can enhance cancer patient care by bridging the gap between data-driven insights and clinical expertise.",
        "subjects": [
            "q-bio.QM"
        ],
        "comment": "Paper has been accepted at the IEEE Challenges and Innovations on TIC (IEEE I2CIT) International Conference"
    },
    {
        "paper id": "2404.05763",
        "abstract url": "https://arxiv.org/abs/2404.05763",
        "title": "Deep Learning-Based Brain Image Segmentation for Automated Tumour Detection",
        "rating": -2,
        "keywords": [
            [
                "3D"
            ],
            [
                "MRI",
                "clinical",
                "tumor"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Introduction: The present study on the development and evaluation of an automated brain tumor segmentation technique based on deep learning using the 3D U-Net model. Objectives: The objective is to leverage state-of-the-art convolutional neural networks (CNNs) on a large dataset of brain MRI scans for segmentation. Methods: The proposed methodology applies pre-processing techniques for enhanced performance and generalizability. Results: Extensive validation on an independent dataset confirms the model's robustness and potential for integration into clinical workflows. The study emphasizes the importance of data pre-processing and explores various hyperparameters to optimize the model's performance. The 3D U-Net, has given IoUs for training and validation dataset have been 0.8181 and 0.66 respectively. Conclusion: Ultimately, this comprehensive framework showcases the efficacy of deep learning in automating brain tumour detection, offering valuable support in clinical practice.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.08675",
        "abstract url": "https://arxiv.org/abs/2404.08675",
        "title": "RecGPT: Generative Personalized Prompts for Sequential Recommendation via ChatGPT Training Paradigm",
        "rating": -2,
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "ChatGPT has achieved remarkable success in natural language understanding. Considering that recommendation is indeed a conversation between users and the system with items as words, which has similar underlying pattern with ChatGPT, we design a new chat framework in item index level for the recommendation task. Our novelty mainly contains three parts: model, training and inference. For the model part, we adopt Generative Pre-training Transformer (GPT) as the sequential recommendation model and design a user modular to capture personalized information. For the training part, we adopt the two-stage paradigm of ChatGPT, including pre-training and fine-tuning. In the pre-training stage, we train GPT model by auto-regression. In the fine-tuning stage, we train the model with prompts, which include both the newly-generated results from the model and the user's feedback. For the inference part, we predict several user interests as user representations in an autoregressive manner. For each interest vector, we recall several items with the highest similarity and merge the items recalled by all interest vectors into the final result. We conduct experiments with both offline public datasets and online A/B test to demonstrate the effectiveness of our proposed method.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.15326",
        "abstract url": "https://arxiv.org/abs/2404.15326",
        "title": "5G-Advanced AI/ML Beam Management: Performance Evaluation with Integrated ML Models",
        "rating": -2,
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "The legacy beam management (BM) procedure in 5G introduces higher measurement and reporting overheads for larger beam codebooks resulting in higher power consumption of user equipment (UEs). Hence, the 3rd generation partnership project (3GPP) studied the use of artificial intelligence (AI) and machine learning (ML) in the air interface to reduce the overhead associated with the legacy BM procedure. The usage of AI/ML in BM is mainly discussed with regard to spatial-domain beam prediction (SBP) and time-domain beam prediction (TBP). In this study, we discuss different sub-use cases of SBP and TBP and evaluate the beam prediction accuracy of AI/ML models designed for each sub-use case along with AI/ML model generalization aspects. Moreover, a comprehensive system-level performance evaluation is presented in terms of user throughput with integrated AI/ML models to a 3GPP-compliant system-level simulator. Based on user throughput evaluations, we present AI/ML BM design guidelines for the deployment of lightweight, low-complexity AI/ML models discussed in this study.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2404.04667",
        "abstract url": "https://arxiv.org/abs/2404.04667",
        "title": "Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology",
        "rating": -2.5,
        "keywords": [
            [
                "synthesize"
            ],
            [
                "medical",
                "Clinical",
                "radiology"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multimodal artificial intelligence (AI) systems have the potential to enhance clinical decision-making by interpreting various types of medical data. However, the effectiveness of these models across all medical fields is uncertain. Each discipline presents unique challenges that need to be addressed for optimal performance. This complexity is further increased when attempting to integrate different fields into a single model. Here, we introduce an alternative approach to multimodal medical AI that utilizes the generalist capabilities of a large language model (LLM) as a central reasoning engine. This engine autonomously coordinates and deploys a set of specialized medical AI tools. These tools include text, radiology and histopathology image interpretation, genomic data processing, web searches, and document retrieval from medical guidelines. We validate our system across a series of clinical oncology scenarios that closely resemble typical patient care workflows. We show that the system has a high capability in employing appropriate tools (97%), drawing correct conclusions (93.6%), and providing complete (94%), and helpful (89.2%) recommendations for individual patient cases while consistently referencing relevant literature (82.5%) upon instruction. This work provides evidence that LLMs can effectively plan and execute domain-specific models to retrieve or synthesize new information when used as autonomous agents. This enables them to function as specialist, patient-tailored clinical assistants. It also simplifies regulatory compliance by allowing each component tool to be individually validated and approved. We believe, that our work can serve as a proof-of-concept for more advanced LLM-agents in the medical domain.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "91 pages, 2 Figures"
    },
    {
        "paper id": "2404.04714",
        "abstract url": "https://arxiv.org/abs/2404.04714",
        "title": "Data Poisoning Attacks on Off-Policy Policy Evaluation Methods",
        "rating": -2.5,
        "keywords": [
            [
                "Attacks"
            ],
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Off-policy Evaluation (OPE) methods are a crucial tool for evaluating policies in high-stakes domains such as healthcare, where exploration is often infeasible, unethical, or expensive. However, the extent to which such methods can be trusted under adversarial threats to data quality is largely unexplored. In this work, we make the first attempt at investigating the sensitivity of OPE methods to marginal adversarial perturbations to the data. We design a generic data poisoning attack framework leveraging influence functions from robust statistics to carefully construct perturbations that maximize error in the policy value estimates. We carry out extensive experimentation with multiple healthcare and control datasets. Our results demonstrate that many existing OPE methods are highly prone to generating value estimates with large errors when subject to data poisoning attacks, even for small adversarial perturbations. These findings question the reliability of policy values derived using OPE methods and motivate the need for developing OPE methods that are statistically robust to train-time data poisoning attacks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at UAI 2022"
    },
    {
        "paper id": "2404.04505",
        "abstract url": "https://arxiv.org/abs/2404.04505",
        "title": "Exploring UAV Networking from the Terrain Information Completeness Perspective: A Tutorial",
        "rating": -3,
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Terrain information is a crucial factor affecting the performance of unmanned aerial vehicle (UAV) networks. As a tutorial, this article provides a unique perspective on the completeness of terrain information, summarizing and enhancing the research on terrain-based UAV deployment. In the presence of complete terrain information, two highly discussed topics are UAV-aided map construction and dynamic trajectory design based on maps. We propose a case study illustrating the mutually reinforcing relationship between them. When terrain information is incomplete, and only terrain-related feature parameters are available, we discuss how existing models map terrain features to blockage probabilities. By introducing the application of this model with stochastic geometry, a case study is proposed to analyze the accuracy of the model. When no terrain information is available, UAVs gather terrain information during the real-time networking process and determine the next position by collected information. This real-time search method is currently limited to relay communication. In the case study, we extend it to a multi-user scenario and summarize three trade-offs of the method. Finally, we conduct a qualitative analysis to assess the impact of three factors that have been overlooked in terrain-based UAV deployment.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04586",
        "abstract url": "https://arxiv.org/abs/2404.04586",
        "title": "PIE: Physics-inspired Low-light Enhancement",
        "rating": -3,
        "keywords": [
            [
                "Low-light Enhancement"
            ],
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we propose a physics-inspired contrastive learning paradigm for low-light enhancement, called PIE. PIE primarily addresses three issues: (i) To resolve the problem of existing learning-based methods often training a LLE model with strict pixel-correspondence image pairs, we eliminate the need for pixel-correspondence paired training data and instead train with unpaired images. (ii) To address the disregard for negative samples and the inadequacy of their generation in existing methods, we incorporate physics-inspired contrastive learning for LLE and design the Bag of Curves (BoC) method to generate more reasonable negative samples that closely adhere to the underlying physical imaging principle. (iii) To overcome the reliance on semantic ground truths in existing methods, we propose an unsupervised regional segmentation module, ensuring regional brightness consistency while eliminating the dependency on semantic ground truths. Overall, the proposed PIE can effectively learn from unpaired positive/negative samples and smoothly realize non-semantic regional enhancement, which is clearly different from existing LLE efforts. Besides the novel architecture of PIE, we explore the gain of PIE on downstream tasks such as semantic segmentation and face detection. Training on readily available open data and extensive experiments demonstrate that our method surpasses the state-of-the-art LLE models over six independent cross-scenes datasets. PIE runs fast with reasonable GFLOPs in test time, making it easy to use on mobile devices.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2112.06451"
    },
    {
        "paper id": "2404.04597",
        "abstract url": "https://arxiv.org/abs/2404.04597",
        "title": "A Two Time-Scale Joint Optimization Approach for UAV-assisted MEC",
        "rating": -3,
        "keywords": [
            [
                "trajectory"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAV)-assisted mobile edge computing (MEC) is emerging as a promising paradigm to provide aerial-terrestrial computing services close to mobile devices (MDs). However, meeting the demands of computation-intensive and delay-sensitive tasks for MDs poses several challenges, including the demand-supply contradiction between MDs and MEC servers, the demand-supply heterogeneity between MDs and MEC servers, the trajectory control requirements on energy efficiency and timeliness, and the different time-scale dynamics of the network. To address these issues, we first present a hierarchical architecture by incorporating terrestrial-aerial computing capabilities and leveraging UAV flexibility. Furthermore, we formulate a joint computing resource allocation, computation offloading, and trajectory control problem to maximize the system utility. Since the problem is a non-convex mixed integer nonlinear programming (MINLP), we propose a two time-scale joint computing resource allocation, computation offloading, and trajectory control (TJCCT) approach. In the short time scale, we propose a price-incentive method for on-demand computing resource allocation and a matching mechanism-based method for computation offloading. In the long time scale, we propose a convex optimization-based method for UAV trajectory control. Besides, we prove the stability, optimality, and polynomial complexity of TJCCT. Simulation results demonstrate that TJCCT outperforms the comparative algorithms in terms of the utility of the system, the QoE of MDs, and the revenue of MEC servers.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2403.15828"
    },
    {
        "paper id": "2404.04629",
        "abstract url": "https://arxiv.org/abs/2404.04629",
        "title": "DifFUSER: Diffusion Model for Robust Multi-Sensor Fusion in 3D Object Detection and BEV Segmentation",
        "rating": -3,
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "synthesize"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have recently gained prominence as powerful deep generative models, demonstrating unmatched performance across various domains. However, their potential in multi-sensor fusion remains largely unexplored. In this work, we introduce DifFUSER, a novel approach that leverages diffusion models for multi-modal fusion in 3D object detection and BEV map segmentation. Benefiting from the inherent denoising property of diffusion, DifFUSER is able to refine or even synthesize sensor features in case of sensor malfunction, thereby improving the quality of the fused output. In terms of architecture, our DifFUSER blocks are chained together in a hierarchical BiFPN fashion, termed cMini-BiFPN, offering an alternative architecture for latent diffusion. We further introduce a Gated Self-conditioned Modulated (GSM) latent diffusion module together with a Progressive Sensor Dropout Training (PSDT) paradigm, designed to add stronger conditioning to the diffusion process and robustness to sensor failures. Our extensive evaluations on the Nuscenes dataset reveal that DifFUSER not only achieves state-of-the-art performance with a 69.1% mIOU in BEV map segmentation tasks but also competes effectively with leading transformer-based fusion techniques in 3D object detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2404.04654",
        "abstract url": "https://arxiv.org/abs/2404.04654",
        "title": "Music Recommendation Based on Facial Emotion Recognition",
        "rating": -3,
        "keywords": [
            [
                "Facial"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Introduction: Music provides an incredible avenue for individuals to express their thoughts and emotions, while also serving as a delightful mode of entertainment for enthusiasts and music lovers. Objectives: This paper presents a comprehensive approach to enhancing the user experience through the integration of emotion recognition, music recommendation, and explainable AI using GRAD-CAM. Methods: The proposed methodology utilizes a ResNet50 model trained on the Facial Expression Recognition (FER) dataset, consisting of real images of individuals expressing various emotions. Results: The system achieves an accuracy of 82% in emotion classification. By leveraging GRAD-CAM, the model provides explanations for its predictions, allowing users to understand the reasoning behind the system's recommendations. The model is trained on both FER and real user datasets, which include labelled facial expressions, and real images of individuals expressing various emotions. The training process involves pre-processing the input images, extracting features through convolutional layers, reasoning with dense layers, and generating emotion predictions through the output layer. Conclusion: The proposed methodology, leveraging the Resnet50 model with ROI-based analysis and explainable AI techniques, offers a robust and interpretable solution for facial emotion detection paper.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.15328",
        "abstract url": "https://arxiv.org/abs/2404.15328",
        "title": "Time topological analysis of EEG using signature theory",
        "rating": -3,
        "keywords": [
            [
                "Anomaly detection"
            ],
            [
                "EEG"
            ]
        ],
        "abstract": "Anomaly detection in multivariate signals is a task of paramount importance in many disciplines (epidemiology, finance, cognitive sciences and neurosciences, oncology, etc.). In this perspective, Topological Data Analysis (TDA) offers a battery of \"shape\" invariants that can be exploited for the implementation of an effective detection scheme. Our contribution consists of extending the constructions presented in \\cite{chretienleveraging} on the construction of simplicial complexes from the Signatures of signals and their predictive capacities, rather than the use of a generic distance as in \\cite{petri2014homological}. Signature theory is a new theme in Machine Learning arXiv:1603.03788 stemming from recent work on the notions of Rough Paths developed by Terry Lyons and his team \\cite{lyons2002system} based on the formalism introduced by Chen \\cite{chen1957integration}. We explore in particular the detection of changes in topology, based on tracking the evolution of homological persistence and the Betti numbers associated with the complex introduced in \\cite{chretienleveraging}. We apply our tools for the analysis of brain signals such as EEG to detect precursor phenomena to epileptic seizures.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages, 5 figures Under review for Journ\u00e9e des Statistiques 2024"
    },
    {
        "paper id": "2404.04804",
        "abstract url": "https://arxiv.org/abs/2404.04804",
        "title": "Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving",
        "rating": -3.5,
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Diffusion"
            ],
            [
                "Autonomous Driving",
                "LiDAR"
            ],
            [
                "Low-Light Enhancement"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Vision-centric perception systems for autonomous driving have gained considerable attention recently due to their cost-effectiveness and scalability, especially compared to LiDAR-based systems. However, these systems often struggle in low-light conditions, potentially compromising their performance and safety. To address this, our paper introduces LightDiff, a domain-tailored framework designed to enhance the low-light image quality for autonomous driving applications. Specifically, we employ a multi-condition controlled diffusion model. LightDiff works without any human-collected paired data, leveraging a dynamic data degradation process instead. It incorporates a novel multi-condition adapter that adaptively controls the input weights from different modalities, including depth maps, RGB images, and text captions, to effectively illuminate dark scenes while maintaining context consistency. Furthermore, to align the enhanced images with the detection model's knowledge, LightDiff employs perception-specific scores as rewards to guide the diffusion training process through reinforcement learning. Extensive experiments on the nuScenes datasets demonstrate that LightDiff can significantly improve the performance of several state-of-the-art 3D detectors in night-time conditions while achieving high visual quality scores, highlighting its potential to safeguard autonomous driving.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper is accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04692",
        "abstract url": "https://arxiv.org/abs/2404.04692",
        "title": "Securing the Skies: An IRS-Assisted AoI-Aware Secure Multi-UAV System with Efficient Task Offloading",
        "rating": -4,
        "keywords": [
            [
                "5G"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Unmanned Aerial Vehicles (UAVs) are integral in various sectors like agriculture, surveillance, and logistics, driven by advancements in 5G. However, existing research lacks a comprehensive approach addressing both data freshness and security concerns. In this paper, we address the intricate challenges of data freshness, and security, especially in the context of eavesdropping and jamming in modern UAV networks. Our framework incorporates exponential AoI metrics and emphasizes secrecy rate to tackle eavesdropping and jamming threats. We introduce a transformer-enhanced Deep Reinforcement Learning (DRL) approach to optimize task offloading processes. Comparative analysis with existing algorithms showcases the superiority of our scheme, indicating its promising advancements in UAV network management.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "7 pages, 5 figures, to be published in IEEE 99th Vehicular Technology Conference (VTC2024-Spring)"
    },
    {
        "paper id": "2404.04698",
        "abstract url": "https://arxiv.org/abs/2404.04698",
        "title": "EAGLE: The First Event Camera Dataset Gathered by an Agile Quadruped Robot",
        "rating": -5,
        "keywords": [
            [
                "RGB-D",
                "Event Camera"
            ],
            [
                "LiDAR"
            ],
            [
                "Robot"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "When legged robots perform agile movements, traditional RGB cameras often produce blurred images, posing a challenge for accurate state estimation. Event cameras, inspired by biological vision mechanisms, have emerged as a promising solution for capturing high-speed movements and coping with challenging lighting conditions, owing to their significant advantages, such as low latency, high temporal resolution, and a high dynamic range. However, the integration of event cameras into agile-legged robots is still largely unexplored. Notably, no event camera-based dataset has yet been specifically developed for dynamic legged robots. To bridge this gap, we introduce EAGLE (Event dataset of an AGile LEgged robot), a new dataset comprising data from an event camera, an RGB-D camera, an IMU, a LiDAR, and joint angle encoders, all mounted on a quadruped robotic platform. This dataset features more than 100 sequences from real-world environments, encompassing various indoor and outdoor environments, different lighting conditions, a range of robot gaits (e.g., trotting, bounding, pronking), as well as acrobatic movements such as backflipping. To our knowledge, this is the first event camera dataset to include multi-sensory data collected by an agile quadruped robot.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2404.04504",
        "abstract url": "https://arxiv.org/abs/2404.04504",
        "title": "Undecidability of tiling the plane with a fixed number of Wang bars",
        "rating": -10,
        "keywords": [],
        "abstract": "To study the fixed parameter undecidability of tiling problem for a set of Wang tiles, Jeandel and Rolin show that the tiling problem for a set of 44 Wang bars is undecidable. In this paper, we improve their result by proving that whether a set of 29 Wang bars can tile the plane is undecidable. As a consequence, the tiling problem for a set of Wang tiles with color deficiency of 25 is also undecidable.",
        "subjects": [
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04515",
        "abstract url": "https://arxiv.org/abs/2404.04515",
        "title": "Predictable Verification using Intrinsic Definitions",
        "rating": -10,
        "keywords": [],
        "abstract": "We propose a novel mechanism of defining data structures using intrinsic definitions that avoids recursion and instead utilizes monadic maps satisfying local conditions. We show that intrinsic definitions are a powerful mechanism that can capture a variety of data structures naturally. We show that they also enable a predictable verification methodology that allows engineers to write ghost code to update monadic maps and perform verification using reduction to decidable logics. We evaluate our methodology using Boogie and prove a suite of data structure manipulating programs correct.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "Published at PLDI 2024"
    },
    {
        "paper id": "2404.04516",
        "abstract url": "https://arxiv.org/abs/2404.04516",
        "title": "Language Models as Critical Thinking Tools: A Case Study of Philosophers",
        "rating": -10,
        "keywords": [],
        "abstract": "Current work in language models (LMs) helps us speed up or even skip thinking by accelerating and automating cognitive work. But can LMs help us with critical thinking -- thinking in deeper, more reflective ways which challenge assumptions, clarify ideas, and engineer new concepts? We treat philosophy as a case study in critical thinking, and interview 21 professional philosophers about how they engage in critical thinking and on their experiences with LMs. We find that philosophers do not find LMs to be useful because they lack a sense of selfhood (memory, beliefs, consistency) and initiative (curiosity, proactivity). We propose the selfhood-initiative model for critical thinking tools to characterize this gap. Using the model, we formulate three roles LMs could play as critical thinking tools: the Interlocutor, the Monitor, and the Respondent. We hope that our work inspires LM researchers to further develop LMs as critical thinking tools and philosophers and other 'critical thinkers' to imagine intellectually substantive uses of LMs.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04521",
        "abstract url": "https://arxiv.org/abs/2404.04521",
        "title": "Automated Computer Program Evaluation and Projects -- Our Experiences",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper provides a few approaches to automating computer programming and project submission tasks, that we have been following for the last six years and have found to be successful. The approaches include using CodeRunner with Learning Management System (LMS) integration for programming practice and evaluation, and Git (GitHub) for project submissions and automatic code evaluation. In this paper, we describe the details of how we set up the tools and customized those for computer science courses. Based on our experiences, we also provide a few insights on using these tools for effective learning.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "14 pages, 15 figures"
    },
    {
        "paper id": "2404.04539",
        "abstract url": "https://arxiv.org/abs/2404.04539",
        "title": "Electromagnetically-Consistent Modeling and Optimization of Mutual Coupling in RIS-Assisted Multi-User MIMO Communication Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "Mutual Coupling (MC) is an unavoidable feature in Reconfigurable Intelligent Surfaces (RISs) with sub-wavelength inter-element spacing. Its inherent presence naturally leads to non-local RIS structures, which can be efficiently described via non-diagonal phase shift matrices. In this paper, we focus on optimizing MC in RIS-assisted multi-user MIMO wireless communication systems. We particularly formulate a novel problem to jointly optimize active and passive beamforming as well as MC in a physically consistent manner. To characterize MC, we deploy scattering parameters and propose a novel approach to optimize them through an offline optimization method, rather than optimizing MC on the fly. Our numerical results showcase that the system performance increases with the proposed MC optimization, and this improvement is achievable without the need for optimizing MC on-the-fly, which can be rather cumbersome.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 5 figures, to be presented in IEEE ICC 2024"
    },
    {
        "paper id": "2404.04541",
        "abstract url": "https://arxiv.org/abs/2404.04541",
        "title": "Compilation of Modular and General Sparse Workspaces",
        "rating": -10,
        "keywords": [],
        "abstract": "Recent years have seen considerable work on compiling sparse tensor algebra expressions. This paper addresses a shortcoming in that work, namely how to generate efficient code (in time and space) that scatters values into a sparse result tensor. We address this shortcoming through a compiler design that generates code that uses sparse intermediate tensors (sparse workspaces) as efficient adapters between compute code that scatters and result tensors that do not support random insertion. Our compiler automatically detects sparse scattering behavior in tensor expressions and inserts necessary intermediate workspace tensors. We present an algorithm template for workspace insertion that is the backbone of our code generation algorithm. Our algorithm template is modular by design, supporting sparse workspaces that span multiple user-defined implementations. Our evaluation shows that sparse workspaces can be up to 27.12$\\times$ faster than the dense workspaces of prior work. On the other hand, dense workspaces can be up to 7.58$\\times$ faster than the sparse workspaces generated by our compiler in other situations, which motivates our compiler design that supports both. Our compiler produces sequential code that is competitive with hand-optimized linear and tensor algebra libraries on the expressions they support, but that generalizes to any other expression. Sparse workspaces are also more memory efficient than dense workspaces as they compress away zeros. This compression can asymptotically decrease memory usage, enabling tensor computations on data that would otherwise run out of memory.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "30 pages, 27 figures, to be published in Proc. ACM Program. Lang., Vol. 8, No. PLDI, Article 196. Publication date: June 2024"
    },
    {
        "paper id": "2404.04542",
        "abstract url": "https://arxiv.org/abs/2404.04542",
        "title": "Adaptive Polynomial Chaos Expansion for Uncertainty Quantification and Optimization of Horn Antennas at SubTHz Frequencies",
        "rating": -10,
        "keywords": [],
        "abstract": "Sub-terahertz (subTHz) antennas will play an important role in the next generations of wireless communication systems. However, when comes to the subTHz frequency spectrum, the antenna fabrication tolerance needs to be accurately considered during the design stage. The classic approach to studying the average performance of an antenna design considering fabrication tolerances is through the use of the Monte-Carlo (MC) method. In this paper, we propose an adaptive polynomial chaos expansion (PCE) method for the uncertainty quantification analysis of subTHz horn antennas with flat-top radiation patterns. The proposed method builds a surrogate model of the antenna's response to electromagnetic (EM) excitation and estimates its statistical moments with accuracy close to the reference MC method, but with a much smaller computational complexity of roughly two orders of magnitude. Moreover, the surrogate model based on PCE can substitute full-wave EM solvers in producing samples for electromagnetic quantities of interest, resulting in significant computational efficiency gains during optimization tasks. To this end, we successfully combined PCE with the particle swarm optimization method to design the free parameters of a horn antenna at $95$ GHz for a flat-top gain.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "10 pages, 12 figures, submitted to an IEEE Transactions Journal"
    },
    {
        "paper id": "2404.04545",
        "abstract url": "https://arxiv.org/abs/2404.04545",
        "title": "TCAN: Text-oriented Cross Attention Network for Multimodal Sentiment Analysis",
        "rating": -10,
        "keywords": [],
        "abstract": "Multimodal Sentiment Analysis (MSA) endeavors to understand human sentiment by leveraging language, visual, and acoustic modalities. Despite the remarkable performance exhibited by previous MSA approaches, the presence of inherent multimodal heterogeneities poses a challenge, with the contribution of different modalities varying considerably. Past research predominantly focused on improving representation learning techniques and feature fusion strategies. However, many of these efforts overlooked the variation in semantic richness among different modalities, treating each modality uniformly. This approach may lead to underestimating the significance of strong modalities while overemphasizing the importance of weak ones. Motivated by these insights, we introduce a Text-oriented Cross-Attention Network (TCAN), emphasizing the predominant role of the text modality in MSA. Specifically, for each multimodal sample, by taking unaligned sequences of the three modalities as inputs, we initially allocate the extracted unimodal features into a visual-text and an acoustic-text pair. Subsequently, we implement self-attention on the text modality and apply text-queried cross-attention to the visual and acoustic modalities. To mitigate the influence of noise signals and redundant features, we incorporate a gated control mechanism into the framework. Additionally, we introduce unimodal joint learning to gain a deeper understanding of homogeneous emotional tendencies across diverse modalities through backpropagation. Experimental results demonstrate that TCAN consistently outperforms state-of-the-art MSA methods on two datasets (CMU-MOSI and CMU-MOSEI).",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04552",
        "abstract url": "https://arxiv.org/abs/2404.04552",
        "title": "Fast and Simple Sorting Using Partial Information",
        "rating": -10,
        "keywords": [],
        "abstract": "We consider the problem of sorting a set of items having an unknown total order by doing binary comparisons of the items, given the outcomes of some pre-existing comparisons. We present a simple algorithm with a running time of $O(m+n+\\log T)$, where $n$, $m$, and $T$ are the number of items, the number of pre-existing comparisons, and the number of total orders consistent with the outcomes of the pre-existing comparisons, respectively. The algorithm does $O(\\log T)$ comparisons. Our running time and comparison bounds are best possible up to constant factors, thus resolving a problem that has been studied intensely since 1976 (Fredman, Theoretical Computer Science). The best previous algorithm with a bound of $O(\\log T)$ on the number of comparisons has a time bound of $O(n^{2.5})$ and is significantly more complicated. Our algorithm combines three classic algorithms: topological sort, heapsort with the right kind of heap, and efficient insertion into a sorted list.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04558",
        "abstract url": "https://arxiv.org/abs/2404.04558",
        "title": "EVT-enriched Radio Maps for URLLC",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper introduces a sophisticated and adaptable framework combining extreme value theory with radio maps to spatially model extreme channel conditions accurately. Utilising existing signal-to-noise ratio (SNR) measurements and leveraging Gaussian processes, our approach predicts the tail of the SNR distribution, which entails estimating the parameters of a generalised Pareto distribution, at unobserved locations. This innovative method offers a versatile solution adaptable to various resource allocation challenges in ultra-reliable low-latency communications. We evaluate the performance of this method in a rate maximisation problem with defined outage constraints and compare it with a benchmark in the literature. Notably, the proposed approach meets the outage demands in a larger percentage of the coverage area and reaches higher transmission rates.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "8 pages, 11 figures, submitted to IEEE Transactions on Wireless Communications"
    },
    {
        "paper id": "2404.04566",
        "abstract url": "https://arxiv.org/abs/2404.04566",
        "title": "Efficient and Green Large Language Models for Software Engineering: Vision and the Road Ahead",
        "rating": -10,
        "keywords": [],
        "abstract": "Large Language Models (LLMs) have recently shown remarkable capabilities in various software engineering tasks, spurring the rapid development of the Large Language Models for Software Engineering (LLM4SE) area. However, limited attention has been paid to crafting efficient LLM4SE solutions that demand minimal time and memory resources, as well as green LLM4SE solutions that reduce energy consumption and carbon emissions. This 2030 Software Engineering position paper aims to redirect the focus of the research community towards the efficiency and greenness of LLM4SE, while also sharing potential research directions to achieve this goal. It commences with a brief overview of the significance of LLM4SE and highlights the need for efficient and green LLM4SE solutions. Subsequently, the paper presents a vision for a future where efficient and green LLM4SE revolutionizes the software engineering tool landscape, benefiting various stakeholders, including industry, individual practitioners, and society. The paper then delineates a roadmap for future research, outlining specific research paths and potential solutions for the research community to pursue. While not intended to be a definitive guide, the paper aims to inspire further progress, with the ultimate goal of establishing efficient and green LLM4SE as a central element in the future of software engineering.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04570",
        "abstract url": "https://arxiv.org/abs/2404.04570",
        "title": "A Map of Exploring Human Interaction patterns with LLM: Insights into Collaboration and Creativity",
        "rating": -10,
        "keywords": [],
        "abstract": "The outstanding performance capabilities of large language model have driven the evolution of current AI system interaction patterns. This has led to considerable discussion within the Human-AI Interaction (HAII) community. Numerous studies explore this interaction from technical, design, and empirical perspectives. However, the majority of current literature reviews concentrate on interactions across the wider spectrum of AI, with limited attention given to the specific realm of interaction with LLM. We searched for articles on human interaction with LLM, selecting 110 relevant publications meeting consensus definition of Human-AI interaction. Subsequently, we developed a comprehensive Mapping Procedure, structured in five distinct stages, to systematically analyze and categorize the collected publications. Applying this methodical approach, we meticulously mapped the chosen studies, culminating in a detailed and insightful representation of the research landscape. Overall, our review presents an novel approach, introducing a distinctive mapping method, specifically tailored to evaluate human-LLM interaction patterns. We conducted a comprehensive analysis of the current research in related fields, employing clustering techniques for categorization, which enabled us to clearly delineate the status and challenges prevalent in each identified area.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04572",
        "abstract url": "https://arxiv.org/abs/2404.04572",
        "title": "Towards Architecting Sustainable MLOps: A Self-Adaptation Approach",
        "rating": -10,
        "keywords": [],
        "abstract": "In today's dynamic technological landscape, sustainability has emerged as a pivotal concern, especially with respect to architecting Machine Learning enabled Systems (MLS). Many ML models fail in transitioning to production, primarily hindered by uncertainties due to data variations, evolving requirements, and model instabilities. Machine Learning Operations (MLOps) offers a promising solution by enhancing adaptability and technical sustainability in MLS. However, MLOps itself faces challenges related to environmental impact, technical maintenance, and economic concerns. Over the years, self-adaptation has emerged as a potential solution to handle uncertainties. This paper introduces a novel approach employing self-adaptive principles integrated into the MLOps architecture through a MAPE-K loop to bolster MLOps sustainability. By autonomously responding to uncertainties, including data, model dynamics, and environmental variations, our approach aims to address the sustainability concerns of a given MLOps pipeline identified by an architect at design time. Further, we implement the method for a Smart City use case to display the capabilities of our approach.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "To be published in ICSA-C 2024"
    },
    {
        "paper id": "2404.04576",
        "abstract url": "https://arxiv.org/abs/2404.04576",
        "title": "Convex Reformulation of LMI-Based Distributed Controller Design with a Class of Non-Block-Diagonal Lyapunov Functions",
        "rating": -10,
        "keywords": [],
        "abstract": "This study addresses a distributed state feedback controller design problem for continuous-time linear time-invariant systems by means of linear matrix inequalities (LMI). As the exact convexification is still open, the block-diagonal relaxation of Lyapunov functions has been prevalent despite its conservatism. In this work, we target a class of non-block-diagonal Lyapunov functions that has the same sparsity as distributed controllers. By leveraging a block-diagonal factorization of sparse matrices and Finsler's lemma, we first present a (nonlinear) matrix inequality for stabilizing distributed controllers with such Lyapunov functions, which boils down to a necessary and sufficient condition for such controllers if the sparsity pattern is chordal. As a relaxation of the inequality, we derive an LMI that completely covers the conventional relaxation and then provide analogous results for $H_\\infty$ control. Lastly, numerical examples underscore the efficacy of our results.",
        "subjects": [
            "math.OC"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2404.04587",
        "abstract url": "https://arxiv.org/abs/2404.04587",
        "title": "Neuroevolving Electronic Dynamical Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "Neuroevolution is a powerful method of applying an evolutionary algorithm to refine the performance of artificial neural networks through natural selection; however, the fitness evaluation of these networks can be time-consuming and computationally expensive, particularly for continuous time recurrent neural networks (CTRNNs) that necessitate the simulation of differential equations. To overcome this challenge, field programmable gate arrays (FPGAs) have emerged as an increasingly popular solution, due to their high performance and low power consumption. Further, their ability to undergo dynamic and partial reconfiguration enables the extremely rapid evaluation of the fitness of CTRNNs, effectively addressing the bottleneck associated with conventional methods of evolvable hardware. By incorporating fitness evaluation directly upon the programmable logic of the FPGA, hyper-parallel evaluation becomes feasible, dramatically reducing the time required for assessment. This inherent parallelism of FPGAs accelerates the entire neuroevolutionary process by several orders of magnitude, facilitating faster convergence to an optimal solution. The work presented in this study demonstrates the potential of utilizing dynamic and partial reconfiguration on capable FPGAs as a powerful platform for neuroevolving dynamic neural networks.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2404.04603",
        "abstract url": "https://arxiv.org/abs/2404.04603",
        "title": "Analyzing LLM Usage in an Advanced Computing Class in India",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper investigates the usage patterns of undergraduate and graduate students when engaging with large language models (LLMs) to tackle programming assignments in the context of advanced computing courses. Existing work predominantly focuses on the influence of LLMs in introductory programming contexts. Additionally, there is a scarcity of studies analyzing actual conversations between students and LLMs. Our study provides a comprehensive quantitative and qualitative analysis of raw interactions between students and LLMs within an advanced computing course (Distributed Systems) at an Indian University. We further complement this by conducting student interviews to gain deeper insights into their usage patterns. Our study shows that students make use of large language models (LLMs) in various ways: generating code or debugging code by identifying and fixing errors. They also copy and paste assignment descriptions into LLM interfaces for specific solutions, ask conceptual questions about complex programming ideas or theoretical concepts, and generate test cases to check code functionality and robustness. Our analysis includes over 4,000 prompts from 411 students and conducting interviews with 10 students. Our analysis shows that LLMs excel at generating boilerplate code and assisting in debugging, while students handle the integration of components and system troubleshooting. This aligns with the learning objectives of advanced computing courses, which are oriented towards teaching students how to build systems and troubleshoot, with less emphasis on generating code from scratch. Therefore, LLM tools can be leveraged to increase student productivity, as shown by the data we collected. This study contributes to the ongoing discussion on LLM use in education, advocating for their usefulness in advanced computing courses to complement higher-level learning and productivity.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Under review: 12 pages"
    },
    {
        "paper id": "2404.04606",
        "abstract url": "https://arxiv.org/abs/2404.04606",
        "title": "Pushing the Limit of Range Resolution Beyond Bandwidth Constraint with Triangle FMCW",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper proposes a novel signal processing technique that doubles the range resolution of FMCW~(Frequency Modulated Continuous Wave) sensing without increasing the required bandwidth. The proposed design overcomes the resolution limit imposed by bandwidth by exploiting the phase consistency observed in the special frequency variation of the beat signal derived from triangle FMCW. Through this approach, the resolution is doubled while maintaining high spectrum SNR. A system model for signal processing is presented, and the energy distribution of the derived beat spectrum is analyzed. The effectiveness of the proposed technique is validated through model-based simulations.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04613",
        "abstract url": "https://arxiv.org/abs/2404.04613",
        "title": "Super Guarding and Dark Rays in Art Galleries",
        "rating": -10,
        "keywords": [],
        "abstract": "We explore an Art Gallery variant where each point of a polygon must be seen by k guards, and guards cannot see through other guards. Surprisingly, even covering convex polygons under this variant is not straightforward. For example, covering every point in a triangle k=4 times (a 4-cover) requires 5 guards, and achieving a 10-cover requires 12 guards. Our main result is tight bounds on k-covering a convex polygon of n vertices, for all k and n. The proofs of both upper and lower bounds are nontrivial. We also obtain bounds for simple polygons, leaving tight bounds an open problem.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "23 pages, 16 figures, 9 references"
    },
    {
        "paper id": "2404.04614",
        "abstract url": "https://arxiv.org/abs/2404.04614",
        "title": "Emerging Challenges of Integrating Solar PV in the Ireland and Northern Ireland Power Systems",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper discusses emerging operational challenges associated with the integration of solar photovoltaic (PV) in the All-Island power system (AIPS) of Ireland and Northern Ireland. These include the impact of solar PV on: (i) dispatch down levels; (ii) long-term frequency deviations; (iii) voltage magnitude variations; and (iv) operational demand variations. A case study based on actual data from the AIPS is used to analyze the above challenges. It is shown that despite its (still) relatively low penetration compared to wind power penetration, solar PV is challenging the real-time operation of the AIPS, e.g., maintaining frequency within operational limits. EirGrid and SONI, the transmission system operators (TSOs) of the AIPS, are working toward addressing all the above challenges.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04618",
        "abstract url": "https://arxiv.org/abs/2404.04618",
        "title": "Stability Assessment of Low-Inertia Power Systems: A System Operator Perspective",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper discusses the stability assessment of low-inertia power systems through a real-world large-scale low-inertia system, namely, the All-Island power system (AIPS) of Ireland and Northern Ireland. This system currently accommodates world-record levels of system non-synchronous penetration namely 75% (planning to increase to 80% next year). The paper discusses one-month results obtained with the state-of-the-art stability tool called look-ahead security assessment (LSAT). This tool carries out rotor-angle, frequency and voltage stability analyses and is implemented in the control centres of the transmission system operators (TSOs). The paper shows that, at the time of writing, the main binding stability constraint of the AIPS is related to the limits on the rate of change of frequency (RoCoF).",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04621",
        "abstract url": "https://arxiv.org/abs/2404.04621",
        "title": "IsoPredict: Dynamic Predictive Analysis for Detecting Unserializable Behaviors in Weakly Isolated Data Store Applications",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper presents the first dynamic predictive analysis for data store applications under weak isolation levels, called Isopredict. Given an observed serializable execution of a data store application, Isopredict generates and solves SMT constraints to find an unserializable execution that is a feasible execution of the application. Isopredict introduces novel techniques that handle divergent application behavior; solve mutually recursive sets of constraints; and balance coverage, precision, and performance. An evaluation on four transactional data store benchmarks shows that Isopredict often predicts unserializable behaviors, 99% of which are feasible.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04668",
        "abstract url": "https://arxiv.org/abs/2404.04668",
        "title": "Spectral Independence Beyond Total Influence on Trees and Related Graphs",
        "rating": -10,
        "keywords": [],
        "abstract": "We study how to establish $\\textit{spectral independence}$, a key concept in sampling, without relying on total influence bounds, by applying an $\\textit{approximate inverse}$ of the influence matrix. Our method gives constant upper bounds on spectral independence for two foundational Gibbs distributions known to have unbounded total influences: $\\bullet$ The monomer-dimer model on graphs with large girth (including trees). Prior to our work, such results were only known for graphs with constant maximum degrees or infinite regular trees, as shown by Chen, Liu, and Vigoda (STOC '21). $\\bullet$ The hardcore model on trees with fugacity $\u03bb< \\mathrm{e}^2$. This remarkably surpasses the well-known $\u03bb_r>\\mathrm{e}-1$ lower bound for the reconstruction threshold on trees, significantly improving upon the current threshold $\u03bb< 1.3$, established in a prior work by Efthymiou, Hayes, \u0160tefankovi\u010d, and Vigoda (RANDOM '23). Consequently, we establish optimal $\u03a9(n^{-1})$ spectral gaps of the Glauber dynamics for these models on arbitrary trees, regardless of the maximum degree $\u0394$.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04674",
        "abstract url": "https://arxiv.org/abs/2404.04674",
        "title": "Study of Adaptive Reweighted Sparse Belief Propagation Decoders for Polar Codes",
        "rating": -10,
        "keywords": [],
        "abstract": "In this paper, we present an adaptive reweighted sparse belief propagation (AR-SBP) decoder for polar codes. The AR-SBP technique is inspired by decoders that employ the sum-product algorithm for low-density parity-check codes. In particular, the AR-SBP decoding strategy introduces reweighting of the exchanged log-likelihood-ratio in order to refine the message passing, improving the performance of the decoder and reducing the number of required iterations. An analysis of the convergence of AR-SBP is carried out along with a study of the complexity of the analyzed decoders. Numerical examples show that the AR-SBP decoder outperforms existing decoding algorithms for a reduced number of iterations, enabling low-latency applications.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 3 figures"
    },
    {
        "paper id": "2404.04681",
        "abstract url": "https://arxiv.org/abs/2404.04681",
        "title": "Computation and Critical Transitions of Rate-Distortion-Perception Functions With Wasserstein Barycenter",
        "rating": -10,
        "keywords": [],
        "abstract": "The information rate-distortion-perception (RDP) function characterizes the three-way trade-off between description rate, average distortion, and perceptual quality measured by discrepancy between probability distributions. We study several variants of the RDP functions through the lens of optimal transport. By transforming the information RDP function into a Wasserstein Barycenter problem, we identify the critical transitions when one of the constraints becomes inactive and demonstrate several critical transition properties of the RDP variants. Further, the non-strictly convexity brought by the perceptual constraint can be regularized by an entropy regularization term. We prove that the entropy regularized model converges to the original problem and propose an alternating iteration method based on the Sinkhorn algorithm to numerically solve the regularized optimization problem. Experimental results demonstrate the effectiveness and accuracy of the proposed algorithms. As a practical application of our theory, we incorporate our numerical method into a reverse data hiding problem, where a secret message is imperceptibly embedded into the image with guarantees of the perceptual fidelity.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2304.14611. This paper was presented in part at the 2023 IEEE International Symposium on Information Theory"
    },
    {
        "paper id": "2404.04688",
        "abstract url": "https://arxiv.org/abs/2404.04688",
        "title": "Search-based Automated Program Repair of CPS Controllers Modeled in Simulink-Stateflow",
        "rating": -10,
        "keywords": [],
        "abstract": "Stateflow models are widely used in the industry to model the high-level control logic of Cyber-Physical Systems (CPSs) in Simulink--the defacto CPS simulator. Many approaches exist to test Simulink models, but once a fault is detected, the process to repair it remains manual. Such a manual process increases the software development cost, making it paramount to develop novel techniques that reduce this cost. Automated Program Repair (APR) techniques can significantly reduce the time for fixing bugs by automatically generating patches. However, current approaches face scalability issues to be applicable in the CPS context. To deal with this problem, we propose an automated search-based approach called FlowRepair, explicitly designed to repair Stateflow models. The novelty of FlowRepair includes, (1) a new algorithm that combines global and local search for patch generation; (2) a definition of novel repair objectives (e.g., the time a fault remained active) specifically designed for repairing CPSs; and (3) a set of mutation operators to repair Stateflow models automatically. We evaluated FlowRepair with three different case study systems and a total of nine faulty stateflow models. Our experiments suggest that (1) Flo wRepaircan fix bugs in stateflow models, including models with multiple faults; (2) FlowRepair surpasses or performs similarly to a baseline APR technique inspired by a well-known CPS program repair approach. Besides, we provide both a replication package and a live repository, paving the way towards the APR of CPSs modeled in Simulink.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04689",
        "abstract url": "https://arxiv.org/abs/2404.04689",
        "title": "Multicalibration for Confidence Scoring in LLMs",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper proposes the use of \"multicalibration\" to yield interpretable and reliable confidence scores for outputs generated by large language models (LLMs). Multicalibration asks for calibration not just marginally, but simultaneously across various intersecting groupings of the data. We show how to form groupings for prompt/completion pairs that are correlated with the probability of correctness via two techniques: clustering within an embedding space, and \"self-annotation\" - querying the LLM by asking it various yes-or-no questions about the prompt. We also develop novel variants of multicalibration algorithms that offer performance improvements by reducing their tendency to overfit. Through systematic benchmarking across various question answering datasets and LLMs, we show how our techniques can yield confidence scores that provide substantial improvements in fine-grained measures of both calibration and accuracy compared to existing methods.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04695",
        "abstract url": "https://arxiv.org/abs/2404.04695",
        "title": "\"Don't Step on My Toes\": Resolving Editing Conflicts in Real-Time Collaboration in Computational Notebooks",
        "rating": -10,
        "keywords": [],
        "abstract": "Real-time collaborative editing in computational notebooks can improve the efficiency of teamwork for data scientists. However, working together through synchronous editing of notebooks introduces new challenges. Data scientists may inadvertently interfere with each others' work by altering the shared codebase and runtime state if they do not set up a social protocol for working together and monitoring their collaborators' progress. In this paper, we propose a real-time collaborative editing model for resolving conflict edits in computational notebooks that introduces three levels of edit protection to help collaborators avoid introducing errors to both the program source code and changes to the runtime state.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04699",
        "abstract url": "https://arxiv.org/abs/2404.04699",
        "title": "Deep Reinforcement Learning Control for Disturbance Rejection in a Nonlinear Dynamic System with Parametric Uncertainty",
        "rating": -10,
        "keywords": [],
        "abstract": "This work describes a technique for active rejection of multiple independent and time-correlated stochastic disturbances for a nonlinear flexible inverted pendulum with cart system with uncertain model parameters. The control law is determined through deep reinforcement learning, specifically with a continuous actor-critic variant of deep Q-learning known as Deep Deterministic Policy Gradient, while the disturbance magnitudes evolve via independent stochastic processes. Simulation results are then compared with those from a classical control system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04703",
        "abstract url": "https://arxiv.org/abs/2404.04703",
        "title": "Aleph Filter: To Infinity in Constant Time",
        "rating": -10,
        "keywords": [],
        "abstract": "Filter data structures are widely used in various areas of computer science to answer approximate set-membership queries. In many applications, the data grows dynamically, requiring their filters to expand along with the data that they represent. However, existing methods for expanding filters cannot maintain stable performance, memory footprint, and false positive rate at the same time. We address this problem with Aleph Filter, which makes the following contributions. (1) It supports all operations (insertions, queries, deletes, etc.) in constant time, no matter how much the data grows. (2) Given any rough estimate of how much the data will ultimately grow, Aleph Filter provides far superior memory vs. false positive rate trade-offs, even if the estimate is off by orders of magnitude.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04705",
        "abstract url": "https://arxiv.org/abs/2404.04705",
        "title": "Twisted conjugacy in dihedral Artin groups II: Baumslag Solitar groups $\\mathrm{BS}(n,n)$",
        "rating": -10,
        "keywords": [],
        "abstract": "In this second paper we solve the twisted conjugacy problem for even dihedral Artin groups, that is, groups with presentation $G(m) = \\langle a,b \\mid {}_{m}(a,b) = {}_{m}(b,a) \\rangle$, where $m \\geq 2$ is even, and $_{m}(a,b)$ is the word $abab\\dots$ of length $m$. Similar to odd dihedral Artin groups, we prove orbit decidability for all subgroups $A \\leq \\mathrm{Aut}(G(m))$, which then implies that the conjugacy problem is solvable in extensions of even dihedral Artin groups.",
        "subjects": [
            "math.GR"
        ],
        "comment": "Comments welcome!"
    },
    {
        "paper id": "2404.04706",
        "abstract url": "https://arxiv.org/abs/2404.04706",
        "title": "Advances in Differential Privacy and Differentially Private Machine Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "There has been an explosion of research on differential privacy (DP) and its various applications in recent years, ranging from novel variants and accounting techniques in differential privacy to the thriving field of differentially private machine learning (DPML) to newer implementations in practice, like those by various companies and organisations such as census bureaus. Most recent surveys focus on the applications of differential privacy in particular contexts like data publishing, specific machine learning tasks, analysis of unstructured data, location privacy, etc. This work thus seeks to fill the gap for a survey that primarily discusses recent developments in the theory of differential privacy along with newer DP variants, viz. Renyi DP and Concentrated DP, novel mechanisms and techniques, and the theoretical developments in differentially private machine learning in proper detail. In addition, this survey discusses its applications to privacy-preserving machine learning in practice and a few practical implementations of DP.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04708",
        "abstract url": "https://arxiv.org/abs/2404.04708",
        "title": "Efficient Sparse Processing-in-Memory Architecture (ESPIM) for Machine Learning Inference",
        "rating": -10,
        "keywords": [],
        "abstract": "Emerging machine learning (ML) models (e.g., transformers) involve memory pin bandwidth-bound matrix-vector (MV) computation in inference. By avoiding pin crossings, processing in memory (PIM) can improve performance and energy for pin-bound workloads, as evidenced by recent commercial efforts in (digital) PIM. Sparse models can improve performance and energy of inference without losing much accuracy. However, unstructured sparse inference injects the key challenges of uncertainty, irregularity, and load imbalance into a dense PIM's operation across all the banks. The dense PIM reads the matrix cells from each bank and broadcasts the vector elements to all the banks exploiting DRAM organization. To address these challenges efficiently, we propose ESPIM which makes four contributions: (1) Because matrix sparsity increases the vector broadcast bandwidth demand per matrix column-read, ESPIM employs a fine-grained interleaving of the matrix cells so that each vector broadcast is shared among multiple rows in each bank, cutting the bandwidth demand. (2) ESPIM mostly avoids on-chip control's area and energy despite sparsity's uncertainties by exploiting the observation that the sparsity is data-dependent but static and known before inference. Accordingly, ESPIM employs static data-dependent scheduling (SDDS) (3) ESPIM decouples the matrix cell values and their indices, placing the indices ahead of the values to enable prefetching of the vector elements. We extend SDDS for performance and correctness with the decoupled prefetching. (4) Finally, we simplify the switch required to select the vector elements that match the matrix cells. We extend SDDS to improve performance by reducing conflicts in the simplified switch. In our simulations, ESPIM achieves 2x average (up to 4.2x) speedup over and 34% average (up to 63%) lower energy than Newton while incurring under 5% area.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04710",
        "abstract url": "https://arxiv.org/abs/2404.04710",
        "title": "Explaining Indian Stock Market through Geometry of Scale free Networks",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper presents an analysis of the Indian stock market using a method based on embedding the network in a hyperbolic space using Machine learning techniques. We claim novelty on four counts. First, it is demonstrated that the hyperbolic clusters resemble the topological network communities more closely than the Euclidean clusters. Second, we are able to clearly distinguish between periods of market stability and volatility through a statistical analysis of hyperbolic distance and hyperbolic shortest path distance corresponding to the embedded network. Third, we demonstrate that using the modularity of the embedded network significant market changes can be spotted early. Lastly, the coalescent embedding is able to segregate the certain market sectors thereby underscoring its natural clustering ability.",
        "subjects": [
            "physics.soc-ph"
        ],
        "comment": "44 pages, 11 figures"
    },
    {
        "paper id": "2404.04713",
        "abstract url": "https://arxiv.org/abs/2404.04713",
        "title": "Faster Algorithms for Fair Max-Min Diversification in $\\mathbb{R}^d$",
        "rating": -10,
        "keywords": [],
        "abstract": "The task of extracting a diverse subset from a dataset, often referred to as maximum diversification, plays a pivotal role in various real-world applications that have far-reaching consequences. In this work, we delve into the realm of fairness-aware data subset selection, specifically focusing on the problem of selecting a diverse set of size $k$ from a large collection of $n$ data points (FairDiv). The FairDiv problem is well-studied in the data management and theory community. In this work, we develop the first constant approximation algorithm for FairDiv that runs in near-linear time using only linear space. In contrast, all previously known constant approximation algorithms run in super-linear time (with respect to $n$ or $k$) and use super-linear space. Our approach achieves this efficiency by employing a novel combination of the Multiplicative Weight Update method and advanced geometric data structures to implicitly and approximately solve a linear program. Furthermore, we improve the efficiency of our techniques by constructing a coreset. Using our coreset, we also propose the first efficient streaming algorithm for the FairDiv problem whose efficiency does not depend on the distribution of data points. Empirical evaluation on million-sized datasets demonstrates that our algorithm achieves the best diversity within a minute. All prior techniques are either highly inefficient or do not generate a good solution.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04725",
        "abstract url": "https://arxiv.org/abs/2404.04725",
        "title": "We need to aim at the top: Factors associated with cybersecurity awareness of cyber and information security decision-makers",
        "rating": -10,
        "keywords": [],
        "abstract": "Cyberattacks pose a significant business risk to organizations. Although there is ample literature focusing on why people pose a major risk to organizational cybersecurity and how to deal with it, there is surprisingly little we know about cyber and information security decision-makers who are essentially the people in charge of setting up and maintaining organizational cybersecurity. In this paper, we study cybersecurity awareness of cyber and information security decision-makers, and investigate factors associated with it. We conducted an online survey among Slovenian cyber and information security decision-makers (N=283) to (1) determine whether their cybersecurity awareness is associated with adoption of antimalware solutions in their organizations, and (2) explore which organizational factors and personal characteristics are associated with their cybersecurity awareness. Our findings indicate that awareness of well-known threats and solutions seems to be quite low for individuals in decision-making roles. They also provide insights into which threats and solutions are cyber and information security decision-makers the least aware of. We uncovered that awareness of certain threats and solutions is positively associated with either adoption of advanced antimalware solutions with EDR/XDR capabilities or adoption of SOC. Additionally, we identified significant organizational factors (organizational role type) and personal characteristics (gender, age, experience with information security and experience with IT) related to cybersecurity awareness of cyber and information security decision-makers. Organization size and formal education were not significant. These results offer insights that can be leveraged in targeted cybersecurity training tailored to the needs of groups of cyber and information security decision-makers based on these key factors.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04727",
        "abstract url": "https://arxiv.org/abs/2404.04727",
        "title": "A code-driven tutorial on encrypted control: From pioneering realizations to modern implementations",
        "rating": -10,
        "keywords": [],
        "abstract": "The growing interconnectivity in control systems due to robust wireless communication and cloud usage paves the way for exciting new opportunities such as data-driven control and service-based decision-making. At the same time, connected systems are susceptible to cyberattacks and data leakages. Against this background, encrypted control aims to increase the security and safety of cyber-physical systems. A central goal is to ensure confidentiality of process data during networked controller evaluations, which is enabled by, e.g., homomorphic encryption. However, the integration of advanced cryptographic systems renders the design of encrypted controllers an interdisciplinary challenge. This code-driven tutorial paper aims to facilitate the access to encrypted control by providing exemplary realizations based on popular homomorphic cryptosystems. In particular, we discuss the encrypted implementation of state feedback and PI controllers using the Paillier, GSW, and CKKS cryptosystem.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04729",
        "abstract url": "https://arxiv.org/abs/2404.04729",
        "title": "Towards a low carbon proof-of-work blockchain",
        "rating": -10,
        "keywords": [],
        "abstract": "Proof of Work (PoW) blockchains burn a lot of energy. Proof-of-work algorithms are expensive by design and often only serve to compute blockchains. In some sense, carbon-based and non-carbon based regional electric power is fungible. So the total carbon and non-carbon electric power mix plays a role. Thus, generally PoW algorithms have large CO$_2$ footprints solely for computing blockchains. A proof of technology is described towards replacing hashcash or other PoW methods with a lottery and proof-of-VM (PoVM) emulation. PoVM emulation is a form of PoW where an autonomous blockchain miner gets a lottery ticket in exchange for providing a VM (virtual Machine) for a specified period. These VMs get their jobs from a job queue. Managing and ensuring, by concensus, that autonomous PoVMs are properly configured and running as expected gives several gaps for a complete practical system. These gaps are discussed. Our system is similar to a number of other blockchain systems. We briefly survey these systems. This paper along with our proof of technology was done as a senior design project.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04744",
        "abstract url": "https://arxiv.org/abs/2404.04744",
        "title": "Adapting Multi-objectivized Software Configuration Tuning",
        "rating": -10,
        "keywords": [],
        "abstract": "When tuning software configuration for better performance (e.g., latency or throughput), an important issue that many optimizers face is the presence of local optimum traps, compounded by a highly rugged configuration landscape and expensive measurements. To mitigate these issues, a recent effort has shifted to focus on the level of optimization model (called meta multi-objectivization or MMO) instead of designing better optimizers as in traditional methods. This is done by using an auxiliary performance objective, together with the target performance objective, to help the search jump out of local optima. While effective, MMO needs a fixed weight to balance the two objectives-a parameter that has been found to be crucial as there is a large deviation of the performance between the best and the other settings. However, given the variety of configurable software systems, the \"sweet spot\" of the weight can vary dramatically in different cases and it is not possible to find the right setting without time-consuming trial and error. In this paper, we seek to overcome this significant shortcoming of MMO by proposing a weight adaptation method, dubbed AdMMO. Our key idea is to adaptively adjust the weight at the right time during tuning, such that a good proportion of the nondominated configurations can be maintained. Moreover, we design a partial duplicate retention mechanism to handle the issue of too many duplicate configurations without losing the rich information provided by the \"good\" duplicates. Experiments on several real-world systems, objectives, and budgets show that, for 71% of the cases, AdMMO is considerably superior to MMO and a wide range of state-of-the-art optimizers while achieving generally better efficiency with the best speedup between 2.2x and 20x.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper has been accepted at ACM FSE'24"
    },
    {
        "paper id": "2404.04751",
        "abstract url": "https://arxiv.org/abs/2404.04751",
        "title": "A 97% Peak Efficiency Single-Inductor-Multiple-Output DC-DC Converter with a Shared Bootstrap Gate Driver",
        "rating": -10,
        "keywords": [],
        "abstract": "This paper describes a SIMO DC-DC converter capable of generating all the required voltages (buck and boost) utilizing n-type transistors for the output switches. The design incorporates only one shared bootstrap capacitor and a single pad to connect the top plate of the off-chip bootstrap capacitor to the on-chip drivers. By utilizing one off-chip bootstrap capacitor and sharing it between the multiple outputs, this work presents a low cost and low area solution for implementing a SIMO DC-DC converter using n-type transistor switches. A prototype of the proposed SIMO DC-DC converter is fabricated in 180nm SILTERRA BCD Technology.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "2 pages, 7 figures"
    },
    {
        "paper id": "2404.04760",
        "abstract url": "https://arxiv.org/abs/2404.04760",
        "title": "KATch: A Fast Symbolic Verifier for NetKAT",
        "rating": -10,
        "keywords": [],
        "abstract": "We develop new data structures and algorithms for checking verification queries in NetKAT, a domain-specific language for specifying the behavior of network data planes. Our results extend the techniques obtained in prior work on symbolic automata and provide a framework for building efficient and scalable verification tools. We present \\KATch, an implementation of these ideas in Scala, featuring an extended set of NetKAT operators that are useful for expressing network-wide specifications, and a verification engine that constructs a bisimulation or generates a counter-example showing that none exists. We evaluate the performance of our implementation on real-world and synthetic benchmarks, verifying properties such as reachability and slice isolation, typically returning a result in well under a second, which is orders of magnitude faster than previous approaches. Our advancements underscore NetKAT's potential as a practical, declarative language for network specification and verification.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04769",
        "abstract url": "https://arxiv.org/abs/2404.04769",
        "title": "Safeguarding Voice Privacy: Harnessing Near-Ultrasonic Interference To Protect Against Unauthorized Audio Recording",
        "rating": -10,
        "keywords": [],
        "abstract": "The widespread adoption of voice-activated systems has modified routine human-machine interaction but has also introduced new vulnerabilities. This paper investigates the susceptibility of automatic speech recognition (ASR) algorithms in these systems to interference from near-ultrasonic noise. Building upon prior research that demonstrated the ability of near-ultrasonic frequencies (16 kHz - 22 kHz) to exploit the inherent properties of microelectromechanical systems (MEMS) microphones, our study explores alternative privacy enforcement means using this interference phenomenon. We expose a critical vulnerability in the most common microphones used in modern voice-activated devices, which inadvertently demodulate near-ultrasonic frequencies into the audible spectrum, disrupting the ASR process. Through a systematic analysis of the impact of near-ultrasonic noise on various ASR systems, we demonstrate that this vulnerability is consistent across different devices and under varying conditions, such as broadcast distance and specific phoneme structures. Our findings highlight the need to develop robust countermeasures to protect voice-activated systems from malicious exploitation of this vulnerability. Furthermore, we explore the potential applications of this phenomenon in enhancing privacy by disrupting unauthorized audio recording or eavesdropping. This research underscores the importance of a comprehensive approach to securing voice-activated systems, combining technological innovation, responsible development practices, and informed policy decisions to ensure the privacy and security of users in an increasingly connected world.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04772",
        "abstract url": "https://arxiv.org/abs/2404.04772",
        "title": "Efficient Reinforcement Learning of Task Planners for Robotic Palletization through Iterative Action Masking Learning",
        "rating": -10,
        "keywords": [],
        "abstract": "The development of robotic systems for palletization in logistics scenarios is of paramount importance, addressing critical efficiency and precision demands in supply chain management. This paper investigates the application of Reinforcement Learning (RL) in enhancing task planning for such robotic systems. Confronted with the substantial challenge of a vast action space, which is a significant impediment to efficiently apply out-of-the-shelf RL methods, our study introduces a novel method of utilizing supervised learning to iteratively prune and manage the action space effectively. By reducing the complexity of the action space, our approach not only accelerates the learning phase but also ensures the effectiveness and reliability of the task planning in robotic palletization. The experimental results underscore the efficacy of this method, highlighting its potential in improving the performance of RL applications in complex and high-dimensional environments like logistics palletization.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2404.04773",
        "abstract url": "https://arxiv.org/abs/2404.04773",
        "title": "Approximating Unrelated Machine Weighted Completion Time Using Iterative Rounding and Computer Assisted Proofs",
        "rating": -10,
        "keywords": [],
        "abstract": "We revisit the unrelated machine scheduling problem with the weighted completion time objective. It is known that independent rounding achieves a 1.5 approximation for the problem, and many prior algorithms improve upon this ratio by leveraging strong negative correlation schemes. On each machine $i$, these schemes introduce strong negative correlation between events that some pairs of jobs are assigned to $i$, while maintaining non-positive correlation for all pairs. Our algorithm deviates from this methodology by relaxing the pairwise non-positive correlation requirement. On each machine $i$, we identify many groups of jobs. For a job $j$ and a group $B$ not containing $j$, we only enforce non-positive correlation between $j$ and the group as a whole, allowing $j$ to be positively-correlated with individual jobs in $B$. This relaxation suffices to maintain the 1.5-approximation, while enabling us to obtain a much stronger negative correlation within groups using an iterative rounding procedure: at most one job from each group is scheduled on $i$. We prove that the algorithm achieves a $(1.36 + \u03b5)$-approximation, improving upon the previous best approximation ratio of $1.4$ due to Harris. While the improvement may not be substantial, the significance of our contribution lies in the relaxed non-positive correlation condition and the iterative rounding framework. Due to the simplicity of our algorithm, we are able to derive a closed form for the weighted completion time our algorithm achieves with a clean analysis. Unfortunately, we could not provide a good analytical analysis for the quantity; instead, we rely on a computer assisted proof.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04776",
        "abstract url": "https://arxiv.org/abs/2404.04776",
        "title": "Soft-in Soft-out Decoding of Spherical Codes from Cartesian Powers of PAM Constellations",
        "rating": -10,
        "keywords": [],
        "abstract": "For applications in concatenated coding for optical communications systems, we examine the encoding and soft-decoding of short spherical codes constructed as constant-energy shells of the Cartesian power of pulse amplitude modulation constellations. These are unions of permutation codes having the same average power. We construct a list decoder for permutation codes by adapting Murty's algorithm, which is then used to determine mutual information curves for these permutation codes. In the process, we discover a straightforward expression for determining the likelihood of large subcodes of permutation codes. We refer to these subcodes, obtained by all possible sign flips of a given permutation codeword, as orbits. We introduce a simple process, which we call orbit decoding with frozen symbols, that allows us to extract soft information from noisy permutation codewords. In a sample communication system with probabilistic amplitude shaping protected by a standard low-density parity-check code that employs short permutation codes, we demonstrate that orbit decoding with frozen symbols provides a gain of about 0.3 dB in signal-to-noise ratio compared to the traditional symbol-by-symbol decoding. By using spherical codes composed of unions of permutation codes, we can increase the input entropy compared to using permutation codes alone. In one scheme, we consider a union of a small number of permutation codes. In this case, orbit decoding with frozen symbols provides about 0.2 dB gain compared to the traditional method. In another scheme, we use all possible permutations to form a spherical code that exhibits a computationally feasible trellis representation. The soft information obtained using the BCJR algorithm outperforms the traditional symbol-by-symbol method by 0.1 dB.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04779",
        "abstract url": "https://arxiv.org/abs/2404.04779",
        "title": "SoPhAr: Solar Phased-Arrays to boost the range of electric, hydrogen and SAF airliners in a solar world",
        "rating": -10,
        "keywords": [],
        "abstract": "In late 2022, ICAO member states adopted a long-term global aspirational goal (LTAG) to achieve net zero carbon emissions from international aviation by 2050. To date however, no economically scalable solution to the aviation decarbonization problem has been proposed. Despite considerable research on potential alternative fuels including e-fuels, Sustainable Aviation Fuel (SAF), Hydrogen or Ammonia, and extensive research on purely electric propulsion, low-carbon propulsion methods are unable to replace fossil-fuels with identical or better economics. A possible alternative to current propulsion technologies is to directly beam the required propulsive power to aircraft. Several techniques have been considered to date, in particular laser energy beaming and microwave energy beaming. This paper proposes a possible concept where future airliners are mostly powered with ground-generated power. With expected improvements and scaling in solar panel manufacturing, the proposed concept would be economically competitive even with current jet fuel prices, while considerably reducing CO2 emissions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04795",
        "abstract url": "https://arxiv.org/abs/2404.04795",
        "title": "Range Longest Increasing Subsequence and its Relatives: Beating Quadratic Barrier and Approaching Optimality",
        "rating": -10,
        "keywords": [],
        "abstract": "In this work, we present a plethora of results for the range longest increasing subsequence problem (Range-LIS) and its variants. The input to Range-LIS is a sequence $\\mathcal{S}$ of $n$ real numbers and a collection $\\mathcal{Q}$ of $m$ query ranges and for each query in $\\mathcal{Q}$, the goal is to report the LIS of the sequence $\\mathcal{S}$ restricted to that query. Our two main results are for the following generalizations of the Range-LIS problem: $\\bullet$ 2D Range Queries: In this variant of the Range-LIS problem, each query is a pair of ranges, one of indices and the other of values, and we provide an algorithm with running time $\\tilde{O}(mn^{1/2}+ n^{3/2} +k)$, where $k$ is the cumulative length of the $m$ output subsequences. This breaks the quadratic barrier of $\\tilde{O}(mn)$ when $m=\u03a9(\\sqrt{n})$. Previously, the only known result breaking the quadratic barrier was of Tiskin [SODA'10] which could only handle 1D range queries (i.e., each query was a range of indices) and also just outputted the length of the LIS (instead of reporting the subsequence achieving that length). $\\bullet$ Colored Sequences: In this variant of the Range-LIS problem, each element in $\\mathcal{S}$ is colored and for each query in $\\mathcal{Q}$, the goal is to report a monochromatic LIS contained in the sequence $\\mathcal{S}$ restricted to that query. For 2D queries, we provide an algorithm for this colored version with running time $\\tilde{O}(mn^{2/3}+ n^{5/3} +k)$. Moreover, for 1D queries, we provide an improved algorithm with running time $\\tilde{O}(mn^{1/2}+ n^{3/2} +k)$. Thus, we again break the quadratic barrier of $\\tilde{O}(mn)$. Additionally, we prove that assuming the well-known Combinatorial Boolean Matrix Multiplication Hypothesis, that the runtime for 1D queries is essentially tight for combinatorial algorithms.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "Abstract shortened to meet Arxiv requirements"
    },
    {
        "paper id": "2404.15193",
        "abstract url": "https://arxiv.org/abs/2404.15193",
        "title": "Structurally Flexible Neural Networks: Evolving the Building Blocks for General Agents",
        "rating": -10,
        "keywords": [],
        "abstract": "Artificial neural networks used for reinforcement learning are structurally rigid, meaning that each optimized parameter of the network is tied to its specific placement in the network structure. It also means that a network only works with pre-defined and fixed input- and output sizes. This is a consequence of having the number of optimized parameters being directly dependent on the structure of the network. Structural rigidity limits the ability to optimize parameters of policies across multiple environments that do not share input and output spaces. Here, we evolve a set of neurons and plastic synapses each represented by a gated recurrent unit (GRU). During optimization, the parameters of these fundamental units of a neural network are optimized in different random structural configurations. Earlier work has shown that parameter sharing between units is important for making structurally flexible neurons We show that it is possible to optimize a set of distinct neuron- and synapse types allowing for a mitigation of the symmetry dilemma. We demonstrate this by optimizing a single set of neurons and synapses to solve multiple reinforcement learning control tasks simultaneously.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    }
]