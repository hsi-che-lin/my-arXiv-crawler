[
    {
        "paper id": "2404.05016",
        "abstract url": "https://arxiv.org/abs/2404.05016",
        "title": "Hyperbolic Learning with Synthetic Captions for Open-World Detection",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Open-world detection poses significant challenges, as it requires the detection of any object using either object class labels or free-form texts. Existing related works often use large-scale manual annotated caption datasets for training, which are extremely expensive to collect. Instead, we propose to transfer knowledge from vision-language models (VLMs) to enrich the open-vocabulary descriptions automatically. Specifically, we bootstrap dense synthetic captions using pre-trained VLMs to provide rich descriptions on different regions in images, and incorporate these captions to train a novel detector that generalizes to novel concepts. To mitigate the noise caused by hallucination in synthetic captions, we also propose a novel hyperbolic vision-language learning approach to impose a hierarchy between visual and caption embeddings. We call our detector ``HyperLearner''. We conduct extensive experiments on a wide variety of open-world detection benchmarks (COCO, LVIS, Object Detection in the Wild, RefCOCO) and our results show that our model consistently outperforms existing state-of-the-art methods, such as GLIP, GLIPv2 and Grounding DINO, when using the same backbone.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2404.05143",
        "abstract url": "https://arxiv.org/abs/2404.05143",
        "title": "Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation",
        "rating": "2.5",
        "keywords": [
            [
                "parameter efficient"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Transformer-based Large Language Models (LLMs) have shown exceptional language generation capabilities in response to text-based prompts. However, controlling the direction of generation via textual prompts has been challenging, especially with smaller models. In this work, we explore the use of Prompt Tuning to achieve controlled language generation. Generated text is steered using prompt embeddings, which are trained using a small language model, used as a discriminator. Moreover, we demonstrate that these prompt embeddings can be trained with a very small dataset, with as low as a few hundred training examples. Our method thus offers a data and parameter efficient solution towards controlling language model outputs. We carry out extensive evaluation on four datasets: SST-5 and Yelp (sentiment analysis), GYAFC (formality) and JIGSAW (toxic language). Finally, we demonstrate the efficacy of our method towards mitigating harmful, toxic, and biased text generated by language models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "9 pages, 3 figures, Presented at Deployable AI Workshop at AAAI-2024"
    },
    {
        "paper id": "2404.04838",
        "abstract url": "https://arxiv.org/abs/2404.04838",
        "title": "Data Bias According to Bipol: Men are Naturally Right and It is the Role of Women to Follow Their Lead",
        "rating": "2",
        "keywords": [
            [
                "social bias"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We introduce new large labeled datasets on bias in 3 languages and show in experiments that bias exists in all 10 datasets of 5 languages evaluated, including benchmark datasets on the English GLUE/SuperGLUE leaderboards. The 3 new languages give a total of almost 6 million labeled samples and we benchmark on these datasets using SotA multilingual pretrained models: mT5 and mBERT. The challenge of social bias, based on prejudice, is ubiquitous, as recent events with AI and large language models (LLMs) have shown. Motivated by this challenge, we set out to estimate bias in multiple datasets. We compare some recent bias metrics and use bipol, which has explainability in the metric. We also confirm the unverified assumption that bias exists in toxic comments by randomly sampling 200 samples from a toxic dataset population using the confidence level of 95% and error margin of 7%. Thirty gold samples were randomly distributed in the 200 samples to secure the quality of the annotation. Our findings confirm that many of the datasets have male bias (prejudice against women), besides other types of bias. We publicly release our new datasets, lexica, models, and codes.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages, 6 figures"
    },
    {
        "paper id": "2404.04871",
        "abstract url": "https://arxiv.org/abs/2404.04871",
        "title": "Data Stream Sampling with Fuzzy Task Boundaries and Noisy Labels",
        "rating": "2",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of continual learning, the presence of noisy labels within data streams represents a notable obstacle to model reliability and fairness. We focus on the data stream scenario outlined in pertinent literature, characterized by fuzzy task boundaries and noisy labels. To address this challenge, we introduce a novel and intuitive sampling method called Noisy Test Debiasing (NTD) to mitigate noisy labels in evolving data streams and establish a fair and robust continual learning algorithm. NTD is straightforward to implement, making it feasible across various scenarios. Our experiments benchmark four datasets, including two synthetic noise datasets (CIFAR10 and CIFAR100) and real-world noise datasets (mini-WebVision and Food-101N). The results validate the efficacy of NTD for online continual learning in scenarios with noisy labels in data streams. Compared to the previous leading approach, NTD achieves a training speedup enhancement over two times while maintaining or surpassing accuracy levels. Moreover, NTD utilizes less than one-fifth of the GPU memory resources compared to previous leading methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04883",
        "abstract url": "https://arxiv.org/abs/2404.04883",
        "title": "Mixture of Low-rank Experts for Transferable AI-Generated Image Detection",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "vision-language"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generative models have shown a giant leap in synthesizing photo-realistic images with minimal expertise, sparking concerns about the authenticity of online information. This study aims to develop a universal AI-generated image detector capable of identifying images from diverse sources. Existing methods struggle to generalize across unseen generative models when provided with limited sample sources. Inspired by the zero-shot transferability of pre-trained vision-language models, we seek to harness the nontrivial visual-world knowledge and descriptive proficiency of CLIP-ViT to generalize over unknown domains. This paper presents a novel parameter-efficient fine-tuning approach, mixture of low-rank experts, to fully exploit CLIP-ViT's potential while preserving knowledge and expanding capacity for transferable detection. We adapt only the MLP layers of deeper ViT blocks via an integration of shared and separate LoRAs within an MoE-based structure. Extensive experiments on public benchmarks show that our method achieves superiority over state-of-the-art approaches in cross-generator generalization and robustness to perturbations. Remarkably, our best-performing ViT-L/14 variant requires training only 0.08% of its parameters to surpass the leading baseline by +3.64% mAP and +12.72% avg.Acc across unseen diffusion and autoregressive models. This even outperforms the baseline with just 0.28% of the training data. Our code and pre-trained models will be available at https://github.com/zhliuworks/CLIPMoLE.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05046",
        "abstract url": "https://arxiv.org/abs/2404.05046",
        "title": "FGAIF: Aligning Large Vision-Language Models with Fine-grained AI Feedback",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs) have demonstrated proficiency in tackling a variety of visual-language tasks. However, current LVLMs suffer from misalignment between text and image modalities which causes three kinds of hallucination problems, i.e., object existence, object attribute, and object relationship. To tackle this issue, existing methods mainly utilize Reinforcement Learning (RL) to align modalities in LVLMs. However, they still suffer from three main limitations: (1) General feedback can not indicate the hallucination type contained in the response; (2) Sparse rewards only give the sequence-level reward for the whole response; and (3)Annotation cost is time-consuming and labor-intensive. To handle these limitations, we propose an innovative method to align modalities in LVLMs through Fine-Grained Artificial Intelligence Feedback (FGAIF), which mainly consists of three steps: AI-based Feedback Collection, Fine-grained Reward Model Training, and Reinforcement Learning with Fine-grained Reward. Specifically, We first utilize AI tools to predict the types of hallucination for each segment in the response and obtain a collection of fine-grained feedback. Then, based on the collected reward data, three specialized reward models are trained to produce dense rewards. Finally, a novel fine-grained feedback module is integrated into the Proximal Policy Optimization (PPO) algorithm. Extensive experiments are conducted on hallucination and general benchmarks, demonstrating the superior performance of our proposed method. Notably, compared with previous models trained with the RL-based aligning method, our proposed method is effective even with fewer parameters.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05182",
        "abstract url": "https://arxiv.org/abs/2404.05182",
        "title": "DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "To enhance the performance of large language models (LLM) on downstream tasks, one solution is to fine-tune certain LLM parameters and make it better align with the characteristics of the training dataset. This process is commonly known as parameter-efficient fine-tuning (PEFT). Due to the scale of LLM, PEFT operations are usually executed in the public environment (e.g., cloud server). This necessitates the sharing of sensitive user data across public environments, thereby raising potential privacy concerns. To tackle these challenges, we propose a distributed PEFT framework called DLoRA. DLoRA enables scalable PEFT operations to be performed collaboratively between the cloud and user devices. Coupled with the proposed Kill and Revive algorithm, the evaluation results demonstrate that DLoRA can significantly reduce the computation and communication workload over the user devices while achieving superior accuracy and privacy protection.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05183",
        "abstract url": "https://arxiv.org/abs/2404.05183",
        "title": "Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset",
        "rating": "2",
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Traditional defect classification approaches are facing with two barriers. (1) Insufficient training data and unstable data quality. Collecting sufficient defective sample is expensive and time-costing, consequently leading to dataset variance. It introduces the difficulty on recognition and learning. (2) Over-dependence on visual modality. When the image pattern and texture is monotonic for all defect classes in a given dataset, the performance of conventional AOI system cannot be guaranteed. In scenarios where image quality is compromised due to mechanical failures or when defect information is inherently difficult to discern, the performance of deep models cannot be guaranteed. A main question is, \"how to solve those two problems when they occur at the same time?\" The feasible strategy is to explore another feature within dataset and combine an eminent vision-language model (VLM) and Large-Language model (LLM) with their astonishing zero-shot capability. In this work, we propose the special ASE dataset, including rich data description recorded on image, for defect classification, but the defect feature is uneasy to learn directly. Secondly, We present the prompting for VLM-LLM against defect classification with the proposed ASE dataset to activate extra-modality feature from images to enhance performance. Then, We design the novel progressive feature alignment (PFA) block to refine image-text feature to alleviate the difficulty of alignment under few-shot scenario. Finally, the proposed Cross-modality attention fusion (CMAF) module can effectively fuse different modality feature. Experiment results have demonstrated our method's effectiveness over several defect classification methods for the ASE dataset.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "MULA 2024"
    },
    {
        "paper id": "2404.04808",
        "abstract url": "https://arxiv.org/abs/2404.04808",
        "title": "MemFlow: Optical Flow Estimation and Prediction with Memory",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Optical flow is a classical task that is important to the vision community. Classical optical flow estimation uses two frames as input, whilst some recent methods consider multiple frames to explicitly model long-range information. The former ones limit their ability to fully leverage temporal coherence along the video sequence; and the latter ones incur heavy computational overhead, typically not possible for real-time flow estimation. Some multi-frame-based approaches even necessitate unseen future frames for current estimation, compromising real-time applicability in safety-critical scenarios. To this end, we present MemFlow, a real-time method for optical flow estimation and prediction with memory. Our method enables memory read-out and update modules for aggregating historical motion information in real-time. Furthermore, we integrate resolution-adaptive re-scaling to accommodate diverse video resolutions. Besides, our approach seamlessly extends to the future prediction of optical flow based on past observations. Leveraging effective historical motion aggregation, our method outperforms VideoFlow with fewer parameters and faster inference speed on Sintel and KITTI-15 datasets in terms of generalization performance. At the time of submission, MemFlow also leads in performance on the 1080p Spring dataset. Codes and models will be available at: https://dqiaole.github.io/MemFlow/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2404.04848",
        "abstract url": "https://arxiv.org/abs/2404.04848",
        "title": "Task-Aware Encoder Control for Deep Video Compression",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Prior research on deep video compression (DVC) for machine tasks typically necessitates training a unique codec for each specific task, mandating a dedicated decoder per task. In contrast, traditional video codecs employ a flexible encoder controller, enabling the adaptation of a single codec to different tasks through mechanisms like mode prediction. Drawing inspiration from this, we introduce an innovative encoder controller for deep video compression for machines. This controller features a mode prediction and a Group of Pictures (GoP) selection module. Our approach centralizes control at the encoding stage, allowing for adaptable encoder adjustments across different tasks, such as detection and tracking, while maintaining compatibility with a standard pre-trained DVC decoder. Empirical evidence demonstrates that our method is applicable across multiple tasks with various existing pre-trained DVCs. Moreover, extensive experiments demonstrate that our method outperforms previous DVC by about 25% bitrate for different tasks, with only one pre-trained decoder.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04865",
        "abstract url": "https://arxiv.org/abs/2404.04865",
        "title": "On the Learnability of Out-of-distribution Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms, and corresponding learning theory is still an open problem. To study the generalization of OOD detection, this paper investigates the probably approximately correct (PAC) learning theory of OOD detection that fits the commonly used evaluation metrics in the literature. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we offer theoretical support for representative OOD detection works based on our OOD theory.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "comment": "Accepted by JMLR in 7th of April, 2024. This is a journal extension of the previous NeurIPS 2022 Outstanding Paper \"Is Out-of-distribution Detection Learnable?\" [arXiv:2210.14707]"
    },
    {
        "paper id": "2404.04996",
        "abstract url": "https://arxiv.org/abs/2404.04996",
        "title": "Fantastic Animals and Where to Find Them: Segment Any Marine Animal with Dual SAM",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "As an important pillar of underwater intelligence, Marine Animal Segmentation (MAS) involves segmenting animals within marine environments. Previous methods don't excel in extracting long-range contextual features and overlook the connectivity between discrete pixels. Recently, Segment Anything Model (SAM) offers a universal framework for general segmentation tasks. Unfortunately, trained with natural images, SAM does not obtain the prior knowledge from marine images. In addition, the single-position prompt of SAM is very insufficient for prior guidance. To address these issues, we propose a novel feature learning framework, named Dual-SAM for high-performance MAS. To this end, we first introduce a dual structure with SAM's paradigm to enhance feature learning of marine images. Then, we propose a Multi-level Coupled Prompt (MCP) strategy to instruct comprehensive underwater prior information, and enhance the multi-level features of SAM's encoder with adapters. Subsequently, we design a Dilated Fusion Attention Module (DFAM) to progressively integrate multi-level features from SAM's encoder. Finally, instead of directly predicting the masks of marine animals, we propose a Criss-Cross Connectivity Prediction (C$^3$P) paradigm to capture the inter-connectivity between discrete pixels. With dual decoders, it generates pseudo-labels and achieves mutual supervision for complementary feature representations, resulting in considerable improvements over previous techniques. Extensive experiments verify that our proposed method achieves state-of-the-art performances on five widely-used MAS datasets. The code is available at https://github.com/Drchip61/Dual_SAM.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted by CVPR2024 as Poster(Highlight)"
    },
    {
        "paper id": "2404.05136",
        "abstract url": "https://arxiv.org/abs/2404.05136",
        "title": "Self-Supervised Multi-Object Tracking with Path Consistency",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In this paper, we propose a novel concept of path consistency to learn robust object matching without using manual object identity supervision. Our key idea is that, to track a object through frames, we can obtain multiple different association results from a model by varying the frames it can observe, i.e., skipping frames in observation. As the differences in observations do not alter the identities of objects, the obtained association results should be consistent. Based on this rationale, we generate multiple observation paths, each specifying a different set of frames to be skipped, and formulate the Path Consistency Loss that enforces the association results are consistent across different observation paths. We use the proposed loss to train our object matching model with only self-supervision. By extensive experiments on three tracking datasets (MOT17, PersonPath22, KITTI), we demonstrate that our method outperforms existing unsupervised methods with consistent margins on various evaluation metrics, and even achieves performance close to supervised methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted at CVPR 2024"
    },
    {
        "paper id": "2404.04809",
        "abstract url": "https://arxiv.org/abs/2404.04809",
        "title": "Low-Resource Machine Translation through Retrieval-Augmented LLM Prompting: A Study on the Mambai Language",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the use of large language models (LLMs) for translating English into Mambai, a low-resource Austronesian language spoken in Timor-Leste, with approximately 200,000 native speakers. Leveraging a novel corpus derived from a Mambai language manual and additional sentences translated by a native speaker, we examine the efficacy of few-shot LLM prompting for machine translation (MT) in this low-resource context. Our methodology involves the strategic selection of parallel sentences and dictionary entries for prompting, aiming to enhance translation accuracy, using open-source and proprietary LLMs (LlaMa 2 70b, Mixtral 8x7B, GPT-4). We find that including dictionary entries in prompts and a mix of sentences retrieved through TF-IDF and semantic embeddings significantly improves translation quality. However, our findings reveal stark disparities in translation performance across test sets, with BLEU scores reaching as high as 21.2 on materials from the language manual, in contrast to a maximum of 4.4 on a test set provided by a native speaker. These results underscore the importance of diverse and representative corpora in assessing MT for low-resource languages. Our research provides insights into few-shot LLM prompting for low-resource MT, and makes available an initial corpus for the Mambai language.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04817",
        "abstract url": "https://arxiv.org/abs/2404.04817",
        "title": "FRACTAL: Fine-Grained Scoring from Aggregate Text Labels",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are being increasingly tuned to power complex generation tasks such as writing, fact-seeking, querying and reasoning. Traditionally, human or model feedback for evaluating and further tuning LLM performance has been provided at the response level, enabling faster and more cost-effective assessments. However, recent works (Amplayo et al. [2022], Wu et al. [2023]) indicate that sentence-level labels may provide more accurate and interpretable feedback for LLM optimization. In this work, we introduce methods to disaggregate response-level labels into sentence-level (pseudo-)labels. Our approach leverages multiple instance learning (MIL) and learning from label proportions (LLP) techniques in conjunction with prior information (e.g., document-sentence cosine similarity) to train a specialized model for sentence-level scoring. We also employ techniques which use model predictions to pseudo-label the train-set at the sentence-level for model training to further improve performance. We conduct extensive evaluations of our methods across six datasets and four tasks: retrieval, question answering, summarization, and math reasoning. Our results demonstrate improved performance compared to multiple baselines across most of these tasks. Our work is the first to develop response-level feedback to sentence-level scoring techniques, leveraging sentence-level prior information, along with comprehensive evaluations on multiple tasks as well as end-to-end finetuning evaluation showing performance comparable to a model trained on fine-grained human annotated labels.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "22 pages, 1 figure"
    },
    {
        "paper id": "2404.04845",
        "abstract url": "https://arxiv.org/abs/2404.04845",
        "title": "SLPL SHROOM at SemEval2024 Task 06: A comprehensive study on models ability to detect hallucination",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Language models, particularly generative models, are susceptible to hallucinations, generating outputs that contradict factual knowledge or the source text. This study explores methods for detecting hallucinations in three SemEval-2024 Task 6 tasks: Machine Translation, Definition Modeling, and Paraphrase Generation. We evaluate two methods: semantic similarity between the generated text and factual references, and an ensemble of language models that judge each other's outputs. Our results show that semantic similarity achieves moderate accuracy and correlation scores in trial data, while the ensemble method offers insights into the complexities of hallucination detection but falls short of expectations. This work highlights the challenges of hallucination detection and underscores the need for further research in this critical area.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04846",
        "abstract url": "https://arxiv.org/abs/2404.04846",
        "title": "F-MALLOC: Feed-forward Memory Allocation for Continual Learning in Neural Machine Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the evolving landscape of Neural Machine Translation (NMT), the pretrain-then-finetune paradigm has yielded impressive results. However, the persistent challenge of Catastrophic Forgetting (CF) remains a hurdle. While previous work has introduced Continual Learning (CL) methods to address CF, these approaches grapple with the delicate balance between avoiding forgetting and maintaining system extensibility. To address this, we propose a CL method, named $\\textbf{F-MALLOC}$ ($\\textbf{F}$eed-forward $\\textbf{M}$emory $\\textbf{ALLOC}ation)$. F-MALLOC is inspired by recent insights highlighting that feed-forward layers emulate neural memories and encapsulate crucial translation knowledge. It decomposes feed-forward layers into discrete memory cells and allocates these memories to different tasks. By learning to allocate and safeguard these memories, our method effectively alleviates CF while ensuring robust extendability. Besides, we propose a comprehensive assessment protocol for multi-stage CL of NMT systems. Experiments conducted following this new protocol showcase the superior performance of F-MALLOC, evidenced by higher BLEU scores and almost zero forgetting.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to the main conference of NAACL 2024"
    },
    {
        "paper id": "2404.04850",
        "abstract url": "https://arxiv.org/abs/2404.04850",
        "title": "Lucky 52: How Many Languages Are Needed to Instruction Fine-Tune Large Language Models?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Fine-tuning large language models for multilingual downstream tasks requires a diverse set of languages to capture the nuances and structures of different linguistic contexts effectively. While the specific number varies depending on the desired scope and target languages, we argue that the number of languages, language exposure, and similarity that incorporate the selection of languages for fine-tuning are some important aspects to examine. By fine-tuning large multilingual models on 1 to 52 languages, this paper answers one question: How many languages are needed in instruction fine-tuning for multilingual tasks? We investigate how multilingual instruction fine-tuned models behave on multilingual benchmarks with an increasing number of languages and discuss our findings from the perspective of language exposure and similarity.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04856",
        "abstract url": "https://arxiv.org/abs/2404.04856",
        "title": "Msmsfnet: a multi-stream and multi-scale fusion net for edge detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Edge detection is a long standing problem in computer vision. Recent deep learning based algorithms achieve state of-the-art performance in publicly available datasets. Despite the efficiency of these algorithms, their performance, however, relies heavily on the pretrained weights of the backbone network on the ImageNet dataset. This limits heavily the design space of deep learning based edge detectors. Whenever we want to devise a new model, we have to train this new model on the ImageNet dataset first, and then fine tune the model using the edge detection datasets. The comparison would be unfair otherwise. However, it is usually not feasible for many researchers to train a model on the ImageNet dataset due to the limited computation resources. In this work, we study the performance that can be achieved by state-of-the-art deep learning based edge detectors in publicly available datasets when they are trained from scratch, and devise a new network architecture, the multi-stream and multi scale fusion net (msmsfnet), for edge detection. We show in our experiments that by training all models from scratch to ensure the fairness of comparison, out model outperforms state-of-the art deep learning based edge detectors in three publicly available datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04889",
        "abstract url": "https://arxiv.org/abs/2404.04889",
        "title": "Ethos and Pathos in Online Group Discussions: Corpora for Polarisation Issues in Social Media",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Growing polarisation in society caught the attention of the scientific community as well as news media, which devote special issues to this phenomenon. At the same time, digitalisation of social interactions requires to revise concepts from social science regarding establishment of trust, which is a key feature of all human interactions, and group polarisation, as well as new computational tools to process large quantities of available data. Existing methods seem insufficient to tackle the problem fully, thus, we propose to approach the problem by investigating rhetorical strategies employed by individuals in polarising discussions online. To this end, we develop multi-topic and multi-platform corpora with manual annotation of appeals to ethos and pathos, two modes of persuasion in Aristotelian rhetoric. It can be employed for training language models to advance the study of communication strategies online on a large scale. With the use of computational methods, our corpora allows an investigation of recurring patterns in polarising exchanges across topics of discussion and media platforms, and conduct both quantitative and qualitative analyses of language structures leading to and engaged in polarisation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04891",
        "abstract url": "https://arxiv.org/abs/2404.04891",
        "title": "DL-EWF: Deep Learning Empowering Women's Fashion with Grounded-Segment-Anything Segmentation for Body Shape Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The global fashion industry plays a pivotal role in the global economy, and addressing fundamental issues within the industry is crucial for developing innovative solutions. One of the most pressing challenges in the fashion industry is the mismatch between body shapes and the garments of individuals they purchase. This issue is particularly prevalent among individuals with non-ideal body shapes, exacerbating the challenges faced. Considering inter-individual variability in body shapes is essential for designing and producing garments that are widely accepted by consumers. Traditional methods for determining human body shape are limited due to their low accuracy, high costs, and time-consuming nature. New approaches, utilizing digital imaging and deep neural networks (DNN), have been introduced to identify human body shape. In this study, the Style4BodyShape dataset is used for classifying body shapes into five categories: Rectangle, Triangle, Inverted Triangle, Hourglass, and Apple. In this paper, the body shape segmentation of a person is extracted from the image, disregarding the surroundings and background. Then, Various pre-trained models, such as ResNet18, ResNet34, ResNet50, VGG16, VGG19, and Inception v3, are used to classify the segmentation results. Among these pre-trained models, the Inception V3 model demonstrates superior performance regarding f1-score evaluation metric and accuracy compared to the other models.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04925",
        "abstract url": "https://arxiv.org/abs/2404.04925",
        "title": "Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multilingual Large Language Models are capable of using powerful Large Language Models to handle and respond to queries in multiple languages, which achieves remarkable success in multilingual natural language processing tasks. Despite these breakthroughs, there still remains a lack of a comprehensive survey to summarize existing approaches and recent developments in this field. To this end, in this paper, we present a thorough review and provide a unified perspective to summarize the recent progress as well as emerging trends in multilingual large language models (MLLMs) literature. The contributions of this paper can be summarized: (1) First survey: to our knowledge, we take the first step and present a thorough review in MLLMs research field according to multi-lingual alignment; (2) New taxonomy: we offer a new and unified perspective to summarize the current progress of MLLMs; (3) New frontiers: we highlight several emerging frontiers and discuss the corresponding challenges; (4) Abundant resources: we collect abundant open-source resources, including relevant papers, data corpora, and leaderboards. We hope our work can provide the community with quick access and spur breakthrough research in MLLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04932",
        "abstract url": "https://arxiv.org/abs/2404.04932",
        "title": "Towards Understanding the Influence of Reward Margin on Preference Model Performance",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely used framework for the training of language models. However, the process of using RLHF to develop a language model that is well-aligned presents challenges, especially when it comes to optimizing the reward model. Our research has found that existing reward models, when trained using the traditional ranking objective based on human preference data, often struggle to effectively distinguish between responses that are more or less favorable in real-world scenarios. To bridge this gap, our study introduces a novel method to estimate the preference differences without the need for detailed, exhaustive labels from human annotators. Our experimental results provide empirical evidence that incorporating margin values into the training process significantly improves the effectiveness of reward models. This comparative analysis not only demonstrates the superiority of our approach in terms of reward prediction accuracy but also highlights its effectiveness in practical applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04933",
        "abstract url": "https://arxiv.org/abs/2404.04933",
        "title": "UniMD: Towards Unifying Moment Retrieval and Temporal Action Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Temporal Action Detection (TAD) focuses on detecting pre-defined actions, while Moment Retrieval (MR) aims to identify the events described by open-ended natural language within untrimmed videos. Despite that they focus on different events, we observe they have a significant connection. For instance, most descriptions in MR involve multiple actions from TAD. In this paper, we aim to investigate the potential synergy between TAD and MR. Firstly, we propose a unified architecture, termed Unified Moment Detection (UniMD), for both TAD and MR. It transforms the inputs of the two tasks, namely actions for TAD or events for MR, into a common embedding space, and utilizes two novel query-dependent decoders to generate a uniform output of classification score and temporal segments. Secondly, we explore the efficacy of two task fusion learning approaches, pre-training and co-training, in order to enhance the mutual benefits between TAD and MR. Extensive experiments demonstrate that the proposed task fusion learning scheme enables the two tasks to help each other and outperform the separately trained counterparts. Impressively, UniMD achieves state-of-the-art results on three paired datasets Ego4D, Charades-STA, and ActivityNet. Our code will be released at https://github.com/yingsen1/UniMD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Tech report"
    },
    {
        "paper id": "2404.04941",
        "abstract url": "https://arxiv.org/abs/2404.04941",
        "title": "Prompting Large Language Models for Zero-shot Essay Scoring via Multi-trait Specialization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Advances in automated essay scoring (AES) have traditionally relied on labeled essays, requiring tremendous cost and expertise for their acquisition. Recently, large language models (LLMs) have achieved great success in various tasks, but their potential is less explored in AES. In this paper, we propose Multi Trait Specialization (MTS), a zero-shot prompting framework to elicit essay scoring capabilities in LLMs. Specifically, we leverage ChatGPT to decompose writing proficiency into distinct traits and generate scoring criteria for each trait. Then, an LLM is prompted to extract trait scores from several conversational rounds, each round scoring one of the traits based on the scoring criteria. Finally, we derive the overall score via trait averaging and min-max scaling. Experimental results on two benchmark datasets demonstrate that MTS consistently outperforms straightforward prompting (Vanilla) in average QWK across all LLMs and datasets, with maximum gains of 0.437 on TOEFL11 and 0.355 on ASAP. Additionally, with the help of MTS, the small-sized Llama2-13b-chat substantially outperforms ChatGPT, facilitating an effective deployment in real applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04949",
        "abstract url": "https://arxiv.org/abs/2404.04949",
        "title": "SilverSight: A Multi-Task Chinese Financial Large Language Model Based on Adaptive Semantic Space Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are increasingly being applied across various specialized fields, leveraging their extensive knowledge to empower a multitude of scenarios within these domains. However, each field encompasses a variety of specific tasks that require learning, and the diverse, heterogeneous data across these domains can lead to conflicts during model task transfer. In response to this challenge, our study introduces an Adaptive Semantic Space Learning (ASSL) framework, which utilizes the adaptive reorganization of data distributions within the semantic space to enhance the performance and selection efficacy of multi-expert models. Utilizing this framework, we trained a financial multi-task LLM named \"SilverSight\". Our research findings demonstrate that our framework can achieve results close to those obtained with full data training using only 10% of the data, while also exhibiting strong generalization capabilities.",
        "subjects": [
            "cs.CL",
            "cs.CE"
        ],
        "comment": "17 pages, 17 figures"
    },
    {
        "paper id": "2404.04953",
        "abstract url": "https://arxiv.org/abs/2404.04953",
        "title": "High-Discriminative Attribute Feature Learning for Generalized Zero-Shot Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-shot learning(ZSL) aims to recognize new classes without prior exposure to their samples, relying on semantic knowledge from observed classes. However, current attention-based models may overlook the transferability of visual features and the distinctiveness of attribute localization when learning regional features in images. Additionally, they often overlook shared attributes among different objects. Highly discriminative attribute features are crucial for identifying and distinguishing unseen classes. To address these issues, we propose an innovative approach called High-Discriminative Attribute Feature Learning for Generalized Zero-Shot Learning (HDAFL). HDAFL optimizes visual features by learning attribute features to obtain discriminative visual embeddings. Specifically, HDAFL utilizes multiple convolutional kernels to automatically learn discriminative regions highly correlated with attributes in images, eliminating irrelevant interference in image features. Furthermore, we introduce a Transformer-based attribute discrimination encoder to enhance the discriminative capability among attributes. Simultaneously, the method employs contrastive loss to alleviate dataset biases and enhance the transferability of visual features, facilitating better semantic transfer between seen and unseen classes. Experimental results demonstrate the effectiveness of HDAFL across three widely used datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04959",
        "abstract url": "https://arxiv.org/abs/2404.04959",
        "title": "A Two Dimensional Feature Engineering Method for Relation Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Transforming a sentence into a two-dimensional (2D) representation (e.g., the table filling) has the ability to unfold a semantic plane, where an element of the plane is a word-pair representation of a sentence which may denote a possible relation representation composed of two named entities. The 2D representation is effective in resolving overlapped relation instances. However, in related works, the representation is directly transformed from a raw input. It is weak to utilize prior knowledge, which is important to support the relation extraction task. In this paper, we propose a two-dimensional feature engineering method in the 2D sentence representation for relation extraction. Our proposed method is evaluated on three public datasets (ACE05 Chinese, ACE05 English, and SanWen) and achieves the state-of-the-art performance. The results indicate that two-dimensional feature engineering can take advantage of a two-dimensional sentence representation and make full use of prior knowledge in traditional feature engineering. Our code is publicly available at https://github.com/Wang-ck123/A-Two-Dimensional-Feature-Engineering-Method-for-Entity-Relation-Extraction",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05003",
        "abstract url": "https://arxiv.org/abs/2404.05003",
        "title": "Camera-Based Remote Physiology Sensing for Hundreds of Subjects Across Skin Tones",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Remote photoplethysmography (rPPG) emerges as a promising method for non-invasive, convenient measurement of vital signs, utilizing the widespread presence of cameras. Despite advancements, existing datasets fall short in terms of size and diversity, limiting comprehensive evaluation under diverse conditions. This paper presents an in-depth analysis of the VitalVideo dataset, the largest real-world rPPG dataset to date, encompassing 893 subjects and 6 Fitzpatrick skin tones. Our experimentation with six unsupervised methods and three supervised models demonstrates that datasets comprising a few hundred subjects(i.e., 300 for UBFC-rPPG, 500 for PURE, and 700 for MMPD-Simple) are sufficient for effective rPPG model training. Our findings highlight the importance of diversity and consistency in skin tones for precise performance evaluation across different datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "11 pages, 5 figures, CHI24 Workshop PhysioCHI"
    },
    {
        "paper id": "2404.05019",
        "abstract url": "https://arxiv.org/abs/2404.05019",
        "title": "Shortcut-connected Expert Parallelism for Accelerating Mixture-of-Experts",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Expert parallelism has been introduced as a strategy to distribute the computational workload of sparsely-gated mixture-of-experts (MoE) models across multiple computing devices, facilitating the execution of these increasingly large-scale models. However, the All-to-All communication intrinsic to expert parallelism constitutes a significant overhead, diminishing the MoE models' efficiency. Current optimization approaches offer some relief, yet they are constrained by the sequential interdependence of communication and computation operations. To address this limitation, we present a novel shortcut-connected MoE architecture with overlapping parallel strategy, designated as ScMoE, which effectively decouples communication from its conventional sequence, allowing for a substantial overlap of 70% to 100% with computation. When compared with the prevalent top-2 MoE architecture, ScMoE demonstrates training speed improvements of 30% and 11%, and inference improvements of 40% and 15%, in our PCIe and NVLink hardware environments, respectively, where communication constitutes 60% and 15% of the total MoE time consumption. On the other hand, extensive experiments and theoretical analyses indicate that ScMoE not only achieves comparable but in some instances surpasses the model quality of existing approaches in vision and language tasks.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05023",
        "abstract url": "https://arxiv.org/abs/2404.05023",
        "title": "Scalable and Efficient Hierarchical Visual Topological Mapping",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Hierarchical topological representations can significantly reduce search times within mapping and localization algorithms. Although recent research has shown the potential for such approaches, limited consideration has been given to the suitability and comparative performance of different global feature representations within this context. In this work, we evaluate state-of-the-art hand-crafted and learned global descriptors using a hierarchical topological mapping technique on benchmark datasets and present results of a comprehensive evaluation of the impact of the global descriptor used. Although learned descriptors have been incorporated into place recognition methods to improve retrieval accuracy and enhance overall recall, the problem of scalability and efficiency when applied to longer trajectories has not been adequately addressed in a majority of research studies. Based on our empirical analysis of multiple runs, we identify that continuity and distinctiveness are crucial characteristics for an optimal global descriptor that enable efficient and scalable hierarchical mapping, and present a methodology for quantifying and contrasting these characteristics across different global descriptors. Our study demonstrates that the use of global descriptors based on an unsupervised learned Variational Autoencoder (VAE) excels in these characteristics and achieves significantly lower runtime. It runs on a consumer grade desktop, up to 2.3x faster than the second best global descriptor, NetVLAD, and up to 9.5x faster than the hand-crafted descriptor, PHOG, on the longest track evaluated (St Lucia, 17.6 km), without sacrificing overall recall performance.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Published in the 21st International Conference on Advanced Robotics (ICAR 2023)"
    },
    {
        "paper id": "2404.05071",
        "abstract url": "https://arxiv.org/abs/2404.05071",
        "title": "Test-Time Training for Depression Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Previous works on depression detection use datasets collected in similar environments to train and test the models. In practice, however, the train and test distributions cannot be guaranteed to be identical. Distribution shifts can be introduced due to variations such as recording environment (e.g., background noise) and demographics (e.g., gender, age, etc). Such distributional shifts can surprisingly lead to severe performance degradation of the depression detection models. In this paper, we analyze the application of test-time training (TTT) to improve robustness of models trained for depression detection. When compared to regular testing of the models, we find TTT can significantly improve the robustness of the model under a variety of distributional shifts introduced due to: (a) background-noise, (b) gender-bias, and (c) data collection and curation procedure (i.e., train and test samples are from separate datasets).",
        "subjects": [
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05083",
        "abstract url": "https://arxiv.org/abs/2404.05083",
        "title": "HaVTR: Improving Video-Text Retrieval Through Augmentation Using Large Foundation Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "While recent progress in video-text retrieval has been driven by the exploration of powerful model architectures and training strategies, the representation learning ability of video-text retrieval models is still limited due to low-quality and scarce training data annotations. To address this issue, we present a novel video-text learning paradigm, HaVTR, which augments video and text data to learn more generalized features. Specifically, we first adopt a simple augmentation method, which generates self-similar data by randomly duplicating or dropping subwords and frames. In addition, inspired by the recent advancement in visual and language generative models, we propose a more powerful augmentation method through textual paraphrasing and video stylization using large language models (LLMs) and visual generative models (VGMs). Further, to bring richer information into video and text, we propose a hallucination-based augmentation method, where we use LLMs and VGMs to generate and add new relevant information to the original data. Benefiting from the enriched data, extensive experiments on several video-text retrieval benchmarks demonstrate the superiority of HaVTR over existing methods.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05086",
        "abstract url": "https://arxiv.org/abs/2404.05086",
        "title": "A Note on LoRA",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "LoRA (Low-Rank Adaptation) has emerged as a preferred method for efficiently adapting Large Language Models (LLMs) with remarkable simplicity and efficacy. This note extends the original LoRA paper by offering new perspectives that were not initially discussed and presents a series of insights for deploying LoRA at scale. Without introducing new experiments, we aim to improve the understanding and application of LoRA.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05089",
        "abstract url": "https://arxiv.org/abs/2404.05089",
        "title": "SEER-MoE: Sparse Expert Efficiency through Regularization for Mixture-of-Experts",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The advancement of deep learning has led to the emergence of Mixture-of-Experts (MoEs) models, known for their dynamic allocation of computational resources based on input. Despite their promise, MoEs face challenges, particularly in terms of memory requirements. To address this, our work introduces SEER-MoE, a novel two-stage framework for reducing both the memory footprint and compute requirements of pre-trained MoE models. The first stage involves pruning the total number of experts using a heavy-hitters counting guidance, while the second stage employs a regularization-based fine-tuning strategy to recover accuracy loss and reduce the number of activated experts during inference. Our empirical studies demonstrate the effectiveness of our method, resulting in a sparse MoEs model optimized for inference efficiency with minimal accuracy trade-offs.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "8+3 pages"
    },
    {
        "paper id": "2404.05090",
        "abstract url": "https://arxiv.org/abs/2404.05090",
        "title": "How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The phenomenon of model collapse, introduced in (Shumailov et al., 2023), refers to the deterioration in performance that occurs when new models are trained on synthetic data generated from previously trained models. This recursive training loop makes the tails of the original distribution disappear, thereby making future-generation models forget about the initial (real) distribution. With the aim of rigorously understanding model collapse in language models, we consider in this paper a statistical model that allows us to characterize the impact of various recursive training scenarios. Specifically, we demonstrate that model collapse cannot be avoided when training solely on synthetic data. However, when mixing both real and synthetic data, we provide an estimate of a maximal amount of synthetic data below which model collapse can eventually be avoided. Our theoretical conclusions are further supported by empirical validations.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05091",
        "abstract url": "https://arxiv.org/abs/2404.05091",
        "title": "Advancing Geometric Problem Solving: A Comprehensive Benchmark for Multimodal Model Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we present the MM-MATH dataset, a novel benchmark developed to rigorously evaluate the performance of advanced large language and multimodal models - including but not limited to GPT-4, GPT-4V, and Claude - within the domain of geometric computation. This dataset comprises 5,929 meticulously crafted geometric problems, each paired with a corresponding image, aimed at mirroring the complexity and requirements typical of ninth-grade mathematics. The motivation behind MM-MATH stems from the burgeoning interest and significant strides in multimodal technology, which necessitates a paradigm shift in assessment methodologies from mere outcome analysis to a more holistic evaluation encompassing reasoning and procedural correctness. Despite impressive gains in various benchmark performances, our analysis uncovers a persistent and notable deficiency in these models' ability to parse and interpret geometric information accurately from images, accounting for over 60% of observed errors. By deploying a dual-focused evaluation approach, examining both the end results and the underlying problem-solving processes, we unearthed a marked discrepancy between the capabilities of current multimodal models and human-level proficiency. The introduction of MM-MATH represents a tripartite contribution to the field: it not only serves as a comprehensive and challenging benchmark for assessing geometric problem-solving prowess but also illuminates critical gaps in textual and visual comprehension that current models exhibit. Through this endeavor, we aspire to catalyze further research and development aimed at bridging these gaps, thereby advancing the state of multimodal model capabilities to new heights.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05111",
        "abstract url": "https://arxiv.org/abs/2404.05111",
        "title": "Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In Generalized Few-shot Segmentation (GFSS), a model is trained with a large corpus of base class samples and then adapted on limited samples of novel classes. This paper focuses on the relevance between base and novel classes, and improves GFSS in two aspects: 1) mining the similarity between base and novel classes to promote the learning of novel classes, and 2) mitigating the class imbalance issue caused by the volume difference between the support set and the training set. Specifically, we first propose a similarity transition matrix to guide the learning of novel classes with base class knowledge. Then, we leverage the Label-Distribution-Aware Margin (LDAM) loss and Transductive Inference to the GFSS task to address the problem of class imbalance as well as overfitting the support set. In addition, by extending the probability transition matrix, the proposed method can mitigate the catastrophic forgetting of base classes when learning novel classes. With a simple training phase, our proposed method can be applied to any segmentation network trained on base classes. We validated our methods on the adapted version of OpenEarthMap. Compared to existing GFSS baselines, our method excels them all from 3% to 7% and ranks second in the OpenEarthMap Land Cover Mapping Few-Shot Challenge at the completion of this paper. Code: https://github.com/earth-insights/ClassTrans",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2404.05128",
        "abstract url": "https://arxiv.org/abs/2404.05128",
        "title": "Improving Deep Learning Predictions with Simulated Images, and Vice Versa",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Artificial neural networks are often used to identify features of crop plants. However, training their models requires many annotated images, which can be expensive and time-consuming to acquire. Procedural models of plants, such as those developed with Lindenmayer-systems (L-systems) can be created to produce visually realistic simulations, and hence images of plant simulations, where annotations are implicitly known. These synthetic images can either augment or completely replace real images in training neural networks for phenotyping tasks. In this paper, we systematically vary amounts of real and synthetic images used for training in both maize and canola to better understand situations where synthetic images generated from L-systems can help prediction on real images. This work also explores the degree to which realism in the synthetic images improves prediction. Furthermore, we see how neural network predictions can be used to help calibrate L-systems themselves, creating a feedback loop.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05129",
        "abstract url": "https://arxiv.org/abs/2404.05129",
        "title": "Image-based Agarwood Resinous Area Segmentation using Deep Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The manual extraction method of Agarwood resinous compound is laborious work, requires skilled workers, and is subject to human errors. Commercial Agarwood industries have been actively exploring using Computer Numerical Control (CNC) machines to replace human effort for this particular task. The CNC machine accepts a G-code script produced from a binary image in which the wood region that needs to be chiselled off is marked with (0, 0, 0) as its RGB value. Rather than requiring a human expert to perform the region marking, we propose using a Deep learning image segmentation method instead. Our setup involves a camera that captures the cross-section image and then passes the image file to a computer. The computer performs the automated image segmentation and feeds the CNC machine with a G-code script. In this article, we report the initial segmentation results achieved using a state-of-the-art Deep learning segmentation method and discuss potential improvements to refine the segmentation accuracy.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages, 6 figures, 3 tables"
    },
    {
        "paper id": "2404.05133",
        "abstract url": "https://arxiv.org/abs/2404.05133",
        "title": "EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Anthropogenic ecological crisis constitutes a significant challenge that all within the academy must urgently face, including the Natural Language Processing (NLP) community. While recent years have seen increasing work revolving around climate-centric discourse, crucial environmental and ecological topics outside of climate change remain largely unaddressed, despite their prominent importance. Mainstream NLP tasks, such as sentiment analysis, dominate the scene, but there remains an untouched space in the literature involving the analysis of environmental impacts of certain events and practices. To address this gap, this paper presents EcoVerse, an annotated English Twitter dataset of 3,023 tweets spanning a wide spectrum of environmental topics. We propose a three-level annotation scheme designed for Eco-Relevance Classification, Stance Detection, and introducing an original approach for Environmental Impact Analysis. We detail the data collection, filtering, and labeling process that led to the creation of the dataset. Remarkable Inter-Annotator Agreement indicates that the annotation scheme produces consistent annotations of high quality. Subsequent classification experiments using BERT-based models, including ClimateBERT, are presented. These yield encouraging results, while also indicating room for a model specifically tailored for environmental texts. The dataset is made freely available to stimulate further research.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05196",
        "abstract url": "https://arxiv.org/abs/2404.05196",
        "title": "HSViT: Horizontally Scalable Vision Transformer",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "While the Vision Transformer (ViT) architecture gains prominence in computer vision and attracts significant attention from multimedia communities, its deficiency in prior knowledge (inductive bias) regarding shift, scale, and rotational invariance necessitates pre-training on large-scale datasets. Furthermore, the growing layers and parameters in both ViT and convolutional neural networks (CNNs) impede their applicability to mobile multimedia services, primarily owing to the constrained computational resources on edge devices. To mitigate the aforementioned challenges, this paper introduces a novel horizontally scalable vision transformer (HSViT). Specifically, a novel image-level feature embedding allows ViT to better leverage the inductive bias inherent in the convolutional layers. Based on this, an innovative horizontally scalable architecture is designed, which reduces the number of layers and parameters of the models while facilitating collaborative training and inference of ViT models across multiple nodes. The experimental results depict that, without pre-training on large-scale datasets, HSViT achieves up to 10% higher top-1 accuracy than state-of-the-art schemes, ascertaining its superior preservation of inductive bias. The code is available at https://github.com/xuchenhao001/HSViT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.06332",
        "abstract url": "https://arxiv.org/abs/2404.06332",
        "title": "X-VARS: Introducing Explainability in Football Refereeing with Multi-Modal Large Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement of artificial intelligence has led to significant improvements in automated decision-making. However, the increased performance of models often comes at the cost of explainability and transparency of their decision-making processes. In this paper, we investigate the capabilities of large language models to explain decisions, using football refereeing as a testing ground, given its decision complexity and subjectivity. We introduce the Explainable Video Assistant Referee System, X-VARS, a multi-modal large language model designed for understanding football videos from the point of view of a referee. X-VARS can perform a multitude of tasks, including video description, question answering, action recognition, and conducting meaningful conversations based on video content and in accordance with the Laws of the Game for football referees. We validate X-VARS on our novel dataset, SoccerNet-XFoul, which consists of more than 22k video-question-answer triplets annotated by over 70 experienced football referees. Our experiments and human study illustrate the impressive capabilities of X-VARS in interpreting complex football clips. Furthermore, we highlight the potential of X-VARS to reach human performance and support football referees in the future.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.08679",
        "abstract url": "https://arxiv.org/abs/2404.08679",
        "title": "Your Finetuned Large Language Model is Already a Powerful Out-of-distribution Detector",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We revisit the likelihood ratio between a pretrained large language model (LLM) and its finetuned variant as a criterion for out-of-distribution (OOD) detection. The intuition behind such a criterion is that, the pretrained LLM has the prior knowledge about OOD data due to its large amount of training data, and once finetuned with the in-distribution data, the LLM has sufficient knowledge to distinguish their difference. Leveraging the power of LLMs, we show that, for the first time, the likelihood ratio can serve as an effective OOD detector. Moreover, we apply the proposed LLM-based likelihood ratio to detect OOD questions in question-answering (QA) systems, which can be used to improve the performance of specialized LLMs for general questions. Given that likelihood can be easily obtained by the loss functions within contemporary neural network frameworks, it is straightforward to implement this approach in practice. Since both the pretrained LLMs and its various finetuned models are available, our proposed criterion can be effortlessly incorporated for OOD detection without the need for further training. We conduct comprehensive evaluation across on multiple settings, including far OOD, near OOD, spam detection, and QA scenarios, to demonstrate the effectiveness of the method.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.08680",
        "abstract url": "https://arxiv.org/abs/2404.08680",
        "title": "Automating Research Synthesis with Domain-Specific Large Language Model Fine-Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This research pioneers the use of fine-tuned Large Language Models (LLMs) to automate Systematic Literature Reviews (SLRs), presenting a significant and novel contribution in integrating AI to enhance academic research methodologies. Our study employed the latest fine-tuning methodologies together with open-sourced LLMs, and demonstrated a practical and efficient approach to automating the final execution stages of an SLR process that involves knowledge synthesis. The results maintained high fidelity in factual accuracy in LLM responses, and were validated through the replication of an existing PRISMA-conforming SLR. Our research proposed solutions for mitigating LLM hallucination and proposed mechanisms for tracking LLM responses to their sources of information, thus demonstrating how this approach can meet the rigorous demands of scholarly research. The findings ultimately confirmed the potential of fine-tuned LLMs in streamlining various labor-intensive processes of conducting literature reviews. Given the potential of this approach and its applicability across all research domains, this foundational study also advocated for updating PRISMA reporting guidelines to incorporate AI-driven processes, ensuring methodological transparency and reliability in future SLRs. This study broadens the appeal of AI-enhanced tools across various academic and research fields, setting a new standard for conducting comprehensive and accurate literature reviews with more efficiency in the face of ever-increasing volumes of academic studies.",
        "subjects": [
            "cs.CL",
            "cs.DL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02314",
        "abstract url": "https://arxiv.org/abs/2405.02314",
        "title": "A geometric framework for interstellar discourse on fundamental physical structures",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper considers the possibility that abstract thinking and advanced synthesis skills might encourage extraterrestrial civilizations to accept communication with mankind on Earth. For this purpose, a notation not relying upon the use of alphabet and numbers is proposed, in order to denote just some basic geometric structures of current physical theories: vector fields, one-form fields, and tensor fields of arbitrary order. An advanced civilization might appreciate the way here proposed to achieve a concise description of electromagnetism and general relativity, and hence it might accept the challenge of responding to our signals. The abstract symbols introduced in this paper to describe the basic structures of physical theories are encoded into black and white bitmap images that can be easily converted into short bit sequences and modulated on a carrier wave for radio transmission.",
        "subjects": [
            "cs.IT",
            "cs.CL"
        ],
        "comment": "15 pages, 2 figures"
    },
    {
        "paper id": "2404.04815",
        "abstract url": "https://arxiv.org/abs/2404.04815",
        "title": "Allo: A Programming Model for Composable Accelerator Design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Special-purpose hardware accelerators are increasingly pivotal for sustaining performance improvements in emerging applications, especially as the benefits of technology scaling continue to diminish. However, designers currently lack effective tools and methodologies to construct complex, high-performance accelerator architectures in a productive manner. Existing high-level synthesis (HLS) tools often require intrusive source-level changes to attain satisfactory quality of results. Despite the introduction of several new accelerator design languages (ADLs) aiming to enhance or replace HLS, their advantages are more evident in relatively simple applications with a single kernel. Existing ADLs prove less effective for realistic hierarchical designs with multiple kernels, even if the design hierarchy is flattened. In this paper, we introduce Allo, a composable programming model for efficient spatial accelerator design. Allo decouples hardware customizations, including compute, memory, communication, and data type from algorithm specification, and encapsulates them as a set of customization primitives. Allo preserves the hierarchical structure of an input program by combining customizations from different functions in a bottom-up, type-safe manner. This approach facilitates holistic optimizations that span across function boundaries. We conduct comprehensive experiments on commonly-used HLS benchmarks and several realistic deep learning models. Our evaluation shows that Allo can outperform state-of-the-art HLS tools and ADLs on all test cases in the PolyBench. For the GPT2 model, the inference latency of the Allo generated accelerator is 1.7x faster than the NVIDIA A100 GPU with 5.4x higher energy efficiency, demonstrating the capability of Allo to handle large-scale designs.",
        "subjects": [
            "cs.PL",
            "cs.AR",
            "cs.LG"
        ],
        "comment": "Accepted to PLDI'24"
    },
    {
        "paper id": "2404.04819",
        "abstract url": "https://arxiv.org/abs/2404.04819",
        "title": "Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Human-object contact serves as a strong cue to understand how humans physically interact with objects. Nevertheless, it is not widely explored to utilize human-object contact information for the joint reconstruction of 3D human and object from a single image. In this work, we present a novel joint 3D human-object reconstruction method (CONTHO) that effectively exploits contact information between humans and objects. There are two core designs in our system: 1) 3D-guided contact estimation and 2) contact-based 3D human and object refinement. First, for accurate human-object contact estimation, CONTHO initially reconstructs 3D humans and objects and utilizes them as explicit 3D guidance for contact estimation. Second, to refine the initial reconstructions of 3D human and object, we propose a novel contact-based refinement Transformer that effectively aggregates human features and object features based on the estimated human-object contact. The proposed contact-based refinement prevents the learning of erroneous correlation between human and object, which enables accurate 3D reconstruction. As a result, our CONTHO achieves state-of-the-art performance in both human-object contact estimation and joint reconstruction of 3D human and object. The code is publicly available at https://github.com/dqj5182/CONTHO_RELEASE.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published at CVPR 2024, 19 pages including the supplementary material"
    },
    {
        "paper id": "2404.04821",
        "abstract url": "https://arxiv.org/abs/2404.04821",
        "title": "A Data-to-Product Multimodal Conceptual Framework to Achieve Automated Software Evolution for Context-rich Intelligent Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "While AI is extensively transforming Software Engineering (SE) fields, SE is still in need of a framework to overall consider all phases to facilitate Automated Software Evolution (ASEv), particularly for intelligent applications that are context-rich, instead of conquering each division independently. Its complexity comes from the intricacy of the intelligent applications, the heterogeneity of the data sources, and the constant changes in the context. This study proposes a conceptual framework for achieving automated software evolution, emphasizing the importance of multimodality learning. A Selective Sequential Scope Model (3S) model is developed based on the conceptual framework, and it can be used to categorize existing and future research when it covers different SE phases and multimodal learning tasks. This research is a preliminary step toward the blueprint of a higher-level ASEv. The proposed conceptual framework can act as a practical guideline for practitioners to prepare themselves for diving into this area. Although the study is about intelligent applications, the framework and analysis methods may be adapted for other types of software as AI brings more intelligence into their life cycles.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04824",
        "abstract url": "https://arxiv.org/abs/2404.04824",
        "title": "Mixup Domain Adaptations for Dynamic Remaining Useful Life Predictions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Remaining Useful Life (RUL) predictions play vital role for asset planning and maintenance leading to many benefits to industries such as reduced downtime, low maintenance costs, etc. Although various efforts have been devoted to study this topic, most existing works are restricted for i.i.d conditions assuming the same condition of the training phase and the deployment phase. This paper proposes a solution to this problem where a mix-up domain adaptation (MDAN) is put forward. MDAN encompasses a three-staged mechanism where the mix-up strategy is not only performed to regularize the source and target domains but also applied to establish an intermediate mix-up domain where the source and target domains are aligned. The self-supervised learning strategy is implemented to prevent the supervision collapse problem. Rigorous evaluations have been performed where MDAN is compared to recently published works for dynamic RUL predictions. MDAN outperforms its counterparts with substantial margins in 12 out of 12 cases. In addition, MDAN is evaluated with the bearing machine dataset where it beats prior art with significant gaps in 8 of 12 cases. Source codes of MDAN are made publicly available in \\url{https://github.com/furqon3009/MDAN}.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "accepted for publication in Knowledge-based Systems"
    },
    {
        "paper id": "2404.04825",
        "abstract url": "https://arxiv.org/abs/2404.04825",
        "title": "Gradient-based Design of Computational Granular Crystals",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "There is growing interest in engineering unconventional computing devices that leverage the intrinsic dynamics of physical substrates to perform fast and energy-efficient computations. Granular metamaterials are one such substrate that has emerged as a promising platform for building wave-based information processing devices with the potential to integrate sensing, actuation, and computation. Their high-dimensional and nonlinear dynamics result in nontrivial and sometimes counter-intuitive wave responses that can be shaped by the material properties, geometry, and configuration of individual grains. Such highly tunable rich dynamics can be utilized for mechanical computing in special-purpose applications. However, there are currently no general frameworks for the inverse design of large-scale granular materials. Here, we build upon the similarity between the spatiotemporal dynamics of wave propagation in material and the computational dynamics of Recurrent Neural Networks to develop a gradient-based optimization framework for harmonically driven granular crystals. We showcase how our framework can be utilized to design basic logic gates where mechanical vibrations carry the information at predetermined frequencies. We compare our design methodology with classic gradient-free methods and find that our approach discovers higher-performing configurations with less computational effort. Our findings show that a gradient-based optimization method can greatly expand the design space of metamaterials and provide the opportunity to systematically traverse the parameter space to find materials with the desired functionalities.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.ET",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04839",
        "abstract url": "https://arxiv.org/abs/2404.04839",
        "title": "AI for DevSecOps: A Landscape and Future Opportunities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They reduce manual efforts, which can be integrated into DevOps to ensure uninterrupted delivery speed and align with the DevSecOps paradigm simultaneously. This paper seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevOps process and reviewed existing AI-driven security approaches. In RQ2, we discovered 15 challenges encountered by existing AI-driven security approaches and derived future research opportunities. Drawing insights from our findings, we discussed the state-of-the-art AI-driven security approaches, highlighted challenges in existing research, and proposed avenues for future opportunities.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04859",
        "abstract url": "https://arxiv.org/abs/2404.04859",
        "title": "Demystifying Lazy Training of Neural Networks from a Macroscopic Viewpoint",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we advance the understanding of neural network training dynamics by examining the intricate interplay of various factors introduced by weight parameters in the initialization process. Motivated by the foundational work of Luo et al. (J. Mach. Learn. Res., Vol. 22, Iss. 1, No. 71, pp 3327-3373), we explore the gradient descent dynamics of neural networks through the lens of macroscopic limits, where we analyze its behavior as width $m$ tends to infinity. Our study presents a unified approach with refined techniques designed for multi-layer fully connected neural networks, which can be readily extended to other neural network architectures. Our investigation reveals that gradient descent can rapidly drive deep neural networks to zero training loss, irrespective of the specific initialization schemes employed by weight parameters, provided that the initial scale of the output function $\u03ba$ surpasses a certain threshold. This regime, characterized as the theta-lazy area, accentuates the predominant influence of the initial scale $\u03ba$ over other factors on the training behavior of neural networks. Furthermore, our approach draws inspiration from the Neural Tangent Kernel (NTK) paradigm, and we expand its applicability. While NTK typically assumes that $\\lim_{m\\to\\infty}\\frac{\\log \u03ba}{\\log m}=\\frac{1}{2}$, and imposes each weight parameters to scale by the factor $\\frac{1}{\\sqrt{m}}$, in our theta-lazy regime, we discard the factor and relax the conditions to $\\lim_{m\\to\\infty}\\frac{\\log \u03ba}{\\log m}>0$. Similar to NTK, the behavior of overparameterized neural networks within the theta-lazy regime trained by gradient descent can be effectively described by a specific kernel. Through rigorous analysis, our investigation illuminates the pivotal role of $\u03ba$ in governing the training dynamics of neural networks.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04870",
        "abstract url": "https://arxiv.org/abs/2404.04870",
        "title": "Signal-noise separation using unsupervised reservoir computing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Removing noise from a signal without knowing the characteristics of the noise is a challenging task. This paper introduces a signal-noise separation method based on time series prediction. We use Reservoir Computing (RC) to extract the maximum portion of \"predictable information\" from a given signal. Reproducing the deterministic component of the signal using RC, we estimate the noise distribution from the difference between the original signal and reconstructed one. The method is based on a machine learning approach and requires no prior knowledge of either the deterministic signal or the noise distribution. It provides a way to identify additivity/multiplicativity of noise and to estimate the signal-to-noise ratio (SNR) indirectly. The method works successfully for combinations of various signal and noise, including chaotic signal and highly oscillating sinusoidal signal which are corrupted by non-Gaussian additive/ multiplicative noise. The separation performances are robust and notably outstanding for signals with strong noise, even for those with negative SNR.",
        "subjects": [
            "cs.LG",
            "eess.SP",
            "nlin.CD"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04876",
        "abstract url": "https://arxiv.org/abs/2404.04876",
        "title": "HiLo: Detailed and Robust 3D Clothed Human Reconstruction with High-and Low-Frequency Information of Parametric Models",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Reconstructing 3D clothed human involves creating a detailed geometry of individuals in clothing, with applications ranging from virtual try-on, movies, to games. To enable practical and widespread applications, recent advances propose to generate a clothed human from an RGB image. However, they struggle to reconstruct detailed and robust avatars simultaneously. We empirically find that the high-frequency (HF) and low-frequency (LF) information from a parametric model has the potential to enhance geometry details and improve robustness to noise, respectively. Based on this, we propose HiLo, namely clothed human reconstruction with high- and low-frequency information, which contains two components. 1) To recover detailed geometry using HF information, we propose a progressive HF Signed Distance Function to enhance the detailed 3D geometry of a clothed human. We analyze that our progressive learning manner alleviates large gradients that hinder model convergence. 2) To achieve robust reconstruction against inaccurate estimation of the parametric model by using LF information, we propose a spatial interaction implicit function. This function effectively exploits the complementary spatial information from a low-resolution voxel grid of the parametric model. Experimental results demonstrate that HiLo outperforms the state-of-the-art methods by 10.43% and 9.54% in terms of Chamfer distance on the Thuman2.0 and CAPE datasets, respectively. Additionally, HiLo demonstrates robustness to noise from the parametric model, challenging poses, and various clothing styles.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024 Accepted Paper"
    },
    {
        "paper id": "2404.04886",
        "abstract url": "https://arxiv.org/abs/2404.04886",
        "title": "PagPassGPT: Pattern Guided Password Guessing via Generative Pretrained Transformer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Amidst the surge in deep learning-based password guessing models, challenges of generating high-quality passwords and reducing duplicate passwords persist. To address these challenges, we present PagPassGPT, a password guessing model constructed on Generative Pretrained Transformer (GPT). It can perform pattern guided guessing by incorporating pattern structure information as background knowledge, resulting in a significant increase in the hit rate. Furthermore, we propose D&C-GEN to reduce the repeat rate of generated passwords, which adopts the concept of a divide-and-conquer approach. The primary task of guessing passwords is recursively divided into non-overlapping subtasks. Each subtask inherits the knowledge from the parent task and predicts succeeding tokens. In comparison to the state-of-the-art model, our proposed scheme exhibits the capability to correctly guess 12% more passwords while producing 25% fewer duplicates.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04902",
        "abstract url": "https://arxiv.org/abs/2404.04902",
        "title": "AI2Apps: A Visual IDE for Building LLM-based AI Agent Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce AI2Apps, a Visual Integrated Development Environment (Visual IDE) with full-cycle capabilities that accelerates developers to build deployable LLM-based AI agent Applications. This Visual IDE prioritizes both the Integrity of its development tools and the Visuality of its components, ensuring a smooth and efficient building experience.On one hand, AI2Apps integrates a comprehensive development toolkit ranging from a prototyping canvas and AI-assisted code editor to agent debugger, management system, and deployment tools all within a web-based graphical user interface. On the other hand, AI2Apps visualizes reusable front-end and back-end code as intuitive drag-and-drop components. Furthermore, a plugin system named AI2Apps Extension (AAE) is designed for Extensibility, showcasing how a new plugin with 20 components enables web agent to mimic human-like browsing behavior. Our case study demonstrates substantial efficiency improvements, with AI2Apps reducing token consumption and API calls when debugging a specific sophisticated multimodal agent by approximately 90% and 80%, respectively. The AI2Apps, including an online demo, open-source code, and a screencast video, is now publicly accessible.",
        "subjects": [
            "cs.AI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04903",
        "abstract url": "https://arxiv.org/abs/2404.04903",
        "title": "Online Learning under Haphazard Input Conditions: A Comprehensive Review and Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The domain of online learning has experienced multifaceted expansion owing to its prevalence in real-life applications. Nonetheless, this progression operates under the assumption that the input feature space of the streaming data remains constant. In this survey paper, we address the topic of online learning in the context of haphazard inputs, explicitly foregoing such an assumption. We discuss, classify, evaluate, and compare the methodologies that are adept at modeling haphazard inputs, additionally providing the corresponding code implementations and their carbon footprint. Moreover, we classify the datasets related to the field of haphazard inputs and introduce evaluation metrics specifically designed for datasets exhibiting imbalance. The code of each methodology can be found at https://github.com/Rohit102497/HaphazardInputsReview",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04912",
        "abstract url": "https://arxiv.org/abs/2404.04912",
        "title": "Opinion Dynamics for Utility Maximizing Agents: Exploring the Impact of Resource Penalty",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "We propose a continuous-time nonlinear model of opinion dynamics with utility-maximizing agents connected via a social influence network. A distinguishing feature of the proposed model is the inclusion of an opinion-dependent resource-penalty term in the utilities, which limits the agents from holding opinions of large magnitude. The proposed utility functions also account for how the relative resources within the social group affect both an agent's stubbornness and social influence. Each agent myopically seeks to maximize its utility by revising its opinion in the gradient ascent direction of its utility function, thus leading to the proposed opinion dynamics. We show that, for any arbitrary social influence network, opinions are ultimately bounded. For networks with weak antagonistic relations, we show that there exists a globally exponentially stable equilibrium using contraction theory. We establish conditions for the existence of consensus equilibrium and analyze the relative dominance of the agents at consensus. We also conduct a game-theoretic analysis of the underlying opinion formation game, including on Nash equilibria and on prices of anarchy in terms of satisfaction ratios. Additionally, we also investigate the oscillatory behavior of opinions in a two-agent scenario. Finally, simulations illustrate our findings.",
        "subjects": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.SI"
        ],
        "comment": "12 pages, 9 figures"
    },
    {
        "paper id": "2404.04916",
        "abstract url": "https://arxiv.org/abs/2404.04916",
        "title": "Correcting Diffusion-Based Perceptual Image Compression with Privileged End-to-End Decoder",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "The images produced by diffusion models can attain excellent perceptual quality. However, it is challenging for diffusion models to guarantee distortion, hence the integration of diffusion models and image compression models still needs more comprehensive explorations. This paper presents a diffusion-based image compression method that employs a privileged end-to-end decoder model as correction, which achieves better perceptual quality while guaranteeing the distortion to an extent. We build a diffusion model and design a novel paradigm that combines the diffusion model and an end-to-end decoder, and the latter is responsible for transmitting the privileged information extracted at the encoder side. Specifically, we theoretically analyze the reconstruction process of the diffusion models at the encoder side with the original images being visible. Based on the analysis, we introduce an end-to-end convolutional decoder to provide a better approximation of the score function $\\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t)$ at the encoder side and effectively transmit the combination. Experiments demonstrate the superiority of our method in both distortion and perception compared with previous perceptual compression methods.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by ICML 2024"
    },
    {
        "paper id": "2404.04931",
        "abstract url": "https://arxiv.org/abs/2404.04931",
        "title": "The Sample Complexity of Gradient Descent in Stochastic Convex Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We analyze the sample complexity of full-batch Gradient Descent (GD) in the setup of non-smooth Stochastic Convex Optimization. We show that the generalization error of GD, with common choice of hyper-parameters, can be $\\tilde \u0398(d/m + 1/\\sqrt{m})$, where $d$ is the dimension and $m$ is the sample size. This matches the sample complexity of \\emph{worst-case} empirical risk minimizers. That means that, in contrast with other algorithms, GD has no advantage over naive ERMs. Our bound follows from a new generalization bound that depends on both the dimension as well as the learning rate and number of iterations. Our bound also shows that, for general hyper-parameters, when the dimension is strictly larger than number of samples, $T=\u03a9(1/\u03b5^4)$ iterations are necessary to avoid overfitting. This resolves an open problem by Schlisserman et al.23 and Amir er Al.21, and improves over previous lower bounds that demonstrated that the sample size must be at least square root of the dimension.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04940",
        "abstract url": "https://arxiv.org/abs/2404.04940",
        "title": "Fuzzy K-Means Clustering without Cluster Centroids",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fuzzy K-Means clustering is a critical technique in unsupervised data analysis. However, the performance of popular Fuzzy K-Means algorithms is sensitive to the selection of initial cluster centroids and is also affected by noise when updating mean cluster centroids. To address these challenges, this paper proposes a novel Fuzzy K-Means clustering algorithm that entirely eliminates the reliance on cluster centroids, obtaining membership matrices solely through distance matrix computation. This innovation enhances flexibility in distance measurement between sample points, thus improving the algorithm's performance and robustness. The paper also establishes theoretical connections between the proposed model and popular Fuzzy K-Means clustering techniques. Experimental results on several real datasets demonstrate the effectiveness of the algorithm.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04942",
        "abstract url": "https://arxiv.org/abs/2404.04942",
        "title": "The Spatial Structures in the Austrian COVID-19 Protest Movement: A Virtual and Geospatial Twitter User Network Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The emergence of the COVID-19 pandemic, followed by policy measures to combat the virus, evoked public protest movements world-wide. These movements emerged through virtual social networks as well as local protest gatherings. Prior research has studied such movements solely in the virtual space through social network analysis, thereby disregarding the role of local interaction for protest. This study, however, recognizes the importance of the geo-spatial dimension in protest movements. We therefore introduce a large-scale spatial-social network analysis of a georeferenced Twitter user network to understand the regional connections and transnational influences of the Austrian COVID-19 protest movement through the social network. Our findings reveal that the virtual network is distinctly structured along geographic and linguistic boundaries. We further find that the movement is clearly organized along national protest communities. These results highlight the importance of regional and local influencing factors over the impact of transnational influences for the protest movement.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04952",
        "abstract url": "https://arxiv.org/abs/2404.04952",
        "title": "The Impact of Virtual Laboratories on Active Learning and Engagement in Cybersecurity Distance Education",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Virtual Laboratories (V Labs) have in the recent past become part and parcel of remote teaching in practical hands-on approaches, particularly in Cybersecurity distance courses. Their potential is meant to assist learners with hands-on practical laboratory exercises irrespective of geographical location. Nevertheless, adopting V Labs in didactic approaches in higher education has seen both merits and demerits. Based on this premise, this study investigates the impact of V Labs on Active Learning (AL) and engagement in cybersecurity distance education. A survey with a limited number of learners and educators who have had an experience with cybersecurity distance courses that leveraged V Labs in their practical Lab assignment, was conducted at Blekinge Tekniska H\u00f6gskola, Sweden, to assess the impact of V Labs on AL and engagement in Cybersecurity Distance Education. 29% and 73% of the learners and educators, respectively responded to the survey administered remotely and with good internal consistency of questionnaires based on the Cronbalch Alpha; the results showed that learners and educators had a positive perception of using V Labs to enhance AL in cybersecurity distance education. The key concentration of the study was on AL and engagement and problem-solving abilities when V Labs are used. Both the learners and educators found the V Labs to be engaging, interactive, and effective in improving their understanding of cybersecurity concepts.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "13 pages 4 figures"
    },
    {
        "paper id": "2404.04960",
        "abstract url": "https://arxiv.org/abs/2404.04960",
        "title": "PairAug: What Can Augmented Image-Text Pairs Do for Radiology?",
        "rating": "0.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "medical",
                "Radiology"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Current vision-language pre-training (VLP) methodologies predominantly depend on paired image-text datasets, a resource that is challenging to acquire in radiology due to privacy considerations and labelling complexities. Data augmentation provides a practical solution to overcome the issue of data scarcity, however, most augmentation methods exhibit a limited focus, prioritising either image or text augmentation exclusively. Acknowledging this limitation, our objective is to devise a framework capable of concurrently augmenting medical image and text data. We design a Pairwise Augmentation (PairAug) approach that contains an Inter-patient Augmentation (InterAug) branch and an Intra-patient Augmentation (IntraAug) branch. Specifically, the InterAug branch of our approach generates radiology images using synthesised yet plausible reports derived from a Large Language Model (LLM). The generated pairs can be considered a collection of new patient cases since they are artificially created and may not exist in the original dataset. In contrast, the IntraAug branch uses newly generated reports to manipulate images. This process allows us to create new paired data for each individual with diverse medical conditions. Our extensive experiments on various downstream tasks covering medical image classification zero-shot and fine-tuning analysis demonstrate that our PairAug, concurrently expanding both image and text data, substantially outperforms image-/text-only expansion baselines and advanced medical VLP baselines. Our code is released at \\url{https://github.com/YtongXie/PairAug}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to CVPR2024"
    },
    {
        "paper id": "2404.04970",
        "abstract url": "https://arxiv.org/abs/2404.04970",
        "title": "How to characterize imprecision in multi-view clustering?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "It is still challenging to cluster multi-view data since existing methods can only assign an object to a specific (singleton) cluster when combining different view information. As a result, it fails to characterize imprecision of objects in overlapping regions of different clusters, thus leading to a high risk of errors. In this paper, we thereby want to answer the question: how to characterize imprecision in multi-view clustering? Correspondingly, we propose a multi-view low-rank evidential c-means based on entropy constraint (MvLRECM). The proposed MvLRECM can be considered as a multi-view version of evidential c-means based on the theory of belief functions. In MvLRECM, each object is allowed to belong to different clusters with various degrees of support (masses of belief) to characterize uncertainty when decision-making. Moreover, if an object is in the overlapping region of several singleton clusters, it can be assigned to a meta-cluster, defined as the union of these singleton clusters, to characterize the local imprecision in the result. In addition, entropy-weighting and low-rank constraints are employed to reduce imprecision and improve accuracy. Compared to state-of-the-art methods, the effectiveness of MvLRECM is demonstrated based on several toy and UCI real datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "19 pages with 8 pages of supplementary"
    },
    {
        "paper id": "2404.04979",
        "abstract url": "https://arxiv.org/abs/2404.04979",
        "title": "CAVIAR: Categorical-Variable Embeddings for Accurate and Robust Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Social science research often hinges on the relationship between categorical variables and outcomes. We introduce CAVIAR, a novel method for embedding categorical variables that assume values in a high-dimensional ambient space but are sampled from an underlying manifold. Our theoretical and numerical analyses outline challenges posed by such categorical variables in causal inference. Specifically, dynamically varying and sparse levels can lead to violations of the Donsker conditions and a failure of the estimation functionals to converge to a tight Gaussian process. Traditional approaches, including the exclusion of rare categorical levels and principled variable selection models like LASSO, fall short. CAVIAR embeds the data into a lower-dimensional global coordinate system. The mapping can be derived from both structured and unstructured data, and ensures stable and robust estimates through dimensionality reduction. In a dataset of direct-to-consumer apparel sales, we illustrate how high-dimensional categorical variables, such as zip codes, can be succinctly represented, facilitating inference and analysis.",
        "subjects": [
            "econ.EM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04986",
        "abstract url": "https://arxiv.org/abs/2404.04986",
        "title": "Dynamic Distinction Learning: Adaptive Pseudo Anomalies for Video Anomaly Detection",
        "rating": "0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We introduce Dynamic Distinction Learning (DDL) for Video Anomaly Detection, a novel video anomaly detection methodology that combines pseudo-anomalies, dynamic anomaly weighting, and a distinction loss function to improve detection accuracy. By training on pseudo-anomalies, our approach adapts to the variability of normal and anomalous behaviors without fixed anomaly thresholds. Our model showcases superior performance on the Ped2, Avenue and ShanghaiTech datasets, where individual models are tailored for each scene. These achievements highlight DDL's effectiveness in advancing anomaly detection, offering a scalable and adaptable solution for video surveillance challenges.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "To be published in the CVPR2024 Workshop"
    },
    {
        "paper id": "2404.04998",
        "abstract url": "https://arxiv.org/abs/2404.04998",
        "title": "Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval",
        "rating": "0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Deep quantization methods have shown high efficiency on large-scale image retrieval. However, current models heavily rely on ground-truth information, hindering the application of quantization in label-hungry scenarios. A more realistic demand is to learn from inexhaustible uploaded images that are associated with informal tags provided by amateur users. Though such sketchy tags do not obviously reveal the labels, they actually contain useful semantic information for supervising deep quantization. To this end, we propose Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first work to learn deep quantization from weakly tagged images. Specifically, 1) we use word embeddings to represent the tags and enhance their semantic information based on a tag correlation graph. 2) To better preserve semantic information in quantization codes and reduce quantization error, we jointly learn semantics-preserving embeddings and supervised quantizer on hypersphere by employing a well-designed fusion layer and tailor-made loss functions. Extensive experiments show that WSDHQ can achieve state-of-art performance on weakly-supervised compact coding. Code is available at https://github.com/gimpong/AAAI21-WSDHQ.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "In proceedings of AAAI 2021. Code and data are available"
    },
    {
        "paper id": "2404.05001",
        "abstract url": "https://arxiv.org/abs/2404.05001",
        "title": "Dual-Scale Transformer for Large-Scale Single-Pixel Imaging",
        "rating": "0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Single-pixel imaging (SPI) is a potential computational imaging technique which produces image by solving an illposed reconstruction problem from few measurements captured by a single-pixel detector. Deep learning has achieved impressive success on SPI reconstruction. However, previous poor reconstruction performance and impractical imaging model limit its real-world applications. In this paper, we propose a deep unfolding network with hybrid-attention Transformer on Kronecker SPI model, dubbed HATNet, to improve the imaging quality of real SPI cameras. Specifically, we unfold the computation graph of the iterative shrinkagethresholding algorithm (ISTA) into two alternative modules: efficient tensor gradient descent and hybrid-attention multiscale denoising. By virtue of Kronecker SPI, the gradient descent module can avoid high computational overheads rooted in previous gradient descent modules based on vectorized SPI. The denoising module is an encoder-decoder architecture powered by dual-scale spatial attention for high- and low-frequency aggregation and channel attention for global information recalibration. Moreover, we build a SPI prototype to verify the effectiveness of the proposed method. Extensive experiments on synthetic and real data demonstrate that our method achieves the state-of-the-art performance. The source code and pre-trained models are available at https://github.com/Gang-Qu/HATNet-SPI.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2404.05043",
        "abstract url": "https://arxiv.org/abs/2404.05043",
        "title": "Optimizing Privacy and Utility Tradeoffs for Group Interests Through Harmonization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel problem formulation to address the privacy-utility tradeoff, specifically when dealing with two distinct user groups characterized by unique sets of private and utility attributes. Unlike previous studies that primarily focus on scenarios where all users share identical private and utility attributes and often rely on auxiliary datasets or manual annotations, we introduce a collaborative data-sharing mechanism between two user groups through a trusted third party. This third party uses adversarial privacy techniques with our proposed data-sharing mechanism to internally sanitize data for both groups and eliminates the need for manual annotation or auxiliary datasets. Our methodology ensures that private attributes cannot be accurately inferred while enabling highly accurate predictions of utility features. Importantly, even if analysts or adversaries possess auxiliary datasets containing raw data, they are unable to accurately deduce private features. Additionally, our data-sharing mechanism is compatible with various existing adversarially trained privacy techniques. We empirically demonstrate the effectiveness of our approach using synthetic and real-world datasets, showcasing its ability to balance the conflicting goals of privacy and utility.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "10 pages, Paper accepted at 2024 IEEE International Joint Conference on Neural Networks (IJCNN)"
    },
    {
        "paper id": "2404.05055",
        "abstract url": "https://arxiv.org/abs/2404.05055",
        "title": "Percentile Criterion Optimization in Offline Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In reinforcement learning, robust policies for high-stakes decision-making problems with limited data are usually computed by optimizing the \\emph{percentile criterion}. The percentile criterion is approximately solved by constructing an \\emph{ambiguity set} that contains the true model with high probability and optimizing the policy for the worst model in the set. Since the percentile criterion is non-convex, constructing ambiguity sets is often challenging. Existing work uses \\emph{Bayesian credible regions} as ambiguity sets, but they are often unnecessarily large and result in learning overly conservative policies. To overcome these shortcomings, we propose a novel Value-at-Risk based dynamic programming algorithm to optimize the percentile criterion without explicitly constructing any ambiguity sets. Our theoretical and empirical results show that our algorithm implicitly constructs much smaller ambiguity sets and learns less conservative robust policies.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted at Neurips 2023"
    },
    {
        "paper id": "2404.05058",
        "abstract url": "https://arxiv.org/abs/2404.05058",
        "title": "A robust assessment for invariant representations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The performance of machine learning models can be impacted by changes in data over time. A promising approach to address this challenge is invariant learning, with a particular focus on a method known as invariant risk minimization (IRM). This technique aims to identify a stable data representation that remains effective with out-of-distribution (OOD) data. While numerous studies have developed IRM-based methods adaptive to data augmentation scenarios, there has been limited attention on directly assessing how well these representations preserve their invariant performance under varying conditions. In our paper, we propose a novel method to evaluate invariant performance, specifically tailored for IRM-based methods. We establish a bridge between the conditional expectation of an invariant predictor across different environments through the likelihood ratio. Our proposed criterion offers a robust basis for evaluating invariant performance. We validate our approach with theoretical support and demonstrate its effectiveness through extensive numerical studies.These experiments illustrate how our method can assess the invariant performance of various representation techniques.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05062",
        "abstract url": "https://arxiv.org/abs/2404.05062",
        "title": "New methods for computing the generalized chi-square distribution",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present several exact and approximate mathematical methods and open-source software to compute the cdf, pdf and inverse cdf of the generalized chi-square distribution, which appears in Bayesian classification problems. Some methods are geared for speed, while others are designed to be accurate far into the tails, using which we can also measure large values of the discriminability index $d'$ between multinormals. We compare the accuracy and speed of these methods against the best existing methods.",
        "subjects": [
            "stat.CO",
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05064",
        "abstract url": "https://arxiv.org/abs/2404.05064",
        "title": "A Structure-Guided Gauss-Newton Method for Shallow ReLU Neural Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a structure-guided Gauss-Newton (SgGN) method for solving least squares problems using a shallow ReLU neural network. The method effectively takes advantage of both the least squares structure and the neural network structure of the objective function. By categorizing the weights and biases of the hidden and output layers of the network as nonlinear and linear parameters, respectively, the method iterates back and forth between the nonlinear and linear parameters. The nonlinear parameters are updated by a damped Gauss-Newton method and the linear ones are updated by a linear solver. Moreover, at the Gauss-Newton step, a special form of the Gauss-Newton matrix is derived for the shallow ReLU neural network and is used for efficient iterations. It is shown that the corresponding mass and Gauss-Newton matrices in the respective linear and nonlinear steps are symmetric and positive definite under reasonable assumptions. Thus, the SgGN method naturally produces an effective search direction without the need of additional techniques like shifting in the Levenberg-Marquardt method to achieve invertibility of the Gauss-Newton matrix. The convergence and accuracy of the method are demonstrated numerically for several challenging function approximation problems, especially those with discontinuities or sharp transition layers that pose significant challenges for commonly used training algorithms in machine learning.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05074",
        "abstract url": "https://arxiv.org/abs/2404.05074",
        "title": "On the Uniqueness of Solution for the Bellman Equation of LTL Objectives",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Surrogate rewards for linear temporal logic (LTL) objectives are commonly utilized in planning problems for LTL objectives. In a widely-adopted surrogate reward approach, two discount factors are used to ensure that the expected return approximates the satisfaction probability of the LTL objective. The expected return then can be estimated by methods using the Bellman updates such as reinforcement learning. However, the uniqueness of the solution to the Bellman equation with two discount factors has not been explicitly discussed. We demonstrate with an example that when one of the discount factors is set to one, as allowed in many previous works, the Bellman equation may have multiple solutions, leading to inaccurate evaluation of the expected return. We then propose a condition for the Bellman equation to have the expected return as the unique solution, requiring the solutions for states inside a rejecting bottom strongly connected component (BSCC) to be 0. We prove this condition is sufficient by showing that the solutions for the states with discounting can be separated from those for the states without discounting under this condition",
        "subjects": [
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Accepted for the 2024 Learning for Dynamics and Control Conference (L4DC)"
    },
    {
        "paper id": "2404.05094",
        "abstract url": "https://arxiv.org/abs/2404.05094",
        "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies. To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting. We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05101",
        "abstract url": "https://arxiv.org/abs/2404.05101",
        "title": "StockGPT: A GenAI Model for Stock Prediction and Trading",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces StockGPT, an autoregressive ``number'' model trained and tested on 70 million daily U.S. stock returns over nearly 100 years. Treating each return series as a sequence of tokens, StockGPT automatically learns the hidden patterns predictive of future returns via its attention mechanism. On a held-out test sample from 2001 to 2023, a daily rebalanced long-short portfolio formed from StockGPT predictions earns an annual return of 119% with a Sharpe ratio of 6.5. The StockGPT-based portfolio completely spans momentum and long-/short-term reversals, eliminating the need for manually crafted price-based strategies, and also encompasses most leading stock market factors. This highlights the immense promise of generative AI in surpassing human in making complex financial investment decisions.",
        "subjects": [
            "q-fin.CP",
            "cs.AI",
            "q-fin.PM",
            "q-fin.PR",
            "q-fin.ST"
        ],
        "comment": "19 pages, 3 figures, 7 tables"
    },
    {
        "paper id": "2404.05145",
        "abstract url": "https://arxiv.org/abs/2404.05145",
        "title": "UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather",
        "rating": "0.5",
        "keywords": [
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "LiDAR semantic segmentation (LSS) is a critical task in autonomous driving and has achieved promising progress. However, prior LSS methods are conventionally investigated and evaluated on datasets within the same domain in clear weather. The robustness of LSS models in unseen scenes and all weather conditions is crucial for ensuring safety and reliability in real applications. To this end, we propose UniMix, a universal method that enhances the adaptability and generalizability of LSS models. UniMix first leverages physically valid adverse weather simulation to construct a Bridge Domain, which serves to bridge the domain gap between the clear weather scenes and the adverse weather scenes. Then, a Universal Mixing operator is defined regarding spatial, intensity, and semantic distributions to create the intermediate domain with mixed samples from given domains. Integrating the proposed two techniques into a teacher-student framework, UniMix efficiently mitigates the domain gap and enables LSS models to learn weather-robust and domain-invariant representations. We devote UniMix to two main setups: 1) unsupervised domain adaption, adapting the model from the clear weather source domain to the adverse weather target domain; 2) domain generalization, learning a model that generalizes well to unseen scenes in adverse weather. Extensive experiments validate the effectiveness of UniMix across different tasks and datasets, all achieving superior performance over state-of-the-art methods. The code will be released.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2404.05155",
        "abstract url": "https://arxiv.org/abs/2404.05155",
        "title": "On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: A regret lower bound for WSU-UX",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In one view of the classical game of prediction with expert advice with binary outcomes, in each round, each expert maintains an adversarially chosen belief and honestly reports this belief. We consider a recently introduced, strategic variant of this problem with selfish (reputation-seeking) experts, where each expert strategically reports in order to maximize their expected future reputation based on their belief. In this work, our goal is to design an algorithm for the selfish experts problem that is incentive-compatible (IC, or \\emph{truthful}), meaning each expert's best strategy is to report truthfully, while also ensuring the algorithm enjoys sublinear regret with respect to the expert with the best belief. Freeman et al. (2020) recently studied this problem in the full information and bandit settings and obtained truthful, no-regret algorithms by leveraging prior work on wagering mechanisms. While their results under full information match the minimax rate for the classical (\"honest experts\") problem, the best-known regret for their bandit algorithm WSU-UX is $O(T^{2/3})$, which does not match the minimax rate for the classical (\"honest bandits\") setting. It was unclear whether the higher regret was an artifact of their analysis or a limitation of WSU-UX. We show, via explicit construction of loss sequences, that the algorithm suffers a worst-case $\u03a9(T^{2/3})$ lower bound. Left open is the possibility that a different IC algorithm obtains $O(\\sqrt{T})$ regret. Yet, WSU-UX was a natural choice for such an algorithm owing to the limited design room for IC algorithms in this setting.",
        "subjects": [
            "cs.LG",
            "cs.GT",
            "stat.ML"
        ],
        "comment": "Accepted to AISTATS 2024"
    },
    {
        "paper id": "2404.05163",
        "abstract url": "https://arxiv.org/abs/2404.05163",
        "title": "Semantic Flow: Learning Semantic Field of Dynamic Scenes from Monocular Videos",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "In this work, we pioneer Semantic Flow, a neural semantic representation of dynamic scenes from monocular videos. In contrast to previous NeRF methods that reconstruct dynamic scenes from the colors and volume densities of individual points, Semantic Flow learns semantics from continuous flows that contain rich 3D motion information. As there is 2D-to-3D ambiguity problem in the viewing direction when extracting 3D flow features from 2D video frames, we consider the volume densities as opacity priors that describe the contributions of flow features to the semantics on the frames. More specifically, we first learn a flow network to predict flows in the dynamic scene, and propose a flow feature aggregation module to extract flow features from video frames. Then, we propose a flow attention module to extract motion information from flow features, which is followed by a semantic network to output semantic logits of flows. We integrate the logits with volume densities in the viewing direction to supervise the flow features with semantic labels on video frames. Experimental results show that our model is able to learn from multiple dynamic scenes and supports a series of new tasks such as instance-level scene editing, semantic completions, dynamic scene tracking and semantic adaption on novel scenes. Codes are available at https://github.com/tianfr/Semantic-Flow/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICLR 2024, Codes are available at https://github.com/tianfr/Semantic-Flow/"
    },
    {
        "paper id": "2404.05168",
        "abstract url": "https://arxiv.org/abs/2404.05168",
        "title": "Adapting to Covariate Shift in Real-time by Encoding Trees with Motion Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Input distribution shift presents a significant problem in many real-world systems. Here we present Xenovert, an adaptive algorithm that can dynamically adapt to changes in input distribution. It is a perfect binary tree that adaptively divides a continuous input space into several intervals of uniform density while receiving a continuous stream of input. This process indirectly maps the source distribution to the shifted target distribution, preserving the data's relationship with the downstream decoder/operation, even after the shift occurs. In this paper, we demonstrated how a neural network integrated with Xenovert achieved better results in 4 out of 5 shifted datasets, saving the hurdle of retraining a machine learning model. We anticipate that Xenovert can be applied to many more applications that require adaptation to unforeseen input distribution shifts, even when the distribution shift is drastic.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 figures, 2 tables"
    },
    {
        "paper id": "2404.05185",
        "abstract url": "https://arxiv.org/abs/2404.05185",
        "title": "Convergence analysis of controlled particle systems arising in deep learning: from finite to infinite sample size",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper deals with a class of neural SDEs and studies the limiting behavior of the associated sampled optimal control problems as the sample size grows to infinity. The neural SDEs with N samples can be linked to the N-particle systems with centralized control. We analyze the Hamilton--Jacobi--Bellman equation corresponding to the N-particle system and establish regularity results which are uniform in N. The uniform regularity estimates are obtained by the stochastic maximum principle and the analysis of a backward stochastic Riccati equation. Using these uniform regularity results, we show the convergence of the minima of objective functionals and optimal parameters of the neural SDEs as the sample size N tends to infinity. The limiting objects can be identified with suitable functions defined on the Wasserstein space of Borel probability measures. Furthermore, quantitative algebraic convergence rates are also obtained.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "comment": "45 pages, 2 figures"
    },
    {
        "paper id": "2404.05767",
        "abstract url": "https://arxiv.org/abs/2404.05767",
        "title": "CSA-Trans: Code Structure Aware Transformer for AST",
        "rating": "0.5",
        "keywords": [
            [
                "memory efficient"
            ],
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "When applying the Transformer architecture to source code, designing a good self-attention mechanism is critical as it affects how node relationship is extracted from the Abstract Syntax Trees (ASTs) of the source code. We present Code Structure Aware Transformer (CSA-Trans), which uses Code Structure Embedder (CSE) to generate specific PE for each node in AST. CSE generates node Positional Encoding (PE) using disentangled attention. To further extend the self-attention capability, we adopt Stochastic Block Model (SBM) attention. Our evaluation shows that our PE captures the relationships between AST nodes better than other graph-related PE techniques. We also show through quantitative and qualitative analysis that SBM attention is able to generate more node specific attention coefficients. We demonstrate that CSA-Trans outperforms 14 baselines in code summarization tasks for both Python and Java, while being 41.92% faster and 25.31% memory efficient in Java dataset compared to AST-Trans and SG-Trans respectively.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.10782",
        "abstract url": "https://arxiv.org/abs/2404.10782",
        "title": "Quantifying AI Vulnerabilities: A Synthesis of Complexity, Dynamical Systems, and Game Theory",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rapid integration of Artificial Intelligence (AI) systems across critical domains necessitates robust security evaluation frameworks. We propose a novel approach that introduces three metrics: System Complexity Index (SCI), Lyapunov Exponent for AI Stability (LEAIS), and Nash Equilibrium Robustness (NER). SCI quantifies the inherent complexity of an AI system, LEAIS captures its stability and sensitivity to perturbations, and NER evaluates its strategic robustness against adversarial manipulation. Through comparative analysis, we demonstrate the advantages of our framework over existing techniques. We discuss the theoretical and practical implications, potential applications, limitations, and future research directions. Our work contributes to the development of secure and trustworthy AI technologies by providing a holistic, theoretically grounded approach to AI security evaluation. As AI continues to advance, prioritising and advancing AI security through interdisciplinary collaboration is crucial to ensure its responsible deployment for the benefit of society.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2404.15207",
        "abstract url": "https://arxiv.org/abs/2404.15207",
        "title": "Simulation-Free Determination of Microstructure Representative Volume Element Size via Fisher Scores",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A representative volume element (RVE) is a reasonably small unit of microstructure that can be simulated to obtain the same effective properties as the entire microstructure sample. Finite element (FE) simulation of RVEs, as opposed to much larger samples, saves computational expense, especially in multiscale modeling. Therefore, it is desirable to have a framework that determines RVE size prior to FE simulations. Existing methods select the RVE size based on when the FE-simulated properties of samples of increasing size converge with insignificant statistical variations, with the drawback that many samples must be simulated. We propose a simulation-free alternative that determines RVE size based only on a micrograph. The approach utilizes a machine learning model trained to implicitly characterize the stochastic nature of the input micrograph. The underlying rationale is to view RVE size as the smallest moving window size for which the stochastic nature of the microstructure within the window is stationary as the window moves across a large micrograph. For this purpose, we adapt a recently developed Fisher score-based framework for microstructure nonstationarity monitoring. Because the resulting RVE size is based solely on the micrograph and does not involve any FE simulation of specific properties, it constitutes an RVE for any property of interest that solely depends on the microstructure characteristics. Through numerical experiments of simple and complex microstructures, we validate our approach and show that our selected RVE sizes are consistent with when the chosen FE-simulated properties converge.",
        "subjects": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04828",
        "abstract url": "https://arxiv.org/abs/2404.04828",
        "title": "Strictly-ID-Preserved and Controllable Accessory Advertising Image Generation",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Customized generative text-to-image models have the ability to produce images that closely resemble a given subject. However, in the context of generating advertising images for e-commerce scenarios, it is crucial that the generated subject's identity aligns perfectly with the product being advertised. In order to address the need for strictly-ID preserved advertising image generation, we have developed a Control-Net based customized image generation pipeline and have taken earring model advertising as an example. Our approach facilitates a seamless interaction between the earrings and the model's face, while ensuring that the identity of the earrings remains intact. Furthermore, to achieve a diverse and controllable display, we have proposed a multi-branch cross-attention architecture, which allows for control over the scale, pose, and appearance of the model, going beyond the limitations of text prompts. Our method manages to achieve fine-grained control of the generated model's face, resulting in controllable and captivating advertising effects.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2404.04833",
        "abstract url": "https://arxiv.org/abs/2404.04833",
        "title": "ShoeModel: Learning to Wear on the User-specified Shoes via Diffusion Model",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the development of the large-scale diffusion model, Artificial Intelligence Generated Content (AIGC) techniques are popular recently. However, how to truly make it serve our daily lives remains an open question. To this end, in this paper, we focus on employing AIGC techniques in one filed of E-commerce marketing, i.e., generating hyper-realistic advertising images for displaying user-specified shoes by human. Specifically, we propose a shoe-wearing system, called Shoe-Model, to generate plausible images of human legs interacting with the given shoes. It consists of three modules: (1) shoe wearable-area detection module (WD), (2) leg-pose synthesis module (LpS) and the final (3) shoe-wearing image generation module (SW). Them three are performed in ordered stages. Compared to baselines, our ShoeModel is shown to generalize better to different type of shoes and has ability of keeping the ID-consistency of the given shoes, as well as automatically producing reasonable interactions with human. Extensive experiments show the effectiveness of our proposed shoe-wearing system. Figure 1 shows the input and output examples of our ShoeModel.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2404.04860",
        "abstract url": "https://arxiv.org/abs/2404.04860",
        "title": "ByteEdit: Boost, Comply and Accelerate Generative Image Editing",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "inpainting",
                "Image Editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in diffusion-based generative image editing have sparked a profound revolution, reshaping the landscape of image outpainting and inpainting tasks. Despite these strides, the field grapples with inherent challenges, including: i) inferior quality; ii) poor consistency; iii) insufficient instrcution adherence; iv) suboptimal generation efficiency. To address these obstacles, we present ByteEdit, an innovative feedback learning framework meticulously designed to Boost, Comply, and Accelerate Generative Image Editing tasks. ByteEdit seamlessly integrates image reward models dedicated to enhancing aesthetics and image-text alignment, while also introducing a dense, pixel-level reward model tailored to foster coherence in the output. Furthermore, we propose a pioneering adversarial and progressive feedback learning strategy to expedite the model's inference speed. Through extensive large-scale user evaluations, we demonstrate that ByteEdit surpasses leading generative image editing products, including Adobe, Canva, and MeiTu, in both generation quality and consistency. ByteEdit-Outpainting exhibits a remarkable enhancement of 388% and 135% in quality and consistency, respectively, when compared to the baseline model. Experiments also verfied that our acceleration models maintains excellent performance results in terms of quality and consistency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04892",
        "abstract url": "https://arxiv.org/abs/2404.04892",
        "title": "Elementary fractal geometry. 5. Weak separation is strong separation",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "For self-similar sets, there are two important separation properties: the open set condition and the weak separation condition introduced by Zerner, which may be replaced by the formally stronger finite type property of Ngai and Wang. We show that any finite type self-similar set can be represented as a graph-directed construction obeying the open set condition. The proof is based on a combinatorial algorithm which performed well in computer experiments.",
        "subjects": [
            "math.DS",
            "cs.CL"
        ],
        "comment": "27 pages, 12 figures"
    },
    {
        "paper id": "2404.04900",
        "abstract url": "https://arxiv.org/abs/2404.04900",
        "title": "Radial Networks: Dynamic Layer Routing for High-Performance Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) often struggle with strict memory, latency, and power demands. To meet these demands, various forms of dynamic sparsity have been proposed that reduce compute on an input-by-input basis. These methods improve over static methods by exploiting the variance across individual inputs, which has steadily grown with the exponential increase in training data. Yet, the increasing depth within modern models, currently with hundreds of layers, has opened opportunities for dynamic layer sparsity, which skips the computation for entire layers. In this work, we explore the practicality of layer sparsity by profiling residual connections and establish the relationship between model depth and layer sparsity. For example, the residual blocks in the OPT-66B model have a median contribution of 5% to its output. We then take advantage of this dynamic sparsity and propose Radial Networks, which perform token-level routing between layers guided by a trained router module. These networks can be used in a post-training distillation from sequential networks or trained from scratch to co-learn the router and layer weights. They enable scaling to larger model sizes by decoupling the number of layers from the dynamic depth of the network, and their design allows for layer reuse. By varying the compute token by token, they reduce the overall resources needed for generating entire sequences. Overall, this leads to larger capacity networks with significantly lower compute and serving costs for large language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "First two authors have equal contribution"
    },
    {
        "paper id": "2404.04908",
        "abstract url": "https://arxiv.org/abs/2404.04908",
        "title": "Dual-Camera Smooth Zoom on Mobile Phones",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "When zooming between dual cameras on a mobile, noticeable jumps in geometric content and image color occur in the preview, inevitably affecting the user's zoom experience. In this work, we introduce a new task, ie, dual-camera smooth zoom (DCSZ) to achieve a smooth zoom preview. The frame interpolation (FI) technique is a potential solution but struggles with ground-truth collection. To address the issue, we suggest a data factory solution where continuous virtual cameras are assembled to generate DCSZ data by rendering reconstructed 3D models of the scene. In particular, we propose a novel dual-camera smooth zoom Gaussian Splatting (ZoomGS), where a camera-specific encoding is introduced to construct a specific 3D model for each virtual camera. With the proposed data factory, we construct a synthetic dataset for DCSZ, and we utilize it to fine-tune FI models. In addition, we collect real-world dual-zoom images without ground-truth for evaluation. Extensive experiments are conducted with multiple FI methods. The results show that the fine-tuned FI models achieve a significant performance improvement over the original ones on DCSZ task. The datasets, codes, and pre-trained models will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "24"
    },
    {
        "paper id": "2404.04922",
        "abstract url": "https://arxiv.org/abs/2404.04922",
        "title": "Efficient Learnable Collaborative Attention for Single Image Super-Resolution",
        "rating": "0",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Non-Local Attention (NLA) is a powerful technique for capturing long-range feature correlations in deep single image super-resolution (SR). However, NLA suffers from high computational complexity and memory consumption, as it requires aggregating all non-local feature information for each query response and recalculating the similarity weight distribution for different abstraction levels of features. To address these challenges, we propose a novel Learnable Collaborative Attention (LCoA) that introduces inductive bias into non-local modeling. Our LCoA consists of two components: Learnable Sparse Pattern (LSP) and Collaborative Attention (CoA). LSP uses the k-means clustering algorithm to dynamically adjust the sparse attention pattern of deep features, which reduces the number of non-local modeling rounds compared with existing sparse solutions. CoA leverages the sparse attention pattern and weights learned by LSP, and co-optimizes the similarity matrix across different abstraction levels, which avoids redundant similarity matrix calculations. The experimental results show that our LCoA can reduce the non-local modeling time by about 83% in the inference stage. In addition, we integrate our LCoA into a deep Learnable Collaborative Attention Network (LCoAN), which achieves competitive performance in terms of inference time, memory consumption, and reconstruction quality compared with other state-of-the-art SR methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04924",
        "abstract url": "https://arxiv.org/abs/2404.04924",
        "title": "GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Vision Transformers (ViTs) have achieved impressive results in large-scale image classification. However, when training from scratch on small datasets, there is still a significant performance gap between ViTs and Convolutional Neural Networks (CNNs), which is attributed to the lack of inductive bias. To address this issue, we propose a Graph-based Vision Transformer (GvT) that utilizes graph convolutional projection and graph-pooling. In each block, queries and keys are calculated through graph convolutional projection based on the spatial adjacency matrix, while dot-product attention is used in another graph convolution to generate values. When using more attention heads, the queries and keys become lower-dimensional, making their dot product an uninformative matching function. To overcome this low-rank bottleneck in attention heads, we employ talking-heads technology based on bilinear pooled features and sparse selection of attention tensors. This allows interaction among filtered attention scores and enables each attention mechanism to depend on all queries and keys. Additionally, we apply graph-pooling between two intermediate blocks to reduce the number of tokens and aggregate semantic information more effectively. Our experimental results show that GvT produces comparable or superior outcomes to deep convolutional networks and surpasses vision transformers without pre-training on large datasets. The code for our proposed model is publicly available on the website.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04946",
        "abstract url": "https://arxiv.org/abs/2404.04946",
        "title": "AnimateZoo: Zero-shot Video Generation of Cross-Species Animation via Subject Alignment",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "video editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent video editing advancements rely on accurate pose sequences to animate subjects. However, these efforts are not suitable for cross-species animation due to pose misalignment between species (for example, the poses of a cat differs greatly from that of a pig due to differences in body structure). In this paper, we present AnimateZoo, a zero-shot diffusion-based video generator to address this challenging cross-species animation issue, aiming to accurately produce animal animations while preserving the background. The key technique used in our AnimateZoo is subject alignment, which includes two steps. First, we improve appearance feature extraction by integrating a Laplacian detail booster and a prompt-tuning identity extractor. These components are specifically designed to capture essential appearance information, including identity and fine details. Second, we align shape features and address conflicts from differing subjects by introducing a scale-information remover. This ensures accurate cross-species animation. Moreover, we introduce two high-quality animal video datasets featuring a wide variety of species. Trained on these extensive datasets, our model is capable of generating videos characterized by accurate movements, consistent appearance, and high-fidelity frames, without the need for the pre-inference fine-tuning that prior arts required. Extensive experiments showcase the outstanding performance of our method in cross-species action following tasks, demonstrating exceptional shape adaptation capability. The project page is available at https://justinxu0.github.io/AnimateZoo/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Technical report,15 pages"
    },
    {
        "paper id": "2404.04947",
        "abstract url": "https://arxiv.org/abs/2404.04947",
        "title": "Gull: A Generative Multifunctional Audio Codec",
        "rating": "0",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We introduce Gull, a generative multifunctional audio codec. Gull is a general purpose neural audio compression and decompression model which can be applied to a wide range of tasks and applications such as real-time communication, audio super-resolution, and codec language models. The key components of Gull include (1) universal-sample-rate modeling via subband modeling schemes motivated by recent progress in audio source separation, (2) gain-shape representations motivated by traditional audio codecs, (3) improved residual vector quantization modules for simpler training, (4) elastic decoder network that enables user-defined model size and complexity during inference time, (5) built-in ability for audio super-resolution without the increase of bitrate. We compare Gull with existing traditional and neural audio codecs and show that Gull is able to achieve on par or better performance across various sample rates, bitrates and model complexities in both subjective and objective evaluation metrics.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.SP"
        ],
        "comment": "Demo page: https://yluo42.github.io/Gull/"
    },
    {
        "paper id": "2404.04969",
        "abstract url": "https://arxiv.org/abs/2404.04969",
        "title": "Temporal Generalization Estimation in Evolving Graphs",
        "rating": "0",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) are widely deployed in vast fields, but they often struggle to maintain accurate representations as graphs evolve. We theoretically establish a lower bound, proving that under mild conditions, representation distortion inevitably occurs over time. To estimate the temporal distortion without human annotation after deployment, one naive approach is to pre-train a recurrent model (e.g., RNN) before deployment and use this model afterwards, but the estimation is far from satisfactory. In this paper, we analyze the representation distortion from an information theory perspective, and attribute it primarily to inaccurate feature extraction during evolution. Consequently, we introduce Smart, a straightforward and effective baseline enhanced by an adaptive feature extractor through self-supervised graph reconstruction. In synthetic random graphs, we further refine the former lower bound to show the inevitable distortion over time and empirically observe that Smart achieves good estimation performance. Moreover, we observe that Smart consistently shows outstanding generalization estimation on four real-world evolving graphs. The ablation studies underscore the necessity of graph reconstruction. For example, on OGB-arXiv dataset, the estimation metric MAPE deteriorates from 2.19% to 8.00% without reconstruction.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Published as a conference paper at ICLR 2024"
    },
    {
        "paper id": "2404.04990",
        "abstract url": "https://arxiv.org/abs/2404.04990",
        "title": "MLaKE: Multilingual Knowledge Editing Benchmark for Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Knowledge Editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The extensive utilization of large language models (LLMs) underscores the crucial necessity for precise and contemporary knowledge embedded within their intrinsic parameters. Existing research on knowledge editing primarily concentrates on monolingual scenarios, neglecting the complexities presented by multilingual contexts and multi-hop reasoning. To address these challenges, our study introduces MLaKE (Multilingual Language Knowledge Editing), a novel benchmark comprising 4072 multi-hop and 5360 single-hop questions designed to evaluate the adaptability of knowledge editing methods across five languages: English, Chinese, Japanese, French, and German. MLaKE aggregates fact chains from Wikipedia across languages and utilizes LLMs to generate questions in both free-form and multiple-choice. We evaluate the multilingual knowledge editing generalization capabilities of existing methods on MLaKE. Existing knowledge editing methods demonstrate higher success rates in English samples compared to other languages. However, their generalization capabilities are limited in multi-language experiments. Notably, existing knowledge editing methods often show relatively high generalization for languages within the same language family compared to languages from different language families. These results underscore the imperative need for advancements in multilingual knowledge editing and we hope MLaKE can serve as a valuable resource for benchmarking and solution development.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04997",
        "abstract url": "https://arxiv.org/abs/2404.04997",
        "title": "Adapting LLMs for Efficient Context Processing through Soft Prompt Compression",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of Large Language Models (LLMs) has inaugurated a transformative epoch in natural language processing, fostering unprecedented proficiency in text generation, comprehension, and contextual scrutiny. Nevertheless, effectively handling extensive contexts, crucial for myriad applications, poses a formidable obstacle owing to the intrinsic constraints of the models' context window sizes and the computational burdens entailed by their operations. This investigation presents an innovative framework that strategically tailors LLMs for streamlined context processing by harnessing the synergies among natural language summarization, soft prompt compression, and augmented utility preservation mechanisms. Our methodology, dubbed SoftPromptComp, amalgamates natural language prompts extracted from summarization methodologies with dynamically generated soft prompts to forge a concise yet semantically robust depiction of protracted contexts. This depiction undergoes further refinement via a weighting mechanism optimizing information retention and utility for subsequent tasks. We substantiate that our framework markedly diminishes computational overhead and enhances LLMs' efficacy across various benchmarks, while upholding or even augmenting the caliber of the produced content. By amalgamating soft prompt compression with sophisticated summarization, SoftPromptComp confronts the dual challenges of managing lengthy contexts and ensuring model scalability. Our findings point towards a propitious trajectory for augmenting LLMs' applicability and efficiency, rendering them more versatile and pragmatic for real-world applications. This research enriches the ongoing discourse on optimizing language models, providing insights into the potency of soft prompts and summarization techniques as pivotal instruments for the forthcoming generation of NLP solutions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "This paper has been accepted by the 2024 International Conference on Image Processing and Computer Applications (IPCA 2024)"
    },
    {
        "paper id": "2404.05052",
        "abstract url": "https://arxiv.org/abs/2404.05052",
        "title": "Facial Affective Behavior Analysis with Instruction Tuning",
        "rating": "0",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial affective behavior analysis (FABA) is crucial for understanding human mental states from images. However, traditional approaches primarily deploy models to discriminate among discrete emotion categories, and lack the fine granularity and reasoning capability for complex facial behaviors. The advent of Multi-modal Large Language Models (MLLMs) has been proven successful in general visual understanding tasks. However, directly harnessing MLLMs for FABA is challenging due to the scarcity of datasets and benchmarks, neglecting facial prior knowledge, and low training efficiency. To address these challenges, we introduce (i) an instruction-following dataset for two FABA tasks, e.g., emotion and action unit recognition, (ii) a benchmark FABA-Bench with a new metric considering both recognition and generation ability, and (iii) a new MLLM \"EmoLA\" as a strong baseline to the community. Our initiative on the dataset and benchmarks reveal the nature and rationale of facial affective behaviors, i.e., fine-grained facial movement, interpretability, and reasoning. Moreover, to build an effective and efficient FABA MLLM, we introduce a facial prior expert module with face structure knowledge and a low-rank adaptation module into pre-trained MLLM. We conduct extensive experiments on FABA-Bench and four commonly-used FABA datasets. The results demonstrate that the proposed facial prior expert can boost the performance and EmoLA achieves the best results on our FABA-Bench. On commonly-used FABA datasets, EmoLA is competitive rivaling task-specific state-of-the-art models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "V1.0"
    },
    {
        "paper id": "2404.05069",
        "abstract url": "https://arxiv.org/abs/2404.05069",
        "title": "AirShot: Efficient Few-Shot Detection for Autonomous Exploration",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot object detection has drawn increasing attention in the field of robotic exploration, where robots are required to find unseen objects with a few online provided examples. Despite recent efforts have been made to yield online processing capabilities, slow inference speeds of low-powered robots fail to meet the demands of real-time detection-making them impractical for autonomous exploration. Existing methods still face performance and efficiency challenges, mainly due to unreliable features and exhaustive class loops. In this work, we propose a new paradigm AirShot, and discover that, by fully exploiting the valuable correlation map, AirShot can result in a more robust and faster few-shot object detection system, which is more applicable to robotics community. The core module Top Prediction Filter (TPF) can operate on multi-scale correlation maps in both the training and inference stages. During training, TPF supervises the generation of a more representative correlation map, while during inference, it reduces looping iterations by selecting top-ranked classes, thus cutting down on computational costs with better performance. Surprisingly, this dual functionality exhibits general effectiveness and efficiency on various off-the-shelf models. Exhaustive experiments on COCO2017, VOC2014, and SubT datasets demonstrate that TPF can significantly boost the efficacy and efficiency of most off-the-shelf models, achieving up to 36.4% precision improvements along with 56.3% faster inference speed. Code and Data are at: https://github.com/ImNotPrepared/AirShot.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05072",
        "abstract url": "https://arxiv.org/abs/2404.05072",
        "title": "Spatial Cognition from Egocentric Video: Out of Sight, Not Out of Mind",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As humans move around, performing their daily tasks, they are able to recall where they have positioned objects in their environment, even if these objects are currently out of sight. In this paper, we aim to mimic this spatial cognition ability. We thus formulate the task of Out of Sight, Not Out of Mind - 3D tracking active objects using observations captured through an egocentric camera. We introduce Lift, Match and Keep (LMK), a method which lifts partial 2D observations to 3D world coordinates, matches them over time using visual appearance, 3D location and interactions to form object tracks, and keeps these object tracks even when they go out-of-view of the camera - hence keeping in mind what is out of sight. We test LMK on 100 long videos from EPIC-KITCHENS. Our results demonstrate that spatial cognition is critical for correctly locating objects over short and long time scales. E.g., for one long egocentric video, we estimate the 3D location of 50 active objects. Of these, 60% can be correctly positioned in 3D after 2 minutes of leaving the camera view.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "21 pages including references and appendix. Project Webpage: http://dimadamen.github.io/OSNOM/"
    },
    {
        "paper id": "2404.05181",
        "abstract url": "https://arxiv.org/abs/2404.05181",
        "title": "Adaptive Learning for Multi-view Stereo Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning has recently demonstrated its excellent performance on the task of multi-view stereo (MVS). However, loss functions applied for deep MVS are rarely studied. In this paper, we first analyze existing loss functions' properties for deep depth based MVS approaches. Regression based loss leads to inaccurate continuous results by computing mathematical expectation, while classification based loss outputs discretized depth values. To this end, we then propose a novel loss function, named adaptive Wasserstein loss, which is able to narrow down the difference between the true and predicted probability distributions of depth. Besides, a simple but effective offset module is introduced to better achieve sub-pixel prediction accuracy. Extensive experiments on different benchmarks, including DTU, Tanks and Temples and BlendedMVS, show that the proposed method with the adaptive Wasserstein loss and the offset module achieves state-of-the-art performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05187",
        "abstract url": "https://arxiv.org/abs/2404.05187",
        "title": "LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating",
        "rating": "0",
        "keywords": [
            [
                "Signed Distance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Implicit reconstruction of ESDF (Euclidean Signed Distance Field) involves training a neural network to regress the signed distance from any point to the nearest obstacle, which has the advantages of lightweight storage and continuous querying. However, existing algorithms usually rely on conflicting raw observations as training data, resulting in poor map performance. In this paper, we propose LGSDF, an ESDF continual Global learning algorithm aided by Local updating. At the front end, axis-aligned grids are dynamically updated by pre-processed sensor observations, where incremental fusion alleviates estimation error caused by limited viewing directions. At the back end, a randomly initialized implicit ESDF neural network performs continual self-supervised learning guided by these grids to generate smooth and continuous maps. The results on multiple scenes show that LGSDF can construct more accurate ESDF maps and meshes compared with SOTA (State Of The Art) explicit and implicit mapping algorithms. The source code of LGSDF is publicly available at https://github.com/BIT-DYN/LGSDF.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04810",
        "abstract url": "https://arxiv.org/abs/2404.04810",
        "title": "AlphaCrystal-II: Distance matrix based crystal structure prediction using deep learning",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Computational prediction of stable crystal structures has a profound impact on the large-scale discovery of novel functional materials. However, predicting the crystal structure solely from a material's composition or formula is a promising yet challenging task, as traditional ab initio crystal structure prediction (CSP) methods rely on time-consuming global searches and first-principles free energy calculations. Inspired by the recent success of deep learning approaches in protein structure prediction, which utilize pairwise amino acid interactions to describe 3D structures, we present AlphaCrystal-II, a novel knowledge-based solution that exploits the abundant inter-atomic interaction patterns found in existing known crystal structures. AlphaCrystal-II predicts the atomic distance matrix of a target crystal material and employs this matrix to reconstruct its 3D crystal structure. By leveraging the wealth of inter-atomic relationships of known crystal structures, our approach demonstrates remarkable effectiveness and reliability in structure prediction through comprehensive experiments. This work highlights the potential of data-driven methods in accelerating the discovery and design of new materials with tailored properties.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2404.04849",
        "abstract url": "https://arxiv.org/abs/2404.04849",
        "title": "Hidden You Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Logic Chain Injection",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Jailbreak attacks on Language Model Models (LLMs) entail crafting prompts aimed at exploiting the models to generate malicious content. Existing jailbreak attacks can successfully deceive the LLMs, however they cannot deceive the human. This paper proposes a new type of jailbreak attacks which can deceive both the LLMs and human (i.e., security analyst). The key insight of our idea is borrowed from the social psychology - that is human are easily deceived if the lie is hidden in truth. Based on this insight, we proposed the logic-chain injection attacks to inject malicious intention into benign truth. Logic-chain injection attack firstly dissembles its malicious target into a chain of benign narrations, and then distribute narrations into a related benign article, with undoubted facts. In this way, newly generate prompt cannot only deceive the LLMs, but also deceive human.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04874",
        "abstract url": "https://arxiv.org/abs/2404.04874",
        "title": "Graph Neural Networks for Binary Programming",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper investigates a link between Graph Neural Networks (GNNs) and Binary Programming (BP) problems, laying the groundwork for GNNs to approximate solutions for these computationally challenging problems. By analyzing the sensitivity of BP problems, we are able to frame the solution of BP problems as a heterophilic node classification task. We then propose Binary-Programming GNN (BPGNN), an architecture that integrates graph representation learning techniques with BP-aware features to approximate BP solutions efficiently. Additionally, we introduce a self-supervised data generation mechanism, to enable efficient and tractable training data acquisition even for large-scale BP problems. Experimental evaluations of BPGNN across diverse BP problem sizes showcase its superior performance compared to exhaustive search and heuristic approaches. Finally, we discuss open challenges in the under-explored field of BP problems with GNNs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04943",
        "abstract url": "https://arxiv.org/abs/2404.04943",
        "title": "Chiplet Placement Order Exploration Based on Learning to Rank with Graph Representation",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Chiplet-based systems, integrating various silicon dies manufactured at different integrated circuit technology nodes on a carrier interposer, have garnered significant attention in recent years due to their cost-effectiveness and competitive performance. The widespread adoption of reinforcement learning as a sequential placement method has introduced a new challenge in determining the optimal placement order for each chiplet. The order in which chiplets are placed on the interposer influences the spatial resources available for earlier and later placed chiplets, making the placement results highly sensitive to the sequence of chiplet placement. To address these challenges, we propose a learning to rank approach with graph representation, building upon the reinforcement learning framework RLPlanner. This method aims to select the optimal chiplet placement order for each chiplet-based system. Experimental results demonstrate that compared to placement order obtained solely based on the descending order of the chiplet area and the number of interconnect wires between the chiplets, utilizing the placement order obtained from the learning to rank network leads to further improvements in system temperature and inter-chiplet wirelength. Specifically, applying the top-ranked placement order obtained from the learning to rank network results in a 10.05% reduction in total inter-chiplet wirelength and a 1.01% improvement in peak system temperature during the chiplet placement process.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR"
        ],
        "comment": "6 pages, 8 figures and 6 tables, accepted by the Conference ISEDA"
    },
    {
        "paper id": "2404.05029",
        "abstract url": "https://arxiv.org/abs/2404.05029",
        "title": "LOGO: A Long-Form Video Dataset for Group Action Quality Assessment",
        "rating": "-0.5",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Action quality assessment (AQA) has become an emerging topic since it can be extensively applied in numerous scenarios. However, most existing methods and datasets focus on single-person short-sequence scenes, hindering the application of AQA in more complex situations. To address this issue, we construct a new multi-person long-form video dataset for action quality assessment named LOGO. Distinguished in scenario complexity, our dataset contains 200 videos from 26 artistic swimming events with 8 athletes in each sample along with an average duration of 204.2 seconds. As for richness in annotations, LOGO includes formation labels to depict group information of multiple athletes and detailed annotations on action procedures. Furthermore, we propose a simple yet effective method to model relations among athletes and reason about the potential temporal logic in long-form videos. Specifically, we design a group-aware attention module, which can be easily plugged into existing AQA methods, to enrich the clip-wise representations based on contextual group information. To benchmark LOGO, we systematically conduct investigations on the performance of several popular methods in AQA and action segmentation. The results reveal the challenges our dataset brings. Extensive experiments also show that our approach achieves state-of-the-art on the LOGO dataset. The dataset and code will be released at \\url{https://github.com/shiyi-zh0408/LOGO }.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2023"
    },
    {
        "paper id": "2404.05057",
        "abstract url": "https://arxiv.org/abs/2404.05057",
        "title": "TimeCSL: Unsupervised Contrastive Learning of General Shapelets for Explorable Time Series Analysis",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised (a.k.a. Self-supervised) representation learning (URL) has emerged as a new paradigm for time series analysis, because it has the ability to learn generalizable time series representation beneficial for many downstream tasks without using labels that are usually difficult to obtain. Considering that existing approaches have limitations in the design of the representation encoder and the learning objective, we have proposed Contrastive Shapelet Learning (CSL), the first URL method that learns the general-purpose shapelet-based representation through unsupervised contrastive learning, and shown its superior performance in several analysis tasks, such as time series classification, clustering, and anomaly detection. In this paper, we develop TimeCSL, an end-to-end system that makes full use of the general and interpretable shapelets learned by CSL to achieve explorable time series analysis in a unified pipeline. We introduce the system components and demonstrate how users interact with TimeCSL to solve different analysis tasks in the unified pipeline, and gain insight into their time series by exploring the learned shapelets and representation.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05769",
        "abstract url": "https://arxiv.org/abs/2404.05769",
        "title": "Dynamic Quality-Diversity Search",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Evolutionary search via the quality-diversity (QD) paradigm can discover highly performing solutions in different behavioural niches, showing considerable potential in complex real-world scenarios such as evolutionary robotics. Yet most QD methods only tackle static tasks that are fixed over time, which is rarely the case in the real world. Unlike noisy environments, where the fitness of an individual changes slightly at every evaluation, dynamic environments simulate tasks where external factors at unknown and irregular intervals alter the performance of the individual with a severity that is unknown a priori. Literature on optimisation in dynamic environments is extensive, yet such environments have not been explored in the context of QD search. This paper introduces a novel and generalisable Dynamic QD methodology that aims to keep the archive of past solutions updated in the case of environment changes. Secondly, we present a novel characterisation of dynamic environments that can be easily applied to well-known benchmarks, with minor interventions to move them from a static task to a dynamic one. Our Dynamic QD intervention is applied on MAP-Elites and CMA-ME, two powerful QD algorithms, and we test the dynamic variants on different dynamic tasks.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": "Parts of this manuscripts are published at The Genetic and Evolutionary Computation Conference (GECCO) 2024"
    },
    {
        "paper id": "2404.15330",
        "abstract url": "https://arxiv.org/abs/2404.15330",
        "title": "Anchor Pair Selection in TDOA Positioning Systems by Door Transition Error Minimization",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents an adaptive anchor pairs selection algorithm for UWB (ultra-wideband) TDOA-based (Time Difference of Arrival) indoor positioning systems. The method assumes dividing the system operation area into zones. The most favorable anchor pairs are selected by minimizing the positioning errors in doorways leading to these zones where possible users' locations are limited to small, narrow areas. The sets are determined separately for going in and out of the zone to take users' body shadowing into account. The determined anchor pairs are then used to calculate TDOA values and localize the user moving around the apartment with an Extended Kalman Filter based algorithm. The method was tested experimentally in a furnished apartment. The results have shown that the adaptive selection of the anchor pairs leads to an increase in the user's localization accuracy. The median trajectory error was about 0.32 m.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "Originally presented at 2022 24th International Microwave and Radar Conference (MIKON), Gdansk, Poland, 2022"
    },
    {
        "paper id": "2404.04818",
        "abstract url": "https://arxiv.org/abs/2404.04818",
        "title": "DWE+: Dual-Way Matching Enhanced Framework for Multimodal Entity Linking",
        "rating": "-1",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal entity linking (MEL) aims to utilize multimodal information (usually textual and visual information) to link ambiguous mentions to unambiguous entities in knowledge base. Current methods facing main issues: (1)treating the entire image as input may contain redundant information. (2)the insufficient utilization of entity-related information, such as attributes in images. (3)semantic inconsistency between the entity in knowledge base and its representation. To this end, we propose DWE+ for multimodal entity linking. DWE+ could capture finer semantics and dynamically maintain semantic consistency with entities. This is achieved by three aspects: (a)we introduce a method for extracting fine-grained image features by partitioning the image into multiple local objects. Then, hierarchical contrastive learning is used to further align semantics between coarse-grained information(text and image) and fine-grained (mention and visual objects). (b)we explore ways to extract visual attributes from images to enhance fusion feature such as facial features and identity. (c)we leverage Wikipedia and ChatGPT to capture the entity representation, achieving semantic enrichment from both static and dynamic perspectives, which better reflects the real-world entity semantics. Experiments on Wikimel, Richpedia, and Wikidiverse datasets demonstrate the effectiveness of DWE+ in improving MEL performance. Specifically, we optimize these datasets and achieve state-of-the-art performance on the enhanced datasets. The code and enhanced datasets are released on https://github.com/season1blue/DWET",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "under review on TOIS. arXiv admin note: substantial text overlap with arXiv:2312.11816"
    },
    {
        "paper id": "2404.04829",
        "abstract url": "https://arxiv.org/abs/2404.04829",
        "title": "Wi-Fi-based Personnel Identity Recognition: Addressing Dataset Imbalance with C-DDPMs",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ]
        ],
        "abstract": "Wireless sensing technologies become increasingly prevalent due to the ubiquitous nature of wireless signals and their inherent privacy-friendly characteristics. Device-free personnel identity recognition, a prevalent application in wireless sensing, is susceptibly challenged by imbalanced channel state information (CSI) datasets. This letter proposes a novel method for CSI dataset augmentation that employs Conditional Denoising Diffusion Probabilistic Models (C-DDPMs) to generate additional samples that address class imbalance issues. The augmentation markedly improves classification accuracies on our homemade dataset, elevating all classes to above 94%.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04847",
        "abstract url": "https://arxiv.org/abs/2404.04847",
        "title": "A many-to-one job market: more about the core and the competitive salaries",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This paper studies many-to-one assignment markets, or matching markets with wages. Although it is well-known that the core of this model is non-empty, the structure of the core has not been fully investigated. To the known dissimilarities with the one-to-one assignment game, we add that the bargaining set does not coincide with the core and the kernel may not be included in the core. Besides, not all extreme core allocations can be obtained by means of a lexicographic maximization or a lexicographic minimization procedure, as it is the case in the one-to-one assignment game. The maximum and minimum competitive salaries are characterized in two ways: axiomatically and by means of easily verifiable properties of an associated directed graph. Regarding the remaining extreme core allocations of the many-to-one assignment game, we propose a lexicographic procedure that, for each order on the set of workers, sequentially maximizes or minimizes each worker's competitive salary. This procedure provides all extreme vectors of competitive salaries, that is all extreme core allocations.",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04857",
        "abstract url": "https://arxiv.org/abs/2404.04857",
        "title": "Learning Adaptive Multi-Objective Robot Navigation with Demonstrations",
        "rating": "-1",
        "keywords": [
            [
                "Robot",
                "Navigation"
            ]
        ],
        "abstract": "Preference-aligned robot navigation in human environments is typically achieved through learning-based approaches, utilizing demonstrations and user feedback for personalization. However, personal preferences are subject to change and might even be context-dependent. Yet traditional reinforcement learning (RL) approaches with a static reward function often fall short in adapting to these varying user preferences. This paper introduces a framework that combines multi-objective reinforcement learning (MORL) with demonstration-based learning. Our approach allows for dynamic adaptation to changing user preferences without retraining. Through rigorous evaluations, including sim-to-real and robot-to-robot transfers, we demonstrate our framework's capability to reflect user preferences accurately while achieving high navigational performance in terms of collision avoidance and goal pursuance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04875",
        "abstract url": "https://arxiv.org/abs/2404.04875",
        "title": "NeRF2Points: Large-Scale Point Cloud Generation From Street Views' Radiance Field Optimization",
        "rating": "-1",
        "keywords": [
            [
                "Point Cloud",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) have emerged as a paradigm-shifting methodology for the photorealistic rendering of objects and environments, enabling the synthesis of novel viewpoints with remarkable fidelity. This is accomplished through the strategic utilization of object-centric camera poses characterized by significant inter-frame overlap. This paper explores a compelling, alternative utility of NeRF: the derivation of point clouds from aggregated urban landscape imagery. The transmutation of street-view data into point clouds is fraught with complexities, attributable to a nexus of interdependent variables. First, high-quality point cloud generation hinges on precise camera poses, yet many datasets suffer from inaccuracies in pose metadata. Also, the standard approach of NeRF is ill-suited for the distinct characteristics of street-view data from autonomous vehicles in vast, open settings. Autonomous vehicle cameras often record with limited overlap, leading to blurring, artifacts, and compromised pavement representation in NeRF-based point clouds. In this paper, we present NeRF2Points, a tailored NeRF variant for urban point cloud synthesis, notable for its high-quality output from RGB inputs alone. Our paper is supported by a bespoke, high-resolution 20-kilometer urban street dataset, designed for point cloud generation and evaluation. NeRF2Points adeptly navigates the inherent challenges of NeRF-based point cloud synthesis through the implementation of the following strategic innovations: (1) Integration of Weighted Iterative Geometric Optimization (WIGO) and Structure from Motion (SfM) for enhanced camera pose accuracy, elevating street-view data precision. (2) Layered Perception and Integrated Modeling (LPiM) is designed for distinct radiance field modeling in urban environments, resulting in coherent point cloud representations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2404.04884",
        "abstract url": "https://arxiv.org/abs/2404.04884",
        "title": "LRNet: Change detection of high-resolution remote sensing imagery via strategy of localization-then-refinement",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Change detection, as a research hotspot in the field of remote sensing, has witnessed continuous development and progress. However, the discrimination of boundary details remains a significant bottleneck due to the complexity of surrounding elements between change areas and backgrounds. Discriminating the boundaries of large change areas results in misalignment, while connecting boundaries occurs for small change targets. To address the above issues, a novel network based on the localization-then-refinement strategy is proposed in this paper, namely LRNet. LRNet consists of two stages: localization and refinement. In the localization stage, a three-branch encoder simultaneously extracts original image features and their differential features for interactive localization of the position of each change area. To minimize information loss during feature extraction, learnable optimal pooling (LOP) is proposed to replace the widely used max-pooling. Additionally, this process is trainable and contributes to the overall optimization of the network. To effectively interact features from different branches and accurately locate change areas of various sizes, change alignment attention (C2A) and hierarchical change alignment module (HCA) are proposed. In the refinement stage, the localization results from the localization stage are corrected by constraining the change areas and change edges through the edge-area alignment module (E2A). Subsequently, the decoder, combined with the difference features strengthened by C2A in the localization phase, refines change areas of different sizes, ultimately achieving accurate boundary discrimination of change areas. The proposed LRNet outperforms 13 other state-of-the-art methods in terms of comprehensive evaluation metrics and provides the most precise boundary discrimination results on the LEVIR-CD and WHU-CD datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 11 figures"
    },
    {
        "paper id": "2404.04887",
        "abstract url": "https://arxiv.org/abs/2404.04887",
        "title": "A Clinical-oriented Multi-level Contrastive Learning Method for Disease Diagnosis in Low-quality Medical Images",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Diagnosis",
                "X-ray",
                "Disease",
                "Clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Representation learning offers a conduit to elucidate distinctive features within the latent space and interpret the deep models. However, the randomness of lesion distribution and the complexity of low-quality factors in medical images pose great challenges for models to extract key lesion features. Disease diagnosis methods guided by contrastive learning (CL) have shown significant advantages in lesion feature representation. Nevertheless, the effectiveness of CL is highly dependent on the quality of the positive and negative sample pairs. In this work, we propose a clinical-oriented multi-level CL framework that aims to enhance the model's capacity to extract lesion features and discriminate between lesion and low-quality factors, thereby enabling more accurate disease diagnosis from low-quality medical images. Specifically, we first construct multi-level positive and negative pairs to enhance the model's comprehensive recognition capability of lesion features by integrating information from different levels and qualities of medical images. Moreover, to improve the quality of the learned lesion embeddings, we introduce a dynamic hard sample mining method based on self-paced learning. The proposed CL framework is validated on two public medical image datasets, EyeQ and Chest X-ray, demonstrating superior performance compared to other state-of-the-art disease diagnostic methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04890",
        "abstract url": "https://arxiv.org/abs/2404.04890",
        "title": "A Unified Diffusion Framework for Scene-aware Human Motion Estimation from Sparse Signals",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Estimating full-body human motion via sparse tracking signals from head-mounted displays and hand controllers in 3D scenes is crucial to applications in AR/VR. One of the biggest challenges to this task is the one-to-many mapping from sparse observations to dense full-body motions, which endowed inherent ambiguities. To help resolve this ambiguous problem, we introduce a new framework to combine rich contextual information provided by scenes to benefit full-body motion tracking from sparse observations. To estimate plausible human motions given sparse tracking signals and 3D scenes, we develop $\\text{S}^2$Fusion, a unified framework fusing \\underline{S}cene and sparse \\underline{S}ignals with a conditional dif\\underline{Fusion} model. $\\text{S}^2$Fusion first extracts the spatial-temporal relations residing in the sparse signals via a periodic autoencoder, and then produces time-alignment feature embedding as additional inputs. Subsequently, by drawing initial noisy motion from a pre-trained prior, $\\text{S}^2$Fusion utilizes conditional diffusion to fuse scene geometry and sparse tracking signals to generate full-body scene-aware motions. The sampling procedure of $\\text{S}^2$Fusion is further guided by a specially designed scene-penetration loss and phase-matching loss, which effectively regularizes the motion of the lower body even in the absence of any tracking signals, making the generated motion much more plausible and coherent. Extensive experimental results have demonstrated that our $\\text{S}^2$Fusion outperforms the state-of-the-art in terms of estimation quality and smoothness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04898",
        "abstract url": "https://arxiv.org/abs/2404.04898",
        "title": "Graph Neural Network Meets Multi-Agent Reinforcement Learning: Fundamentals, Applications, and Future Directions",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Multi-agent reinforcement learning (MARL) has become a fundamental component of next-generation wireless communication systems. Theoretically, although MARL has the advantages of low computational complexity and fast convergence rate, there exist several challenges including partial observability, non-stationary, and scalability. In this article, we investigate a novel MARL with graph neural network-aided communication (GNNComm-MARL) to address the aforementioned challenges by making use of graph attention networks to effectively sample neighborhoods and selectively aggregate messages. Furthermore, we thoroughly study the architecture of GNNComm-MARL and present a systematic design solution. We then present the typical applications of GNNComm-MARL from two aspects: resource allocation and mobility management. The results obtained unveil that GNNComm-MARL can achieve better performance with lower communication overhead compared to conventional communication schemes. Finally, several important research directions regarding GNNComm-MARL are presented to facilitate further investigation.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04910",
        "abstract url": "https://arxiv.org/abs/2404.04910",
        "title": "MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D Object Detection",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular 3D object detection (Mono3D) is an indispensable research topic in autonomous driving, thanks to the cost-effective monocular camera sensors and its wide range of applications. Since the image perspective has depth ambiguity, the challenges of Mono3D lie in understanding 3D scene geometry and reconstructing 3D object information from a single image. Previous methods attempted to transfer 3D information directly from the LiDAR-based teacher to the camera-based student. However, a considerable gap in feature representation makes direct cross-modal distillation inefficient, resulting in a significant performance deterioration between the LiDAR-based teacher and the camera-based student. To address this issue, we propose the Teaching Assistant Knowledge Distillation (MonoTAKD) to break down the learning objective by integrating intra-modal distillation with cross-modal residual distillation. In particular, we employ a strong camera-based teaching assistant model to distill powerful visual knowledge effectively through intra-modal distillation. Subsequently, we introduce the cross-modal residual distillation to transfer the 3D spatial cues. By acquiring both visual knowledge and 3D spatial cues, the predictions of our approach are rigorously evaluated on the KITTI 3D object detection benchmark and achieve state-of-the-art performance in Mono3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2404.04913",
        "abstract url": "https://arxiv.org/abs/2404.04913",
        "title": "CodecNeRF: Toward Fast Encoding and Decoding, Compact, and High-quality Novel-view Synthesis",
        "rating": "-1",
        "keywords": [
            [
                "parameter-efficient",
                "efficient finetuning"
            ],
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "neural codec"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) have achieved huge success in effectively capturing and representing 3D objects and scenes. However, several factors have impeded its further proliferation as next-generation 3D media. To establish a ubiquitous presence in everyday media formats, such as images and videos, it is imperative to devise a solution that effectively fulfills three key objectives: fast encoding and decoding time, compact model sizes, and high-quality renderings. Despite significant advancements, a comprehensive algorithm that adequately addresses all objectives has yet to be fully realized. In this work, we present CodecNeRF, a neural codec for NeRF representations, consisting of a novel encoder and decoder architecture that can generate a NeRF representation in a single forward pass. Furthermore, inspired by the recent parameter-efficient finetuning approaches, we develop a novel finetuning method to efficiently adapt the generated NeRF representations to a new test instance, leading to high-quality image renderings and compact code sizes. The proposed CodecNeRF, a newly suggested encoding-decoding-finetuning pipeline for NeRF, achieved unprecedented compression performance of more than 150x and 20x reduction in encoding time while maintaining (or improving) the image quality on widely used 3D object datasets, such as ShapeNet and Objaverse.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "34 pages, 22 figures, Project page: https://gynjn.github.io/Codec-NeRF/"
    },
    {
        "paper id": "2404.04929",
        "abstract url": "https://arxiv.org/abs/2404.04929",
        "title": "RoboMP$^2$: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "robotic manipulation"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive reasoning abilities and general intelligence in various domains. It inspires researchers to train end-to-end MLLMs or utilize large models to generate policies with human-selected prompts for embodied agents. However, these methods exhibit limited generalization capabilities on unseen tasks or scenarios, and overlook the multimodal environment information which is critical for robots to make decisions. In this paper, we introduce a novel Robotic Multimodal Perception-Planning (RoboMP$^2$) framework for robotic manipulation which consists of a Goal-Conditioned Multimodal Preceptor (GCMP) and a Retrieval-Augmented Multimodal Planner (RAMP). Specially, GCMP captures environment states by employing a tailored MLLMs for embodied agents with the abilities of semantic reasoning and localization. RAMP utilizes coarse-to-fine retrieval method to find the $k$ most-relevant policies as in-context demonstrations to enhance the planner. Extensive experiments demonstrate the superiority of RoboMP$^2$ on both VIMA benchmark and real-world tasks, with around 10% improvement over the baselines.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Project page: https://aopolin-lv.github.io/RoboMP2.github.io/"
    },
    {
        "paper id": "2404.04948",
        "abstract url": "https://arxiv.org/abs/2404.04948",
        "title": "Iniva: Inclusive and Incentive-compatible Vote Aggregation",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Many blockchain platforms use committee-based consensus for scalability, finality, and security. In this consensus scheme, a committee decides which blocks get appended to the chain, typically through several voting phases. Platforms typically leverage the committee members' recorded votes to reward, punish, or detect failures. A common approach is to let the block proposer decide which votes to include, opening the door to possible attacks. For example, a malicious proposer can omit votes from targeted committee members, resulting in lost profits and, ultimately, their departure from the system. This paper presents Iniva, an inclusive and incentive-compatible vote aggregation scheme that prevents such vote omission attacks. Iniva relies on a tree overlay with carefully selected fallback paths, making it robust against process failures without needing reconfiguration or additional redundancy. Our analysis shows that Iniva significantly reduces the chance to omit individual votes while ensuring that omitting many votes incurs a significant cost. In addition, our experimental results show that Iniva enjoys robustness, scalability, and reasonable throughput.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": "Committee-based blockchains, Vote omission attack, Vote inclusion, Signature aggregation, Incentive-compatible"
    },
    {
        "paper id": "2404.04963",
        "abstract url": "https://arxiv.org/abs/2404.04963",
        "title": "SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical",
                "medical",
                "healthcare",
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are at the forefront of NLP achievements but fall short in dealing with shortcut learning, factual inconsistency, and vulnerability to adversarial inputs.These shortcomings are especially critical in medical contexts, where they can misrepresent actual model capabilities. Addressing this, we present SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for ClinicalTrials. Our contributions include the refined NLI4CT-P dataset (i.e., Natural Language Inference for Clinical Trials - Perturbed), designed to challenge LLMs with interventional and causal reasoning tasks, along with a comprehensive evaluation of methods and results for participant submissions. A total of 106 participants registered for the task contributing to over 1200 individual submissions and 25 system overview papers. This initiative aims to advance the robustness and applicability of NLI models in healthcare, ensuring safer and more dependable AI assistance in clinical decision-making. We anticipate that the dataset, models, and outcomes of this task can support future research in the field of biomedical NLI. The dataset, competition leaderboard, and website are publicly available.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04973",
        "abstract url": "https://arxiv.org/abs/2404.04973",
        "title": "Nanometer Scanning with Micrometer Sensing: Beating Quantization Constraints in Lissajous Trajectory Tracking",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "This paper addresses the task of tracking Lissajous trajectories in the presence of quantized positioning sensors. To do so, theoretical results on tracking of continuous time periodic signals in the presence of output quantization are provided. With these results in hand, the application to Lissajous tracking is explored. The method proposed relies on the internal model principle and dispenses perfect knowledge of the system equations. Numerical results show that an arbitrary small scanning resolution is achievable despite large sensor quantization intervals.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04983",
        "abstract url": "https://arxiv.org/abs/2404.04983",
        "title": "Primary liver cancer classification from routine tumour biopsy using weakly supervised deep learning",
        "rating": "-1",
        "keywords": [
            [
                "biopsy",
                "diagnosis",
                "whole-slide",
                "cancer",
                "pathological"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The diagnosis of primary liver cancers (PLCs) can be challenging, especially on biopsies and for combined hepatocellular-cholangiocarcinoma (cHCC-CCA). We automatically classified PLCs on routine-stained biopsies using a weakly supervised learning method. Weak tumour/non-tumour annotations served as labels for training a Resnet18 neural network, and the network's last convolutional layer was used to extract new tumour tile features. Without knowledge of the precise labels of the malignancies, we then applied an unsupervised clustering algorithm. Our model identified specific features of hepatocellular carcinoma (HCC) and intrahepatic cholangiocarcinoma (iCCA). Despite no specific features of cHCC-CCA being recognized, the identification of HCC and iCCA tiles within a slide could facilitate the diagnosis of primary liver cancers, particularly cHCC-CCA. Method and results: 166 PLC biopsies were divided into training, internal and external validation sets: 90, 29 and 47 samples. Two liver pathologists reviewed each whole-slide hematein eosin saffron (HES)-stained image (WSI). After annotating the tumour/non-tumour areas, 256x256 pixel tiles were extracted from the WSIs and used to train a ResNet18. The network was used to extract new tile features. An unsupervised clustering algorithm was then applied to the new tile features. In a two-cluster model, Clusters 0 and 1 contained mainly HCC and iCCA histological features. The diagnostic agreement between the pathological diagnosis and the model predictions in the internal and external validation sets was 100% (11/11) and 96% (25/26) for HCC and 78% (7/9) and 87% (13/15) for iCCA, respectively. For cHCC-CCA, we observed a highly variable proportion of tiles from each cluster (Cluster 0: 5-97%; Cluster 1: 2-94%).",
        "subjects": [
            "q-bio.TO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "https://www.sciencedirect.com/science/article/pii/S2589555924000090"
    },
    {
        "paper id": "2404.04987",
        "abstract url": "https://arxiv.org/abs/2404.04987",
        "title": "Chromatic number in $1.9999^n$ time? Fast deterministic set partitioning under the asymptotic rank conjecture",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper we further explore the recently discovered connection by Bj\u00f6rklund and Kaski [STOC 2024] and Pratt [STOC 2024] between the asymptotic rank conjecture of Strassen [Progr. Math. 1994] and the three-way partitioning problem. We show that under the asymptotic rank conjecture, the chromatic number of an $n$-vertex graph can be computed deterministically in $O(1.99982^n)$ time, thus giving a conditional answer to a question of Zamir [ICALP 2021], and questioning the optimality of the $2^n\\operatorname{poly}(n)$ time algorithm for chromatic number by Bj\u00f6rklund, Husfeldt, and Koivisto [SICOMP 2009]. Our technique is a combination of earlier algorithms for detecting $k$-colorings for small $k$ and enumerating $k$-colorable subgraphs, with an extension and derandomisation of Pratt's tensor-based algorithm for balanced three-way partitioning to the unbalanced case.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04992",
        "abstract url": "https://arxiv.org/abs/2404.04992",
        "title": "Efficient Surgical Tool Recognition via HMM-Stabilized Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "Surgical",
                "surgery",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recognizing various surgical tools, actions and phases from surgery videos is an important problem in computer vision with exciting clinical applications. Existing deep-learning-based methods for this problem either process each surgical video as a series of independent images without considering their dependence, or rely on complicated deep learning models to count for dependence of video frames. In this study, we revealed from exploratory data analysis that surgical videos enjoy relatively simple semantic structure, where the presence of surgical phases and tools can be well modeled by a compact hidden Markov model (HMM). Based on this observation, we propose an HMM-stabilized deep learning method for tool presence detection. A wide range of experiments confirm that the proposed approaches achieve better performance with lower training and running costs, and support more flexible ways to construct and utilize training data in scenarios where not all surgery videos of interest are extensively labelled. These results suggest that popular deep learning approaches with over-complicated model structures may suffer from inefficient utilization of data, and integrating ingredients of deep learning and statistical learning wisely may lead to more powerful algorithms that enjoy competitive performance, transparent interpretation and convenient model training simultaneously.",
        "subjects": [
            "cs.CV",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05008",
        "abstract url": "https://arxiv.org/abs/2404.05008",
        "title": "Minimax Least-Square Policy Iteration for Cost-Aware Defense of Traffic Routing against Unknown Threats",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Dynamic routing is one of the representative control scheme in transportation, production lines, and data transmission. In the modern context of connectivity and autonomy, routing decisions are potentially vulnerable to malicious attacks. In this paper, we consider the dynamic routing problem over parallel traffic links in the face of such threats. An attacker is capable of increasing or destabilizing traffic queues by strategic manipulating the nominally optimal routing decisions. A defender is capable of securing the correct routing decision. Attacking and defensive actions induce technological costs. The defender has no prior information about the attacker's strategy. We develop an least-square policy iteration algorithm for the defender to compute a cost-aware and threat-adaptive defensive strategy. The policy evaluation step computes a weight vector that minimizes the sampled temporal-difference error. We derive a concrete theoretical upper bound on the evaluation error based on the theory of value function approximation. The policy improvement step solves a minimax problem and thus iteratively computes the Markov perfect equilibrium of the security game. We also discuss the training error of the entire policy iteration process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2404.05012",
        "abstract url": "https://arxiv.org/abs/2404.05012",
        "title": "Towards Reliable and Empathetic Depression-Diagnosis-Oriented Chats",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "Diagnosis"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Chatbots can serve as a viable tool for preliminary depression diagnosis via interactive conversations with potential patients. Nevertheless, the blend of task-oriented and chit-chat in diagnosis-related dialogues necessitates professional expertise and empathy. Such unique requirements challenge traditional dialogue frameworks geared towards single optimization goals. To address this, we propose an innovative ontology definition and generation framework tailored explicitly for depression diagnosis dialogues, combining the reliability of task-oriented conversations with the appeal of empathy-related chit-chat. We further apply the framework to D$^4$, the only existing public dialogue dataset on depression diagnosis-oriented chats. Exhaustive experimental results indicate significant improvements in task completion and emotional support generation in depression diagnosis, fostering a more comprehensive approach to task-oriented chat dialogue system development and its applications in digital mental health.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05022",
        "abstract url": "https://arxiv.org/abs/2404.05022",
        "title": "DinoBloom: A Foundation Model for Generalizable Cell Embeddings in Hematology",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In hematology, computational models offer significant potential to improve diagnostic accuracy, streamline workflows, and reduce the tedious work of analyzing single cells in peripheral blood or bone marrow smears. However, clinical adoption of computational models has been hampered by the lack of generalization due to large batch effects, small dataset sizes, and poor performance in transfer learning from natural images. To address these challenges, we introduce DinoBloom, the first foundation model for single cell images in hematology, utilizing a tailored DINOv2 pipeline. Our model is built upon an extensive collection of 13 diverse, publicly available datasets of peripheral blood and bone marrow smears, the most substantial open-source cohort in hematology so far, comprising over 380,000 white blood cell images. To assess its generalization capability, we evaluate it on an external dataset with a challenging domain shift. We show that our model outperforms existing medical and non-medical vision models in (i) linear probing and k-nearest neighbor evaluations for cell-type classification on blood and bone marrow smears and (ii) weakly supervised multiple instance learning for acute myeloid leukemia subtyping by a large margin. A family of four DinoBloom models (small, base, large, and giant) can be adapted for a wide range of downstream applications, be a strong baseline for classification problems, and facilitate the assessment of batch effects in new datasets. All models are available at github.com/marrlab/DinoBloom.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05039",
        "abstract url": "https://arxiv.org/abs/2404.05039",
        "title": "StaccaToe: A Single-Leg Robot that Mimics the Human Leg and Toe",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "We introduce StaccaToe, a human-scale, electric motor-powered single-leg robot designed to rival the agility of human locomotion through two distinctive attributes: an actuated toe and a co-actuation configuration inspired by the human leg. Leveraging the foundational design of HyperLeg's lower leg mechanism, we develop a stand-alone robot by incorporating new link designs, custom-designed power electronics, and a refined control system. Unlike previous jumping robots that rely on either special mechanisms (e.g., springs and clutches) or hydraulic/pneumatic actuators, StaccaToe employs electric motors without energy storage mechanisms. This choice underscores our ultimate goal of developing a practical, high-performance humanoid robot capable of human-like, stable walking as well as explosive dynamic movements. In this paper, we aim to empirically evaluate the balance capability and the exertion of explosive ground reaction forces of our toe and co-actuation mechanisms. Throughout extensive hardware and controller development, StaccaToe showcases its control fidelity by demonstrating a balanced tip-toe stance and dynamic jump. This study is significant for three key reasons: 1) StaccaToe represents the first human-scale, electric motor-driven single-leg robot to execute dynamic maneuvers without relying on specialized mechanisms; 2) our research provides empirical evidence of the benefits of replicating critical human leg attributes in robotic design; and 3) we explain the design process for creating agile legged robots, the details that have been scantily covered in academic literature.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)"
    },
    {
        "paper id": "2404.05049",
        "abstract url": "https://arxiv.org/abs/2404.05049",
        "title": "PlateSegFL: A Privacy-Preserving License Plate Detection Using Federated Segmentation Learning",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic License Plate Recognition (ALPR) is an integral component of an intelligent transport system with extensive applications in secure transportation, vehicle-to-vehicle communication, stolen vehicles detection, traffic violations, and traffic flow management. The existing license plate detection system focuses on one-shot learners or pre-trained models that operate with a geometric bounding box, limiting the model's performance. Furthermore, continuous video data streams uploaded to the central server result in network and complexity issues. To combat this, PlateSegFL was introduced, which implements U-Net-based segmentation along with Federated Learning (FL). U-Net is well-suited for multi-class image segmentation tasks because it can analyze a large number of classes and generate a pixel-level segmentation map for each class. Federated Learning is used to reduce the quantity of data required while safeguarding the user's privacy. Different computing platforms, such as mobile phones, are able to collaborate on the development of a standard prediction model where it makes efficient use of one's time; incorporates more diverse data; delivers projections in real-time; and requires no physical effort from the user; resulting around 95% F1 score.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05050",
        "abstract url": "https://arxiv.org/abs/2404.05050",
        "title": "Co-design Accessible Public Robots: Insights from People with Mobility Disability, Robotic Practitioners and Their Collaborations",
        "rating": "-1",
        "keywords": [
            [
                "robotics"
            ]
        ],
        "abstract": "Sidewalk robots are increasingly common across the globe. Yet, their operation on public paths poses challenges for people with mobility disabilities (PwMD) who face barriers to accessibility, such as insufficient curb cuts. We interviewed 15 PwMD to understand how they perceive sidewalk robots. Findings indicated that PwMD feel they have to compete for space on the sidewalk when robots are introduced. We next interviewed eight robotics practitioners to learn about their attitudes towards accessibility. Practitioners described how issues often stem from robotic companies addressing accessibility only after problems arise. Both interview groups underscored the importance of integrating accessibility from the outset. Building on this finding, we held four co-design workshops with PwMD and practitioners in pairs. These convenings brought to bear accessibility needs around robots operating in public spaces and in the public interest. Our study aims to set the stage for a more inclusive future around public service robots.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05063",
        "abstract url": "https://arxiv.org/abs/2404.05063",
        "title": "AUEditNet: Dual-Branch Facial Action Unit Intensity Manipulation with Implicit Disentanglement",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial action unit (AU) intensity plays a pivotal role in quantifying fine-grained expression behaviors, which is an effective condition for facial expression manipulation. However, publicly available datasets containing intensity annotations for multiple AUs remain severely limited, often featuring a restricted number of subjects. This limitation places challenges to the AU intensity manipulation in images due to disentanglement issues, leading researchers to resort to other large datasets with pretrained AU intensity estimators for pseudo labels. In addressing this constraint and fully leveraging manual annotations of AU intensities for precise manipulation, we introduce AUEditNet. Our proposed model achieves impressive intensity manipulation across 12 AUs, trained effectively with only 18 subjects. Utilizing a dual-branch architecture, our approach achieves comprehensive disentanglement of facial attributes and identity without necessitating additional loss functions or implementing with large batch sizes. This approach offers a potential solution to achieve desired facial attribute editing despite the dataset's limited subject count. Our experiments demonstrate AUEditNet's superior accuracy in editing AU intensities, affirming its capability in disentangling facial attributes and identity within a limited subject pool. AUEditNet allows conditioning by either intensity values or target images, eliminating the need for constructing AU combinations for specific facial expression synthesis. Moreover, AU intensity estimation, as a downstream task, validates the consistency between real and edited images, confirming the effectiveness of our proposed AU intensity manipulation method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05070",
        "abstract url": "https://arxiv.org/abs/2404.05070",
        "title": "STAIC regularization for spatio-temporal image reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "image restoration"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "We propose a regularization-based image restoration scheme for 2D images recorded over time (2D+t). We design an infimal convolution-based regularization function which we call spatio-temporal Adaptive Infimal Convolution (STAIC) regularization. We formulate the infimal convolution in the form of an additive decomposition of the 2D+t image such that the extent of spatial and temporal smoothing is controlled in a spatially and temporally varying manner. This makes the regularization adaptable to the local characteristics of the motion leading to an improved ability to handle noise. We also develop a minimization method for image reconstruction by using the proposed form of regularization. We demonstrate the effectiveness of the proposed regularization using TIRF images recorded over time and compare with some selected existing regularizations.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05073",
        "abstract url": "https://arxiv.org/abs/2404.05073",
        "title": "QRscript: Embedding a Programming Language in QR codes to support Decision and Management",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Embedding a programming language in a QR code is a new and extremely promising opportunity, as it makes devices and objects smarter without necessarily requiring an Internet connection. In this paper, all the steps needed to translate a program written in a high-level programming language to its binary representation encoded in a QR code, and the opposite process that, starting from the QR code, executes it by means of a virtual machine, have been carefully detailed. The proposed programming language was named QRscript, and can be easily extended so as to integrate new features. One of the main design goals was to produce a very compact target binary code. In particular, in this work we propose a specific sub-language (a dialect) that is aimed at encoding decision trees. Besides industrial scenarios, this is useful in many other application fields. The reported example, related to the configuration of an industrial networked device, highlights the potential of the proposed technology, and permits to better understand all the translation steps.",
        "subjects": [
            "cs.NI",
            "cs.CL"
        ],
        "comment": "preprint, 8 pages"
    },
    {
        "paper id": "2404.05087",
        "abstract url": "https://arxiv.org/abs/2404.05087",
        "title": "PCBot: a Minimalist Robot Designed for Swarm Applications",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Complexity, cost, and power requirements for the actuation of individual robots can play a large factor in limiting the size of robotic swarms. Here we present PCBot, a minimalist robot that can precisely move on an orbital shake table using a bi-stable solenoid actuator built directly into its PCB. This allows the actuator to be built as part of the automated PCB manufacturing process, greatly reducing the impact it has on manual assembly. Thanks to this novel actuator design, PCBot has merely five major components and can be assembled in under 20 seconds, potentially enabling them to be easily mass-manufactured. Here we present the electro-magnetic and mechanical design of PCBot. Additionally, a prototype robot is used to demonstrate its ability to move in a straight line as well as follow given paths.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted by IROS 2022, best paper and best mechanism design paper finalist"
    },
    {
        "paper id": "2404.05100",
        "abstract url": "https://arxiv.org/abs/2404.05100",
        "title": "Legibot: Generating Legible Motions for Service Robots Using Cost-Based Local Planners",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "With the increasing presence of social robots in various environments and applications, there is an increasing need for these robots to exhibit socially-compliant behaviors. Legible motion, characterized by the ability of a robot to clearly and quickly convey intentions and goals to the individuals in its vicinity, through its motion, holds significant importance in this context. This will improve the overall user experience and acceptance of robots in human environments. In this paper, we introduce a novel approach to incorporate legibility into local motion planning for mobile robots. This can enable robots to generate legible motions in real-time and dynamic environments. To demonstrate the effectiveness of our proposed methodology, we also provide a robotic stack designed for deploying legibility-aware motion planning in a social robot, by integrating perception and localization components.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05102",
        "abstract url": "https://arxiv.org/abs/2404.05102",
        "title": "LHU-Net: A Light Hybrid U-Net for Cost-Efficient, High-Performance Volumetric Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "As a result of the rise of Transformer architectures in medical image analysis, specifically in the domain of medical image segmentation, a multitude of hybrid models have been created that merge the advantages of Convolutional Neural Networks (CNNs) and Transformers. These hybrid models have achieved notable success by significantly improving segmentation accuracy. Yet, this progress often comes at the cost of increased model complexity, both in terms of parameters and computational demand. Moreover, many of these models fail to consider the crucial interplay between spatial and channel features, which could further refine and improve segmentation outcomes. To address this, we introduce LHU-Net, a Light Hybrid U-Net architecture optimized for volumetric medical image segmentation. LHU-Net is meticulously designed to prioritize spatial feature analysis in its initial layers before shifting focus to channel-based features in its deeper layers, ensuring a comprehensive feature extraction process. Rigorous evaluation across five benchmark datasets - Synapse, LA, Pancreas, ACDC, and BRaTS 2018 - underscores LHU-Net's superior performance, showcasing its dual capacity for efficiency and accuracy. Notably, LHU-Net sets new performance benchmarks, such as attaining a Dice score of 92.66 on the ACDC dataset, while simultaneously reducing parameters by 85% and quartering the computational load compared to existing state-of-the-art models. Achieved without any reliance on pre-training, additional data, or model ensemble, LHU-Net's effectiveness is further evidenced by its state-of-the-art performance across all evaluated datasets, utilizing fewer than 11 million parameters. This achievement highlights that balancing computational efficiency with high accuracy in medical image segmentation is feasible. Our implementation of LHU-Net is freely accessible to the research community on GitHub.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05106",
        "abstract url": "https://arxiv.org/abs/2404.05106",
        "title": "Stop Stealing My Data: Sanitizing Stego Channels in 3D Printing Design Files",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The increased adoption of additive manufacturing (AM) and the acceptance of AM outsourcing created an ecosystem in which the sending and receiving of digital designs by different actors became normal. It has recently been shown that the STL design files -- most commonly used in AM -- contain steganographic channels. Such channels can allow additional data to be embedded within the STL files without changing the printed model. These factors create a threat of misusing the design files as a covert communication channel to either exfiltrate stolen sensitive digital data from organizations or infiltrate malicious software into a secure environment. This paper addresses this security threat by designing and evaluating a \\emph{sanitizer} that erases hidden content where steganographic channels might exist. The proposed sanitizer takes into account a set of specific constraints imposed by the application domain, such as not affecting the ability to manufacture part of the required quality using the sanitized design.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "CODASPY'24"
    },
    {
        "paper id": "2404.05116",
        "abstract url": "https://arxiv.org/abs/2404.05116",
        "title": "Nanouniverse: Virtual Instancing of Structural Detail and Adaptive Shell Mapping",
        "rating": "-1",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Rendering huge biological scenes with atomistic detail presents a significant challenge in molecular visualization due to the memory limitations inherent in traditional rendering approaches. In this paper, we propose a novel method for the interactive rendering of massive molecular scenes based on hardware-accelerated ray tracing. Our approach circumvents GPU memory constraints by introducing virtual instantiation of full-detail scene elements. Using instancing significantly reduces memory consumption while preserving the full atomistic detail of scenes comprising trillions of atoms, with interactive rendering performance and completely free user exploration. We utilize coarse meshes as proxy geometries to approximate the overall shape of biological compartments, and access all atomistic detail dynamically during ray tracing. We do this via a novel adaptive technique utilizing a volumetric shell layer of prisms extruded around proxy geometry triangles, and a virtual volume grid for the interior of each compartment. Our algorithm scales to enormous molecular scenes with minimal memory consumption and the potential to accommodate even larger scenes. Our method also supports advanced effects such as clipping planes and animations. We demonstrate the efficiency and scalability of our approach by rendering tens of instances of Red Blood Cell and SARS-CoV-2 models theoretically containing more than 20 trillion atoms.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05139",
        "abstract url": "https://arxiv.org/abs/2404.05139",
        "title": "Better Monocular 3D Detectors with LiDAR from the Past",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate 3D object detection is crucial to autonomous driving. Though LiDAR-based detectors have achieved impressive performance, the high cost of LiDAR sensors precludes their widespread adoption in affordable vehicles. Camera-based detectors are cheaper alternatives but often suffer inferior performance compared to their LiDAR-based counterparts due to inherent depth ambiguities in images. In this work, we seek to improve monocular 3D detectors by leveraging unlabeled historical LiDAR data. Specifically, at inference time, we assume that the camera-based detectors have access to multiple unlabeled LiDAR scans from past traversals at locations of interest (potentially from other high-end vehicles equipped with LiDAR sensors). Under this setup, we proposed a novel, simple, and end-to-end trainable framework, termed AsyncDepth, to effectively extract relevant features from asynchronous LiDAR traversals of the same location for monocular 3D detectors. We show consistent and significant performance gain (up to 9 AP) across multiple state-of-the-art models and datasets with a negligible additional latency of 9.66 ms and a small storage cost.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted by ICRA 2024. The code can be found at https://github.com/YurongYou/AsyncDepth"
    },
    {
        "paper id": "2404.05144",
        "abstract url": "https://arxiv.org/abs/2404.05144",
        "title": "Enhancing Clinical Efficiency through LLM: Discharge Note Generation for Cardiac Patients",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare",
                "Clinical",
                "Cardiac"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Medical documentation, including discharge notes, is crucial for ensuring patient care quality, continuity, and effective medical communication. However, the manual creation of these documents is not only time-consuming but also prone to inconsistencies and potential errors. The automation of this documentation process using artificial intelligence (AI) represents a promising area of innovation in healthcare. This study directly addresses the inefficiencies and inaccuracies in creating discharge notes manually, particularly for cardiac patients, by employing AI techniques, specifically large language model (LLM). Utilizing a substantial dataset from a cardiology center, encompassing wide-ranging medical records and physician assessments, our research evaluates the capability of LLM to enhance the documentation process. Among the various models assessed, Mistral-7B distinguished itself by accurately generating discharge notes that significantly improve both documentation efficiency and the continuity of care for patients. These notes underwent rigorous qualitative evaluation by medical expert, receiving high marks for their clinical relevance, completeness, readability, and contribution to informed decision-making and care planning. Coupled with quantitative analyses, these results confirm Mistral-7B's efficacy in distilling complex medical information into concise, coherent summaries. Overall, our findings illuminate the considerable promise of specialized LLM, such as Mistral-7B, in refining healthcare documentation workflows and advancing patient care. This study lays the groundwork for further integrating advanced AI technologies in healthcare, demonstrating their potential to revolutionize patient documentation and support better care outcomes.",
        "subjects": [
            "cs.CL",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "10 pages, 1 figure, 3 tables, conference"
    },
    {
        "paper id": "2404.05151",
        "abstract url": "https://arxiv.org/abs/2404.05151",
        "title": "STITCH: Augmented Dexterity for Suture Throws Including Thread Coordination and Handoffs",
        "rating": "-1",
        "keywords": [
            [
                "6D"
            ]
        ],
        "abstract": "We present STITCH: an augmented dexterity pipeline that performs Suture Throws Including Thread Coordination and Handoffs. STITCH iteratively performs needle insertion, thread sweeping, needle extraction, suture cinching, needle handover, and needle pose correction with failure recovery policies. We introduce a novel visual 6D needle pose estimation framework using a stereo camera pair and new suturing motion primitives. We compare STITCH to baselines, including a proprioception-only and a policy without visual servoing. In physical experiments across 15 trials, STITCH achieves an average of 2.93 sutures without human intervention and 4.47 sutures with human intervention. See https://sites.google.com/berkeley.edu/stitch for code and supplemental materials.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05160",
        "abstract url": "https://arxiv.org/abs/2404.05160",
        "title": "Linguistic Changes in Spontaneous Speech for Detecting Parkinsons Disease Using Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "diagnosing",
                "Disease"
            ],
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Parkinsons disease is the second most prevalent neurodegenerative disorder with over ten million active cases worldwide and one million new diagnoses per year. Detecting and subsequently diagnosing the disease is challenging because of symptom heterogeneity with respect to complexity, as well as the type and timing of phenotypic manifestations. Typically, language impairment can present in the prodromal phase and precede motor symptoms suggesting that a linguistic-based approach could serve as a diagnostic method for incipient Parkinsons disease. Additionally, improved linguistic models may enhance other approaches through ensemble techniques. The field of large language models is advancing rapidly, presenting the opportunity to explore the use of these new models for detecting Parkinsons disease and to improve on current linguistic approaches with high-dimensional representations of linguistics. We evaluate the application of state-of-the-art large language models to detect Parkinsons disease automatically from spontaneous speech with up to 73% accuracy.",
        "subjects": [
            "cs.CL",
            "eess.AS"
        ],
        "comment": "12 pages, 3 figures"
    },
    {
        "paper id": "2404.05164",
        "abstract url": "https://arxiv.org/abs/2404.05164",
        "title": "Rendering-Enhanced Automatic Image-to-Point Cloud Registration for Roadside Scenes",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ]
        ],
        "abstract": "Prior point cloud provides 3D environmental context, which enhances the capabilities of monocular camera in downstream vision tasks, such as 3D object detection, via data fusion. However, the absence of accurate and automated registration methods for estimating camera extrinsic parameters in roadside scene point clouds notably constrains the potential applications of roadside cameras. This paper proposes a novel approach for the automatic registration between prior point clouds and images from roadside scenes. The main idea involves rendering photorealistic grayscale views taken at specific perspectives from the prior point cloud with the help of their features like RGB or intensity values. These generated views can reduce the modality differences between images and prior point clouds, thereby improve the robustness and accuracy of the registration results. Particularly, we specify an efficient algorithm, named neighbor rendering, for the rendering process. Then we introduce a method for automatically estimating the initial guess using only rough guesses of camera's position. At last, we propose a procedure for iteratively refining the extrinsic parameters by minimizing the reprojection error for line features extracted from both generated and camera images using Segment Anything Model (SAM). We assess our method using a self-collected dataset, comprising eight cameras strategically positioned throughout the university campus. Experiments demonstrate our method's capability to automatically align prior point cloud with roadside camera image, achieving a rotation accuracy of 0.202 degrees and a translation precision of 0.079m. Furthermore, we validate our approach's effectiveness in visual applications by substantially improving monocular 3D object detection performance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05169",
        "abstract url": "https://arxiv.org/abs/2404.05169",
        "title": "QMix: Quality-aware Learning with Mixed Noise for Robust Retinal Disease Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "Disease",
                "Retinal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Due to the complexity of medical image acquisition and the difficulty of annotation, medical image datasets inevitably contain noise. Noisy data with wrong labels affects the robustness and generalization ability of deep neural networks. Previous noise learning methods mainly considered noise arising from images being mislabeled, i.e. label noise, assuming that all mislabeled images are of high image quality. However, medical images are prone to suffering extreme quality issues, i.e. data noise, where discriminative visual features are missing for disease diagnosis. In this paper, we propose a noise learning framework, termed as QMix, that learns a robust disease diagnosis model under mixed noise. QMix alternates between sample separation and quality-aware semisupervised training in each training epoch. In the sample separation phase, we design a joint uncertainty-loss criterion to effectively separate (1) correctly labeled images; (2) mislabeled images with high quality and (3) mislabeled images with low quality. In the semi-supervised training phase, we train a disease diagnosis model to learn robust feature representation from the separated samples. Specifically, we devise a sample-reweighing loss to mitigate the effect of mislabeled images with low quality during training. Meanwhile, a contrastive enhancement loss is proposed to further distinguish mislabeled images with low quality from correctly labeled images. QMix achieved state-of-the-art disease diagnosis performance on five public retinal image datasets and exhibited substantial improvement on robustness against mixed noise.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05180",
        "abstract url": "https://arxiv.org/abs/2404.05180",
        "title": "GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Solar Photovoltaic (PV) technology is increasingly recognized as a pivotal solution in the global pursuit of clean and renewable energy. This technology addresses the urgent need for sustainable energy alternatives by converting solar power into electricity without greenhouse gas emissions. It not only curtails global carbon emissions but also reduces reliance on finite, non-renewable energy sources. In this context, monitoring solar panel farms becomes essential for understanding and facilitating the worldwide shift toward clean energy. This study contributes to this effort by developing the first comprehensive global dataset of multispectral satellite imagery of solar panel farms. This dataset is intended to form the basis for training robust machine learning models, which can accurately map and analyze the expansion and distribution of solar panel farms globally. The insights gained from this endeavor will be instrumental in guiding informed decision-making for a sustainable energy future. https://github.com/yzyly1992/GloSoFarID",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05188",
        "abstract url": "https://arxiv.org/abs/2404.05188",
        "title": "Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging",
        "rating": "-1",
        "keywords": [
            [
                "Watermarking"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data. Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities. However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models. In this paper, we conduct the first study on the robustness of IP protection methods in model merging scenarios. We investigate two state-of-the-art IP protection techniques: Quantization Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on. Experimental results indicate that current Large Language Model (LLM) watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can. Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source LLM community.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2404.05191",
        "abstract url": "https://arxiv.org/abs/2404.05191",
        "title": "Graph-based Untrained Neural Network Detector for OTFS Systems",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Inter-carrier interference (ICI) caused by mobile reflectors significantly degrades the conventional orthogonal frequency division multiplexing (OFDM) performance in high-mobility environments. The orthogonal time frequency space (OTFS) modulation system effectively represents ICI in the delay-Doppler domain, thus significantly outperforming OFDM. Existing iterative and neural network (NN) based OTFS detectors suffer from high complex matrix operations and performance degradation in untrained environments, where the real wireless channel does not match the one used in the training, which often happens in real wireless networks. In this paper, we propose to embed the prior knowledge of interference extracted from the estimated channel state information (CSI) as a directed graph into a decoder untrained neural network (DUNN), namely graph-based DUNN (GDUNN). We then combine it with Bayesian parallel interference cancellation (BPIC) for OTFS symbol detection, resulting in GDUNN-BPIC. Simulation results show that the proposed GDUNN-BPIC outperforms state-of-the-art OTFS detectors under imperfect CSI.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04814",
        "abstract url": "https://arxiv.org/abs/2404.04814",
        "title": "Inference-Time Rule Eraser: Distilling and Removing Bias Rules to Mitigate Bias in Deployed Models",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Machine learning models often make predictions based on biased features such as gender, race, and other social attributes, posing significant fairness risks, especially in societal applications, such as hiring, banking, and criminal justice. Traditional approaches to addressing this issue involve retraining or fine-tuning neural networks with fairness-aware optimization objectives. However, these methods can be impractical due to significant computational resources, complex industrial tests, and the associated CO2 footprint. Additionally, regular users aiming to use fair models often lack access to model parameters. In this paper, we introduce Inference-Time Rule Eraser (Eraser), a novel method focused on removing biased decision-making rules during inference to address fairness concerns without modifying model weights. We begin by establishing a theoretical foundation for modifying model outputs to eliminate biased rules through Bayesian analysis. Next, we present a specific implementation of Eraser that involves two stages: (1) querying the model to distill biased rules into a patched model, and (2) excluding these biased rules during inference. Extensive experiments validate the effectiveness of our approach, showcasing its superior performance in addressing fairness concerns in AI systems.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04823",
        "abstract url": "https://arxiv.org/abs/2404.04823",
        "title": "3D Building Reconstruction from Monocular Remote Sensing Images with Multi-level Supervisions",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "3D building reconstruction from monocular remote sensing images is an important and challenging research problem that has received increasing attention in recent years, owing to its low cost of data acquisition and availability for large-scale applications. However, existing methods rely on expensive 3D-annotated samples for fully-supervised training, restricting their application to large-scale cross-city scenarios. In this work, we propose MLS-BRN, a multi-level supervised building reconstruction network that can flexibly utilize training samples with different annotation levels to achieve better reconstruction results in an end-to-end manner. To alleviate the demand on full 3D supervision, we design two new modules, Pseudo Building Bbox Calculator and Roof-Offset guided Footprint Extractor, as well as new tasks and training strategies for different types of samples. Experimental results on several public and new datasets demonstrate that our proposed MLS-BRN achieves competitive performance using much fewer 3D-annotated samples, and significantly improves the footprint extraction and 3D reconstruction performance compared with current state-of-the-art. The code and datasets of this work will be released at https://github.com/opendatalab/MLS-BRN.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04854",
        "abstract url": "https://arxiv.org/abs/2404.04854",
        "title": "Contextual Chart Generation for Cyber Deception",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Honeyfiles are security assets designed to attract and detect intruders on compromised systems. Honeyfiles are a type of honeypot that mimic real, sensitive documents, creating the illusion of the presence of valuable data. Interaction with a honeyfile reveals the presence of an intruder, and can provide insights into their goals and intentions. Their practical use, however, is limited by the time, cost and effort associated with manually creating realistic content. The introduction of large language models has made high-quality text generation accessible, but honeyfiles contain a variety of content including charts, tables and images. This content needs to be plausible and realistic, as well as semantically consistent both within honeyfiles and with the real documents they mimic, to successfully deceive an intruder. In this paper, we focus on an important component of the honeyfile content generation problem: document charts. Charts are ubiquitous in corporate documents and are commonly used to communicate quantitative and scientific data. Existing image generation models, such as DALL-E, are rather prone to generating charts with incomprehensible text and unconvincing data. We take a multi-modal approach to this problem by combining two purpose-built generative models: a multitask Transformer and a specialized multi-head autoencoder. The Transformer generates realistic captions and plot text, while the autoencoder generates the underlying tabular data for the plot. To advance the field of automated honeyplot generation, we also release a new document-chart dataset and propose a novel metric Keyword Semantic Matching (KSM). This metric measures the semantic consistency between keywords of a corpus and a smaller bag of words. Extensive experiments demonstrate excellent performance against multiple large language models, including ChatGPT and GPT4.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "13 pages including references"
    },
    {
        "paper id": "2404.04869",
        "abstract url": "https://arxiv.org/abs/2404.04869",
        "title": "Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs",
        "rating": "-1.5",
        "keywords": [
            [
                "Autonomous Driving",
                "LiDAR"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The utilization of Large Language Models (LLMs) within the realm of reinforcement learning, particularly as planners, has garnered a significant degree of attention in recent scholarly literature. However, a substantial proportion of existing research predominantly focuses on planning models for robotics that transmute the outputs derived from perception models into linguistic forms, thus adopting a `pure-language' strategy. In this research, we propose a hybrid End-to-End learning framework for autonomous driving by combining basic driving imitation learning with LLMs based on multi-modality prompt tokens. Instead of simply converting perception results from the separated train model into pure language input, our novelty lies in two aspects. 1) The end-to-end integration of visual and LiDAR sensory input into learnable multi-modality tokens, thereby intrinsically alleviating description bias by separated pre-trained perception models. 2) Instead of directly letting LLMs drive, this paper explores a hybrid setting of letting LLMs help the driving model correct mistakes and complicated scenarios. The results of our experiments suggest that the proposed methodology can attain driving scores of 49.21%, coupled with an impressive route completion rate of 91.34% in the offline evaluation conducted via CARLA. These performance metrics are comparable to the most advanced driving models.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04877",
        "abstract url": "https://arxiv.org/abs/2404.04877",
        "title": "A Bird-Eye view on DNA Storage Simulators",
        "rating": "-1.5",
        "keywords": [
            [
                "DNA"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "In the current world due to the huge demand for storage, DNA-based storage solution sounds quite promising because of their longevity, low power consumption, and high capacity. However in real life storing data in the form of DNA is quite expensive, and challenging. Therefore researchers and developers develop such kind of software that helps simulate real-life DNA storage without worrying about the cost. This paper aims to review some of the software that performs DNA storage simulations in different domains. The paper also explains the core concepts such as synthesis, sequencing, clustering, reconstruction, GC window, K-mer window, etc and some overview on existing algorithms. Further, we present 3 different softwares on the basis of domain, implementation techniques, and customer/commercial usability.",
        "subjects": [
            "cs.IT",
            "cs.CY",
            "cs.ET"
        ],
        "comment": "19 pages, 19 figures, draft, review"
    },
    {
        "paper id": "2404.04905",
        "abstract url": "https://arxiv.org/abs/2404.04905",
        "title": "Review for Handling Missing Data with special missing mechanism",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Missing data poses a significant challenge in data science, affecting decision-making processes and outcomes. Understanding what missing data is, how it occurs, and why it is crucial to handle it appropriately is paramount when working with real-world data, especially in tabular data, one of the most commonly used data types in the real world. Three missing mechanisms are defined in the literature: Missing Completely At Random (MCAR), Missing At Random (MAR), and Missing Not At Random (MNAR), each presenting unique challenges in imputation. Most existing work are focused on MCAR that is relatively easy to handle. The special missing mechanisms of MNAR and MAR are less explored and understood. This article reviews existing literature on handling missing values. It compares and contrasts existing methods in terms of their ability to handle different missing mechanisms and data types. It identifies research gap in the existing literature and lays out potential directions for future research in the field. The information in this review will help data analysts and researchers to adopt and promote good practices for handling missing data in real-world problems.",
        "subjects": [
            "stat.ME",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04920",
        "abstract url": "https://arxiv.org/abs/2404.04920",
        "title": "Regularized Conditional Diffusion Model for Multi-Task Preference Alignment",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sequential decision-making is desired to align with human intents and exhibit versatility across various tasks. Previous methods formulate it as a conditional generation process, utilizing return-conditioned diffusion models to directly model trajectory distributions. Nevertheless, the return-conditioned paradigm relies on pre-defined reward functions, facing challenges when applied in multi-task settings characterized by varying reward functions (versatility) and showing limited controllability concerning human preferences (alignment). In this work, we adopt multi-task preferences as a unified condition for both single- and multi-task decision-making, and propose preference representations aligned with preference labels. The learned representations are used to guide the conditional generation process of diffusion models, and we introduce an auxiliary objective to maximize the mutual information between representations and corresponding generated trajectories, improving alignment between trajectories and preferences. Extensive experiments in D4RL and Meta-World demonstrate that our method presents favorable performance in single- and multi-task scenarios, and exhibits superior alignment with preferences.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04936",
        "abstract url": "https://arxiv.org/abs/2404.04936",
        "title": "Bootstrapping Chest CT Image Understanding by Distilling Knowledge from X-ray Expert Models",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "CT",
                "X-ray",
                "disease",
                "radiology"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Radiologists highly desire fully automated versatile AI for medical imaging interpretation. However, the lack of extensively annotated large-scale multi-disease datasets has hindered the achievement of this goal. In this paper, we explore the feasibility of leveraging language as a naturally high-quality supervision for chest CT imaging. In light of the limited availability of image-report pairs, we bootstrap the understanding of 3D chest CT images by distilling chest-related diagnostic knowledge from an extensively pre-trained 2D X-ray expert model. Specifically, we propose a language-guided retrieval method to match each 3D CT image with its semantically closest 2D X-ray image, and perform pair-wise and semantic relation knowledge distillation. Subsequently, we use contrastive learning to align images and reports within the same patient while distinguishing them from the other patients. However, the challenge arises when patients have similar semantic diagnoses, such as healthy patients, potentially confusing if treated as negatives. We introduce a robust contrastive learning that identifies and corrects these false negatives. We train our model with over 12,000 pairs of chest CT images and radiology reports. Extensive experiments across multiple scenarios, including zero-shot learning, report generation, and fine-tuning processes, demonstrate the model's feasibility in interpreting chest CT images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04956",
        "abstract url": "https://arxiv.org/abs/2404.04956",
        "title": "Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Ethical concerns surrounding copyright protection and inappropriate content generation pose challenges for the practical implementation of diffusion models. One effective solution involves watermarking the generated images. However, existing methods often compromise the model performance or require additional training, which is undesirable for operators and users. To address this issue, we propose Gaussian Shading, a diffusion model watermarking technique that is both performance-lossless and training-free, while serving the dual purpose of copyright protection and tracing of offending content. Our watermark embedding is free of model parameter modifications and thus is plug-and-play. We map the watermark to latent representations following a standard Gaussian distribution, which is indistinguishable from latent representations obtained from the non-watermarked diffusion model. Therefore we can achieve watermark embedding with lossless performance, for which we also provide theoretical proof. Furthermore, since the watermark is intricately linked with image semantics, it exhibits resilience to lossy processing and erasure attempts. The watermark can be extracted by Denoising Diffusion Implicit Models (DDIM) inversion and inverse sampling. We evaluate Gaussian Shading on multiple versions of Stable Diffusion, and the results demonstrate that Gaussian Shading not only is performance-lossless but also outperforms existing methods in terms of robustness.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": "17 pages, 11 figures, accepted by CVPR 2024"
    },
    {
        "paper id": "2404.04974",
        "abstract url": "https://arxiv.org/abs/2404.04974",
        "title": "Neural Network Modeling for Forecasting Tourism Demand in Stopi\u0107a Cave: A Serbian Cave Tourism Study",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "For modeling the number of visits in Stopi\u0107a cave (Serbia) we consider the classical Auto-regressive Integrated Moving Average (ARIMA) model, Machine Learning (ML) method Support Vector Regression (SVR), and hybrid NeuralPropeth method which combines classical and ML concepts. The most accurate predictions were obtained with NeuralPropeth which includes the seasonal component and growing trend of time-series. In addition, non-linearity is modeled by shallow Neural Network (NN), and Google Trend is incorporated as an exogenous variable. Modeling tourist demand represents great importance for management structures and decision-makers due to its applicability in establishing sustainable tourism utilization strategies in environmentally vulnerable destinations such as caves. The data provided insights into the tourist demand in Stopi\u0107a cave and preliminary data for addressing the issues of carrying capacity within the most visited cave in Serbia.",
        "subjects": [
            "econ.EM",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05047",
        "abstract url": "https://arxiv.org/abs/2404.05047",
        "title": "Initial Exploration of Zero-Shot Privacy Utility Tradeoffs in Tabular Data Using GPT-4",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the application of large language models (LLMs), specifically GPT-4, to scenarios involving the tradeoff between privacy and utility in tabular data. Our approach entails prompting GPT-4 by transforming tabular data points into textual format, followed by the inclusion of precise sanitization instructions in a zero-shot manner. The primary objective is to sanitize the tabular data in such a way that it hinders existing machine learning models from accurately inferring private features while allowing models to accurately infer utility-related attributes. We explore various sanitization instructions. Notably, we discover that this relatively simple approach yields performance comparable to more complex adversarial optimization methods used for managing privacy-utility tradeoffs. Furthermore, while the prompts successfully obscure private features from the detection capabilities of existing machine learning models, we observe that this obscuration alone does not necessarily meet a range of fairness metrics. Nevertheless, our research indicates the potential effectiveness of LLMs in adhering to these fairness metrics, with some of our experimental results aligning with those achieved by well-established adversarial optimization techniques.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "8 pages, Paper accepted at 2024 IEEE International Joint Conference on Neural Networks (IJCNN)"
    },
    {
        "paper id": "2404.05051",
        "abstract url": "https://arxiv.org/abs/2404.05051",
        "title": "Skill Transfer and Discovery for Sim-to-Real Learning: A Representation-Based Viewpoint",
        "rating": "-1.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study sim-to-real skill transfer and discovery in the context of robotics control using representation learning. We draw inspiration from spectral decomposition of Markov decision processes. The spectral decomposition brings about representation that can linearly represent the state-action value function induced by any policies, thus can be regarded as skills. The skill representations are transferable across arbitrary tasks with the same transition dynamics. Moreover, to handle the sim-to-real gap in the dynamics, we propose a skill discovery algorithm that learns new skills caused by the sim-to-real gap from real-world data. We promote the discovery of new skills by enforcing orthogonal constraints between the skills to learn and the skills from simulators, and then synthesize the policy using the enlarged skill sets. We demonstrate our methodology by transferring quadrotor controllers from simulators to Crazyflie 2.1 quadrotors. We show that we can learn the skill representations from a single simulator task and transfer these to multiple different real-world tasks including hovering, taking off, landing and trajectory tracking. Our skill discovery approach helps narrow the sim-to-real gap and improve the real-world controller performance by up to 30.2%.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": "9 pages, 6 figures. Project page: https://congharvard.github.io/steady-sim-to-real/"
    },
    {
        "paper id": "2404.05108",
        "abstract url": "https://arxiv.org/abs/2404.05108",
        "title": "Efficient Gradient Estimation of Variational Quantum Circuits with Lie Algebraic Symmetries",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hybrid quantum-classical optimization and learning strategies are among the most promising approaches to harnessing quantum information or gaining a quantum advantage over classical methods. However, efficient estimation of the gradient of the objective function in such models remains a challenge due to several factors including the exponential dimensionality of the Hilbert spaces, and information loss of quantum measurements. In this work, we study generic parameterized circuits in the context of variational methods. We develop a framework for gradient estimation that exploits the algebraic symmetries of Hamiltonian characterized through Lie algebra or group theory. Particularly, we prove that when the dimension of the dynamical Lie algebra is polynomial in the number of qubits, one can estimate the gradient with polynomial classical and quantum resources. This is done by a series of Hadamard tests applied to the output of the ansatz with no change to its circuit. We show that this approach can be equipped with classical shadow tomography to further reduce the measurement shot complexity to scale logarithmically with the number of parameters.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05184",
        "abstract url": "https://arxiv.org/abs/2404.05184",
        "title": "Predicting the Geothermal Gradient in Colombia: a Machine Learning Approach",
        "rating": "-1.5",
        "keywords": [
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurate determination of the geothermal gradient is critical for assessing the geothermal energy potential of a given region. Of particular interest is the case of Colombia, a country with abundant geothermal resources. A history of active oil and gas exploration and production has left drilled boreholes in different geological settings, providing direct measurements of the geothermal gradient. Unfortunately, large regions of the country where geothermal resources might exist lack such measurements. Indirect geophysical measurements are costly and difficult to perform at regional scales. Computational thermal models could be constructed, but they require very detailed knowledge of the underlying geology and uniform sampling of subsurface temperatures to be well-constrained. We present an alternative approach that leverages recent advances in supervised machine learning and available direct measurements to predict the geothermal gradient in regions where only global-scale geophysical datasets and course geological knowledge are available. We find that a Gradient Boosted Regression Tree algorithm yields optimal predictions and extensively validate the trained model. We show that predictions of our model are within 12% accuracy and that independent measurements performed by other authors agree well with our model. Finnally, we present a geothermal gradient map for Colombia that highlights regions where futher exploration and data collection should be performed.",
        "subjects": [
            "physics.geo-ph",
            "cs.LG"
        ],
        "comment": "This is the version we re-submitted to the journal after addressing all the peer review requirements"
    },
    {
        "paper id": "2404.05192",
        "abstract url": "https://arxiv.org/abs/2404.05192",
        "title": "ATFNet: Adaptive Time-Frequency Ensembled Network for Long-term Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The intricate nature of time series data analysis benefits greatly from the distinct advantages offered by time and frequency domain representations. While the time domain is superior in representing local dependencies, particularly in non-periodic series, the frequency domain excels in capturing global dependencies, making it ideal for series with evident periodic patterns. To capitalize on both of these strengths, we propose ATFNet, an innovative framework that combines a time domain module and a frequency domain module to concurrently capture local and global dependencies in time series data. Specifically, we introduce Dominant Harmonic Series Energy Weighting, a novel mechanism for dynamically adjusting the weights between the two modules based on the periodicity of the input time series. In the frequency domain module, we enhance the traditional Discrete Fourier Transform (DFT) with our Extended DFT, designed to address the challenge of discrete frequency misalignment. Additionally, our Complex-valued Spectrum Attention mechanism offers a novel approach to discern the intricate relationships between different frequency combinations. Extensive experiments across multiple real-world datasets demonstrate that our ATFNet framework outperforms current state-of-the-art methods in long-term time series forecasting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05768",
        "abstract url": "https://arxiv.org/abs/2404.05768",
        "title": "Streamlining Ocean Dynamics Modeling with Fourier Neural Operators: A Multiobjective Hyperparameter and Architecture Optimization Approach",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training an effective deep learning model to learn ocean processes involves careful choices of various hyperparameters. We leverage the advanced search algorithms for multiobjective optimization in DeepHyper, a scalable hyperparameter optimization software, to streamline the development of neural networks tailored for ocean modeling. The focus is on optimizing Fourier neural operators (FNOs), a data-driven model capable of simulating complex ocean behaviors. Selecting the correct model and tuning the hyperparameters are challenging tasks, requiring much effort to ensure model accuracy. DeepHyper allows efficient exploration of hyperparameters associated with data preprocessing, FNO architecture-related hyperparameters, and various model training strategies. We aim to obtain an optimal set of hyperparameters leading to the most performant model. Moreover, on top of the commonly used mean squared error for model training, we propose adopting the negative anomaly correlation coefficient as the additional loss term to improve model performance and investigate the potential trade-off between the two terms. The experimental results show that the optimal set of hyperparameters enhanced model performance in single timestepping forecasting and greatly exceeded the baseline configuration in the autoregressive rollout for long-horizon forecasting up to 30 days. Utilizing DeepHyper, we demonstrate an approach to enhance the use of FNOs in ocean dynamics forecasting, offering a scalable solution with improved precision.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05774",
        "abstract url": "https://arxiv.org/abs/2404.05774",
        "title": "STMGF: An Effective Spatial-Temporal Multi-Granularity Framework for Traffic Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accurate Traffic Prediction is a challenging task in intelligent transportation due to the spatial-temporal aspects of road networks. The traffic of a road network can be affected by long-distance or long-term dependencies where existing methods fall short in modeling them. In this paper, we introduce a novel framework known as Spatial-Temporal Multi-Granularity Framework (STMGF) to enhance the capture of long-distance and long-term information of the road networks. STMGF makes full use of different granularity information of road networks and models the long-distance and long-term information by gathering information in a hierarchical interactive way. Further, it leverages the inherent periodicity in traffic sequences to refine prediction results by matching with recent traffic data. We conduct experiments on two real-world datasets, and the results demonstrate that STMGF outperforms all baseline models and achieves state-of-the-art performance.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.07235",
        "abstract url": "https://arxiv.org/abs/2404.07235",
        "title": "Explaining EDA synthesis errors with LLMs",
        "rating": "-1.5",
        "keywords": [
            [
                "FPGAs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Training new engineers in digital design is a challenge, particularly when it comes to teaching the complex electronic design automation (EDA) tooling used in this domain. Learners will typically deploy designs in the Verilog and VHDL hardware description languages to Field Programmable Gate Arrays (FPGAs) from Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus Prime and Vivado, respectively). These tools are complex and difficult to use -- yet, as they are the tools used in industry, they are an essential first step in this space. In this work, we examine how recent advances in artificial intelligence may be leveraged to address aspects of this challenge. Specifically, we investigate if Large Language Models (LLMs), which have demonstrated text comprehension and question-answering capabilities, can be used to generate novice-friendly explanations of compile-time synthesis error messages from Quartus Prime and Vivado. To perform this study we generate 936 error message explanations using three OpenAI LLMs over 21 different buggy code samples. These are then graded for relevance and correctness, and we find that in approximately 71% of cases the LLMs give correct & complete explanations suitable for novice learners.",
        "subjects": [
            "cs.AR",
            "cs.AI",
            "cs.PL",
            "cs.SE"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2405.04539",
        "abstract url": "https://arxiv.org/abs/2405.04539",
        "title": "Some variation of COBRA in sequential learning setup",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This research paper introduces innovative approaches for multivariate time series forecasting based on different variations of the combined regression strategy. We use specific data preprocessing techniques which makes a radical change in the behaviour of prediction. We compare the performance of the model based on two types of hyper-parameter tuning Bayesian optimisation (BO) and Usual Grid search. Our proposed methodologies outperform all state-of-the-art comparative models. We illustrate the methodologies through eight time series datasets from three categories: cryptocurrency, stock index, and short-term load forecasting.",
        "subjects": [
            "stat.ML",
            "cs.CE",
            "cs.LG",
            "eess.SP",
            "q-fin.CP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04844",
        "abstract url": "https://arxiv.org/abs/2404.04844",
        "title": "Self-Evolving Wireless Communications: A Novel Intelligence Trend for 6G and Beyond",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Wireless communication is rapidly evolving, and future wireless communications (6G and beyond) will be more heterogeneous, multi-layered, and complex, which poses challenges to traditional communications. Adaptive technologies in traditional communication systems respond to environmental changes by modifying system parameters and structures on their own and are not flexible and agile enough to satisfy requirements in future communications. To tackle these challenges, we propose a novel self-evolving communication framework, which consists of three layers: data layer, information layer, and knowledge layer. The first two layers allow communication systems to sense environments, fuse data, and generate a knowledge base for the knowledge layer. When dealing with a variety of application scenarios and environments, the generated knowledge is subsequently fed back to the first two layers for communication in practical application scenarios to obtain self-evolving ability and enhance the robustness of the system. In this paper, we first highlight the limitations of current adaptive communication systems and the need for intelligence, automation, and self-evolution in future wireless communications. We overview the development of self-evolving technologies and conceive the concept of self-evolving communications with its hypothetical architecture. To demonstrate the power of self-evolving modules, we compare the performances of a communication system with and without evolution. We then provide some potential techniques that enable self-evolving communications and challenges in implementing them.",
        "subjects": [
            "cs.ET",
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04852",
        "abstract url": "https://arxiv.org/abs/2404.04852",
        "title": "EnQuery: Ensemble Policies for Diverse Query-Generation in Preference Alignment of Robot Navigation",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot",
                "Navigation"
            ]
        ],
        "abstract": "To align mobile robot navigation policies with user preferences through reinforcement learning from human feedback (RLHF), reliable and behavior-diverse user queries are required. However, deterministic policies fail to generate a variety of navigation trajectory suggestions for a given navigation task configuration. We introduce EnQuery, a query generation approach using an ensemble of policies that achieve behavioral diversity through a regularization term. For a given navigation task, EnQuery produces multiple navigation trajectory suggestions, thereby optimizing the efficiency of preference data collection with fewer queries. Our methodology demonstrates superior performance in aligning navigation policies with user preferences in low-query regimes, offering enhanced policy convergence from sparse preference queries. The evaluation is complemented with a novel explainability representation, capturing full scene navigation behavior of the mobile robot in a single plot.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04864",
        "abstract url": "https://arxiv.org/abs/2404.04864",
        "title": "Towards Atomic MIMO Receivers",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "The advancement of Rydberg atoms in quantum sensing is driving a paradigm shift from classical receivers to atomic receivers. Capitalizing on the extreme sensitivity of Rydberg atoms to external disturbance, atomic receivers can measure radio-waves more precisely than classical receivers to support high-performance wireless communication and sensing. Although the atomic receiver is developing rapidly in quantum-sensing domain, its integration with wireless communications is still at a nascent stage. Particularly, systematic methods to enhance communication performance through this integration are largely uncharted. Motivated by this observation, we propose to incorporate atomic receivers into multiple-input-multiple-output (MIMO) communication to implement atomic-MIMO receivers. Specifically, we establish the framework of atomic-MIMO receivers exploiting the principle of quantum sensing, and reveal that its signal detection is intrinsically a non-linear biased phase-retrieval (PR) problem, as opposed to the linear model in classical MIMO systems. To this end, we modify the Gerchberg-Saxton (GS) algorithm, a typical PR solver, with a biased GS algorithm to solve the discovered biased PR problem. Moreover, we propose an Expectation-Maximization-GS (EM-GS) algorithm by introducing a high-pass filter constructed by Bessel functions into the iteration of GS, which improves the detection accuracy efficiently. Finally, the effectiveness of atomic MIMO receivers is demonstrated by theoretical analysis and numerical simulation.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages, 8 figures. Submitted to IEEE for possible publication"
    },
    {
        "paper id": "2404.04906",
        "abstract url": "https://arxiv.org/abs/2404.04906",
        "title": "Balancing Information Perception with Yin-Yang: Agent-Based Information Neutrality Model for Recommendation Systems",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "While preference-based recommendation algorithms effectively enhance user engagement by recommending personalized content, they often result in the creation of ``filter bubbles''. These bubbles restrict the range of information users interact with, inadvertently reinforcing their existing viewpoints. Previous research has focused on modifying these underlying algorithms to tackle this issue. Yet, approaches that maintain the integrity of the original algorithms remain largely unexplored. This paper introduces an Agent-based Information Neutrality model grounded in the Yin-Yang theory, namely, AbIN. This innovative approach targets the imbalance in information perception within existing recommendation systems. It is designed to integrate with these preference-based systems, ensuring the delivery of recommendations with neutral information. Our empirical evaluation of this model proved its efficacy, showcasing its capacity to expand information diversity while respecting user preferences. Consequently, AbIN emerges as an instrumental tool in mitigating the negative impact of filter bubbles on information consumption.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04935",
        "abstract url": "https://arxiv.org/abs/2404.04935",
        "title": "Anomaly Detection in Electrocardiograms: Advancing Clinical Diagnosis Through Self-Supervised Learning",
        "rating": "-2",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "healthcare",
                "Diagnosis",
                "disease",
                "Clinical",
                "cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The electrocardiogram (ECG) is an essential tool for diagnosing heart disease, with computer-aided systems improving diagnostic accuracy and reducing healthcare costs. Despite advancements, existing systems often miss rare cardiac anomalies that could be precursors to serious, life-threatening issues or alterations in the cardiac macro/microstructure. We address this gap by focusing on self-supervised anomaly detection (AD), training exclusively on normal ECGs to recognize deviations indicating anomalies. We introduce a novel self-supervised learning framework for ECG AD, utilizing a vast dataset of normal ECGs to autonomously detect and localize cardiac anomalies. It proposes a novel masking and restoration technique alongside a multi-scale cross-attention module, enhancing the model's ability to integrate global and local signal features. The framework emphasizes accurate localization of anomalies within ECG signals, ensuring the method's clinical relevance and reliability. To reduce the impact of individual variability, the approach further incorporates crucial patient-specific information from ECG reports, such as age and gender, thus enabling accurate identification of a broad spectrum of cardiac anomalies, including rare ones. Utilizing an extensive dataset of 478,803 ECG graphic reports from real-world clinical practice, our method has demonstrated exceptional effectiveness in AD across all tested conditions, regardless of their frequency of occurrence, significantly outperforming existing models. It achieved superior performance metrics, including an AUROC of 91.2%, an F1 score of 83.7%, a sensitivity rate of 84.2%, a specificity of 83.0%, and a precision of 75.6% with a fixed recall rate of 90%. It has also demonstrated robust localization capabilities, with an AUROC of 76.5% and a Dice coefficient of 65.3% for anomaly localization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04937",
        "abstract url": "https://arxiv.org/abs/2404.04937",
        "title": "Optimizing Information Propagation for Blockchain-empowered Mobile AIGC: A Graph Attention Network Approach",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "Artificial Intelligence-Generated Content (AIGC) is a rapidly evolving field that utilizes advanced AI algorithms to generate content. Through integration with mobile edge networks, mobile AIGC networks have gained significant attention, which can provide real-time customized and personalized AIGC services and products. Since blockchains can facilitate decentralized and transparent data management, AIGC products can be securely managed by blockchain to avoid tampering and plagiarization. However, the evolution of blockchain-empowered mobile AIGC is still in its nascent phase, grappling with challenges such as improving information propagation efficiency to enable blockchain-empowered mobile AIGC. In this paper, we design a Graph Attention Network (GAT)-based information propagation optimization framework for blockchain-empowered mobile AIGC. We first innovatively apply age of information as a data-freshness metric to measure information propagation efficiency in public blockchains. Considering that GATs possess the excellent ability to process graph-structured data, we utilize the GAT to obtain the optimal information propagation trajectory. Numerical results demonstrate that the proposed scheme exhibits the most outstanding information propagation efficiency compared with traditional routing mechanisms.",
        "subjects": [
            "cs.CR",
            "cs.GT"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2403.13237"
    },
    {
        "paper id": "2404.04965",
        "abstract url": "https://arxiv.org/abs/2404.04965",
        "title": "Towards Developing Brain-Computer Interfaces for People with Multiple Sclerosis",
        "rating": "-2",
        "keywords": [
            [
                "bionic",
                "pathological"
            ]
        ],
        "abstract": "Multiple Sclerosis (MS) is a severely disabling condition that leads to various neurological symptoms. A Brain-Computer Interface (BCI) may substitute some lost function; however, there is a lack of BCI research in people with MS. To progress this research area effectively and efficiently, we aimed to evaluate user needs and assess the feasibility and user-centric requirements of a BCI for people with MS. We conducted an online survey of 34 people with MS to qualitatively assess user preferences and establish the initial steps of user-centred design. The survey aimed to understand their interest and preferences in BCI and bionic applications. We demonstrated widespread interest for BCI applications in all stages of MS, with a preference for a non-invasive (n = 12) or minimally invasive (n = 15) BCI over carer assistance (n = 6). Qualitative assessment indicated that this preference was not influenced by level of independence. Additionally, strong interest was noted in bionic technology for sensory and autonomic functions. Considering the potential to enhance independence and quality of life for people living with MS, the results emphasise the importance of user-centred design for future advancement of BCIs that account for the unique pathological changes associated with MS.",
        "subjects": [
            "cs.HC",
            "q-bio.NC"
        ],
        "comment": "18 pages, 9 figures, 1 table. For supplementary material, please contact the corresponding author; corrected ordering of figures 6 and 7"
    },
    {
        "paper id": "2404.04971",
        "abstract url": "https://arxiv.org/abs/2404.04971",
        "title": "FPL+: Filtered Pseudo Label-based Unsupervised Cross-Modality Adaptation for 3D Medical Image Segmentation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Adapting a medical image segmentation model to a new domain is important for improving its cross-domain transferability, and due to the expensive annotation process, Unsupervised Domain Adaptation (UDA) is appealing where only unlabeled images are needed for the adaptation. Existing UDA methods are mainly based on image or feature alignment with adversarial training for regularization, and they are limited by insufficient supervision in the target domain. In this paper, we propose an enhanced Filtered Pseudo Label (FPL+)-based UDA method for 3D medical image segmentation. It first uses cross-domain data augmentation to translate labeled images in the source domain to a dual-domain training set consisting of a pseudo source-domain set and a pseudo target-domain set. To leverage the dual-domain augmented images to train a pseudo label generator, domain-specific batch normalization layers are used to deal with the domain shift while learning the domain-invariant structure features, generating high-quality pseudo labels for target-domain images. We then combine labeled source-domain images and target-domain images with pseudo labels to train a final segmentor, where image-level weighting based on uncertainty estimation and pixel-level weighting based on dual-domain consensus are proposed to mitigate the adverse effect of noisy pseudo labels. Experiments on three public multi-modal datasets for Vestibular Schwannoma, brain tumor and whole heart segmentation show that our method surpassed ten state-of-the-art UDA methods, and it even achieved better results than fully supervised learning in the target domain in some cases.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2404.04991",
        "abstract url": "https://arxiv.org/abs/2404.04991",
        "title": "OSS Malicious Package Analysis in the Wild",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "The open-source software (OSS) ecosystem suffers from various security threats and risks, and malicious packages play a central role in software supply chain (SSC) attacks. Although malware research has a history of over thirty years, less attention has been paid to OSS malware. Its existing research has three limitations: a lack of high-quality datasets, malware diversity, and attack campaign context. In this paper, we first build and curate the largest dataset of 23,425 malicious packages from scattered online sources. We then propose a knowledge graph to represent the OSS malware corpus and conduct malicious package analysis in the wild. Our main findings include (1) it is essential to collect malicious packages from various online sources because there is little data overlap between different sources; (2) despite the sheer volume of SSC attack campaigns, many malicious packages are similar, and unknown/sophisticated attack behaviors have yet to emerge or be detected; (3) OSS malicious package has its distinct life cycle, denoted as {changing->release->detection->removal}, and slightly changing the package (different name) is a widespread attack manner; (4) while malicious packages often lack context about how and who released them, security reports disclose the information about corresponding SSC attack campaigns.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04993",
        "abstract url": "https://arxiv.org/abs/2404.04993",
        "title": "On Linear Codes Whose Hermitian Hulls are MD",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Hermitian hulls of linear codes are interesting for theoretical and practical reasons alike. In terms of recent application, linear codes whose hulls meet certain conditions have been utilized as ingredients to construct entanglement-assisted quantum error correcting codes. This family of quantum codes is often seen as a generalization of quantum stabilizer codes. Theoretically, compared with the Euclidean setup, the Hermitian case is much harder to deal with. Hermitian hulls of MDS linear codes with low dimensions have been explored, mostly from generalized Reed-Solomon codes. Characterizing Hermitian hulls which themselves are MDS appears to be more involved and has not been extensively studied. This paper introduces some tools to study linear codes whose Hermitian hulls are MDS. Using the tools, we then propose explicit constructions of such codes. We consider Hermitian hulls of both Reed-Solomon and non Reed-Solomon types of linear MDS codes. We demonstrate that, given the same Hermitian hull dimensions, the codes from our constructions have dimensions which are larger than those in the literature.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05011",
        "abstract url": "https://arxiv.org/abs/2404.05011",
        "title": "A Hybrid Execution Environment for Computer-Interpretable Guidelines in PROforma",
        "rating": "-2",
        "keywords": [
            [
                "cancer"
            ]
        ],
        "abstract": "In this paper, we share our experience of developing a hybrid execution environment for computer-interpretable guidelines (CIGs) in PROforma. The proposed environment is part of the CAPABLE system which provides coaching for cancer patients and decision support for physicians. It extends a standard PROforma execution engine - Deontics Engine (DE) - with additional components that act as wrappers around DE, allow handling of non-standard tasks, and facilitate integration with the rest of the CAPABLE system. This yields a hybrid environment in which the standard engine and specialized components must be interfaced together by some intervening layer. In the CAPABLE system this has been achieved by defining a set of specialized meta-properties which are attached to data and tasks in the PROforma CIGs to specify the interface between engine and components.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Presented as a short paper at the Knowledge Representation for Healthcare 2023 (KR4HC 2023) workshop"
    },
    {
        "paper id": "2404.05014",
        "abstract url": "https://arxiv.org/abs/2404.05014",
        "title": "MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators",
        "rating": "-2",
        "keywords": [
            [
                "Text-to-Video"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in Text-to-Video generation (T2V) have achieved remarkable success in synthesizing high-quality general videos from textual descriptions. A largely overlooked problem in T2V is that existing models have not adequately encoded physical knowledge of the real world, thus generated videos tend to have limited motion and poor variations. In this paper, we propose \\textbf{MagicTime}, a metamorphic time-lapse video generation model, which learns real-world physics knowledge from time-lapse videos and implements metamorphic generation. First, we design a MagicAdapter scheme to decouple spatial and temporal training, encode more physical knowledge from metamorphic videos, and transform pre-trained T2V models to generate metamorphic videos. Second, we introduce a Dynamic Frames Extraction strategy to adapt to metamorphic time-lapse videos, which have a wider variation range and cover dramatic object metamorphic processes, thus embodying more physical knowledge than general videos. Finally, we introduce a Magic Text-Encoder to improve the understanding of metamorphic video prompts. Furthermore, we create a time-lapse video-text dataset called \\textbf{ChronoMagic}, specifically curated to unlock the metamorphic video generation ability. Extensive experiments demonstrate the superiority and effectiveness of MagicTime for generating high-quality and dynamic metamorphic videos, suggesting time-lapse video generation is a promising path toward building metamorphic simulators of the physical world.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05044",
        "abstract url": "https://arxiv.org/abs/2404.05044",
        "title": "Clinical Trials Protocol Authoring using LLMs",
        "rating": "-2",
        "keywords": [
            [
                "Clinical"
            ]
        ],
        "abstract": "This report embarks on a mission to revolutionize clinical trial protocol development through the integration of advanced AI technologies. With a focus on leveraging the capabilities of generative AI, specifically GPT-4, this initiative aimed to streamline and enhance the efficiency and accuracy of clinical trial protocols. The methodology encompassed a detailed analysis and preparation of comprehensive drug and study level metadata, followed by the deployment of GPT-4 for automated protocol section generation. Results demonstrated a significant improvement in protocol authoring, highlighted by increases in efficiency, accuracy, and the customization of protocols to specific trial requirements. Challenges encountered during model selection and prompt engineering were systematically addressed, leading to refined methodologies that capitalized on the advanced text generation capabilities of GPT-4. This project not only showcases the practical applications and benefits of generative AI in clinical trial design but also sets a foundation for future innovations in the field.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "18 pages, 2 tables, 7 figures, under review by MDPI Journal"
    },
    {
        "paper id": "2404.05061",
        "abstract url": "https://arxiv.org/abs/2404.05061",
        "title": "Automated Prediction of Breast Cancer Response to Neoadjuvant Chemotherapy from DWI Data",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "surgical",
                "MRI",
                "Cancer",
                "tumor",
                "pathological"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Effective surgical planning for breast cancer hinges on accurately predicting pathological complete response (pCR) to neoadjuvant chemotherapy (NAC). Diffusion-weighted MRI (DWI) and machine learning offer a non-invasive approach for early pCR assessment. However, most machine-learning models require manual tumor segmentation, a cumbersome and error-prone task. We propose a deep learning model employing \"Size-Adaptive Lesion Weighting\" for automatic DWI tumor segmentation to enhance pCR prediction accuracy. Despite histopathological changes during NAC complicating DWI image segmentation, our model demonstrates robust performance. Utilizing the BMMR2 challenge dataset, it matches human experts in pCR prediction pre-NAC with an area under the curve (AUC) of 0.76 vs. 0.796, and surpasses standard automated methods mid-NAC, with an AUC of 0.729 vs. 0.654 and 0.576. Our approach represents a significant advancement in automating breast cancer treatment planning, enabling more reliable pCR predictions without manual segmentation.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted for presentation at the IEEE International Symposium on Biomedical Imaging (ISBI)"
    },
    {
        "paper id": "2404.05067",
        "abstract url": "https://arxiv.org/abs/2404.05067",
        "title": "Adaptive Anchor Pairs Selection in a TDOA-based System Through Robot Localization Error Minimization",
        "rating": "-2",
        "keywords": [
            [
                "trajectory",
                "LiDAR"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "The following paper presents an adaptive anchor pairs selection method for ultra-wideband (UWB) Time Difference of Arrival (TDOA) based positioning systems. The method divides the area covered by the system into several zones and assigns them anchor pair sets. The pair sets are determined during calibration based on localization root mean square error (RMSE). The calibration assumes driving a mobile platform equipped with a LiDAR sensor and a UWB tag through the specified zones. The robot is localized separately based on a large set of different TDOA pairs and using a LiDAR, which acts as the reference. For each zone, the TDOA pairs set for which the registered RMSE is lowest is selected and used for localization in the routine system work. The proposed method has been tested with simulations and experiments. The results for both simulated static and experimental dynamic scenarios have proven that the adaptive selection of the anchor nodes leads to an increase in localization accuracy. In the experiment, the median trajectory error for a moving person localization was at a level of 25 cm.",
        "subjects": [
            "cs.RO",
            "eess.SP"
        ],
        "comment": "Originally presented at: 2021 Signal Processing Symposium (SPSympo), LODZ, Poland, 2021"
    },
    {
        "paper id": "2404.05105",
        "abstract url": "https://arxiv.org/abs/2404.05105",
        "title": "VMambaMorph: a Multi-Modality Deformable Image Registration Framework based on Visual State Space Model with Cross-Scan Module",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "CT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image registration, a critical process in medical imaging, involves aligning different sets of medical imaging data into a single unified coordinate system. Deep learning networks, such as the Convolutional Neural Network (CNN)-based VoxelMorph, Vision Transformer (ViT)-based TransMorph, and State Space Model (SSM)-based MambaMorph, have demonstrated effective performance in this domain. The recent Visual State Space Model (VMamba), which incorporates a cross-scan module with SSM, has exhibited promising improvements in modeling global-range dependencies with efficient computational cost in computer vision tasks. This paper hereby introduces an exploration of VMamba with image registration, named VMambaMorph. This novel hybrid VMamba-CNN network is designed specifically for 3D image registration. Utilizing a U-shaped network architecture, VMambaMorph computes the deformation field based on target and source volumes. The VMamba-based block with 2D cross-scan module is redesigned for 3D volumetric feature processing. To overcome the complex motion and structure on multi-modality images, we further propose a fine-tune recursive registration framework. We validate VMambaMorph using a public benchmark brain MR-CT registration dataset, comparing its performance against current state-of-the-art methods. The results indicate that VMambaMorph achieves competitive registration quality. The code for VMambaMorph with all baseline methods is available on GitHub.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05107",
        "abstract url": "https://arxiv.org/abs/2404.05107",
        "title": "Reconstructing Retinal Visual Images from 3T fMRI Data Enhanced by Unsupervised Learning",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "fMRI",
                "Retinal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The reconstruction of human visual inputs from brain activity, particularly through functional Magnetic Resonance Imaging (fMRI), holds promising avenues for unraveling the mechanisms of the human visual system. Despite the significant strides made by deep learning methods in improving the quality and interpretability of visual reconstruction, there remains a substantial demand for high-quality, long-duration, subject-specific 7-Tesla fMRI experiments. The challenge arises in integrating diverse smaller 3-Tesla datasets or accommodating new subjects with brief and low-quality fMRI scans. In response to these constraints, we propose a novel framework that generates enhanced 3T fMRI data through an unsupervised Generative Adversarial Network (GAN), leveraging unpaired training across two distinct fMRI datasets in 7T and 3T, respectively. This approach aims to overcome the limitations of the scarcity of high-quality 7-Tesla data and the challenges associated with brief and low-quality scans in 3-Tesla experiments. In this paper, we demonstrate the reconstruction capabilities of the enhanced 3T fMRI data, highlighting its proficiency in generating superior input visual images compared to data-intensive methods trained and tested on a single subject.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ISBI 2024"
    },
    {
        "paper id": "2404.05120",
        "abstract url": "https://arxiv.org/abs/2404.05120",
        "title": "Rollbot: a Spherical Robot Driven by a Single Actuator",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Here we present Rollbot, the first spherical robot capable of controllably maneuvering on 2D plane with a single actuator. Rollbot rolls on the ground in circular pattern and controls its motion by changing the curvature of the trajectory through accelerating and decelerating its single motor and attached mass. We present the theoretical analysis, design, and control of Rollbot, and demonstrate its ability to move in a controllable circular pattern and follow waypoints.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Submission to IROS 2024"
    },
    {
        "paper id": "2404.05130",
        "abstract url": "https://arxiv.org/abs/2404.05130",
        "title": "Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning",
        "rating": "-2",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Despite achieving good performance and wide adoption, machine learning based security detection models (e.g., malware classifiers) are subject to concept drift and evasive evolution of attackers, which renders up-to-date threat data as a necessity. However, due to enforcement of various privacy protection regulations (e.g., GDPR), it is becoming increasingly challenging or even prohibitive for security vendors to collect individual-relevant and privacy-sensitive threat datasets, e.g., SMS spam/non-spam messages from mobile devices. To address such obstacles, this study systematically profiles the (in)feasibility of federated learning for privacy-preserving cyber threat detection in terms of effectiveness, byzantine resilience, and efficiency. This is made possible by the build-up of multiple threat datasets and threat detection models, and more importantly, the design of realistic and security-specific experiments. We evaluate FL on two representative threat detection tasks, namely SMS spam detection and Android malware detection. It shows that FL-trained detection models can achieve a performance that is comparable to centrally trained counterparts. Also, most non-IID data distributions have either minor or negligible impact on the model performance, while a label-based non-IID distribution of a high extent can incur non-negligible fluctuation and delay in FL training. Then, under a realistic threat model, FL turns out to be adversary-resistant to attacks of both data poisoning and model poisoning. Particularly, the attacking impact of a practical data poisoning attack is no more than 0.14\\% loss in model accuracy. Regarding FL efficiency, a bootstrapping strategy turns out to be effective to mitigate the training delay as observed in label-based non-IID scenarios.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05149",
        "abstract url": "https://arxiv.org/abs/2404.05149",
        "title": "Intelligent Reflecting Surface Aided Target Localization With Unknown Transceiver-IRS Channel State Information",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Integrating wireless sensing capabilities into base stations (BSs) has become a widespread trend in the future beyond fifth-generation (B5G)/sixth-generation (6G) wireless networks. In this paper, we investigate intelligent reflecting surface (IRS) enabled wireless localization, in which an IRS is deployed to assist a BS in locating a target in its non-line-of-sight (NLoS) region. In particular, we consider the case where the BS-IRS channel state information (CSI) is unknown. Specifically, we first propose a separate BS-IRS channel estimation scheme in which the BS operates in full-duplex mode (FDM), i.e., a portion of the BS antennas send downlink pilot signals to the IRS, while the remaining BS antennas receive the uplink pilot signals reflected by the IRS. However, we can only obtain an incomplete BS-IRS channel matrix based on our developed iterative coordinate descent-based channel estimation algorithm due to the \"sign ambiguity issue\". Then, we employ the multiple hypotheses testing framework to perform target localization based on the incomplete estimated channel, in which the probability of each hypothesis is updated using Bayesian inference at each cycle. Moreover, we formulate a joint BS transmit waveform and IRS phase shifts optimization problem to improve the target localization performance by maximizing the weighted sum distance between each two hypotheses. However, the objective function is essentially a quartic function of the IRS phase shift vector, thus motivating us to resort to the penalty-based method to tackle this challenge. Simulation results validate the effectiveness of our proposed target localization scheme and show that the scheme's performance can be further improved by finely designing the BS transmit waveform and IRS phase shifts intending to maximize the weighted sum distance between different hypotheses.",
        "subjects": [
            "cs.ET",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05159",
        "abstract url": "https://arxiv.org/abs/2404.05159",
        "title": "Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods",
        "rating": "-2",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "healthcare"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In various real-world applications such as machine translation, sentiment analysis, and question answering, a pivotal role is played by NLP models, facilitating efficient communication and decision-making processes in domains ranging from healthcare to finance. However, a significant challenge is posed to the robustness of these natural language processing models by text adversarial attacks. These attacks involve the deliberate manipulation of input text to mislead the predictions of the model while maintaining human interpretability. Despite the remarkable performance achieved by state-of-the-art models like BERT in various natural language processing tasks, they are found to remain vulnerable to adversarial perturbations in the input text. In addressing the vulnerability of text classifiers to adversarial attacks, three distinct attack mechanisms are explored in this paper using the victim model BERT: BERT-on-BERT attack, PWWS attack, and Fraud Bargain's Attack (FBA). Leveraging the IMDB, AG News, and SST2 datasets, a thorough comparative analysis is conducted to assess the effectiveness of these attacks on the BERT classifier model. It is revealed by the analysis that PWWS emerges as the most potent adversary, consistently outperforming other methods across multiple evaluation scenarios, thereby emphasizing its efficacy in generating adversarial examples for text classification. Through comprehensive experimentation, the performance of these attacks is assessed and the findings indicate that the PWWS attack outperforms others, demonstrating lower runtime, higher accuracy, and favorable semantic similarity scores. The key insight of this paper lies in the assessment of the relative performances of three prevalent state-of-the-art attack mechanisms.",
        "subjects": [
            "cs.CL",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "This report pertains to the Capstone Project done by Group 2 of the Fall batch of 2023 students at Praxis Tech School, Kolkata, India. The reports consists of 28 pages and it includes 10 tables. This is the preprint which will be submitted to IEEE CONIT 2024 for review"
    },
    {
        "paper id": "2404.04878",
        "abstract url": "https://arxiv.org/abs/2404.04878",
        "title": "CycleINR: Cycle Implicit Neural Representation for Arbitrary-Scale Volumetric Super-Resolution of Medical Data",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Super-Resolution"
            ],
            [
                "Medical",
                "MRI",
                "CT",
                "clinical",
                "tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In the realm of medical 3D data, such as CT and MRI images, prevalent anisotropic resolution is characterized by high intra-slice but diminished inter-slice resolution. The lowered resolution between adjacent slices poses challenges, hindering optimal viewing experiences and impeding the development of robust downstream analysis algorithms. Various volumetric super-resolution algorithms aim to surmount these challenges, enhancing inter-slice resolution and overall 3D medical imaging quality. However, existing approaches confront inherent challenges: 1) often tailored to specific upsampling factors, lacking flexibility for diverse clinical scenarios; 2) newly generated slices frequently suffer from over-smoothing, degrading fine details, and leading to inter-slice inconsistency. In response, this study presents CycleINR, a novel enhanced Implicit Neural Representation model for 3D medical data volumetric super-resolution. Leveraging the continuity of the learned implicit function, the CycleINR model can achieve results with arbitrary up-sampling rates, eliminating the need for separate training. Additionally, we enhance the grid sampling in CycleINR with a local attention mechanism and mitigate over-smoothing by integrating cycle-consistent loss. We introduce a new metric, Slice-wise Noise Level Inconsistency (SNLI), to quantitatively assess inter-slice noise level inconsistency. The effectiveness of our approach is demonstrated through image quality evaluations on an in-house dataset and a downstream task analysis on the Medical Segmentation Decathlon liver tumor dataset.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "CVPR accepted paper"
    },
    {
        "paper id": "2404.04879",
        "abstract url": "https://arxiv.org/abs/2404.04879",
        "title": "Multi-Type Map Construction via Semantics-Aware Autonomous Exploration in Unknown Indoor Environments",
        "rating": "-3",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "This paper proposes a novel semantics-aware autonomous exploration model to handle the long-standing issue: the mainstream RRT (Rapid-exploration Random Tree) based exploration models usually make the mobile robot switch frequently between different regions, leading to the excessively-repeated explorations for the same region. Our proposed semantics-aware model encourages a mobile robot to fully explore the current region before moving to the next region, which is able to avoid excessively-repeated explorations and make the exploration faster. The core idea of semantics-aware autonomous exploration model is optimizing the sampling point selection mechanism and frontier point evaluation function by considering the semantic information of regions. In addition, compared with existing autonomous exploration methods that usually construct the single-type or 2-3 types of maps, our model allows to construct four kinds of maps including point cloud map, occupancy grid map, topological map, and semantic map. To test the performance of our model, we conducted experiments in three simulated environments. The experiment results demonstrate that compared to Improved RRT, our model achieved 33.0% exploration time reduction and 39.3% exploration trajectory length reduction when maintaining >98% exploration rate.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04880",
        "abstract url": "https://arxiv.org/abs/2404.04880",
        "title": "GauU-Scene V2: Assessing the Reliability of Image-Based Metrics with Expansive Lidar Image Dataset Using 3DGS and NeRF",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "Lidar"
            ],
            [
                "drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a novel, multimodal large-scale scene reconstruction benchmark that utilizes newly developed 3D representation approaches: Gaussian Splatting and Neural Radiance Fields (NeRF). Our expansive U-Scene dataset surpasses any previously existing real large-scale outdoor LiDAR and image dataset in both area and point count. GauU-Scene encompasses over 6.5 square kilometers and features a comprehensive RGB dataset coupled with LiDAR ground truth. Additionally, we are the first to propose a LiDAR and image alignment method for a drone-based dataset. Our assessment of GauU-Scene includes a detailed analysis across various novel viewpoints, employing image-based metrics such as SSIM, LPIPS, and PSNR on NeRF and Gaussian Splatting based methods. This analysis reveals contradictory results when applying geometric-based metrics like Chamfer distance. The experimental results on our multimodal dataset highlight the unreliability of current image-based metrics and reveal significant drawbacks in geometric reconstruction using the current Gaussian Splatting-based method, further illustrating the necessity of our dataset for assessing geometry reconstruction tasks. We also provide detailed supplementary information on data collection protocols and make the dataset available on the following anonymous project page",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04904",
        "abstract url": "https://arxiv.org/abs/2404.04904",
        "title": "Cross-Domain Audio Deepfake Detection: Dataset and Analysis",
        "rating": "-3",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "attack"
            ],
            [
                "neural codec"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Audio deepfake detection (ADD) is essential for preventing the misuse of synthetic voices that may infringe on personal rights and privacy. Recent zero-shot text-to-speech (TTS) models pose higher risks as they can clone voices with a single utterance. However, the existing ADD datasets are outdated, leading to suboptimal generalization of detection models. In this paper, we construct a new cross-domain ADD dataset comprising over 300 hours of speech data that is generated by five advanced zero-shot TTS models. To simulate real-world scenarios, we employ diverse attack methods and audio prompts from different datasets. Experiments show that, through novel attack-augmented training, the Wav2Vec2-large and Whisper-medium models achieve equal error rates of 4.1\\% and 6.5\\% respectively. Additionally, we demonstrate our models' outstanding few-shot ADD ability by fine-tuning with just one minute of target-domain data. Nonetheless, neural codec compressors greatly affect the detection accuracy, necessitating further research.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05024",
        "abstract url": "https://arxiv.org/abs/2404.05024",
        "title": "PathFinder: Attention-Driven Dynamic Non-Line-of-Sight Tracking with a Mobile Robot",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ],
            [
                "drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The study of non-line-of-sight (NLOS) imaging is growing due to its many potential applications, including rescue operations and pedestrian detection by self-driving cars. However, implementing NLOS imaging on a moving camera remains an open area of research. Existing NLOS imaging methods rely on time-resolved detectors and laser configurations that require precise optical alignment, making it difficult to deploy them in dynamic environments. This work proposes a data-driven approach to NLOS imaging, PathFinder, that can be used with a standard RGB camera mounted on a small, power-constrained mobile robot, such as an aerial drone. Our experimental pipeline is designed to accurately estimate the 2D trajectory of a person who moves in a Manhattan-world environment while remaining hidden from the camera's field-of-view. We introduce a novel approach to process a sequence of dynamic successive frames in a line-of-sight (LOS) video using an attention-based neural network that performs inference in real-time. The method also includes a preprocessing selection metric that analyzes images from a moving camera which contain multiple vertical planar surfaces, such as walls and building facades, and extracts planes that return maximum NLOS information. We validate the approach on in-the-wild scenes using a drone for video capture, thus demonstrating low-cost NLOS imaging in dynamic capture environments.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "First two authors have equal contribution"
    },
    {
        "paper id": "2404.05088",
        "abstract url": "https://arxiv.org/abs/2404.05088",
        "title": "How much reliable is ChatGPT's prediction on Information Extraction under Input Perturbations?",
        "rating": "-3",
        "keywords": [
            [
                "Disease"
            ],
            [
                "Named Entity Recognition"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we assess the robustness (reliability) of ChatGPT under input perturbations for one of the most fundamental tasks of Information Extraction (IE) i.e. Named Entity Recognition (NER). Despite the hype, the majority of the researchers have vouched for its language understanding and generation capabilities; a little attention has been paid to understand its robustness: How the input-perturbations affect 1) the predictions, 2) the confidence of predictions and 3) the quality of rationale behind its prediction. We perform a systematic analysis of ChatGPT's robustness (under both zero-shot and few-shot setup) on two NER datasets using both automatic and human evaluation. Based on automatic evaluation metrics, we find that 1) ChatGPT is more brittle on Drug or Disease replacements (rare entities) compared to the perturbations on widely known Person or Location entities, 2) the quality of explanations for the same entity considerably differ under different types of \"Entity-Specific\" and \"Context-Specific\" perturbations and the quality can be significantly improved using in-context learning, and 3) it is overconfident for majority of the incorrect predictions, and hence it could lead to misguidance of the end-users.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "3 Figures, 7 Tables"
    },
    {
        "paper id": "2404.04885",
        "abstract url": "https://arxiv.org/abs/2404.04885",
        "title": "TimeGPT in Load Forecasting: A Large Time Series Model Perspective",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models have made significant progress in load forecasting, but their forecast accuracy is limited in cases where historical load data is scarce. Inspired by the outstanding performance of large language models (LLMs) in computer vision and natural language processing, this paper aims to discuss the potential of large time series models in load forecasting with scarce historical data. Specifically, the large time series model is constructed as a time series generative pre-trained transformer (TimeGPT), which is trained on massive and diverse time series datasets consisting of 100 billion data points (e.g., finance, transportation, banking, web traffic, weather, energy, healthcare, etc.). Then, the scarce historical load data is used to fine-tune the TimeGPT, which helps it to adapt to the data distribution and characteristics associated with load forecasting. Simulation results show that TimeGPT outperforms the benchmarks (e.g., popular machine learning models and statistical models) for load forecasting on several real datasets with scarce training samples, particularly for short look-ahead times. However, it cannot be guaranteed that TimeGPT is always superior to benchmarks for load forecasting with scarce data, since the performance of TimeGPT may be affected by the distribution differences between the load data and the training data. In practical applications, we can divide the historical data into a training set and a validation set, and then use the validation set loss to decide whether TimeGPT is the best choice for a specific dataset.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2404.04820",
        "abstract url": "https://arxiv.org/abs/2404.04820",
        "title": "Single-Server Pliable Private Information Retrieval with Identifiable Side Information",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Pliable Private Information Retrieval (PPIR) with a single server, messages are partitioned into $\u0393$ non-overlapping classes. The user wants to retrieve a message from its desired class without revealing the identity of the desired class to the server. In S. A. Obead, H. Y. Lin and E. Rosnes, Single-Server Pliable Private Information Retrieval With Side Information, arXiv:2305.06857, authors consider the problem of PPIR with Side Information (PPIR-SI), where the user now has side information. The user wants to retrieve any new message (not included in the side information) from its desired class without revealing the identity of the desired class and its side information. A scheme for the PPIR-SI is given by Obead et al. for the case when the users side information is unidentified, and this case is referred to as PPIR with Unidentifiable SI (PPIR-USI). In this paper, we study the problem of PPIR for the single server case when the side information is partially identifiable, and we term this case as PPIR with Identifiable Side Information (PPIR-ISI). The user is well aware of the identity of the side information belonging to $\u03b7$ number of classes, where $1\\leq \u03b7\\leq \u0393$. In this problem, The user wants to retrieve a message from its desired class without revealing the identity of the desired class to the server. We give a scheme for PPIR-ISI, and we prove that having identifiable side information is advantageous by comparing the rate of the proposed scheme to the rate of the PPIR-USI scheme given by Obead et al. for some cases. Further, we extend the problem of PPIR-ISI for multi-user case, where users can collaborately generate the query sets, and we give a scheme for this problem.",
        "subjects": [
            "cs.IT",
            "cs.IR"
        ],
        "comment": "11 pages and 3 figures Additional references included"
    },
    {
        "paper id": "2404.04822",
        "abstract url": "https://arxiv.org/abs/2404.04822",
        "title": "Some Characterizations of TTC in Multiple-Object Exchange Problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers exchange of indivisible objects when agents are endowed with and desire bundles of objects. Agents are assumed to have lexicographic preferences over bundles. We show that Top Trading Cycles (TTC) is characterized by efficiency, the weak endowment lower bound, balancedness, and truncation-proofness. In the classic Shapley--Scarf Economy, TTC is characterized by efficiency, individual rationality, and truncation-proofness. These results strengthen the uniqueness results of Ma (1994) and, more recently, Altunta\u015f et al. (2023). In a model with variable endowments, TTC is susceptible to various forms of endowment manipulation. However, no rule is core-selecting and hiding-proof.",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "comment": "28 pages"
    },
    {
        "paper id": "2404.04834",
        "abstract url": "https://arxiv.org/abs/2404.04834",
        "title": "LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead",
        "rating": "-10",
        "keywords": [],
        "abstract": "Integrating Large Language Models(LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities competitive to human planning and reasoning. This paper envisions the evolution of LLM-based Multi-Agent (LMA) systems in addressing complex and multi-faceted software engineering challenges. LMA systems introduce numerous benefits, including enhanced robustness through collaborative cross-examination, autonomous problem-solving, and scalable solutions to complex software projects. By examining the role of LMA systems in future software engineering practices, this vision paper highlights the potential applications and emerging challenges. We further point to specific opportunities for research and conclude with a research agenda with a set of research questions to guide future research directions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04837",
        "abstract url": "https://arxiv.org/abs/2404.04837",
        "title": "GATlab: Modeling and Programming with Generalized Algebraic Theories",
        "rating": "-10",
        "keywords": [],
        "abstract": "Categories and categorical structures are increasingly recognized as useful abstractions for modeling in science and engineering. To uniformly implement category-theoretic mathematical models in software, we introduce GATlab, a domain-specific language for algebraic specification embedded in a technical programming language. GATlab is based on generalized algebraic theories (GATs), a logical system extending algebraic theories with dependent types so as to encompass category theory. Using GATlab, the programmer can specify generalized algebraic theories and their models, including both free models, based on symbolic expressions, and computational models, defined by arbitrary code in the host language. Moreover, the programmer can define maps between theories and use them to declaratively migrate models of one theory to models of another. In short, GATlab aims to provide a unified environment for both computer algebra and software interface design with generalized algebraic theories. In this paper, we describe the design, implementation, and applications of GATlab.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": "15 pages plus references"
    },
    {
        "paper id": "2404.04841",
        "abstract url": "https://arxiv.org/abs/2404.04841",
        "title": "Unveiling Decentralization: A Comprehensive Review of Technologies, Comparison, Challenges in Bitcoin, Ethereum, and Solana Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bitcoin stands as a groundbreaking development in decentralized exchange throughout human history, enabling transactions without the need for intermediaries. By leveraging cryptographic proof mechanisms, Bitcoin eliminates the reliance on third-party financial institutions. Ethereum, ranking as the second-largest cryptocurrency by market capitalization, builds upon Bitcoin's groundwork by introducing smart contracts and decentralized applications. Ethereum strives to surpass the limitations of Bitcoin's scripting language, achieving full Turing-completeness for executing intricate computational tasks. Solana introduces a novel architecture for high-performance blockchain, employing timestamps to validate decentralized transactions and significantly boosting block creation throughput. Through a comprehensive examination of these blockchain technologies, their distinctions, and the associated challenges, this paper aims to offer valuable insights and comparative analysis for both researchers and practitioners.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04842",
        "abstract url": "https://arxiv.org/abs/2404.04842",
        "title": "Analog-Digital Beam Focusing for Line of Sight Wide-Aperture MIMO with Spherical Wavefronts",
        "rating": "-10",
        "keywords": [],
        "abstract": "Enhancing high-speed wireless communication in the future relies significantly on harnessing high frequency bands effectively. These bands predominantly operate in line-of-sight (LoS) paths, necessitating well-configured antenna arrays and beamforming techniques for optimal spectrum utilization. Maximizing the potential of LoS multiple-input multiple-output (MIMO) systems, which are crucial for achieving high spectral efficiency, heavily depends on this. As the costs and power demands of mixed-signal devices in high frequency bands make a fully-digital architecture impractical for large-scale MIMO setups, our focus shifts to a hybrid analog-digital hardware configuration. Yet, analog processors' limitations restrict flexibility within arrays, necessitating a nuanced understanding of hardware constraints for optimal antenna configuration design. We explore array design that optimizes the spectral efficiency of hybrid systems, considering hardware constraints. We propose an optimal antenna configuration, leveraging the prolate matrix structure of the LoS channel between two planar arrays. Building on the optimal array configuration, we introduce a low-complexity explicit analog-digital beam focusing scheme that exploits the asymptotic behavior of the LoS channel matrix in the near-field region. Simulation results validate that the proposed antenna configuration and beam focusing scheme achieves near-optimal performance across a range of signal-to-noise ratios with low computational complexity, even under arbitrary rotations relative to the communication link.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04861",
        "abstract url": "https://arxiv.org/abs/2404.04861",
        "title": "Privacy-Preserving Traceable Functional Encryption for Inner Product",
        "rating": "-10",
        "keywords": [],
        "abstract": "Functional encryption introduces a new paradigm of public key encryption that decryption only reveals the function value of encrypted data. To curb key leakage issues and trace users in FE-IP, a new primitive called traceable functional encryption for inner product (TFE-IP) has been proposed. However, the privacy protection of user's identities has not been considered in the existing TFE-IP schemes. In order to balance privacy and accountability, we propose the concept of privacy-preserving traceable functional encryption for inner product (PPTFE-IP) and give a concrete construction. Our scheme provides the following features: (1) To prevent key sharing, a user's key is bound with both his/her identity and a vector; (2) The key generation center (KGC) and a user execute a two-party secure computing protocol to generate a key without the former knowing anything about the latter's identity; (3) Each user can verify the correctness of his/her key; (4) A user can calculate the inner product of the two vectors embedded in his/her key and in a ciphertext; (5) Only the tracer can trace the identity embedded in a key. The security of our scheme is formally reduced to well-known complexity assumptions, and the implementation is conducted to evaluate its efficiency. The novelty of our scheme is to protect users' privacy and provide traceability if required.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04862",
        "abstract url": "https://arxiv.org/abs/2404.04862",
        "title": "Efficient and Provably Convergent Computation of Information Bottleneck: A Semi-Relaxed Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Information Bottleneck (IB) is a technique to extract information about one target random variable through another relevant random variable. This technique has garnered significant interest due to its broad applications in information theory and deep learning. Hence, there is a strong motivation to develop efficient numerical methods with high precision and theoretical convergence guarantees. In this paper, we propose a semi-relaxed IB model, where the Markov chain and transition probability condition are relaxed from the relevance-compression function. Based on the proposed model, we develop an algorithm, which recovers the relaxed constraints and involves only closed-form iterations. Specifically, the algorithm is obtained by analyzing the Lagrangian of the relaxed model with alternating minimization in each direction. The convergence property of the proposed algorithm is theoretically guaranteed through descent estimation and Pinsker's inequality. Numerical experiments across classical and discrete distributions corroborate the analysis. Moreover, our proposed algorithm demonstrates notable advantages in terms of computational efficiency, evidenced by significantly reduced run times compared to existing methods with comparable accuracy.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04894",
        "abstract url": "https://arxiv.org/abs/2404.04894",
        "title": "Theoretical Analysis of the Three-Dimensional CAC Considering Connection and Communication Quality",
        "rating": "-10",
        "keywords": [],
        "abstract": "In emergencies such as disasters, the number of voice calls (VoIP sessions) increases rapidly for a variety of purposes. Thus, a control server near a disaster area may not be able to connect to VoIP sessions due to congestion. To solve this problem, a Call Admission Control (CAC) is needed to determine whether a VoIP session requesting a connection can be accepted or rejected. A CAC has the purpose of guaranteeing the connection quality and communication quality of VoIP sessions. One conventional method classifies VoIP sessions into three classes (emergency VoIP sessions, VoIP sessions from the disaster area, and VoIP sessions from outside the disaster area) by focusing on the outgoing location and offers a CAC with a priority level for each. However, a conventional CAC method cannot be applied to VoIP networks because reception control is designed for Public Switched Telephone Networks (PSTN). When conventional methods are applied to VoIP networks, the connection quality is guaranteed, however the communication quality cannot be guaranteed because the packet dropping probability is not considered. In this paper, we propose a three-dimensional CAC that controls three classes of VoIP sessions and guarantees both communication and connection quality in VoIP networks during emergencies. A conventional CAC method and our proposed CAC method are evaluated in terms of the call blocking probability, which guarantees the connection quality, and packet dropping probability, which guarantees the communication quality, to show the effectiveness of the proposed method.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": "25 pages, 31 figures"
    },
    {
        "paper id": "2404.04895",
        "abstract url": "https://arxiv.org/abs/2404.04895",
        "title": "Tensorized Ant Colony Optimization for GPU Acceleration",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ant Colony Optimization (ACO) is renowned for its effectiveness in solving Traveling Salesman Problems, yet it faces computational challenges in CPU-based environments, particularly with large-scale instances. In response, we introduce a Tensorized Ant Colony Optimization (TensorACO) to utilize the advancements of GPU acceleration. As the core, TensorACO fully transforms ant system and ant path into tensor forms, a process we refer to as tensorization. For the tensorization of ant system, we propose a preprocessing method to reduce the computational overhead by calculating the probability transition matrix. In the tensorization of ant path, we propose an index mapping method to accelerate the update of pheromone matrix by replacing the mechanism of sequential path update with parallel matrix operations. Additionally, we introduce an Adaptive Independent Roulette (AdaIR) method to overcome the challenges of parallelizing ACO's selection mechanism on GPUs. Comprehensive experiments demonstrate the superior performance of TensorACO achieving up to 1921$\\times$ speedup over standard ACO. Moreover, the AdaIR method further improves TensorACO's convergence speed by 80% and solution quality by 2%. Source codes are available at https://github.com/EMI-Group/tensoraco.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "Genetic and Evolutionary Computation Conference (GECCO '24)"
    },
    {
        "paper id": "2404.04919",
        "abstract url": "https://arxiv.org/abs/2404.04919",
        "title": "The Use of MEMS Accelerometers for Remote Activity and Living Parameters Monitoring",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the paper a ballistocardiographic sensor for remote monitoring of activity and vital parameters is presented. The sensor is mainly intended for use in monitoring systems supporting care of older people. It allows to detect occupancy of a piece of furniture, to which it is attached and to estimate basic vital parameters (heart and respiration rates) of the monitored person. The presented device includes three inertial sensors: two accelerometers of different parameters and prices and one reference BCG module. The device sends the measurement results to the external server over WiFi. The vital parameters are estimated based on the Continuous Wavelet Transform of the registered acceleration signals. User's presence is detected by tracking changes in acceleration measured in axes parallel to the ground.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Originally presented at 2020 Baltic URSI Symposium (URSI), Warsaw, Poland, 2020"
    },
    {
        "paper id": "2404.04927",
        "abstract url": "https://arxiv.org/abs/2404.04927",
        "title": "Holographic Integrated Data and Energy Transfer",
        "rating": "-10",
        "keywords": [],
        "abstract": "Thanks to the application of metamaterials, holographic multiple-input multiple-output (H-MIMO) is expected to achieve a higher spatial diversity gain by enabling the ability to generate any current distribution on the surface. With the aid of electromagnetic (EM) manipulation capability of H-MIMO, integrated data and energy transfer (IDET) system can fully exploits the EM channel to realize energy focusing and eliminate inter-user interference, which yields the concept of holographic IDET (H-IDET). In this paper, we invetigate the beamforming designs for H-IDET systems, where the sum-rate of data users (DUs) are maximized by guaranteeing the energy harvesting requirements of energy users (EUs). In order to solve the non-convex functional programming, a block coordinate descent (BCD) based scheme is proposed, wherein the Fourier transform and the equivalence between the signal-to-interference-plus-noise ratio (SINR) and the mean-square error (MSE) are also conceived, followed by the successive convex approximation (SCA) and an initialization scheme to enhance robustness. Numerical results illustrate that our proposed H-IDET scheme outperforms benchmark schemes, especially the one adopting traditional discrete antennas. Besides, the near-field focusing using EM channel model achieves better performance compared to that using the traditional channel model, especially for WPT where the EUs are usually close to the transmitter.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.04966",
        "abstract url": "https://arxiv.org/abs/2404.04966",
        "title": "Enhancing LLM-based Test Generation for Hard-to-Cover Branches via Program Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Automatic test generation plays a critical role in software quality assurance. While the recent advances in Search-Based Software Testing (SBST) and Large Language Models (LLMs) have shown promise in generating useful tests, these techniques still struggle to cover certain branches. Reaching these hard-to-cover branches usually requires constructing complex objects and resolving intricate inter-procedural dependencies in branch conditions, which poses significant challenges for existing test generation techniques. In this work, we propose TELPA, a novel technique aimed at addressing these challenges. Its key insight lies in extracting real usage scenarios of the target method under test to learn how to construct complex objects and extracting methods entailing inter-procedural dependencies with hard-to-cover branches to learn the semantics of branch constraints. To enhance efficiency and effectiveness, TELPA identifies a set of ineffective tests as counter-examples for LLMs and employs a feedback-based process to iteratively refine these counter-examples. Then, TELPA integrates program analysis results and counter-examples into the prompt, guiding LLMs to gain deeper understandings of the semantics of the target method and generate diverse tests that can reach the hard-to-cover branches. Our experimental results on 27 open-source Python projects demonstrate that TELPA significantly outperforms the state-of-the-art SBST and LLM-based techniques, achieving an average improvement of 31.39% and 22.22% in terms of branch coverage.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2404.05007",
        "abstract url": "https://arxiv.org/abs/2404.05007",
        "title": "Reduction of Forgetting by Contextual Variation During Encoding Using 360-Degree Video-Based Immersive Virtual Environments",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recall impairment in a different environmental context from learning is called context-dependent forgetting. Two learning methods have been proposed to prevent context-dependent forgetting: reinstatement and decontextualization. Reinstatement matches the environmental context between learning and retrieval, whereas decontextualization involves repeated learning in various environmental contexts and eliminates the context dependency of memory. Conventionally, these methods have been validated by switching between physical rooms. However, in this study, we use immersive virtual environments (IVEs) as the environmental context assisted by virtual reality (VR), which is known for its low cost and high reproducibility compared to traditional manipulation. Whereas most existing studies using VR have failed to reveal the reinstatement effect, we test its occurrence using a 360-degree video-based IVE with improved familiarity and realism instead of a computer graphics-based IVE. Furthermore, we are the first to address decontextualization using VR. Our experiment showed that repeated learning in the same constant IVE as retrieval did not significantly reduce forgetting compared to repeated learning in different constant IVEs. Conversely, repeated learning in various IVEs significantly reduced forgetting than repeated learning in constant IVEs. These findings contribute to the design of IVEs for VR-based applications, particularly in educational settings.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05036",
        "abstract url": "https://arxiv.org/abs/2404.05036",
        "title": "The Hyperdrive Protocol: An Automated Market Maker for Fixed and Variable Rates",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hyperdrive is a protocol designed to facilitate the trading of fixed and variable rate assets. The protocol's unique pricing model consolidates liquidity into a single pool which addresses the challenges of fragmented liquidity across terms, eliminates the need for rollovers, and allows terms to be issued on demand. Its design meaningfully improves trading efficiency, liquidity provisioning, and user experience over existing fixed and variable rate protocol models.",
        "subjects": [
            "cs.GT",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05040",
        "abstract url": "https://arxiv.org/abs/2404.05040",
        "title": "Lagrangian operator inference enhanced with structure-preserving machine learning for nonintrusive model reduction of mechanical systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Complex mechanical systems often exhibit strongly nonlinear behavior due to the presence of nonlinearities in the energy dissipation mechanisms, material constitutive relationships, or geometric/connectivity mechanics. Numerical modeling of these systems leads to nonlinear full-order models that possess an underlying Lagrangian structure. This work proposes a Lagrangian operator inference method enhanced with structure-preserving machine learning to learn nonlinear reduced-order models (ROMs) of nonlinear mechanical systems. This two-step approach first learns the best-fit linear Lagrangian ROM via Lagrangian operator inference and then presents a structure-preserving machine learning method to learn nonlinearities in the reduced space. The proposed approach can learn a structure-preserving nonlinear ROM purely from data, unlike the existing operator inference approaches that require knowledge about the mathematical form of nonlinear terms. From a machine learning perspective, it accelerates the training of the structure-preserving neural network by providing an informed prior, and it reduces the computational cost of the network training by operating on the reduced space. The method is first demonstrated on two simulated examples: a conservative nonlinear rod model and a two-dimensional nonlinear membrane with nonlinear internal damping. Finally, the method is demonstrated on an experimental dataset consisting of digital image correlation measurements taken from a lap-joint beam structure from which a predictive model is learned that captures amplitude-dependent frequency and damping characteristics accurately. The numerical results demonstrate that the proposed approach yields generalizable nonlinear ROMs that exhibit bounded energy error, capture the nonlinear characteristics reliably, and provide accurate long-time predictions outside the training data regime.",
        "subjects": [
            "cs.CE",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05041",
        "abstract url": "https://arxiv.org/abs/2404.05041",
        "title": "How Do OSS Developers Utilize Architectural Solutions from Q&A Sites: An Empirical Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "Developers utilize programming-related knowledge (e.g., code snippets) on Q&A sites (e.g., Stack Overflow) that functionally matches the programming problems they encounter in their development. Despite extensive research on Q&A sites, being a high-level and important type of development-related knowledge, architectural solutions (e.g., architecture tactics) and their utilization are rarely explored. To fill this gap, we conducted a mixed-methods study that includes a mining study and a survey study. For the mining study, we mined 984 commits and issues (i.e., 821 commits and 163 issues) from 893 Open-Source Software (OSS) projects on GitHub that explicitly referenced architectural solutions from Stack Overflow (SO) and Software Engineering Stack Exchange (SWESE). For the survey study, we identified practitioners involved in the utilization of these architectural solutions and surveyed 227 of them to further understand how practitioners utilize architectural solutions from Q&A sites in their OSS development. Our main findings are that: (1) OSS practitioners use architectural solutions from Q&A sites to solve a large variety (15 categories) of architectural problems, wherein Component design issue, Architectural anti-pattern, and Security issue are dominant; (2) Seven categories of architectural solutions from Q&A sites have been utilized to solve those problems, among which Architectural refactoring, Use of frameworks, and Architectural tactic are the three most utilized architectural solutions; (3) Using architectural solutions from SO comes with a variety of challenges, e.g., OSS practitioners complain that they need to spend significant time to adapt such architectural solutions to address design concerns raised in their OSS development, and it is challenging to use architectural solutions that are not tailored to the design context of their OSS projects.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05045",
        "abstract url": "https://arxiv.org/abs/2404.05045",
        "title": "Spanners in Planar Domains via Steiner Spanners and non-Steiner Tree Covers",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study spanners in planar domains, including polygonal domains, polyhedral terrain, and planar metrics. Previous work showed that for any constant $\u03b5\\in (0,1)$, one could construct a $(2+\u03b5)$-spanner with $O(n\\log(n))$ edges (SICOMP 2019), and there is a lower bound of $\u03a9(n^2)$ edges for any $(2-\u03b5)$-spanner (SoCG 2015). The main open question is whether a linear number of edges suffices and the stretch can be reduced to $2$. We resolve this problem by showing that for stretch $2$, one needs $\u03a9(n\\log n)$ edges, and for stretch $2+\u03b5$ for any fixed $\u03b5\\in (0,1)$, $O(n)$ edges are sufficient. Our lower bound is the first super-linear lower bound for stretch $2$. En route to achieve our result, we introduce the problem of constructing non-Steiner tree covers for metrics, which is a natural variant of the well-known Steiner point removal problem for trees (SODA 2001). Given a tree and a set of terminals in the tree, our goal is to construct a collection of a small number of dominating trees such that for every two points, at least one tree in the collection preserves their distance within a small stretch factor. Here, we identify an unexpected threshold phenomenon around $2$ where a sharp transition from $n$ trees to $\u0398(\\log n)$ trees and then to $O(1)$ trees happens. Specifically, (i) for stretch $ 2-\u03b5$, one needs $\u03a9(n)$ trees; (ii) for stretch $2$, $\u0398(\\log n)$ tree is necessary and sufficient; and (iii) for stretch $2+\u03b5$, a constant number of trees suffice. Furthermore, our lower bound technique for the non-Steiner tree covers of stretch $2$ has further applications in proving lower bounds for two related constructions in tree metrics: reliable spanners and locality-sensitive orderings. Our lower bound for locality-sensitive orderings matches the best upper bound (STOC 2022).",
        "subjects": [
            "cs.CG",
            "cs.DS"
        ],
        "comment": "40 pages, 11 figures. Abstract shorten to meet Arxiv limits"
    },
    {
        "paper id": "2404.05053",
        "abstract url": "https://arxiv.org/abs/2404.05053",
        "title": "Cooking Poisons: Thinking Laterally with Game Theory",
        "rating": "-10",
        "keywords": [],
        "abstract": "We revive an old lateral-thinking puzzle by Michael Rabin, involving poisons with strange properties. We show that the puzzle admits several unintended solutions that are just as interesting as the intended solution. Analyzing these alternative solutions using game theory yields surprisingly subtle results and several unanswered questions.",
        "subjects": [
            "math.CO",
            "cs.GT"
        ],
        "comment": "7 pages, to be published in Mathematics Magazine"
    },
    {
        "paper id": "2404.05076",
        "abstract url": "https://arxiv.org/abs/2404.05076",
        "title": "Performance Analysis of Wideband Near-Field Sensing (NISE)",
        "rating": "-10",
        "keywords": [],
        "abstract": "The impact of large bandwidth on near-filed sensing (NISE) is analyzed in multi-carrier systems. The fundamental Cramer-Rao bounds (CRBs) for wideband NISE are characterized. In particular, the closed-form CRBs are derived for both uniform linear arrays (ULAs) and uniform circular arrays (UCAs). Then, the asymptotic CRBs are analyzed. It is rigorously proved that: 1) as the number of antennas N increases, the maximum decay rates of asymptotic CRBs are 1/N for ULAs and 1/N^2 for UCAs; 2) as the number of subcarriers M increases, the asymptotic CRBs decay as 1/M^3 for both ULAs and UCAs; and 3) CRBs are inversely proportional to the beamforming gain. Based on the analytical results, two practical beamforming approaches are proposed for near-field wideband integrated sensing and communication (ISAC), namely independent and joint approaches. For the independent approach, the beamformer on each subcarrier is designed exclusively for either sensing or communication. For the joint approach, the beamformer on each subcarrier is jointly optimized for both functions through a low-complexity iterative algorithm. Finally, numerical results show that 1) large bandwidth sets an estimation error ceiling for NISE; 2) NISE performance converges to far-field sensing performance when the bandwidth is extremely large; 3) there is a tradeoff between array size and system bandwidth for achieving a given sensing performance; and 4) the simple independent beamforming approach achieves an ISAC performance close to the complex joint beamforming approach.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures"
    },
    {
        "paper id": "2404.05082",
        "abstract url": "https://arxiv.org/abs/2404.05082",
        "title": "Probabilistic Examination of Least Squares Error in Low-bitwidth Cholesky Decomposition",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose a new approach to justify a round-off error impact on the accuracy of the linear least squares (LS) solution using Cholesky decomposition. This decomposition is widely employed to inverse a matrix in the linear detector of the Multi-User multi-antenna receiver. The proposed stochastic bound is much closer to actual errors than other numerical bounds. It was tested with a half-precision format and validated in realistic scenarios. Experimental results demonstrate our approach predicts errors very close to those achieved by simulations. The proposed approach can be employed to analyze the resulting round-off error in many other applications.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05085",
        "abstract url": "https://arxiv.org/abs/2404.05085",
        "title": "Fork is All You Need in Heterogeneous Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a unified programming model for heterogeneous computing systems. Such systems integrate multiple computing accelerators and memory units to deliver higher performance than CPU-centric systems. Although heterogeneous systems have been adopted by modern workloads such as machine learning, programming remains a critical limiting factor. Conventional heterogeneous programming techniques either impose heavy modifications to the code base or require rewriting the program in a different language. Such programming complexity stems from the lack of a unified abstraction layer for computing and data exchange, which forces each programming model to define its abstractions. However, with the emerging cache-coherent interconnections such as Compute Express Link, we see an opportunity to standardize such architecture heterogeneity and provide a unified programming model. We present CodeFlow, a language runtime system for heterogeneous computing. CodeFlow abstracts architecture computation in programming language runtime and utilizes CXL as a unified data exchange protocol. Workloads written in high-level languages such as C++ and Rust can be compiled to CodeFlow, which schedules different parts of the workload to suitable accelerators without requiring the developer to implement code or call APIs for specific accelerators. CodeFlow reduces programmers' effort in utilizing heterogeneous systems and improves workload performance.",
        "subjects": [
            "cs.ET",
            "cs.DC"
        ],
        "comment": "Presented at the 3rd Workshop on Heterogeneous Composable and Disaggregated Systems (HCDS 2024)"
    },
    {
        "paper id": "2404.05097",
        "abstract url": "https://arxiv.org/abs/2404.05097",
        "title": "Quantitative Weakest Hyper Pre: Unifying Correctness and Incorrectness Hyperproperties via Predicate Transformers",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a novel \\emph{weakest pre calculus} for \\emph{reasoning about quantitative hyperproperties} over \\emph{nondeterministic and probabilistic} programs. Whereas existing calculi allow reasoning about the expected value that a quantity assumes after program termination from a \\emph{single initial state}, we do so for \\emph{initial sets of states} or \\emph{initial probability distributions}. We thus (i)~obtain a weakest pre calculus for hyper Hoare logic and (ii)~enable reasoning about so-called \\emph{hyperquantities} which include expected values but also quantities (e.g. variance) out of scope of previous work. As a byproduct, we obtain a novel strongest post for weighted programs that extends both existing strongest and strongest liberal post calculi. Our framework reveals novel dualities between forward and backward transformers, correctness and incorrectness, as well as nontermination and unreachability.",
        "subjects": [
            "cs.LO",
            "cs.CR",
            "cs.FL",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05103",
        "abstract url": "https://arxiv.org/abs/2404.05103",
        "title": "Chart What I Say: Exploring Cross-Modality Prompt Alignment in AI-Assisted Chart Authoring",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent chart-authoring systems, such as Amazon Q in QuickSight and Copilot for Power BI, demonstrate an emergent focus on supporting natural language input to share meaningful insights from data through chart creation. Currently, chart-authoring systems tend to integrate voice input capabilities by relying on speech-to-text transcription, processing spoken and typed input similarly. However, cross-modality input comparisons in other interaction domains suggest that the structure of spoken and typed-in interactions could notably differ, reflecting variations in user expectations based on interface affordances. Thus, in this work, we compare spoken and typed instructions for chart creation. Findings suggest that while both text and voice instructions cover chart elements and element organization, voice descriptions have a variety of command formats, element characteristics, and complex linguistic features. Based on these findings, we developed guidelines for designing voice-based authoring-oriented systems and additional features that can be incorporated into existing text-based systems to support speech modality.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Will be published In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA 2024)"
    },
    {
        "paper id": "2404.05119",
        "abstract url": "https://arxiv.org/abs/2404.05119",
        "title": "A 0.65-pJ/bit 3.6-TB/s/mm I/O Interface with XTalk Minimizing Affine Signaling for Next-Generation HBM with High Interconnect Density",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an I/O interface with Xtalk Minimizing Affine Signaling (XMAS), which is designed to support high-speed data transmission in die-to-die communication over silicon interposers or similar high-density interconnects susceptible to crosstalk. The operating principles of XMAS are elucidated through rigorous analyses, and its advantages over existing signaling are validated through numerical experiments. XMAS not only demonstrates exceptional crosstalk removing capabilities but also exhibits robustness against noise, especially simultaneous switching noise. Fabricated in a 28-nm CMOS process, the prototype XMAS transceiver achieves an edge density of 3.6TB/s/mm and an energy efficiency of 0.65pJ/b. Compared to the single-ended signaling, the crosstalk-induced peak-to-peak jitter of the received eye with XMAS is reduced by 75% at 10GS/s/pin data rate, and the horizontal eye opening extends to 0.2UI at a bit error rate < 10$^{-12}$.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05125",
        "abstract url": "https://arxiv.org/abs/2404.05125",
        "title": "Optimized LinDistFlow for High-Fidelity Power Flow Modeling of Distribution Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The DistFlow model accurately represents power flows in distribution systems, but the model's nonlinearities result in computational challenges for many optimization applications. Accordingly, a linear approximation known as LinDistFlow is commonly employed. This paper introduces an algorithm for enhancing the accuracy of the LinDistFlow approximation, with the goal of aligning the outputs more closely with those from the nonlinear DistFlow model. Using sensitivity information, our algorithm optimizes the LinDistFlow approximation's coefficient and bias parameters to minimize discrepancies in predictions of voltage magnitudes relative to the nonlinear DistFlow model. The algorithm employs the Truncated Newton Conjugate-Gradient (TNC) optimization method to fine-tune coefficients and bias parameters during an offline training phase in order to improve the LinDistFlow approximation's accuracy in optimization applications. This improves the model's effectiveness across various system scenarios, leading to a marked improvement in predictive accuracy. Numerical results underscore the algorithm's efficacy, showcasing accuracy improvements in $L_{1}$-norm and $L_{\\infty}$-norm losses of up to $92\\%$ and $88\\%$, respectively, relative to the traditional LinDistFlow model. We assess how the optimized parameters perform under changes in the network topology and also validate the optimized LinDistFlow approximation's efficacy in a hosting capacity optimization problem.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05134",
        "abstract url": "https://arxiv.org/abs/2404.05134",
        "title": "LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Models (LLMs) have been widely utilized to perform complex robotic tasks. However, handling external disturbances during tasks is still an open challenge. This paper proposes a novel method to achieve robotic adaptive tasks based on LLMs and Behavior Trees (BTs). It utilizes ChatGPT to reason the descriptive steps of tasks. In order to enable ChatGPT to understand the environment, semantic maps are constructed by an object recognition algorithm. Then, we design a Parser module based on Bidirectional Encoder Representations from Transformers (BERT) to parse these steps into initial BTs. Subsequently, a BTs Update algorithm is proposed to expand the initial BTs dynamically to control robots to perform adaptive tasks. Different from other LLM-based methods for complex robotic tasks, our method outputs variable BTs that can add and execute new actions according to environmental changes, which is robust to external disturbances. Our method is validated with simulation in different practical scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 11figures, WILL PUBLISHED ON ICRA 2024"
    },
    {
        "paper id": "2404.05167",
        "abstract url": "https://arxiv.org/abs/2404.05167",
        "title": "Exact Analysis of the Age of Information in the Multi-Source M/GI/1 Queueing System",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a situation that multiple monitoring applications (each with a different sensor-monitor pair) compete for a common service resource such as a communication link. Each sensor reports the latest state of its own time-varying information source to its corresponding monitor, incurring queueing and processing delays at the shared resource. The primary performance metric of interest is the age of information (AoI) of each sensor-monitor pair, which is defined as the elapsed time from the generation of the information currently displayed on the monitor. Although the multi-source first-come first-served (FCFS) M/GI/1 queue is one of the most fundamental model to describe such competing sensors, its exact analysis has been an open problem for years. In this paper, we show that the Laplace-Stieltjes transform (LST) of the stationary distribution of the AoI in this model, as well as the mean AoI, is given by a simple explicit formula, utilizing the double Laplace transform of the transient workload in the M/GI/1 queue.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05172",
        "abstract url": "https://arxiv.org/abs/2404.05172",
        "title": "Directed Buy-at-Bulk Spanners",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a framework that unifies directed buy-at-bulk network design and directed spanner problems, namely, buy-at-bulk spanners. The goal is to find a minimum-cost routing solution for network design problems that capture economies at scale, while satisfying demands and distance constraints for terminal pairs. A more restricted version of this problem was shown to be $O(2^{{\\log^{1-\\varepsilon} n}})$-hard to approximate, where $n$ is the number of vertices, under a standard complexity assumption, due to Elkin and Peleg (Theory of Computing Systems, 2007). To the best of our knowledge, our results are the first sublinear factor approximation algorithms for directed buy-at-bulk spanners. Furthermore, these results hold even when we allow the edge lengths to be negative, unlike the previous literature for spanners. Our approximation ratios match the state-of-the-art ratios in special cases, namely, buy-at-bulk network design by Antonakopoulos (WAOA, 2010) and weighted spanners by Grigorescu, Kumar, and Lin (APPROX 2023). Our results are based on new approximation algorithms for the following two problems that are of independent interest: minimum-density distance-constrained junction trees and resource-constrained shortest path with negative consumption.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2404.05173",
        "abstract url": "https://arxiv.org/abs/2404.05173",
        "title": "A Riemannian Manifold Approach to Constrained Resource Allocation in ISAC",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a new resource allocation framework for integrated sensing and communication (ISAC) systems, which are expected to be fundamental aspects of sixth-generation networks. In particular, we develop an augmented Lagrangian manifold optimization (ALMO) framework designed to maximize communication sum rate while satisfying sensing beampattern gain targets and base station (BS) transmit power limits. ALMO applies the principles of Riemannian manifold optimization (MO) to navigate the complex, non-convex landscape of the resource allocation problem. It efficiently leverages the augmented Lagrangian method to ensure adherence to constraints. We present comprehensive numerical results to validate our framework, which illustrates the ALMO method's superior capability to enhance the dual functionalities of communication and sensing in ISAC systems. For instance, with 12 antennas and 30 dBm BS transmit power, our proposed ALMO algorithm delivers a 10.1% sum rate gain over a benchmark optimization-based algorithm. This work demonstrates significant improvements in system performance and contributes a new algorithmic perspective to ISAC resource management.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures, submitted to an IEEE Transactions Journal"
    },
    {
        "paper id": "2404.05177",
        "abstract url": "https://arxiv.org/abs/2404.05177",
        "title": "Power Series Composition in Near-Linear Time",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present an algebraic algorithm that computes the composition of two power series in $\\mathop{\\tilde{\\mathrm O}}(n)$ time complexity. The previous best algorithms are $\\mathop{\\mathrm O}(n^{1+o(1)})$ by Kedlaya and Umans (FOCS 2008) and an $\\mathop{\\mathrm O}(n^{1.43})$ algebraic algorithm by Neiger, Salvy, Schost and Villard (JACM 2023). Our algorithm builds upon the recent Graeffe iteration approach to manipulate rational power series introduced by Bostan and Mori (SOSA 2021).",
        "subjects": [
            "cs.SC"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2404.08678",
        "abstract url": "https://arxiv.org/abs/2404.08678",
        "title": "Information Retrieval with Entity Linking",
        "rating": "-10",
        "keywords": [],
        "abstract": "Despite the advantages of their low-resource settings, traditional sparse retrievers depend on exact matching approaches between high-dimensional bag-of-words (BoW) representations of both the queries and the collection. As a result, retrieval performance is restricted by semantic discrepancies and vocabulary gaps. On the other hand, transformer-based dense retrievers introduce significant improvements in information retrieval tasks by exploiting low-dimensional contextualized representations of the corpus. While dense retrievers are known for their relative effectiveness, they suffer from lower efficiency and lack of generalization issues, when compared to sparse retrievers. For a lightweight retrieval task, high computational resources and time consumption are major barriers encouraging the renunciation of dense models despite potential gains. In this work, I propose boosting the performance of sparse retrievers by expanding both the queries and the documents with linked entities in two formats for the entity names: 1) explicit and 2) hashed. A zero-shot end-to-end dense entity linking system is employed for entity recognition and disambiguation to augment the corpus. By leveraging the advanced entity linking methods, I believe that the effectiveness gap between sparse and dense retrievers can be narrowed. Experiments are conducted on the MS MARCO passage dataset using the original qrel set, the re-ranked qrels favoured by MonoT5 and the latter set further re-ranked by DuoT5. Since I am concerned with the early stage retrieval in cascaded ranking architectures of large information retrieval systems, the results are evaluated using recall@1000. The suggested approach is also capable of retrieving documents for query subsets judged to be particularly difficult in prior work.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.15329",
        "abstract url": "https://arxiv.org/abs/2404.15329",
        "title": "Greedy Capon Beamformer",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose greedy Capon beamformer (GBF) for direction finding of narrow-band sources present in the array's viewing field. After defining the grid covering the location search space, the algorithm greedily builds the interference-plus-noise covariance matrix by identifying a high-power source on the grid using Capon's principle of maximizing the signal to interference plus noise ratio (SINR) while enforcing unit gain towards the signal of interest. An estimate of the power of the detected source is derived by exploiting the unit power constraint, which subsequently allows to update the noise covariance matrix by simple rank-1 matrix addition composed of outerproduct of the selected steering matrix with itself scaled by the signal power estimate. Our numerical examples demonstrate effectiveness of the proposed GCB in direction finding where it perform favourably compared to the state-of-the-art algorithms under a broad variety of settings. Furthermore, GCB estimates of direction-of-arrivals (DOAs) are very fast to compute.",
        "subjects": [
            "eess.SP",
            "stat.ME"
        ],
        "comment": "Submitted for publication"
    }
]