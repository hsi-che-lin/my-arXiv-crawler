[
    {
        "paper id": "2404.17929",
        "abstract url": "https://arxiv.org/abs/2404.17929",
        "title": "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition",
        "rating": "3",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing pedestrian attribute recognition (PAR) algorithms are mainly developed based on a static image, however, the performance is unreliable in challenging scenarios, such as heavy occlusion, motion blur, etc. In this work, we propose to understand human attributes using video frames that can fully use temporal information by fine-tuning a pre-trained multi-modal foundation model efficiently. Specifically, we formulate the video-based PAR as a vision-language fusion problem and adopt a pre-trained foundation model CLIP to extract the visual features. More importantly, we propose a novel spatiotemporal side-tuning strategy to achieve parameter-efficient optimization of the pre-trained vision foundation model. To better utilize the semantic information, we take the full attribute list that needs to be recognized as another input and transform the attribute words/phrases into the corresponding sentence via split, expand, and prompt operations. Then, the text encoder of CLIP is utilized for embedding processed attribute descriptions. The averaged visual tokens and text tokens are concatenated and fed into a fusion Transformer for multi-modal interactive learning. The enhanced tokens will be fed into a classification head for pedestrian attribute prediction. Extensive experiments on two large-scale video-based PAR datasets fully validated the effectiveness of our proposed framework. The source code of this paper is available at https://github.com/Event-AHU/OpenPAR.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Parameter Efficient Fine-Tuning Strategy for Video-based Pedestrian Attribute Recognition"
    },
    {
        "paper id": "2404.18952",
        "abstract url": "https://arxiv.org/abs/2404.18952",
        "title": "CUE-Net: Violence Detection Video Analytics with Spatial Cropping, Enhanced UniformerV2 and Modified Efficient Additive Attention",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "Workshop",
                "CVPR"
            ]
        ],
        "abstract": "In this paper we introduce CUE-Net, a novel architecture designed for automated violence detection in video surveillance. As surveillance systems become more prevalent due to technological advances and decreasing costs, the challenge of efficiently monitoring vast amounts of video data has intensified. CUE-Net addresses this challenge by combining spatial Cropping with an enhanced version of the UniformerV2 architecture, integrating convolutional and self-attention mechanisms alongside a novel Modified Efficient Additive Attention mechanism (which reduces the quadratic time complexity of self-attention) to effectively and efficiently identify violent activities. This approach aims to overcome traditional challenges such as capturing distant or partially obscured subjects within video frames. By focusing on both local and global spatiotemporal features, CUE-Net achieves state-of-the-art performance on the RWF-2000 and RLVS datasets, surpassing existing methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To be published in the proceedings of 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)"
    },
    {
        "paper id": "2404.17785",
        "abstract url": "https://arxiv.org/abs/2404.17785",
        "title": "Temporal Scaling Law for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recently, Large Language Models (LLMs) are widely adopted in a wide range of tasks, leading to increasing attention towards the research on how scaling LLMs affects their performance. Existing works, termed as Scaling Laws, have discovered that the loss of LLMs scales as power laws with model size, computational budget, and dataset size. However, the performance of LLMs throughout the training process remains untouched. In this paper, we propose the novel concept of Temporal Scaling Law and study the loss of LLMs from the temporal dimension. We first investigate the imbalance of loss on each token positions and develop a reciprocal-law across model scales and training stages. We then derive the temporal scaling law by studying the temporal patterns of the reciprocal-law parameters. Results on both in-distribution (IID) data and out-of-distribution (OOD) data demonstrate that our temporal scaling law accurately predicts the performance of LLMs in future training stages. Moreover, the temporal scaling law reveals that LLMs learn uniformly on different token positions, despite the loss imbalance. Experiments on pre-training LLMs in various scales show that this phenomenon verifies the default training paradigm for generative language models, in which no re-weighting strategies are attached during training. Overall, the temporal scaling law provides deeper insight into LLM pre-training.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2404.17790",
        "abstract url": "https://arxiv.org/abs/2404.17790",
        "title": "Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Cross-lingual continual pre-training of large language models (LLMs) initially trained on English corpus allows us to leverage the vast amount of English language resources and reduce the pre-training cost. In this study, we constructed Swallow, an LLM with enhanced Japanese capability, by extending the vocabulary of Llama 2 to include Japanese characters and conducting continual pre-training on a large Japanese web corpus. Experimental results confirmed that the performance on Japanese tasks drastically improved through continual pre-training, and the performance monotonically increased with the amount of training data up to 100B tokens. Consequently, Swallow achieved superior performance compared to other LLMs that were trained from scratch in English and Japanese. An analysis of the effects of continual pre-training revealed that it was particularly effective for Japanese question answering tasks. Furthermore, to elucidate effective methodologies for cross-lingual continual pre-training from English to Japanese, we investigated the impact of vocabulary expansion and the effectiveness of incorporating parallel corpora. The results showed that the efficiency gained through vocabulary expansion had no negative impact on performance, except for the summarization task, and that the combined use of parallel corpora enhanced translation ability.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17802",
        "abstract url": "https://arxiv.org/abs/2404.17802",
        "title": "Empirical Analysis of Dialogue Relation Extraction with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Dialogue relation extraction (DRE) aims to extract relations between two arguments within a dialogue, which is more challenging than standard RE due to the higher person pronoun frequency and lower information density in dialogues. However, existing DRE methods still suffer from two serious issues: (1) hard to capture long and sparse multi-turn information, and (2) struggle to extract golden relations based on partial dialogues, which motivates us to discover more effective methods that can alleviate the above issues. We notice that the rise of large language models (LLMs) has sparked considerable interest in evaluating their performance across diverse tasks. To this end, we initially investigate the capabilities of different LLMs in DRE, considering both proprietary models and open-source models. Interestingly, we discover that LLMs significantly alleviate two issues in existing DRE methods. Generally, we have following findings: (1) scaling up model size substantially boosts the overall DRE performance and achieves exceptional results, tackling the difficulty of capturing long and sparse multi-turn information; (2) LLMs encounter with much smaller performance drop from entire dialogue setting to partial dialogue setting compared to existing methods; (3) LLMs deliver competitive or superior performances under both full-shot and few-shot settings compared to current state-of-the-art; (4) LLMs show modest performances on inverse relations but much stronger improvements on general relations, and they can handle dialogues of various lengths especially for longer sequences.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "IJCAI 2024"
    },
    {
        "paper id": "2404.17806",
        "abstract url": "https://arxiv.org/abs/2404.17806",
        "title": "T-CLAP: Temporal-Enhanced Contrastive Language-Audio Pretraining",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Contrastive language-audio pretraining~(CLAP) has been developed to align the representations of audio and language, achieving remarkable performance in retrieval and classification tasks. However, current CLAP struggles to capture temporal information within audio and text features, presenting substantial limitations for tasks such as audio retrieval and generation. To address this gap, we introduce T-CLAP, a temporal-enhanced CLAP model. We use Large Language Models~(LLMs) and mixed-up strategies to generate temporal-contrastive captions for audio clips from extensive audio-text datasets. Subsequently, a new temporal-focused contrastive loss is designed to fine-tune the CLAP model by incorporating these synthetic data. We conduct comprehensive experiments and analysis in multiple downstream tasks. T-CLAP shows improved capability in capturing the temporal relationship of sound events and outperforms state-of-the-art models by a significant margin.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "Preprint submitted to IEEE MLSP 2024"
    },
    {
        "paper id": "2404.17807",
        "abstract url": "https://arxiv.org/abs/2404.17807",
        "title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot learning, recent studies indicate that current LLMs still struggle with zero and few-shot RE. Previous studies are mainly dedicated to design prompt formats and select good examples for improving ICL-based RE. Although both factors are vital for ICL, if one can fundamentally boost the ICL capability of LLMs in RE, the zero and few-shot RE performance via ICL would be significantly improved. To this end, we introduce \\textsc{Micre} (\\textbf{M}eta \\textbf{I}n-\\textbf{C}ontext learning of LLMs for \\textbf{R}elation \\textbf{E}xtraction), a new meta-training framework for zero and few-shot RE where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e., learning to learn in context for RE). Through meta-training, the model becomes more effectively to learn a new RE task in context by conditioning on a few training examples with no parameter updates or task-specific templates at inference time, enabling better zero and few-shot task generalization. We experiment \\textsc{Micre} on various LLMs with different model scales and 12 public RE datasets, and then evaluate it on unseen RE benchmarks under zero and few-shot settings. \\textsc{Micre} delivers comparable or superior performance compared to a range of baselines including supervised fine-tuning and typical in-context learning methods. We find that the gains are particular significant for larger model scales, and using a diverse set of the meta-training RE datasets is key to improvements. Empirically, we show that \\textsc{Micre} can transfer the relation semantic knowledge via relation label name during inference on target RE datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "IJCAI 2024"
    },
    {
        "paper id": "2404.17808",
        "abstract url": "https://arxiv.org/abs/2404.17808",
        "title": "Scaffold-BPE: Enhancing Byte Pair Encoding with Simple and Effective Scaffold Token Removal",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Byte Pair Encoding (BPE) serves as a foundation method for text tokenization in the Natural Language Processing (NLP) field. Despite its wide adoption, the original BPE algorithm harbors an inherent flaw: it inadvertently introduces a frequency imbalance for tokens in the text corpus. Since BPE iteratively merges the most frequent token pair in the text corpus while keeping all tokens that have been merged in the vocabulary, it unavoidably holds tokens that primarily represent subwords of complete words and appear infrequently on their own in the text corpus. We term such tokens as Scaffold Tokens. Due to their infrequent appearance in the text corpus, Scaffold Tokens pose a learning imbalance issue for language models. To address that issue, we propose Scaffold-BPE, which incorporates a dynamic scaffold token removal mechanism by parameter-free, computation-light, and easy-to-implement modifications to the original BPE. This novel approach ensures the exclusion of low-frequency Scaffold Tokens from the token representations for the given texts, thereby mitigating the issue of frequency imbalance and facilitating model training. On extensive experiments across language modeling tasks and machine translation tasks, Scaffold-BPE consistently outperforms the original BPE, well demonstrating its effectiveness and superiority.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17809",
        "abstract url": "https://arxiv.org/abs/2404.17809",
        "title": "Recall, Retrieve and Reason: Towards Better In-Context Relation Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Relation extraction (RE) aims to identify relations between entities mentioned in texts. Although large language models (LLMs) have demonstrated impressive in-context learning (ICL) abilities in various tasks, they still suffer from poor performances compared to most supervised fine-tuned RE methods. Utilizing ICL for RE with LLMs encounters two challenges: (1) retrieving good demonstrations from training examples, and (2) enabling LLMs exhibit strong ICL abilities in RE. On the one hand, retrieving good demonstrations is a non-trivial process in RE, which easily results in low relevance regarding entities and relations. On the other hand, ICL with an LLM achieves poor performance in RE while RE is different from language modeling in nature or the LLM is not large enough. In this work, we propose a novel recall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora (training examples) to enable relevant retrieving and reliable in-context reasoning. Specifically, we distill the consistently ontological knowledge from training datasets to let LLMs generate relevant entity pairs grounded by retrieval corpora as valid queries. These entity pairs are then used to retrieve relevant training examples from the retrieval corpora as demonstrations for LLMs to conduct better ICL via instruction tuning. Extensive experiments on different LLMs and RE datasets demonstrate that our method generates relevant and valid entity pairs and boosts ICL abilities of LLMs, achieving competitive or new state-of-the-art performance on sentence-level RE compared to previous supervised fine-tuning methods and ICL-based methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "IJCAI 2024"
    },
    {
        "paper id": "2404.17821",
        "abstract url": "https://arxiv.org/abs/2404.17821",
        "title": "An automatic mixing speech enhancement system for multi-track audio",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "We propose a speech enhancement system for multitrack audio. The system will minimize auditory masking while allowing one to hear multiple simultaneous speakers. The system can be used in multiple communication scenarios e.g., teleconferencing, invoice gaming, and live streaming. The ITU-R BS.1387 Perceptual Evaluation of Audio Quality (PEAQ) model is used to evaluate the amount of masking in the audio signals. Different audio effects e.g., level balance, equalization, dynamic range compression, and spatialization are applied via an iterative Harmony searching algorithm that aims to minimize the masking. In the subjective listening test, the designed system can compete with mixes by professional sound engineers and outperforms mixes by existing auto-mixing systems.",
        "subjects": [
            "cs.SD"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2404.17832",
        "abstract url": "https://arxiv.org/abs/2404.17832",
        "title": "Evaluation of Few-Shot Learning for Classification Tasks in the Polish Language",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We introduce a few-shot benchmark consisting of 7 different classification tasks native to the Polish language. We conducted an empirical comparison with 0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context learning (ICL) using various pre-trained commercial and open-source models. Our findings reveal that ICL achieves the best performance, with commercial models like GPT-3.5 and GPT-4 attaining the best performance. However, there remains a significant 14 percentage points gap between our best few-shot learning score and the performance of HerBERT-large fine-tuned on the entire training dataset. Among the techniques, SetFit emerges as the second-best approach, closely followed by linear probing. We observed the worst and most unstable performance with non-linear head fine-tuning. Results for ICL indicate that continual pre-training of models like Mistral-7b or Llama-2-13b on Polish corpora is beneficial. This is confirmed by the improved performances of Bielik-7b and Trurl-13b, respectively. To further support experiments in few-shot learning for Polish, we are releasing handcrafted templates for the ICL.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "34 pages, 3 figures, 10 tables"
    },
    {
        "paper id": "2404.17841",
        "abstract url": "https://arxiv.org/abs/2404.17841",
        "title": "Toxicity Classification in Ukrainian",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The task of toxicity detection is still a relevant task, especially in the context of safe and fair LMs development. Nevertheless, labeled binary toxicity classification corpora are not available for all languages, which is understandable given the resource-intensive nature of the annotation process. Ukrainian, in particular, is among the languages lacking such resources. To our knowledge, there has been no existing toxicity classification corpus in Ukrainian. In this study, we aim to fill this gap by investigating cross-lingual knowledge transfer techniques and creating labeled corpora by: (i)~translating from an English corpus, (ii)~filtering toxic samples using keywords, and (iii)~annotating with crowdsourcing. We compare LLMs prompting and other cross-lingual transfer approaches with and without fine-tuning offering insights into the most robust and efficient baselines.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to WOAH, NAACL, 2024. arXiv admin note: text overlap with arXiv:2404.02043"
    },
    {
        "paper id": "2404.17874",
        "abstract url": "https://arxiv.org/abs/2404.17874",
        "title": "From Languages to Geographies: Towards Evaluating Cultural Bias in Hate Speech Datasets",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Perceptions of hate can vary greatly across cultural contexts. Hate speech (HS) datasets, however, have traditionally been developed by language. This hides potential cultural biases, as one language may be spoken in different countries home to different cultures. In this work, we evaluate cultural bias in HS datasets by leveraging two interrelated cultural proxies: language and geography. We conduct a systematic survey of HS datasets in eight languages and confirm past findings on their English-language bias, but also show that this bias has been steadily decreasing in the past few years. For three geographically-widespread languages -- English, Arabic and Spanish -- we then leverage geographical metadata from tweets to approximate geo-cultural contexts by pairing language and country information. We find that HS datasets for these languages exhibit a strong geo-cultural bias, largely overrepresenting a handful of countries (e.g., US and UK for English) relative to their prominence in both the broader social media population and the general population speaking these languages. Based on these findings, we formulate recommendations for the creation of future HS datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at WOAH (NAACL 2024)"
    },
    {
        "paper id": "2404.17877",
        "abstract url": "https://arxiv.org/abs/2404.17877",
        "title": "PromptCL: Improving Event Representation via Prompt Template and Contrastive Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The representation of events in text plays a significant role in various NLP tasks. Recent research demonstrates that contrastive learning has the ability to improve event comprehension capabilities of Pre-trained Language Models (PLMs) and enhance the performance of event representation learning. However, the efficacy of event representation learning based on contrastive learning and PLMs is limited by the short length of event texts. The length of event texts differs significantly from the text length used in the pre-training of PLMs. As a result, there is inconsistency in the distribution of text length between pre-training and event representation learning, which may undermine the learning process of event representation based on PLMs. In this study, we present PromptCL, a novel framework for event representation learning that effectively elicits the capabilities of PLMs to comprehensively capture the semantics of short event texts. PromptCL utilizes a Prompt template borrowed from prompt learning to expand the input text during Contrastive Learning. This helps in enhancing the event representation learning by providing a structured outline of the event components. Moreover, we propose Subject-Predicate-Object (SPO) word order and Event-oriented Masked Language Modeling (EventMLM) to train PLMs to understand the relationships between event components. Our experimental results demonstrate that PromptCL outperforms state-of-the-art baselines on event related tasks. Additionally, we conduct a thorough analysis and demonstrate that using a prompt results in improved generalization capabilities for event representations. Our code will be available at https://github.com/YuboFeng2023/PromptCL.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "NLPCC 2023 Best Student Paper"
    },
    {
        "paper id": "2404.17888",
        "abstract url": "https://arxiv.org/abs/2404.17888",
        "title": "A Hybrid Approach for Document Layout Analysis in Document images",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Document layout analysis involves understanding the arrangement of elements within a document. This paper navigates the complexities of understanding various elements within document images, such as text, images, tables, and headings. The approach employs an advanced Transformer-based object detection network as an innovative graphical page object detector for identifying tables, figures, and displayed elements. We introduce a query encoding mechanism to provide high-quality object queries for contrastive learning, enhancing efficiency in the decoder phase. We also present a hybrid matching scheme that integrates the decoder's original one-to-one matching strategy with the one-to-many matching strategy during the training phase. This approach aims to improve the model's accuracy and versatility in detecting various graphical elements on a page. Our experiments on PubLayNet, DocLayNet, and PubTables benchmarks show that our approach outperforms current state-of-the-art methods. It achieves an average precision of 97.3% on PubLayNet, 81.6% on DocLayNet, and 98.6 on PubTables, demonstrating its superior performance in layout analysis. These advancements not only enhance the conversion of document images into editable and accessible formats but also streamline information retrieval and data extraction processes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICDAR 2024"
    },
    {
        "paper id": "2404.17894",
        "abstract url": "https://arxiv.org/abs/2404.17894",
        "title": "Unpaired Multi-view Clustering via Reliable View Guidance",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper focuses on unpaired multi-view clustering (UMC), a challenging problem where paired observed samples are unavailable across multiple views. The goal is to perform effective joint clustering using the unpaired observed samples in all views. In incomplete multi-view clustering, existing methods typically rely on sample pairing between views to capture their complementary. However, that is not applicable in the case of UMC. Hence, we aim to extract the consistent cluster structure across views. In UMC, two challenging issues arise: uncertain cluster structure due to lack of label and uncertain pairing relationship due to absence of paired samples. We assume that the view with a good cluster structure is the reliable view, which acts as a supervisor to guide the clustering of the other views. With the guidance of reliable views, a more certain cluster structure of these views is obtained while achieving alignment between reliable views and other views. Then we propose Reliable view Guidance with one reliable view (RG-UMC) and multiple reliable views (RGs-UMC) for UMC. Specifically, we design alignment modules with one reliable view and multiple reliable views, respectively, to adaptively guide the optimization process. Also, we utilize the compactness module to enhance the relationship of samples within the same cluster. Meanwhile, an orthogonal constraint is applied to latent representation to obtain discriminate features. Extensive experiments show that both RG-UMC and RGs-UMC outperform the best state-of-the-art method by an average of 24.14\\% and 29.42\\% in NMI, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17918",
        "abstract url": "https://arxiv.org/abs/2404.17918",
        "title": "I Have an Attention Bridge to Sell You: Generalization Capabilities of Modular Translation Architectures",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Modularity is a paradigm of machine translation with the potential of bringing forth models that are large at training time and small during inference. Within this field of study, modular approaches, and in particular attention bridges, have been argued to improve the generalization capabilities of models by fostering language-independent representations. In the present paper, we study whether modularity affects translation quality; as well as how well modular architectures generalize across different evaluation scenarios. For a given computational budget, we find non-modular architectures to be always comparable or preferable to all modular designs we study.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17949",
        "abstract url": "https://arxiv.org/abs/2404.17949",
        "title": "Transfer Learning Enhanced Single-choice Decision for Multi-choice Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multi-choice Machine Reading Comprehension (MMRC) aims to select the correct answer from a set of options based on a given passage and question. The existing methods employ the pre-trained language model as the encoder, share and transfer knowledge through fine-tuning.These methods mainly focus on the design of exquisite mechanisms to effectively capture the relationships among the triplet of passage, question and answers. It is non-trivial but ignored to transfer knowledge from other MRC tasks such as SQuAD due to task specific of MMRC.In this paper, we reconstruct multi-choice to single-choice by training a binary classification to distinguish whether a certain answer is correct. Then select the option with the highest confidence score as the final answer. Our proposed method gets rid of the multi-choice framework and can leverage resources of other tasks. We construct our model based on the ALBERT-xxlarge model and evaluate it on the RACE and DREAM datasets. Experimental results show that our model performs better than multi-choice methods. In addition, by transferring knowledge from other kinds of MRC tasks, our model achieves state-of-the-art results in both single and ensemble settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 1 figures.This article supersedes arXiv:2011.03292"
    },
    {
        "paper id": "2404.17951",
        "abstract url": "https://arxiv.org/abs/2404.17951",
        "title": "Cauchy-Schwarz Divergence Information Bottleneck for Regression",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "The information bottleneck (IB) approach is popular to improve the generalization, robustness and explainability of deep neural networks. Essentially, it aims to find a minimum sufficient representation $\\mathbf{t}$ by striking a trade-off between a compression term $I(\\mathbf{x};\\mathbf{t})$ and a prediction term $I(y;\\mathbf{t})$, where $I(\\cdot;\\cdot)$ refers to the mutual information (MI). MI is for the IB for the most part expressed in terms of the Kullback-Leibler (KL) divergence, which in the regression case corresponds to prediction based on mean squared error (MSE) loss with Gaussian assumption and compression approximated by variational inference. In this paper, we study the IB principle for the regression problem and develop a new way to parameterize the IB with deep neural networks by exploiting favorable properties of the Cauchy-Schwarz (CS) divergence. By doing so, we move away from MSE-based regression and ease estimation by avoiding variational approximations or distributional assumptions. We investigate the improved generalization ability of our proposed CS-IB and demonstrate strong adversarial robustness guarantees. We demonstrate its superior performance on six real-world regression tasks over other popular deep IB approaches. We additionally observe that the solutions discovered by CS-IB always achieve the best trade-off between prediction accuracy and compression ratio in the information plane. The code is available at \\url{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "accepted by ICLR-24, project page: \\url{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck}"
    },
    {
        "paper id": "2404.17961",
        "abstract url": "https://arxiv.org/abs/2404.17961",
        "title": "Random Walk on Pixel Manifolds for Anomaly Segmentation of Complex Driving Scenes",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In anomaly segmentation for complex driving scenes, state-of-the-art approaches utilize anomaly scoring functions to calculate anomaly scores. For these functions, accurately predicting the logits of inlier classes for each pixel is crucial for precisely inferring the anomaly score. However, in real-world driving scenarios, the diversity of scenes often results in distorted manifolds of pixel embeddings in embedding space. This effect is not conducive to directly using the pixel embeddings for the logit prediction during inference, a concern overlooked by existing methods. To address this problem, we propose a novel method called Random Walk on Pixel Manifolds (RWPM). RWPM utilizes random walks to reveal the intrinsic relationships among pixels to refine the pixel embeddings. The refined pixel embeddings alleviate the distortion of manifolds, improving the accuracy of anomaly scores. Our extensive experiments show that RWPM consistently improve the performance of the existing anomaly segmentation methods and achieve the best results. Code: \\url{https://github.com/ZelongZeng/RWPM}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2404.17968",
        "abstract url": "https://arxiv.org/abs/2404.17968",
        "title": "Usefulness of Emotional Prosody in Neural Machine Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Neural Machine Translation (NMT) is the task of translating a text from one language to another with the use of a trained neural network. Several existing works aim at incorporating external information into NMT models to improve or control predicted translations (e.g. sentiment, politeness, gender). In this work, we propose to improve translation quality by adding another external source of information: the automatically recognized emotion in the voice. This work is motivated by the assumption that each emotion is associated with a specific lexicon that can overlap between emotions. Our proposed method follows a two-stage procedure. At first, we select a state-of-the-art Speech Emotion Recognition (SER) model to predict dimensional emotion values from all input audio in the dataset. Then, we use these predicted emotions as source tokens added at the beginning of input texts to train our NMT model. We show that integrating emotion information, especially arousal, into NMT systems leads to better translations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "5 pages, In Proceedings of the 11th International Conference on Speech Prosody (SP), Leiden, The Netherlands, 2024"
    },
    {
        "paper id": "2404.17975",
        "abstract url": "https://arxiv.org/abs/2404.17975",
        "title": "Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools for many tasks, such as extracting valuable insights from vast amounts of textual data. In this study, we conduct a comparative analysis of LLMs for the extraction of travel customer needs from TripAdvisor posts. Leveraging a diverse range of models, including both open-source and proprietary ones such as GPT-4 and Gemini, we aim to elucidate their strengths and weaknesses in this specialized domain. Through an evaluation process involving metrics such as BERTScore, ROUGE, and BLEU, we assess the performance of each model in accurately identifying and summarizing customer needs. Our findings highlight the efficacy of opensource LLMs, particularly Mistral 7B, in achieving comparable performance to larger closed models while offering affordability and customization benefits. Additionally, we underscore the importance of considering factors such as model size, resource requirements, and performance metrics when selecting the most suitable LLM for customer needs analysis tasks. Overall, this study contributes valuable insights for businesses seeking to leverage advanced NLP techniques to enhance customer experience and drive operational efficiency in the travel industry.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17978",
        "abstract url": "https://arxiv.org/abs/2404.17978",
        "title": "A Method of Moments Embedding Constraint and its Application to Semi-Supervised Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Discriminative deep learning models with a linear+softmax final layer have a problem: the latent space only predicts the conditional probabilities $p(Y|X)$ but not the full joint distribution $p(Y,X)$, which necessitates a generative approach. The conditional probability cannot detect outliers, causing outlier sensitivity in softmax networks. This exacerbates model over-confidence impacting many problems, such as hallucinations, confounding biases, and dependence on large datasets. To address this we introduce a novel embedding constraint based on the Method of Moments (MoM). We investigate the use of polynomial moments ranging from 1st through 4th order hyper-covariance matrices. Furthermore, we use this embedding constraint to train an Axis-Aligned Gaussian Mixture Model (AAGMM) final layer, which learns not only the conditional, but also the joint distribution of the latent space. We apply this method to the domain of semi-supervised image classification by extending FlexMatch with our technique. We find our MoM constraint with the AAGMM layer is able to match the reported FlexMatch accuracy, while also modeling the joint distribution, thereby reducing outlier sensitivity. We also present a preliminary outlier detection strategy based on Mahalanobis distance and discuss future improvements to this strategy. Code is available at: \\url{https://github.com/mmajurski/ssl-gmm}",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17983",
        "abstract url": "https://arxiv.org/abs/2404.17983",
        "title": "TI-ASU: Toward Robust Automatic Speech Understanding through Text-to-speech Imputation Against Missing Speech Modality",
        "rating": "1",
        "keywords": [
            [
                "cs.SD"
            ]
        ],
        "abstract": "Automatic Speech Understanding (ASU) aims at human-like speech interpretation, providing nuanced intent, emotion, sentiment, and content understanding from speech and language (text) content conveyed in speech. Typically, training a robust ASU model relies heavily on acquiring large-scale, high-quality speech and associated transcriptions. However, it is often challenging to collect or use speech data for training ASU due to concerns such as privacy. To approach this setting of enabling ASU when speech (audio) modality is missing, we propose TI-ASU, using a pre-trained text-to-speech model to impute the missing speech. We report extensive experiments evaluating TI-ASU on various missing scales, both multi- and single-modality settings, and the use of LLMs. Our findings show that TI-ASU yields substantial benefits to improve ASU in scenarios where even up to 95% of training speech is missing. Moreover, we show that TI-ASU is adaptive to dropout training, improving model robustness in addressing missing speech during inference.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17991",
        "abstract url": "https://arxiv.org/abs/2404.17991",
        "title": "Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Machine Reading Comprehension (MRC) poses a significant challenge in the field of Natural Language Processing (NLP). While mainstream MRC methods predominantly leverage extractive strategies using encoder-only models such as BERT, generative approaches face the issue of out-of-control generation -- a critical problem where answers generated are often incorrect, irrelevant, or unfaithful to the source text. To address these limitations in generative models for MRC, we introduce the Question-Attended Span Extraction (QASE) module. Integrated during the fine-tuning phase of pre-trained generative language models (PLMs), QASE significantly enhances their performance, allowing them to surpass the extractive capabilities of advanced Large Language Models (LLMs) such as GPT-4. Notably, these gains in performance do not come with an increase in computational demands. The efficacy of the QASE module has been rigorously tested across various datasets, consistently achieving or even surpassing state-of-the-art (SOTA) results.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17994",
        "abstract url": "https://arxiv.org/abs/2404.17994",
        "title": "LpQcM: Adaptable Lesion-Quantification-Consistent Modulation for Deep Learning Low-Count PET Image Denoising",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning-based positron emission tomography (PET) image denoising offers the potential to reduce radiation exposure and scanning time by transforming low-count images into high-count equivalents. However, existing methods typically blur crucial details, leading to inaccurate lesion quantification. This paper proposes a lesion-perceived and quantification-consistent modulation (LpQcM) strategy for enhanced PET image denoising, via employing downstream lesion quantification analysis as auxiliary tools. The LpQcM is a plug-and-play design adaptable to a wide range of model architectures, modulating the sampling and optimization procedures of model training without adding any computational burden to the inference phase. Specifically, the LpQcM consists of two components, the lesion-perceived modulation (LpM) and the multiscale quantification-consistent modulation (QcM). The LpM enhances lesion contrast and visibility by allocating higher sampling weights and stricter loss criteria to lesion-present samples determined by an auxiliary segmentation network than lesion-absent ones. The QcM further emphasizes accuracy of quantification for both the mean and maximum standardized uptake value (SUVmean and SUVmax) across multiscale sub-regions throughout the entire image, thereby enhancing the overall image quality. Experiments conducted on large PET datasets from multiple centers and vendors, and varying noise levels demonstrated the LpQcM efficacy across various denoising frameworks. Compared to frameworks without LpQcM, the integration of LpQcM reduces the lesion SUVmean bias by 2.92% on average and increases the peak signal-to-noise ratio (PSNR) by 0.34 on average, for denoising images of extremely low-count levels below 10%.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2404.18025",
        "abstract url": "https://arxiv.org/abs/2404.18025",
        "title": "Retrieval Robust to Object Motion Blur",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Moving objects are frequently seen in daily life and usually appear blurred in images due to their motion. While general object retrieval is a widely explored area in computer vision, it primarily focuses on sharp and static objects, and retrieval of motion-blurred objects in large image collections remains unexplored. We propose a method for object retrieval in images that are affected by motion blur. The proposed method learns a robust representation capable of matching blurred objects to their deblurred versions and vice versa. To evaluate our approach, we present the first large-scale datasets for blurred object retrieval, featuring images with objects exhibiting varying degrees of blur in various poses and scales. We conducted extensive experiments, showing that our method outperforms state-of-the-art retrieval methods on the new blur-retrieval datasets, which validates the effectiveness of the proposed approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18031",
        "abstract url": "https://arxiv.org/abs/2404.18031",
        "title": "Quality Estimation with $k$-nearest Neighbors and Automatic Evaluation for Model-specific Quality Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Providing quality scores along with Machine Translation (MT) output, so-called reference-free Quality Estimation (QE), is crucial to inform users about the reliability of the translation. We propose a model-specific, unsupervised QE approach, termed $k$NN-QE, that extracts information from the MT model's training data using $k$-nearest neighbors. Measuring the performance of model-specific QE is not straightforward, since they provide quality scores on their own MT output, thus cannot be evaluated using benchmark QE test sets containing human quality scores on premade MT output. Therefore, we propose an automatic evaluation method that uses quality scores from reference-based metrics as gold standard instead of human-generated ones. We are the first to conduct detailed analyses and conclude that this automatic method is sufficient, and the reference-based MetricX-23 is best for the task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EAMT 2024"
    },
    {
        "paper id": "2404.18043",
        "abstract url": "https://arxiv.org/abs/2404.18043",
        "title": "Utilizing Large Language Models for Information Extraction from Real Estate Transactions",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Real estate sales contracts contain crucial information for property transactions, but manual extraction of data can be time-consuming and error-prone. This paper explores the application of large language models, specifically transformer-based architectures, for automated information extraction from real estate contracts. We discuss challenges, techniques, and future directions in leveraging these models to improve efficiency and accuracy in real estate contract analysis.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18057",
        "abstract url": "https://arxiv.org/abs/2404.18057",
        "title": "Efficient LLM Inference with Kcache",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models(LLMs) have had a profound impact on AI applications, particularly in the domains of long-text comprehension and generation. KV Cache technology is one of the most widely used techniques in the industry. It ensures efficient sequence generation by caching previously computed KV states. However, it also introduces significant memory overhead. We discovered that KV Cache is not necessary and proposed a novel KCache technique to alleviate the memory bottleneck issue during the LLMs inference process. KCache can be used directly for inference without any training process, Our evaluations show that KCache improves the throughput of popular LLMs by 40% with the baseline, while keeping accuracy.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Technical Report, 8 pages"
    },
    {
        "paper id": "2404.18060",
        "abstract url": "https://arxiv.org/abs/2404.18060",
        "title": "Prompt Customization for Continual Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Contemporary continual learning approaches typically select prompts from a pool, which function as supplementary inputs to a pre-trained model. However, this strategy is hindered by the inherent noise of its selection approach when handling increasing tasks. In response to these challenges, we reformulate the prompting approach for continual learning and propose the prompt customization (PC) method. PC mainly comprises a prompt generation module (PGM) and a prompt modulation module (PMM). In contrast to conventional methods that employ hard prompt selection, PGM assigns different coefficients to prompts from a fixed-sized pool of prompts and generates tailored prompts. Moreover, PMM further modulates the prompts by adaptively assigning weights according to the correlations between input data and corresponding prompts. We evaluate our method on four benchmark datasets for three diverse settings, including the class, domain, and task-agnostic incremental learning tasks. Experimental results demonstrate consistent improvement (by up to 16.2\\%), yielded by the proposed method, over the state-of-the-art (SOTA) techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ACM MM"
    },
    {
        "paper id": "2404.17789",
        "abstract url": "https://arxiv.org/abs/2404.17789",
        "title": "BiLO: Bilevel Local Operator Learning for PDE inverse problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to soft PDE constraints.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17830",
        "abstract url": "https://arxiv.org/abs/2404.17830",
        "title": "Dynamic Against Dynamic: An Open-set Self-learning Framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In open-set recognition, existing methods generally learn statically fixed decision boundaries using known classes to reject unknown classes. Though they have achieved promising results, such decision boundaries are evidently insufficient for universal unknown classes in dynamic and open scenarios as they can potentially appear at any position in the feature space. Moreover, these methods just simply reject unknown class samples during testing without any effective utilization for them. In fact, such samples completely can constitute the true instantiated representation of the unknown classes to further enhance the model's performance. To address these issues, this paper proposes a novel dynamic against dynamic idea, i.e., dynamic method against dynamic changing open-set world, where an open-set self-learning (OSSL) framework is correspondingly developed. OSSL starts with a good closed-set classifier trained by known classes and utilizes available test samples for model adaptation during testing, thus gaining the adaptability to changing data distributions. In particular, a novel self-matching module is designed for OSSL, which can achieve the adaptation in automatically identifying known class samples while rejecting unknown class samples which are further utilized to enhance the discriminability of the model as the instantiated representation of unknown classes. Our method establishes new performance milestones respectively in almost all standard and cross-data benchmarks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "The first two authors contributed equally to this work. Accepted at IJCAI2024"
    },
    {
        "paper id": "2404.17855",
        "abstract url": "https://arxiv.org/abs/2404.17855",
        "title": "Recontextualized Knowledge and Narrative Coalitions on Telegram",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "A defining characteristic of conspiracy texts is that they negotiate power and identity by recontextualizing prior knowledge. This dynamic has been shown to intensify on social media, where knowledge sources can readily be integrated into antagonistic narratives through hyperlinks. The objective of the present chapter is to further our understanding of this dynamic by surfacing and examining 1) how online conspiracy narratives recontextualize prior knowledge by coupling it with heterogeneous antagonistic elements, and 2) how such recontextualizing narratives operate as connectors around which diverse actors might form narrative coalitions. To this end, the chapter offers an empirical analysis of links to prior knowledge in public messaging channels from the Pushshift Telegram dataset. Using transferable methods from the field of bibliometrics, we find that politically extreme Telegram channels engage with a variety of established knowledge sources, including scientific journals, scientific repositories and other sources associated with the system of scholarly communication. Channels engaging with shared knowledge sources thereby form narrative coalitions ranging from scientific and technological imaginaries to far-right extremist and antisemitic conspiracy theories. Our analysis of these coalitions reveals (i) linguistic, political, and thematic forces that shape conspiracy narratives, (ii) emerging ideological, epistemological and ontological positions associated with online conspiracism, and (iii) how references to shared knowledge contribute to the communicability of conspiracy narratives.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Book chapter submitted to Advances in Sociolinguistics (Bloomsbury)"
    },
    {
        "paper id": "2404.17861",
        "abstract url": "https://arxiv.org/abs/2404.17861",
        "title": "BoostRad: Enhancing Object Detection by Boosting Radar Reflections",
        "rating": "0.5",
        "keywords": [
            [
                "autonomous driving",
                "Radar"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Automotive radars have an important role in autonomous driving systems. The main challenge in automotive radar detection is the radar's wide point spread function (PSF) in the angular domain that causes blurriness and clutter in the radar image. Numerous studies suggest employing an 'end-to-end' learning strategy using a Deep Neural Network (DNN) to directly detect objects from radar images. This approach implicitly addresses the PSF's impact on objects of interest. In this paper, we propose an alternative approach, which we term \"Boosting Radar Reflections\" (BoostRad). In BoostRad, a first DNN is trained to narrow the PSF for all the reflection points in the scene. The output of the first DNN is a boosted reflection image with higher resolution and reduced clutter, resulting in a sharper and cleaner image. Subsequently, a second DNN is employed to detect objects within the boosted reflection image. We develop a novel method for training the boosting DNN that incorporates domain knowledge of radar's PSF characteristics. BoostRad's performance is evaluated using the RADDet and CARRADA datasets, revealing its superiority over reference methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "WACV2024"
    },
    {
        "paper id": "2404.17910",
        "abstract url": "https://arxiv.org/abs/2404.17910",
        "title": "Reliable Student: Addressing Noise in Semi-Supervised 3D Object Detection",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ],
            [
                "Workshop",
                "CVPR"
            ]
        ],
        "abstract": "Semi-supervised 3D object detection can benefit from the promising pseudo-labeling technique when labeled data is limited. However, recent approaches have overlooked the impact of noisy pseudo-labels during training, despite efforts to enhance pseudo-label quality through confidence-based filtering. In this paper, we examine the impact of noisy pseudo-labels on IoU-based target assignment and propose the Reliable Student framework, which incorporates two complementary approaches to mitigate errors. First, it involves a class-aware target assignment strategy that reduces false negative assignments in difficult classes. Second, it includes a reliability weighting strategy that suppresses false positive assignment errors while also addressing remaining false negatives from the first step. The reliability weights are determined by querying the teacher network for confidence scores of the student-generated proposals. Our work surpasses the previous state-of-the-art on KITTI 3D object detection benchmark on point clouds in the semi-supervised setting. On 1% labeled data, our approach achieves a 6.2% AP improvement for the pedestrian class, despite having only 37 labeled samples available. The improvements become significant for the 2% setting, achieving 6.0% AP and 5.7% AP improvements for the pedestrian and cyclist classes, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at CVPR Workshop L3D-IVU 2023. Code: https://github.com/fnozarian/ReliableStudent"
    },
    {
        "paper id": "2404.17924",
        "abstract url": "https://arxiv.org/abs/2404.17924",
        "title": "Results about sets of desirable gamble sets",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Coherent sets of desirable gamble sets is used as a model for representing an agents opinions and choice preferences under uncertainty. In this paper we provide some results about the axioms required for coherence and the natural extension of a given set of desirable gamble sets. We also show that coherent sets of desirable gamble sets can be represented by a proper filter of coherent sets of desirable gambles.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17931",
        "abstract url": "https://arxiv.org/abs/2404.17931",
        "title": "Critical Review for One-class Classification: recent advances and the reality behind them",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper offers a comprehensive review of one-class classification (OCC), examining the technologies and methodologies employed in its implementation. It delves into various approaches utilized for OCC across diverse data types, such as feature data, image, video, time series, and others. Through a systematic review, this paper synthesizes promi-nent strategies used in OCC from its inception to its current advance-ments, with a particular emphasis on the promising application. Moreo-ver, the article criticizes the state-of-the-art (SOTA) image anomaly de-tection (AD) algorithms dominating one-class experiments. These algo-rithms include outlier exposure (binary classification) and pretrained model (multi-class classification), conflicting with the fundamental con-cept of learning from one class. Our investigation reveals that the top nine algorithms for one-class CIFAR10 benchmark are not OCC. We ar-gue that binary/multi-class classification algorithms should not be com-pared with OCC.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17937",
        "abstract url": "https://arxiv.org/abs/2404.17937",
        "title": "DTization: A New Method for Supervised Feature Scaling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Artificial intelligence is currently a dominant force in shaping various aspects of the world. Machine learning is a sub-field in artificial intelligence. Feature scaling is one of the data pre-processing techniques that improves the performance of machine learning algorithms. The traditional feature scaling techniques are unsupervised where they do not have influence of the dependent variable in the scaling process. In this paper, we have presented a novel feature scaling technique named DTization that employs decision tree and robust scaler for supervised feature scaling. The proposed method utilizes decision tree to measure the feature importance and based on the importance, different features get scaled differently with the robust scaler algorithm. The proposed method has been extensively evaluated on ten classification and regression datasets on various evaluation matrices and the results show a noteworthy performance improvement compared to the traditional feature scaling methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17940",
        "abstract url": "https://arxiv.org/abs/2404.17940",
        "title": "CBMAP: Clustering-based manifold approximation and projection for dimensionality reduction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Dimensionality reduction methods are employed to decrease data dimensionality, either to enhance machine learning performance or to facilitate data visualization in two or three-dimensional spaces. These methods typically fall into two categories: feature selection and feature transformation. Feature selection retains significant features, while feature transformation projects data into a lower-dimensional space, with linear and nonlinear methods. While nonlinear methods excel in preserving local structures and capturing nonlinear relationships, they may struggle with interpreting global structures and can be computationally intensive. Recent algorithms, such as the t-SNE, UMAP, TriMap, and PaCMAP prioritize preserving local structures, often at the expense of accurately representing global structures, leading to clusters being spread out more in lower-dimensional spaces. Moreover, these methods heavily rely on hyperparameters, making their results sensitive to parameter settings. To address these limitations, this study introduces a clustering-based approach, namely CBMAP (Clustering-Based Manifold Approximation and Projection), for dimensionality reduction. CBMAP aims to preserve both global and local structures, ensuring that clusters in lower-dimensional spaces closely resemble those in high-dimensional spaces. Experimental evaluations on benchmark datasets demonstrate CBMAP's efficacy, offering speed, scalability, and minimal reliance on hyperparameters. Importantly, CBMAP enables low-dimensional projection of test data, addressing a critical need in machine learning applications. CBMAP is made freely available at https://github.com/doganlab/cbmap and can be installed from the Python Package Directory (PyPI) software repository with the command pip install cbmap.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17985",
        "abstract url": "https://arxiv.org/abs/2404.17985",
        "title": "Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "The automated detection of conspiracy theories online typically relies on supervised learning. However, creating respective training data requires expertise, time and mental resilience, given the often harmful content. Moreover, available datasets are predominantly in English and often keyword-based, introducing a token-level bias into the models. Our work addresses the task of detecting conspiracy theories in German Telegram messages. We compare the performance of supervised fine-tuning approaches using BERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4 which require little or no additional training data. We use a dataset of $\\sim\\!\\! 4,000$ messages collected during the COVID-19 pandemic, without the use of keyword filters. Our findings demonstrate that both approaches can be leveraged effectively: For supervised fine-tuning, we report an F1 score of $\\sim\\!\\! 0.8$ for the positive class, making our model comparable to recent models trained on keyword-focused English corpora. We demonstrate our model's adaptability to intra-domain temporal shifts, achieving F1 scores of $\\sim\\!\\! 0.7$. Among prompting variants, the best model is GPT-4, achieving an F1 score of $\\sim\\!\\! 0.8$ for the positive class in a zero-shot setting and equipped with a custom conspiracy theory definition.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to the 8th Workshop on Online Abuse and Harms (WOAH), ACL 2024"
    },
    {
        "paper id": "2404.17997",
        "abstract url": "https://arxiv.org/abs/2404.17997",
        "title": "Optimal Initialization of Batch Bayesian Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Field experiments and computer simulations are effective but time-consuming methods of measuring the quality of engineered systems at different settings. To reduce the total time required, experimenters may employ Bayesian optimization, which is parsimonious with measurements, and take measurements of multiple settings simultaneously, in a batch. In practice, experimenters use very few batches, thus, it is imperative that each batch be as informative as possible. Typically, the initial batch in a Batch Bayesian Optimization (BBO) is constructed from a quasi-random sample of settings values. We propose a batch-design acquisition function, Minimal Terminal Variance (MTV), that designs a batch by optimization rather than random sampling. MTV adapts a design criterion function from Design of Experiments, called I-Optimality, which minimizes the variance of the post-evaluation estimates of quality, integrated over the entire space of settings. MTV weights the integral by the probability that a setting is optimal, making it able to design not only an initial batch but all subsequent batches, as well. Applicability to both initialization and subsequent batches is novel among acquisition functions. Numerical experiments on test functions and simulators show that MTV compares favorably to other BBO methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 8 figures"
    },
    {
        "paper id": "2404.18008",
        "abstract url": "https://arxiv.org/abs/2404.18008",
        "title": "Implicit Generative Prior for Bayesian Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predictive uncertainty quantification is crucial for reliable decision-making in various applied domains. Bayesian neural networks offer a powerful framework for this task. However, defining meaningful priors and ensuring computational efficiency remain significant challenges, especially for complex real-world applications. This paper addresses these challenges by proposing a novel neural adaptive empirical Bayes (NA-EB) framework. NA-EB leverages a class of implicit generative priors derived from low-dimensional distributions. This allows for efficient handling of complex data structures and effective capture of underlying relationships in real-world datasets. The proposed NA-EB framework combines variational inference with a gradient ascent algorithm. This enables simultaneous hyperparameter selection and approximation of the posterior distribution, leading to improved computational efficiency. We establish the theoretical foundation of the framework through posterior and classification consistency. We demonstrate the practical applications of our framework through extensive evaluations on a variety of tasks, including the two-spiral problem, regression, 10 UCI datasets, and image classification tasks on both MNIST and CIFAR-10 datasets. The results of our experiments highlight the superiority of our proposed framework over existing methods, such as sparse variational Bayesian and generative models, in terms of prediction accuracy and uncertainty quantification.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18063",
        "abstract url": "https://arxiv.org/abs/2404.18063",
        "title": "Machine Learning Techniques for Data Reduction of CFD Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present an approach called guaranteed block autoencoder that leverages Tensor Correlations (GBATC) for reducing the spatiotemporal data generated by computational fluid dynamics (CFD) and other scientific applications. It uses a multidimensional block of tensors (spanning in space and time) for both input and output, capturing the spatiotemporal and interspecies relationship within a tensor. The tensor consists of species that represent different elements in a CFD simulation. To guarantee the error bound of the reconstructed data, principal component analysis (PCA) is applied to the residual between the original and reconstructed data. This yields a basis matrix, which is then used to project the residual of each instance. The resulting coefficients are retained to enable accurate reconstruction. Experimental results demonstrate that our approach can deliver two orders of magnitude in reduction while still keeping the errors of primary data under scientifically acceptable bounds. Compared to reduction-based approaches based on SZ, our method achieves a substantially higher compression ratio for a given error bound or a better error for a given compression ratio.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 8 figures"
    },
    {
        "paper id": "2404.17779",
        "abstract url": "https://arxiv.org/abs/2404.17779",
        "title": "Medical Vision-Language Pre-Training for Brain Abnormalities",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Vision-language models have become increasingly powerful for tasks that require an understanding of both visual and linguistic elements, bridging the gap between these modalities. In the context of multimodal clinical AI, there is a growing need for models that possess domain-specific knowledge, as existing models often lack the expertise required for medical applications. In this paper, we take brain abnormalities as an example to demonstrate how to automatically collect medical image-text aligned data for pretraining from public resources such as PubMed. In particular, we present a pipeline that streamlines the pre-training process by initially collecting a large brain image-text dataset from case reports and published journals and subsequently constructing a high-performance vision-language model tailored to specific medical tasks. We also investigate the unique challenge of mapping subfigures to subcaptions in the medical domain. We evaluated the resulting model with quantitative and qualitative intrinsic evaluations. The resulting dataset and our code can be found here https://github.com/masoud-monajati/MedVL_pretraining_pipeline",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17793",
        "abstract url": "https://arxiv.org/abs/2404.17793",
        "title": "CLFT: Camera-LiDAR Fusion Transformer for Semantic Segmentation in Autonomous Driving",
        "rating": "0",
        "keywords": [
            [
                "Autonomous Driving",
                "LiDAR",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Critical research about camera-and-LiDAR-based semantic object segmentation for autonomous driving significantly benefited from the recent development of deep learning. Specifically, the vision transformer is the novel ground-breaker that successfully brought the multi-head-attention mechanism to computer vision applications. Therefore, we propose a vision-transformer-based network to carry out camera-LiDAR fusion for semantic segmentation applied to autonomous driving. Our proposal uses the novel progressive-assemble strategy of vision transformers on a double-direction network and then integrates the results in a cross-fusion strategy over the transformer decoder layers. Unlike other works in the literature, our camera-LiDAR fusion transformers have been evaluated in challenging conditions like rain and low illumination, showing robust performance. The paper reports the segmentation results over the vehicle and human classes in different modalities: camera-only, LiDAR-only, and camera-LiDAR fusion. We perform coherent controlled benchmark experiments of CLFT against other networks that are also designed for semantic segmentation. The experiments aim to evaluate the performance of CLFT independently from two perspectives: multimodal sensor fusion and backbone architectures. The quantitative assessments show our CLFT networks yield an improvement of up to 10\\% for challenging dark-wet conditions when comparing with Fully-Convolutional-Neural-Network-based (FCN) camera-LiDAR fusion neural network. Contrasting to the network with transformer backbone but using single modality input, the all-around improvement is 5-10\\%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to IEEE Transactions on Intelligent Vehicles"
    },
    {
        "paper id": "2404.17845",
        "abstract url": "https://arxiv.org/abs/2404.17845",
        "title": "Instance-free Text to Point Cloud Localization with Relative Position Awareness",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D",
                "Point Cloud"
            ],
            [
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-point-cloud cross-modal localization is an emerging vision-language task critical for future robot-human collaboration. It seeks to localize a position from a city-scale point cloud scene based on a few natural language instructions. In this paper, we address two key limitations of existing approaches: 1) their reliance on ground-truth instances as input; and 2) their neglect of the relative positions among potential instances. Our proposed model follows a two-stage pipeline, including a coarse stage for text-cell retrieval and a fine stage for position estimation. In both stages, we introduce an instance query extractor, in which the cells are encoded by a 3D sparse convolution U-Net to generate the multi-scale point cloud features, and a set of queries iteratively attend to these features to represent instances. In the coarse stage, a row-column relative position-aware self-attention (RowColRPA) module is designed to capture the spatial relations among the instance queries. In the fine stage, a multi-modal relative position-aware cross-attention (RPCA) module is developed to fuse the text and point cloud features along with spatial relations for improving fine position estimation. Experiment results on the KITTI360Pose dataset demonstrate that our model achieves competitive performance with the state-of-the-art models without taking ground-truth instances as input.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 10 figures, conference"
    },
    {
        "paper id": "2404.17862",
        "abstract url": "https://arxiv.org/abs/2404.17862",
        "title": "Revisiting Multimodal Emotion Recognition in Conversation from the Perspective of Graph Spectrum",
        "rating": "0",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Efficiently capturing consistent and complementary semantic features in a multimodal conversation context is crucial for Multimodal Emotion Recognition in Conversation (MERC). Existing methods mainly use graph structures to model dialogue context semantic dependencies and employ Graph Neural Networks (GNN) to capture multimodal semantic features for emotion recognition. However, these methods are limited by some inherent characteristics of GNN, such as over-smoothing and low-pass filtering, resulting in the inability to learn long-distance consistency information and complementary information efficiently. Since consistency and complementarity information correspond to low-frequency and high-frequency information, respectively, this paper revisits the problem of multimodal emotion recognition in conversation from the perspective of the graph spectrum. Specifically, we propose a Graph-Spectrum-based Multimodal Consistency and Complementary collaborative learning framework GS-MCC. First, GS-MCC uses a sliding window to construct a multimodal interaction graph to model conversational relationships and uses efficient Fourier graph operators to extract long-distance high-frequency and low-frequency information, respectively. Then, GS-MCC uses contrastive learning to construct self-supervised signals that reflect complementarity and consistent semantic collaboration with high and low-frequency signals, thereby improving the ability of high and low-frequency information to reflect real emotions. Finally, GS-MCC inputs the collaborative high and low-frequency information into the MLP network and softmax function for emotion prediction. Extensive experiments have proven the superiority of the GS-MCC architecture proposed in this paper on two benchmark data sets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 4 figures"
    },
    {
        "paper id": "2404.17865",
        "abstract url": "https://arxiv.org/abs/2404.17865",
        "title": "Vision-based Discovery of Nonlinear Dynamics for 3D Moving Target",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Data-driven discovery of governing equations has kindled significant interests in many science and engineering areas. Existing studies primarily focus on uncovering equations that govern nonlinear dynamics based on direct measurement of the system states (e.g., trajectories). Limited efforts have been placed on distilling governing laws of dynamics directly from videos for moving targets in a 3D space. To this end, we propose a vision-based approach to automatically uncover governing equations of nonlinear dynamics for 3D moving targets via raw videos recorded by a set of cameras. The approach is composed of three key blocks: (1) a target tracking module that extracts plane pixel motions of the moving target in each video, (2) a Rodrigues' rotation formula-based coordinate transformation learning module that reconstructs the 3D coordinates with respect to a predefined reference point, and (3) a spline-enhanced library-based sparse regressor that uncovers the underlying governing law of dynamics. This framework is capable of effectively handling the challenges associated with measurement data, e.g., noise in the video, imprecise tracking of the target that causes data missing, etc. The efficacy of our method has been demonstrated through multiple sets of synthetic videos considering different nonlinear dynamics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2404.17876",
        "abstract url": "https://arxiv.org/abs/2404.17876",
        "title": "DF-SLAM: Neural Feature Rendering Based on Dictionary Factors Representation for High-Fidelity Dense Visual SLAM System",
        "rating": "0",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a high-fidelity neural implicit dense visual Simultaneous Localization and Mapping (SLAM) system, termed DF-SLAM. In our work, we employ dictionary factors for scene representation, encoding the geometry and appearance information of the scene as a combination of basis and coefficient factors. Compared to neural implicit SLAM methods that directly encode scene information as features, our method exhibits superior scene detail reconstruction capabilities and more efficient memory usage, while our model size is insensitive to the size of the scene map, making our method more suitable for large-scale scenes. Additionally, we employ feature integration rendering to accelerate color rendering speed while ensuring color rendering quality, further enhancing the real-time performance of our neural SLAM method. Extensive experiments on synthetic and real-world datasets demonstrate that our method is competitive with existing state-of-the-art neural implicit SLAM methods in terms of real-time performance, localization accuracy, and scene reconstruction quality. Our source code is available at https://github.com/funcdecl/DF-SLAM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17922",
        "abstract url": "https://arxiv.org/abs/2404.17922",
        "title": "Open-Set 3D Semantic Instance Maps for Vision Language Navigation -- O3D-SIM",
        "rating": "0",
        "keywords": [
            [
                "Vision Language"
            ],
            [
                "3D",
                "point cloud"
            ],
            [
                "Navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Humans excel at forming mental maps of their surroundings, equipping them to understand object relationships and navigate based on language queries. Our previous work SI Maps [1] showed that having instance-level information and the semantic understanding of an environment helps significantly improve performance for language-guided tasks. We extend this instance-level approach to 3D while increasing the pipeline's robustness and improving quantitative and qualitative results. Our method leverages foundational models for object recognition, image segmentation, and feature extraction. We propose a representation that results in a 3D point cloud map with instance-level embeddings, which bring in the semantic understanding that natural language commands can query. Quantitatively, the work improves upon the success rate of language-guided tasks. At the same time, we qualitatively observe the ability to identify instances more clearly and leverage the foundational models and language and image-aligned embeddings to identify objects that, otherwise, a closed-set approach wouldn't be able to identify.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17993",
        "abstract url": "https://arxiv.org/abs/2404.17993",
        "title": "MinBackProp -- Backpropagating through Minimal Solvers",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present an approach to backpropagating through minimal problem solvers in end-to-end neural network training. Traditional methods relying on manually constructed formulas, finite differences, and autograd are laborious, approximate, and unstable for complex minimal problem solvers. We show that using the Implicit function theorem to calculate derivatives to backpropagate through the solution of a minimal problem solver is simple, fast, and stable. We compare our approach to (i) using the standard autograd on minimal problem solvers and relate it to existing backpropagation formulas through SVD-based and Eig-based solvers and (ii) implementing the backprop with an existing PyTorch Deep Declarative Networks (DDN) framework. We demonstrate our technique on a toy example of training outlier-rejection weights for 3D point registration and on a real application of training an outlier-rejection and RANSAC sampling network in image matching. Our method provides $100\\%$ stability and is 10 times faster compared to autograd, which is unstable and slow, and compared to DDN, which is stable but also slow.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18020",
        "abstract url": "https://arxiv.org/abs/2404.18020",
        "title": "DM-Align: Leveraging the Power of Natural Language Instructions to Make Changes to Images",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "image editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-based semantic image editing assumes the manipulation of an image using a natural language instruction. Although recent works are capable of generating creative and qualitative images, the problem is still mostly approached as a black box sensitive to generating unexpected outputs. Therefore, we propose a novel model to enhance the text-based control of an image editor by explicitly reasoning about which parts of the image to alter or preserve. It relies on word alignments between a description of the original source image and the instruction that reflects the needed updates, and the input image. The proposed Diffusion Masking with word Alignments (DM-Align) allows the editing of an image in a transparent and explainable way. It is evaluated on a subset of the Bison dataset and a self-defined dataset dubbed Dream. When comparing to state-of-the-art baselines, quantitative and qualitative results show that DM-Align has superior performance in image editing conditioned on language instructions, well preserves the background of the image and can better cope with long text instructions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18033",
        "abstract url": "https://arxiv.org/abs/2404.18033",
        "title": "Exposing Text-Image Inconsistency Using Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the battle against widespread online misinformation, a growing problem is text-image inconsistency, where images are misleadingly paired with texts with different intent or meaning. Existing classification-based methods for text-image inconsistency can identify contextual inconsistencies but fail to provide explainable justifications for their decisions that humans can understand. Although more nuanced, human evaluation is impractical at scale and susceptible to errors. To address these limitations, this study introduces D-TIIL (Diffusion-based Text-Image Inconsistency Localization), which employs text-to-image diffusion models to localize semantic inconsistencies in text and image pairs. These models, trained on large-scale datasets act as ``omniscient\" agents that filter out irrelevant information and incorporate background knowledge to identify inconsistencies. In addition, D-TIIL uses text embeddings and modified image regions to visualize these inconsistencies. To evaluate D-TIIL's efficacy, we introduce a new TIIL dataset containing 14K consistent and inconsistent text-image pairs. Unlike existing datasets, TIIL enables assessment at the level of individual words and image regions and is carefully designed to represent various inconsistencies. D-TIIL offers a scalable and evidence-based approach to identifying and localizing text-image inconsistency, providing a robust framework for future research combating misinformation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18058",
        "abstract url": "https://arxiv.org/abs/2404.18058",
        "title": "Joint Reference Frame Synthesis and Post Filter Enhancement for Versatile Video Coding",
        "rating": "0",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "This paper presents the joint reference frame synthesis (RFS) and post-processing filter enhancement (PFE) for Versatile Video Coding (VVC), aiming to explore the combination of different neural network-based video coding (NNVC) tools to better utilize the hierarchical bi-directional coding structure of VVC. Both RFS and PFE utilize the Space-Time Enhancement Network (STENet), which receives two input frames with artifacts and produces two enhanced frames with suppressed artifacts, along with an intermediate synthesized frame. STENet comprises two pipelines, the synthesis pipeline and the enhancement pipeline, tailored for different purposes. During RFS, two reconstructed frames are sent into STENet's synthesis pipeline to synthesize a virtual reference frame, similar to the current to-be-coded frame. The synthesized frame serves as an additional reference frame inserted into the reference picture list (RPL). During PFE, two reconstructed frames are fed into STENet's enhancement pipeline to alleviate their artifacts and distortions, resulting in enhanced frames with reduced artifacts and distortions. To reduce inference complexity, we propose joint inference of RFS and PFE (JISE), achieved through a single execution of STENet. Integrated into the VVC reference software VTM-15.0, RFS, PFE, and JISE are coordinated within a novel Space-Time Enhancement Window (STEW) under Random Access (RA) configuration. The proposed method could achieve -7.34%/-17.21%/-16.65% PSNR-based BD-rate on average for three components under RA configuration.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17799",
        "abstract url": "https://arxiv.org/abs/2404.17799",
        "title": "Personalized Federated Learning via Sequential Layer Expansion in Representation Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning ensures the privacy of clients by conducting distributed training on individual client devices and sharing only the model weights with a central server. However, in real-world scenarios, the heterogeneity of data among clients necessitates appropriate personalization methods. In this paper, we aim to address this heterogeneity using a form of parameter decoupling known as representation learning. Representation learning divides deep learning models into 'base' and 'head' components. The base component, capturing common features across all clients, is shared with the server, while the head component, capturing unique features specific to individual clients, remains local. We propose a new representation learning-based approach that suggests decoupling the entire deep learning model into more densely divided parts with the application of suitable scheduling methods, which can benefit not only data heterogeneity but also class heterogeneity. In this paper, we compare and analyze two layer scheduling approaches, namely forward (\\textit{Vanilla}) and backward (\\textit{Anti}), in the context of data and class heterogeneity among clients. Our experimental results show that the proposed algorithm, when compared to existing personalized federated learning algorithms, achieves increased accuracy, especially under challenging conditions, while reducing computation costs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 7 figure"
    },
    {
        "paper id": "2404.17847",
        "abstract url": "https://arxiv.org/abs/2404.17847",
        "title": "pFedAFM: Adaptive Feature Mixture for Batch-Level Personalization in Heterogeneous Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Model-heterogeneous personalized federated learning (MHPFL) enables FL clients to train structurally different personalized models on non-independent and identically distributed (non-IID) local data. Existing MHPFL methods focus on achieving client-level personalization, but cannot address batch-level data heterogeneity. To bridge this important gap, we propose a model-heterogeneous personalized Federated learning approach with Adaptive Feature Mixture (pFedAFM) for supervised learning tasks. It consists of three novel designs: 1) A sharing global homogeneous small feature extractor is assigned alongside each client's local heterogeneous model (consisting of a heterogeneous feature extractor and a prediction header) to facilitate cross-client knowledge fusion. The two feature extractors share the local heterogeneous model's prediction header containing rich personalized prediction knowledge to retain personalized prediction capabilities. 2) An iterative training strategy is designed to alternately train the global homogeneous small feature extractor and the local heterogeneous large model for effective global-local knowledge exchange. 3) A trainable weight vector is designed to dynamically mix the features extracted by both feature extractors to adapt to batch-level data heterogeneity. Theoretical analysis proves that pFedAFM can converge over time. Extensive experiments on 2 benchmark datasets demonstrate that it significantly outperforms 7 state-of-the-art MHPFL methods, achieving up to 7.93% accuracy improvement while incurring low communication and computation costs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17875",
        "abstract url": "https://arxiv.org/abs/2404.17875",
        "title": "Noisy Node Classification by Bi-level Optimization based Multi-teacher Distillation",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Previous graph neural networks (GNNs) usually assume that the graph data is with clean labels for representation learning, but it is not true in real applications. In this paper, we propose a new multi-teacher distillation method based on bi-level optimization (namely BO-NNC), to conduct noisy node classification on the graph data. Specifically, we first employ multiple self-supervised learning methods to train diverse teacher models, and then aggregate their predictions through a teacher weight matrix. Furthermore, we design a new bi-level optimization strategy to dynamically adjust the teacher weight matrix based on the training progress of the student model. Finally, we design a label improvement module to improve the label quality. Extensive experimental results on real datasets show that our method achieves the best results compared to state-of-the-art methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17912",
        "abstract url": "https://arxiv.org/abs/2404.17912",
        "title": "SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Vision Language",
                "VLM"
            ],
            [
                "BiomedGPT",
                "medical",
                "X-ray",
                "Radiology"
            ],
            [
                "cs.CL"
            ],
            [
                "workshop"
            ]
        ],
        "abstract": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large Language Models (MLLMs) can automate the creation of accurate and coherent radiological reports. Existing methods often hallucinate details in text-based reports that don't accurately reflect the image content. To mitigate this, we introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort GENeraTion using Vision Language Models), which improves the R2Gen task by integrating a self-refining mechanism into the MLLM framework. We employ a unique self-supervised loss that leverages similarity between pooled image representations and the contextual representations of the generated radiological text, alongside the standard Causal Language Modeling objective, to refine image-text representations. This allows the model to scrutinize and align the generated text through dynamic interaction between a given image and the generated text, therefore reducing hallucination and continuously enhancing nuanced report generation. SERPENT-VLM outperforms existing baselines such as LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and Radiology Objects in COntext (ROCO) datasets, and also proves to be robust against noisy images. A qualitative case study emphasizes the significant advancements towards more sophisticated MLLM frameworks for R2Gen, opening paths for further research into self-supervised refinement in the medical imaging domain.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 3 figures, 4 tables, Accepted as oral at Clinical NLP workshop at NAACL 2024"
    },
    {
        "paper id": "2404.17916",
        "abstract url": "https://arxiv.org/abs/2404.17916",
        "title": "FedCRL: Personalized Federated Learning with Contrastive Shared Representations for Label Heterogeneity in Non-IID Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "To deal with heterogeneity resulting from label distribution skew and data scarcity in distributed machine learning scenarios, this paper proposes a novel Personalized Federated Learning (PFL) algorithm, named Federated Contrastive Representation Learning (FedCRL). FedCRL introduces contrastive representation learning (CRL) on shared representations to facilitate knowledge acquisition of clients. Specifically, both local model parameters and averaged values of local representations are considered as shareable information to the server, both of which are then aggregated globally. CRL is applied between local representations and global representations to regularize personalized training by drawing similar representations closer and separating dissimilar ones, thereby enhancing local models with external knowledge and avoiding being harmed by label distribution skew. Additionally, FedCRL adopts local aggregation between each local model and the global model to tackle data scarcity. A loss-wise weighting mechanism is introduced to guide the local aggregation using each local model's contrastive loss to coordinate the global model involvement in each client, thus helping clients with scarce data. Our simulations demonstrate FedCRL's effectiveness in mitigating label heterogeneity by achieving accuracy improvements over existing methods on datasets with varying degrees of label heterogeneity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17990",
        "abstract url": "https://arxiv.org/abs/2404.17990",
        "title": "TabVFL: Improving Latent Representation in Vertical Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Autoencoders are popular neural networks that are able to compress high dimensional data to extract relevant latent information. TabNet is a state-of-the-art neural network model designed for tabular data that utilizes an autoencoder architecture for training. Vertical Federated Learning (VFL) is an emerging distributed machine learning paradigm that allows multiple parties to train a model collaboratively on vertically partitioned data while maintaining data privacy. The existing design of training autoencoders in VFL is to train a separate autoencoder in each participant and aggregate the latent representation later. This design could potentially break important correlations between feature data of participating parties, as each autoencoder is trained on locally available features while disregarding the features of others. In addition, traditional autoencoders are not specifically designed for tabular data, which is ubiquitous in VFL settings. Moreover, the impact of client failures during training on the model robustness is under-researched in the VFL scene. In this paper, we propose TabVFL, a distributed framework designed to improve latent representation learning using the joint features of participants. The framework (i) preserves privacy by mitigating potential data leakage with the addition of a fully-connected layer, (ii) conserves feature correlations by learning one latent representation vector, and (iii) provides enhanced robustness against client failures during training phase. Extensive experiments on five classification datasets show that TabVFL can outperform the prior work design, with 26.12% of improvement on f1-score.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18948",
        "abstract url": "https://arxiv.org/abs/2404.18948",
        "title": "Sub-Adjacent Transformer: Improving Time Series Anomaly Detection with Reconstruction Error from Sub-Adjacent Neighborhoods",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present the Sub-Adjacent Transformer with a novel attention mechanism for unsupervised time series anomaly detection. Unlike previous approaches that rely on all the points within some neighborhood for time point reconstruction, our method restricts the attention to regions not immediately adjacent to the target points, termed sub-adjacent neighborhoods. Our key observation is that owing to the rarity of anomalies, they typically exhibit more pronounced differences from their sub-adjacent neighborhoods than from their immediate vicinities. By focusing the attention on the sub-adjacent areas, we make the reconstruction of anomalies more challenging, thereby enhancing their detectability. Technically, our approach concentrates attention on the non-diagonal areas of the attention matrix by enlarging the corresponding elements in the training stage. To facilitate the implementation of the desired attention matrix pattern, we adopt linear attention because of its flexibility and adaptability. Moreover, a learnable mapping function is proposed to improve the performance of linear attention. Empirically, the Sub-Adjacent Transformer achieves state-of-the-art performance across six real-world anomaly detection benchmarks, covering diverse fields such as server monitoring, space exploration, and water treatment.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "IJCAI 2024"
    },
    {
        "paper id": "2404.18949",
        "abstract url": "https://arxiv.org/abs/2404.18949",
        "title": "The Simpler The Better: An Entropy-Based Importance Metric To Reduce Neural Networks' Depth",
        "rating": "-0.5",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "While deep neural networks are highly effective at solving complex tasks, large pre-trained models are commonly employed even to solve consistently simpler downstream tasks, which do not necessarily require a large model's complexity. Motivated by the awareness of the ever-growing AI environmental impact, we propose an efficiency strategy that leverages prior knowledge transferred by large models. Simple but effective, we propose a method relying on an Entropy-bASed Importance mEtRic (EASIER) to reduce the depth of over-parametrized deep neural networks, which alleviates their computational burden. We assess the effectiveness of our method on traditional image classification setups. The source code will be publicly released upon acceptance of the article.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2404.16890"
    },
    {
        "paper id": "2404.17810",
        "abstract url": "https://arxiv.org/abs/2404.17810",
        "title": "A Comparison of Differential Performance Metrics for the Evaluation of Automatic Speaker Verification Fairness",
        "rating": "-1",
        "keywords": [
            [
                "biometric"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "When decisions are made and when personal data is treated by automated processes, there is an expectation of fairness -- that members of different demographic groups receive equitable treatment. This expectation applies to biometric systems such as automatic speaker verification (ASV). We present a comparison of three candidate fairness metrics and extend previous work performed for face recognition, by examining differential performance across a range of different ASV operating points. Results show that the Gini Aggregation Rate for Biometric Equitability (GARBE) is the only one which meets three functional fairness measure criteria. Furthermore, a comprehensive evaluation of the fairness and verification performance of five state-of-the-art ASV systems is also presented. Our findings reveal a nuanced trade-off between fairness and verification accuracy underscoring the complex interplay between system design, demographic inclusiveness, and verification reliability.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2404.17811",
        "abstract url": "https://arxiv.org/abs/2404.17811",
        "title": "Efficient Bi-manipulation using RGBD Multi-model Fusion based on Attention Mechanism",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "RGBD",
                "depth"
            ]
        ],
        "abstract": "Dual-arm robots have great application prospects in intelligent manufacturing due to their human-like structure when deployed with advanced intelligence algorithm. However, the previous visuomotor policy suffers from perception deficiencies in environments where features of images are impaired by the various conditions, such as abnormal lighting, occlusion and shadow etc. The Focal CVAE framework is proposed for RGB-D multi-modal data fusion to address this challenge. In this study, a mixed focal attention module is designed for the fusion of RGB images containing color features and depth images containing 3D shape and structure information. This module highlights the prominent local features and focuses on the relevance of RGB and depth via cross-attention. A saliency attention module is proposed to improve its computational efficiency, which is applied in the encoder and the decoder of the framework. We illustrate the effectiveness of the proposed method via extensive simulation and experiments. It's shown that the performances of bi-manipulation are all significantly improved in the four real-world tasks with lower computational cost. Besides, the robustness is validated through experiments under different scenarios where there is a perception deficiency problem, demonstrating the feasibility of the method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "14 pages,5 figures"
    },
    {
        "paper id": "2404.17820",
        "abstract url": "https://arxiv.org/abs/2404.17820",
        "title": "Motion planning for off-road autonomous driving based on human-like cognition and weight adaptation",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "Driving in an off-road environment is challenging for autonomous vehicles due to the complex and varied terrain. To ensure stable and efficient travel, the vehicle requires consideration and balancing of environmental factors, such as undulations, roughness, and obstacles, to generate optimal trajectories that can adapt to changing scenarios. However, traditional motion planners often utilize a fixed cost function for trajectory optimization, making it difficult to adapt to different driving strategies in challenging irregular terrains and uncommon scenarios. To address these issues, we propose an adaptive motion planner based on human-like cognition and cost evaluation for off-road driving. First, we construct a multi-layer map describing different features of off-road terrains, including terrain elevation, roughness, obstacle, and artificial potential field map. Subsequently, we employ a CNN-LSTM network to learn the trajectories planned by human drivers in various off-road scenarios. Then, based on human-like generated trajectories in different environments, we design a primitive-based trajectory planner that aims to mimic human trajectories and cost weight selection, generating trajectories that are consistent with the dynamics of off-road vehicles. Finally, we compute optimal cost weights and select and extend behavioral primitives to generate highly adaptive, stable, and efficient trajectories. We validate the effectiveness of the proposed method through experiments in a desert off-road environment with complex terrain and varying road conditions. The experimental results show that the proposed human-like motion planner has excellent adaptability to different off-road conditions. It shows real-time operation, greater stability, and more human-like planning ability in diverse and challenging scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17834",
        "abstract url": "https://arxiv.org/abs/2404.17834",
        "title": "Efficient Reactive Synthesis",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "Our main result is a polynomial time algorithm for deciding realizability for the GXU sublogic of linear temporal logic. This logic is particularly suitable for the specification of embedded control systems, and it is more expressive than GR(1). Reactive control programs for GXU specifications are represented as Mealy machines, which are extended by the monitoring of input events. Now, realizability for GXU specifications is shown to be equivalent to solving a certain subclass of 2QBF satisfiability problems. These logical problems can be solved in cubic time in the size of GXU specifications. For unrealizable GXU specifications, stronger environment assumptions are mined from failed consistency checks based on Padoa's characterization of definability and Craig interpolation.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17835",
        "abstract url": "https://arxiv.org/abs/2404.17835",
        "title": "VANER: Leveraging Large Language Model for Versatile and Adaptive Biomedical Named Entity Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical",
                "medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Prevalent solution for BioNER involves using representation learning techniques coupled with sequence labeling. However, such methods are inherently task-specific, demonstrate poor generalizability, and often require dedicated model for each dataset. To leverage the versatile capabilities of recently remarkable large language models (LLMs), several endeavors have explored generative approaches to entity extraction. Yet, these approaches often fall short of the effectiveness of previouly sequence labeling approaches. In this paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design specific instructions to distinguish between different types of entities and datasets. By combining the LLM's understanding of instructions with sequence labeling techniques, we use mix of datasets to train a model capable of extracting various types of entities. Given that the backbone LLMs lacks specialized medical knowledge, we also integrate external entity knowledge bases and employ instruction tuning to compel the model to densely recognize carefully curated entities. Our model VANER, trained with a small partition of parameters, significantly outperforms previous LLMs-based models and, for the first time, as a model based on LLM, surpasses the majority of conventional state-of-the-art BioNER systems, achieving the highest F1 scores across three datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17854",
        "abstract url": "https://arxiv.org/abs/2404.17854",
        "title": "GLIMS: Attention-Guided Lightweight Multi-Scale Hybrid Network for Volumetric Semantic Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "CT",
                "organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Convolutional Neural Networks (CNNs) have become widely adopted for medical image segmentation tasks, demonstrating promising performance. However, the inherent inductive biases in convolutional architectures limit their ability to model long-range dependencies and spatial correlations. While recent transformer-based architectures address these limitations by leveraging self-attention mechanisms to encode long-range dependencies and learn expressive representations, they often struggle to extract low-level features and are highly dependent on data availability. This motivated us for the development of GLIMS, a data-efficient attention-guided hybrid volumetric segmentation network. GLIMS utilizes Dilated Feature Aggregator Convolutional Blocks (DACB) to capture local-global feature correlations efficiently. Furthermore, the incorporated Swin Transformer-based bottleneck bridges the local and global features to improve the robustness of the model. Additionally, GLIMS employs an attention-guided segmentation approach through Channel and Spatial-Wise Attention Blocks (CSAB) to localize expressive features for fine-grained border segmentation. Quantitative and qualitative results on glioblastoma and multi-organ CT segmentation tasks demonstrate GLIMS' effectiveness in terms of complexity and accuracy. GLIMS demonstrated outstanding performance on BraTS2021 and BTCV datasets, surpassing the performance of Swin UNETR. Notably, GLIMS achieved this high performance with a significantly reduced number of trainable parameters. Specifically, GLIMS has 47.16M trainable parameters and 72.30G FLOPs, while Swin UNETR has 61.98M trainable parameters and 394.84G FLOPs. The code is publicly available on https://github.com/yaziciz/GLIMS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The article was accepted for publication in the Image and Vision Computing journal"
    },
    {
        "paper id": "2404.17856",
        "abstract url": "https://arxiv.org/abs/2404.17856",
        "title": "Uncertainty quantification for iterative algorithms in linear models with application to early stopping",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This paper investigates the iterates $\\hbb^1,\\dots,\\hbb^T$ obtained from iterative algorithms in high-dimensional linear regression problems, in the regime where the feature dimension $p$ is comparable with the sample size $n$, i.e., $p \\asymp n$. The analysis and proposed estimators are applicable to Gradient Descent (GD), proximal GD and their accelerated variants such as Fast Iterative Soft-Thresholding (FISTA). The paper proposes novel estimators for the generalization error of the iterate $\\hbb^t$ for any fixed iteration $t$ along the trajectory. These estimators are proved to be $\\sqrt n$-consistent under Gaussian designs. Applications to early-stopping are provided: when the generalization error of the iterates is a U-shape function of the iteration $t$, the estimates allow to select from the data an iteration $\\hat t$ that achieves the smallest generalization error along the trajectory. Additionally, we provide a technique for developing debiasing corrections and valid confidence intervals for the components of the true coefficient vector from the iterate $\\hbb^t$ at any finite iteration $t$. Extensive simulations on synthetic data illustrate the theoretical results.",
        "subjects": [
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17858",
        "abstract url": "https://arxiv.org/abs/2404.17858",
        "title": "Revisiting Multi-modal Emotion Learning with Broad State Space Models and Probability-guidance Fusion",
        "rating": "-1",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multi-modal Emotion Recognition in Conversation (MERC) has received considerable attention in various fields, e.g., human-computer interaction and recommendation systems. Most existing works perform feature disentanglement and fusion to extract emotional contextual information from multi-modal features and emotion classification. After revisiting the characteristic of MERC, we argue that long-range contextual semantic information should be extracted in the feature disentanglement stage and the inter-modal semantic information consistency should be maximized in the feature fusion stage. Inspired by recent State Space Models (SSMs), Mamba can efficiently model long-distance dependencies. Therefore, in this work, we fully consider the above insights to further improve the performance of MERC. Specifically, on the one hand, in the feature disentanglement stage, we propose a Broad Mamba, which does not rely on a self-attention mechanism for sequence modeling, but uses state space models to compress emotional representation, and utilizes broad learning systems to explore the potential data distribution in broad space. Different from previous SSMs, we design a bidirectional SSM convolution to extract global context information. On the other hand, we design a multi-modal fusion strategy based on probability guidance to maximize the consistency of information between modalities. Experimental results show that the proposed method can overcome the computational and memory limitations of Transformer when modeling long-distance contexts, and has great potential to become a next-generation general architecture in MERC.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2404.17872",
        "abstract url": "https://arxiv.org/abs/2404.17872",
        "title": "Generalizing Roberts' characterization of unit interval graphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "For any natural number $d$, a graph $G$ is a (disjoint) $d$-interval graph if it is the intersection graph of (disjoint) $d$-intervals, the union of $d$ (disjoint) intervals on the real line. Two important subclasses of $d$-interval graphs are unit and balanced $d$-interval graphs (where every interval has unit length or all the intervals associated to a same vertex have the same length, respectively). A celebrated result by Roberts gives a simple characterization of unit interval graphs being exactly claw-free interval graphs. Here, we study the generalization of this characterization for $d$-interval graphs. In particular, we prove that for any $d \\geq 2$, if $G$ is a $K_{1,2d+1}$-free interval graph, then $G$ is a unit $d$-interval graph. However, somehow surprisingly, under the same assumptions, $G$ is not always a \\emph{disjoint} unit $d$-interval graph. This implies that the class of disjoint unit $d$-interval graphs is strictly included in the class of unit $d$-interval graphs. Finally, we study the relationships between the classes obtained under disjoint and non-disjoint $d$-intervals in the balanced case and show that the classes of disjoint balanced 2-intervals and balanced 2-intervals coincide, but this is no longer true for $d>2$.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17878",
        "abstract url": "https://arxiv.org/abs/2404.17878",
        "title": "Processing HSV Colored Medical Images and Adapting Color Thresholds for Computational Image Analysis: a Practical Introduction to an open-source tool",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Background: Using artificial intelligence (AI) techniques for computational medical image analysis has shown promising results. However, colored images are often not readily available for AI analysis because of different coloring thresholds used across centers and physicians as well as the removal of clinical annotations. We aimed to develop an open-source tool that can adapt different color thresholds of HSV-colored medical images and remove annotations with a simple click. Materials and Methods: We built a function using MATLAB and used multi-center international shear wave elastography data (NCT 02638935) to test the function. We provide step-by-step instructions with accompanying code lines. Results: We demonstrate that the newly developed pre-processing function successfully removed letters and adapted different color thresholds of HSV-colored medical images. Conclusion: We developed an open-source tool for removing letters and adapting different color thresholds in HSV-colored medical images. We hope this contributes to advancing medical image processing for developing robust computational imaging algorithms using diverse multi-center big data. The open-source Matlab tool is available at https://github.com/cailiemed/image-threshold-adapting.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "An open-source tool that can adapt different color thresholds of HSV-colored medical images. The newly developed pre-processing Matlab function successfully works on multi-center, international shear wave elastography data (NCT 02638935). Step-by-step instructions with accompanying code lines were provided, easy to follow and reproduce"
    },
    {
        "paper id": "2404.17892",
        "abstract url": "https://arxiv.org/abs/2404.17892",
        "title": "Shared learning of powertrain control policies for vehicle fleets",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Emerging data-driven approaches, such as deep reinforcement learning (DRL), aim at on-the-field learning of powertrain control policies that optimize fuel economy and other performance metrics. Indeed, they have shown great potential in this regard for individual vehicles on specific routes or drive cycles. However, for fleets of vehicles that must service a distribution of routes, DRL approaches struggle with learning stability issues that result in high variances and challenge their practical deployment. In this paper, we present a novel framework for shared learning among a fleet of vehicles through the use of a distilled group policy as the knowledge sharing mechanism for the policy learning computations at each vehicle. We detail the mathematical formulation that makes this possible. Several scenarios are considered to analyze the functionality, performance, and computational scalability of the framework with fleet size. Comparisons of the cumulative performance of fleets using our proposed shared learning approach with a baseline of individual learning agents and another state-of-the-art approach with a centralized learner show clear advantages to our approach. For example, we find a fleet average asymptotic improvement of 8.5 percent in fuel economy compared to the baseline while also improving on the metrics of acceleration error and shifting frequency for fleets serving a distribution of suburban routes. Furthermore, we include demonstrative results that show how the framework reduces variance within a fleet and also how it helps individual agents adapt better to new routes.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17897",
        "abstract url": "https://arxiv.org/abs/2404.17897",
        "title": "Tool Calling: Enhancing Medication Consultation via Retrieval-Augmented Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large-scale language models (LLMs) have achieved remarkable success across various language tasks but suffer from hallucinations and temporal misalignment. To mitigate these shortcomings, Retrieval-augmented generation (RAG) has been utilized to provide external knowledge to facilitate the answer generation. However, applying such models to the medical domain faces several challenges due to the lack of domain-specific knowledge and the intricacy of real-world scenarios. In this study, we explore LLMs with RAG framework for knowledge-intensive tasks in the medical field. To evaluate the capabilities of LLMs, we introduce MedicineQA, a multi-round dialogue benchmark that simulates the real-world medication consultation scenario and requires LLMs to answer with retrieved evidence from the medicine database. MedicineQA contains 300 multi-round question-answering pairs, each embedded within a detailed dialogue history, highlighting the challenge posed by this knowledge-intensive task to current LLMs. We further propose a new \\textit{Distill-Retrieve-Read} framework instead of the previous \\textit{Retrieve-then-Read}. Specifically, the distillation and retrieval process utilizes a tool calling mechanism to formulate search queries that emulate the keyword-based inquiries used by search engines. With experimental results, we show that our framework brings notable performance improvements and surpasses the previous counterparts in the evidence retrieval process in terms of evidence retrieval accuracy. This advancement sheds light on applying RAG to the medical domain.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17900",
        "abstract url": "https://arxiv.org/abs/2404.17900",
        "title": "Unsupervised Anomaly Detection via Masked Diffusion Posterior Sampling",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstruction-based methods have been commonly used for unsupervised anomaly detection, in which a normal image is reconstructed and compared with the given test image to detect and locate anomalies. Recently, diffusion models have shown promising applications for anomaly detection due to their powerful generative ability. However, these models lack strict mathematical support for normal image reconstruction and unexpectedly suffer from low reconstruction quality. To address these issues, this paper proposes a novel and highly-interpretable method named Masked Diffusion Posterior Sampling (MDPS). In MDPS, the problem of normal image reconstruction is mathematically modeled as multiple diffusion posterior sampling for normal images based on the devised masked noisy observation model and the diffusion-based normal image prior under Bayesian framework. Using a metric designed from pixel-level and perceptual-level perspectives, MDPS can effectively compute the difference map between each normal posterior sample and the given test image. Anomaly scores are obtained by averaging all difference maps for multiple posterior samples. Exhaustive experiments on MVTec and BTAD datasets demonstrate that MDPS can achieve state-of-the-art performance in normal image reconstruction quality as well as anomaly detection and localization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17917",
        "abstract url": "https://arxiv.org/abs/2404.17917",
        "title": "EvaNet: Elevation-Guided Flood Extent Mapping on Earth Imagery",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate and timely mapping of flood extent from high-resolution satellite imagery plays a crucial role in disaster management such as damage assessment and relief activities. However, current state-of-the-art solutions are based on U-Net, which can-not segment the flood pixels accurately due to the ambiguous pixels (e.g., tree canopies, clouds) that prevent a direct judgement from only the spectral features. Thanks to the digital elevation model (DEM) data readily available from sources such as United States Geological Survey (USGS), this work explores the use of an elevation map to improve flood extent mapping. We propose, EvaNet, an elevation-guided segmentation model based on the encoder-decoder architecture with two novel techniques: (1) a loss function encoding the physical law of gravity that if a location is flooded (resp. dry), then its adjacent locations with a lower (resp. higher) elevation must also be flooded (resp. dry); (2) a new (de)convolution operation that integrates the elevation map by a location sensitive gating mechanism to regulate how much spectral features flow through adjacent layers. Extensive experiments show that EvaNet significantly outperforms the U-Net baselines, and works as a perfect drop-in replacement for U-Net in existing solutions to flood extent mapping.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at the International Joint Conference on Artificial Intelligence (IJCAI, 2024)"
    },
    {
        "paper id": "2404.17926",
        "abstract url": "https://arxiv.org/abs/2404.17926",
        "title": "Pre-training on High Definition X-ray Images: An Experimental Study",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "X-ray",
                "disease"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Existing X-ray based pre-trained vision models are usually conducted on a relatively small-scale dataset (less than 500k samples) with limited resolution (e.g., 224 $\\times$ 224). However, the key to the success of self-supervised pre-training large models lies in massive training data, and maintaining high resolution in the field of X-ray images is the guarantee of effective solutions to difficult miscellaneous diseases. In this paper, we address these issues by proposing the first high-definition (1280 $\\times$ 1280) X-ray based pre-trained foundation vision model on our newly collected large-scale dataset which contains more than 1 million X-ray images. Our model follows the masked auto-encoder framework which takes the tokens after mask processing (with a high rate) is used as input, and the masked image patches are reconstructed by the Transformer encoder-decoder network. More importantly, we introduce a novel context-aware masking strategy that utilizes the chest contour as a boundary for adaptive masking operations. We validate the effectiveness of our model on two downstream tasks, including X-ray report generation and disease recognition. Extensive experiments demonstrate that our pre-trained medical foundation vision model achieves comparable or even new state-of-the-art performance on downstream benchmark datasets. The source code and pre-trained models of this paper will be released on https://github.com/Event-AHU/Medical_Image_Analysis.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Technology Report"
    },
    {
        "paper id": "2404.17927",
        "abstract url": "https://arxiv.org/abs/2404.17927",
        "title": "Approximation and FPT Algorithms for Finding DM-Irreducible Spanning Subgraphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Finding a minimum strongly connected spanning subgraph of a given directed graph generalizes the well-known strong connectivity augmentation problem, and it is NP-hard. For the weighted problem, a simple $2$-approximation algorithm was proposed by Frederickson and J\u00e1j\u00e1 (1981); surprisingly, it still achieves the best known approximation ratio in general. Also, the unweighted problem was shown to be FPT by Bang-Jensen and Yeo (2008), where the parameter is the difference from the trivial upper bound of the optimal value. In this paper, we consider a generalized problem related to the Dulmage--Mendelsohn decompositions of bipartite graphs instead of the strong connectivity of directed graphs, and extend the above approximation and FPT results to this setting.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "15 pages, 1 figure"
    },
    {
        "paper id": "2404.17930",
        "abstract url": "https://arxiv.org/abs/2404.17930",
        "title": "Multi-Stream Cellular Test-Time Adaptation of Real-Time Models Evolving in Dynamic Environments",
        "rating": "-1",
        "keywords": [
            [
                "5G",
                "IoT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the era of the Internet of Things (IoT), objects connect through a dynamic network, empowered by technologies like 5G, enabling real-time data sharing. However, smart objects, notably autonomous vehicles, face challenges in critical local computations due to limited resources. Lightweight AI models offer a solution but struggle with diverse data distributions. To address this limitation, we propose a novel Multi-Stream Cellular Test-Time Adaptation (MSC-TTA) setup where models adapt on the fly to a dynamic environment divided into cells. Then, we propose a real-time adaptive student-teacher method that leverages the multiple streams available in each cell to quickly adapt to changing data distributions. We validate our methodology in the context of autonomous vehicles navigating across cells defined based on location and weather conditions. To facilitate future benchmarking, we release a new multi-stream large-scale synthetic semantic segmentation dataset, called DADE, and show that our multi-stream approach outperforms a single-stream baseline. We believe that our work will open research opportunities in the IoT and 5G eras, offering solutions for real-time model adaptation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17936",
        "abstract url": "https://arxiv.org/abs/2404.17936",
        "title": "FDCE-Net: Underwater Image Enhancement with Embedding Frequency and Dual Color Encoder",
        "rating": "-1",
        "keywords": [
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Underwater images often suffer from various issues such as low brightness, color shift, blurred details, and noise due to light absorption and scattering caused by water and suspended particles. Previous underwater image enhancement (UIE) methods have primarily focused on spatial domain enhancement, neglecting the frequency domain information inherent in the images. However, the degradation factors of underwater images are closely intertwined in the spatial domain. Although certain methods focus on enhancing images in the frequency domain, they overlook the inherent relationship between the image degradation factors and the information present in the frequency domain. As a result, these methods frequently enhance certain attributes of the improved image while inadequately addressing or even exacerbating other attributes. Moreover, many existing methods heavily rely on prior knowledge to address color shift problems in underwater images, limiting their flexibility and robustness. In order to overcome these limitations, we propose the Embedding Frequency and Dual Color Encoder Network (FDCE-Net) in our paper. The FDCE-Net consists of two main structures: (1) Frequency Spatial Network (FS-Net) aims to achieve initial enhancement by utilizing our designed Frequency Spatial Residual Block (FSRB) to decouple image degradation factors in the frequency domain and enhance different attributes separately. (2) To tackle the color shift issue, we introduce the Dual-Color Encoder (DCE). The DCE establishes correlations between color and semantic representations through cross-attention and leverages multi-scale image features to guide the optimization of adaptive color query. The final enhanced images are generated by combining the outputs of FS-Net and DCE through a fusion network. These images exhibit rich details, clear textures, low noise and natural colors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16pages,13 figures"
    },
    {
        "paper id": "2404.17947",
        "abstract url": "https://arxiv.org/abs/2404.17947",
        "title": "Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have demonstrated state-of-the-art performance in various graph representation learning tasks. Recently, studies revealed their vulnerability to adversarial attacks. In this work, we theoretically define the concept of expected robustness in the context of attributed graphs and relate it to the classical definition of adversarial robustness in the graph representation learning literature. Our definition allows us to derive an upper bound of the expected robustness of Graph Convolutional Networks (GCNs) and Graph Isomorphism Networks subject to node feature attacks. Building on these findings, we connect the expected robustness of GNNs to the orthonormality of their weight matrices and consequently propose an attack-independent, more robust variant of the GCN, called the Graph Convolutional Orthonormal Robust Networks (GCORNs). We further introduce a probabilistic method to estimate the expected robustness, which allows us to evaluate the effectiveness of GCORN on several real-world datasets. Experimental experiments showed that GCORN outperforms available defense methods. Our code is publicly available at: \\href{https://github.com/Sennadir/GCORN}{https://github.com/Sennadir/GCORN}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at ICLR 2024"
    },
    {
        "paper id": "2404.17960",
        "abstract url": "https://arxiv.org/abs/2404.17960",
        "title": "PhishGuard: A Convolutional Neural Network Based Model for Detecting Phishing URLs with Explainability Analysis",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Cybersecurity is one of the global issues because of the extensive dependence on cyber systems of individuals, industries, and organizations. Among the cyber attacks, phishing is increasing tremendously and affecting the global economy. Therefore, this phenomenon highlights the vital need for enhancing user awareness and robust support at both individual and organizational levels. Phishing URL identification is the best way to address the problem. Various machine learning and deep learning methods have been proposed to automate the detection of phishing URLs. However, these approaches often need more convincing accuracy and rely on datasets consisting of limited samples. Furthermore, these black box intelligent models decision to detect suspicious URLs needs proper explanation to understand the features affecting the output. To address the issues, we propose a 1D Convolutional Neural Network (CNN) and trained the model with extensive features and a substantial amount of data. The proposed model outperforms existing works by attaining an accuracy of 99.85%. Additionally, our explainability analysis highlights certain features that significantly contribute to identifying the phishing URL.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2404.17967",
        "abstract url": "https://arxiv.org/abs/2404.17967",
        "title": "SCorP: Statistics-Informed Dense Correspondence Prediction Directly from Unsegmented Medical Images",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Statistical shape modeling (SSM) is a powerful computational framework for quantifying and analyzing the geometric variability of anatomical structures, facilitating advancements in medical research, diagnostics, and treatment planning. Traditional methods for shape modeling from imaging data demand significant manual and computational resources. Additionally, these methods necessitate repeating the entire modeling pipeline to derive shape descriptors (e.g., surface-based point correspondences) for new data. While deep learning approaches have shown promise in streamlining the construction of SSMs on new data, they still rely on traditional techniques to supervise the training of the deep networks. Moreover, the predominant linearity assumption of traditional approaches restricts their efficacy, a limitation also inherited by deep learning models trained using optimized/established correspondences. Consequently, representing complex anatomies becomes challenging. To address these limitations, we introduce SCorP, a novel framework capable of predicting surface-based correspondences directly from unsegmented images. By leveraging the shape prior learned directly from surface meshes in an unsupervised manner, the proposed model eliminates the need for an optimized shape model for training supervision. The strong shape prior acts as a teacher and regularizes the feature learning of the student network to guide it in learning image-based features that are predictive of surface correspondences. The proposed model streamlines the training and inference phases by removing the supervision for the correspondence prediction task while alleviating the linearity assumption.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17984",
        "abstract url": "https://arxiv.org/abs/2404.17984",
        "title": "Privacy-Preserving, Dropout-Resilient Aggregation in Decentralized Learning",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Decentralized learning (DL) offers a novel paradigm in machine learning by distributing training across clients without central aggregation, enhancing scalability and efficiency. However, DL's peer-to-peer model raises challenges in protecting against inference attacks and privacy leaks. By forgoing central bottlenecks, DL demands privacy-preserving aggregation methods to protect data from 'honest but curious' clients and adversaries, maintaining network-wide privacy. Privacy-preserving DL faces the additional hurdle of client dropout, clients not submitting updates due to connectivity problems or unavailability, further complicating aggregation. This work proposes three secret sharing-based dropout resilience approaches for privacy-preserving DL. Our study evaluates the efficiency, performance, and accuracy of these protocols through experiments on datasets such as MNIST, Fashion-MNIST, SVHN, and CIFAR-10. We compare our protocols with traditional secret-sharing solutions across scenarios, including those with up to 1000 clients. Evaluations show that our protocols significantly outperform conventional methods, especially in scenarios with up to 30% of clients dropout and model sizes of up to $10^6$ parameters. Our approaches demonstrate markedly high efficiency with larger models, higher dropout rates, and extensive client networks, highlighting their effectiveness in enhancing decentralized learning systems' privacy and dropout robustness.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17989",
        "abstract url": "https://arxiv.org/abs/2404.17989",
        "title": "InfoSec.pptx: A Longitudinal Study of Speakers, Topics, and Sponsors at Security Conferences in Academia and Industry",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Security conferences are important venues at which academics and practitioners share knowledge about new attacks and state-of-the-art defenses. Despite this, researchers have not studied who shares information and about which security topics. To address this, our study characterizes the speakers, sponsors, and topics presented at the most prestigious academic and industry conferences. We collect a longitudinal data set that contains 9,728 abstracts and 1,686 sponsors across 4 academic and 6 industry conferences. There is limited knowledge sharing between industry and academia. Conferences vary significantly in the equality of how talks/authorship is distributed across individuals. The topics of academic and industry abstracts display consistent coverage of techniques within the MITRE ATT&CK framework. Top tier academic conferences, as well as DEFCON and Black Hat, inconsistently address the governance, response and recovery functions of the NIST Cybersecurity Framework. Commercial InfoSec and insurance conferences (RSA, Gartner, Advisen and NetDillgience) cover the framework more consistently. Prevention and detection remain the most common topic of talks, with no clear temporal trend.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Code and data can be found in the repository: https://git.uibk.ac.at/csaw9252/master_thesis"
    },
    {
        "paper id": "2404.18002",
        "abstract url": "https://arxiv.org/abs/2404.18002",
        "title": "Towards Privacy-Preserving Audio Classification Systems",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.SD"
            ]
        ],
        "abstract": "Audio signals can reveal intimate details about a person's life, including their conversations, health status, emotions, location, and personal preferences. Unauthorized access or misuse of this information can have profound personal and social implications. In an era increasingly populated by devices capable of audio recording, safeguarding user privacy is a critical obligation. This work studies the ethical and privacy concerns in current audio classification systems. We discuss the challenges and research directions in designing privacy-preserving audio sensing systems. We propose privacy-preserving audio features that can be used to classify wide range of audio classes, while being privacy preserving.",
        "subjects": [
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18028",
        "abstract url": "https://arxiv.org/abs/2404.18028",
        "title": "Reducing Dominating Sets in Graphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A dominating set of a graph $G=(V,E)$ is a subset of vertices $S\\subseteq V$ such that every vertex $v\\in V\\setminus S$ has at least one neighbor in set $S$. The corresponding optimization problem is known to be NP-hard. The best known polynomial time approximation algorithm for the problem separates the solution process in two stages applying first a fast greedy algorithm to obtain an initial dominating set, and then it uses an iterative procedure to reduce (purify) this dominating set. The purification stage turned out to be practically efficient. Here we further strengthen the purification stage presenting four new purification algorithms. All four purification procedures outperform the earlier purification procedure. The algorithms were tested for over 1300 benchmark problem instances. Compared to the known upper bounds, the obtained solutions were about 7 times better. Remarkably, for the 500 benchmark instances for which the optimum is known, the optimal solutions were obtained for 46.33\\% of the tested instances, whereas the average error for the remaining instances was about 1.01.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18042",
        "abstract url": "https://arxiv.org/abs/2404.18042",
        "title": "Pose-aware 3D Beamwidth Adaptation for Mobile Extended Reality",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper presents a sensor-aided pose-aware beamwidth adaptation design for a conceptual extended reality (XR) Head-Mounted Display (HMD) equipped with a 2D planar array. The beam is tracked and adapted on the user side by leveraging HMD orientation estimates. The beamwidth adaptation scheme is effected by selective deactivation of elements in the 2D antenna array, employing the angular estimation covariance matrix to overlap the beam with the estimation confidence interval. The proposed method utilizes the estimation correlations to adapt the beamwidth along the confidence interval of these estimates. Compared to a beamwidth adaptation without leveraging estimation correlations, the proposed method demonstrates the gain of leveraging estimation correlations by improving the coverage area for a given outage probability threshold by approximately 16%, or equivalently increasing the power efficiency up to 18%.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Accepted in the 2024 IEEE ICC"
    },
    {
        "paper id": "2404.18062",
        "abstract url": "https://arxiv.org/abs/2404.18062",
        "title": "Compressed Image Captioning using CNN-based Encoder-Decoder Framework",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In today's world, image processing plays a crucial role across various fields, from scientific research to industrial applications. But one particularly exciting application is image captioning. The potential impact of effective image captioning is vast. It can significantly boost the accuracy of search engines, making it easier to find relevant information. Moreover, it can greatly enhance accessibility for visually impaired individuals, providing them with a more immersive experience of digital content. However, despite its promise, image captioning presents several challenges. One major hurdle is extracting meaningful visual information from images and transforming it into coherent language. This requires bridging the gap between the visual and linguistic domains, a task that demands sophisticated algorithms and models. Our project is focused on addressing these challenges by developing an automatic image captioning architecture that combines the strengths of convolutional neural networks (CNNs) and encoder-decoder models. The CNN model is used to extract the visual features from images, and later, with the help of the encoder-decoder framework, captions are generated. We also did a performance comparison where we delved into the realm of pre-trained CNN models, experimenting with multiple architectures to understand their performance variations. In our quest for optimization, we also explored the integration of frequency regularization techniques to compress the \"AlexNet\" and \"EfficientNetB0\" model. We aimed to see if this compressed model could maintain its effectiveness in generating image captions while being more resource-efficient.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18065",
        "abstract url": "https://arxiv.org/abs/2404.18065",
        "title": "Grounded Compositional and Diverse Text-to-3D with Pretrained Multi-View Diffusion Model",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we propose an effective two-stage approach named Grounded-Dreamer to generate 3D assets that can accurately follow complex, compositional text prompts while achieving high fidelity by using a pre-trained multi-view diffusion model. Multi-view diffusion models, such as MVDream, have shown to generate high-fidelity 3D assets using score distillation sampling (SDS). However, applied naively, these methods often fail to comprehend compositional text prompts, and may often entirely omit certain subjects or parts. To address this issue, we first advocate leveraging text-guided 4-view images as the bottleneck in the text-to-3D pipeline. We then introduce an attention refocusing mechanism to encourage text-aligned 4-view image generation, without the necessity to re-train the multi-view diffusion model or craft a high-quality compositional 3D dataset. We further propose a hybrid optimization strategy to encourage synergy between the SDS loss and the sparse RGB reference images. Our method consistently outperforms previous state-of-the-art (SOTA) methods in generating compositional 3D assets, excelling in both quality and accuracy, and enabling diverse 3D from the same text prompt.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 10 figures"
    },
    {
        "paper id": "2404.17825",
        "abstract url": "https://arxiv.org/abs/2404.17825",
        "title": "ODCR: Orthogonal Decoupling Contrastive Regularization for Unpaired Image Dehazing",
        "rating": "-1.5",
        "keywords": [
            [
                "Depth"
            ],
            [
                "haze",
                "Dehazing"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Unpaired image dehazing (UID) holds significant research importance due to the challenges in acquiring haze/clear image pairs with identical backgrounds. This paper proposes a novel method for UID named Orthogonal Decoupling Contrastive Regularization (ODCR). Our method is grounded in the assumption that an image consists of both haze-related features, which influence the degree of haze, and haze-unrelated features, such as texture and semantic information. ODCR aims to ensure that the haze-related features of the dehazing result closely resemble those of the clear image, while the haze-unrelated features align with the input hazy image. To accomplish the motivation, Orthogonal MLPs optimized geometrically on the Stiefel manifold are proposed, which can project image features into an orthogonal space, thereby reducing the relevance between different features. Furthermore, a task-driven Depth-wise Feature Classifier (DWFC) is proposed, which assigns weights to the orthogonal features based on the contribution of each channel's feature in predicting whether the feature source is hazy or clear in a self-supervised fashion. Finally, a Weighted PatchNCE (WPNCE) loss is introduced to achieve the pulling of haze-related features in the output image toward those of clear images, while bringing haze-unrelated features close to those of the hazy input. Extensive experiments demonstrate the superior performance of our ODCR method on UID.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2404.17977",
        "abstract url": "https://arxiv.org/abs/2404.17977",
        "title": "Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "Healthcare",
                "clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper explores the application of Swarm-Structured Multi-Agent Systems (MAS) to establish medical necessity, a process that involves a systematic review of patient-specific medical structured and unstructured data against clinical guidelines. We addressed this complex task by decomposing it into smaller, more manageable sub-tasks. Each sub-task is handled by a specialized AI agent. We conduct a systematic study of the impact of various prompting strategies on these agents and benchmark different Large Language Models (LLMs) to determine their accuracy in completing these tasks. Additionally, we investigate how these agents can provide explainability, thereby enhancing trust and transparency within the system.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "5 pages, 4 figures. Work In Progress"
    },
    {
        "paper id": "2404.17999",
        "abstract url": "https://arxiv.org/abs/2404.17999",
        "title": "MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.CL"
            ],
            [
                "Workshop"
            ]
        ],
        "abstract": "Accurate representation of medical information is crucial for patient safety, yet artificial intelligence (AI) systems, such as Large Language Models (LLMs), encounter challenges in error-free clinical text interpretation. This paper presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben Abacha et al., 2024a), focusing on the automatic correction of single-word errors in clinical notes. Unlike LLMs that rely on extensive generic data, our method emphasizes extracting contextually relevant information from available clinical text data. Leveraging an ensemble of extractive and abstractive question-answering approaches, we construct a supervised learning framework with domain-specific feature engineering. Our methodology incorporates domain expertise to enhance error correction accuracy. By integrating domain expertise and prioritizing meaningful information extraction, our approach underscores the significance of a human-centric strategy in adapting AI for healthcare.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "7 pages, 4 figures, Clinical NLP 2024 Workshop"
    },
    {
        "paper id": "2404.18021",
        "abstract url": "https://arxiv.org/abs/2404.18021",
        "title": "CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments",
        "rating": "-1.5",
        "keywords": [
            [
                "biomedical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agent's effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between beginner biological researchers and CRISPR genome engineering techniques, and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17787",
        "abstract url": "https://arxiv.org/abs/2404.17787",
        "title": "Quantum resistant multi-signature scheme with optimal communication round: A Blockchain-based approach",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Blockchain is a decentralized network to increase trust, integrity, and transparency of transactions. With the exponential growth of transactions in the realm of Blockchain, especially in Bitcoin, Blockchain size increases as all transactions must be stored and verified. In Bitcoin, validating M of N transactions involves the necessity of M authentic signatures out of the total N transactions. This procedure is so time-consuming and needs a significant storage capacity. To address these issues, several multi signature schemes have been proposed, enabling users to interactively generate a common signature on a single message. Recently, some lattice based multi signature schemes have been presented to deal with the threats of quantum computers. However, none of them have met all desirable features of multi signature schemes like aggregate public key, low numbers of communication rounds, or resistant to quantum computers. Within this paper, we present a new multi signature scheme based on lattices, known as Razhims, that has aggregate public key, necessitates solely a single round of communication, and is resistant to quantum computers. In Razhims, the aggregate public key size and the final signature size are equal to the public key size and the final signature size of a standard signature respectively, and are independent of the number of signers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This article has 18 pages, 6 figures, and 4 tables"
    },
    {
        "paper id": "2404.17791",
        "abstract url": "https://arxiv.org/abs/2404.17791",
        "title": "HIPer: A Human-Inspired Scene Perception Model for Multifunctional Mobile Robots",
        "rating": "-2",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Taking over arbitrary tasks like humans do with a mobile service robot in open-world settings requires a holistic scene perception for decision-making and high-level control. This paper presents a human-inspired scene perception model to minimize the gap between human and robotic capabilities. The approach takes over fundamental neuroscience concepts, such as a triplet perception split into recognition, knowledge representation, and knowledge interpretation. A recognition system splits the background and foreground to integrate exchangeable image-based object detectors and SLAM, a multi-layer knowledge base represents scene information in a hierarchical structure and offers interfaces for high-level control, and knowledge interpretation methods deploy spatio-temporal scene analysis and perceptual learning for self-adjustment. A single-setting ablation study is used to evaluate the impact of each component on the overall performance for a fetch-and-carry scenario in two simulated and one real-world environment.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17822",
        "abstract url": "https://arxiv.org/abs/2404.17822",
        "title": "GenAI Distortion: The Effect of GenAI Fluency and Positive Affect",
        "rating": "-2",
        "keywords": [
            [
                "psychological"
            ]
        ],
        "abstract": "The introduction of generative artificial intelligence (GenAI) into educational practices has been transformative, yet it brings a crucial concern about the potential distortion of users' beliefs. Given the prevalence of GenAI among college students, examining the psychological mechanisms that lead to GenAI distortion from both technological factors and the individual's psychological processes is a critical priority. A mixed-methods approach is employed to test the proposed hypotheses. Study 1 (N = 10) revealed through qualitative analysis that GenAI's fluent outputs significantly engaged college students, eliciting positive emotional responses during an interaction. GenAI's tendency to conflate fact with fiction often led to presentations of unrealistic and exaggerated information, potentially distorting users' perceptions of reality-a phenomenon termed GenAI distortion. Following these insights, Study 2 (cross-sectional survey, N = 999) and Study 3 (experimental manipulation, N = 175) explored how GenAI fluency affects college students' GenAI distortion and examined the mediating effect of positive affect. The results indicated that GenAI fluency predicts GenAI distortion via the mediating role of positive affect. Our findings provide theoretical foundations and practical implications for understanding GenAI distortion among college students.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17826",
        "abstract url": "https://arxiv.org/abs/2404.17826",
        "title": "A Taxation Perspective for Fair Re-ranking",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Fair re-ranking aims to redistribute ranking slots among items more equitably to ensure responsibility and ethics. The exploration of redistribution problems has a long history in economics, offering valuable insights for conceptualizing fair re-ranking as a taxation process. Such a formulation provides us with a fresh perspective to re-examine fair re-ranking and inspire the development of new methods. From a taxation perspective, we theoretically demonstrate that most previous fair re-ranking methods can be reformulated as an item-level tax policy. Ideally, a good tax policy should be effective and conveniently controllable to adjust ranking resources. However, both empirical and theoretical analyses indicate that the previous item-level tax policy cannot meet two ideal controllable requirements: (1) continuity, ensuring minor changes in tax rates result in small accuracy and fairness shifts; (2) controllability over accuracy loss, ensuring precise estimation of the accuracy loss under a specific tax rate. To overcome these challenges, we introduce a new fair re-ranking method named Tax-rank, which levies taxes based on the difference in utility between two items. Then, we efficiently optimize such an objective by utilizing the Sinkhorn algorithm in optimal transport. Upon a comprehensive analysis, Our model Tax-rank offers a superior tax policy for fair re-ranking, theoretically demonstrating both continuity and controllability over accuracy loss. Experimental results show that Tax-rank outperforms all state-of-the-art baselines in terms of effectiveness and efficiency on recommendation and advertising tasks.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted in SIGIR 2024"
    },
    {
        "paper id": "2404.17837",
        "abstract url": "https://arxiv.org/abs/2404.17837",
        "title": "Hybrid 3D Human Pose Estimation with Monocular Video and Sparse IMUs",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth",
                "skeleton"
            ],
            [
                "biomechanically"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Temporal 3D human pose estimation from monocular videos is a challenging task in human-centered computer vision due to the depth ambiguity of 2D-to-3D lifting. To improve accuracy and address occlusion issues, inertial sensor has been introduced to provide complementary source of information. However, it remains challenging to integrate heterogeneous sensor data for producing physically rational 3D human poses. In this paper, we propose a novel framework, Real-time Optimization and Fusion (RTOF), to address this issue. We first incorporate sparse inertial orientations into a parametric human skeleton to refine 3D poses in kinematics. The poses are then optimized by energy functions built on both visual and inertial observations to reduce the temporal jitters. Our framework outputs smooth and biomechanically plausible human motion. Comprehensive experiments with ablation studies demonstrate its rationality and efficiency. On Total Capture dataset, the pose estimation error is significantly decreased compared to the baseline method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 5 figures, Under Review"
    },
    {
        "paper id": "2404.17851",
        "abstract url": "https://arxiv.org/abs/2404.17851",
        "title": "Spatial, Temporal, and Geometric Fusion for Remote Sensing Images",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Remote Sensing"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Remote sensing (RS) images are important to monitor and survey earth at varying spatial scales. Continuous observations from various RS sources complement single observations to improve applications. Fusion into single or multiple images provides more informative, accurate, complete, and coherent data. Studies intensively investigated spatial-temporal fusion for specific applications like pan-sharpening and spatial-temporal fusion for time-series analysis. Fusion methods can process different images, modalities, and tasks and are expected to be robust and adaptive to various types of images (e.g., spectral images, classification maps, and elevation maps) and scene complexities. This work presents solutions to improve existing fusion methods that process gridded data and consider their type-specific uncertainties. The contributions include: 1) A spatial-temporal filter that addresses spectral heterogeneity of multitemporal images. 2) 3D iterative spatiotemporal filter that enhances spatiotemporal inconsistencies of classification maps. 3) Adaptive semantic-guided fusion that enhances the accuracy of DSMs and compares them with traditional fusion approaches to show the significance of adaptive methods. 4) A comprehensive analysis of DL stereo matching methods against traditional Census-SGM to obtain detailed knowledge on the accuracy of the DSMs at the stereo matching level. We analyze the overall performance, robustness, and generalization capability, which helps identify the limitations of current DSM generation methods. 5) Based on previous analysis, we develop a novel finetuning strategy to enhance transferability of DL stereo matching methods, hence, the accuracy of DSMs. Our work shows the importance of spatial, temporal, and geometric fusion in enhancing RS applications. It shows that the fusion problem is case-specific and depends on the image type, scene content, and application.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Ph.D. Dissertation, Geospatial Data Analytics Lab, The Ohio State University, 2022"
    },
    {
        "paper id": "2404.17867",
        "abstract url": "https://arxiv.org/abs/2404.17867",
        "title": "Are Watermarks Bugs for Deepfake Detectors? Rethinking Proactive Forensics",
        "rating": "-2",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "watermarking"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "AI-generated content has accelerated the topic of media synthesis, particularly Deepfake, which can manipulate our portraits for positive or malicious purposes. Before releasing these threatening face images, one promising forensics solution is the injection of robust watermarks to track their own provenance. However, we argue that current watermarking models, originally devised for genuine images, may harm the deployed Deepfake detectors when directly applied to forged images, since the watermarks are prone to overlap with the forgery signals used for detection. To bridge this gap, we thus propose AdvMark, on behalf of proactive forensics, to exploit the adversarial vulnerability of passive detectors for good. Specifically, AdvMark serves as a plug-and-play procedure for fine-tuning any robust watermarking into adversarial watermarking, to enhance the forensic detectability of watermarked images; meanwhile, the watermarks can still be extracted for provenance tracking. Extensive experiments demonstrate the effectiveness of the proposed AdvMark, leveraging robust watermarking to fool Deepfake detectors, which can help improve the accuracy of downstream Deepfake detection without tuning the in-the-wild detectors. We believe this work will shed some light on the harmless proactive forensics against Deepfake.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IJCAI 2024"
    },
    {
        "paper id": "2404.17882",
        "abstract url": "https://arxiv.org/abs/2404.17882",
        "title": "Directed Isoperimetry and Monotonicity Testing: A Dynamical Approach",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "This paper explores the connection between classical isoperimetric inequalities, their directed analogues, and monotonicity testing. We study the setting of real-valued functions $f : [0,1]^d \\to \\mathbb{R}$ on the solid unit cube, where the goal is to test with respect to the $L^p$ distance. Our goals are twofold: to further understand the relationship between classical and directed isoperimetry, and to give a monotonicity tester with sublinear query complexity in this setting. Our main results are 1) an $L^2$ monotonicity tester for $M$-Lipschitz functions with query complexity $\\widetilde O(\\sqrt{d} M^2 / \u03b5^2)$ and, behind this result, 2) the directed Poincar\u00e9 inequality $\\mathsf{dist}^{\\mathsf{mono}}_2(f)^2 \\le C \\mathbb{E}[|\\nabla^- f|^2]$, where the \"directed gradient\" operator $\\nabla^-$ measures the local violations of monotonicity of $f$. To prove the second result, we introduce a partial differential equation (PDE), the directed heat equation, which takes a one-dimensional function $f$ into a monotone function $f^*$ over time and enjoys many desirable analytic properties. We obtain the directed Poincar\u00e9 inequality by combining convergence aspects of this PDE with the theory of optimal transport. Crucially for our conceptual motivation, this proof is in complete analogy with the mathematical physics perspective on the classical Poincar\u00e9 inequality, namely as characterizing the convergence of the standard heat equation toward equilibrium.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "83 pages"
    },
    {
        "paper id": "2404.17883",
        "abstract url": "https://arxiv.org/abs/2404.17883",
        "title": "Underwater Variable Zoom: Depth-Guided Perception Network for Underwater Image Enhancement",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Underwater scenes intrinsically involve degradation problems owing to heterogeneous ocean elements. Prevailing underwater image enhancement (UIE) methods stick to straightforward feature modeling to learn the mapping function, which leads to limited vision gain as it lacks more explicit physical cues (e.g., depth). In this work, we investigate injecting the depth prior into the deep UIE model for more precise scene enhancement capability. To this end, we present a novel depth-guided perception UIE framework, dubbed underwater variable zoom (UVZ). Specifically, UVZ resorts to a two-stage pipeline. First, a depth estimation network is designed to generate critical depth maps, combined with an auxiliary supervision network introduced to suppress estimation differences during training. Second, UVZ parses near-far scenarios by harnessing the predicted depth maps, enabling local and non-local perceiving in different regions. Extensive experiments on five benchmark datasets demonstrate that UVZ achieves superior visual gain and delivers promising quantitative metrics. Besides, UVZ is confirmed to exhibit good generalization in some visual tasks, especially in unusual lighting conditions. The code, models and results are available at: https://github.com/WindySprint/UVZ.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17895",
        "abstract url": "https://arxiv.org/abs/2404.17895",
        "title": "Empowering Mobility: Brain-Computer Interface for Enhancing Wheelchair Control for Individuals with Physical Disabilities",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "The integration of brain-computer interfaces (BCIs) into the realm of smart wheelchair (SW) technology signifies a notable leap forward in enhancing the mobility and autonomy of individuals with physical disabilities. BCIs are a technology that enables direct communication between the brain and external devices. While BCIs systems offer remarkable opportunities for enhancing human-computer interaction and providing mobility solutions for individuals with disabilities, they also raise significant concerns regarding security, safety, and privacy that have not been thoroughly addressed by researchers on a large scale. Our research aims to enhance wheelchair control for individuals with physical disabilities by leveraging electroencephalography (EEG) signals for BCIs. We introduce a non-invasive BCI system that utilizes a neuro-signal acquisition headset to capture EEG signals. These signals are obtained from specific brain activities that individuals have been trained to produce, allowing for precise control of the wheelchair. EEG-based BCIs are instrumental in capturing the brain's electrical activity and translating these signals into actionable commands. The primary objective of our study is to demonstrate the system's capability to interpret EEG signals and decode specific thought patterns or mental commands issued by the user. By doing so, it aims to convert these into accurate control commands for the wheelchair. This process includes the recognition of navigational intentions, such as moving forward, backward, or executing turns, specifically tailored for wheelchair operation. Through this innovative approach, we aim to create a seamless interface between the user's cognitive intentions and the wheelchair's movements, enhancing autonomy and mobility for individuals with physical disabilities.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "2024 HCI International Conference"
    },
    {
        "paper id": "2404.17903",
        "abstract url": "https://arxiv.org/abs/2404.17903",
        "title": "3D Extended Object Tracking by Fusing Roadside Sparse Radar Point Clouds and Pixel Keypoints",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "skeleton"
            ],
            [
                "Radar",
                "vehicle"
            ]
        ],
        "abstract": "Roadside perception is a key component in intelligent transportation systems. In this paper, we present a novel three-dimensional (3D) extended object tracking (EOT) method, which simultaneously estimates the object kinematics and extent state, in roadside perception using both the radar and camera data. Because of the influence of sensor viewing angle and limited angle resolution, radar measurements from objects are sparse and non-uniformly distributed, leading to inaccuracies in object extent and position estimation. To address this problem, we present a novel spherical Gaussian function weighted Gaussian mixture model. This model assumes that radar measurements originate from a series of probabilistic weighted radar reflectors on the vehicle's extent. Additionally, we utilize visual detection of vehicle keypoints to provide additional information on the positions of radar reflectors. Since keypoints may not always correspond to radar reflectors, we propose an elastic skeleton fusion mechanism, which constructs a virtual force to establish the relationship between the radar reflectors on the vehicle and its extent. Furthermore, to better describe the kinematic state of the vehicle and constrain its extent state, we develop a new 3D constant turn rate and velocity motion model, considering the complex 3D motion of the vehicle relative to the roadside sensor. Finally, we apply variational Bayesian approximation to the intractable measurement update step to enable recursive Bayesian estimation of the object's state. Simulation results using the Carla simulator and experimental results on the nuScenes dataset demonstrate the effectiveness and superiority of the proposed method in comparison to several state-of-the-art 3D EOT methods.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17906",
        "abstract url": "https://arxiv.org/abs/2404.17906",
        "title": "VIEW: Visual Imitation Learning with Waypoints",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Robots can use Visual Imitation Learning (VIL) to learn everyday tasks from video demonstrations. However, translating visual observations into actionable robot policies is challenging due to the high-dimensional nature of video data. This challenge is further exacerbated by the morphological differences between humans and robots, especially when the video demonstrations feature humans performing tasks. To address these problems we introduce Visual Imitation lEarning with Waypoints (VIEW), an algorithm that significantly enhances the sample efficiency of human-to-robot VIL. VIEW achieves this efficiency using a multi-pronged approach: extracting a condensed prior trajectory that captures the demonstrator's intent, employing an agent-agnostic reward function for feedback on the robot's actions, and utilizing an exploration algorithm that efficiently samples around waypoints in the extracted trajectory. VIEW also segments the human trajectory into grasp and task phases to further accelerate learning efficiency. Through comprehensive simulations and real-world experiments, VIEW demonstrates improved performance compared to current state-of-the-art VIL methods. VIEW enables robots to learn a diverse range of manipulation tasks involving multiple objects from arbitrarily long video demonstrations. Additionally, it can learn standard manipulation tasks such as pushing or moving objects from a single video demonstration in under 30 minutes, with fewer than 20 real-world rollouts. Code and videos here: https://collab.me.vt.edu/view/",
        "subjects": [
            "cs.RO"
        ],
        "comment": "27 pages, 17 figures"
    },
    {
        "paper id": "2404.17962",
        "abstract url": "https://arxiv.org/abs/2404.17962",
        "title": "Deep Learning for Low-Latency, Quantum-Ready RF Sensing",
        "rating": "-2",
        "keywords": [
            [
                "Quantum",
                "physics"
            ]
        ],
        "abstract": "Recent work has shown the promise of applying deep learning to enhance software processing of radio frequency (RF) signals. In parallel, hardware developments with quantum RF sensors based on Rydberg atoms are breaking longstanding barriers in frequency range, resolution, and sensitivity. In this paper, we describe our implementations of quantum-ready machine learning approaches for RF signal classification. Our primary objective is latency: while deep learning offers a more powerful computational paradigm, it also traditionally incurs latency overheads that hinder wider scale deployment. Our work spans three axes. (1) A novel continuous wavelet transform (CWT) based recurrent neural network (RNN) architecture that enables flexible online classification of RF signals on-the-fly with reduced sampling time. (2) Low-latency inference techniques for both GPU and CPU that span over 100x reductions in inference time, enabling real-time operation with sub-millisecond inference. (3) Quantum-readiness validated through application of our models to physics-based simulation of Rydberg atom QRF sensors. Altogether, our work bridges towards next-generation RF sensors that use quantum technology to surpass previous physical limits, paired with latency-optimized AI/ML software that is suitable for real-time deployment.",
        "subjects": [
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17970",
        "abstract url": "https://arxiv.org/abs/2404.17970",
        "title": "Privacy-Preserving Aggregation for Decentralized Learning with Byzantine-Robustness",
        "rating": "-2",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Decentralized machine learning (DL) has been receiving an increasing interest recently due to the elimination of a single point of failure, present in Federated learning setting. Yet, it is threatened by the looming threat of Byzantine clients who intentionally disrupt the learning process by broadcasting arbitrary model updates to other clients, seeking to degrade the performance of the global model. In response, robust aggregation schemes have emerged as promising solutions to defend against such Byzantine clients, thereby enhancing the robustness of Decentralized Learning. Defenses against Byzantine adversaries, however, typically require access to the updates of other clients, a counterproductive privacy trade-off that in turn increases the risk of inference attacks on those same model updates. In this paper, we introduce SecureDL, a novel DL protocol designed to enhance the security and privacy of DL against Byzantine threats. SecureDL~facilitates a collaborative defense, while protecting the privacy of clients' model updates through secure multiparty computation. The protocol employs efficient computation of cosine similarity and normalization of updates to robustly detect and exclude model updates detrimental to model convergence. By using MNIST, Fashion-MNIST, SVHN and CIFAR-10 datasets, we evaluated SecureDL against various Byzantine attacks and compared its effectiveness with four existing defense mechanisms. Our experiments show that SecureDL is effective even in the case of attacks by the malicious majority (e.g., 80% Byzantine clients) while preserving high training accuracy.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17974",
        "abstract url": "https://arxiv.org/abs/2404.17974",
        "title": "HVOFusion: Incremental Mesh Reconstruction Using Hybrid Voxel Octree",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Voxel"
            ],
            [
                "robotics",
                "navigation"
            ]
        ],
        "abstract": "Incremental scene reconstruction is essential to the navigation in robotics. Most of the conventional methods typically make use of either TSDF (truncated signed distance functions) volume or neural networks to implicitly represent the surface. Due to the voxel representation or involving with time-consuming sampling, they have difficulty in balancing speed, memory storage, and surface quality. In this paper, we propose a novel hybrid voxel-octree approach to effectively fuse octree with voxel structures so that we can take advantage of both implicit surface and explicit triangular mesh representation. Such sparse structure preserves triangular faces in the leaf nodes and produces partial meshes sequentially for incremental reconstruction. This storage scheme allows us to naturally optimize the mesh in explicit 3D space to achieve higher surface quality. We iteratively deform the mesh towards the target and recovers vertex colors by optimizing a shading model. Experimental results on several datasets show that our proposed approach is capable of quickly and accurately reconstructing a scene with realistic colors.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18006",
        "abstract url": "https://arxiv.org/abs/2404.18006",
        "title": "FRAME: A Modular Framework for Autonomous Map-merging: Advancements in the Field",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "In this article, a novel approach for merging 3D point cloud maps in the context of egocentric multi-robot exploration is presented. Unlike traditional methods, the proposed approach leverages state-of-the-art place recognition and learned descriptors to efficiently detect overlap between maps, eliminating the need for the time-consuming global feature extraction and feature matching process. The estimated overlapping regions are used to calculate a homogeneous rigid transform, which serves as an initial condition for the GICP point cloud registration algorithm to refine the alignment between the maps. The advantages of this approach include faster processing time, improved accuracy, and increased robustness in challenging environments. Furthermore, the effectiveness of the proposed framework is successfully demonstrated through multiple field missions of robot exploration in a variety of different underground environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "28 pages, 24 figures. Submitted to Field Robotics"
    },
    {
        "paper id": "2404.18012",
        "abstract url": "https://arxiv.org/abs/2404.18012",
        "title": "Lessons Learned: The Evolution of an Undergraduate Robotics Course in Computer Science",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "Robotics"
            ]
        ],
        "abstract": "Seven years ago (2016), we began integrating Robotics into our Computer Science curriculum. This paper explores the mission, initial goals and objectives, specific choices we made along the way, and why and outcomes. Of course, we were not the first to do so. Our contribution in this paper is to describe a seven-year experience in the hope that others going down this road will benefit, perhaps avoiding some missteps and dead-ends. We offer our answers to many questions that anyone undertaking bootstrapping a new robotics program may have to deal with. At the end of the paper, we discuss a set of lessons learned, including striking the right balance between depth and breadth in syllabus design and material organization, the significance of utilizing physical robots and criteria for selecting a suitable robotics platform, insights into the scope and design of a robotics lab, the necessity of standardizing hardware and software configurations, along with implementation methods, and strategies for preparing students for the steep learning curve.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "11 pages, presented at Robotics in Education, 2024, in Koblenz, DE"
    },
    {
        "paper id": "2404.18027",
        "abstract url": "https://arxiv.org/abs/2404.18027",
        "title": "Non-Spatial Hash Chemistry as a Minimalistic Open-Ended Evolutionary System",
        "rating": "-2",
        "keywords": [
            [
                "Chemistry"
            ]
        ],
        "abstract": "There is an increasing level of interest in open-endedness in the recent literature of Artificial Life and Artificial Intelligence. We previously proposed the cardinality leap of possibility spaces as a promising mechanism to facilitate open-endedness in artificial evolutionary systems, and demonstrated its effectiveness using Hash Chemistry, an artificial chemistry model that used a hash function as a universal fitness evaluator. However, the spatial nature of Hash Chemistry came with extensive computational costs involved in its simulation, and the particle density limit imposed to prevent explosion of computational costs prevented unbounded growth in complexity of higher-order entities. To address these limitations, here we propose a simpler non-spatial variant of Hash Chemistry in which spatial proximity of particles are represented explicitly in the form of multisets. This model modification achieved a significant reduction of computational costs in simulating the model. Results of numerical simulations showed much more significant unbounded growth in both maximal and average sizes of replicating higher-order entities than the original model, demonstrating the effectiveness of this non-spatial model as a minimalistic example of open-ended evolutionary systems.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "7 pages, 6 figures, 1 table; accepted for publication in Proceedings of IEEE CEC 2024 (part of IEEE WCCI 2024)"
    },
    {
        "paper id": "2404.18040",
        "abstract url": "https://arxiv.org/abs/2404.18040",
        "title": "Fashion Recommendation: Outfit Compatibility using GNN",
        "rating": "-2",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Numerous industries have benefited from the use of machine learning and fashion in industry is no exception. By gaining a better understanding of what makes a good outfit, companies can provide useful product recommendations to their users. In this project, we follow two existing approaches that employ graphs to represent outfits and use modified versions of the Graph neural network (GNN) frameworks. Both Node-wise Graph Neural Network (NGNN) and Hypergraph Neural Network aim to score a set of items according to the outfit compatibility of items. The data used is the Polyvore Dataset which consists of curated outfits with product images and text descriptions for each product in an outfit. We recreate the analysis on a subset of this data and compare the two existing models on their performance on two tasks Fill in the blank (FITB): finding an item that completes an outfit, and Compatibility prediction: estimating compatibility of different items grouped as an outfit. We can replicate the results directionally and find that HGNN does have a slightly better performance on both tasks. On top of replicating the results of the two papers we also tried to use embeddings generated from a vision transformer and witness enhanced prediction accuracy across the board",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18041",
        "abstract url": "https://arxiv.org/abs/2404.18041",
        "title": "Variational Optimization for Quantum Problems using Deep Generative Networks",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Optimization is one of the keystones of modern science and engineering. Its applications in quantum technology and machine learning helped nurture variational quantum algorithms and generative AI respectively. We propose a general approach to design variational optimization algorithms based on generative models: the Variational Generative Optimization Network (VGON). To demonstrate its broad applicability, we apply VGON to three quantum tasks: finding the best state in an entanglement-detection protocol, finding the ground state of a 1D quantum spin model with variational quantum circuits, and generating degenerate ground states of many-body quantum Hamiltonians. For the first task, VGON greatly reduces the optimization time compared to stochastic gradient descent while generating nearly optimal quantum states. For the second task, VGON alleviates the barren plateau problem in variational quantum circuits. For the final task, VGON can identify the degenerate ground state spaces after a single stage of training and generate a variety of states therein.",
        "subjects": [
            "quant-ph"
        ],
        "comment": "17 pages, 13 figures, comments welcome"
    },
    {
        "paper id": "2404.18047",
        "abstract url": "https://arxiv.org/abs/2404.18047",
        "title": "LIKO: LiDAR, Inertial, and Kinematic Odometry for Bipedal Robots",
        "rating": "-2",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "High-frequency and accurate state estimation is crucial for biped robots. This paper presents a tightly-coupled LiDAR-Inertial-Kinematic Odometry (LIKO) for biped robot state estimation based on an iterated extended Kalman filter. Beyond state estimation, the foot contact position is also modeled and estimated. This allows for both position and velocity updates from kinematic measurement. Additionally, the use of kinematic measurement results in an increased output state frequency of about 1kHz. This ensures temporal continuity of the estimated state and makes it practical for control purposes of biped robots. We also announce a biped robot dataset consisting of LiDAR, inertial measurement unit (IMU), joint encoders, force/torque (F/T) sensors, and motion capture ground truth to evaluate the proposed method. The dataset is collected during robot locomotion, and our approach reached the best quantitative result among other LIO-based methods and biped robot state estimation algorithms. The dataset and source code will be available at https://github.com/Mr-Zqr/LIKO.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17801",
        "abstract url": "https://arxiv.org/abs/2404.17801",
        "title": "Dynamical Mode Recognition of Coupled Flame Oscillators by Supervised and Unsupervised Learning Approaches",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Combustion instability in gas turbines and rocket engines, as one of the most challenging problems in combustion research, arises from the complex interactions among flames, which are also influenced by chemical reactions, heat and mass transfer, and acoustics. Identifying and understanding combustion instability is essential to ensure the safe and reliable operation of many combustion systems, where exploring and classifying the dynamical behaviors of complex flame systems is a core take. To facilitate fundamental studies, the present work concerns dynamical mode recognition of coupled flame oscillators made of flickering buoyant diffusion flames, which have gained increasing attention in recent years but are not sufficiently understood. The time series data of flame oscillators are generated by fully validated reacting flow simulations. Due to limitations of expertise-based models, a data-driven approach is adopted. In this study, a nonlinear dimensional reduction model of variational autoencoder (VAE) is used to project the simulation data onto a 2-dimensional latent space. Based on the phase trajectories in latent space, both supervised and unsupervised classifiers are proposed for datasets with well known labeling and without, respectively. For labeled datasets, we establish the Wasserstein-distance-based classifier (WDC) for mode recognition; for unlabeled datasets, we develop a novel unsupervised classifier (GMM-DTWC) combining dynamic time warping (DTW) and Gaussian mixture model (GMM). Through comparing with conventional approaches for dimensionality reduction and classification, the proposed supervised and unsupervised VAE-based approaches exhibit a prominent performance for distinguishing dynamical modes, implying their potential extension to dynamical mode recognition of complex combustion problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "research paper (21 pages, 15 figures)"
    },
    {
        "paper id": "2404.17805",
        "abstract url": "https://arxiv.org/abs/2404.17805",
        "title": "From Optimization to Generalization: Fair Federated Learning against Quality Shift via Inter-Client Sharpness Matching",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Due to escalating privacy concerns, federated learning has been recognized as a vital approach for training deep neural networks with decentralized medical data. In practice, it is challenging to ensure consistent imaging quality across various institutions, often attributed to equipment malfunctions affecting a minority of clients. This imbalance in image quality can cause the federated model to develop an inherent bias towards higher-quality images, thus posing a severe fairness issue. In this study, we pioneer the identification and formulation of this new fairness challenge within the context of the imaging quality shift. Traditional methods for promoting fairness in federated learning predominantly focus on balancing empirical risks across diverse client distributions. This strategy primarily facilitates fair optimization across different training data distributions, yet neglects the crucial aspect of generalization. To address this, we introduce a solution termed Federated learning with Inter-client Sharpness Matching (FedISM). FedISM enhances both local training and global aggregation by incorporating sharpness-awareness, aiming to harmonize the sharpness levels across clients for fair generalization. Our empirical evaluations, conducted using the widely-used ICH and ISIC 2019 datasets, establish FedISM's superiority over current state-of-the-art federated learning methods in promoting fairness. Code is available at https://github.com/wnn2000/FFL4MIA.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This paper is accepted at IJCAI'24 (Main Track)"
    },
    {
        "paper id": "2404.17833",
        "abstract url": "https://arxiv.org/abs/2404.17833",
        "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs",
        "rating": "-2.5",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Agents based on large language models (LLMs) have demonstrated effectiveness in solving a wide range of tasks by integrating LLMs with key modules such as planning, memory, and tool usage. Increasingly, customers are adopting LLM agents across a variety of commercial applications critical to reliability, including support for mental well-being, chemical synthesis, and software development. Nevertheless, our observations and daily use of LLM agents indicate that they are prone to making erroneous plans, especially when the tasks are complex and require long-term planning. In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning. As the first work in this direction, we formulate the detection of erroneous planning as a constraint satisfiability problem: an LLM agent's plan is considered erroneous if its execution violates the constraints derived from the user inputs. To this end, PDoctor first defines a domain-specific language (DSL) for user queries and synthesizes varying inputs with the assistance of the Z3 constraint solver. These synthesized inputs are natural language paragraphs that specify the requirements for completing a series of tasks. Then, PDoctor derives constraints from these requirements to form a testing oracle. We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4). The results show that PDoctor can effectively detect diverse errors in agent planning and provide insights and error characteristics that are valuable to both agent developers and users. We conclude by discussing potential alternative designs and directions to extend PDoctor.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17886",
        "abstract url": "https://arxiv.org/abs/2404.17886",
        "title": "Feature graphs for interpretable unsupervised tree ensembles: centrality, interaction, and application in disease subtyping",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biomedicine",
                "healthcare",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Interpretable machine learning has emerged as central in leveraging artificial intelligence within high-stakes domains such as healthcare, where understanding the rationale behind model predictions is as critical as achieving high predictive accuracy. In this context, feature selection assumes a pivotal role in enhancing model interpretability by identifying the most important input features in black-box models. While random forests are frequently used in biomedicine for their remarkable performance on tabular datasets, the accuracy gained from aggregating decision trees comes at the expense of interpretability. Consequently, feature selection for enhancing interpretability in random forests has been extensively explored in supervised settings. However, its investigation in the unsupervised regime remains notably limited. To address this gap, the study introduces novel methods to construct feature graphs from unsupervised random forests and feature selection strategies to derive effective feature combinations from these graphs. Feature graphs are constructed for the entire dataset as well as individual clusters leveraging the parent-child node splits within the trees, such that feature centrality captures their relevance to the clustering task, while edge weights reflect the discriminating power of feature pairs. Graph-based feature selection methods are extensively evaluated on synthetic and benchmark datasets both in terms of their ability to reduce dimensionality while improving clustering performance, as well as to enhance model interpretability. An application on omics data for disease subtyping identifies the top features for each cluster, showcasing the potential of the proposed approach to enhance interpretability in clustering analyses and its utility in a real-world biomedical application.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17925",
        "abstract url": "https://arxiv.org/abs/2404.17925",
        "title": "Accurate and fast anomaly detection in industrial processes and IoT environments",
        "rating": "-2.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "industrial",
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a novel, simple and widely applicable semi-supervised procedure for anomaly detection in industrial and IoT environments, SAnD (Simple Anomaly Detection). SAnD comprises 5 steps, each leveraging well-known statistical tools, namely; smoothing filters, variance inflation factors, the Mahalanobis distance, threshold selection algorithms and feature importance techniques. To our knowledge, SAnD is the first procedure that integrates these tools to identify anomalies and help decipher their putative causes. We show how each step contributes to tackling technical challenges that practitioners face when detecting anomalies in industrial contexts, where signals can be highly multicollinear, have unknown distributions, and intertwine short-lived noise with the long(er)-lived actual anomalies. The development of SAnD was motivated by a concrete case study from our industrial partner, which we use here to show its effectiveness. We also evaluate the performance of SAnD by comparing it with a selection of semi-supervised methods on public datasets from the literature on anomaly detection. We conclude that SAnD is effective, broadly applicable, and outperforms existing approaches in both anomaly detection and runtime.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18947",
        "abstract url": "https://arxiv.org/abs/2404.18947",
        "title": "Multimodal Fusion on Low-quality Data: A Comprehensive Survey",
        "rating": "-2.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "medical",
                "diagnosis"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multimodal fusion focuses on integrating information from multiple modalities with the goal of more accurate prediction, which has achieved remarkable progress in a wide range of scenarios, including autonomous driving and medical diagnosis. However, the reliability of multimodal fusion remains largely unexplored especially under low-quality data settings. This paper surveys the common challenges and recent advances of multimodal fusion in the wild and presents them in a comprehensive taxonomy. From a data-centric view, we identify four main challenges that are faced by multimodal fusion on low-quality data, namely (1) noisy multimodal data that are contaminated with heterogeneous noises, (2) incomplete multimodal data that some modalities are missing, (3) imbalanced multimodal data that the qualities or properties of different modalities are significantly different and (4) quality-varying multimodal data that the quality of each modality dynamically changes with respect to different samples. This new taxonomy will enable researchers to understand the state of the field and identify several potential directions. We also provide discussion for the open problems in this field together with interesting future research directions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Feel free to comment on our manuscript: qingyangzhang@tju.edu.cn"
    },
    {
        "paper id": "2405.01583",
        "abstract url": "https://arxiv.org/abs/2405.01583",
        "title": "MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "Medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.CL"
            ],
            [
                "workshop"
            ]
        ],
        "abstract": "The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual & Multimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a). This paper addresses the limitations of traditional methods by proposing a weakly supervised learning approach for open-ended medical question-answering (QA). Our system leverages readily available MEDIQA-M3G images via a VGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning of informative skin condition representations. Using pre-trained QA models, we further bridge the gap between visual and textual information through multimodal fusion. This approach tackles complex, open-ended questions even without predefined answer choices. We empower the generation of comprehensive answers by feeding the ViT-CLIP model with multiple responses alongside images. This work advances medical QA research, paving the way for clinical decision support systems and ultimately improving healthcare delivery.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "7 pages, 3 figures, Clinical NLP 2024 workshop proceedings in Shared Task"
    },
    {
        "paper id": "2404.17815",
        "abstract url": "https://arxiv.org/abs/2404.17815",
        "title": "Learning-based Hierarchical Control: Emulating the Central Nervous System for Bio-Inspired Legged Robot Locomotion",
        "rating": "-3",
        "keywords": [
            [
                "Robot"
            ],
            [
                "Bio-Inspired"
            ]
        ],
        "abstract": "Animals possess a remarkable ability to navigate challenging terrains, achieved through the interplay of various pathways between the brain, central pattern generators (CPGs) in the spinal cord, and musculoskeletal system. Traditional bioinspired control frameworks often rely on a singular control policy that models both higher (supraspinal) and spinal cord functions. In this work, we build upon our previous research by introducing two distinct neural networks: one tasked with modulating the frequency and amplitude of CPGs to generate the basic locomotor rhythm (referred to as the spinal policy, SCP), and the other responsible for receiving environmental perception data and directly modulating the rhythmic output from the SCP to execute precise movements on challenging terrains (referred to as the descending modulation policy). This division of labor more closely mimics the hierarchical locomotor control systems observed in legged animals, thereby enhancing the robot's ability to navigate various uneven surfaces, including steps, high obstacles, and terrains with gaps. Additionally, we investigate the impact of sensorimotor delays within our framework, validating several biological assumptions about animal locomotion systems. Specifically, we demonstrate that spinal circuits play a crucial role in generating the basic locomotor rhythm, while descending pathways are essential for enabling appropriate gait modifications to accommodate uneven terrain. Notably, our findings also reveal that the multi-layered control inherent in animals exhibits remarkable robustness against time delays. Through these investigations, this paper contributes to a deeper understanding of the fundamental principles of interplay between spinal and supraspinal mechanisms in biological locomotion. It also supports the development of locomotion controllers in parallel to biological structures which are ...",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)"
    },
    {
        "paper id": "2404.17823",
        "abstract url": "https://arxiv.org/abs/2404.17823",
        "title": "Performance Analysis for Downlink Transmission in Multi-Connectivity Cellular V2X Networks",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "5G"
            ]
        ],
        "abstract": "With the ever-increasing number of connected vehicles in the fifth-generation mobile communication networks (5G) and beyond 5G (B5G), ensuring the reliability and high-speed demand of cellular vehicle-to-everything (C-V2X) communication in scenarios where vehicles are moving at high speeds poses a significant challenge.Recently, multi-connectivity technology has become a promising network access paradigm for improving network performance and reliability for C-V2X in the 5G and B5G era. To this end, this paper proposes an analytical framework for the performance of downlink in multi-connectivity C-V2X networks. Specifically, by modeling the vehicles and base stations as one-dimensional Poisson point processes, we first derive and analyze the joint distance distribution of multi-connectivity. Then through leveraging the tools of stochastic geometry, the coverage probability and spectral efficiency are obtained based on the previous results for general multi-connectivity cases in C-V2X. Additionally, we evaluate the effect of path loss exponent and the density of downlink base station on system performance indicators. We demonstrate through extensive Monte Carlo simulations that multi-connectivity technology can effectively enhance network performance in C-V2X. Our findings have important implications for the research and application of multi-connectivity C-V2X in the 5G and B5G era.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages,14 figures. IEEE Internet of Things Journal, 2023"
    },
    {
        "paper id": "2404.17844",
        "abstract url": "https://arxiv.org/abs/2404.17844",
        "title": "Towards Robust Recommendation: A Review and an Adversarial Robustness Evaluation Library",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recently, recommender system has achieved significant success. However, due to the openness of recommender systems, they remain vulnerable to malicious attacks. Additionally, natural noise in training data and issues such as data sparsity can also degrade the performance of recommender systems. Therefore, enhancing the robustness of recommender systems has become an increasingly important research topic. In this survey, we provide a comprehensive overview of the robustness of recommender systems. Based on our investigation, we categorize the robustness of recommender systems into adversarial robustness and non-adversarial robustness. In the adversarial robustness, we introduce the fundamental principles and classical methods of recommender system adversarial attacks and defenses. In the non-adversarial robustness, we analyze non-adversarial robustness from the perspectives of data sparsity, natural noise, and data imbalance. Additionally, we summarize commonly used datasets and evaluation metrics for evaluating the robustness of recommender systems. Finally, we also discuss the current challenges in the field of recommender system robustness and potential future research directions. Additionally, to facilitate fair and efficient evaluation of attack and defense methods in adversarial robustness, we propose an adversarial robustness evaluation library--ShillingREC, and we conduct evaluations of basic attack models and recommendation models. ShillingREC project is released at https://github.com/chengleileilei/ShillingREC.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17890",
        "abstract url": "https://arxiv.org/abs/2404.17890",
        "title": "DPER: Diffusion Prior Driven Neural Representation for Limited Angle and Sparse View CT Reconstruction",
        "rating": "-3",
        "keywords": [
            [
                "NeRF"
            ],
            [
                "Diffusion"
            ],
            [
                "CT",
                "X-ray"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Limited-angle and sparse-view computed tomography (LACT and SVCT) are crucial for expanding the scope of X-ray CT applications. However, they face challenges due to incomplete data acquisition, resulting in diverse artifacts in the reconstructed CT images. Emerging implicit neural representation (INR) techniques, such as NeRF, NeAT, and NeRP, have shown promise in under-determined CT imaging reconstruction tasks. However, the unsupervised nature of INR architecture imposes limited constraints on the solution space, particularly for the highly ill-posed reconstruction task posed by LACT and ultra-SVCT. In this study, we introduce the Diffusion Prior Driven Neural Representation (DPER), an advanced unsupervised framework designed to address the exceptionally ill-posed CT reconstruction inverse problems. DPER adopts the Half Quadratic Splitting (HQS) algorithm to decompose the inverse problem into data fidelity and distribution prior sub-problems. The two sub-problems are respectively addressed by INR reconstruction scheme and pre-trained score-based diffusion model. This combination initially preserves the implicit image local consistency prior from INR. Additionally, it effectively augments the feasibility of the solution space for the inverse problem through the generative diffusion model, resulting in increased stability and precision in the solutions. We conduct comprehensive experiments to evaluate the performance of DPER on LACT and ultra-SVCT reconstruction with two public datasets (AAPM and LIDC). The results show that our method outperforms the state-of-the-art reconstruction methods on in-domain datasets, while achieving significant performance improvements on out-of-domain datasets.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "15 pages, 10 figures"
    },
    {
        "paper id": "2404.17954",
        "abstract url": "https://arxiv.org/abs/2404.17954",
        "title": "Parameterized Linear Time Transitive Closure",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Inquiries such as whether a task A depends on a task B, whether an author A has been influenced by a paper B, whether a certain protein is associated with a specific biological process or molecular function, or whether class A inherits from class B, are just a few examples of inquiries that can be modeled as reachability queries on a network (Directed Graph). Digital systems answer myriad such inquiries every day. In this paper, we discuss the transitive closure problem. We focus on applicable solutions that enable us to answer queries fast, in constant time, and can serve in real-world applications. In contrast to the majority of research on this topic that revolves around the construction of a two-dimensional adjacency matrix, we present an approach that builds a reachability indexing scheme. This scheme enables us to answer queries in constant time and can be built in parameterized linear time. In addition, it captures a compressed data structure. Our approach and algorithms are validated by extensive experiments that shed light on the factors that play a key role in this problem. To stress the efficiency of this solution and demonstrate the potential to apply our approach to important problems, we use it to speed up Fulkerson's method for finding the width of a DAG. Our results challenge the prevailing belief, reiterated over the last thirty years, regarding the efficiency of this method. Our approach is based on the concept of chain decomposition. Before we delve into its description, we introduce, analyze, and utilize a chain decomposition algorithm. Furthermore, we explore how chain decomposition can facilitate transitive closure solutions introducing a general purpose linear time reduction technique that removes a large subset of transitive edges given any chain decomposition.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2212.03945"
    },
    {
        "paper id": "2404.17973",
        "abstract url": "https://arxiv.org/abs/2404.17973",
        "title": "Over-the-Air Fusion of Sparse Spatial Features for Integrated Sensing and Edge AI over Broadband Channels",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "The 6G mobile networks are differentiated from 5G by two new usage scenarios - distributed sensing and edge AI. Their natural integration, termed integrated sensing and edge AI (ISEA), promised to create a platform for enabling environment perception to make intelligent decisions and take real-time actions. A basic operation in ISEA is for a fusion center to acquire and fuse features of spatial sensing data distributed at many agents. To overcome its communication bottleneck due to multiple access by numerous agents over hostile wireless channels, we propose a novel framework, called Spatial Over-the-Air Fusion (Spatial AirFusion), which exploits radio waveform superposition to aggregate spatially sparse features over the air. The technology is more sophisticated than conventional Over-the-Air Computing (AirComp) as it supports simultaneous aggregation over multiple voxels, which partition the 3D sensing region, and across multiple subcarriers. Its efficiency and robustness are derived from exploitation of both spatial feature sparsity and multiuser channel diversity to intelligently pair voxel-level aggregation tasks and subcarriers to maximize the minimum receive SNR among voxels under instantaneous power constraints. To optimally solve the mixed-integer Voxel-Carrier Pairing and Power Allocation (VoCa-PPA) problem, the proposed approach hinges on two useful results: (1) deriving the optimal power allocation as a closed-form function of voxel-carrier pairing and (2) discovering a useful property of VoCa-PPA that dramatically reduces the solution-space dimensionality. Both a low-complexity greedy algorithm and an optimal tree-search based approach are designed for VoCa-PPA. Extensive simulations using real datasets show that Spatial AirFusion achieves significant error reduction and accuracy improvement compared with conventional AirComp without awareness of spatial sparsity.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to IEEE for possible publication"
    },
    {
        "paper id": "2404.18010",
        "abstract url": "https://arxiv.org/abs/2404.18010",
        "title": "Energy-Efficient Federated Learning in Cooperative Communication within Factory Subnetworks",
        "rating": "-3",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "This paper investigates energy-efficient transmission protocols in relay-assisted federated learning (FL) setup within industrial subnetworks, considering latency and power constraints. In the subnetworks, devices collaborate to train a global model by transmitting their local models at the edge-enabled primary access (pAP) directly or via secondary access points (sAPs), which act as relays to optimize the training latency. We begin by formulating the energy efficiency problem for our proposed transmission protocol. Given its non-convex nature, we decompose it to minimize computational and transmission energy separately. First, we introduce an algorithm that categorizes devices into single-hop and two-hop groups to decrease transmission energy and then selects associated sAPs. Subsequently, we optimize the transmit power, aiming to maximize energy efficiency. To that end, we propose a Sequential Parametric Convex Approximation (SPCA) method to configure system parameters jointly. Simulation results show a 5% improvement in convergence, significantly reduced outage, and at least a twofold savings in total energy achieved by our proposed algorithm compared to single-hop transmission.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17859",
        "abstract url": "https://arxiv.org/abs/2404.17859",
        "title": "A Formal Specification of a Data Model for Malaria Surveillance in the Developing World",
        "rating": "-4",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "The fourth Industrial Revolution(4IR), together with the COVID-19 pandemic have made a loud call for digitizing diagnosis processes. The world is now convinced that it is imperative to digitize the diagnosis of long standing diseases such as malaria for more efficient treatment and control. It has been seen that malaria control would benefit a lot from digitizing its diagnosis processes such as data gathering. We propose, in this paper, the architecture of a digital data collection system and how it is used to gather data for malaria awareness. The system is formally specified using Z notation, and based on the capability of the system, possible malaria determinants are defined and their retrieving mechanisms are discussed.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "This paper has been accepted at 2024 The 7th International Conference on Information and Computer Technologies. Due to funding constraints, the paper cannot be published"
    },
    {
        "paper id": "2404.17884",
        "abstract url": "https://arxiv.org/abs/2404.17884",
        "title": "Exploring the efficacy of a hybrid approach with modal decomposition over fully deep learning models for flow dynamics forecasting",
        "rating": "-4",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Fluid dynamics problems are characterized by being multidimensional and nonlinear, causing the experiments and numerical simulations being complex, time-consuming and monetarily expensive. In this sense, there is a need to find new ways to obtain data in a more economical manner. Thus, in this work we study the application of time series forecasting to fluid dynamics problems, where the aim is to predict the flow dynamics using only past information. We focus our study on models based on deep learning that do not require a high amount of data for training, as this is the problem we are trying to address. Specifically in this work we have tested three autoregressive models where two of them are fully based on deep learning and the other one is a hybrid model that combines modal decomposition with deep learning. We ask these models to generate $200$ time-ahead predictions of two datasets coming from a numerical simulation and experimental measurements, where the latter is characterized by being turbulent. We show how the hybrid model generates more reliable predictions in the experimental case, as it is physics-informed in the sense that the modal decomposition extracts the physics in a way that allows us to predict it.",
        "subjects": [
            "physics.flu-dyn"
        ],
        "comment": "37 pages, 17 figures and 9 tables"
    },
    {
        "paper id": "2404.18950",
        "abstract url": "https://arxiv.org/abs/2404.18950",
        "title": "Remote Sensing Image Enhancement through Spatiotemporal Filtering",
        "rating": "-4",
        "keywords": [
            [
                "SVM",
                "support vector machine"
            ],
            [
                "Remote Sensing",
                "satellite"
            ],
            [
                "Image Enhancement"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The analysis of time-sequence satellite images is a powerful tool in remote sensing; it is used to explore the statics and dynamics of the surface of the earth. Usually, the quality of multitemporal images is influenced by metrological conditions, high reflectance of surfaces, illumination, and satellite sensor conditions. These negative influences may produce noises and different radiances and appearances between the images, which can affect the applications that process them. Thus, a spatiotemporal bilateral filter has been adopted in this research to enhance the quality of an image before using it in any application. The filter takes advantage of the temporal information provided by multi temporal images and attempts to reduce the differences between them to improve transfer learning used in classification. The classification method used here is support vector machine (SVM). Three experiments were conducted in this research, two were on Landsat 8 images with low-medium resolution, and the third on high-resolution images of Planet satellite. The newly developed filter proved that it can enhance the accuracy of classification using transfer learning by about 5%,15%, and 2% for the three experiments respectively.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Masters Thesis, Geospatial Data Analytics Lab, The Ohio State University, 2017"
    },
    {
        "paper id": "2404.17943",
        "abstract url": "https://arxiv.org/abs/2404.17943",
        "title": "Interaction Event Forecasting in Multi-Relational Recursive HyperGraphs: A Temporal Point Process Approach",
        "rating": "-4.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "survival"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modeling the dynamics of interacting entities using an evolving graph is an essential problem in fields such as financial networks and e-commerce. Traditional approaches focus primarily on pairwise interactions, limiting their ability to capture the complexity of real-world interactions involving multiple entities and their intricate relationship structures. This work addresses the problem of forecasting higher-order interaction events in multi-relational recursive hypergraphs. This is done using a dynamic graph representation learning framework that can capture complex relationships involving multiple entities. The proposed model, \\textit{Relational Recursive Hyperedge Temporal Point Process} (RRHyperTPP) uses an encoder that learns a dynamic node representation based on the historical interaction patterns and then a hyperedge link prediction based decoder to model the event's occurrence. These learned representations are then used for downstream tasks involving forecasting the type and time of interactions. The main challenge in learning from hyperedge events is that the number of possible hyperedges grows exponentially with the number of nodes in the network. This will make the computation of negative log-likelihood of the temporal point process expensive, as the calculation of survival function requires a summation over all possible hyperedges. In our work, we use noise contrastive estimation to learn the parameters of our model, and we have experimentally shown that our models perform better than previous state-of-the-art methods for interaction forecasting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2404.18048",
        "abstract url": "https://arxiv.org/abs/2404.18048",
        "title": "Scalable, Interpretable Distributed Protocol Verification by Inductive Proof Slicing",
        "rating": "-6",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "graph"
            ],
            [
                "diagnosis"
            ],
            [
                "grammar"
            ]
        ],
        "abstract": "Many techniques for automated inference of inductive invariants for distributed protocols have been developed over the past several years, but their performance can still be unpredictable and their failure modes opaque for large-scale verification tasks. In this paper, we present inductive proof slicing, a new automated, compositional technique for inductive invariant inference that scales effectively to large distributed protocol verification tasks. Our technique is built on a core, novel data structure, the inductive proof graph, which explicitly represents the lemma and action dependencies of an inductive invariant and is built incrementally during the inference procedure, backwards from a target safety property. We present an invariant inference algorithm that integrates localized syntax-guided lemma synthesis routines at nodes of this graph, which are accelerated by computation of localized grammar and state variable slices. Additionally, in the case of failure to produce a complete inductive invariant, maintenance of this proof graph structure allows failures to be localized to small sub-components of this graph, enabling fine-grained failure diagnosis and repair by a user. We evaluate our technique on several complex distributed and concurrent protocols, including a large scale specification of the Raft consensus protocol, which is beyond the capabilities of modern distributed protocol verification tools, and also demonstrate how its interpretability features allow effective diagnosis and repair in cases of initial failure.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17780",
        "abstract url": "https://arxiv.org/abs/2404.17780",
        "title": "Verco: Learning Coordinated Verbal Communication for Multi-agent Reinforcement Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, multi-agent reinforcement learning algorithms have made significant advancements in diverse gaming environments, leading to increased interest in the broader application of such techniques. To address the prevalent challenge of partial observability, communication-based algorithms have improved cooperative performance through the sharing of numerical embedding between agents. However, the understanding of the formation of collaborative mechanisms is still very limited, making designing a human-understandable communication mechanism a valuable problem to address. In this paper, we propose a novel multi-agent reinforcement learning algorithm that embeds large language models into agents, endowing them with the ability to generate human-understandable verbal communication. The entire framework has a message module and an action module. The message module is responsible for generating and sending verbal messages to other agents, effectively enhancing information sharing among agents. To further enhance the message module, we employ a teacher model to generate message labels from the global view and update the student model through Supervised Fine-Tuning (SFT). The action module receives messages from other agents and selects actions based on current local observations and received messages. Experiments conducted on the Overcooked game demonstrate our method significantly enhances the learning efficiency and performance of existing methods, while also providing an interpretable tool for humans to understand the process of multi-agent cooperation.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2404.17781",
        "abstract url": "https://arxiv.org/abs/2404.17781",
        "title": "A Value-Oriented Investigation of Photoshop's Generative Fill",
        "rating": "-10",
        "keywords": [],
        "abstract": "The creative industry is both concerned and enthusiastic about how generative AI will reshape creativity. How might these tools interact with the workflow values of creative artists? In this paper, we adopt a value-sensitive design framework to examine how generative AI, particularly Photoshop's Generative Fill (GF), helps or hinders creative professionals' values. We obtained 566 unique posts about GF from online forums for creative professionals who use Photoshop in their current work practices. We conducted reflexive thematic analysis focusing on usefulness, ease of use, and user values. Users found GF useful in doing touch-ups, expanding images, and generating composite images. GF helped users' values of productivity by making work efficient but created a value tension around creativity: it helped reduce barriers to creativity but hindered distinguishing 'human' from algorithmic art. Furthermore, GF hindered lived experiences shaping creativity and hindered the honed prideful skills of creative work.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17783",
        "abstract url": "https://arxiv.org/abs/2404.17783",
        "title": "KnapsackLB: Enabling Performance-Aware Layer-4 Load Balancing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Layer-4 load balancer (LB) is a key building block of online services. In this paper, we empower such LBs to adapt to different and dynamic performance of backend instances (DIPs). Our system, KNAPSACKLB, is generic (can work with variety of LBs), does not require agents on DIPs, LBs or clients, and scales to large numbers of DIPs. KNAPSACKLB uses judicious active probes to learn a mapping from LB weights to the response latency of each DIP, and then applies Integer Linear Programming (ILP) to calculate LB weights that optimize latency, using an iterative method to scale the computation to large numbers of DIPs. Using testbed experiments and simulations, we show that KNAPSACKLB load balances traffic as per the performance and cuts average latency by up to 45% compared to existing designs.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17794",
        "abstract url": "https://arxiv.org/abs/2404.17794",
        "title": "GPT for Games: A Scoping Review (2020-2023)",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a scoping review of 55 articles to explore GPT's potential for games, offering researchers a comprehensive understanding of the current applications and identifying both emerging trends and unexplored areas. We identify five key applications of GPT in current game research: procedural content generation, mixed-initiative game design, mixed-initiative gameplay, playing games, and game user research. Drawing from insights in each of these application areas, we propose directions for future research in each one. This review aims to lay the groundwork by illustrating the state of the art for innovative GPT applications in games, promising to enrich game development and enhance player experiences with cutting-edge AI innovations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "To be published in IEEE Conference on Games 2024"
    },
    {
        "paper id": "2404.17818",
        "abstract url": "https://arxiv.org/abs/2404.17818",
        "title": "Automatic Build Repair for Test Cases using Incompatible Java Versions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context: Bug bisection is a common technique used to identify a revision that introduces a bug or indirectly fixes a bug, and often involves executing multiple revisions of a project to determine whether the bug is present within the revision. However, many legacy revisions often cannot be successfully compiled due to changes in the programming language or tools used in the compilation process, adding complexity and preventing automation in the bisection process. Objective: In this paper, we introduce an approach to repair test cases of Java projects by performing dependency minimization. Our approach aims to remove classes and methods that are not required for the execution of one or more test cases. Unlike existing state-of-the-art techniques, our approach performs minimization at source-level, which allows compile-time errors to be fixed. Method: A standalone Java tool implementing our technique was developed, and we evaluated our technique using subjects from Defects4J retargeted against Java 8 and 17. Results: Our evaluation showed that a majority of subjects can be repaired solely by performing minimization, including replicating the test results of the original version. Furthermore, our technique is also shown to achieve accurate minimized results, while only adding a small overhead to the bisection process. Conclusion: Our proposed technique is shown to be effective for repairing build failures with minimal overhead, making it suitable for use in automated bug bisection. Our tool can also be adapted for use cases such as bug corpus creation and refactoring.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "44 pages, 22 figures (incl. tables and listings); To be published in Information and Software Technology. Link to artifact is available within the paper"
    },
    {
        "paper id": "2404.17839",
        "abstract url": "https://arxiv.org/abs/2404.17839",
        "title": "Improving Smart Contract Security with Contrastive Learning-based Vulnerability Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Currently, smart contract vulnerabilities (SCVs) have emerged as a major factor threatening the transaction security of blockchain. Existing state-of-the-art methods rely on deep learning to mitigate this threat. They treat each input contract as an independent entity and feed it into a deep learning model to learn vulnerability patterns by fitting vulnerability labels. It is a pity that they disregard the correlation between contracts, failing to consider the commonalities between contracts of the same type and the differences among contracts of different types. As a result, the performance of these methods falls short of the desired level. To tackle this problem, we propose a novel Contrastive Learning Enhanced Automated Recognition Approach for Smart Contract Vulnerabilities, named Clear. In particular, Clear employs a contrastive learning (CL) model to capture the fine-grained correlation information among contracts and generates correlation labels based on the relationships between contracts to guide the training process of the CL model. Finally, it combines the correlation and the semantic information of the contract to detect SCVs. Through an empirical evaluation of a large-scale real-world dataset of over 40K smart contracts and compare 13 state-of-the-art baseline methods. We show that Clear achieves (1) optimal performance over all baseline methods; (2) 9.73%-39.99% higher F1-score than existing deep learning methods.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17842",
        "abstract url": "https://arxiv.org/abs/2404.17842",
        "title": "Using LLMs in Software Requirements Specifications: An Empirical Evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "The creation of a Software Requirements Specification (SRS) document is important for any software development project. Given the recent prowess of Large Language Models (LLMs) in answering natural language queries and generating sophisticated textual outputs, our study explores their capability to produce accurate, coherent, and structured drafts of these documents to accelerate the software development lifecycle. We assess the performance of GPT-4 and CodeLlama in drafting an SRS for a university club management system and compare it against human benchmarks using eight distinct criteria. Our results suggest that LLMs can match the output quality of an entry-level software engineer to generate an SRS, delivering complete and consistent drafts. We also evaluate the capabilities of LLMs to identify and rectify problems in a given requirements document. Our experiments indicate that GPT-4 is capable of identifying issues and giving constructive feedback for rectifying them, while CodeLlama's results for validation were not as encouraging. We repeated the generation exercise for four distinct use cases to study the time saved by employing LLMs for SRS generation. The experiment demonstrates that LLMs may facilitate a significant reduction in development time for entry-level software engineers. Hence, we conclude that the LLMs can be gainfully used by software engineers to increase productivity by saving time and effort in generating, validating and rectifying software requirements.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted to RE@Next! at the IEEE International Requirements Engineering Conference 2024 at Reykjavik, Iceland"
    },
    {
        "paper id": "2404.17864",
        "abstract url": "https://arxiv.org/abs/2404.17864",
        "title": "Solvent: liquidity verification of smart contracts",
        "rating": "-10",
        "keywords": [],
        "abstract": "Smart contracts are programs executed by blockchains networks to regulate the exchange of crypto-assets between untrusted users. Due to their immutability, public accessibility and high value at stake, smart contracts are an attractive target for attackers, as evidenced by a long history of security incidents. This has been a driving factor for the application of formal methods to Ethereum, the leading smart contract platform, and Solidity, its main smart contract language, which have become the target of dozens of verification tools with varying objectives. A current limitation of these tools is that they are not really effective in expressing and verifying liquidity properties regarding the exchange of crypto-assets: for example, is it true that in every reachable state a user can fire a sequence of transactions to withdraw a given amount of crypto-assets? We propose Solvent, a tool aimed at verifying these kinds of properties, which are beyond the reach of existing verification tools for Solidity. We evaluate the effectiveness and performance of Solvent through a common benchmark of smart contracts.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17866",
        "abstract url": "https://arxiv.org/abs/2404.17866",
        "title": "IRatePL2C: Importance Rating-based Approach for Product Lines Collaborative Configuration",
        "rating": "-10",
        "keywords": [],
        "abstract": "Some of them proposed an approach in which involved stakeholders can freely configure the product line without being constrained by the choices made the other ones. The core of any proposed approach in this context focuses on how conflictual situations are resolved. Few works consider stakeholders preferences in their resolution process. However, to generate a valid solution satisfying all constraints, they generally rely on a process of exponential complexity. In this work, we propose the IRatePL2C approach, which resolution strategy relies on importance degrees assigned by the stakeholders to their initial configuration choices. IRatePL2C starts by merging stakeholders' configurations and then detecting and resolving the conflicts according to their type: explicit or implicit in sequential steps. Finally, domain constraints are propagated and the process is reiterated to reach a final valid configuration. An illustrative example is presented to evaluate the approach. The complexity of IRatePL2C is polynomial which an important advantage compared with previous works.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17868",
        "abstract url": "https://arxiv.org/abs/2404.17868",
        "title": "Error analysis for finite element operator learning methods for solving parametric second-order elliptic PDEs",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we provide a theoretical analysis of a type of operator learning method without data reliance based on the classical finite element approximation, which is called the finite element operator network (FEONet). We first establish the convergence of this method for general second-order linear elliptic PDEs with respect to the parameters for neural network approximation. In this regard, we address the role of the condition number of the finite element matrix in the convergence of the method. Secondly, we derive an explicit error estimate for the self-adjoint case. For this, we investigate some regularity properties of the solution in certain function classes for a neural network approximation, verifying the sufficient condition for the solution to have the desired regularity. Finally, we will also conduct some numerical experiments that support the theoretical findings, confirming the role of the condition number of the finite element matrix in the overall convergence.",
        "subjects": [
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17871",
        "abstract url": "https://arxiv.org/abs/2404.17871",
        "title": "A Survey of Deep Learning Library Testing Methods",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, software systems powered by deep learning (DL) techniques have significantly facilitated people's lives in many aspects. As the backbone of these DL systems, various DL libraries undertake the underlying optimization and computation. However, like traditional software, DL libraries are not immune to bugs, which can pose serious threats to users' personal property and safety. Studying the characteristics of DL libraries, their associated bugs, and the corresponding testing methods is crucial for enhancing the security of DL systems and advancing the widespread application of DL technology. This paper provides an overview of the testing research related to various DL libraries, discusses the strengths and weaknesses of existing methods, and provides guidance and reference for the application of the DL library. This paper first introduces the workflow of DL underlying libraries and the characteristics of three kinds of DL libraries involved, namely DL framework, DL compiler, and DL hardware library. It then provides definitions for DL underlying library bugs and testing. Additionally, this paper summarizes the existing testing methods and tools tailored to these DL libraries separately and analyzes their effectiveness and limitations. It also discusses the existing challenges of DL library testing and outlines potential directions for future research.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "34 pages, 8 figures, 4 tables"
    },
    {
        "paper id": "2404.17896",
        "abstract url": "https://arxiv.org/abs/2404.17896",
        "title": "How the Training Procedure Impacts the Performance of Deep Learning-based Vulnerability Patching",
        "rating": "-10",
        "keywords": [],
        "abstract": "Generative deep learning (DL) models have been successfully adopted for vulnerability patching. However, such models require the availability of a large dataset of patches to learn from. To overcome this issue, researchers have proposed to start from models pre-trained with general knowledge, either on the programming language or on similar tasks such as bug fixing. Despite the efforts in the area of automated vulnerability patching, there is a lack of systematic studies on how these different training procedures impact the performance of DL models for such a task. This paper provides a manyfold contribution to bridge this gap, by (i) comparing existing solutions of self-supervised and supervised pre-training for vulnerability patching; and (ii) for the first time, experimenting with different kinds of prompt-tuning for this task. The study required to train/test 23 DL models. We found that a supervised pre-training focused on bug-fixing, while expensive in terms of data collection, substantially improves DL-based vulnerability patching. When applying prompt-tuning on top of this supervised pre-trained model, there is no significant gain in performance. Instead, prompt-tuning is an effective and cheap solution to substantially boost the performance of self-supervised pre-trained models, i.e., those not relying on the bug-fixing pre-training.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17901",
        "abstract url": "https://arxiv.org/abs/2404.17901",
        "title": "The Theory and Practice of Deductive Verification of OCaml Programs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Despite all the tremendous recent success of deductive verification, it is rarely the case that verification tools are applied to programs written in functional languages. When compared to the imperative world, there are only a handful of verification tools that can deal with functional programs. We believe the lack of pedagogical, problem-oriented documentation on how to use such tools might be one of the reasons behind this apparent mismatch between deductive verification and real-world functional software. In this paper, our goal is to drift away from this tendency. We chose the OCaml language as our working environment and provide a comprehensive, hands-on tutorial on how to apply different verification tools to OCaml-written programs. Our presentation takes an incremental approach: we first focus on purely functional programs; then on imperative programs, yet avoid pointers; finally, we use Separation Logic to reason about pointer-manipulating programs.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17933",
        "abstract url": "https://arxiv.org/abs/2404.17933",
        "title": "Stability for binary scalar products",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bohn, Faenza, Fiorini, Fisikopoulos, Macchia, and Pashkovich (2015) conjectured that 2-level polytopes cannot simultaneously have many vertices and many facets, namely, that the maximum of the product of the number of vertices and facets is attained on the cube and cross-polytope. This was proved in a recent work by Kupavskii and Weltge. In this paper, we resolve a strong version of the conjecture by Bohn et al., and find the maximum possible product of the number of vertices and the number of facets in a 2-level polytope that is not affinely isomorphic to the cube or the cross-polytope. To do this, we get a sharp stability result of Kupavskii and Weltge's upper bound on $\\left|\\mathcal A\\right|\\cdot\\left|\\mathcal B\\right|$ for $\\mathcal A,\\mathcal B \\subseteq \\mathbb R^d$ with a property that $\\forall a \\in \\mathcal A, b \\in \\mathcal B$ the scalar product $\\langle a, b\\rangle \\in\\{0,1\\}$.",
        "subjects": [
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17944",
        "abstract url": "https://arxiv.org/abs/2404.17944",
        "title": "Mobile Edge Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mobile Edge Computing (MEC) has emerged as a solution to the high latency and suboptimal Quality of Experience (QoE) associated with Mobile Cloud Computing (MCC). By processing data near the source, MEC reduces the need to send information to distant data centers, resulting in faster response times and lower latency. This paper explores the differences between MEC and traditional cloud computing, emphasizing architecture, data flow, and resource allocation. Key technologies like Network Function Virtualization (NFV) and Software-Defined Networking (SDN) are discussed for their role in achieving scalability and flexibility. Additionally, security and privacy challenges are addressed, underscoring the need for robust frameworks. We conclude with an examination of various edge computing applications and suggest future research directions to enhance the effectiveness and adoption of MEC in the evolving technological landscape.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "13 pages, 5 figures"
    },
    {
        "paper id": "2404.17946",
        "abstract url": "https://arxiv.org/abs/2404.17946",
        "title": "Geometric Characteristic in Phaseless Operator and Structured Matrix Recovery",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we first propose a simple and unified approach to stability of phaseless operator to both amplitude and intensity measurement, both complex and real cases on arbitrary geometric set, thus characterizing the robust performance of phase retrieval via empirical minimization method. The unified analysis involves the random embedding of concave lifting operator on tangent space. Similarly, we investigate structured matrix recovery problem through the robust injectivity of linear rank one measurement operator on arbitrary matrix set. The core of our analysis lies in bounding the empirical chaos process. We introduce Talagrand's $\u03b3_\u03b1$ functionals to characterize the relationship between the required number of measurements and the geometric constraints. Additionally, adversarial noise is generated to illustrate the recovery bounds are sharp in the above situations.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17955",
        "abstract url": "https://arxiv.org/abs/2404.17955",
        "title": "A Survey of Third-Party Library Security Research in Application Software",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the current software development environment, third-party libraries play a crucial role. They provide developers with rich functionality and convenient solutions, speeding up the pace and efficiency of software development. However, with the widespread use of third-party libraries, associated security risks and potential vulnerabilities are increasingly apparent. Malicious attackers can exploit these vulnerabilities to infiltrate systems, execute unauthorized operations, or steal sensitive information, posing a severe threat to software security. Research on third-party libraries in software becomes paramount to address this growing security challenge. Numerous research findings exist regarding third-party libraries' usage, ecosystem, detection, and fortification defenses. Understanding the usage and ecosystem of third-party libraries helps developers comprehend the potential risks they bring and select trustworthy libraries. Third-party library detection tools aid developers in automatically discovering third-party libraries in software, facilitating their management. In addition to detection, fortification defenses are also indispensable. This article profoundly investigates and analyzes this literature, summarizing current research achievements and future development directions. It aims to provide practical and valuable insights for developers and researchers, jointly promoting the healthy development of software ecosystems and better-protecting software from security threats.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "21 pages, 3 figures, one table"
    },
    {
        "paper id": "2404.17964",
        "abstract url": "https://arxiv.org/abs/2404.17964",
        "title": "Automating Zero-Shot Patch Porting for Hard Forks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Forking is a typical way of code reuse, which provides a simple way for developers to create a variant software (denoted as hard fork) by copying and modifying an existing codebase. Despite of the benefits, forking also leads to duplicate efforts in software maintenance. Developers need to port patches across the hard forks to address similar bugs or implement similar features. Due to the divergence between the source project and the hard fork, patch porting is complicated, which requires an adaption regarding different implementations of the same functionality. In this work, we take the first step to automate patch porting for hard forks under a zero-shot setting. We first conduct an empirical study of the patches ported from Vim to Neovim over the last ten years to investigate the necessities of patch porting and the potential flaws in the current practice. We then propose a large language model (LLM) based approach (namely PPatHF) to automatically port patches for hard forks on a function-wise basis. Specifically, PPatHF is composed of a reduction module and a porting module. Given the pre- and post-patch versions of a function from the reference project and the corresponding function from the target project, the reduction module first slims the input functions by removing code snippets less relevant to the patch. Then, the porting module leverages a LLM to apply the patch to the function from the target project. We evaluate PPatHF on 310 Neovim patches ported from Vim. The experimental results show that PPatHF outperforms the baselines significantly. Specifically, PPatHF can correctly port 131 (42.3%) patches and automate 57% of the manual edits required for the developer to port the patch.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by ISSTA 2024"
    },
    {
        "paper id": "2404.17966",
        "abstract url": "https://arxiv.org/abs/2404.17966",
        "title": "Maximizing Patch Coverage for Testing of Highly-Configurable Software without Exploding Build Times",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Linux kernel is highly-configurable, with a build system that takes a configuration file as input and automatically tailors the source code accordingly. Configurability, however, complicates testing, because different configuration options lead to the inclusion of different code fragments. With thousands of patches received per month, Linux kernel maintainers employ extensive automated continuous integration testing. To attempt patch coverage, i.e., taking all changed lines into account, current approaches either use configuration files that maximize total statement coverage or use multiple randomly-generated configuration files, both of which incur high build times without guaranteeing patch coverage. To achieve patch coverage without exploding build times, we propose krepair, which automatically repairs configuration files that are fast-building but have poor patch coverage to achieve high patch coverage with little effect on build times. krepair works by discovering a small set of changes to a configuration file that will ensure patch coverage, preserving most of the original configuration file's settings. Our evaluation shows that, when applied to configuration files with poor patch coverage on a statistically-significant sample of recent Linux kernel patches, krepair achieves nearly complete patch coverage, 98.5% on average, while changing less than 1.53% of the original default configuration file in 99% of patches, which keeps build times 10.5x faster than maximal configuration files.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.17969",
        "abstract url": "https://arxiv.org/abs/2404.17969",
        "title": "From the Lyndon factorization to the Canonical Inverse Lyndon factorization: back and forth",
        "rating": "-10",
        "keywords": [],
        "abstract": "The notion of inverse Lyndon word is related to the classical notion of Lyndon word. More precisely, inverse Lyndon words are all and only the nonempty prefixes of the powers of the anti-Lyndon words, where an anti-Lyndon word with respect to a lexicographical order is a classical Lyndon word with respect to the inverse lexicographic order. Each word $w$ admits a factorization in inverse Lyndon words, named the canonical inverse Lyndon factorization $\\ICFL(w)$, which maintains the main properties of the Lyndon factorization of $w$. Although there is a huge literature on the Lyndon factorization, the relation between the Lyndon factorization $\\CFL_{in}$ with respect to the inverse order and the canonical inverse Lyndon factorization $\\ICFL$ has not been thoroughly investigated. In this paper, we address this question and we show how to obtain one factorization from the other via the notion of grouping. This result naturally opens new insights in the investigation of the relationship between $\\ICFL$ and other notions, e.g., variants of Burrows Wheeler Transform, as already done for the Lyndon factorization.",
        "subjects": [
            "math.CO"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:1911.01851"
    },
    {
        "paper id": "2404.17980",
        "abstract url": "https://arxiv.org/abs/2404.17980",
        "title": "ALock: Asymmetric Lock Primitive for RDMA Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Remote direct memory access (RDMA) networks are being rapidly adopted into industry for their high speed, low latency, and reduced CPU overheads compared to traditional kernel-based TCP/IP networks. RDMA enables threads to access remote memory without interacting with another process. However, atomicity between local accesses and remote accesses is not guaranteed by the technology, hence complicating synchronization significantly. The current solution is to require threads wanting to access local memory in an RDMA-accessible region to pass through the RDMA card using a mechanism known as loopback, but this can quickly degrade performance. In this paper, we introduce ALock, a novel locking primitive designed for RDMA-based systems. ALock allows programmers to synchronize local and remote accesses without using loopback or remote procedure calls (RPCs). We draw inspiration from the classic Peterson's algorithm to create a hierarchical design that includes embedded MCS locks for two cohorts, remote and local. To evaluate the ALock we implement a distributed lock table, measuring throughput and latency in various cluster configurations and workloads. In workloads with a majority of local operations, the ALock outperforms competitors up to 29x and achieves a latency up to 20x faster.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "13 pages, 6 figures, SPAA '24"
    },
    {
        "paper id": "2404.17996",
        "abstract url": "https://arxiv.org/abs/2404.17996",
        "title": "Varia\u00e7\u00f5es do Problema de Dist\u00e2ncia de Rearranjos",
        "rating": "-10",
        "keywords": [],
        "abstract": "Considering a pair of genomes, the goal of rearrangement distance problems is to estimate how distant these genomes are from each other based on genome rearrangements. Seminal works in genome rearrangements assumed that both genomes being compared have the same set of genes (balanced genomes) and, furthermore, only the relative order of genes and their orientations, when they are known, are used in the mathematical representation of the genomes. In this case, the genomes are represented as permutations, originating the Sorting Permutations by Rearrangements problems. The main problems of Sorting Permutations by Rearrangements considered DCJs, reversals, transpositions, or the combination of both reversals and transpositions, and these problems have their complexity known. Besides these problems, other ones were studied involving the combination of transpositions with one or more of the following rearrangements: transreversals, revrevs, and reversals. Although there are approximation results for these problems, their complexity remained open. Some of the results of this thesis are the complexity proofs for these problems. Furthermore, we present a new 1.375-approximation algorithm, which has better time complexity, for the Sorting Permutations by Transpositions. When considering unbalanced genomes, it is necessary to use insertions and deletions to transform one genome into another. In this thesis, we studied Rearrangement Distance problems on unbalanced genomes considering only gene order and their orientations (when they are known), as well as Intergenic Rearrangement Distance problems, which incorporate the information regarding the size distribution of intergenic regions, besides the use of gene order and their orientations (when they are known). We present complexity proofs and approximation algorithms for problems that include reversals and transpositions.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "PhD Dissertation, in Portuguese, presented at the Institute of Computing - Unicamp in March 2024"
    },
    {
        "paper id": "2404.18001",
        "abstract url": "https://arxiv.org/abs/2404.18001",
        "title": "LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18007",
        "abstract url": "https://arxiv.org/abs/2404.18007",
        "title": "A Formal Model to Prove Instantiation Termination for E-matching-Based Axiomatisations (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "SMT-based program analysis and verification often involve reasoning about program features that have been specified using quantifiers; incorporating quantifiers into SMT-based reasoning is, however, known to be challenging. If quantifier instantiation is not carefully controlled, then runtime and outcomes can be brittle and hard to predict. In particular, uncontrolled quantifier instantiation can lead to unexpected incompleteness and even non-termination. E-matching is the most widely-used approach for controlling quantifier instantiation, but when axiomatisations are complex, even experts cannot tell if their use of E-matching guarantees completeness or termination. This paper presents a new formal model that facilitates the proof, once and for all, that giving a complex E-matching-based axiomatisation to an SMT solver, such as Z3 or cvc5, will not cause non-termination. Key to our technique is an operational semantics for solver behaviour that models how the E-matching rules common to most solvers are used to determine when quantifier instantiations are enabled, but abstracts over irrelevant details of individual solvers. We demonstrate the effectiveness of our technique by presenting a termination proof for a set theory axiomatisation adapted from those used in the Dafny and Viper verifiers.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "extended version of IJCAR 2024 publication"
    },
    {
        "paper id": "2404.18013",
        "abstract url": "https://arxiv.org/abs/2404.18013",
        "title": "Impact of Dynamic Operating Envelopes on Distribution Network Hosting Capacity for Electric Vehicles",
        "rating": "-10",
        "keywords": [],
        "abstract": "The examination of the maximum number of electric vehicles (EVs) that can be integrated into the distribution network (DN) without causing any operational incidents has become increasingly crucial as EV penetration rises. This issue can be addressed by utilizing dynamic operating envelopes (DOEs), which are generated based on the grid status. While DOEs improve the hosting capacity of the DN for EVs (EV-HC) by restricting the operational parameters of the network, they also alter the amount of energy needed for charging each EV, resulting in a decrease in the quality of service (QoS). This study proposes a network-aware hosting capacity framework for EVs (EV-NAHC) that i) aims to assess the effects of DOEs on active distribution networks, ii) introduces a novel definition for HC and calculates the EV-NAHC based on the aggregated QoS of all customers. A small-scale Belgian feeder is utilized to examine the proposed framework. The results show a substantial increase in the EV-NAHC with low, medium, and high-daily charging energy scenarios.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18017",
        "abstract url": "https://arxiv.org/abs/2404.18017",
        "title": "Application of Deep Learning for Factor Timing in Asset Management",
        "rating": "-10",
        "keywords": [],
        "abstract": "The paper examines the performance of regression models (OLS linear regression, Ridge regression, Random Forest, and Fully-connected Neural Network) on the prediction of CMA (Conservative Minus Aggressive) factor premium and the performance of factor timing investment with them. Out-of-sample R-squared shows that more flexible models have better performance in explaining the variance in factor premium of the unseen period, and the back testing affirms that the factor timing based on more flexible models tends to over perform the ones with linear models. However, for flexible models like neural networks, the optimal weights based on their prediction tend to be unstable, which can lead to high transaction costs and market impacts. We verify that tilting down the rebalance frequency according to the historical optimal rebalancing scheme can help reduce the transaction costs.",
        "subjects": [
            "q-fin.PM"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18023",
        "abstract url": "https://arxiv.org/abs/2404.18023",
        "title": "Tasking framework for Adaptive Speculative Parallel Mesh Generation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Handling the ever-increasing complexity of mesh generation codes along with the intricacies of newer hardware often results in codes that are both difficult to comprehend and maintain. Different facets of codes such as thread management and load balancing are often intertwined, resulting in efficient but highly complex software. In this work, we present a framework which aids in establishing a core principle, deemed separation of concerns, where functionality is separated from performance aspects of various mesh operations. In particular, thread management and scheduling decisions are elevated into a generic and reusable tasking framework. The results indicate that our approach can successfully abstract the load balancing aspects of two case studies, while providing access to a plethora of different execution back-ends. One would expect, this new flexibility to lead to some additional cost. However, for the configurations studied in this work, we observed up to 13% speedup for some meshing operations and up to 5.8% speedup over the entire application runtime compared to hand-optimized code. Moreover, we show that by using different task creation strategies, the overhead compared to straight-forward task execution models can be improved dramatically by as much as 1200% without compromises in portability and functionality.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18030",
        "abstract url": "https://arxiv.org/abs/2404.18030",
        "title": "Parallel Adaptive Anisotropic Meshing on cc-NUMA Machines",
        "rating": "-10",
        "keywords": [],
        "abstract": "Efficient and robust anisotropic mesh adaptation is crucial for Computational Fluid Dynamics (CFD) simulations. The CFD Vision 2030 Study highlights the pressing need for this technology, particularly for simulations targeting supercomputers. This work applies a fine-grained speculative approach to anisotropic mesh operations. Our implementation exhibits more than 90% parallel efficiency on a multi-core node. Additionally, we evaluate our method within an adaptive pipeline for a spectrum of publicly available test-cases that includes both analytically derived and error-based fields. For all test-cases, our results are in accordance with published results in the literature. Support for CAD-based data is introduced, and its effectiveness is demonstrated on one of NASA's High-Lift prediction workshop cases.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18032",
        "abstract url": "https://arxiv.org/abs/2404.18032",
        "title": "Study of Clustering Techniques and Scheduling Algorithms with Fairness for Cell-Free MIMO Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we propose a clustering technique based on information rates for cell-free massive multiple-input multiple-output (MIMO) networks. Unlike existing clustering approaches that rely on the large scale fading coefficients of the channels and user-centric techniques, we develop an approach that is based on the information rates of cell-free massive MIMO networks. We also devise a resource allocation technique to incorporate the proposed clustering and schedule users with fairness. An analysis of the proposed clustering approach based on information rates is carried out along with an assessment of its benefits for scheduling. Numerical results show that the proposed techniques outperform existing approaches.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2404.18046",
        "abstract url": "https://arxiv.org/abs/2404.18046",
        "title": "Fast Beam Training and Performance Analysis for Extremely Large Aperture Array",
        "rating": "-10",
        "keywords": [],
        "abstract": "Extremely large aperture array (ELAA) can significantly enhance beamforming gain and spectral efficiency. Unfortunately, the use of narrower beams for data transmission results in a substantial increase in the cost of beam training. In this paper, we study a high-efficiency and low-overhead scheme named hash beam training. Specifically, two improved hash codebook design methods, random and fixed, are proposed. Moreover, we analyze beam alignment performance. Since the derived beam alignment success probability is a complex function, we also propose a heuristic metric to evaluate the impact of codebook parameter on performance. Finally, simulation results validate the theoretical analysis, indicating that the proposed beam training scheme can achieve fast beam alignment with lower overhead and higher accuracy.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2404.18053",
        "abstract url": "https://arxiv.org/abs/2404.18053",
        "title": "Binary duadic codes and their related codes with a square-root-like lower bound",
        "rating": "-10",
        "keywords": [],
        "abstract": "Binary cyclic codes have been a hot topic for many years, and significant progress has been made in the study of this types of codes. As is well known, it is hard to construct infinite families of binary cyclic codes [n, n+1/2] with good minimum distance. In this paper, by using the BCH bound on cyclic codes, one of the open problems proposed by Liu et al. about binary cyclic codes (Finite Field Appl 91:102270, 2023) is settled. Specially, we present several families of binary duadic codes with length 2^m-1 and dimension 2^(m-1), and the minimum distances have a square-root-like lower bound. As a by-product, the parameters of their dual codes and extended codes are provided, where the latter are self-dual and doubly-even.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2404.18066",
        "abstract url": "https://arxiv.org/abs/2404.18066",
        "title": "Quantized Context Based LIF Neurons for Recurrent Spiking Neural Networks in 45nm",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this study, we propose the first hardware implementation of a context-based recurrent spiking neural network (RSNN) emphasizing on integrating dual information streams within the neocortical pyramidal neurons specifically Context- Dependent Leaky Integrate and Fire (CLIF) neuron models, essential element in RSNN. We present a quantized version of the CLIF neuron (qCLIF), developed through a hardware-software codesign approach utilizing the sparse activity of RSNN. Implemented in a 45nm technology node, the qCLIF is compact (900um^2) and achieves a high accuracy of 90% despite 8 bit quantization on DVS gesture classification dataset. Our analysis spans a network configuration from 10 to 200 qCLIF neurons, supporting up to 82k synapses within a 1.86 mm^2 footprint, demonstrating scalability and efficiency",
        "subjects": [
            "cs.NE"
        ],
        "comment": "7 Pages, 7 Figures, 2 Tables"
    },
    {
        "paper id": "2404.18067",
        "abstract url": "https://arxiv.org/abs/2404.18067",
        "title": "Type Inference for Isabelle2Cpp",
        "rating": "-10",
        "keywords": [],
        "abstract": "Isabelle2Cpp is a code generation framework that supports automatic generation of C++ code from Isabelle/HOL specifications. However, if some type information of Isabelle/HOL specification is missing, Isabelle2Cpp may not complete the code generation automatically. In order to solve this problem, this paper provides a type system for Isabelle2Cpp, which is used to perform type inference and type unification for expressions of the intermediate representation in Isabelle2Cpp. The system introduces new type inference rules and unification algorithms to enhance the Isabelle2Cpp framework. By incorporating the type system, the Isabelle2Cpp framework can provide more comprehensive type information for expression generation, which leads to more complete and accurate C++ code.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "22 pages, 4 figures"
    },
    {
        "paper id": "2404.18953",
        "abstract url": "https://arxiv.org/abs/2404.18953",
        "title": "A Knowledge-driven Memetic Algorithm for the Energy-efficient Distributed Homogeneous Flow Shop Scheduling Problem",
        "rating": "-10",
        "keywords": [],
        "abstract": "The reduction of carbon emissions in the manufacturing industry holds significant importance in achieving the national \"double carbon\" target. Ensuring energy efficiency is a crucial factor to be incorporated into future generation manufacturing systems. In this study, energy consumption is considered in the distributed homogeneous flow shop scheduling problem (DHFSSP). A knowledge-driven memetic algorithm (KDMA) is proposed to address the energy-efficient DHFSSP (EEDHFSSP). KDMA incorporates a collaborative initialization strategy to generate high-quality initial populations. Furthermore, several algorithmic improvements including update strategy, local search strategy, and carbon reduction strategy are employed to improve the search performance of the algorithm. The effectiveness of KDMA in solving EEDHFSSP is verified through extensive simulation experiments. It is evident that KDMA outperforms many state-of-the-art algorithms across various evaluation aspects.",
        "subjects": [
            "math.OC"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2405.00065",
        "abstract url": "https://arxiv.org/abs/2405.00065",
        "title": "From Linear to Linearizable Optimization: A Novel Framework with Applications to Stationary and Non-stationary DR-submodular Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces the notion of upper linearizable/quadratizable functions, a class that extends concavity and DR-submodularity in various settings, including monotone and non-monotone cases over different convex sets. A general meta-algorithm is devised to convert algorithms for linear/quadratic maximization into ones that optimize upper quadratizable functions, offering a unified approach to tackling concave and DR-submodular optimization problems. The paper extends these results to multiple feedback settings, facilitating conversions between semi-bandit/first-order feedback and bandit/zeroth-order feedback, as well as between first/zeroth-order feedback and semi-bandit/bandit feedback. Leveraging this framework, new projection-free algorithms are derived using Follow The Perturbed Leader (FTPL) and other algorithms as base algorithms for linear/convex optimization, improving upon state-of-the-art results in various cases. Dynamic and adaptive regret guarantees are obtained for DR-submodular maximization, marking the first algorithms to achieve such guarantees in these settings. Notably, the paper achieves these advancements with fewer assumptions compared to existing state-of-the-art results, underscoring its broad applicability and theoretical contributions to non-convex optimization.",
        "subjects": [
            "math.OC"
        ],
        "comment": null
    }
]