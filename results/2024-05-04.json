[
    {
        "paper id": "2405.02596",
        "abstract url": "https://arxiv.org/abs/2405.02596",
        "title": "Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning",
        "rating": "2.5",
        "keywords": [
            [
                "Parameter Efficient",
                "PEFT",
                "Efficient Fine-tuning"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Fine-tuning large language models (LLM) can be costly. Parameter-efficient fine-tuning (PEFT) addresses the problems by training a fraction of the parameters, whose success reveals the expressiveness and flexibility of pretrained models. This paper studies the limit of PEFT, by further simplifying its design and reducing the number of trainable parameters beyond standard setups. To this end, we use Random Masking to fine-tune the pretrained model. Despite its simplicity, we show that Random Masking is surprisingly effective: with a larger-than-expected learning rate, Random Masking can match the performance of standard PEFT algorithms such as LoRA on various tasks, using fewer trainable parameters. We provide both empirical and theoretical explorations into the success of Random Masking. We show that masking induces a flatter loss landscape and more distant solutions, which allows for and necessitates large learning rates.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2405.02586",
        "abstract url": "https://arxiv.org/abs/2405.02586",
        "title": "Generalizing CLIP to Unseen Domain via Text-Guided Diverse Novel Feature Synthesis",
        "rating": "2",
        "keywords": [
            [
                "Vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-language foundation models like CLIP have shown impressive zero-shot generalization, but finetuning on downstream datasets can cause overfitting and loss of its generalization ability on unseen domains. Although collecting additional data from new domains of interest is possible, this method is often impractical due to the challenges in obtaining annotated data. To address this, we propose a plug-and-play feature augmentation method called LDFS (Language-Guided Diverse Feature Synthesis) to synthesize new domain features and improve existing CLIP fine-tuning strategies. LDFS has three main contributions: 1) To synthesize novel domain features and promote diversity, we propose an instance-conditional feature augmentation strategy based on a textguided feature augmentation loss. 2) To maintain feature quality after augmenting, we introduce a pairwise regularizer to preserve augmented feature coherence within the CLIP feature space. 3) We propose to use stochastic text feature augmentation to reduce the modality gap and further facilitate the process of text-guided feature synthesis. Extensive experiments show LDFS superiority in improving CLIP generalization ability on unseen domains without collecting data from those domains. The code will be made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2405.02710",
        "abstract url": "https://arxiv.org/abs/2405.02710",
        "title": "Enhancing News Summarization with ELearnFit through Efficient In-Context Learning and Efficient Fine-Tuning",
        "rating": "2",
        "keywords": [
            [
                "Parameter Efficient",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the deluge of information delivered by the daily news cycle, there is a growing need to effectively and efficiently summarize news feeds for quick consumption. We leverage large language models (LLMs), with their advanced learning and generative abilities as compared to conventional language models, to generate concise and coherent summaries for news articles from the XSum dataset. Our paper focuses on two key aspects of LLMs: Efficient in-context Learning (ELearn) and Parameter Efficient Fine-tuning (EFit). Under ELearn, we find that increasing the number of shots in prompts and utilizing simple templates generally improve the quality of summaries. We also find that utilizing relevant examples in few-shot learning for ELearn does not improve model performance. In addition, we studied EFit using different methods and demonstrate that fine-tuning the first layer of LLMs produces better outcomes as compared to fine-tuning other layers or utilizing LoRA. We also find that leveraging more relevant training samples using selective layers does not result in better performance. By combining ELearn and EFit, we create a new model (ELearnFit) that leverages the benefits of both few-shot learning and fine-tuning and produces superior performance to either model alone. We also use ELearnFit to highlight the trade-offs between prompting and fine-tuning, especially for situations where only a limited number of annotated samples are available. Ultimately, our research provides practical techniques to optimize news summarization during the prompting and fine-tuning stages and enhances the synthesis of news articles.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 Pages"
    },
    {
        "paper id": "2405.02581",
        "abstract url": "https://arxiv.org/abs/2405.02581",
        "title": "Stationary Representations: Optimally Approximating Compatibility and Implications for Improved Model Replacements",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Learning compatible representations enables the interchangeable use of semantic features as models are updated over time. This is particularly relevant in search and retrieval systems where it is crucial to avoid reprocessing of the gallery images with the updated model. While recent research has shown promising empirical evidence, there is still a lack of comprehensive theoretical understanding about learning compatible representations. In this paper, we demonstrate that the stationary representations learned by the $d$-Simplex fixed classifier optimally approximate compatibility representation according to the two inequality constraints of its formal definition. This not only establishes a solid foundation for future works in this line of research but also presents implications that can be exploited in practical learning scenarios. An exemplary application is the now-standard practice of downloading and fine-tuning new pre-trained models. Specifically, we show the strengths and critical issues of stationary representations in the case in which a model undergoing sequential fine-tuning is asynchronously replaced by downloading a better-performing model pre-trained elsewhere. Such a representation enables seamless delivery of retrieval service (i.e., no reprocessing of gallery images) and offers improved performance without operational disruptions during model replacement. Code available at: https://github.com/miccunifi/iamcl2r.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at CVPR24 as Poster Highlight"
    },
    {
        "paper id": "2405.02608",
        "abstract url": "https://arxiv.org/abs/2405.02608",
        "title": "UnSAMFlow: Unsupervised Optical Flow Guided by Segment Anything Model",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Traditional unsupervised optical flow methods are vulnerable to occlusions and motion boundaries due to lack of object-level information. Therefore, we propose UnSAMFlow, an unsupervised flow network that also leverages object information from the latest foundation model Segment Anything Model (SAM). We first include a self-supervised semantic augmentation module tailored to SAM masks. We also analyze the poor gradient landscapes of traditional smoothness losses and propose a new smoothness definition based on homography instead. A simple yet effective mask feature module has also been added to further aggregate features on the object level. With all these adaptations, our method produces clear optical flow estimation with sharp boundaries around objects, which outperforms state-of-the-art methods on both KITTI and Sintel datasets. Our method also generalizes well across domains and runs very efficiently.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Accepted by CVPR 2024. Code is available at https://github.com/facebookresearch/UnSAMFlow"
    },
    {
        "paper id": "2405.02774",
        "abstract url": "https://arxiv.org/abs/2405.02774",
        "title": "Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "This work focuses on leveraging and selecting from vast, unlabeled, open data to pre-fine-tune a pre-trained language model. The goal is to minimize the need for costly domain-specific data for subsequent fine-tuning while achieving desired performance levels. While many data selection algorithms have been designed for small-scale applications, rendering them unsuitable for our context, some emerging methods do cater to language data scales. However, they often prioritize data that aligns with the target distribution. While this strategy may be effective when training a model from scratch, it can yield limited results when the model has already been pre-trained on a different distribution. Differing from prior work, our key idea is to select data that nudges the pre-training distribution closer to the target distribution. We show the optimality of this approach for fine-tuning tasks under certain conditions. We demonstrate the efficacy of our methodology across a diverse array of tasks (NLU, NLG, zero-shot) with models up to 2.7B, showing that it consistently surpasses other selection methods. Moreover, our proposed method is significantly faster than existing techniques, scaling to millions of samples within a single GPU hour. Our code is open-sourced (Code repository: https://anonymous.4open.science/r/DV4LLM-D761/ ). While fine-tuning offers significant potential for enhancing performance across diverse tasks, its associated costs often limit its widespread adoption; with this work, we hope to lay the groundwork for cost-effective fine-tuning, making its benefits more accessible.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Published as a conference paper at ICLR 2024"
    },
    {
        "paper id": "2405.02797",
        "abstract url": "https://arxiv.org/abs/2405.02797",
        "title": "Adapting to Distribution Shift by Visual Domain Prompt Generation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "In this paper, we aim to adapt a model at test-time using a few unlabeled data to address distribution shifts. To tackle the challenges of extracting domain knowledge from a limited amount of data, it is crucial to utilize correlated information from pre-trained backbones and source domains. Previous studies fail to utilize recent foundation models with strong out-of-distribution generalization. Additionally, domain-centric designs are not flavored in their works. Furthermore, they employ the process of modelling source domains and the process of learning to adapt independently into disjoint training stages. In this work, we propose an approach on top of the pre-computed features of the foundation model. Specifically, we build a knowledge bank to learn the transferable knowledge from source domains. Conditioned on few-shot target data, we introduce a domain prompt generator to condense the knowledge bank into a domain-specific prompt. The domain prompt then directs the visual features towards a particular domain via a guidance module. Moreover, we propose a domain-aware contrastive loss and employ meta-learning to facilitate domain knowledge extraction. Extensive experiments are conducted to validate the domain knowledge extraction. The proposed method outperforms previous work on 5 large-scale benchmarks including WILDS and DomainNet.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "ICLR2024, code: https://github.com/Guliisgreat/VDPG"
    },
    {
        "paper id": "2405.02573",
        "abstract url": "https://arxiv.org/abs/2405.02573",
        "title": "A Combination of BERT and Transformer for Vietnamese Spelling Correction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recently, many studies have shown the efficiency of using Bidirectional Encoder Representations from Transformers (BERT) in various Natural Language Processing (NLP) tasks. Specifically, English spelling correction task that uses Encoder-Decoder architecture and takes advantage of BERT has achieved state-of-the-art result. However, to our knowledge, there is no implementation in Vietnamese yet. Therefore, in this study, a combination of Transformer architecture (state-of-the-art for Encoder-Decoder model) and BERT was proposed to deal with Vietnamese spelling correction. The experiment results have shown that our model outperforms other approaches as well as the Google Docs Spell Checking tool, achieves an 86.24 BLEU score on this task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2405.02578",
        "abstract url": "https://arxiv.org/abs/2405.02578",
        "title": "Mixat: A Data Set of Bilingual Emirati-English Speech",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces Mixat: a dataset of Emirati speech code-mixed with English. Mixat was developed to address the shortcomings of current speech recognition resources when applied to Emirati speech, and in particular, to bilignual Emirati speakers who often mix and switch between their local dialect and English. The data set consists of 15 hours of speech derived from two public podcasts featuring native Emirati speakers, one of which is in the form of conversations between the host and a guest. Therefore, the collection contains examples of Emirati-English code-switching in both formal and natural conversational contexts. In this paper, we describe the process of data collection and annotation, and describe some of the features and statistics of the resulting data set. In addition, we evaluate the performance of pre-trained Arabic and multi-lingual ASR systems on our dataset, demonstrating the shortcomings of existing models on this low-resource dialectal Arabic, and the additional challenge of recognizing code-switching in ASR. The dataset will be made publicly available for research use.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "SIGUL 2024"
    },
    {
        "paper id": "2405.02591",
        "abstract url": "https://arxiv.org/abs/2405.02591",
        "title": "Better YOLO with Attention-Augmented Network and Enhanced Generalization Performance for Safety Helmet Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Safety helmets play a crucial role in protecting workers from head injuries in construction sites, where potential hazards are prevalent. However, currently, there is no approach that can simultaneously achieve both model accuracy and performance in complex environments. In this study, we utilized a Yolo-based model for safety helmet detection, achieved a 2% improvement in mAP (mean Average Precision) performance while reducing parameters and Flops count by over 25%. YOLO(You Only Look Once) is a widely used, high-performance, lightweight model architecture that is well suited for complex environments. We presents a novel approach by incorporating a lightweight feature extraction network backbone based on GhostNetv2, integrating attention modules such as Spatial Channel-wise Attention Net(SCNet) and Coordination Attention Net(CANet), and adopting the Gradient Norm Aware optimizer (GAM) for improved generalization ability. In safety-critical environments, the accurate detection and speed of safety helmets plays a pivotal role in preventing occupational hazards and ensuring compliance with safety protocols. This work addresses the pressing need for robust and efficient helmet detection methods, offering a comprehensive framework that not only enhances accuracy but also improves the adaptability of detection models to real-world conditions. Our experimental results underscore the synergistic effects of GhostNetv2, attention modules, and the GAM optimizer, presenting a compelling solution for safety helmet detection that achieves superior performance in terms of accuracy, generalization, and efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02594",
        "abstract url": "https://arxiv.org/abs/2405.02594",
        "title": "Leveraging (Biased) Information: Multi-armed Bandits with Offline Data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "We leverage offline data to facilitate online learning in stochastic multi-armed bandits. The probability distributions that govern the offline data and the online rewards can be different. Without any non-trivial upper bound on their difference, we show that no non-anticipatory policy can outperform the UCB policy by (Auer et al. 2002), even in the presence of offline data. In complement, we propose an online policy MIN-UCB, which outperforms UCB when a non-trivial upper bound is given. MIN-UCB adaptively chooses to utilize the offline data when they are deemed informative, and to ignore them otherwise. MIN-UCB is shown to be tight in terms of both instance independent and dependent regret bounds. Finally, we corroborate the theoretical results with numerical experiments.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "24 pages, 5 figures. Accepted to ICML 2024"
    },
    {
        "paper id": "2405.02637",
        "abstract url": "https://arxiv.org/abs/2405.02637",
        "title": "TREC iKAT 2023: A Test Collection for Evaluating Conversational and Interactive Knowledge Assistants",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Conversational information seeking has evolved rapidly in the last few years with the development of Large Language Models (LLMs), providing the basis for interpreting and responding in a naturalistic manner to user requests. The extended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to enable researchers to test and evaluate their Conversational Search Agents (CSA). The collection contains a set of 36 personalized dialogues over 20 different topics each coupled with a Personal Text Knowledge Base (PTKB) that defines the bespoke user personas. A total of 344 turns with approximately 26,000 passages are provided as assessments on relevance, as well as additional assessments on generated responses over four key dimensions: relevance, completeness, groundedness, and naturalness. The collection challenges CSA to efficiently navigate diverse personal contexts, elicit pertinent persona information, and employ context for relevant conversations. The integration of a PTKB and the emphasis on decisional search tasks contribute to the uniqueness of this test collection, making it an essential benchmark for advancing research in conversational and interactive knowledge assistants.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "To appear in SIGIR 2024. arXiv admin note: substantial text overlap with arXiv:2401.01330"
    },
    {
        "paper id": "2405.02650",
        "abstract url": "https://arxiv.org/abs/2405.02650",
        "title": "Identifying Narrative Patterns and Outliers in Holocaust Testimonies Using Topic Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The vast collection of Holocaust survivor testimonies presents invaluable historical insights but poses challenges for manual analysis. This paper leverages advanced Natural Language Processing (NLP) techniques to explore the USC Shoah Foundation Holocaust testimony corpus. By treating testimonies as structured question-and-answer sections, we apply topic modeling to identify key themes. We experiment with BERTopic, which leverages recent advances in language modeling technology. We align testimony sections into fixed parts, revealing the evolution of topics across the corpus of testimonies. This highlights both a common narrative schema and divergences between subgroups based on age and gender. We introduce a novel method to identify testimonies within groups that exhibit atypical topic distributions resembling those of other groups. This study offers unique insights into the complex narratives of Holocaust survivors, demonstrating the power of NLP to illuminate historical discourse and identify potential deviations in survivor experiences.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "9 pages, 7 figures, LREC-COLING 2024"
    },
    {
        "paper id": "2405.02652",
        "abstract url": "https://arxiv.org/abs/2405.02652",
        "title": "Deep Pulse-Signal Magnification for remote Heart Rate Estimation in Compressed Videos",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in remote heart rate measurement (rPPG), motivated by data-driven approaches, have significantly improved accuracy. However, certain challenges, such as video compression, still remain: recovering the rPPG signal from highly compressed videos is particularly complex. Although several studies have highlighted the difficulties and impact of video compression for this, effective solutions remain limited. In this paper, we present a novel approach to address the impact of video compression on rPPG estimation, which leverages a pulse-signal magnification transformation to adapt compressed videos to an uncompressed data domain in which the rPPG signal is magnified. We validate the effectiveness of our model by exhaustive evaluations on two publicly available datasets, UCLA-rPPG and UBFC-rPPG, employing both intra- and cross-database performance at several compression rates. Additionally, we assess the robustness of our approach on two additional highly compressed and widely-used datasets, MAHNOB-HCI and COHFACE, which reveal outstanding heart rate estimation results.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02655",
        "abstract url": "https://arxiv.org/abs/2405.02655",
        "title": "Fast Online Movement Optimization of Aerial Base Stations Based on Global Connectivity Map",
        "rating": "1",
        "keywords": [
            [
                "time efficiency"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) can serve as aerial base stations (ABSs) to provide wireless connectivity for ground users (GUs) in diverse scenarios. However, it is an NP-hard problem with exponential complexity in $M$ and $N$, in order to maximize the coverage rate (CR) of $M$ GUs by jointly placing $N$ ABSs with limited coverage range. This problem becomes even more intricate when the coverage range becomes irregular due to site-specific obstructions (e.g., buildings) on the air-ground channel, and/or when the GUs are in motion. To address the above challenges, we study a multi-ABS movement optimization problem to maximize the average coverage rate of mobile GUs within a site-specific environment. We tackle this challenging problem by 1) constructing the global connectivity map (GCM) which contains the connectivity information between given pairs of ABS/GU locations; 2) partitioning the ABS movement problem into ABS placement sub-problems and formulate each sub-problem into a binary integer linear programing (BILP) problem based on GCM; 3) proposing a fast online algorithm to execute (one-pass) projected stochastic subgradient descent within the dual space to rapidly solve the BILP problem with near-optimal performance. Numerical results demonstrate that our proposed algorithm achieves a high CR performance close to that obtained by the open source solver (SCIP), yet with significantly reduced running time. In addition, the algorithm also notably outperforms one of the state-of-the-art deep reinforcement learning (DRL) methods and the K-means initiated evolutionary algorithm in terms of CR performance and/or time efficiency.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 6 figures. Investigate site-specific movement optimization of UAV-mounted aerial base stations to cover a group of moving ground users, based on site-specific Global Connectivity Map. arXiv admin note: text overlap with arXiv:2312.10490"
    },
    {
        "paper id": "2405.02673",
        "abstract url": "https://arxiv.org/abs/2405.02673",
        "title": "On the Information Redundancy in Non-Autoregressive Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Token repetition is a typical form of multi-modal problem in fully non-autoregressive translation (NAT). In this work, we revisit the multi-modal problem in recently proposed NAT models. Our study reveals that these advanced models have introduced other types of information redundancy errors, which cannot be measured by the conventional metric - the continuous repetition ratio. By manually annotating the NAT outputs, we identify two types of information redundancy errors that correspond well to lexical and reordering multi-modality problems. Since human annotation is time-consuming and labor-intensive, we propose automatic metrics to evaluate the two types of redundant errors. Our metrics allow future studies to evaluate new methods and gain a more comprehensive understanding of their effectiveness.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 10 tables"
    },
    {
        "paper id": "2405.02675",
        "abstract url": "https://arxiv.org/abs/2405.02675",
        "title": "Quranic Audio Dataset: Crowdsourced and Labeled Recitation from Non-Arabic Speakers",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper addresses the challenge of learning to recite the Quran for non-Arabic speakers. We explore the possibility of crowdsourcing a carefully annotated Quranic dataset, on top of which AI models can be built to simplify the learning process. In particular, we use the volunteer-based crowdsourcing genre and implement a crowdsourcing API to gather audio assets. We integrated the API into an existing mobile application called NamazApp to collect audio recitations. We developed a crowdsourcing platform called Quran Voice for annotating the gathered audio assets. As a result, we have collected around 7000 Quranic recitations from a pool of 1287 participants across more than 11 non-Arabic countries, and we have annotated 1166 recitations from the dataset in six categories. We have achieved a crowd accuracy of 0.77, an inter-rater agreement of 0.63 between the annotators, and 0.89 between the labels assigned by the algorithm and the expert judgments.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02677",
        "abstract url": "https://arxiv.org/abs/2405.02677",
        "title": "Evaluating the Ability of Computationally Extracted Narrative Maps to Encode Media Framing",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Narratives serve as fundamental frameworks in our understanding of the world and play a crucial role in collaborative sensemaking, providing a versatile foundation for sensemaking. Framing is a subtle yet potent mechanism that influences public perception through specific word choices, shaping interpretations of reported news events. Despite the recognized importance of narratives and framing, a significant gap exists in the literature with regard to the explicit consideration of framing within the context of computational extraction and representation. This article explores the capabilities of a specific narrative extraction and representation approach -- narrative maps -- to capture framing information from news data. The research addresses two key questions: (1) Does the narrative extraction method capture the framing distribution of the data set? (2) Does it produce a representation with consistent framing? Our results indicate that while the algorithm captures framing distributions, achieving consistent framing across various starting and ending events poses challenges. Our results highlight the potential of narrative maps to provide users with insights into the intricate framing dynamics within news narratives. However, we note that directly leveraging framing information in the computational narrative extraction process remains an open challenge.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "Text2Story Workshop 2024"
    },
    {
        "paper id": "2405.02700",
        "abstract url": "https://arxiv.org/abs/2405.02700",
        "title": "Towards a Scalable Identification of Novel Modes in Generative Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "An interpretable comparison of generative models requires the identification of sample types produced more frequently by each of the involved models. While several quantitative scores have been proposed in the literature to rank different generative models, such score-based evaluations do not reveal the nuanced differences between the generative models in capturing various sample types. In this work, we propose a method called Fourier-based Identification of Novel Clusters (FINC) to identify modes produced by a generative model with a higher frequency in comparison to a reference distribution. FINC provides a scalable stochastic algorithm based on random Fourier features to estimate the eigenspace of kernel covariance matrices of two generative models and utilize the principal eigendirections to detect the sample types present more dominantly in each model. We demonstrate the application of the FINC method to standard computer vision datasets and generative model frameworks. Our numerical results suggest the scalability and efficiency of the developed Fourier-based method in highlighting the sample types captured with different frequencies by widely-used generative models.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02714",
        "abstract url": "https://arxiv.org/abs/2405.02714",
        "title": "Beyond Relevance: Evaluate and Improve Retrievers on Perspective Awareness",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The task of Information Retrieval (IR) requires a system to identify relevant documents based on users' information needs. In real-world scenarios, retrievers are expected to not only rely on the semantic relevance between the documents and the queries but also recognize the nuanced intents or perspectives behind a user query. For example, when asked to verify a claim, a retrieval system is expected to identify evidence from both supporting vs. contradicting perspectives, for the downstream system to make a fair judgment call. In this work, we study whether retrievers can recognize and respond to different perspectives of the queries -- beyond finding relevant documents for a claim, can retrievers distinguish supporting vs. opposing documents? We reform and extend six existing tasks to create a benchmark for retrieval, where we have diverse perspectives described in free-form text, besides root, neutral queries. We show that current retrievers covered in our experiments have limited awareness of subtly different perspectives in queries and can also be biased toward certain perspectives. Motivated by the observation, we further explore the potential to leverage geometric features of retriever representation space to improve the perspective awareness of retrievers in a zero-shot manner. We demonstrate the efficiency and effectiveness of our projection-based methods on the same set of tasks. Further analysis also shows how perspective awareness improves performance on various downstream tasks, with 4.2% higher accuracy on AmbigQA and 29.9% more correlation with designated viewpoints on essay writing, compared to non-perspective-aware baselines.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02732",
        "abstract url": "https://arxiv.org/abs/2405.02732",
        "title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be spread across many passages in long texts. This poses the challenge of extracting long lists from long texts. We present the L3X method which tackles the problem in two stages: (1) recall-oriented generation using a large language model (LLM) with judicious techniques for retrieval augmentation, and (2) precision-oriented scrutinization to validate or prune candidates. Our L3X method outperforms LLM-only generations by a substantial margin.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02743",
        "abstract url": "https://arxiv.org/abs/2405.02743",
        "title": "Beyond Performance: Quantifying and Mitigating Label Bias in LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown remarkable adaptability to diverse tasks, by leveraging context prompts containing instructions, or minimal input-output examples. However, recent work revealed they also exhibit label bias -- an undesirable preference toward predicting certain answers over others. Still, detecting and measuring this bias reliably and at scale has remained relatively unexplored. In this study, we evaluate different approaches to quantifying label bias in a model's predictions, conducting a comprehensive investigation across 279 classification tasks and ten LLMs. Our investigation reveals substantial label bias in models both before and after debiasing attempts, as well as highlights the importance of outcomes-based evaluation metrics, which were not previously used in this regard. We further propose a novel label bias calibration method tailored for few-shot prompting, which outperforms recent calibration approaches for both improving performance and mitigating label bias. Our results emphasize that label bias in the predictions of LLMs remains a barrier to their reliability.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "NAACL 2024"
    },
    {
        "paper id": "2405.02750",
        "abstract url": "https://arxiv.org/abs/2405.02750",
        "title": "Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) tend to inadequately integrate input context during text generation, relying excessively on encoded prior knowledge in model parameters, potentially resulting in generated text with factual inconsistencies or contextually unfaithful content. LLMs utilize two primary knowledge sources: 1) prior (parametric) knowledge from pretraining, and 2) contextual (non-parametric) knowledge from input prompts. The study addresses the open question of how LLMs effectively balance these knowledge sources during the generation process, specifically in the context of open-domain question answering. To address this issue, we introduce a novel approach integrating contrastive decoding with adversarial irrelevant passages as negative samples to enhance robust context grounding during generation. Notably, our method operates at inference time without requiring further training. We conduct comprehensive experiments to demonstrate its applicability and effectiveness, providing empirical evidence showcasing its superiority over existing methodologies. Our code is publicly available at: https://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted to NAACL 2024"
    },
    {
        "paper id": "2405.02766",
        "abstract url": "https://arxiv.org/abs/2405.02766",
        "title": "Beyond Unimodal Learning: The Importance of Integrating Multiple Modalities for Lifelong Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "While humans excel at continual learning (CL), deep neural networks (DNNs) exhibit catastrophic forgetting. A salient feature of the brain that allows effective CL is that it utilizes multiple modalities for learning and inference, which is underexplored in DNNs. Therefore, we study the role and interactions of multiple modalities in mitigating forgetting and introduce a benchmark for multimodal continual learning. Our findings demonstrate that leveraging multiple views and complementary information from multiple modalities enables the model to learn more accurate and robust representations. This makes the model less vulnerable to modality-specific regularities and considerably mitigates forgetting. Furthermore, we observe that individual modalities exhibit varying degrees of robustness to distribution shift. Finally, we propose a method for integrating and aligning the information from different modalities by utilizing the relational structural similarities between the data points in each modality. Our method sets a strong baseline that enables both single- and multimodal inference. Our study provides a promising case for further exploring the role of multiple modalities in enabling CL and provides a standard benchmark for future research.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted at 3rd Conference on Lifelong Learning Agents (CoLLAs), 2024"
    },
    {
        "paper id": "2405.02787",
        "abstract url": "https://arxiv.org/abs/2405.02787",
        "title": "Light Field Spatial Resolution Enhancement Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Light field (LF) imaging captures both angular and spatial light distributions, enabling advanced photographic techniques. However, micro-lens array (MLA)- based cameras face a spatial-angular resolution tradeoff due to a single shared sensor. We propose a novel light field framework for resolution enhancement, employing a modular approach. The first module generates a high-resolution, all-in-focus image. The second module, a texture transformer network, enhances the resolution of each light field perspective independently using the output of the first module as a reference image. The final module leverages light field regularity to jointly improve resolution across all LF image perspectives. Our approach demonstrates superior performance to existing methods in both qualitative and quantitative evaluations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 6 figures, accepted in IEEE Conference on Signal Processing and Communications Applications"
    },
    {
        "paper id": "2405.02793",
        "abstract url": "https://arxiv.org/abs/2405.02793",
        "title": "ImageInWords: Unlocking Hyper-Detailed Image Descriptions",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "text-to-image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Despite the longstanding adage \"an image is worth a thousand words,\" creating accurate and hyper-detailed image descriptions for training Vision-Language models remains challenging. Current datasets typically have web-scraped descriptions that are short, low-granularity, and often contain details unrelated to the visual content. As a result, models trained on such data generate descriptions replete with missing information, visual inconsistencies, and hallucinations. To address these issues, we introduce ImageInWords (IIW), a carefully designed human-in-the-loop annotation framework for curating hyper-detailed image descriptions and a new dataset resulting from this process. We validate the framework through evaluations focused on the quality of the dataset and its utility for fine-tuning with considerations for readability, comprehensiveness, specificity, hallucinations, and human-likeness. Our dataset significantly improves across these dimensions compared to recently released datasets (+66%) and GPT-4V outputs (+48%). Furthermore, models fine-tuned with IIW data excel by +31% against prior work along the same human evaluation dimensions. Given our fine-tuned models, we also evaluate text-to-image generation and vision-language reasoning. Our model's descriptions can generate images closest to the original, as judged by both automated and human metrics. We also find our model produces more compositionally rich descriptions, outperforming the best baseline by up to 6% on ARO, SVO-Probes, and Winoground datasets.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Webpage (https://google.github.io/imageinwords), GitHub (https://github.com/google/imageinwords), HuggingFace (https://huggingface.co/datasets/google/imageinwords)"
    },
    {
        "paper id": "2405.02801",
        "abstract url": "https://arxiv.org/abs/2405.02801",
        "title": "Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In recent years, AI-Generated Content (AIGC) has witnessed rapid advancements, facilitating the generation of music, images, and other forms of artistic expression across various industries. However, researches on general multi-modal music generation model remain scarce. To fill this gap, we propose a multi-modal music generation framework Mozart's Touch. It could generate aligned music with the cross-modality inputs, such as images, videos and text. Mozart's Touch is composed of three main components: Multi-modal Captioning Module, Large Language Model (LLM) Understanding & Bridging Module, and Music Generation Module. Unlike traditional approaches, Mozart's Touch requires no training or fine-tuning pre-trained models, offering efficiency and transparency through clear, interpretable prompts. We also introduce \"LLM-Bridge\" method to resolve the heterogeneous representation problems between descriptive texts of different modalities. We conduct a series of objective and subjective evaluations on the proposed model, and results indicate that our model surpasses the performance of current state-of-the-art models. Our codes and examples is availble at: https://github.com/WangTooNaive/MozartsTouch",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "7 pages, 2 figures, submitted to ACM MM 2024"
    },
    {
        "paper id": "2405.02805",
        "abstract url": "https://arxiv.org/abs/2405.02805",
        "title": "Verlet Flows: Exact-Likelihood Integrators for Flow-Based Generative Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Approximations in computing model likelihoods with continuous normalizing flows (CNFs) hinder the use of these models for importance sampling of Boltzmann distributions, where exact likelihoods are required. In this work, we present Verlet flows, a class of CNFs on an augmented state-space inspired by symplectic integrators from Hamiltonian dynamics. When used with carefully constructed Taylor-Verlet integrators, Verlet flows provide exact-likelihood generative models which generalize coupled flow architectures from a non-continuous setting while imposing minimal expressivity constraints. On experiments over toy densities, we demonstrate that the variance of the commonly used Hutchinson trace estimator is unsuitable for importance sampling, whereas Verlet flows perform comparably to full autograd trace computations while being significantly faster.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICLR AI4DifferentialEqautions In Science workshop 2024"
    },
    {
        "paper id": "2405.02807",
        "abstract url": "https://arxiv.org/abs/2405.02807",
        "title": "Kinematic analysis of structural mechanics based on convolutional neural network",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Attempt to use convolutional neural network to achieve kinematic analysis of plane bar structure. Through 3dsMax animation software and OpenCV module, self-build image dataset of geometrically stable system and geometrically unstable system. we construct and train convolutional neural network model based on the TensorFlow and Keras deep learning platform framework. The model achieves 100% accuracy on the training set, validation set, and test set. The accuracy on the additional test set is 93.7%, indicating that convolutional neural network can learn and master the relevant knowledge of kinematic analysis of structural mechanics. In the future, the generalization ability of the model can be improved through the diversity of dataset, which has the potential to surpass human experts for complex structures. Convolutional neural network has certain practical value in the field of kinematic analysis of structural mechanics. Using visualization technology, we reveal how convolutional neural network learns and recognizes structural features. Using pre-trained VGG16 model for feature extraction and fine-tuning, we found that the generalization ability is inferior to the self-built model.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "9 pages, 13 figures"
    },
    {
        "paper id": "2405.02569",
        "abstract url": "https://arxiv.org/abs/2405.02569",
        "title": "Decoupling Exploration and Exploitation for Unsupervised Pre-training with Successor Features",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised pre-training has been on the lookout for the virtue of a value function representation referred to as successor features (SFs), which decouples the dynamics of the environment from the rewards. It has a significant impact on the process of task-specific fine-tuning due to the decomposition. However, existing approaches struggle with local optima due to the unified intrinsic reward of exploration and exploitation without considering the linear regression problem and the discriminator supporting a small skill sapce. We propose a novel unsupervised pre-training model with SFs based on a non-monolithic exploration methodology. Our approach pursues the decomposition of exploitation and exploration of an agent built on SFs, which requires separate agents for the respective purpose. The idea will leverage not only the inherent characteristics of SFs such as a quick adaptation to new tasks but also the exploratory and task-agnostic capabilities. Our suggested model is termed Non-Monolithic unsupervised Pre-training with Successor features (NMPS), which improves the performance of the original monolithic exploration method of pre-training with SFs. NMPS outperforms Active Pre-training with Successor Features (APS) in a comparative experiment.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "IJCNN 2024"
    },
    {
        "paper id": "2405.02572",
        "abstract url": "https://arxiv.org/abs/2405.02572",
        "title": "Off-OAB: Off-Policy Policy Gradient Method with Optimal Action-Dependent Baseline",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Policy-based methods have achieved remarkable success in solving challenging reinforcement learning problems. Among these methods, off-policy policy gradient methods are particularly important due to that they can benefit from off-policy data. However, these methods suffer from the high variance of the off-policy policy gradient (OPPG) estimator, which results in poor sample efficiency during training. In this paper, we propose an off-policy policy gradient method with the optimal action-dependent baseline (Off-OAB) to mitigate this variance issue. Specifically, this baseline maintains the OPPG estimator's unbiasedness while theoretically minimizing its variance. To enhance practical computational efficiency, we design an approximated version of this optimal baseline. Utilizing this approximation, our method (Off-OAB) aims to decrease the OPPG estimator's variance during policy optimization. We evaluate the proposed Off-OAB method on six representative tasks from OpenAI Gym and MuJoCo, where it demonstrably surpasses state-of-the-art methods on the majority of these tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "12 pages, 3 figures"
    },
    {
        "paper id": "2405.02576",
        "abstract url": "https://arxiv.org/abs/2405.02576",
        "title": "CTD4 - A Deep Continuous Distributional Actor-Critic Agent with a Kalman Fusion of Multiple Critics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Categorical Distributional Reinforcement Learning (CDRL) has demonstrated superior sample efficiency in learning complex tasks compared to conventional Reinforcement Learning (RL) approaches. However, the practical application of CDRL is encumbered by challenging projection steps, detailed parameter tuning, and domain knowledge. This paper addresses these challenges by introducing a pioneering Continuous Distributional Model-Free RL algorithm tailored for continuous action spaces. The proposed algorithm simplifies the implementation of distributional RL, adopting an actor-critic architecture wherein the critic outputs a continuous probability distribution. Additionally, we propose an ensemble of multiple critics fused through a Kalman fusion mechanism to mitigate overestimation bias. Through a series of experiments, we validate that our proposed method is easy to train and serves as a sample-efficient solution for executing complex continuous-control tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02598",
        "abstract url": "https://arxiv.org/abs/2405.02598",
        "title": "UDUC: An Uncertainty-driven Approach for Learning-based Robust Control",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning-based techniques have become popular in both model predictive control (MPC) and reinforcement learning (RL). Probabilistic ensemble (PE) models offer a promising approach for modelling system dynamics, showcasing the ability to capture uncertainty and scalability in high-dimensional control scenarios. However, PE models are susceptible to mode collapse, resulting in non-robust control when faced with environments slightly different from the training set. In this paper, we introduce the $\\textbf{u}$ncertainty-$\\textbf{d}$riven rob$\\textbf{u}$st $\\textbf{c}$ontrol (UDUC) loss as an alternative objective for training PE models, drawing inspiration from contrastive learning. We analyze the robustness of UDUC loss through the lens of robust optimization and evaluate its performance on the challenging Real-world Reinforcement Learning (RWRL) benchmark, which involves significant environmental mismatches between the training and testing environments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02609",
        "abstract url": "https://arxiv.org/abs/2405.02609",
        "title": "Advanced Equalization in 112 Gb/s Upstream PON Using a Novel Fourier Convolution-based Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We experimentally demonstrate a novel, low-complexity Fourier Convolution-based Network (FConvNet) based equalizer for 112 Gb/s upstream PAM4-PON. At a BER of 0.005, FConvNet enhances the receiver sensitivity by 2 and 1 dB compared to a 51-tap Sato equalizer and benchmark machine learning algorithms respectively.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "4 pages, 5 figures"
    },
    {
        "paper id": "2405.02612",
        "abstract url": "https://arxiv.org/abs/2405.02612",
        "title": "Learning Linear Utility Functions From Pairwise Comparison Queries",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "We study learnability of linear utility functions from pairwise comparison queries. In particular, we consider two learning objectives. The first objective is to predict out-of-sample responses to pairwise comparisons, whereas the second is to approximately recover the true parameters of the utility function. We show that in the passive learning setting, linear utilities are efficiently learnable with respect to the first objective, both when query responses are uncorrupted by noise, and under Tsybakov noise when the distributions are sufficiently \"nice\". In contrast, we show that utility parameters are not learnable for a large set of data distributions without strong modeling assumptions, even when query responses are noise-free. Next, we proceed to analyze the learning problem in an active learning setting. In this case, we show that even the second objective is efficiently learnable, and present algorithms for both the noise-free and noisy query response settings. Our results thus exhibit a qualitative learnability gap between passive and active learning from pairwise preference queries, demonstrating the value of the ability to select pairwise queries for utility learning.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY",
            "stat.ML"
        ],
        "comment": "Submitted to ECAI for review"
    },
    {
        "paper id": "2405.02631",
        "abstract url": "https://arxiv.org/abs/2405.02631",
        "title": "Unsupervised machine learning for data-driven classification of rock mass using drilling data: How can a data-driven system handle limitations in existing rock mass classification systems?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Rock mass classification systems are crucial for assessing stability and risk in underground construction globally and guiding support and excavation design. However, systems developed primarily in the 1970s lack access to modern high-resolution data and advanced statistical techniques, limiting their effectiveness as decision-support systems. Initially, we outline the limitations observed in this context and later describe how a data-driven system, based on drilling data as detailed in this study, can overcome these limitations. Using extracted statistical information from thousands of MWD-data values in one-meter sections of a full tunnel profile, thus working as a signature of the rock mass, we have demonstrated that it is possible to form well-defined clusters that can act as a foundational basis for various rock mass classification systems. We reduced the dimensionality of 48-value vectors using nonlinear manifold learning techniques (UMAP) and linear principal component analysis (PCA) to enhance clustering. Unsupervised machine learning methods (HDBSCAN, Agglomerative Clustering, K-means) were employed to cluster the data, with hyperparameters optimised through multi-objective Bayesian optimisation for effective clustering. Using domain knowledge, we experienced improved clustering and system tuning opportunities in adding extra features to core clusters of MWD-data. We structured and correlated these clusters with physical rock mass properties, including labels of rock type and rock quality, and analysed cumulative distributions of key MWD-parameters for rock mass assessment to determine if clusters meaningfully differentiate rock masses. The ability of MWD data to form distinct rock mass clusters suggests substantial potential for future classification systems grounded in this objective, data-driven methodology, free from human bias.",
        "subjects": [
            "cs.LG",
            "cs.ET",
            "eess.SY"
        ],
        "comment": "38 pages, 11 figures. Includes ancillary interactive versions of some figures"
    },
    {
        "paper id": "2405.02638",
        "abstract url": "https://arxiv.org/abs/2405.02638",
        "title": "PrivSGP-VR: Differentially Private Variance-Reduced Stochastic Gradient Push with Tight Utility Bounds",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a differentially private decentralized learning method (termed PrivSGP-VR) which employs stochastic gradient push with variance reduction and guarantees $(\u03b5, \u03b4)$-differential privacy (DP) for each node. Our theoretical analysis shows that, under DP Gaussian noise with constant variance, PrivSGP-VR achieves a sub-linear convergence rate of $\\mathcal{O}(1/\\sqrt{nK})$, where $n$ and $K$ are the number of nodes and iterations, respectively, which is independent of stochastic gradient variance, and achieves a linear speedup with respect to $n$. Leveraging the moments accountant method, we further derive an optimal $K$ to maximize the model utility under certain privacy budget in decentralized settings. With this optimized $K$, PrivSGP-VR achieves a tight utility bound of $\\mathcal{O}\\left( \\sqrt{d\\log \\left( \\frac{1}\u03b4 \\right)}/(\\sqrt{n}J\u03b5) \\right)$, where $J$ and $d$ are the number of local samples and the dimension of decision variable, respectively, which matches that of the server-client distributed counterparts, and exhibits an extra factor of $1/\\sqrt{n}$ improvement compared to that of the existing decentralized counterparts, such as A(DP)$^2$SGD. Extensive experiments corroborate our theoretical findings, especially in terms of the maximized utility with optimized $K$, in fully decentralized settings.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This paper has been accepted by the 33rd International Joint Conference on Artificial Intelligence(IJCAI 2024)"
    },
    {
        "paper id": "2405.02642",
        "abstract url": "https://arxiv.org/abs/2405.02642",
        "title": "Machine Learning in Space: Surveying the Robustness of on-board ML models to Radiation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern spacecraft are increasingly relying on machine learning (ML). However, physical equipment in space is subject to various natural hazards, such as radiation, which may inhibit the correct operation of computing devices. Despite plenty of evidence showing the damage that naturally-induced faults can cause to ML-related hardware, we observe that the effects of radiation on ML models for space applications are not well-studied. This is a problem: without understanding how ML models are affected by these natural phenomena, it is uncertain \"where to start from\" to develop radiation-tolerant ML software. As ML researchers, we attempt to tackle this dilemma. By partnering up with space-industry practitioners specialized in ML, we perform a reflective analysis of the state of the art. We provide factual evidence that prior work did not thoroughly examine the impact of natural hazards on ML models meant for spacecraft. Then, through a \"negative result\", we show that some existing open-source technologies can hardly be used by researchers to study the effects of radiation for some applications of ML in satellites. As a constructive step forward, we perform simple experiments showcasing how to leverage current frameworks to assess the robustness of practical ML models for cloud detection against radiation-induced faults. Our evaluation reveals that not all faults are as devastating as claimed by some prior work. By publicly releasing our resources, we provide a foothold -- usable by researchers without access to spacecraft -- for spearheading development of space-tolerant ML models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02644",
        "abstract url": "https://arxiv.org/abs/2405.02644",
        "title": "Interpretable Multi-View Clustering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi-view clustering has become a significant area of research, with numerous methods proposed over the past decades to enhance clustering accuracy. However, in many real-world applications, it is crucial to demonstrate a clear decision-making process-specifically, explaining why samples are assigned to particular clusters. Consequently, there remains a notable gap in developing interpretable methods for clustering multi-view data. To fill this crucial gap, we make the first attempt towards this direction by introducing an interpretable multi-view clustering framework. Our method begins by extracting embedded features from each view and generates pseudo-labels to guide the initial construction of the decision tree. Subsequently, it iteratively optimizes the feature representation for each view along with refining the interpretable decision tree. Experimental results on real datasets demonstrate that our method not only provides a transparent clustering process for multi-view data but also delivers performance comparable to state-of-the-art multi-view clustering methods. To the best of our knowledge, this is the first effort to design an interpretable clustering framework specifically for multi-view data, opening a new avenue in this field.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages,6 figures"
    },
    {
        "paper id": "2405.02653",
        "abstract url": "https://arxiv.org/abs/2405.02653",
        "title": "Isopignistic Canonical Decomposition via Belief Evolution Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Developing a general information processing model in uncertain environments is fundamental for the advancement of explainable artificial intelligence. Dempster-Shafer theory of evidence is a well-known and effective reasoning method for representing epistemic uncertainty, which is closely related to subjective probability theory and possibility theory. Although they can be transformed to each other under some particular belief structures, there remains a lack of a clear and interpretable transformation process, as well as a unified approach for information processing. In this paper, we aim to address these issues from the perspectives of isopignistic belief functions and the hyper-cautious transferable belief model. Firstly, we propose an isopignistic transformation based on the belief evolution network. This transformation allows for the adjustment of the information granule while retaining the potential decision outcome. The isopignistic transformation is integrated with a hyper-cautious transferable belief model to establish a new canonical decomposition. This decomposition offers a reverse path between the possibility distribution and its isopignistic mass functions. The result of the canonical decomposition, called isopignistic function, is an identical information content distribution to reflect the propensity and relative commitment degree of the BPA. Furthermore, this paper introduces a method to reconstruct the basic belief assignment by adjusting the isopignistic function. It explores the advantages of this approach in modeling and handling uncertainty within the hyper-cautious transferable belief model. More general, this paper establishes a theoretical basis for building general models of artificial intelligence based on probability theory, Dempster-Shafer theory, and possibility theory.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02654",
        "abstract url": "https://arxiv.org/abs/2405.02654",
        "title": "Enhancing Cooperation through Selective Interaction and Long-term Experiences in Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The significance of network structures in promoting group cooperation within social dilemmas has been widely recognized. Prior studies attribute this facilitation to the assortment of strategies driven by spatial interactions. Although reinforcement learning has been employed to investigate the impact of dynamic interaction on the evolution of cooperation, there remains a lack of understanding about how agents develop neighbour selection behaviours and the formation of strategic assortment within an explicit interaction structure. To address this, our study introduces a computational framework based on multi-agent reinforcement learning in the spatial Prisoner's Dilemma game. This framework allows agents to select dilemma strategies and interacting neighbours based on their long-term experiences, differing from existing research that relies on preset social norms or external incentives. By modelling each agent using two distinct Q-networks, we disentangle the coevolutionary dynamics between cooperation and interaction. The results indicate that long-term experience enables agents to develop the ability to identify non-cooperative neighbours and exhibit a preference for interaction with cooperative ones. This emergent self-organizing behaviour leads to the clustering of agents with similar strategies, thereby increasing network reciprocity and enhancing group cooperation.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ],
        "comment": "Accepted at IJCAI 2024 (33nd International Joint Conference on Artificial Intelligence - Jeju)"
    },
    {
        "paper id": "2405.02661",
        "abstract url": "https://arxiv.org/abs/2405.02661",
        "title": "DDE-Find: Learning Delay Differential Equations from Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Delay Differential Equations (DDEs) are a class of differential equations that can model diverse scientific phenomena. However, identifying the parameters, especially the time delay, that make a DDE's predictions match experimental results can be challenging. We introduce DDE-Find, a data-driven framework for learning a DDE's parameters, time delay, and initial condition function. DDE-Find uses an adjoint-based approach to efficiently compute the gradient of a loss function with respect to the model parameters. We motivate and rigorously prove an expression for the gradients of the loss using the adjoint. DDE-Find builds upon recent developments in learning DDEs from data and delivers the first complete framework for learning DDEs from data. Through a series of numerical experiments, we demonstrate that DDE-Find can learn DDEs from noisy, limited data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "42 pages, 19 tables, 8 figures"
    },
    {
        "paper id": "2405.02670",
        "abstract url": "https://arxiv.org/abs/2405.02670",
        "title": "From Generalization Analysis to Optimization Designs for State Space Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A State Space Model (SSM) is a foundation model in time series analysis, which has recently been shown as an alternative to transformers in sequence modeling. In this paper, we theoretically study the generalization of SSMs and propose improvements to training algorithms based on the generalization results. Specifically, we give a \\textit{data-dependent} generalization bound for SSMs, showing an interplay between the SSM parameters and the temporal dependencies of the training sequences. Leveraging the generalization bound, we (1) set up a scaling rule for model initialization based on the proposed generalization measure, which significantly improves the robustness of the output value scales on SSMs to different temporal patterns in the sequence data; (2) introduce a new regularization method for training SSMs to enhance the generalization performance. Numerical results are conducted to validate our results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02678",
        "abstract url": "https://arxiv.org/abs/2405.02678",
        "title": "Position Paper: Quo Vadis, Unsupervised Time Series Anomaly Detection?",
        "rating": "0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "The current state of machine learning scholarship in Timeseries Anomaly Detection (TAD) is plagued by the persistent use of flawed evaluation metrics, inconsistent benchmarking practices, and a lack of proper justification for the choices made in novel deep learning-based model designs. Our paper presents a critical analysis of the status quo in TAD, revealing the misleading track of current research and highlighting problematic methods, and evaluation practices. Our position advocates for a shift in focus from pursuing only the novelty in model design to improving benchmarking practices, creating non-trivial datasets, and placing renewed emphasis on studying the utility of model architectures for specific tasks. Our findings demonstrate the need for rigorous evaluation protocols, the creation of simple baselines, and the revelation that state-of-the-art deep anomaly detection models effectively learn linear mappings. These findings suggest the need for more exploration and development of simple and interpretable TAD methods. The increment of model complexity in the state-of-the-art deep-learning based models unfortunately offers very little improvement. We offer insights and suggestions for the field to move forward.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2405.02688",
        "abstract url": "https://arxiv.org/abs/2405.02688",
        "title": "Semi-supervised Symmetric Matrix Factorization with Low-Rank Tensor Representation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Semi-supervised symmetric non-negative matrix factorization (SNMF) utilizes the available supervisory information (usually in the form of pairwise constraints) to improve the clustering ability of SNMF. The previous methods introduce the pairwise constraints from the local perspective, i.e., they either directly refine the similarity matrix element-wisely or restrain the distance of the decomposed vectors in pairs according to the pairwise constraints, which overlook the global perspective, i.e., in the ideal case, the pairwise constraint matrix and the ideal similarity matrix possess the same low-rank structure. To this end, we first propose a novel semi-supervised SNMF model by seeking low-rank representation for the tensor synthesized by the pairwise constraint matrix and a similarity matrix obtained by the product of the embedding matrix and its transpose, which could strengthen those two matrices simultaneously from a global perspective. We then propose an enhanced SNMF model, making the embedding matrix tailored to the above tensor low-rank representation. We finally refine the similarity matrix by the strengthened pairwise constraints. We repeat the above steps to continuously boost the similarity matrix and pairwise constraint matrix, leading to a high-quality embedding matrix. Extensive experiments substantiate the superiority of our method. The code is available at https://github.com/JinaLeejnl/TSNMF.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02724",
        "abstract url": "https://arxiv.org/abs/2405.02724",
        "title": "Taming Equilibrium Bias in Risk-Sensitive Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study risk-sensitive multi-agent reinforcement learning under general-sum Markov games, where agents optimize the entropic risk measure of rewards with possibly diverse risk preferences. We show that using the regret naively adapted from existing literature as a performance metric could induce policies with equilibrium bias that favor the most risk-sensitive agents and overlook the other agents. To address such deficiency of the naive regret, we propose a novel notion of regret, which we call risk-balanced regret, and show through a lower bound that it overcomes the issue of equilibrium bias. Furthermore, we develop a self-play algorithm for learning Nash, correlated, and coarse correlated equilibria in risk-sensitive Markov games. We prove that the proposed algorithm attains near-optimal regret guarantees with respect to the risk-balanced regret.",
        "subjects": [
            "cs.LG",
            "cs.GT"
        ],
        "comment": "29 pages"
    },
    {
        "paper id": "2405.02726",
        "abstract url": "https://arxiv.org/abs/2405.02726",
        "title": "A Mathematical Model of the Hidden Feedback Loop Effect in Machine Learning Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Widespread deployment of societal-scale machine learning systems necessitates a thorough understanding of the resulting long-term effects these systems have on their environment, including loss of trustworthiness, bias amplification, and violation of AI safety requirements. We introduce a repeated learning process to jointly describe several phenomena attributed to unintended hidden feedback loops, such as error amplification, induced concept drift, echo chambers and others. The process comprises the entire cycle of obtaining the data, training the predictive model, and delivering predictions to end-users within a single mathematical model. A distinctive feature of such repeated learning setting is that the state of the environment becomes causally dependent on the learner itself over time, thus violating the usual assumptions about the data distribution. We present a novel dynamical systems model of the repeated learning process and prove the limiting set of probability distributions for positive and negative feedback loop modes of the system operation. We conduct a series of computational experiments using an exemplary supervised learning problem on two synthetic data sets. The results of the experiments correspond to the theoretical predictions derived from the dynamical model. Our results demonstrate the feasibility of the proposed approach for studying the repeated learning processes in machine learning systems and open a range of opportunities for further research in the area.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": "21 pages, 15 figures"
    },
    {
        "paper id": "2405.02749",
        "abstract url": "https://arxiv.org/abs/2405.02749",
        "title": "Sub-goal Distillation: A Method to Improve Small Language Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "While Large Language Models (LLMs) have demonstrated significant promise as agents in interactive tasks, their substantial computational requirements and restricted number of calls constrain their practical utility, especially in long-horizon interactive tasks such as decision-making or in scenarios involving continuous ongoing tasks. To address these constraints, we propose a method for transferring the performance of an LLM with billions of parameters to a much smaller language model (770M parameters). Our approach involves constructing a hierarchical agent comprising a planning module, which learns through Knowledge Distillation from an LLM to generate sub-goals, and an execution module, which learns to accomplish these sub-goals using elementary actions. In detail, we leverage an LLM to annotate an oracle path with a sequence of sub-goals towards completing a goal. Subsequently, we utilize this annotated data to fine-tune both the planning and execution modules. Importantly, neither module relies on real-time access to an LLM during inference, significantly reducing the overall cost associated with LLM interactions to a fixed cost. In ScienceWorld, a challenging and multi-task interactive text environment, our method surpasses standard imitation learning based solely on elementary actions by 16.7% (absolute). Our analysis highlights the efficiency of our approach compared to other LLM-based methods. Our code and annotated data for distillation can be found on GitHub.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02754",
        "abstract url": "https://arxiv.org/abs/2405.02754",
        "title": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep reinforcement learning (DRL) has demonstrated remarkable performance in many continuous control tasks. However, a significant obstacle to the real-world application of DRL is the lack of safety guarantees. Although DRL agents can satisfy system safety in expectation through reward shaping, designing agents to consistently meet hard constraints (e.g., safety specifications) at every time step remains a formidable challenge. In contrast, existing work in the field of safe control provides guarantees on persistent satisfaction of hard safety constraints. However, these methods require explicit analytical system dynamics models to synthesize safe control, which are typically inaccessible in DRL settings. In this paper, we present a model-free safe control algorithm, the implicit safe set algorithm, for synthesizing safeguards for DRL agents that ensure provable safety throughout training. The proposed algorithm synthesizes a safety index (barrier certificate) and a subsequent safe control law solely by querying a black-box dynamic function (e.g., a digital twin simulator). Moreover, we theoretically prove that the implicit safe set algorithm guarantees finite time convergence to the safe set and forward invariance for both continuous-time and discrete-time systems. We validate the proposed algorithm on the state-of-the-art Safety Gym benchmark, where it achieves zero safety violations while gaining $95\\% \\pm 9\\%$ cumulative reward compared to state-of-the-art safe DRL methods. Furthermore, the resulting algorithm scales well to high-dimensional systems with parallel computing.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "submissions to Journal of Artificial Intelligence Research. arXiv admin note: text overlap with arXiv:2308.13140"
    },
    {
        "paper id": "2405.02760",
        "abstract url": "https://arxiv.org/abs/2405.02760",
        "title": "GTFS2STN: Analyzing GTFS Transit Data by Generating Spatiotemporal Transit Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "GTFS, the General Transit Feed Specialization, is an open standard format to record transit information used by thousands of transit agencies across the world. By converting a static GTFS transit network to a spatiotemporal network connecting bus stops over space and time, a preliminary tool named GTFS2STN is implemented to analyze the accessibility of the transit system. Furthermore, a simple application is built for users to generate spatiotemporal network online. The online tool also supports some basic analysis including generate isochrone maps given origin, generate travel time variability over time given a pair of origin and destination, etc. Results show that the tool has a similar result compared with Mapnificent, another open source endeavour to generate isochrone maps given GTFS inputs. Compared with Mapnificent, the proposed GTFS2STN tool is suited for research and evaluation purposes because the users can upload any historical GTFS dataset by any transit agencies to evaluate the accessibility and travel time variability of transit networks over time.",
        "subjects": [
            "cs.CE",
            "cs.SI"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2405.02769",
        "abstract url": "https://arxiv.org/abs/2405.02769",
        "title": "Linear Convergence of Independent Natural Policy Gradient in Games with Entropy Regularization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work focuses on the entropy-regularized independent natural policy gradient (NPG) algorithm in multi-agent reinforcement learning. In this work, agents are assumed to have access to an oracle with exact policy evaluation and seek to maximize their respective independent rewards. Each individual's reward is assumed to depend on the actions of all the agents in the multi-agent system, leading to a game between agents. We assume all agents make decisions under a policy with bounded rationality, which is enforced by the introduction of entropy regularization. In practice, a smaller regularization implies the agents are more rational and behave closer to Nash policies. On the other hand, agents with larger regularization acts more randomly, which ensures more exploration. We show that, under sufficient entropy regularization, the dynamics of this system converge at a linear rate to the quantal response equilibrium (QRE). Although regularization assumptions prevent the QRE from approximating a Nash equilibrium, our findings apply to a wide range of games, including cooperative, potential, and two-player matrix games. We also provide extensive empirical results on multiple games (including Markov games) as a verification of our theoretical analysis.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02798",
        "abstract url": "https://arxiv.org/abs/2405.02798",
        "title": "Structural Balance in Real-World Social Networks: Incorporating Direction and Transitivity in Measuring Partial Balance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Structural balance theory predicts that triads in networks gravitate towards stable configurations. The theory has been verified for undirected graphs. Since real-world networks are often directed, we introduce a novel method for considering both transitivity and sign consistency for evaluating partial balance in signed digraphs. We test our approach on graphs constructed by using different methods for identifying edge signs: natural language processing to infer signs from underlying text data, and self-reported survey data. Our results show that for various social contexts and edge sign detection methods, partial balance of these digraphs are moderately high, ranging from 61% to 96%. Our approach not only enhances the theoretical framework of structural balance but also provides practical insights into the stability of social networks, enabling a deeper understanding of interpersonal and group dynamics across different communication platforms.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2006.02565"
    },
    {
        "paper id": "2405.02803",
        "abstract url": "https://arxiv.org/abs/2405.02803",
        "title": "Is Flash Attention Stable?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training large-scale machine learning models poses distinct system challenges, given both the size and complexity of today's workloads. Recently, many organizations training state-of-the-art Generative AI models have reported cases of instability during training, often taking the form of loss spikes. Numeric deviation has emerged as a potential cause of this training instability, although quantifying this is especially challenging given the costly nature of training runs. In this work, we develop a principled approach to understanding the effects of numeric deviation, and construct proxies to put observations into context when downstream effects are difficult to quantify. As a case study, we apply this framework to analyze the widely-adopted Flash Attention optimization. We find that Flash Attention sees roughly an order of magnitude more numeric deviation as compared to Baseline Attention at BF16 when measured during an isolated forward pass. We then use a data-driven analysis based on the Wasserstein Distance to provide upper bounds on how this numeric deviation impacts model weights during training, finding that the numerical deviation present in Flash Attention is 2-5 times less significant than low-precision training.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.03712",
        "abstract url": "https://arxiv.org/abs/2405.03712",
        "title": "Your Network May Need to Be Rewritten: Network Adversarial Based on High-Dimensional Function Graph Decomposition",
        "rating": "0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the past, research on a single low dimensional activation function in networks has led to internal covariate shift and gradient deviation problems. A relatively small research area is how to use function combinations to provide property completion for a single activation function application. We propose a network adversarial method to address the aforementioned challenges. This is the first method to use different activation functions in a network. Based on the existing activation functions in the current network, an adversarial function with opposite derivative image properties is constructed, and the two are alternately used as activation functions for different network layers. For complex situations, we propose a method of high-dimensional function graph decomposition(HD-FGD), which divides it into different parts and then passes through a linear layer. After integrating the inverse of the partial derivatives of each decomposed term, we obtain its adversarial function by referring to the computational rules of the decomposition process. The use of network adversarial methods or the use of HD-FGD alone can effectively replace the traditional MLP+activation function mode. Through the above methods, we have achieved a substantial improvement over standard activation functions regarding both training efficiency and predictive accuracy. The article addresses the adversarial issues associated with several prevalent activation functions, presenting alternatives that can be seamlessly integrated into existing models without any adverse effects. We will release the code as open source after the conference review process is completed.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.03714",
        "abstract url": "https://arxiv.org/abs/2405.03714",
        "title": "UniDEC : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Extreme Multi-label Classification (XMC) involves predicting a subset of relevant labels from an extremely large label space, given an input query and labels with textual features. Models developed for this problem have conventionally used modular approach with (i) a Dual Encoder (DE) to embed the queries and label texts, (ii) a One-vs-All classifier to rerank the shortlisted labels mined through meta-classifier training. While such methods have shown empirical success, we observe two key uncharted aspects, (i) DE training typically uses only a single positive relation even for datasets which offer more, (ii) existing approaches fixate on using only OvA reduction of the multi-label problem. This work aims to explore these aspects by proposing UniDEC, a novel end-to-end trainable framework which trains the dual encoder and classifier in together in a unified fashion using a multi-class loss. For the choice of multi-class loss, the work proposes a novel pick-some-label (PSL) reduction of the multi-label problem with leverages multiple (in come cases, all) positives. The proposed framework achieves state-of-the-art results on a single GPU, while achieving on par results with respect to multi-GPU SOTA methods on various XML benchmark datasets, all while using 4-16x lesser compute and being practically scalable even beyond million label scale datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02568",
        "abstract url": "https://arxiv.org/abs/2405.02568",
        "title": "ActiveNeuS: Active 3D Reconstruction using Neural Implicit Surface Uncertainty",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Active learning in 3D scene reconstruction has been widely studied, as selecting informative training views is critical for the reconstruction. Recently, Neural Radiance Fields (NeRF) variants have shown performance increases in active 3D reconstruction using image rendering or geometric uncertainty. However, the simultaneous consideration of both uncertainties in selecting informative views remains unexplored, while utilizing different types of uncertainty can reduce the bias that arises in the early training stage with sparse inputs. In this paper, we propose ActiveNeuS, which evaluates candidate views considering both uncertainties. ActiveNeuS provides a way to accumulate image rendering uncertainty while avoiding the bias that the estimated densities can introduce. ActiveNeuS computes the neural implicit surface uncertainty, providing the color uncertainty along with the surface information. It efficiently handles the bias by using the surface information and a grid, enabling the fast selection of diverse viewpoints. Our method outperforms previous works on popular datasets, Blender and DTU, showing that the views selected by ActiveNeuS significantly improve performance.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02659",
        "abstract url": "https://arxiv.org/abs/2405.02659",
        "title": "R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-augmented large language models (LLMs) leverage relevant content retrieved by information retrieval systems to generate correct responses, aiming to alleviate the hallucination problem. However, existing retriever-responder methods typically append relevant documents to the prompt of LLMs to perform text generation tasks without considering the interaction of fine-grained structural semantics between the retrieved documents and the LLMs. This issue is particularly important for accurate response generation as LLMs tend to ``lose in the middle'' when dealing with input prompts augmented with lengthy documents. In this work, we propose a new pipeline named ``Reinforced Retriever-Reorder-Responder'' (R$^4$) to learn document orderings for retrieval-augmented LLMs, thereby further enhancing their generation abilities while the large numbers of parameters of LLMs remain frozen. The reordering learning process is divided into two steps according to the quality of the generated responses: document order adjustment and document representation enhancement. Specifically, document order adjustment aims to organize retrieved document orderings into beginning, middle, and end positions based on graph attention learning, which maximizes the reinforced reward of response quality. Document representation enhancement further refines the representations of retrieved documents for responses of poor quality via document-level gradient adversarial learning. Extensive experiments demonstrate that our proposed pipeline achieves better factual question-answering performance on knowledge-intensive tasks compared to strong baselines across various public datasets. The source codes and trained models will be released upon paper acceptance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02686",
        "abstract url": "https://arxiv.org/abs/2405.02686",
        "title": "Boosting 3D Neuron Segmentation with 2D Vision Transformer Pre-trained on Natural Images",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Neuron reconstruction, one of the fundamental tasks in neuroscience, rebuilds neuronal morphology from 3D light microscope imaging data. It plays a critical role in analyzing the structure-function relationship of neurons in the nervous system. However, due to the scarcity of neuron datasets and high-quality SWC annotations, it is still challenging to develop robust segmentation methods for single neuron reconstruction. To address this limitation, we aim to distill the consensus knowledge from massive natural image data to aid the segmentation model in learning the complex neuron structures. Specifically, in this work, we propose a novel training paradigm that leverages a 2D Vision Transformer model pre-trained on large-scale natural images to initialize our Transformer-based 3D neuron segmentation model with a tailored 2D-to-3D weight transferring strategy. Our method builds a knowledge sharing connection between the abundant natural and the scarce neuron image domains to improve the 3D neuron segmentation ability in a data-efficiency manner. Evaluated on a popular benchmark, BigNeuron, our method enhances neuron segmentation performance by 8.71% over the model trained from scratch with the same amount of training samples.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "3 pages"
    },
    {
        "paper id": "2405.02698",
        "abstract url": "https://arxiv.org/abs/2405.02698",
        "title": "Stable Diffusion Dataset Generation for Downstream Classification Tasks",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in generative artificial intelligence have enabled the creation of high-quality synthetic data that closely mimics real-world data. This paper explores the adaptation of the Stable Diffusion 2.0 model for generating synthetic datasets, using Transfer Learning, Fine-Tuning and generation parameter optimisation techniques to improve the utility of the dataset for downstream classification tasks. We present a class-conditional version of the model that exploits a Class-Encoder and optimisation of key generation parameters. Our methodology led to synthetic datasets that, in a third of cases, produced models that outperformed those trained on real datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02717",
        "abstract url": "https://arxiv.org/abs/2405.02717",
        "title": "AFter: Attention-based Fusion Router for RGBT Tracking",
        "rating": "0",
        "keywords": [
            [
                "architecture search"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal feature fusion as a core investigative component of RGBT tracking emerges numerous fusion studies in recent years. However, existing RGBT tracking methods widely adopt fixed fusion structures to integrate multi-modal feature, which are hard to handle various challenges in dynamic scenarios. To address this problem, this work presents a novel \\emph{A}ttention-based \\emph{F}usion rou\\emph{ter} called AFter, which optimizes the fusion structure to adapt to the dynamic challenging scenarios, for robust RGBT tracking. In particular, we design a fusion structure space based on the hierarchical attention network, each attention-based fusion unit corresponding to a fusion operation and a combination of these attention units corresponding to a fusion structure. Through optimizing the combination of attention-based fusion units, we can dynamically select the fusion structure to adapt to various challenging scenarios. Unlike complex search of different structures in neural architecture search algorithms, we develop a dynamic routing algorithm, which equips each attention-based fusion unit with a router, to predict the combination weights for efficient optimization of the fusion structure. Extensive experiments on five mainstream RGBT tracking datasets demonstrate the superior performance of the proposed AFter against state-of-the-art RGBT trackers. We release the code in https://github.com/Alexadlu/AFter.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Peer review"
    },
    {
        "paper id": "2405.02730",
        "abstract url": "https://arxiv.org/abs/2405.02730",
        "title": "U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion Transformers (DiTs) introduce the transformer architecture to diffusion tasks for latent-space image generation. With an isotropic architecture that chains a series of transformer blocks, DiTs demonstrate competitive performance and good scalability; but meanwhile, the abandonment of U-Net by DiTs and their following improvements is worth rethinking. To this end, we conduct a simple toy experiment by comparing a U-Net architectured DiT with an isotropic one. It turns out that the U-Net architecture only gain a slight advantage amid the U-Net inductive bias, indicating potential redundancies within the U-Net-style DiT. Inspired by the discovery that U-Net backbone features are low-frequency-dominated, we perform token downsampling on the query-key-value tuple for self-attention and bring further improvements despite a considerable amount of reduction in computation. Based on self-attention with downsampled tokens, we propose a series of U-shaped DiTs (U-DiTs) in the paper and conduct extensive experiments to demonstrate the extraordinary performance of U-DiT models. The proposed U-DiT could outperform DiT-XL/2 with only 1/6 of its computation cost. Codes are available at https://github.com/YuchuanTian/U-DiT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2405.02738",
        "abstract url": "https://arxiv.org/abs/2405.02738",
        "title": "Relations Prediction for Knowledge Graph Completion using Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge Graphs have been widely used to represent facts in a structured format. Due to their large scale applications, knowledge graphs suffer from being incomplete. The relation prediction task obtains knowledge graph completion by assigning one or more possible relations to each pair of nodes. In this work, we make use of the knowledge graph node names to fine-tune a large language model for the relation prediction task. By utilizing the node names only we enable our model to operate sufficiently in the inductive settings. Our experiments show that we accomplish new scores on a widely used knowledge graph benchmark.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02745",
        "abstract url": "https://arxiv.org/abs/2405.02745",
        "title": "Understanding Server-Assisted Federated Learning in the Presence of Incomplete Client Participation",
        "rating": "0",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Existing works in federated learning (FL) often assume an ideal system with either full client or uniformly distributed client participation. However, in practice, it has been observed that some clients may never participate in FL training (aka incomplete client participation) due to a myriad of system heterogeneity factors. A popular approach to mitigate impacts of incomplete client participation is the server-assisted federated learning (SA-FL) framework, where the server is equipped with an auxiliary dataset. However, despite SA-FL has been empirically shown to be effective in addressing the incomplete client participation problem, there remains a lack of theoretical understanding for SA-FL. Meanwhile, the ramifications of incomplete client participation in conventional FL are also poorly understood. These theoretical gaps motivate us to rigorously investigate SA-FL. Toward this end, we first show that conventional FL is {\\em not} PAC-learnable under incomplete client participation in the worst case. Then, we show that the PAC-learnability of FL with incomplete client participation can indeed be revived by SA-FL, which theoretically justifies the use of SA-FL for the first time. Lastly, to provide practical guidance for SA-FL training under {\\em incomplete client participation}, we propose the $\\mathsf{SAFARI}$ (server-assisted federated averaging) algorithm that enjoys the same linear convergence speedup guarantees as classic FL with ideal client participation assumptions, offering the first SA-FL algorithm with convergence guarantee. Extensive experiments on different datasets show $\\mathsf{SAFARI}$ significantly improves the performance under incomplete client participation.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "Accepted in ICML2024"
    },
    {
        "paper id": "2405.02764",
        "abstract url": "https://arxiv.org/abs/2405.02764",
        "title": "Assessing Adversarial Robustness of Large Language Models: An Empirical Study",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing, but their robustness against adversarial attacks remains a critical concern. We presents a novel white-box style attack approach that exposes vulnerabilities in leading open-source LLMs, including Llama, OPT, and T5. We assess the impact of model size, structure, and fine-tuning strategies on their resistance to adversarial perturbations. Our comprehensive evaluation across five diverse text classification tasks establishes a new benchmark for LLM robustness. The findings of this study have far-reaching implications for the reliable deployment of LLMs in real-world applications and contribute to the advancement of trustworthy AI systems.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "16 pages, 9 figures, 10 tables"
    },
    {
        "paper id": "2405.02765",
        "abstract url": "https://arxiv.org/abs/2405.02765",
        "title": "Detecting Edited Knowledge in Language Models",
        "rating": "0",
        "keywords": [
            [
                "Knowledge editing"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge editing techniques (KEs) can update language models' obsolete or inaccurate knowledge learned from pre-training. However, KE also faces potential malicious applications, e.g. inserting misinformation and toxic content. Moreover, in the context of responsible AI, it is instructive for end-users to know whether a generated output is driven by edited knowledge or first-hand knowledge from pre-training. To this end, we study detecting edited knowledge in language models by introducing a novel task: given an edited model and a specific piece of knowledge the model generates, our objective is to classify the knowledge as either \"non-edited\" (based on the pre-training), or ``edited'' (based on subsequent editing). We initiate the task with two state-of-the-art KEs, two language models, and two datasets. We further propose a simple classifier, RepReg, a logistic regression model that takes hidden state representations as input features. Our results reveal that RepReg establishes a strong baseline, achieving a peak accuracy of 99.81%, and 97.79% in out-of-domain settings. Second, RepReg achieves near-optimal performance with a limited training set (200 training samples), and it maintains its performance even in out-of-domain settings. Last, we find it more challenging to separate edited and non-edited knowledge when they contain the same subject or object.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02771",
        "abstract url": "https://arxiv.org/abs/2405.02771",
        "title": "MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning",
        "rating": "0",
        "keywords": [
            [
                "parameter efficiency"
            ],
            [
                "satellite"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The volume of unlabelled Earth observation (EO) data is huge, but many important applications lack labelled training data. However, EO data offers the unique opportunity to pair data from different modalities and sensors automatically based on geographic location and time, at virtually no human labor cost. We seize this opportunity to create a diverse multi-modal pretraining dataset at global scale. Using this new corpus of 1.2 million locations, we propose a Multi-Pretext Masked Autoencoder (MP-MAE) approach to learn general-purpose representations for optical satellite images. Our approach builds on the ConvNeXt V2 architecture, a fully convolutional masked autoencoder (MAE). Drawing upon a suite of multi-modal pretext tasks, we demonstrate that our MP-MAE approach outperforms both MAEs pretrained on ImageNet and MAEs pretrained on domain-specific satellite images. This is shown on several downstream tasks including image classification and semantic segmentation. We find that multi-modal pretraining notably improves the linear probing performance, e.g. 4pp on BigEarthNet and 16pp on So2Sat, compared to pretraining on optical satellite images only. We show that this also leads to better label and parameter efficiency which are crucial aspects in global scale applications.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Data and code is available on the project page: https://vishalned.github.io/mmearth"
    },
    {
        "paper id": "2405.02792",
        "abstract url": "https://arxiv.org/abs/2405.02792",
        "title": "Jointly Learning Spatial, Angular, and Temporal Information for Enhanced Lane Detection",
        "rating": "0",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel approach for enhanced lane detection by integrating spatial, angular, and temporal information through light field imaging and novel deep learning models. Utilizing lenslet-inspired 2D light field representations and LSTM networks, our method significantly improves lane detection in challenging conditions. We demonstrate the efficacy of this approach with modified CNN architectures, showing superior per- formance over traditional methods. Our findings suggest this integrated data approach could advance lane detection technologies and inspire new models that leverage these multidimensional insights for autonomous vehicle percep- tion.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 3 Figures , Accepted IEEE Conference on Signal Processing and Communications Applications"
    },
    {
        "paper id": "2405.02794",
        "abstract url": "https://arxiv.org/abs/2405.02794",
        "title": "Octopi: Object Property Reasoning with Large Tactile-Language Models",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Physical reasoning is important for effective robot manipulation. Recent work has investigated both vision and language modalities for physical reasoning; vision can reveal information about objects in the environment and language serves as an abstraction and communication medium for additional context. Although these works have demonstrated success on a variety of physical reasoning tasks, they are limited to physical properties that can be inferred from visual or language inputs. In this work, we investigate combining tactile perception with language, which enables embodied systems to obtain physical properties through interaction and apply common-sense reasoning. We contribute a new dataset PhysiCleAR, which comprises both physical/property reasoning tasks and annotated tactile videos obtained using a GelSight tactile sensor. We then introduce Octopi, a system that leverages both tactile representation learning and large vision-language models to predict and reason about tactile inputs with minimal language fine-tuning. Our evaluations on PhysiCleAR show that Octopi is able to effectively use intermediate physical property predictions to improve physical reasoning in both trained tasks and for zero-shot reasoning. PhysiCleAR and Octopi are available on https://github.com/clear-nus/octopi.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2405.02795",
        "abstract url": "https://arxiv.org/abs/2405.02795",
        "title": "Graph as Point Set",
        "rating": "0",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Graph is a fundamental data structure to model interconnections between entities. Set, on the contrary, stores independent elements. To learn graph representations, current Graph Neural Networks (GNNs) primarily use message passing to encode the interconnections. In contrast, this paper introduces a novel graph-to-set conversion method that bijectively transforms interconnected nodes into a set of independent points and then uses a set encoder to learn the graph representation. This conversion method holds dual significance. Firstly, it enables using set encoders to learn from graphs, thereby significantly expanding the design space of GNNs. Secondly, for Transformer, a specific set encoder, we provide a novel and principled approach to inject graph information losslessly, different from all the heuristic structural/positional encoding methods adopted in previous graph transformers. To demonstrate the effectiveness of our approach, we introduce Point Set Transformer (PST), a transformer architecture that accepts a point set converted from a graph as input. Theoretically, PST exhibits superior expressivity for both short-range substructure counting and long-range shortest path distance tasks compared to existing GNNs. Extensive experiments further validate PST's outstanding real-world performance. Besides Transformer, we also devise a Deepset-based set encoder, which achieves performance comparable to representative GNNs, affirming the versatility of our graph-to-set method.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2405.02811",
        "abstract url": "https://arxiv.org/abs/2405.02811",
        "title": "PVTransformer: Point-to-Voxel Transformer for Scalable 3D Object Detection",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Voxel"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D object detectors for point clouds often rely on a pooling-based PointNet to encode sparse points into grid-like voxels or pillars. In this paper, we identify that the common PointNet design introduces an information bottleneck that limits 3D object detection accuracy and scalability. To address this limitation, we propose PVTransformer: a transformer-based point-to-voxel architecture for 3D detection. Our key idea is to replace the PointNet pooling operation with an attention module, leading to a better point-to-voxel aggregation function. Our design respects the permutation invariance of sparse 3D points while being more expressive than the pooling-based PointNet. Experimental results show our PVTransformer achieves much better performance compared to the latest 3D object detectors. On the widely used Waymo Open Dataset, our PVTransformer achieves state-of-the-art 76.5 mAPH L2, outperforming the prior art of SWFormer by +1.7 mAPH L2.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02574",
        "abstract url": "https://arxiv.org/abs/2405.02574",
        "title": "A Data Mining-Based Dynamical Anomaly Detection Method for Integrating with an Advance Metering System",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Building operations consume 30% of total power consumption and contribute 26% of global power-related emissions. Therefore, monitoring, and early detection of anomalies at the meter level are essential for residential and commercial buildings. This work investigates both supervised and unsupervised approaches and introduces a dynamic anomaly detection system. The system introduces a supervised Light Gradient Boosting machine and an unsupervised autoencoder with a dynamic threshold. This system is designed to provide real-time detection of anomalies at the meter level. The proposed dynamical system comes with a dynamic threshold based on the Mahalanobis distance and moving averages. This approach allows the system to adapt to changes in the data distribution over time. The effectiveness of the proposed system is evaluated using real-life power consumption data collected from smart metering systems. This empirical testing ensures that the system's performance is validated under real-world conditions. By detecting unusual data movements and providing early warnings, the proposed system contributes significantly to visual analytics and decision science. Early detection of anomalies enables timely troubleshooting, preventing financial losses and potential disasters such as fire incidents.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02580",
        "abstract url": "https://arxiv.org/abs/2405.02580",
        "title": "PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "With recent advances in large language models (LLMs), this paper explores the potential of leveraging state-of-the-art LLMs, such as GPT-4, to transfer existing human-written properties (e.g., those from Certora auditing reports) and automatically generate customized properties for unknown code. To this end, we embed existing properties into a vector database and retrieve a reference property for LLM-based in-context learning to generate a new prop- erty for a given code. While this basic process is relatively straight- forward, ensuring that the generated properties are (i) compilable, (ii) appropriate, and (iii) runtime-verifiable presents challenges. To address (i), we use the compilation and static analysis feedback as an external oracle to guide LLMs in iteratively revising the generated properties. For (ii), we consider multiple dimensions of similarity to rank the properties and employ a weighted algorithm to identify the top-K properties as the final result. For (iii), we design a dedicated prover to formally verify the correctness of the generated prop- erties. We have implemented these strategies into a novel system called PropertyGPT, with 623 human-written properties collected from 23 Certora projects. Our experiments show that PropertyGPT can generate comprehensive and high-quality properties, achieving an 80% recall compared to the ground truth. It successfully detected 26 CVEs/attack incidents out of 37 tested and also uncovered 12 zero-day vulnerabilities, resulting in $8,256 bug bounty rewards.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02605",
        "abstract url": "https://arxiv.org/abs/2405.02605",
        "title": "MEXGEN: An Effective and Efficient Information Gain Approximation for Information Gathering Path Planning",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autonomous robots for gathering information on objects of interest has numerous real-world applications because of they improve efficiency, performance and safety. Realizing autonomy demands online planning algorithms to solve sequential decision making problems under uncertainty; because, objects of interest are often dynamic, object state, such as location is not directly observable and are obtained from noisy measurements. Such planning problems are notoriously difficult due to the combinatorial nature of predicting the future to make optimal decisions. For information theoretic planning algorithms, we develop a computationally efficient and effective approximation for the difficult problem of predicting the likely sensor measurements from uncertain belief states}. The approach more accurately predicts information gain from information gathering actions. Our theoretical analysis proves the proposed formulation achieves a lower prediction error than the current efficient-method. We demonstrate improved performance gains in radio-source tracking and localization problems using extensive simulated and field experiments with a multirotor aerial robot.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)(Demo Video: https://www.youtube.com/watch?v=XrsCC6MkaB4)"
    },
    {
        "paper id": "2405.02628",
        "abstract url": "https://arxiv.org/abs/2405.02628",
        "title": "Contrastive Dual-Interaction Graph Neural Network for Molecular Property Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Molecular property prediction is a key component of AI-driven drug discovery and molecular characterization learning. Despite recent advances, existing methods still face challenges such as limited ability to generalize, and inadequate representation of learning from unlabeled data, especially for tasks specific to molecular structures. To address these limitations, we introduce DIG-Mol, a novel self-supervised graph neural network framework for molecular property prediction. This architecture leverages the power of contrast learning with dual interaction mechanisms and unique molecular graph enhancement strategies. DIG-Mol integrates a momentum distillation network with two interconnected networks to efficiently improve molecular characterization. The framework's ability to extract key information about molecular structure and higher-order semantics is supported by minimizing loss of contrast. We have established DIG-Mol's state-of-the-art performance through extensive experimental evaluation in a variety of molecular property prediction tasks. In addition to demonstrating superior transferability in a small number of learning scenarios, our visualizations highlight DIG-Mol's enhanced interpretability and representation capabilities. These findings confirm the effectiveness of our approach in overcoming challenges faced by traditional methods and mark a significant advance in molecular property prediction.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02649",
        "abstract url": "https://arxiv.org/abs/2405.02649",
        "title": "Generic Multi-modal Representation Learning for Network Traffic Analysis",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Network traffic analysis is fundamental for network management, troubleshooting, and security. Tasks such as traffic classification, anomaly detection, and novelty discovery are fundamental for extracting operational information from network data and measurements. We witness the shift from deep packet inspection and basic machine learning to Deep Learning (DL) approaches where researchers define and test a custom DL architecture designed for each specific problem. We here advocate the need for a general DL architecture flexible enough to solve different traffic analysis tasks. We test this idea by proposing a DL architecture based on generic data adaptation modules, followed by an integration module that summarises the extracted information into a compact and rich intermediate representation (i.e. embeddings). The result is a flexible Multi-modal Autoencoder (MAE) pipeline that can solve different use cases. We demonstrate the architecture with traffic classification (TC) tasks since they allow us to quantitatively compare results with state-of-the-art solutions. However, we argue that the MAE architecture is generic and can be used to learn representations useful in multiple scenarios. On TC, the MAE performs on par or better than alternatives while avoiding cumbersome feature engineering, thus streamlining the adoption of DL solutions for traffic analysis.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02685",
        "abstract url": "https://arxiv.org/abs/2405.02685",
        "title": "FedProK: Trustworthy Federated Class-Incremental Learning via Prototypical Feature Knowledge Transfer",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Federated Class-Incremental Learning (FCIL) focuses on continually transferring the previous knowledge to learn new classes in dynamic Federated Learning (FL). However, existing methods do not consider the trustworthiness of FCIL, i.e., improving continual utility, privacy, and efficiency simultaneously, which is greatly influenced by catastrophic forgetting and data heterogeneity among clients. To address this issue, we propose FedProK (Federated Prototypical Feature Knowledge Transfer), leveraging prototypical feature as a novel representation of knowledge to perform spatial-temporal knowledge transfer. Specifically, FedProK consists of two components: (1) feature translation procedure on the client side by temporal knowledge transfer from the learned classes and (2) prototypical knowledge fusion on the server side by spatial knowledge transfer among clients. Extensive experiments conducted in both synchronous and asynchronous settings demonstrate that our FedProK outperforms the other state-of-the-art methods in three perspectives of trustworthiness, validating its effectiveness in selectively transferring spatial-temporal knowledge.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02703",
        "abstract url": "https://arxiv.org/abs/2405.02703",
        "title": "Machine Learning Data Practices through a Data Curation Lens: An Evaluation Framework",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Studies of dataset development in machine learning call for greater attention to the data practices that make model development possible and shape its outcomes. Many argue that the adoption of theory and practices from archives and data curation fields can support greater fairness, accountability, transparency, and more ethical machine learning. In response, this paper examines data practices in machine learning dataset development through the lens of data curation. We evaluate data practices in machine learning as data curation practices. To do so, we develop a framework for evaluating machine learning datasets using data curation concepts and principles through a rubric. Through a mixed-methods analysis of evaluation results for 25 ML datasets, we study the feasibility of data curation principles to be adopted for machine learning data work in practice and explore how data curation is currently performed. We find that researchers in machine learning, which often emphasizes model development, struggle to apply standard data curation principles. Our findings illustrate difficulties at the intersection of these fields, such as evaluating dimensions that have shared terms in both fields but non-shared meanings, a high degree of interpretative flexibility in adapting concepts without prescriptive restrictions, obstacles in limiting the depth of data curation expertise needed to apply the rubric, and challenges in scoping the extent of documentation dataset creators are responsible for. We propose ways to address these challenges and develop an overall framework for evaluation that outlines how data curation concepts and methods can inform machine learning data practices.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "In ACM Conference on Fairness, Accountability, and Transparency 2024. ACM, Rio de Janeiro, Brazil"
    },
    {
        "paper id": "2405.02781",
        "abstract url": "https://arxiv.org/abs/2405.02781",
        "title": "Instantaneous Perception of Moving Objects in 3D",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Lidar"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "The perception of 3D motion of surrounding traffic participants is crucial for driving safety. While existing works primarily focus on general large motions, we contend that the instantaneous detection and quantification of subtle motions is equally important as they indicate the nuances in driving behavior that may be safety critical, such as behaviors near a stop sign of parking positions. We delve into this under-explored task, examining its unique challenges and developing our solution, accompanied by a carefully designed benchmark. Specifically, due to the lack of correspondences between consecutive frames of sparse Lidar point clouds, static objects might appear to be moving - the so-called swimming effect. This intertwines with the true object motion, thereby posing ambiguity in accurate estimation, especially for subtle motions. To address this, we propose to leverage local occupancy completion of object point clouds to densify the shape cue, and mitigate the impact of swimming artifacts. The occupancy completion is learned in an end-to-end fashion together with the detection of moving objects and the estimation of their motion, instantaneously as soon as objects start to move. Extensive experiments demonstrate superior performance compared to standard 3D motion estimation approaches, particularly highlighting our method's specialized treatment of subtle motions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2405.02571",
        "abstract url": "https://arxiv.org/abs/2405.02571",
        "title": "ViTALS: Vision Transformer for Action Localization in Surgical Nephrectomy",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Surgical",
                "surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Surgical action localization is a challenging computer vision problem. While it has promising applications including automated training of surgery procedures, surgical workflow optimization, etc., appropriate model design is pivotal to accomplishing this task. Moreover, the lack of suitable medical datasets adds an additional layer of complexity. To that effect, we introduce a new complex dataset of nephrectomy surgeries called UroSlice. To perform the action localization from these videos, we propose a novel model termed as `ViTALS' (Vision Transformer for Action Localization in Surgical Nephrectomy). Our model incorporates hierarchical dilated temporal convolution layers and inter-layer residual connections to capture the temporal correlations at finer as well as coarser granularities. The proposed approach achieves state-of-the-art performance on Cholec80 and UroSlice datasets (89.8% and 66.1% accuracy, respectively), validating its effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Nephrectomy surgery, Surgical Phase Recognition, Surgical Workflow Segmentation, 11 pages, 2 figures, 2 tables"
    },
    {
        "paper id": "2405.02579",
        "abstract url": "https://arxiv.org/abs/2405.02579",
        "title": "Innate Motivation for Robot Swarms by Minimizing Surprise: From Simple Simulations to Real-World Experiments",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "Robot"
            ]
        ],
        "abstract": "Applications of large-scale mobile multi-robot systems can be beneficial over monolithic robots because of higher potential for robustness and scalability. Developing controllers for multi-robot systems is challenging because the multitude of interactions is hard to anticipate and difficult to model. Automatic design using machine learning or evolutionary robotics seem to be options to avoid that challenge, but bring the challenge of designing reward or fitness functions. Generic reward and fitness functions seem unlikely to exist and task-specific rewards often have undesired side effects. Approaches of so-called innate motivation try to avoid the specific formulation of rewards and work instead with different drivers, such as curiosity. Our approach to innate motivation is to minimize surprise, which we implement by maximizing the accuracy of the swarm robot's sensor predictions using neuroevolution. A unique advantage of the swarm robot case is that swarm members populate the robot's environment and can trigger more active behaviors in a self-referential loop. We summarize our previous simulation-based results concerning behavioral diversity, robustness, scalability, and engineered self-organization, and put them into context. In several new studies, we analyze the influence of the optimizer's hyperparameters, the scalability of evolved behaviors, and the impact of realistic robot simulations. Finally, we present results using real robots that show how the reality gap can be bridged.",
        "subjects": [
            "cs.RO",
            "cs.MA",
            "cs.NE"
        ],
        "comment": "Published in IEEE Transactions on Robotics"
    },
    {
        "paper id": "2405.02595",
        "abstract url": "https://arxiv.org/abs/2405.02595",
        "title": "Vision-based 3D occupancy prediction in autonomous driving: a review and outlook",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, autonomous driving has garnered escalating attention for its potential to relieve drivers' burdens and improve driving safety. Vision-based 3D occupancy prediction, which predicts the spatial occupancy status and semantics of 3D voxel grids around the autonomous vehicle from image inputs, is an emerging perception task suitable for cost-effective perception system of autonomous driving. Although numerous studies have demonstrated the greater advantages of 3D occupancy prediction over object-centric perception tasks, there is still a lack of a dedicated review focusing on this rapidly developing field. In this paper, we first introduce the background of vision-based 3D occupancy prediction and discuss the challenges in this task. Secondly, we conduct a comprehensive survey of the progress in vision-based 3D occupancy prediction from three aspects: feature enhancement, deployment friendliness and label efficiency, and provide an in-depth analysis of the potentials and challenges of each category of methods. Finally, we present a summary of prevailing research trends and propose some inspiring future outlooks. To provide a valuable reference for researchers, a regularly updated collection of related papers, datasets, and codes is organized at https://github.com/zya3d/Awesome-3D-Occupancy-Prediction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "20 pages, 20 figures"
    },
    {
        "paper id": "2405.02620",
        "abstract url": "https://arxiv.org/abs/2405.02620",
        "title": "Accelerating Autonomy: Insights from Pro Racers in the Era of Autonomous Racing - An Expert Interview Study",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ]
        ],
        "abstract": "This research aims to investigate professional racing drivers' expertise to develop an understanding of their cognitive and adaptive skills to create new autonomy algorithms. An expert interview study was conducted with 11 professional race drivers, data analysts, and racing instructors from across prominent racing leagues. The interviews were conducted using an exploratory, non-standardized expert interview format guided by a set of prepared questions. The study investigates drivers' exploration strategies to reach their vehicle limits and contrasts them with the capabilities of state-of-the-art autonomous racing software stacks. Participants were questioned about the techniques and skills they have developed to quickly approach and maneuver at the vehicle limit, ultimately minimizing lap times. The analysis of the interviews was grounded in Mayring's qualitative content analysis framework, which facilitated the organization of the data into multiple categories and subcategories. Our findings create insights into human behavior regarding reaching a vehicle's limit and minimizing lap times. We conclude from the findings the development of new autonomy software modules that allow for more adaptive vehicle behavior. By emphasizing the distinct nuances between manual and autonomous driving techniques, the paper encourages further investigation into human drivers' strategies to maximize their vehicles' capabilities.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2405.02633",
        "abstract url": "https://arxiv.org/abs/2405.02633",
        "title": "Risk Assessment for Nonlinear Cyber-Physical Systems under Stealth Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Stealth attacks pose potential risks to cyber-physical systems because they are difficult to detect. Assessing the risk of systems under stealth attacks remains an open challenge, especially in nonlinear systems. To comprehensively quantify these risks, we propose a framework that considers both the reachability of a system and the risk distribution of a scenario. We propose an algorithm to approximate the reachability of a nonlinear system under stealth attacks with a union of standard sets. Meanwhile, we present a method to construct a risk field to formally describe the risk distribution in a given scenario. The intersection relationships of system reachability and risk regions in the risk field indicate that attackers can cause corresponding risks without being detected. Based on this, we introduce a metric to dynamically quantify the risk. Compared to traditional methods, our framework predicts the risk value in an explainable way and provides early warnings for safety control. We demonstrate the effectiveness of our framework through a case study of an automated warehouse.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "12 pages and 9 figures"
    },
    {
        "paper id": "2405.02639",
        "abstract url": "https://arxiv.org/abs/2405.02639",
        "title": "Wall-Climbing Performance of Gecko-inspired Robot with Soft Feet and Digits enhanced by Gravity Compensation",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Gravitational forces can induce deviations in body posture from desired configurations in multi-legged arboreal robot locomotion with low leg stiffness, affecting the contact angle between the swing leg's end-effector and the climbing surface during the gait cycle. The relationship between desired and actual foot positions is investigated here in a leg-stiffness-enhanced model under external forces, focusing on the challenge of unreliable end-effector attachment on climbing surfaces in such robots. Inspired by the difference in ceiling attachment postures of dead and living geckos, feedforward compensation of the stance phase legs is the key to solving this problem. A feedforward gravity compensation (FGC) strategy, complemented by leg coordination, is proposed to correct gravity-influenced body posture and improve adhesion stability by reducing body inclination. The efficacy of this strategy is validated using a quadrupedal climbing robot, EF-I, as the experimental platform. Experimental validation on an inverted surface (ceiling walking) highlight the benefits of the FGC strategy, demonstrating its role in enhancing stability and ensuring reliable end-effector attachment without external assistance. In the experiment, robots without FGC only completed in 3 out of 10 trials, while robots with FGC achieved a 100\\% success rate in the same trials. The speed was substantially greater with FGC, achieved 9.2 mm/s in the trot gait. This underscores the proposed potential of FGC strategy in overcoming the challenges associated with inconsistent end-effector attachment in robots with low leg stiffness, thereby facilitating stable locomotion even at inverted body attitude.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02643",
        "abstract url": "https://arxiv.org/abs/2405.02643",
        "title": "EM-based Algorithm for Unsupervised Clustering of Measurements from a Radar Sensor Network",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "This paper deals with the problem of clustering data returned by a radar sensor network that monitors a region where multiple moving targets are present. The network is formed by nodes with limited functionalities that transmit the estimates of target positions (after a detection) to a fusion center without any association between measurements and targets. To solve the problem at hand, we resort to model-based learning algorithms and instead of applying the plain maximum likelihood approach, due to the related computational requirements, we exploit the latent variable model coupled with the expectation-maximization algorithm. The devised estimation procedure returns posterior probabilities that are used to cluster the huge amount of data collected by the fusion center. Remarkably, we also consider challenging scenarios with an unknown number of targets and estimate it by means of the model order selection rules. The clustering performance of the proposed strategy is compared to that of conventional data-driven methods over synthetic data. The numerical examples point out that the herein proposed solutions can provide reliable clustering performance overcoming the considered competitors.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "12 pages 14 figures"
    },
    {
        "paper id": "2405.02646",
        "abstract url": "https://arxiv.org/abs/2405.02646",
        "title": "Updating Windows Malware Detectors: Balancing Robustness and Regression against Adversarial EXEmples",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Adversarial EXEmples are carefully-perturbed programs tailored to evade machine learning Windows malware detectors, with an on-going effort in developing robust models able to address detection effectiveness. However, even if robust models can prevent the majority of EXEmples, to maintain predictive power over time, models are fine-tuned to newer threats, leading either to partial updates or time-consuming retraining from scratch. Thus, even if the robustness against attacks is higher, the new models might suffer a regression in performance by misclassifying threats that were previously correctly detected. For these reasons, we study the trade-off between accuracy and regression when updating Windows malware detectors, by proposing EXE-scanner, a plugin that can be chained to existing detectors to promptly stop EXEmples without causing regression. We empirically show that previously-proposed hardening techniques suffer a regression of accuracy when updating non-robust models. On the contrary, we show that EXE-scanner exhibits comparable performance to robust models without regression of accuracy, and we show how to properly chain it after the base classifier to obtain the best performance without the need of costly retraining. To foster reproducibility, we openly release source code, along with the dataset of adversarial EXEmples based on state-of-the-art perturbation algorithms.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "11 pages, 3 figures, 7 tables"
    },
    {
        "paper id": "2405.02648",
        "abstract url": "https://arxiv.org/abs/2405.02648",
        "title": "A Conformal Prediction Score that is Robust to Label Noise",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Conformal Prediction (CP) quantifies network uncertainty by building a small prediction set with a pre-defined probability that the correct class is within this set. In this study we tackle the problem of CP calibration based on a validation set with noisy labels. We introduce a conformal score that is robust to label noise. The noise-free conformal score is estimated using the noisy labeled data and the noise level. In the test phase the noise-free score is used to form the prediction set. We applied the proposed algorithm to several standard medical imaging classification datasets. We show that our method outperforms current methods by a large margin, in terms of the average size of the prediction set, while maintaining the required coverage.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02692",
        "abstract url": "https://arxiv.org/abs/2405.02692",
        "title": "Diffeomorphic Transformer-based Abdomen MRI-CT Deformable Image Registration",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "CT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper aims to create a deep learning framework that can estimate the deformation vector field (DVF) for directly registering abdominal MRI-CT images. The proposed method assumed a diffeomorphic deformation. By using topology-preserved deformation features extracted from the probabilistic diffeomorphic registration model, abdominal motion can be accurately obtained and utilized for DVF estimation. The model integrated Swin transformers, which have demonstrated superior performance in motion tracking, into the convolutional neural network (CNN) for deformation feature extraction. The model was optimized using a cross-modality image similarity loss and a surface matching loss. To compute the image loss, a modality-independent neighborhood descriptor (MIND) was used between the deformed MRI and CT images. The surface matching loss was determined by measuring the distance between the warped coordinates of the surfaces of contoured structures on the MRI and CT images. The deformed MRI image was assessed against the CT image using the target registration error (TRE), Dice similarity coefficient (DSC), and mean surface distance (MSD) between the deformed contours of the MRI image and manual contours of the CT image. When compared to only rigid registration, DIR with the proposed method resulted in an increase of the mean DSC values of the liver and portal vein from 0.850 and 0.628 to 0.903 and 0.763, a decrease of the mean MSD of the liver from 7.216 mm to 3.232 mm, and a decrease of the TRE from 26.238 mm to 8.492 mm. The proposed deformable image registration method based on a diffeomorphic transformer provides an effective and efficient way to generate an accurate DVF from an MRI-CT image pair of the abdomen. It could be utilized in the current treatment planning workflow for liver radiotherapy.",
        "subjects": [
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": "18 pages and 4 figures"
    },
    {
        "paper id": "2405.02695",
        "abstract url": "https://arxiv.org/abs/2405.02695",
        "title": "Improved All-Pairs Approximate Shortest Paths in Congested Clique",
        "rating": "-1",
        "keywords": [
            [
                "skeleton"
            ]
        ],
        "abstract": "In this paper, we present new algorithms for approximating All-Pairs Shortest Paths (APSP) in the Congested Clique model. We present randomized algorithms for weighted undirected graphs. Our first contribution is an $O(1)$-approximate APSP algorithm taking just $O(\\log \\log \\log n)$ rounds. Prior to our work, the fastest algorithms that give an $O(1)$-approximation for APSP take $\\operatorname{poly}(\\log{n})$ rounds in weighted undirected graphs, and $\\operatorname{poly}(\\log \\log n)$ rounds in unweighted undirected graphs. If we terminate the execution of the algorithm early, we obtain an $O(t)$-round algorithm that yields an $O \\big( (\\log n)^{1/2^t} \\big) $ distance approximation for a parameter $t$. The trade-off between $t$ and the approximation quality provides flexibility for different scenarios, allowing the algorithm to adapt to specific requirements. In particular, we can get an $O \\big( (\\log n)^{1/2^t} \\big) $-approximation for any constant $t$ in $O(1)$-rounds. Such result was previously known only for the special case that $t=0$. A key ingredient in our algorithm is a lemma that allows to improve an $O(a)$-approximation for APSP to an $O(\\sqrt{a})$-approximation for APSP in $O(1)$ rounds. To prove the lemma, we develop several new tools, including $O(1)$-round algorithms for computing the $k$ closest nodes, a certain type of hopset, and skeleton graphs.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02712",
        "abstract url": "https://arxiv.org/abs/2405.02712",
        "title": "CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions",
        "rating": "-1",
        "keywords": [
            [
                "SQL"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recently, Large Language Models (LLMs) have been demonstrated to possess impressive capabilities in a variety of domains and tasks. We investigate the issue of prompt design in the multi-turn text-to-SQL task and attempt to enhance the LLMs' reasoning capacity when generating SQL queries. In the conversational context, the current SQL query can be modified from the preceding SQL query with only a few operations due to the context dependency. We introduce our method called CoE-SQL which can prompt LLMs to generate the SQL query based on the previously generated SQL query with an edition chain. We also conduct extensive ablation studies to determine the optimal configuration of our approach. Our approach outperforms different in-context learning baselines stably and achieves state-of-the-art performances on two benchmarks SParC and CoSQL using LLMs, which is also competitive to the SOTA fine-tuned models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02716",
        "abstract url": "https://arxiv.org/abs/2405.02716",
        "title": "Sign-Guided Bipartite Graph Hashing for Hamming Space Search",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Bipartite graph hashing (BGH) is extensively used for Top-K search in Hamming space at low storage and inference costs. Recent research adopts graph convolutional hashing for BGH and has achieved the state-of-the-art performance. However, the contributions of its various influencing factors to hashing performance have not been explored in-depth, including the same/different sign count between two binary embeddings during Hamming space search (sign property), the contribution of sub-embeddings at each layer (model property), the contribution of different node types in the bipartite graph (node property), and the combination of augmentation methods. In this work, we build a lightweight graph convolutional hashing model named LightGCH by mainly removing the augmentation methods of the state-of-the-art model BGCH. By analyzing the contributions of each layer and node type to performance, as well as analyzing the Hamming similarity statistics at each layer, we find that the actual neighbors in the bipartite graph tend to have low Hamming similarity at the shallow layer, and all nodes tend to have high Hamming similarity at the deep layers in LightGCH. To tackle these problems, we propose a novel sign-guided framework SGBGH to make improvement, which uses sign-guided negative sampling to improve the Hamming similarity of neighbors, and uses sign-aware contrastive learning to help nodes learn more uniform representations. Experimental results show that SGBGH outperforms BGCH and LightGCH significantly in embedding quality.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02751",
        "abstract url": "https://arxiv.org/abs/2405.02751",
        "title": "Deep Image Restoration For Image Anti-Forensics",
        "rating": "-1",
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While image forensics is concerned with whether an image has been tampered with, image anti-forensics attempts to prevent image forensics methods from detecting tampered images. The competition between these two fields started long before the advancement of deep learning. JPEG compression, blurring and noising, which are simple methods by today's standards, have long been used for anti-forensics and have been the subject of much research in both forensics and anti-forensics. Although these traditional methods are old, they make it difficult to detect fake images and are used for data augmentation in training deep image forgery detection models. In addition to making the image difficult to detect, these methods leave traces on the image and consequently degrade the image quality. Separate image forensics methods have also been developed to detect these traces. In this study, we go one step further and improve the image quality after these methods with deep image restoration models and make it harder to detect the forged image. We evaluate the impact of these methods on image quality. We then test both our proposed methods with deep learning and methods without deep learning on the two best existing image manipulation detection models. In the obtained results, we show how existing image forgery detection models fail against the proposed methods. Code implementation will be publicly available at https://github.com/99eren99/DIRFIAF .",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02753",
        "abstract url": "https://arxiv.org/abs/2405.02753",
        "title": "Unscented Trajectory Optimization",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "In a nutshell, unscented trajectory optimization is the generation of optimal trajectories through the use of an unscented transform. Although unscented trajectory optimization was introduced by the authors about a decade ago, it is reintroduced in this paper as a special instantiation of tychastic optimal control theory. Tychastic optimal control theory (from \\textit{Tyche}, the Greek goddess of chance) avoids the use of a Brownian motion and the resulting It\u00f4 calculus even though it uses random variables across the entire spectrum of a problem formulation. This approach circumvents the enormous technical and numerical challenges associated with stochastic trajectory optimization. Furthermore, it is shown how a tychastic optimal control problem that involves nonlinear transformations of the expectation operator can be quickly instantiated using an unscented transform. These nonlinear transformations are particularly useful in managing trajectory dispersions be it associated with path constraints or targeted values of final-time conditions. This paper also presents a systematic and rapid process for formulating and computing the most desirable tychastic trajectory using an unscented transform. Numerical examples are used to illustrate how unscented trajectory optimization may be used for risk reduction and mission recovery caused by uncertainties and failures.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "math.ST",
            "stat.CO"
        ],
        "comment": "21 pages, 11 figures 2023 AAS/AIAA Astrodynamics Specialist Conference, Big Sky, MT, Aug 13-17, 2023"
    },
    {
        "paper id": "2405.02772",
        "abstract url": "https://arxiv.org/abs/2405.02772",
        "title": "SkinGrip: An Adaptive Soft Robotic Manipulator with Capacitive Sensing for Whole-Limb Bathing Assistance",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "robot"
            ]
        ],
        "abstract": "Robotics presents a promising opportunity for enhancing bathing assistance, potentially to alleviate labor shortages and reduce care costs, while offering consistent and gentle care for individuals with physical disabilities. However, ensuring flexible and efficient cleaning of the human body poses challenges as it involves direct physical contact between the human and the robot, and necessitates simple, safe, and effective control. In this paper, we introduce a soft, expandable robotic manipulator with embedded capacitive proximity sensing arrays, designed for safe and efficient bathing assistance. We conduct a thorough evaluation of our soft manipulator, comparing it with a baseline rigid end effector in a human study involving 12 participants across $96$ bathing trails. Our soft manipulator achieves an an average cleaning effectiveness of 88.8% on arms and 81.4% on legs, far exceeding the performance of the baseline. Participant feedback further validates the manipulator's ability to maintain safety, comfort, and thorough cleaning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02782",
        "abstract url": "https://arxiv.org/abs/2405.02782",
        "title": "A self-supervised text-vision framework for automated brain abnormality detection",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "MRI",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Artificial neural networks trained on large, expert-labelled datasets are considered state-of-the-art for a range of medical image recognition tasks. However, categorically labelled datasets are time-consuming to generate and constrain classification to a pre-defined, fixed set of classes. For neuroradiological applications in particular, this represents a barrier to clinical adoption. To address these challenges, we present a self-supervised text-vision framework that learns to detect clinically relevant abnormalities in brain MRI scans by directly leveraging the rich information contained in accompanying free-text neuroradiology reports. Our training approach consisted of two-steps. First, a dedicated neuroradiological language model - NeuroBERT - was trained to generate fixed-dimensional vector representations of neuroradiology reports (N = 50,523) via domain-specific self-supervised learning tasks. Next, convolutional neural networks (one per MRI sequence) learnt to map individual brain scans to their corresponding text vector representations by optimising a mean square error loss. Once trained, our text-vision framework can be used to detect abnormalities in unreported brain MRI examinations by scoring scans against suitable query sentences (e.g., 'there is an acute stroke', 'there is hydrocephalus' etc.), enabling a range of classification-based applications including automated triage. Potentially, our framework could also serve as a clinical decision support tool, not only by suggesting findings to radiologists and detecting errors in provisional reports, but also by retrieving and displaying examples of pathologies from historical examinations that could be relevant to the current case based on textual descriptors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2405.02785",
        "abstract url": "https://arxiv.org/abs/2405.02785",
        "title": "Fused attention mechanism-based ore sorting network",
        "rating": "-1",
        "keywords": [
            [
                "mineral"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning has had a significant impact on the identification and classification of mineral resources, especially playing a key role in efficiently and accurately identifying different minerals, which is important for improving the efficiency and accuracy of mining. However, traditional ore sorting meth- ods often suffer from inefficiency and lack of accuracy, especially in complex mineral environments. To address these challenges, this study proposes a method called OreYOLO, which incorporates an attentional mechanism and a multi-scale feature fusion strategy, based on ore data from gold and sul- fide ores. By introducing the progressive feature pyramid structure into YOLOv5 and embedding the attention mechanism in the feature extraction module, the detection performance and accuracy of the model are greatly improved. In order to adapt to the diverse ore sorting scenarios and the deployment requirements of edge devices, the network structure is designed to be lightweight, which achieves a low number of parameters (3.458M) and computational complexity (6.3GFLOPs) while maintaining high accuracy (99.3% and 99.2%, respectively). In the experimental part, a target detection dataset containing 6000 images of gold and sulfuric iron ore is constructed for gold and sulfuric iron ore classification training, and several sets of comparison experiments are set up, including the YOLO series, EfficientDet, Faster-RCNN, and CenterNet, etc., and the experiments prove that OreYOLO outperforms the commonly used high-performance object detection of these architectures",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02791",
        "abstract url": "https://arxiv.org/abs/2405.02791",
        "title": "Efficient Text-driven Motion Generation via Latent Consistency Training",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Motion diffusion models have recently proven successful for text-driven human motion generation. Despite their excellent generation performance, they are challenging to infer in real time due to the multi-step sampling mechanism that involves tens or hundreds of repeat function evaluation iterations. To this end, we investigate a motion latent consistency Training (MLCT) for motion generation to alleviate the computation and time consumption during iteration inference. It applies diffusion pipelines to low-dimensional motion latent spaces to mitigate the computational burden of each function evaluation. Explaining the diffusion process with probabilistic flow ordinary differential equation (PF-ODE) theory, the MLCT allows extremely few steps infer between the prior distribution to the motion latent representation distribution via maintaining consistency of the outputs over the trajectory of PF-ODE. Especially, we introduce a quantization constraint to optimize motion latent representations that are bounded, regular, and well-reconstructed compared to traditional variational constraints. Furthermore, we propose a conditional PF-ODE trajectory simulation method, which improves the conditional generation performance with minimal additional training costs. Extensive experiments on two human motion generation benchmarks show that the proposed model achieves state-of-the-art performance with less than 10\\% time cost.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02809",
        "abstract url": "https://arxiv.org/abs/2405.02809",
        "title": "Does Optimal Control Always Benefit from Better Prediction? An Analysis Framework for Predictive Optimal Control",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "The ``prediction + optimal control'' scheme has shown good performance in many applications of automotive, traffic, robot, and building control. In practice, the prediction results are simply considered correct in the optimal control design process. However, in reality, these predictions may never be perfect. Under a conventional stochastic optimal control formulation, it is difficult to answer questions like ``what if the predictions are wrong''. This paper presents an analysis framework for predictive optimal control where the subjective belief about the future is no longer considered perfect. A novel concept called the hidden prediction state is proposed to establish connections among the predictors, the subjective beliefs, the control policies and the objective control performance. Based on this framework, the predictor evaluation problem is analyzed. Three commonly-used predictor evaluation measures, including the mean squared error, the regret and the log-likelihood, are considered. It is shown that neither using the mean square error nor using the likelihood can guarantee a monotonic relationship between the predictor error and the optimal control cost. To guarantee control cost improvement, it is suggested the predictor should be evaluated with the control performance, e.g., using the optimal control cost or the regret to evaluate predictors. Numerical examples and examples from automotive applications with real-world driving data are provided to illustrate the ideas and the results.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.03713",
        "abstract url": "https://arxiv.org/abs/2405.03713",
        "title": "Improve Cross-Modality Segmentation by Treating MRI Images as Inverted CT Scans",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "CT"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Computed tomography (CT) segmentation models frequently include classes that are not currently supported by magnetic resonance imaging (MRI) segmentation models. In this study, we show that a simple image inversion technique can significantly improve the segmentation quality of CT segmentation models on MRI data, by using the TotalSegmentator model, applied to T1-weighted MRI images, as example. Image inversion is straightforward to implement and does not require dedicated graphics processing units (GPUs), thus providing a quick alternative to complex deep modality-transfer models for generating segmentation masks for MRI data.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "3 pages, 2 figures"
    },
    {
        "paper id": "2405.02583",
        "abstract url": "https://arxiv.org/abs/2405.02583",
        "title": "Explainable Interface for Human-Autonomy Teaming: A Survey",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Nowadays, large-scale foundation models are being increasingly integrated into numerous safety-critical applications, including human-autonomy teaming (HAT) within transportation, medical, and defence domains. Consequently, the inherent 'black-box' nature of these sophisticated deep neural networks heightens the significance of fostering mutual understanding and trust between humans and autonomous systems. To tackle the transparency challenges in HAT, this paper conducts a thoughtful study on the underexplored domain of Explainable Interface (EI) in HAT systems from a human-centric perspective, thereby enriching the existing body of research in Explainable Artificial Intelligence (XAI). We explore the design, development, and evaluation of EI within XAI-enhanced HAT systems. To do so, we first clarify the distinctions between these concepts: EI, explanations and model explainability, aiming to provide researchers and practitioners with a structured understanding. Second, we contribute to a novel framework for EI, addressing the unique challenges in HAT. Last, our summarized evaluation framework for ongoing EI offers a holistic perspective, encompassing model performance, human-centered factors, and group task objectives. Based on extensive surveys across XAI, HAT, psychology, and Human-Computer Interaction (HCI), this review offers multiple novel insights into incorporating XAI into HAT systems and outlines future directions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "45 pages, 9 figures"
    },
    {
        "paper id": "2405.02634",
        "abstract url": "https://arxiv.org/abs/2405.02634",
        "title": "Onboard Out-of-Calibration Detection of Deep Learning Models using Conformal Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The black box nature of deep learning models complicate their usage in critical applications such as remote sensing. Conformal prediction is a method to ensure trust in such scenarios. Subject to data exchangeability, conformal prediction provides finite sample coverage guarantees in the form of a prediction set that is guaranteed to contain the true class within a user defined error rate. In this letter we show that conformal prediction algorithms are related to the uncertainty of the deep learning model and that this relation can be used to detect if the deep learning model is out-of-calibration. Popular classification models like Resnet50, Densenet161, InceptionV3, and MobileNetV2 are applied on remote sensing datasets such as the EuroSAT to demonstrate how under noisy scenarios the model outputs become untrustworthy. Furthermore an out-of-calibration detection procedure relating the model uncertainty and the average size of the conformal prediction set is presented.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02664",
        "abstract url": "https://arxiv.org/abs/2405.02664",
        "title": "MedPromptExtract (Medical Data Extraction Tool): Anonymization and Hi-fidelity Automated data extraction using NLP and prompt engineering",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "A major roadblock in the seamless digitization of medical records remains the lack of interoperability of existing records. Extracting relevant medical information required for further treatment planning or even research is a time consuming labour intensive task involving the much valuable time of doctors. In this demo paper we present, MedPromptExtract an automated tool using a combination of semi supervised learning, large language models, natural lanuguage processing and prompt engineering to convert unstructured medical records to structured data which is amenable to further analysis.",
        "subjects": [
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02679",
        "abstract url": "https://arxiv.org/abs/2405.02679",
        "title": "Pr\u00e9visions m\u00e9t\u00e9orologiques bas\u00e9es sur l'intelligence artificielle : une r\u00e9volution peut en cacher une autre",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Artificial intelligence (AI), based on deep-learning algorithm using high-quality reanalysis datasets, is showing enormous potential for weather forecasting. In this context, the European Centre for Medium-Range Weather Forecasts (ECMWF) is developing a new forecasting system based on AI. Verification results of deterministic forecast for now are promising. However, the realism of weather forecasts based on AI is often questioned. Here, different types of realism are identified and we discuss, in particular, the relationship between structural realism and predictability of weather events. Furthermore, a statistical analysis of deterministic forecasts based on AI points to a realism/performance dilemma that a probabilistic approach should help to solve. -- L'intelligence artificielle (IA) bouleverse aujourd'hui le monde de la pr\u00e9vision m\u00e9t\u00e9orologique avec l'utilisation d'algorithmes d'apprentissage profond nourris par des champs de r\u00e9analyses. Dans ce contexte, le Centre Europ\u00e9en pour les Pr\u00e9visions M\u00e9t\u00e9orologiques \u00e0 Moyen Terme (CEPMMT) a d\u00e9cid\u00e9 de d\u00e9velopper un nouveau syst\u00e8me de pr\u00e9visions resposant sur l'IA. Ces pr\u00e9visions, pour le moment de type d\u00e9terministe, montrent des r\u00e9sultats prometteurs. Toutefois, le r\u00e9alisme de ce type de pr\u00e9visions reposant sur l'IA est souvent questionn\u00e9. Ici, nous identifions diff\u00e9rents types de r\u00e9alisme et interrogeons notamment le rapport entre r\u00e9alisme structurel et pr\u00e9visibilit\u00e9 des \u00e9v\u00eanements m\u00e9t\u00e9orologiques. Une analyse statistique de pr\u00e9visions d\u00e9terministes reposant sur l'IA laisse apparaitre un dilemme r\u00e9alisme/performance qu'une approche probabiliste devrait aider \u00e0 r\u00e9soudre.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": "8 pages, in French"
    },
    {
        "paper id": "2405.02711",
        "abstract url": "https://arxiv.org/abs/2405.02711",
        "title": "The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generative Artificial Intelligence (AI) is integrated into everyday technology, including news, education, and social media. AI has further pervaded private conversations as conversational partners, auto-completion, and response suggestions. As social media becomes young people's main method of peer support exchange, we need to understand when and how AI can facilitate and assist in such exchanges in a beneficial, safe, and socially appropriate way. We asked 622 young people to complete an online survey and evaluate blinded human- and AI-generated responses to help-seeking messages. We found that participants preferred the AI-generated response to situations about relationships, self-expression, and physical health. However, when addressing a sensitive topic, like suicidal thoughts, young people preferred the human response. We also discuss the role of training in online peer support exchange and its implications for supporting young people's well-being. Disclaimer: This paper includes sensitive topics, including suicide ideation. Reader discretion is advised.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02770",
        "abstract url": "https://arxiv.org/abs/2405.02770",
        "title": "PhilHumans: Benchmarking Machine Learning for Personal Health",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "Healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The use of machine learning in Healthcare has the potential to improve patient outcomes as well as broaden the reach and affordability of Healthcare. The history of other application areas indicates that strong benchmarks are essential for the development of intelligent systems. We present Personal Health Interfaces Leveraging HUman-MAchine Natural interactions (PhilHumans), a holistic suite of benchmarks for machine learning across different Healthcare settings - talk therapy, diet coaching, emergency care, intensive care, obstetric sonography - as well as different learning settings, such as action anticipation, timeseries modeling, insight mining, language modeling, computer vision, reinforcement learning and program synthesis",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02783",
        "abstract url": "https://arxiv.org/abs/2405.02783",
        "title": "Linear Noise Approximation Assisted Bayesian Inference on Mechanistic Model of Partially Observed Stochastic Reaction Network",
        "rating": "-1.5",
        "keywords": [
            [
                "biomanufacturing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "To support mechanism online learning and facilitate digital twin development for biomanufacturing processes, this paper develops an efficient Bayesian inference approach for partially observed enzymatic stochastic reaction network (SRN), a fundamental building block of multi-scale bioprocess mechanistic model. To tackle the critical challenges brought by the nonlinear stochastic differential equations (SDEs)-based mechanistic model with partially observed state and having measurement error, an interpretable Bayesian updating linear noise approximation (LNA) metamodel, incorporating the structure information of the mechanistic model, is proposed to approximate the likelihood of observations. Then, an efficient posterior sampling approach is developed by utilizing the gradients of the derived likelihood to speed up the convergence of MCMC. The empirical study demonstrates that the proposed approach has a promising performance.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "11 pages, 2 figures"
    },
    {
        "paper id": "2405.02790",
        "abstract url": "https://arxiv.org/abs/2405.02790",
        "title": "Confidential and Protected Disease Classifier using Fully Homomorphic Encryption",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "health",
                "healthcare",
                "diagnosis",
                "Disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the rapid surge in the prevalence of Large Language Models (LLMs), individuals are increasingly turning to conversational AI for initial insights across various domains, including health-related inquiries such as disease diagnosis. Many users seek potential causes on platforms like ChatGPT or Bard before consulting a medical professional for their ailment. These platforms offer valuable benefits by streamlining the diagnosis process, alleviating the significant workload of healthcare practitioners, and saving users both time and money by avoiding unnecessary doctor visits. However, Despite the convenience of such platforms, sharing personal medical data online poses risks, including the presence of malicious platforms or potential eavesdropping by attackers. To address privacy concerns, we propose a novel framework combining FHE and Deep Learning for a secure and private diagnosis system. Operating on a question-and-answer-based model akin to an interaction with a medical practitioner, this end-to-end secure system employs Fully Homomorphic Encryption (FHE) to handle encrypted input data. Given FHE's computational constraints, we adapt deep neural networks and activation functions to the encryted domain. Further, we also propose a faster algorithm to compute summation of ciphertext elements. Through rigorous experiments, we demonstrate the efficacy of our approach. The proposed framework achieves strict security and privacy with minimal loss in performance.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.03711",
        "abstract url": "https://arxiv.org/abs/2405.03711",
        "title": "Guidance Design for Escape Flight Vehicle Using Evolution Strategy Enhanced Deep Reinforcement Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Vehicle",
                "Flight"
            ],
            [
                "navigation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Guidance commands of flight vehicles are a series of data sets with fixed time intervals, thus guidance design constitutes a sequential decision problem and satisfies the basic conditions for using deep reinforcement learning (DRL). In this paper, we consider the scenario where the escape flight vehicle (EFV) generates guidance commands based on DRL and the pursuit flight vehicle (PFV) generates guidance commands based on the proportional navigation method. For the EFV, the objective of the guidance design entails progressively maximizing the residual velocity, subject to the constraint imposed by the given evasion distance. Thus an irregular dynamic max-min problem of extremely large-scale is formulated, where the time instant when the optimal solution can be attained is uncertain and the optimum solution depends on all the intermediate guidance commands generated before. For solving this problem, a two-step strategy is conceived. In the first step, we use the proximal policy optimization (PPO) algorithm to generate the guidance commands of the EFV. The results obtained by PPO in the global search space are coarse, despite the fact that the reward function, the neural network parameters and the learning rate are designed elaborately. Therefore, in the second step, we propose to invoke the evolution strategy (ES) based algorithm, which uses the result of PPO as the initial value, to further improve the quality of the solution by searching in the local space. Simulation results demonstrate that the proposed guidance design method based on the PPO algorithm is capable of achieving a residual velocity of 67.24 m/s, higher than the residual velocities achieved by the benchmark soft actor-critic and deep deterministic policy gradient algorithms. Furthermore, the proposed ES-enhanced PPO algorithm outperforms the PPO algorithm by 2.7\\%, achieving a residual velocity of 69.04 m/s.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "eess.SY"
        ],
        "comment": "13 pages, 13 figures, accepted to appear on IEEE Access, Mar. 2024"
    },
    {
        "paper id": "2405.02603",
        "abstract url": "https://arxiv.org/abs/2405.02603",
        "title": "A Massively Parallel Performance Portable Free-space Spectral Poisson Solver",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Vico et al. (2016) suggest a fast algorithm for computing volume potentials, beneficial to fields with problems requiring the solution of Poisson's equation with free-space boundary conditions, such as the beam and plasma physics communities. Currently, the standard method for solving the free-space Poisson equation is the algorithm of Hockney and Eastwood (1988), which is second order in convergence at best. The algorithm proposed by Vico et al. converges spectrally for sufficiently smooth functions i.e. faster than any fixed order in the number of grid points. In this paper, we implement a performance portable version of the traditional Hockney-Eastwood and the novel Vico-Greengard Poisson solver as part of the IPPL (Independent Parallel Particle Layer) library. For sufficiently smooth source functions, the Vico-Greengard algorithm achieves higher accuracy than the Hockney-Eastwood method with the same grid size, reducing the computational demands of high resolution simulations since one could use coarser grids to achieve them. More concretely, to get a relative error of $10^{-4}$ between the numerical and analytical solution, one requires only $16^3$ grid points in the former, but $128^3$ in the latter, more than a 99% memory footprint reduction. Additionally, we propose an algorithmic improvement to the Vico-Greengard method which further reduces its memory footprint. This is particularly important for GPUs which have limited memory resources, and should be taken into account when selecting numerical algorithms for performance portable codes. Finally, we showcase performance through GPU and CPU scaling studies on the Perlmutter (NERSC) supercomputer, with efficiencies staying above 50% in the strong scaling case.",
        "subjects": [
            "physics.comp-ph",
            "cs.DC"
        ],
        "comment": "18 pages, 11 figures"
    },
    {
        "paper id": "2405.02629",
        "abstract url": "https://arxiv.org/abs/2405.02629",
        "title": "SPARSE: Semantic Tracking and Path Analysis for Attack Investigation in Real-time",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "As the complexity and destructiveness of Advanced Persistent Threat (APT) increase, there is a growing tendency to identify a series of actions undertaken to achieve the attacker's target, called attack investigation. Currently, analysts construct the provenance graph to perform causality analysis on Point-Of-Interest (POI) event for capturing critical events (related to the attack). However, due to the vast size of the provenance graph and the rarity of critical events, existing attack investigation methods suffer from problems of high false positives, high overhead, and high latency. To this end, we propose SPARSE, an efficient and real-time system for constructing critical component graphs (i.e., consisting of critical events) from streaming logs. Our key observation is 1) Critical events exist in a suspicious semantic graph (SSG) composed of interaction flows between suspicious entities, and 2) Information flows that accomplish attacker's goal exist in the form of paths. Therefore, SPARSE uses a two-stage framework to implement attack investigation (i.e., constructing the SSG and performing path-level contextual analysis). First, SPARSE operates in a state-based mode where events are consumed as streams, allowing easy access to the SSG related to the POI event through semantic transfer rule and storage strategy. Then, SPARSE identifies all suspicious flow paths (SFPs) related to the POI event from the SSG, quantifies the influence of each path to filter irrelevant events. Our evaluation on a real large-scale attack dataset shows that SPARSE can generate a critical component graph (~ 113 edges) in 1.6 seconds, which is 2014 X smaller than the backtracking graph (~ 227,589 edges). SPARSE is 25 X more effective than other state-of-the-art techniques in filtering irrelevant edges.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02672",
        "abstract url": "https://arxiv.org/abs/2405.02672",
        "title": "Effects of Realism and Representation on Self-Embodied Avatars in Immersive Virtual Environments",
        "rating": "-2",
        "keywords": [
            [
                "depth",
                "avatar"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Virtual Reality (VR) has recently gained traction with many new and ever more affordable devices being released. The increase in popularity of this paradigm of interaction has given birth to new applications and has attracted casual consumers to experience VR. Providing a self-embodied representation (avatar) of users' full bodies inside shared virtual spaces can improve the VR experience and make it more engaging to both new and experienced users . This is especially important in fully immersive systems, where the equipment completely occludes the real world making self awareness problematic. Indeed, the feeling of presence of the user is highly influenced by their virtual representations, even though small flaws could lead to uncanny valley side-effects. Following previous research, we would like to assess whether using a third-person perspective could also benefit the VR experience, via an improved spatial awareness of the user's virtual surroundings. In this paper we investigate realism and perspective of self-embodied representation in VR setups in natural tasks, such as walking and avoiding obstacles. We compare both First and Third-Person perspectives with three different levels of realism in avatar representation. These range from a stylized abstract avatar, to a \"realistic\" mesh-based humanoid representation and a point-cloud rendering. The latter uses data captured via depth-sensors and mapped into a virtual self inside the Virtual Environment. We present a throughout evaluation and comparison of these different representations, describing a series of guidelines for self-embodied VR applications. The effects of the uncanny valley are also discussed in the context of navigation and reflex-based tasks.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02676",
        "abstract url": "https://arxiv.org/abs/2405.02676",
        "title": "Hand-Object Interaction Controller (HOIC): Deep Reinforcement Learning for Reconstructing Interactions with Physics",
        "rating": "-2",
        "keywords": [
            [
                "RGBD"
            ],
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Hand manipulating objects is an important interaction motion in our daily activities. We faithfully reconstruct this motion with a single RGBD camera by a novel deep reinforcement learning method to leverage physics. Firstly, we propose object compensation control which establishes direct object control to make the network training more stable. Meanwhile, by leveraging the compensation force and torque, we seamlessly upgrade the simple point contact model to a more physical-plausible surface contact model, further improving the reconstruction accuracy and physical correctness. Experiments indicate that without involving any heuristic physical rules, this work still successfully involves physics in the reconstruction of hand-object interactions which are complex motions hard to imitate with deep reinforcement learning. Our code and data are available at https://github.com/hu-hy17/HOIC.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "SIGGRAPH 2024 Conference Track"
    },
    {
        "paper id": "2405.02719",
        "abstract url": "https://arxiv.org/abs/2405.02719",
        "title": "Active Signal Emitter Placement In Complex Environments",
        "rating": "-2",
        "keywords": [
            [
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Placement of electromagnetic signal emitting devices, such as light sources, has important usage in for signal coverage tasks. Automatic placement of these devices is challenging because of the complex interaction of the signal and environment due to reflection, refraction and scattering. In this work, we iteratively improve the placement of these devices by interleaving device placement and sensing actions, correcting errors in the model of the signal propagation. To this end, we propose a novel factor-graph based belief model which combines the measurements taken by the robot and an analytical light propagation model. This model allows accurately modelling the uncertainty of the light propagation with respect to the obstacles, which greatly improves the informative path planning routine. Additionally, we propose a method for determining when to re-plan the emitter placements to balance a trade-off between information about a specific configuration and frequent updating of the configuration. This method incorporates the uncertainty from belief model to adaptively determine when re-configuration is needed. We find that our system has a 9.8% median error reduction compared to a baseline system in simulations in the most difficult environment. We also run on-robot tests and determine that our system performs favorably compared to the baseline.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to RA-L"
    },
    {
        "paper id": "2405.02778",
        "abstract url": "https://arxiv.org/abs/2405.02778",
        "title": "Improve Temporal Awareness of LLMs for Sequential Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated impressive zero-shot abilities in solving a wide range of general-purpose tasks. However, it is empirically found that LLMs fall short in recognizing and utilizing temporal information, rendering poor performance in tasks that require an understanding of sequential data, such as sequential recommendation. In this paper, we aim to improve temporal awareness of LLMs by designing a principled prompting framework inspired by human cognitive processes. Specifically, we propose three prompting strategies to exploit temporal information within historical interactions for LLM-based sequential recommendation. Besides, we emulate divergent thinking by aggregating LLM ranking results derived from these strategies. Evaluations on MovieLens-1M and Amazon Review datasets indicate that our proposed method significantly enhances the zero-shot capabilities of LLMs in sequential recommendation tasks.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2405.02784",
        "abstract url": "https://arxiv.org/abs/2405.02784",
        "title": "MR-Transformer: Vision Transformer for Total Knee Replacement Prediction Using Magnetic Resonance Imaging",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosis",
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "A transformer-based deep learning model, MR-Transformer, was developed for total knee replacement (TKR) prediction using magnetic resonance imaging (MRI). The model incorporates the ImageNet pre-training and captures three-dimensional (3D) spatial correlation from the MR images. The performance of the proposed model was compared to existing state-of-the-art deep learning models for knee injury diagnosis using MRI. Knee MR scans of four different tissue contrasts from the Osteoarthritis Initiative and Multicenter Osteoarthritis Study databases were utilized in the study. Experimental results demonstrated the state-of-the-art performance of the proposed model on TKR prediction using MRI.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02788",
        "abstract url": "https://arxiv.org/abs/2405.02788",
        "title": "Antenna Failure Resilience: Deep Learning-Enabled Robust DOA Estimation with Single Snapshot Sparse Arrays",
        "rating": "-2",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "radar"
            ]
        ],
        "abstract": "Recent advancements in Deep Learning (DL) for Direction of Arrival (DOA) estimation have highlighted its superiority over traditional methods, offering faster inference, enhanced super-resolution, and robust performance in low Signal-to-Noise Ratio (SNR) environments. Despite these advancements, existing research predominantly focuses on multi-snapshot scenarios, a limitation in the context of automotive radar systems which demand high angular resolution and often rely on limited snapshots, sometimes as scarce as a single snapshot. Furthermore, the increasing interest in sparse arrays for automotive radar, owing to their cost-effectiveness and reduced antenna element coupling, presents additional challenges including susceptibility to random sensor failures. This paper introduces a pioneering DL framework featuring a sparse signal augmentation layer, meticulously crafted to bolster single snapshot DOA estimation across diverse sparse array setups and amidst antenna failures. To our best knowledge, this is the first work to tackle this issue. Our approach improves the adaptability of deep learning techniques to overcome the unique difficulties posed by sparse arrays with single snapshot. We conduct thorough evaluations of our network's performance using simulated and real-world data, showcasing the efficacy and real-world viability of our proposed solution. The code and real-world dataset employed in this study are available at https://github.com/ruxinzh/Deep_RSA_DOA.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Invited paper for IEEE Asilomar conference 2024"
    },
    {
        "paper id": "2405.03715",
        "abstract url": "https://arxiv.org/abs/2405.03715",
        "title": "Iterative Filter Pruning for Concatenation-based CNN Architectures",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "FPGA"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Model compression and hardware acceleration are essential for the resource-efficient deployment of deep neural networks. Modern object detectors have highly interconnected convolutional layers with concatenations. In this work, we study how pruning can be applied to such architectures, exemplary for YOLOv7. We propose a method to handle concatenation layers, based on the connectivity graph of convolutional layers. By automating iterative sensitivity analysis, pruning, and subsequent model fine-tuning, we can significantly reduce model size both in terms of the number of parameters and FLOPs, while keeping comparable model accuracy. Finally, we deploy pruned models to FPGA and NVIDIA Jetson Xavier AGX. Pruned models demonstrate a 2x speedup for the convolutional layers in comparison to the unpruned counterparts and reach real-time capability with 14 FPS on FPGA. Our code is available at https://github.com/fzi-forschungszentrum-informatik/iterative-yolo-pruning.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for publication at IJCNN 2024"
    },
    {
        "paper id": "2405.02602",
        "abstract url": "https://arxiv.org/abs/2405.02602",
        "title": "Astro-NER -- Astronomy Named Entity Recognition: Is GPT a Good Domain Expert Annotator?",
        "rating": "-3",
        "keywords": [
            [
                "Astronomy"
            ],
            [
                "Named Entity Recognition"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we address one of the challenges of developing NER models for scholarly domains, namely the scarcity of suitable labeled data. We experiment with an approach using predictions from a fine-tuned LLM model to aid non-domain experts in annotating scientific entities within astronomy literature, with the goal of uncovering whether such a collaborative process can approximate domain expertise. Our results reveal moderate agreement between a domain expert and the LLM-assisted non-experts, as well as fair agreement between the domain expert and the LLM model's predictions. In an additional experiment, we compare the performance of finetuned and default LLMs on this task. We have also introduced a specialized scientific entity annotation scheme for astronomy, validated by a domain expert. Our approach adopts a scholarly research contribution-centric perspective, focusing exclusively on scientific entities relevant to the research theme. The resultant dataset, containing 5,000 annotated astronomy article titles, is made publicly available.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IT"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2405.02630",
        "abstract url": "https://arxiv.org/abs/2405.02630",
        "title": "cuTN-QSVM: cuTensorNet-accelerated Quantum Support Vector Machine with cuQuantum SDK",
        "rating": "-3",
        "keywords": [
            [
                "Support Vector Machine"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "This paper investigates the application of Quantum Support Vector Machines (QSVMs) with an emphasis on the computational advancements enabled by NVIDIA's cuQuantum SDK, especially leveraging the cuTensorNet library. We present a simulation workflow that substantially diminishes computational overhead, as evidenced by our experiments, from exponential to quadratic cost. While state vector simulations become infeasible for qubit counts over 50, our evaluation demonstrates that cuTensorNet speeds up simulations to be completed within seconds on the NVIDIA A100 GPU, even for qubit counts approaching 784. By employing multi-GPU processing with Message Passing Interface (MPI), we document a marked decrease in computation times, effectively demonstrating the strong linear speedup of our approach for increasing data sizes. This enables QSVMs to operate efficiently on High-Performance Computing (HPC) systems, thereby opening a new window for researchers to explore complex quantum algorithms that have not yet been investigated. In accuracy assessments, our QSVM achieves up to 95\\% on challenging classifications within the MNIST dataset for training sets larger than 100 instances, surpassing the capabilities of classical SVMs. These advancements position cuTensorNet within the cuQuantum SDK as a pivotal tool for scaling quantum machine learning simulations and potentially signpost the seamless integration of such computational strategies as pivotal within the Quantum-HPC ecosystem.",
        "subjects": [
            "quant-ph",
            "cs.DC",
            "cs.SE"
        ],
        "comment": "10 pages, 14 figures"
    },
    {
        "paper id": "2405.02681",
        "abstract url": "https://arxiv.org/abs/2405.02681",
        "title": "Spider RIS: Mobilizing Intelligent Surfaces for Enhanced Wireless Communications",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this study, we introduce Spider RIS technology, which offers an innovative solution to the challenges encountered in movable antennas (MAs) and unmanned aerial vehicle (UAV)-enabled communication systems. By combining the dynamic adaptation capability of MAs and the flexible location advantages of UAVs, this technology offers a dynamic and movable RIS, which can flexibly optimize physical locations within the two-dimensional movement platform. Spider RIS aims to enhance the communication efficiency and reliability of wireless networks, particularly in obstructive environments, by elevating the signal quality and achievable rate. The motivation of Spider RIS is based on the ability to fully exploit the spatial variability of wireless channels and maximize channel capacity even with a limited number of reflecting elements by overcoming the limitations of traditional fixed RIS and energy-intensive UAV systems. Considering the geometry-based millimeter wave channel model, we present the design of a three-stage angular-based hybrid beamforming system empowered by Spider RIS: First, analog beamformers are designed using angular information, followed by the generation of digital precoder/combiner based on the effective channel observed from baseband stage. Subsequently, the joint dynamic positioning with phase shift design of the Spider RIS is optimized using particle swarm optimization, maximizing the achievable rate of the systems.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Accepted in 2024 EuCNC and 6G Summit, Antwerp, Belgium, 3-6 June 2024"
    },
    {
        "paper id": "2405.02762",
        "abstract url": "https://arxiv.org/abs/2405.02762",
        "title": "TK-Planes: Tiered K-Planes with High Dimensional Feature Vectors for Dynamic UAV-based Scenes",
        "rating": "-3",
        "keywords": [
            [
                "NeRF"
            ],
            [
                "vehicle"
            ],
            [
                "UAV"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present a new approach to bridge the domain gap between synthetic and real-world data for un- manned aerial vehicle (UAV)-based perception. Our formu- lation is designed for dynamic scenes, consisting of moving objects or human actions, where the goal is to recognize the pose or actions. We propose an extension of K-Planes Neural Radiance Field (NeRF), wherein our algorithm stores a set of tiered feature vectors. The tiered feature vectors are generated to effectively model conceptual information about a scene as well as an image decoder that transforms output feature maps into RGB images. Our technique leverages the information amongst both static and dynamic objects within a scene and is able to capture salient scene attributes of high altitude videos. We evaluate its performance on challenging datasets, including Okutama Action and UG2, and observe considerable improvement in accuracy over state of the art aerial perception algorithms.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "8 pages, submitted to IROS2024"
    },
    {
        "paper id": "2405.02696",
        "abstract url": "https://arxiv.org/abs/2405.02696",
        "title": "DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent Diffusion Model",
        "rating": "-3.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Latent Diffusion Models (LDMs) enable a wide range of applications but raise ethical concerns regarding illegal utilization.Adding watermarks to generative model outputs is a vital technique employed for copyright tracking and mitigating potential risks associated with AI-generated content. However, post-hoc watermarking techniques are susceptible to evasion. Existing watermarking methods for LDMs can only embed fixed messages. Watermark message alteration requires model retraining. The stability of the watermark is influenced by model updates and iterations. Furthermore, the current reconstruction-based watermark removal techniques utilizing variational autoencoders (VAE) and diffusion models have the capability to remove a significant portion of watermarks. Therefore, we propose a novel technique called DiffuseTrace. The goal is to embed invisible watermarks in all generated images for future detection semantically. The method establishes a unified representation of the initial latent variables and the watermark information through training an encoder-decoder model. The watermark information is embedded into the initial latent variables through the encoder and integrated into the sampling process. The watermark information is extracted by reversing the diffusion process and utilizing the decoder. DiffuseTrace does not rely on fine-tuning of the diffusion model components. The watermark is embedded into the image space semantically without compromising image quality. The encoder-decoder can be utilized as a plug-in in arbitrary diffusion models. We validate through experiments the effectiveness and flexibility of DiffuseTrace. DiffuseTrace holds an unprecedented advantage in combating the latest attacks based on variational autoencoders and Diffusion Models.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02731",
        "abstract url": "https://arxiv.org/abs/2405.02731",
        "title": "Systematic Review: Anomaly Detection in Connected and Autonomous Vehicles",
        "rating": "-3.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "SVM"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This systematic review focuses on anomaly detection for connected and autonomous vehicles. The initial database search identified 2160 articles, of which 203 were included in this review after rigorous screening and assessment. This study revealed that the most commonly used Artificial Intelligence (AI) algorithms employed in anomaly detection are neural networks like LSTM, CNN, and autoencoders, alongside one-class SVM. Most anomaly-based models were trained using real-world operational vehicle data, although anomalies, such as attacks and faults, were often injected artificially into the datasets. These models were evaluated mostly using five key evaluation metrics: recall, accuracy, precision, F1-score, and false positive rate. The most frequently used selection of evaluation metrics used for anomaly detection models were accuracy, precision, recall, and F1-score. This systematic review presents several recommendations. First, there is a need to incorporate multiple evaluation metrics to provide a comprehensive assessment of the anomaly detection models. Second, only a small proportion of the studies have made their models open source, indicating a need to share models publicly to facilitate collaboration within the research community, and to validate and compare findings effectively. Third, there is a need for benchmarking datasets with predefined anomalies or cyberattacks to test and improve the effectiveness of the proposed anomaly-based detection models. Furthermore, there is a need for future research to investigate the deployment of anomaly detection to a vehicle to assess its performance on the road. There is a notable lack of research done on intrusion detection systems using different protocols to CAN, such as Ethernet and FlexRay.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 2 tables, 5 figures"
    },
    {
        "paper id": "2405.02585",
        "abstract url": "https://arxiv.org/abs/2405.02585",
        "title": "Maximal Guesswork Leakage",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce the study of information leakage through \\emph{guesswork}, the minimum expected number of guesses required to guess a random variable. In particular, we define \\emph{maximal guesswork leakage} as the multiplicative decrease, upon observing $Y$, of the guesswork of a randomized function of $X$, maximized over all such randomized functions. We also study a pointwise form of the leakage which captures the leakage due to the release of a single realization of $Y$. We also study these two notions of leakage with oblivious (or memoryless) guessing. We obtain closed-form expressions for all these leakage measures, with the exception of one. Specifically, we are able to obtain closed-form expression for maximal guesswork leakage for the binary erasure source only; deriving expressions for arbitrary sources appears challenging. Some of the consequences of our results are -- a connection between guesswork and differential privacy and a new operational interpretation to maximal $\u03b1$-leakage in terms of guesswork.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages. Extended version of a paper accepted to ISIT 2024"
    },
    {
        "paper id": "2405.02590",
        "abstract url": "https://arxiv.org/abs/2405.02590",
        "title": "Performance Evaluation of PAC Decoding with Deep Neural Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "By concatenating a polar transform with a convolutional transform, polarization-adjusted convolutional (PAC) codes can reach the dispersion approximation bound in certain rate cases. However, the sequential decoding nature of traditional PAC decoding algorithms results in high decoding latency. Due to the parallel computing capability, deep neural network (DNN) decoders have emerged as a promising solution. In this paper, we propose three types of DNN decoders for PAC codes: multi-layer perceptron (MLP), convolutional neural network (CNN), and recurrent neural network (RNN). The performance of these DNN decoders is evaluated through extensive simulation. Numerical results show that the MLP decoder has the best error-correction performance under a similar model parameter number.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02599",
        "abstract url": "https://arxiv.org/abs/2405.02599",
        "title": "Assembling ensembling: An adventure in approaches across disciplines",
        "rating": "-10",
        "keywords": [],
        "abstract": "When we think of model ensembling or ensemble modeling, there are many possibilities that come to mind in different disciplines. For example, one might think of a set of descriptions of a phenomenon in the world, perhaps a time series or a snapshot of multivariate space, and perhaps that set is comprised of data-independent descriptions, or perhaps it is quite intentionally fit *to* data, or even a suite of data sets with a common theme or intention. The very meaning of 'ensemble' - a collection together - conjures different ideas across and even within disciplines approaching phenomena. In this paper, we present a typology of the scope of these potential perspectives. It is not our goal to present a review of terms and concepts, nor is it to convince all disciplines to adopt a common suite of terms, which we view as futile. Rather, our goal is to disambiguate terms, concepts, and processes associated with 'ensembles' and 'ensembling' in order to facilitate communication, awareness, and possible adoption of tools across disciplines.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "33 pages, 4 figures"
    },
    {
        "paper id": "2405.02604",
        "abstract url": "https://arxiv.org/abs/2405.02604",
        "title": "Interleave Frequency Division Multiplexing",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this letter, we study interleave frequency division multiplexing (IFDM) for multicarrier modulation in static multipath and mobile time-varying channels, which outperforms orthogonal frequency division multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine frequency division multiplexing (AFDM) by considering practical advanced detectors. The fundamental principle underlying existing modulation techniques is to establish sparse equivalent channel matrices in order to facilitate the design of low-complexity detection algorithms for signal recovery, making a trade-off between performance and implementation complexity. In contrast, the proposed IFDM establishes an equivalent fully dense and right-unitarily invariant channel matrix with the goal of achieving channel capacity, ensuring that the signals undergo sufficient statistical channel fading. Meanwhile, a low-complexity and replica maximum a posteriori (MAP)-optimal cross-domain memory approximate message passing (CD-MAMP) detector is proposed for IFDM by exploiting the sparsity of the time-domain channel and the unitary invariance in interleave-frequency-domain channel. Numerical results show that IFDM with extremely low-complexity CD-MAMP outperforms OFDM, OTFS, and AFDM with state-of-the-art orthogonal approximate message passing detectors, particularly at low velocities.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Accepted by IEEE Wireless Communications Letters"
    },
    {
        "paper id": "2405.02606",
        "abstract url": "https://arxiv.org/abs/2405.02606",
        "title": "Communication Modalities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Epistemic analysis of distributed systems is one of the biggest successes among applications of logic in computer science. The reason for that is that agents' actions are necessarily guided by their knowledge. Thus, epistemic modal logic, with its knowledge and belief modalities (and group versions thereof), has played a vital role in establishing both impossibility results and necessary conditions for solvable distributed tasks. In distributed systems, knowledge is largely attained via communication. It has been standard in both distributed systems and dynamic epistemic logic to treat incoming messages as trustworthy, thus, creating difficulties in the epistemic analysis of byzantine distributed systems where faulty agents may lie. In this paper, we argue that handling such communication scenarios calls for additional modalities representing the informational content of messages that should not be taken at face value. We present two such modalities: hope for the case of fully byzantine agents and creed for non-uniform communication protocols in general.",
        "subjects": [
            "cs.DC",
            "cs.LO",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02611",
        "abstract url": "https://arxiv.org/abs/2405.02611",
        "title": "Predicting the impact of water transport on carbonation-induced corrosion in variably saturated reinforced concrete",
        "rating": "-10",
        "keywords": [],
        "abstract": "A modelling framework for predicting carbonation-induced corrosion in reinforced concrete is presented. The framework constituents include a new model for water transport in cracked concrete, a link between corrosion current density and water saturation, and a theory for characterising concrete carbonation. The theoretical framework is numerically implemented using the finite element method and model predictions are extensively benchmarked against experimental data. The results show that the model is capable of accurately predicting carbonation progress, as well as wetting and drying of cracked and uncracked concrete, revealing a very good agreement with independent experiments from a set of consistent parameters. In addition, insight is gained into the evolution of carbonation penetration and corrosion current density under periodic wetting and drying conditions. Among others, we find that cyclic wetting periods significantly speed up the carbonation progress and that the induced corrosion current density is very sensitive to concrete saturation.",
        "subjects": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.app-ph",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02615",
        "abstract url": "https://arxiv.org/abs/2405.02615",
        "title": "TetraBFT: Reducing Latency of Unauthenticated, Responsive BFT Consensus",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents TetraBFT, a novel unauthenticated Byzantine fault tolerant protocol for solving consensus in partial synchrony, eliminating the need for public key cryptography and ensuring resilience against computationally unbounded adversaries. TetraBFT has several compelling features: it necessitates only constant local storage, has optimal communication complexity, satisfies optimistic responsiveness -- allowing the protocol to operate at actual network speeds under ideal conditions -- and can achieve consensus in just 5 message delays, which outperforms all known unauthenticated protocols achieving the other properties listed. We validate the correctness of TetraBFT through rigorous security analysis and formal verification. Furthermore, we extend TetraBFT into a multi-shot, chained consensus protocol, making a pioneering effort in applying pipelining techniques to unauthenticated protocols. This positions TetraBFT as a practical and deployable solution for blockchain systems aiming for high efficiency.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "The full version of the PODC 2024 paper"
    },
    {
        "paper id": "2405.02621",
        "abstract url": "https://arxiv.org/abs/2405.02621",
        "title": "Intersecting families with covering number $3$",
        "rating": "-10",
        "keywords": [],
        "abstract": "A covering number of a family is the size of the smallest set that intersects all sets from the family. In 1978 Frankl determined for $n\\ge n_0(k)$ the largest intersecting family of $k$-element subsets of $[n]$ with covering number $3$. In this paper, we essentially settle this problem, showing that the same family is extremal for any $k\\ge 100$ and $n>2k$.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:1810.00920"
    },
    {
        "paper id": "2405.02647",
        "abstract url": "https://arxiv.org/abs/2405.02647",
        "title": "SubwayMeshDTN: Exploring Opportunistic Delay Tolerant Routing Protocols when Disseminating Emergency Alerts on a Smart City Subway Network",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper seeks to understand the effectiveness of using multi-dimensional opportunistic delay-tolerant network (DTN) routing protocols, specifically Epidemic and MaxProp, in the context of New York City (NYC) metropolitan subway network. We examine how efficiently emergency messages spread through mobile, self-configuring, edge-based movement patterns on the train network to understand and propose solutions for improving communication in subterranean environments. Since DTNs are able to store, carry and forward messages through intermediate edges, this paper benchmarks both Wi-Fi and Bluetooth topologies to compare and critically evaluate movement patterns, latency, overheads and delivery rates on pseudo-realistic underground traces. We also show that the accordion effect is predominant in these networks, and therefore, the most effective protocol configurations vary.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02660",
        "abstract url": "https://arxiv.org/abs/2405.02660",
        "title": "AFDM Channel Estimation in Multi-Scale Multi-Lag Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "Affine Frequency Division Multiplexing (AFDM) is a brand new chirp-based multi-carrier (MC) waveform for high mobility communications, with promising advantages over Orthogonal Frequency Division Multiplexing (OFDM) and other MC waveforms. Existing AFDM research focuses on wireless communication at high carrier frequency (CF), which typically considers only Doppler frequency shift (DFS) as a result of mobility, while ignoring the accompanied Doppler time scaling (DTS) on waveform. However, for underwater acoustic (UWA) communication at much lower CF and propagating at speed of sound, the DTS effect could not be ignored and poses significant challenges for channel estimation. This paper analyzes the channel frequency response (CFR) of AFDM under multi-scale multi-lag (MSML) channels, where each propagating path could have different delay and DFS/DTS. Based on the newly derived input-output formula and its characteristics, two new channel estimation methods are proposed, i.e., AFDM with iterative multi-index (AFDM-IMI) estimation under low to moderate DTS, and AFDM with orthogonal matching pursuit (AFDM-OMP) estimation under high DTS. Numerical results confirm the effectiveness of the proposed methods against the original AFDM channel estimation method. Moreover, the resulted AFDM system outperforms OFDM as well as Orthogonal Chirp Division Multiplexing (OCDM) in terms of channel estimation accuracy and bit error rate (BER), which is consistent with our theoretical analysis based on CFR overlap probability (COP), mutual incoherent property (MIP) and channel diversity gain under MSML channels.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 6 figures. Investigate AFDM under underwater multi-scale multi-lag channels. Derive the new input-output formula with the impact of Doppler time scaling. Propose two new channel estimation methods to tackle different level of Doppler factors. Perform diversity analyis based on CFR overlap probability (COP) and mutual incoherent property (MIP)"
    },
    {
        "paper id": "2405.02665",
        "abstract url": "https://arxiv.org/abs/2405.02665",
        "title": "Metric Differential Privacy at the User-Level",
        "rating": "-10",
        "keywords": [],
        "abstract": "Metric differential privacy (DP) provides heterogeneous privacy guarantees based on a distance between the pair of inputs. It is a widely popular notion of privacy since it captures the natural privacy semantics for many applications (such as, for location data) and results in better utility than standard DP. However, prior work in metric DP has primarily focused on the \\textit{item-level} setting where every user only reports a single data item. A more realistic setting is that of user-level DP where each user contributes multiple items and privacy is then desired at the granularity of the user's \\textit{entire} contribution. In this paper, we initiate the study of metric DP at the user-level. Specifically, we use the earth-mover's distance ($d_\\textsf{EM}$) as our metric to obtain a notion of privacy as it captures both the magnitude and spatial aspects of changes in a user's data. We make three main technical contributions. First, we design two novel mechanisms under $d_\\textsf{EM}$-DP to answer linear queries and item-wise queries. Specifically, our analysis for the latter involves a generalization of the privacy amplification by shuffling result which may be of independent interest. Second, we provide a black-box reduction from the general unbounded to bounded $d_\\textsf{EM}$-DP (size of the dataset is fixed and public) with a novel sampling based mechanism. Third, we show that our proposed mechanisms can provably provide improved utility over user-level DP, for certain types of linear queries and frequency estimation.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02682",
        "abstract url": "https://arxiv.org/abs/2405.02682",
        "title": "Deduplicator: When Computation Reuse Meets Load Balancing at the Network Edge",
        "rating": "-10",
        "keywords": [],
        "abstract": "Load balancing has been a fundamental building block of cloud and, more recently, edge computing environments. At the same time, in edge computing environments, prior research has highlighted that applications operate on similar (correlated) data. Based on this observation, prior research has advocated for the direction of \"computation reuse\", where the results of previously executed computational tasks are stored at the edge and are reused (if possible) to satisfy incoming tasks with similar input data, instead of executing incoming tasks from scratch. Both load balancing and computation reuse are critical to the deployment of scalable edge computing environments, yet they are contradictory in nature. In this paper, we propose the Deduplicator, a middlebox that aims to facilitate both load balancing and computation reuse at the edge. The Deduplicator features mechanisms to identify and deduplicate similar tasks offloaded by user devices, collect information about the usage of edge servers' resources, manage the addition of new edge servers and the failures of existing edge servers, and ultimately balance the load imposed on edge servers. Our evaluation results demonstrate that the Deduplicator achieves up to 20% higher percentages of computation reuse compared to several other load balancing approaches, while also effectively balancing the distribution of tasks among edge servers at line rate.",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "comment": "Accepted for publication by IFIP Networking 2024"
    },
    {
        "paper id": "2405.02683",
        "abstract url": "https://arxiv.org/abs/2405.02683",
        "title": "Two-Dimensional Multi-Access Coded Caching with Multiple Transmit Antennas",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work introduces a multi-antenna coded caching problem in a two-dimensional multi-access network, where a server with $L$ transmit antennas and $N$ files communicates to $K_1K_2$ users, each with a single receive antenna, through a wireless broadcast link. The network consists of $K_1K_2$ cache nodes and $K_1K_2$ users. The cache nodes, each with capacity $M$, are placed on a rectangular grid with $K_1$ rows and $K_2$ columns, and the users are placed regularly on the square grid such that a user can access $r^2$ neighbouring caches in a cyclic wrap-around fashion. For a given cache memory $M$, the goal of the coded caching problem is to serve the user demands with a minimum delivery time. We propose a solution for the aforementioned coded caching problem by designing two arrays: a caching array and a delivery array. Further, we present two classes of caching and delivery arrays and obtain corresponding multi-access coded caching schemes. The first scheme achieves a normalized delivery time (NDT) $\\frac{K_1K_2(1-r^2\\frac{M}{N})}{L+K_1K_2\\frac{M}{N}}$. The second scheme achieves an NDT $\\frac{K_1K_2(1-r^2\\frac{M}{N})}{L+K_1K_2r^2\\frac{M}{N}}$ when $M/N=1/K_1K_2$ and $L=K_1K_2-r^2$, which is optimal under uncoded placement and one-shot delivery.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "A shorter version is accepted for presentation in ISIT 2024. 8 pages, 4 figures"
    },
    {
        "paper id": "2405.02687",
        "abstract url": "https://arxiv.org/abs/2405.02687",
        "title": "Placement Delivery Arrays for Coded Caching with Shared and Private Caches",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a coded caching network consisting of a server with a library of $N$ files connected to $K$ users, where each user is equipped with a dedicated cache of size $M_p$ units. In addition to that, the network consists of $\u039b\\leq K$ helper caches, each with a size $M_h$ units. Each helper cache can serve an arbitrary number of users; however, each user can access only a single helper cache. Also, we assume that the server knows the user-to-helper cache association, defined as the sets of users connected to each helper cache, during the cache placement phase. We propose a solution for the aforementioned coded caching problem by introducing a combinatorial structure called a Shared and Private Placement Delivery Array (SP-PDA). These SP-PDAs describe the helper cache placement, private cache placement, and the server transmissions in a single array. Further, we propose a novel construction of SP-PDAs using two Placement Delivery Arrays (PDAs). Interestingly, we observe that the permutations of the columns of the two chosen PDAs result in SP-PDAs with different performances. Moreover, we characterize the conditions for selecting the best column permutations of the chosen PDAs. Furthermore, the coded caching schemes resulting from SP-PDAs subsume two existing coded caching schemes as special cases. Additionally, SP-PDAs enable the construction of coded caching schemes with much smaller subpacketization numbers -subpacketization number is defined as the number of subfiles to which a file is divided- compared to the existing schemes, without paying much in terms of rate (the size of the transmission in the delivery phase).",
        "subjects": [
            "cs.IT"
        ],
        "comment": "A shorter version is accepted for presentation in ISIT 2024. 11 pages, 4 figures"
    },
    {
        "paper id": "2405.02693",
        "abstract url": "https://arxiv.org/abs/2405.02693",
        "title": "TV White Space and LTE Network Optimization towards Energy Efficiency in Suburban and Rural Scenarios",
        "rating": "-10",
        "keywords": [],
        "abstract": "The radio spectrum is a limited resource. Demand for wireless communication services is increasing exponentially, stressing the availability of radio spectrum to accommodate new services. TV White Space (TVWS) technologies allow a dynamic usage of the spectrum. These technologies provide wireless connectivity, in the channels of the Very High Frequency (VHF) and Ultra High Frequency (UHF) television broadcasting bands. In this paper, we investigate and compare the coverage range, network capacity, and network energy efficiency for TVWS technologies and LTE. We consider Ghent, Belgium and Boyeros, Havana, Cuba to evaluate a realistic outdoor suburban and rural area, respectively. The comparison shows that TVWS networks have an energy efficiency 9-12 times higher than LTE networks.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02694",
        "abstract url": "https://arxiv.org/abs/2405.02694",
        "title": "Multi-objective Optimization of Cognitive Radio Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "New generation networks, based on Cognitive Radio technology, allow dynamic allocation of the spectrum, alleviating spectrum scarcity. These networks also have a resilient potential for dynamic operation for energy saving. In this paper, we present a novel wireless network optimization algorithm for cognitive radio networks based on a cloud sharing-decision mechanism. Three Key Performance Indicators (KPIs) were optimized: spectrum usage, power consumption, and exposure of human beings. For a realistic suburban scenario in Ghent city, Belgium, we determine the optimality among the KPIs. Compared to a traditional Cognitive Radio network design, our optimization algorithm for the cloud-based architecture reduced the network power consumption by 27.5%, the average global exposure by 34.3%, and spectrum usage by 34.5% at the same time. Even for the worst optimization case, our solution performs better than the traditional architecture by 4.8% in terms of network power consumption, 7.3% in terms of spectrum usage and 4.3% in terms of global exposure.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02699",
        "abstract url": "https://arxiv.org/abs/2405.02699",
        "title": "Platform Competition in the Autobidding World",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of auction design for advertising platforms that face strategic advertisers who are bidding across platforms. Each advertiser's goal is to maximize their total value or conversions while satisfying some constraint(s) across all the platforms they participates in. In this paper, we focus on advertisers with return-over-investment (henceforth, ROI) constraints, i.e. each advertiser is trying to maximize value while making sure that their ROI across all platforms is no less than some target value. An advertiser interacts with the platforms through autobidders -- for each platform, the advertiser strategically chooses a target ROI to report to the platform's autobidder, which in turn uses a uniform bid multiplier to bid on the advertiser's behalf on the queries owned by the given platform. Our main result is that for a platform trying to maximize revenue, competition with other platforms is a key factor to consider when designing their auction. While first-price auctions are optimal (for both revenue and welfare) in the absence of competition, this no longer holds true in multi-platform settings. We show that there exists a large class of advertiser valuations over queries such that, from the platform's perspective, running a second price auction dominates running a first price auction. Furthermore, our analysis reveals the key factors influencing platform choice of auction format: (i) intensity of competition among advertisers, (ii) sensitivity of bid landscapes to an auction change (driven by advertiser sensitivity to price changes), and (iii) relative inefficiency of second-price auctions compared to first-price auctions.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02705",
        "abstract url": "https://arxiv.org/abs/2405.02705",
        "title": "Peak Age of Information under Tandem of Queues",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers a communication system where a source sends time-sensitive information to its destination via queues in tandem. We assume that the arrival process as well as the service process (of each server) are memoryless, and each of the servers has no buffer. For this setup, we develop a recursive framework to characterize the mean peak age of information (PAoI) under preemptive and non-preemptive policies with $N$ servers having different service rates. For the preemptive case, the proposed framework also allows to obtain mean age of information (AoI).",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Accepted at IEEE ISIT'24"
    },
    {
        "paper id": "2405.02713",
        "abstract url": "https://arxiv.org/abs/2405.02713",
        "title": "Set Transformation: Trade-off Between Repair Bandwidth and Sub-packetization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Maximum distance separable (MDS) codes facilitate the achievement of elevated levels of fault tolerance in storage systems while incurring minimal redundancy overhead. Reed-Solomon (RS) codes are typical MDS codes with the sub-packetization level being one, however, they require large repair bandwidth defined as the total amount of symbols downloaded from other surviving nodes during single-node failure/repair. In this paper, we present the {\\em set transformation}, which can transform any MDS code into set transformed code such that (i) the sub-packetization level is flexible and ranges from 2 to $(n-k)^{\\lfloor\\frac{n}{n-k}\\rfloor}$ in which $n$ is the number of nodes and $k$ is the number of data nodes, (ii) the new code is MDS code, (iii) the new code has lower repair bandwidth for any single-node failure. We show that our set transformed codes have both lower repair bandwidth and lower field size than the existing related MDS array codes, such as elastic transformed codes \\cite{10228984}. Specifically, our set transformed codes have $2\\%-6.6\\%$ repair bandwidth reduction compared with elastic transformed codes \\cite{10228984} for the evaluated typical parameters.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02718",
        "abstract url": "https://arxiv.org/abs/2405.02718",
        "title": "Zak-OTFS: Pulse Shaping and the Tradeoff between Time/Bandwidth Expansion and Predictability",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Zak-OTFS input/output (I/O) relation is predictable and non-fading when the delay and Doppler periods are greater than the effective channel delay and Doppler spreads, a condition which we refer to as the crystallization condition. When the crystallization condition is satisfied, we describe how to integrate sensing and communication within a single Zak-OTFS subframe by transmitting a pilot in the center of the subframe and surrounding the pilot with a pilot region and guard band to mitigate interference between data symbols and pilot. At the receiver we first read off the effective channel taps within the pilot region, and then use the estimated channel taps to recover the data from the symbols received outside the pilot region. We introduce a framework for filter design in the delay-Doppler (DD) domain where the symplectic Fourier transform connects aliasing in the DD domain (predictability of the I/O relation) with time/bandwidth expansion. The choice of pulse shaping filter determines the fraction of pilot energy that lies outside the pilot region and the degradation in BER performance that results from the interference to data symbols. We demonstrate that Gaussian filters in the DD domain provide significant improvements in BER performance over the sinc and root raised cosine filters considered in previous work. We also demonstrate that, by limiting DD domain aliasing, Gaussian filters extend the region where the crystallization condition is satisfied. The Gaussian filters considered in this paper are a particular case of factorizable pulse shaping filters in the DD domain, and this family of filters may be of independent interest.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2405.02727",
        "abstract url": "https://arxiv.org/abs/2405.02727",
        "title": "Using finite automata to compute the base-$b$ representation of the golden ratio and other quadratic irrationals",
        "rating": "-10",
        "keywords": [],
        "abstract": "We show that the $n$'th digit of the base-$b$ representation of the golden ratio is a finite-state function of the Zeckendorf representation of $b^n$, and hence can be computed by a finite automaton. Similar results can be proven for any quadratic irrational. We use a satisfiability (SAT) solver to prove, in some cases, that the automata we construct are minimal.",
        "subjects": [
            "cs.FL",
            "cs.DM",
            "math.NT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02734",
        "abstract url": "https://arxiv.org/abs/2405.02734",
        "title": "A Diagramming Technique for Teaching Students to Read Software Engineering Research Papers: an experience report",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reading scientific research papers is a skill that many students do not learn before entering PhD programs, but it is critical to their success. This paper describes our diagramming technique for teaching this skill, which helps them identify the structure and the scientific argument of the paper. This has made our students more effective readers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "6 pages, 6 figures, working paper"
    },
    {
        "paper id": "2405.02741",
        "abstract url": "https://arxiv.org/abs/2405.02741",
        "title": "Activity Detection for Massive Random Access using Covariance-based Matching Pursuit",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Internet of Things paradigm heavily relies on a network of a massive number of machine-type devices (MTDs) that monitor changes in various phenomena. Consequently, MTDs are randomly activated at different times whenever a change occurs. This essentially results in relatively few MTDs being active simultaneously compared to the entire network, resembling targeted sampling in compressed sensing. Therefore, signal recovery in machine-type communications is addressed through joint user activity detection and channel estimation algorithms built using compressed sensing theory. However, most of these algorithms follow a two-stage procedure in which a channel is first estimated and later mapped to find active users. This approach is inefficient because the estimated channel information is subsequently discarded. To overcome this limitation, we introduce a novel covariance-learning matching pursuit algorithm that bypasses explicit channel estimation. Instead, it focuses on estimating the indices of the active users greedily. Simulation results presented in terms of probability of miss detection, exact recovery rate, and computational complexity validate the proposed technique's superior performance and efficiency.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "submitted to IEEE IoT journal"
    },
    {
        "paper id": "2405.02756",
        "abstract url": "https://arxiv.org/abs/2405.02756",
        "title": "Efficient Open Modification Spectral Library Searching in High-Dimensional Space with Multi-Level-Cell Memory",
        "rating": "-10",
        "keywords": [],
        "abstract": "Open Modification Search (OMS) is a promising algorithm for mass spectrometry analysis that enables the discovery of modified peptides. However, OMS encounters challenges as it exponentially extends the search scope. Existing OMS accelerators either have limited parallelism or struggle to scale effectively with growing data volumes. In this work, we introduce an OMS accelerator utilizing multi-level-cell (MLC) RRAM memory to enhance storage capacity by 3x. Through in-memory computing, we achieve up to 77x faster data processing with two to three orders of magnitude better energy efficiency. Testing was done on a fabricated MLC RRAM chip. We leverage hyperdimensional computing to tolerate up to 10% memory errors while delivering massive parallelism in hardware.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Accepted by DAC'24"
    },
    {
        "paper id": "2405.02759",
        "abstract url": "https://arxiv.org/abs/2405.02759",
        "title": "Region-Aware Color Smudging",
        "rating": "-10",
        "keywords": [],
        "abstract": "Color smudge operations from digital painting software enable users to create natural shading effects in high-fidelity paintings by interactively mixing colors. To precisely control results in traditional painting software, users tend to organize flat-filled color regions in multiple layers and smudge them to generate different color gradients. However, the requirement to carefully deal with regions makes the smudging process time-consuming and laborious, especially for non-professional users. This motivates us to investigate how to infer user-desired smudging effects when users smudge over regions in a single layer. To investigate improving color smudge performance, we first conduct a formative study. Following the findings of this study, we design SmartSmudge, a novel smudge tool that offers users dynamical smudge brushes and real-time region selection for easily generating natural and efficient shading effects. We demonstrate the efficiency and effectiveness of the proposed tool via a user study and quantitative analysis",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02763",
        "abstract url": "https://arxiv.org/abs/2405.02763",
        "title": "Can Nuanced Language Lead to More Actionable Insights? Exploring the Role of Generative AI in Analytical Narrative Structure",
        "rating": "-10",
        "keywords": [],
        "abstract": "Relevant language describing trends in data can be useful for generating summaries to help with readers' takeaways. However, the language employed in these often template-generated summaries tends to be simple, ranging from describing simple statistical information (e.g., extrema and trends) without additional context and richer language to provide actionable insights. Recent advances in Large Language Models (LLMs) have shown promising capabilities in capturing subtle nuances in language when describing information. This workshop paper specifically explores how LLMs can provide more actionable insights when describing trends by focusing on three dimensions of analytical narrative structure: semantic, rhetorical, and pragmatic. Building on prior research that examines visual and linguistic signatures for univariate line charts, we examine how LLMs can further leverage the semantic dimension of analytical narratives using quantified semantics to describe shapes in trends as people intuitively view them. These semantic descriptions help convey insights in a way that leads to a pragmatic outcome, i.e., a call to action, persuasion, warning vs. alert, and situational awareness. Finally, we identify rhetorical implications for how well these generated narratives align with the perceived shape of the data, thereby empowering users to make informed decisions and take meaningful actions based on these data insights.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2405.02800",
        "abstract url": "https://arxiv.org/abs/2405.02800",
        "title": "Designing Distinguishable Mid-Air Ultrasound Tactons with Temporal Parameters",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mid-air ultrasound technology offers new design opportunities for contactless tactile patterns (i.e., Tactons) in user applications. Yet, few guidelines exist for making ultrasound Tactons easy to distinguish for users. In this paper, we investigated the distinguishability of temporal parameters of ultrasound Tactons in five studies (n=72 participants). Study 1 established the discrimination thresholds for amplitude-modulated (AM) frequencies. In Studies 2-5, we investigated distinguishable ultrasound Tactons by creating four Tacton sets based on mechanical vibrations in the literature and collected similarity ratings for the ultrasound Tactons. We identified a subset of temporal parameters, such as rhythm and low envelope frequency, that could create distinguishable ultrasound Tactons. Also, a strong correlation (mean Spearman's $\u03c1$=0.75) existed between similarity ratings for ultrasound Tactons and similarities of mechanical Tactons from the literature, suggesting vibrotactile designers can transfer their knowledge to ultrasound design. We present design guidelines and future directions for creating distinguishable mid-air ultrasound Tactons.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.02808",
        "abstract url": "https://arxiv.org/abs/2405.02808",
        "title": "An Interactive Tool for Simulating Mid-Air Ultrasound Tactons on the Skin",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mid-air ultrasound haptic technology offers a myriad of temporal and spatial parameters for contactless haptic design. Yet, predicting how these parameters interact to render an ultrasound signal is difficult before testing them on a mid-air ultrasound haptic device. Thus, haptic designers often use a trial-and-error process with different parameter combinations to obtain desired tactile patterns (i.e., Tactons) for user applications. We propose an interactive tool with five temporal and three spatiotemporal design parameters that can simulate the temporal and spectral properties of stimulation at specific skin points. As a preliminary verification, we measured vibrations induced from the ultrasound Tactons varying on one temporal and two spatiotemporal parameters. The measurements and simulation showed similar results for three different ultrasound rendering techniques, suggesting the efficacy of the simulation tool. We present key insights from the simulation and discuss future directions for enhancing the capabilities of simulations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    }
]