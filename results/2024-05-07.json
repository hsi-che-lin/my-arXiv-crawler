[
    {
        "paper id": "2405.04327",
        "abstract url": "https://arxiv.org/abs/2405.04327",
        "title": "Audio-Visual Speech Representation Expert for Enhanced Talking Face Video Generation and Evaluation",
        "rating": "2.5",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In the task of talking face generation, the objective is to generate a face video with lips synchronized to the corresponding audio while preserving visual details and identity information. Current methods face the challenge of learning accurate lip synchronization while avoiding detrimental effects on visual quality, as well as robustly evaluating such synchronization. To tackle these problems, we propose utilizing an audio-visual speech representation expert (AV-HuBERT) for calculating lip synchronization loss during training. Moreover, leveraging AV-HuBERT's features, we introduce three novel lip synchronization evaluation metrics, aiming to provide a comprehensive assessment of lip synchronization performance. Experimental results, along with a detailed ablation study, demonstrate the effectiveness of our approach and the utility of the proposed evaluation metrics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR2024 NTIRE Workshop"
    },
    {
        "paper id": "2405.04412",
        "abstract url": "https://arxiv.org/abs/2405.04412",
        "title": "The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring",
        "rating": "2",
        "keywords": [
            [
                "social biases"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are increasingly being introduced in workplace settings, with the goals of improving efficiency and fairness. However, concerns have arisen regarding these models' potential to reflect or exacerbate social biases and stereotypes. This study explores the potential impact of LLMs on hiring practices. To do so, we conduct an algorithm audit of race and gender biases in one commonly-used LLM, OpenAI's GPT-3.5, taking inspiration from the history of traditional offline resume audits. We conduct two studies using names with varied race and gender connotations: resume assessment (Study 1) and resume generation (Study 2). In Study 1, we ask GPT to score resumes with 32 different names (4 names for each combination of the 2 gender and 4 racial groups) and two anonymous options across 10 occupations and 3 evaluation tasks (overall rating, willingness to interview, and hireability). We find that the model reflects some biases based on stereotypes. In Study 2, we prompt GPT to create resumes (10 for each name) for fictitious job candidates. When generating resumes, GPT reveals underlying biases; women's resumes had occupations with less experience, while Asian and Hispanic resumes had immigrant markers, such as non-native English and non-U.S. education and work experiences. Our findings contribute to a growing body of literature on LLM biases, in particular when used in workplace contexts.",
        "subjects": [
            "cs.CY",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04781",
        "abstract url": "https://arxiv.org/abs/2405.04781",
        "title": "CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated astonishing capabilities in natural language processing (NLP) tasks, sparking interest in their application to professional domains with higher specialized requirements. However, restricted access to closed-source LLMs via APIs and the difficulty in collecting massive high-quality datasets pose obstacles to the development of large language models in education fields of various courses. Given these challenges, we propose CourseGPT-zh, a course-oriented education LLM that supports customization and low-cost deployment. To address the comprehensiveness and diversity requirements of course-specific corpora, we design a high-quality question-answering corpus distillation framework incorporating prompt optimization, which effectively mines textbook knowledge and enhances its diversity. Moreover, considering the alignment of LLM responses with user needs, a novel method for discrete prompt optimization based on LLM-as-Judge is introduced. During optimization, this framework leverages the LLM's ability to reflect on and exploit error feedback and patterns, allowing for prompts that meet user needs and preferences while saving response length. Lastly, we obtain CourseGPT-zh based on the open-source LLM using parameter-efficient fine-tuning. Experimental results show that our discrete prompt optimization framework effectively improves the response quality of ChatGPT, and CourseGPT-zh exhibits strong professional capabilities in specialized knowledge question-answering, significantly outperforming comparable open-source models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04126",
        "abstract url": "https://arxiv.org/abs/2405.04126",
        "title": "Refining Joint Text and Source Code Embeddings for Retrieval Task with Parameter-Efficient Fine-Tuning",
        "rating": "1.5",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The latest developments in Natural Language Processing (NLP) have demonstrated remarkable progress in a code-text retrieval problem. As the Transformer-based models used in this task continue to increase in size, the computational costs and time required for end-to-end fine-tuning become substantial. This poses a significant challenge for adapting and utilizing these models when computational resources are limited. Motivated by these concerns, we propose a fine-tuning framework that leverages Parameter-Efficient Fine-Tuning (PEFT) techniques. Moreover, we adopt contrastive learning objectives to improve the quality of bimodal representations learned by transformer models. Additionally, for PEFT methods we provide extensive benchmarking, the lack of which has been highlighted as a crucial problem in the literature. Based on the thorough experimentation with the CodeT5+ model conducted on two datasets, we demonstrate that the proposed fine-tuning framework has the potential to improve code-text retrieval performance by tuning only 0.4% parameters at most.",
        "subjects": [
            "cs.LG",
            "cs.SE"
        ],
        "comment": "17 pages, 4 figures, Accepted to AINL-2024"
    },
    {
        "paper id": "2405.04296",
        "abstract url": "https://arxiv.org/abs/2405.04296",
        "title": "Open Implementation and Study of BEST-RQ for Speech Processing",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Self-Supervised Learning (SSL) has proven to be useful in various speech tasks. However, these methods are generally very demanding in terms of data, memory, and computational resources. BERT-based Speech pre-Training with Random-projection Quantizer (BEST-RQ), is an SSL method that has shown great performance on Automatic Speech Recognition (ASR) while being simpler than other SSL methods, such as wav2vec 2.0. Despite BEST-RQ's great performance, details are lacking in the original paper, such as the amount of GPU/TPU hours used in pre-training, and there is no official easy-to-use open-source implementation. Furthermore, BEST-RQ has not been evaluated on other downstream tasks aside from ASR and speech translation. In this work, we describe a re-implementation of a Random-projection quantizer and perform a preliminary study with a comparison to wav2vec 2.0 on four downstream tasks. We discuss the details and differences of our implementation. We show that a random projection quantizer can achieve similar downstream performance as wav2vec 2.0 while decreasing training time by over a factor of two.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted in IEEE ICASSP 2024 workshop on Self-supervision in Audio, Speech and Beyond (SASB 2024)"
    },
    {
        "paper id": "2405.04437",
        "abstract url": "https://arxiv.org/abs/2405.04437",
        "title": "vAttention: Dynamic Memory Management for Serving LLMs without PagedAttention",
        "rating": "1.5",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Efficient use of GPU memory is essential for high throughput LLM inference. Prior systems reserved memory for the KV-cache ahead-of-time, resulting in wasted capacity due to internal fragmentation. Inspired by OS-based virtual memory systems, vLLM proposed PagedAttention to enable dynamic memory allocation for KV-cache. This approach eliminates fragmentation, enabling high-throughput LLM serving with larger batch sizes. However, to be able to allocate physical memory dynamically, PagedAttention changes the layout of KV-cache from contiguous virtual memory to non-contiguous virtual memory. This change requires attention kernels to be rewritten to support paging, and serving framework to implement a memory manager. Thus, the PagedAttention model leads to software complexity, portability issues, redundancy and inefficiency. In this paper, we propose vAttention for dynamic KV-cache memory management. In contrast to PagedAttention, vAttention retains KV-cache in contiguous virtual memory and leverages low-level system support for demand paging, that already exists, to enable on-demand physical memory allocation. Thus, vAttention unburdens the attention kernel developer from having to explicitly support paging and avoids re-implementation of memory management in the serving framework. We show that vAttention enables seamless dynamic memory management for unchanged implementations of various attention kernels. vAttention also generates tokens up to 1.97x faster than vLLM, while processing input prompts up to 3.92x and 1.45x faster than the PagedAttention variants of FlashAttention and FlashInfer.",
        "subjects": [
            "cs.LG",
            "cs.OS"
        ],
        "comment": "15 pages, 12 figures, 8 tables"
    },
    {
        "paper id": "2405.04513",
        "abstract url": "https://arxiv.org/abs/2405.04513",
        "title": "Switchable Decision: Dynamic Neural Generation Networks",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Auto-regressive generation models achieve competitive performance across many different NLP tasks such as summarization, question answering, and classifications. However, they are also known for being slow in inference, which makes them challenging to deploy in real-time applications. We propose a switchable decision to accelerate inference by dynamically assigning computation resources for each data instance. Automatically making decisions on where to skip and how to balance quality and computation cost with constrained optimization, our dynamic neural generation networks enforce the efficient inference path and determine the optimized trade-off. Experiments across question answering, summarization, and classification benchmarks show that our method benefits from less computation cost during inference while keeping the same accuracy. Extensive experiments and ablation studies demonstrate that our method can be general, effective, and beneficial for many NLP tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to ICML 2024"
    },
    {
        "paper id": "2405.04623",
        "abstract url": "https://arxiv.org/abs/2405.04623",
        "title": "The Dark Side of Dataset Scaling: Evaluating Racial Classification in Multimodal Models",
        "rating": "1.5",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Scale the model, scale the data, scale the GPU farms is the reigning sentiment in the world of generative AI today. While model scaling has been extensively studied, data scaling and its downstream impacts on model performance remain under-explored. This is particularly important in the context of multimodal datasets whose main source is the World Wide Web, condensed and packaged as the Common Crawl dump, which is known to exhibit numerous drawbacks. In this paper, we evaluate the downstream impact of dataset scaling on 14 visio-linguistic models (VLMs) trained on the LAION400-M and LAION-2B datasets by measuring racial and gender bias using the Chicago Face Dataset (CFD) as the probe. Our results show that as the training data increased, the probability of a pre-trained CLIP model misclassifying human images as offensive non-human classes such as chimpanzee, gorilla, and orangutan decreased, but misclassifying the same images as human offensive classes such as criminal increased. Furthermore, of the 14 Vision Transformer-based VLMs we evaluated, the probability of predicting an image of a Black man and a Latino man as criminal increases by 65% and 69%, respectively, when the dataset is scaled from 400M to 2B samples for the larger ViT-L models. Conversely, for the smaller base ViT-B models, the probability of predicting an image of a Black man and a Latino man as criminal decreases by 20% and 47%, respectively, when the dataset is scaled from 400M to 2B samples. We ground the model audit results in a qualitative and historical analysis, reflect on our findings and their implications for dataset curation practice, and close with a summary of mitigation mechanisms and ways forward. Content warning: This article contains racially dehumanising and offensive descriptions.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "To appear in the proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT 24), June 3 to 6, 2024, Rio de Janeiro, Brazil. arXiv admin note: text overlap with arXiv:2306.13141"
    },
    {
        "paper id": "2405.04034",
        "abstract url": "https://arxiv.org/abs/2405.04034",
        "title": "Differentially Private Post-Processing for Fair Regression",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "This paper describes a differentially private post-processing algorithm for learning fair regressors satisfying statistical parity, addressing privacy concerns of machine learning models trained on sensitive data, as well as fairness concerns of their potential to propagate historical biases. Our algorithm can be applied to post-process any given regressor to improve fairness by remapping its outputs. It consists of three steps: first, the output distributions are estimated privately via histogram density estimation and the Laplace mechanism, then their Wasserstein barycenter is computed, and the optimal transports to the barycenter are used for post-processing to satisfy fairness. We analyze the sample complexity of our algorithm and provide fairness guarantee, revealing a trade-off between the statistical bias and variance induced from the choice of the number of bins in the histogram, in which using less bins always favors fairness at the expense of error.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.CY"
        ],
        "comment": "ICML 2024. Code is at https://github.com/rxian/fair-regression"
    },
    {
        "paper id": "2405.04039",
        "abstract url": "https://arxiv.org/abs/2405.04039",
        "title": "Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize Hallucinations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this research, we uses the DistilBERT model to generate extractive summary and the T5 model to generate abstractive summaries. Also, we generate hybrid summaries by combining both DistilBERT and T5 models. Central to our research is the implementation of GPT-based refining process to minimize the common problem of hallucinations that happens in AI-generated summaries. We evaluate unrefined summaries and, after refining, we also assess refined summaries using a range of traditional and novel metrics, demonstrating marked improvements in the accuracy and reliability of the summaries. Results highlight significant improvements in reducing hallucinatory content, thereby increasing the factual integrity of the summaries.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "9 pages, 3 figures"
    },
    {
        "paper id": "2405.04042",
        "abstract url": "https://arxiv.org/abs/2405.04042",
        "title": "Space-time Reinforcement Network for Video Object Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, video object segmentation (VOS) networks typically use memory-based methods: for each query frame, the mask is predicted by space-time matching to memory frames. Despite these methods having superior performance, they suffer from two issues: 1) Challenging data can destroy the space-time coherence between adjacent video frames. 2) Pixel-level matching will lead to undesired mismatching caused by the noises or distractors. To address the aforementioned issues, we first propose to generate an auxiliary frame between adjacent frames, serving as an implicit short-temporal reference for the query one. Next, we learn a prototype for each video object and prototype-level matching can be implemented between the query and memory. The experiment demonstrated that our network outperforms the state-of-the-art method on the DAVIS 2017, achieving a J&F score of 86.4%, and attains a competitive result 85.0% on YouTube VOS 2018. In addition, our network exhibits a high inference speed of 32+ FPS.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by ICME 2024. 6 pages, 10 figures"
    },
    {
        "paper id": "2405.04044",
        "abstract url": "https://arxiv.org/abs/2405.04044",
        "title": "DMOFC: Discrimination Metric-Optimized Feature Compression",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Feature compression, as an important branch of video coding for machines (VCM), has attracted significant attention and exploration. However, the existing methods mainly focus on intra-feature similarity, such as the Mean Squared Error (MSE) between the reconstructed and original features, while neglecting the importance of inter-feature relationships. In this paper, we analyze the inter-feature relationships, focusing on feature discriminability in machine vision and underscoring its significance in feature compression. To maintain the feature discriminability of reconstructed features, we introduce a discrimination metric for feature compression. The discrimination metric is designed to ensure that the distance between features of the same category is smaller than the distance between features of different categories. Furthermore, we explore the relationship between the discrimination metric and the discriminability of the original features. Experimental results confirm the effectiveness of the proposed discrimination metric and reveal there exists a trade-off between the discrimination metric and the discriminability of the original features.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04048",
        "abstract url": "https://arxiv.org/abs/2405.04048",
        "title": "Philosophy of Cognitive Science in the Age of Deep Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Deep learning has enabled major advances across most areas of artificial intelligence research. This remarkable progress extends beyond mere engineering achievements and holds significant relevance for the philosophy of cognitive science. Deep neural networks have made significant strides in overcoming the limitations of older connectionist models that once occupied the centre stage of philosophical debates about cognition. This development is directly relevant to long-standing theoretical debates in the philosophy of cognitive science. Furthermore, ongoing methodological challenges related to the comparative evaluation of deep neural networks stand to benefit greatly from interdisciplinary collaboration with philosophy and cognitive science. The time is ripe for philosophers to explore foundational issues related to deep learning and cognition; this perspective paper surveys key areas where their contributions can be especially fruitful.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Forthcoming in WIREs Cognitive Science"
    },
    {
        "paper id": "2405.04053",
        "abstract url": "https://arxiv.org/abs/2405.04053",
        "title": "Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This research examines the effectiveness of OpenAI's GPT models as independent evaluators of text summaries generated by six transformer-based models from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS. We evaluated these summaries based on essential properties of high-quality summary - conciseness, relevance, coherence, and readability - using traditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely, we also employed GPT not as a summarizer but as an evaluator, allowing it to independently assess summary quality without predefined metrics. Our analysis revealed significant correlations between GPT evaluations and traditional metrics, particularly in assessing relevance and coherence. The results demonstrate GPT's potential as a robust tool for evaluating text summaries, offering insights that complement established metrics and providing a basis for comparative analysis of transformer-based models in natural language processing tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "10 pages, 5 figures"
    },
    {
        "paper id": "2405.04065",
        "abstract url": "https://arxiv.org/abs/2405.04065",
        "title": "FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-Augmented Language Modeling (RALM) by integrating large language models (LLM) with relevant documents from an external corpus is a proven method for enabling the LLM to generate information beyond the scope of its pre-training corpus. Previous work using utilizing retrieved content by simply prepending retrieved contents to the input poses a high runtime issue, which degrades the inference efficiency of the LLMs because they fail to use the Key-Value (KV) cache efficiently. In this paper, we propose \\textsc{FlashBack}, a modular RALM designed to improve the inference efficiency of RALM with appending context pattern while maintaining decent performance after specific fine-tuning without heavily destruct the knowledge integrity of the LLM. \\textsc{FlashBack} appends retrieved documents at the end of the context for efficiently utilizing the KV cache instead of prepending them. Our experiment shows that the inference speed of \\textsc{FlashBack} is up to $4\\times$ faster than the prepending method on a 7B LLM (Llama 2). Via bypassing unnecessary re-computation, it demonstrates an advancement by achieving significantly faster inference speed, and this heightened efficiency will substantially reduce inferential cost. Our code will be publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2405.04086",
        "abstract url": "https://arxiv.org/abs/2405.04086",
        "title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling complex queries, much of the past work has depended on extensively annotated datasets by human experts. However, this reliance on fully-supervised annotations poses scalability challenges, particularly as models and data requirements grow. To mitigate this, we explore the potential of enhancing LLMs' reasoning abilities with minimal human supervision. In this work, we introduce self-reinforcement, which begins with Supervised Fine-Tuning (SFT) of the model using a small collection of annotated questions. Then it iteratively improves LLMs by learning from the differences in responses from the SFT and unfinetuned models on unlabeled questions. Our approach provides an efficient approach without relying heavily on extensive human-annotated explanations. However, current reasoning benchmarks typically only include golden-reference answers or rationales. Therefore, we present \\textsc{PuzzleBen}, a weakly supervised benchmark that comprises 25,147 complex questions, answers, and human-generated rationales across various domains, such as brainteasers, puzzles, riddles, parajumbles, and critical reasoning tasks. A unique aspect of our dataset is the inclusion of 10,000 unannotated questions, enabling us to explore utilizing fewer supersized data to boost LLMs' inference capabilities. Our experiments underscore the significance of \\textsc{PuzzleBen}, as well as the effectiveness of our methodology as a promising direction in future endeavors. Our dataset and code will be published soon on \\texttt{Anonymity Link}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04093",
        "abstract url": "https://arxiv.org/abs/2405.04093",
        "title": "DCNN: Dual Cross-current Neural Networks Realized Using An Interactive Deep Learning Discriminator for Fine-grained Objects",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate classification of fine-grained images remains a challenge in backbones based on convolutional operations or self-attention mechanisms. This study proposes novel dual-current neural networks (DCNN), which combine the advantages of convolutional operations and self-attention mechanisms to improve the accuracy of fine-grained image classification. The main novel design features for constructing a weakly supervised learning backbone model DCNN include (a) extracting heterogeneous data, (b) keeping the feature map resolution unchanged, (c) expanding the receptive field, and (d) fusing global representations and local features. Experimental results demonstrated that using DCNN as the backbone network for classifying certain fine-grained benchmark datasets achieved performance advantage improvements of 13.5--19.5% and 2.2--12.9%, respectively, compared to other advanced convolution or attention-based fine-grained backbones.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04096",
        "abstract url": "https://arxiv.org/abs/2405.04096",
        "title": "Speaker Characterization by means of Attention Pooling",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "State-of-the-art Deep Learning systems for speaker verification are commonly based on speaker embedding extractors. These architectures are usually composed of a feature extractor front-end together with a pooling layer to encode variable-length utterances into fixed-length speaker vectors. The authors have recently proposed the use of a Double Multi-Head Self-Attention pooling for speaker recognition, placed between a CNN-based front-end and a set of fully connected layers. This has shown to be an excellent approach to efficiently select the most relevant features captured by the front-end from the speech signal. In this paper we show excellent experimental results by adapting this architecture to other different speaker characterization tasks, such as emotion recognition, sex classification and COVID-19 detection.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "IberSpeech 2022"
    },
    {
        "paper id": "2405.04097",
        "abstract url": "https://arxiv.org/abs/2405.04097",
        "title": "Unmasking Illusions: Understanding Human Perception of Audiovisual Deepfakes",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY",
                "cs.CV"
            ]
        ],
        "abstract": "The emergence of contemporary deepfakes has attracted significant attention in machine learning research, as artificial intelligence (AI) generated synthetic media increases the incidence of misinterpretation and is difficult to distinguish from genuine content. Currently, machine learning techniques have been extensively studied for automatically detecting deepfakes. However, human perception has been less explored. Malicious deepfakes could ultimately cause public and social problems. Can we humans correctly perceive the authenticity of the content of the videos we watch? The answer is obviously uncertain; therefore, this paper aims to evaluate the human ability to discern deepfake videos through a subjective study. We present our findings by comparing human observers to five state-ofthe-art audiovisual deepfake detection models. To this end, we used gamification concepts to provide 110 participants (55 native English speakers and 55 non-native English speakers) with a webbased platform where they could access a series of 40 videos (20 real and 20 fake) to determine their authenticity. Each participant performed the experiment twice with the same 40 videos in different random orders. The videos are manually selected from the FakeAVCeleb dataset. We found that all AI models performed better than humans when evaluated on the same 40 videos. The study also reveals that while deception is not impossible, humans tend to overestimate their detection capabilities. Our experimental results may help benchmark human versus machine performance, advance forensics analysis, and enable adaptive countermeasures.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CY",
            "cs.LG",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04101",
        "abstract url": "https://arxiv.org/abs/2405.04101",
        "title": "Continual Learning in the Presence of Repetition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Continual learning (CL) provides a framework for training models in ever-evolving environments. Although re-occurrence of previously seen objects or tasks is common in real-world problems, the concept of repetition in the data stream is not often considered in standard benchmarks for CL. Unlike with the rehearsal mechanism in buffer-based strategies, where sample repetition is controlled by the strategy, repetition in the data stream naturally stems from the environment. This report provides a summary of the CLVision challenge at CVPR 2023, which focused on the topic of repetition in class-incremental learning. The report initially outlines the challenge objective and then describes three solutions proposed by finalist teams that aim to effectively exploit the repetition in the stream to learn continually. The experimental results from the challenge highlight the effectiveness of ensemble-based solutions that employ multiple versions of similar modules, each trained on different but overlapping subsets of classes. This report underscores the transformative potential of taking a different perspective in CL by employing repetition in the data stream to foster innovative strategy design.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Preprint; Challenge Report of the 4th Workshop on Continual Learning in Computer Vision at CVPR"
    },
    {
        "paper id": "2405.04118",
        "abstract url": "https://arxiv.org/abs/2405.04118",
        "title": "Policy Learning with a Language Bottleneck",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Modern AI systems such as self-driving cars and game-playing agents achieve superhuman performance, but often lack human-like features such as generalization, interpretability and human inter-operability. Inspired by the rich interactions between language and decision-making in humans, we introduce Policy Learning with a Language Bottleneck (PLLB), a framework enabling AI agents to generate linguistic rules that capture the strategies underlying their most rewarding behaviors. PLLB alternates between a rule generation step guided by language models, and an update step where agents learn new policies guided by rules. In a two-player communication game, a maze solving task, and two image reconstruction tasks, we show that PLLB agents are not only able to learn more interpretable and generalizable behaviors, but can also share the learned rules with human users, enabling more effective human-AI coordination.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "18 pages, 13 figures"
    },
    {
        "paper id": "2405.04122",
        "abstract url": "https://arxiv.org/abs/2405.04122",
        "title": "Ranking-based Client Selection with Imitation Learning for Efficient Federated Learning",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Federated Learning (FL) enables multiple devices to collaboratively train a shared model while ensuring data privacy. The selection of participating devices in each training round critically affects both the model performance and training efficiency, especially given the vast heterogeneity in training capabilities and data distribution across devices. To address these challenges, we introduce a novel device selection solution called FedRank, which is an end-to-end, ranking-based approach that is pre-trained by imitation learning against state-of-the-art analytical approaches. It not only considers data and system heterogeneity at runtime but also adaptively and efficiently chooses the most suitable clients for model training. Specifically, FedRank views client selection in FL as a ranking problem and employs a pairwise training strategy for the smart selection process. Additionally, an imitation learning-based approach is designed to counteract the cold-start issues often seen in state-of-the-art learning-based approaches. Experimental results reveal that \\model~ boosts model accuracy by 5.2\\% to 56.9\\%, accelerates the training convergence up to $2.01 \\times$ and saves the energy consumption up to $40.1\\%$.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "Accepted by ICML 2024"
    },
    {
        "paper id": "2405.04124",
        "abstract url": "https://arxiv.org/abs/2405.04124",
        "title": "Comparative Study of Recurrent Neural Networks for Virtual Analog Audio Effects Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "Analog electronic circuits are at the core of an important category of musical devices. The nonlinear features of their electronic components give analog musical devices a distinctive timbre and sound quality, making them highly desirable. Artificial neural networks have rapidly gained popularity for the emulation of analog audio effects circuits, particularly recurrent networks. While neural approaches have been successful in accurately modeling distortion circuits, they require architectural improvements that account for parameter conditioning and low latency response. In this article, we explore the application of recent machine learning advancements for virtual analog modeling. We compare State Space models and Linear Recurrent Units against the more common Long Short Term Memory networks. These have shown promising ability in sequence to sequence modeling tasks, showing a notable improvement in signal history encoding. Our comparative study uses these black box neural modeling techniques with a variety of audio effects. We evaluate the performance and limitations using multiple metrics aiming to assess the models' ability to accurately replicate energy envelopes, frequency contents, and transients in the audio signal. To incorporate control parameters we employ the Feature wise Linear Modulation method. Long Short Term Memory networks exhibit better accuracy in emulating distortions and equalizers, while the State Space model, followed by Long Short Term Memory networks when integrated in an encoder decoder structure, outperforms others in emulating saturation and compression. When considering long time variant characteristics, the State Space model demonstrates the greatest accuracy. The Long Short Term Memory and, in particular, Linear Recurrent Unit networks present more tendency to introduce audio artifacts.",
        "subjects": [
            "cs.SD",
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:1810.06603 by other authors"
    },
    {
        "paper id": "2405.04160",
        "abstract url": "https://arxiv.org/abs/2405.04160",
        "title": "A Causal Explainable Guardrails for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown impressive performance in natural language tasks, but their outputs can exhibit undesirable attributes or biases. Existing methods for steering LLMs towards desired attributes often assume unbiased representations and rely solely on steering prompts. However, the representations learned from pre-training can introduce semantic biases that influence the steering process, leading to suboptimal results. We propose LLMGuardaril, a novel framework that incorporates causal analysis and adversarial learning to obtain unbiased steering representations in LLMs. LLMGuardaril systematically identifies and blocks the confounding effects of biases, enabling the extraction of unbiased steering representations. Additionally, it includes an explainable component that provides insights into the alignment between the generated output and the desired direction. Experiments demonstrate LLMGuardaril's effectiveness in steering LLMs towards desired attributes while mitigating biases. Our work contributes to the development of safe and reliable LLMs that align with desired attributes. We discuss the limitations and future research directions, highlighting the need for ongoing research to address the ethical implications of large language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2405.04165",
        "abstract url": "https://arxiv.org/abs/2405.04165",
        "title": "LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Nowadays, Information spreads at an unprecedented pace in social media and discerning truth from misinformation and fake news has become an acute societal challenge. Machine learning (ML) models have been employed to identify fake news but are far from perfect with challenging problems like limited accuracy, interpretability, and generalizability. In this paper, we enhance ML-based solutions with linguistics input and we propose LingML, linguistic-informed ML, for fake news detection. We conducted an experimental study with a popular dataset on fake news during the pandemic. The experiment results show that our proposed solution is highly effective. There are fewer than two errors out of every ten attempts with only linguistic input used in ML and the knowledge is highly explainable. When linguistics input is integrated with advanced large-scale ML models for natural language processing, our solution outperforms existing ones with 1.8% average error rate. LingML creates a new path with linguistics to push the frontier of effective and efficient fake news detection. It also sheds light on real-world multi-disciplinary applications requiring both ML and domain expertise to achieve optimal performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2405.04181",
        "abstract url": "https://arxiv.org/abs/2405.04181",
        "title": "Detecting music deepfakes is easy but actually hard",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In the face of a new era of generative models, the detection of artificially generated content has become a matter of utmost importance. The ability to create credible minute-long music deepfakes in a few seconds on user-friendly platforms poses a real threat of fraud on streaming services and unfair competition to human artists. This paper demonstrates the possibility (and surprising ease) of training classifiers on datasets comprising real audio and fake reconstructions, achieving a convincing accuracy of 99.8%. To our knowledge, this marks the first publication of a music deepfake detector, a tool that will help in the regulation of music forgery. Nevertheless, informed by decades of literature on forgery detection in other fields, we stress that a good test score is not the end of the story. We step back from the straightforward ML framework and expose many facets that could be problematic with such a deployed detector: calibration, robustness to audio manipulation, generalisation to unseen models, interpretability and possibility for recourse. This second part acts as a position for future research steps in the field and a caveat to a flourishing market of fake content checkers.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2405.04191",
        "abstract url": "https://arxiv.org/abs/2405.04191",
        "title": "Effective and Robust Adversarial Training against Data and Label Corruptions",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Corruptions due to data perturbations and label noise are prevalent in the datasets from unreliable sources, which poses significant threats to model training. Despite existing efforts in developing robust models, current learning methods commonly overlook the possible co-existence of both corruptions, limiting the effectiveness and practicability of the model. In this paper, we develop an Effective and Robust Adversarial Training (ERAT) framework to simultaneously handle two types of corruption (i.e., data and label) without prior knowledge of their specifics. We propose a hybrid adversarial training surrounding multiple potential adversarial perturbations, alongside a semi-supervised learning based on class-rebalancing sample selection to enhance the resilience of the model for dual corruption. On the one hand, in the proposed adversarial training, the perturbation generation module learns multiple surrogate malicious data perturbations by taking a DNN model as the victim, while the model is trained to maintain semantic consistency between the original data and the hybrid perturbed data. It is expected to enable the model to cope with unpredictable perturbations in real-world data corruption. On the other hand, a class-rebalancing data selection strategy is designed to fairly differentiate clean labels from noisy labels. Semi-supervised learning is performed accordingly by discarding noisy labels. Extensive experiments demonstrate the superiority of the proposed ERAT framework.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "12 pages, 8 figures"
    },
    {
        "paper id": "2405.04219",
        "abstract url": "https://arxiv.org/abs/2405.04219",
        "title": "Iterative Experience Refinement of Software-Developing Agents",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Autonomous agents powered by large language models (LLMs) show significant potential for achieving high autonomy in various scenarios such as software development. Recent research has shown that LLM agents can leverage past experiences to reduce errors and enhance efficiency. However, the static experience paradigm, reliant on a fixed collection of past experiences acquired heuristically, lacks iterative refinement and thus hampers agents' adaptability. In this paper, we introduce the Iterative Experience Refinement framework, enabling LLM agents to refine experiences iteratively during task execution. We propose two fundamental patterns: the successive pattern, refining based on nearest experiences within a task batch, and the cumulative pattern, acquiring experiences across all previous task batches. Augmented with our heuristic experience elimination, the method prioritizes high-quality and frequently-used experiences, effectively managing the experience space and enhancing efficiency. Extensive experiments show that while the successive pattern may yield superior results, the cumulative pattern provides more stable performance. Moreover, experience elimination facilitates achieving better performance using just 11.54% of a high-quality subset.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.MA",
            "cs.SE"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2405.04251",
        "abstract url": "https://arxiv.org/abs/2405.04251",
        "title": "A General Model for Detecting Learner Engagement: Implementation and Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Considering learner engagement has a mutual benefit for both learners and instructors. Instructors can help learners increase their attention, involvement, motivation, and interest. On the other hand, instructors can improve their instructional performance by evaluating the cumulative results of all learners and upgrading their training programs. This paper proposes a general, lightweight model for selecting and processing features to detect learners' engagement levels while preserving the sequential temporal relationship over time. During training and testing, we analyzed the videos from the publicly available DAiSEE dataset to capture the dynamic essence of learner engagement. We have also proposed an adaptation policy to find new labels that utilize the affective states of this dataset related to education, thereby improving the models' judgment. The suggested model achieves an accuracy of 68.57\\% in a specific implementation and outperforms the studied state-of-the-art models detecting learners' engagement levels.",
        "subjects": [
            "cs.CV",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "13 pages, 2 Postscript figures"
    },
    {
        "paper id": "2405.04271",
        "abstract url": "https://arxiv.org/abs/2405.04271",
        "title": "Generating Feature Vectors from Phonetic Transcriptions in Cross-Linguistic Data Formats",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "When comparing speech sounds across languages, scholars often make use of feature representations of individual sounds in order to determine fine-grained sound similarities. Although binary feature systems for large numbers of speech sounds have been proposed, large-scale computational applications often face the challenges that the proposed feature systems -- even if they list features for several thousand sounds -- only cover a smaller part of the numerous speech sounds reflected in actual cross-linguistic data. In order to address the problem of missing data for attested speech sounds, we propose a new approach that can create binary feature vectors dynamically for all sounds that can be represented in the the standardized version of the International Phonetic Alphabet proposed by the Cross-Linguistic Transcription Systems (CLTS) reference catalog. Since CLTS is actively used in large data collections, covering more than 2,000 distinct language varieties, our procedure for the generation of binary feature vectors provides immediate access to a very large collection of multilingual wordlists. Testing our feature system in different ways on different datasets proves that the system is not only useful to provide a straightforward means to compare the similarity of speech sounds, but also illustrates its potential to be used in future cross-linguistic machine learning applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "To appear in the Proceedings of the 2024 Meeting of the Society for Computation in Linguistics (SCiL)"
    },
    {
        "paper id": "2405.04292",
        "abstract url": "https://arxiv.org/abs/2405.04292",
        "title": "Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces 'clickbait spoiling', a novel technique designed to detect, categorize, and generate spoilers as succinct text responses, countering the curiosity induced by clickbait content. By leveraging a multi-task learning framework, our model's generalization capabilities are significantly enhanced, effectively addressing the pervasive issue of clickbait. The crux of our research lies in generating appropriate spoilers, be it a phrase, an extended passage, or multiple, depending on the spoiler type required. Our methodology integrates two crucial techniques: a refined spoiler categorization method and a modified version of the Question Answering (QA) mechanism, incorporated within a multi-task learning paradigm for optimized spoiler extraction from context. Notably, we have included fine-tuning methods for models capable of handling longer sequences to accommodate the generation of extended spoilers. This research highlights the potential of sophisticated text processing techniques in tackling the omnipresent issue of clickbait, promising an enhanced user experience in the digital realm.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted in ICON 2023"
    },
    {
        "paper id": "2405.04304",
        "abstract url": "https://arxiv.org/abs/2405.04304",
        "title": "Accelerating Speculative Decoding using Dynamic Speculation Length",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Speculative decoding is a promising method for reducing the inference latency of large language models. The effectiveness of the method depends on the speculation length (SL) - the number of tokens generated by the draft model at each iteration. The vast majority of speculative decoding approaches use the same SL for all iterations. In this work, we show that this practice is suboptimal. We introduce DISCO, a DynamIc SpeCulation length Optimization method that uses a classifier to dynamically adjust the SL at each iteration, while provably preserving the decoding quality. Experiments with four benchmarks demonstrate average speedup gains of 10.3% relative to our best baselines.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04324",
        "abstract url": "https://arxiv.org/abs/2405.04324",
        "title": "Granite Code Models: A Family of Open Foundation Models for Code Intelligence",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) trained on code are revolutionizing the software development process. Increasingly, code LLMs are being integrated into software development environments to improve the productivity of human programmers, and LLM-based agents are beginning to show promise for handling complex tasks autonomously. Realizing the full potential of code LLMs requires a wide range of capabilities, including code generation, fixing bugs, explaining and documenting code, maintaining repositories, and more. In this work, we introduce the Granite series of decoder-only code models for code generative tasks, trained with code written in 116 programming languages. The Granite Code models family consists of models ranging in size from 3 to 34 billion parameters, suitable for applications ranging from complex application modernization tasks to on-device memory-constrained use cases. Evaluation on a comprehensive set of tasks demonstrates that Granite Code models consistently reaches state-of-the-art performance among available open-source code LLMs. The Granite Code model family was optimized for enterprise software development workflows and performs well across a range of coding tasks (e.g. code generation, fixing and explanation), making it a versatile all around code model. We release all our Granite Code models under an Apache 2.0 license for both research and commercial use.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.SE"
        ],
        "comment": "Corresponding Authors: Rameswar Panda, Ruchir Puri; Equal Contributors: Mayank Mishra, Matt Stallone, Gaoyuan Zhang"
    },
    {
        "paper id": "2405.04325",
        "abstract url": "https://arxiv.org/abs/2405.04325",
        "title": "Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent developments in large language models (LLMs), while offering a powerful foundation for developing natural language agents, raise safety concerns about them and the autonomous agents built upon them. Deception is one potential capability of AI agents of particular concern, which we refer to as an act or statement that misleads, hides the truth, or promotes a belief that is not true in its entirety or in part. We move away from the conventional understanding of deception through straight-out lying, making objective selfish decisions, or giving false information, as seen in previous AI safety research. We target a specific category of deception achieved through obfuscation and equivocation. We broadly explain the two types of deception by analogizing them with the rabbit-out-of-hat magic trick, where (i) the rabbit either comes out of a hidden trap door or (ii) (our focus) the audience is completely distracted to see the magician bring out the rabbit right in front of them using sleight of hand or misdirection. Our novel testbed framework displays intrinsic deception capabilities of LLM agents in a goal-driven environment when directed to be deceptive in their natural language generations in a two-agent adversarial dialogue system built upon the legislative task of \"lobbying\" for a bill. Along the lines of a goal-driven environment, we show developing deceptive capacity through a reinforcement learning setup, building it around the theories of language philosophy and cognitive psychology. We find that the lobbyist agent increases its deceptive capabilities by ~ 40% (relative) through subsequent reinforcement trials of adversarial interactions, and our deception detection mechanism shows a detection capability of up to 92%. Our results highlight potential issues in agent-human interaction, with agents potentially manipulating humans towards its programmed end-goal.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04342",
        "abstract url": "https://arxiv.org/abs/2405.04342",
        "title": "The Curse of Diversity in Ensemble-Based Exploration",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "We uncover a surprising phenomenon in deep reinforcement learning: training a diverse ensemble of data-sharing agents -- a well-established exploration strategy -- can significantly impair the performance of the individual ensemble members when compared to standard single-agent training. Through careful analysis, we attribute the degradation in performance to the low proportion of self-generated data in the shared training data for each ensemble member, as well as the inefficiency of the individual ensemble members to learn from such highly off-policy data. We thus name this phenomenon the curse of diversity. We find that several intuitive solutions -- such as a larger replay buffer or a smaller ensemble size -- either fail to consistently mitigate the performance loss or undermine the advantages of ensembling. Finally, we demonstrate the potential of representation learning to counteract the curse of diversity with a novel method named Cross-Ensemble Representation Learning (CERL) in both discrete and continuous control domains. Our work offers valuable insights into an unexpected pitfall in ensemble-based exploration and raises important caveats for future applications of similar approaches.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Published as a conference paper at ICLR 2024"
    },
    {
        "paper id": "2405.04403",
        "abstract url": "https://arxiv.org/abs/2405.04403",
        "title": "Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "Attacks"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Augmenting Large Language Models (LLMs) with image-understanding capabilities has resulted in a boom of high-performing Vision-Language models (VLMs). While studying the alignment of LLMs to human values has received widespread attention, the safety of VLMs has not received the same attention. In this paper, we explore the impact of jailbreaking on three state-of-the-art VLMs, each using a distinct modeling approach. By comparing each VLM to their respective LLM backbone, we find that each VLM is more susceptible to jailbreaking. We consider this as an undesirable outcome from visual instruction-tuning, which imposes a forgetting effect on an LLM's safety guardrails. Therefore, we provide recommendations for future work based on evaluation strategies that aim to highlight the weaknesses of a VLM, as well as take safety measures into account during visual instruction tuning.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04405",
        "abstract url": "https://arxiv.org/abs/2405.04405",
        "title": "Weakly-Supervised Residual Evidential Learning for Multi-Instance Uncertainty Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Uncertainty estimation (UE), as an effective means of quantifying predictive uncertainty, is crucial for safe and reliable decision-making, especially in high-risk scenarios. Existing UE schemes usually assume that there are completely-labeled samples to support fully-supervised learning. In practice, however, many UE tasks often have no sufficiently-labeled data to use, such as the Multiple Instance Learning (MIL) with only weak instance annotations. To bridge this gap, this paper, for the first time, addresses the weakly-supervised issue of Multi-Instance UE (MIUE) and proposes a new baseline scheme, Multi-Instance Residual Evidential Learning (MIREL). Particularly, at the fine-grained instance UE with only weak supervision, we derive a multi-instance residual operator through the Fundamental Theorem of Symmetric Functions. On this operator derivation, we further propose MIREL to jointly model the high-order predictive distribution at bag and instance levels for MIUE. Extensive experiments empirically demonstrate that our MIREL not only could often make existing MIL networks perform better in MIUE, but also could surpass representative UE methods by large margins, especially in instance-level UE tasks. Our source code is available at https://github.com/liupei101/MIREL.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2405.04416",
        "abstract url": "https://arxiv.org/abs/2405.04416",
        "title": "DistGrid: Scalable Scene Reconstruction with Distributed Multi-resolution Hash Grid",
        "rating": "1",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Field~(NeRF) achieves extremely high quality in object-scaled and indoor scene reconstruction. However, there exist some challenges when reconstructing large-scale scenes. MLP-based NeRFs suffer from limited network capacity, while volume-based NeRFs are heavily memory-consuming when the scene resolution increases. Recent approaches propose to geographically partition the scene and learn each sub-region using an individual NeRF. Such partitioning strategies help volume-based NeRF exceed the single GPU memory limit and scale to larger scenes. However, this approach requires multiple background NeRF to handle out-of-partition rays, which leads to redundancy of learning. Inspired by the fact that the background of current partition is the foreground of adjacent partition, we propose a scalable scene reconstruction method based on joint Multi-resolution Hash Grids, named DistGrid. In this method, the scene is divided into multiple closely-paved yet non-overlapped Axis-Aligned Bounding Boxes, and a novel segmented volume rendering method is proposed to handle cross-boundary rays, thereby eliminating the need for background NeRFs. The experiments demonstrate that our method outperforms existing methods on all evaluated large-scale scenes, and provides visually plausible scene reconstruction. The scalability of our method on reconstruction quality is further evaluated qualitatively and quantitatively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Originally submitted to Siggraph Asia 2023"
    },
    {
        "paper id": "2405.04434",
        "abstract url": "https://arxiv.org/abs/2405.04434",
        "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model characterized by economical training and efficient inference. It comprises 236B total parameters, of which 21B are activated for each token, and supports a context length of 128K tokens. DeepSeek-V2 adopts innovative architectures including Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees efficient inference through significantly compressing the Key-Value (KV) cache into a latent vector, while DeepSeekMoE enables training strong models at an economical cost through sparse computation. Compared with DeepSeek 67B, DeepSeek-V2 achieves significantly stronger performance, and meanwhile saves 42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum generation throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality and multi-source corpus consisting of 8.1T tokens, and further perform Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock its potential. Evaluation results show that, even with only 21B activated parameters, DeepSeek-V2 and its chat versions still achieve top-tier performance among open-source models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04435",
        "abstract url": "https://arxiv.org/abs/2405.04435",
        "title": "Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Exact nearest neighbor search is a computationally intensive process, and even its simpler sibling -- vector retrieval -- can be computationally complex. This is exacerbated when retrieving vectors which have high-dimension $d$ relative to the number of vectors, $N$, in the database. Exact nearest neighbor retrieval has been generally acknowledged to be a $O(Nd)$ problem with no sub-linear solutions. Attention has instead shifted towards Approximate Nearest-Neighbor (ANN) retrieval techniques, many of which have sub-linear or even logarithmic time complexities. However, if our intuition from binary search problems (e.g. $d=1$ vector retrieval) carries, there ought to be a way to retrieve an organized representation of vectors without brute-forcing our way to a solution. For low dimension (e.g. $d=2$ or $d=3$ cases), \\texttt{kd-trees} provide a $O(d\\log N)$ algorithm for retrieval. Unfortunately the algorithm deteriorates rapidly to a $O(dN)$ solution at high dimensions (e.g. $k=128$), in practice. We propose a novel algorithm for logarithmic Fast Exact Retrieval for Nearest-neighbor lookup (FERN), inspired by \\texttt{kd-trees}. The algorithm achieves $O(d\\log N)$ look-up with 100\\% recall on 10 million $d=128$ uniformly randomly generated vectors.\\footnote{Code available at https://github.com/RichardZhu123/ferns}",
        "subjects": [
            "cs.CL",
            "cs.DS"
        ],
        "comment": "NAACL 2024 SRW"
    },
    {
        "paper id": "2405.04442",
        "abstract url": "https://arxiv.org/abs/2405.04442",
        "title": "AugmenTory: A Fast and Flexible Polygon Augmentation Library",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Data augmentation is a key technique for addressing the challenge of limited datasets, which have become a major component in the training procedures of image processing. Techniques such as geometric transformations and color space adjustments have been thoroughly tested for their ability to artificially expand training datasets and generate semi-realistic data for training purposes. Data augmentation is the most important key to addressing the challenge of limited datasets, which have become a major component of image processing training procedures. Data augmentation techniques, such as geometric transformations and color space adjustments, are thoroughly tested for their ability to artificially expand training datasets and generate semi-realistic data for training purposes. Polygons play a crucial role in instance segmentation and have seen a surge in use across advanced models, such as YOLOv8. Despite their growing popularity, the lack of specialized libraries hampers the polygon-augmentation process. This paper introduces a novel solution to this challenge, embodied in the newly developed AugmenTory library. Notably, AugmenTory offers reduced computational demands in both time and space compared to existing methods. Additionally, the library includes a postprocessing thresholding feature. The AugmenTory package is publicly available on GitHub, where interested users can access the source code: https://github.com/Smartory/AugmenTory",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04459",
        "abstract url": "https://arxiv.org/abs/2405.04459",
        "title": "A Significantly Better Class of Activation Functions Than ReLU Like Activation Functions",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a significantly better class of activation functions than the almost universally used ReLU like and Sigmoidal class of activation functions. Two new activation functions referred to as the Cone and Parabolic-Cone that differ drastically from popular activation functions and significantly outperform these on the CIFAR-10 and Imagenette benchmmarks are proposed. The cone activation functions are positive only on a finite interval and are strictly negative except at the end-points of the interval, where they become zero. Thus the set of inputs that produce a positive output for a neuron with cone activation functions is a hyperstrip and not a half-space as is the usual case. Since a hyper strip is the region between two parallel hyper-planes, it allows neurons to more finely divide the input feature space into positive and negative classes than with infinitely wide half-spaces. In particular the XOR function can be learn by a single neuron with cone-like activation functions. Both the cone and parabolic-cone activation functions are shown to achieve higher accuracies with significantly fewer neurons on benchmarks. The results presented in this paper indicate that many nonlinear real-world datasets may be separated with fewer hyperstrips than half-spaces. The Cone and Parabolic-Cone activation functions have larger derivatives than ReLU and are shown to significantly speedup training.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2405.04476",
        "abstract url": "https://arxiv.org/abs/2405.04476",
        "title": "BERP: A Blind Estimator of Room Acoustic and Physical Parameters for Single-Channel Noisy Speech Signals",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Room acoustic parameters (RAPs) and room physical parameters ( RPPs) are essential metrics for parameterizing the room acoustical characteristics (RAC) of a sound field around a listener's local environment, offering comprehensive indications for various applications. The current RAPs and RPPs estimation methods either fall short of covering broad real-world acoustic environments in the context of real background noise or lack universal frameworks for blindly estimating RAPs and RPPs from noisy single-channel speech signals, particularly sound source distances, direction-of-arrival (DOA) of sound sources, and occupancy levels. On the other hand, in this paper, we propose a novel universal blind estimation framework called the blind estimator of room acoustical and physical parameters (BERP), by introducing a new stochastic room impulse response (RIR) model, namely, the sparse stochastic impulse response (SSIR) model, and endowing the BERP with a unified encoder and multiple separate predictors to estimate RPPs and SSIR parameters in parallel. This estimation framework enables the computationally efficient and universal estimation of room parameters by solely using noisy single-channel speech signals. Finally, all the RAPs can be simultaneously derived from the RIRs synthesized from SSIR model with the estimated parameters. To evaluate the effectiveness of the proposed BERP and SSIR models, we compile a task-specific dataset from several publicly available datasets. The results reveal that the BERP achieves state-of-the-art (SOTA) performance. Moreover, the evaluation results pertaining to the SSIR RIR model also demonstrated its efficacy. The code is available on GitHub.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Submitted to IEEE/ACM Transaction on Audio Speech and Language Processing (TASLP)"
    },
    {
        "paper id": "2405.04485",
        "abstract url": "https://arxiv.org/abs/2405.04485",
        "title": "Adapting WavLM for Speech Emotion Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recently, the usage of speech self-supervised models (SSL) for downstream tasks has been drawing a lot of attention. While large pre-trained models commonly outperform smaller models trained from scratch, questions regarding the optimal fine-tuning strategies remain prevalent. In this paper, we explore the fine-tuning strategies of the WavLM Large model for the speech emotion recognition task on the MSP Podcast Corpus. More specifically, we perform a series of experiments focusing on using gender and semantic information from utterances. We then sum up our findings and describe the final model we used for submission to Speech Emotion Recognition Challenge 2024.",
        "subjects": [
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04489",
        "abstract url": "https://arxiv.org/abs/2405.04489",
        "title": "S3Former: Self-supervised High-resolution Transformer for Solar PV Profiling",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "As the impact of climate change escalates, the global necessity to transition to sustainable energy sources becomes increasingly evident. Renewable energies have emerged as a viable solution for users, with Photovoltaic energy being a favored choice for small installations due to its reliability and efficiency. Accurate mapping of PV installations is crucial for understanding the extension of its adoption and informing energy policy. To meet this need, we introduce S3Former, designed to segment solar panels from aerial imagery and provide size and location information critical for analyzing the impact of such installations on the grid. Solar panel identification is challenging due to factors such as varying weather conditions, roof characteristics, Ground Sampling Distance variations and lack of appropriate initialization weights for optimized training. To tackle these complexities, S3Former features a Masked Attention Mask Transformer incorporating a self-supervised learning pretrained backbone. Specifically, our model leverages low-level and high-level features extracted from the backbone and incorporates an instance query mechanism incorporated on the Transformer architecture to enhance the localization of solar PV installations. We introduce a self-supervised learning phase (pretext task) to improve the initialization weights on the backbone of S3Former. We evaluated S3Former using diverse datasets, demonstrate improvement state-of-the-art models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2405.04495",
        "abstract url": "https://arxiv.org/abs/2405.04495",
        "title": "Toward In-Context Teaching: Adapting Examples to Students' Misconceptions",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "When a teacher provides examples for a student to study, these examples must be informative, enabling a student to progress from their current state toward a target concept or skill. Good teachers must therefore simultaneously infer what students already know and adapt their teaching to students' changing state of knowledge. There is increasing interest in using computational models, particularly large language models, as pedagogical tools. As students, language models in particular have shown a remarkable ability to adapt to new tasks given small numbers of examples. But how effectively can these models adapt as teachers to students of different types? To study this question, we introduce a suite of models and evaluation methods we call AdapT. AdapT has two components: (1) a collection of simulated Bayesian student models that can be used for evaluation of automated teaching methods; (2) a platform for evaluation with human students, to characterize the real-world effectiveness of these methods. We additionally introduce (3) AToM, a new probabilistic model for adaptive teaching that jointly infers students' past beliefs and optimizes for the correctness of future beliefs. In evaluations of simulated students across three learning domains (fraction arithmetic, English morphology, function learning), AToM systematically outperforms LLM-based and standard Bayesian teaching models. In human experiments, both AToM and LLMs outperform non-adaptive random example selection. Our results highlight both the difficulty of the adaptive teaching task and the potential of learned adaptive models for solving it.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04497",
        "abstract url": "https://arxiv.org/abs/2405.04497",
        "title": "Unveiling Disparities in Web Task Handling Between Human and Web Agent",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ]
        ],
        "abstract": "With the advancement of Large-Language Models (LLMs) and Large Vision-Language Models (LVMs), agents have shown significant capabilities in various tasks, such as data analysis, gaming, or code generation. Recently, there has been a surge in research on web agents, capable of performing tasks within the web environment. However, the web poses unforeseeable scenarios, challenging the generalizability of these agents. This study investigates the disparities between human and web agents' performance in web tasks (e.g., information search) by concentrating on planning, action, and reflection aspects during task execution. We conducted a web task study with a think-aloud protocol, revealing distinct cognitive actions and operations on websites employed by humans. Comparative examination of existing agent structures and human behavior with thought processes highlighted differences in knowledge updating and ambiguity handling when performing the task. Humans demonstrated a propensity for exploring and modifying plans based on additional information and investigating reasons for failure. These findings offer insights into designing planning, reflection, and information discovery modules for web agents and designing the capturing method for implicit human knowledge in a web task.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04515",
        "abstract url": "https://arxiv.org/abs/2405.04515",
        "title": "A Transformer with Stack Attention",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Natural languages are believed to be (mildly) context-sensitive. Despite underpinning remarkably capable large language models, transformers are unable to model many context-free language tasks. In an attempt to address this limitation in the modeling power of transformer-based language models, we propose augmenting them with a differentiable, stack-based attention mechanism. Our stack-based attention mechanism can be incorporated into any transformer-based language model and adds a level of interpretability to the model. We show that the addition of our stack-based attention mechanism enables the transformer to model some, but not all, deterministic context-free languages.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "NAACL 2024"
    },
    {
        "paper id": "2405.04532",
        "abstract url": "https://arxiv.org/abs/2405.04532",
        "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Quantization can accelerate large language model (LLM) inference. Going beyond INT8 quantization, the research community is actively exploring even lower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization techniques only accelerate low-batch, edge LLM inference, failing to deliver performance gains in large-batch, cloud-based LLM serving. We uncover a critical issue: existing INT4 quantization methods suffer from significant runtime overhead (20-90%) when dequantizing either weights or partial sums on GPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization algorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands for quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented by the QServe inference library that achieves measured speedup. The key insight driving QServe is that the efficiency of LLM serving on GPUs is critically influenced by operations on low-throughput CUDA cores. Building upon this insight, in QoQ algorithm, we introduce progressive quantization that can allow low dequantization overhead in W4A8 GEMM. Additionally, we develop SmoothAttention to effectively mitigate the accuracy degradation incurred by 4-bit KV quantization. In the QServe system, we perform compute-aware weight reordering and take advantage of register-level parallelism to reduce dequantization latency. We also make fused attention memory-bound, harnessing the performance gain brought by KV4 quantization. As a result, QServe improves the maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x on L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to TensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput than TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of LLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.PF"
        ],
        "comment": "The first three authors contribute equally to this project and are listed in the alphabetical order. Yujun Lin leads the quantization algorithm, Haotian Tang and Shang Yang lead the GPU kernels and the serving system. Code is available at https://github.com/mit-han-lab/qserve"
    },
    {
        "paper id": "2405.04590",
        "abstract url": "https://arxiv.org/abs/2405.04590",
        "title": "Language Modeling Using Tensor Trains",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose a novel tensor network language model based on the simplest tensor network (i.e., tensor trains), called `Tensor Train Language Model' (TTLM). TTLM represents sentences in an exponential space constructed by the tensor product of words, but computing the probabilities of sentences in a low-dimensional fashion. We demonstrate that the architectures of Second-order RNNs, Recurrent Arithmetic Circuits (RACs), and Multiplicative Integration RNNs are, essentially, special cases of TTLM. Experimental evaluations on real language modeling tasks show that the proposed variants of TTLM (i.e., TTLM-Large and TTLM-Tiny) outperform the vanilla Recurrent Neural Networks (RNNs) with low-scale of hidden units. (The code is available at https://github.com/shuishen112/tensortrainlm.)",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04620",
        "abstract url": "https://arxiv.org/abs/2405.04620",
        "title": "Folded context condensation in Path Integral formalism for infinite context transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This short note is written for rapid communication of long context training and to share the idea of how to train it with low memory usage. In the note, we generalize the attention algorithm and neural network of Generative Pre-Trained Transformers and reinterpret it in Path integral formalism. First, the role of the transformer is understood as the time evolution of the token state and second, it is suggested that the all key-token states in the same time as the query-token can attend to the attention with the query token states. As a result of the repetitive time evolution, it is discussed that the token states in the past sequence meats the token states in the present sequence so that the attention between separated sequences becomes possible for maintaining infinite contextual information just by using low memory for limited size of sequence. For the experiment, the $12$ input token window size was taken and one GPU with $24$GB memory was used for the pre-training. It was confirmed that more than $150$ length context is preserved. The sampling result of the training, the code and the other details will be included in the revised version of this note later.",
        "subjects": [
            "hep-ph",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "7 pages, 2 figures"
    },
    {
        "paper id": "2405.04627",
        "abstract url": "https://arxiv.org/abs/2405.04627",
        "title": "SingIt! Singer Voice Transformation",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we propose a model which can generate a singing voice from normal speech utterance by harnessing zero-shot, many-to-many style transfer learning. Our goal is to give anyone the opportunity to sing any song in a timely manner. We present a system comprising several available blocks, as well as a modified auto-encoder, and show how this highly-complex challenge can be achieved by tailoring rather simple solutions together. We demonstrate the applicability of the proposed system using a group of 25 non-expert listeners. Samples of the data generated from our model are provided.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04655",
        "abstract url": "https://arxiv.org/abs/2405.04655",
        "title": "Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated substantial commonsense understanding through numerous benchmark evaluations. However, their understanding of cultural commonsense remains largely unexamined. In this paper, we conduct a comprehensive examination of the capabilities and limitations of several state-of-the-art LLMs in the context of cultural commonsense tasks. Using several general and cultural commonsense benchmarks, we find that (1) LLMs have a significant discrepancy in performance when tested on culture-specific commonsense knowledge for different cultures; (2) LLMs' general commonsense capability is affected by cultural context; and (3) The language used to query the LLMs can impact their performance on cultural-related tasks. Our study points to the inherent bias in the cultural understanding of LLMs and provides insights that can help develop culturally aware language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04669",
        "abstract url": "https://arxiv.org/abs/2405.04669",
        "title": "Towards a Theoretical Understanding of the 'Reversal Curse' via Training Dynamics",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Auto-regressive large language models (LLMs) show impressive capacities to solve many complex reasoning tasks while struggling with some simple logical reasoning tasks such as inverse search: when trained on ''A is B'', LLM fails to directly conclude ''B is A'' during inference, which is known as the ''reversal curse'' (Berglund et al., 2023). In this paper, we theoretically analyze the reversal curse via the training dynamics of (stochastic) gradient descent for two auto-regressive models: (1) a bilinear model that can be viewed as a simplification of a one-layer transformer; (2) one-layer transformers using the framework of Tian et al. (2023a). Our analysis reveals a core reason why the reversal curse happens: the (effective) weights of both auto-regressive models show asymmetry, i.e., the increase of weights from a token $A$ to token $B$ during training does not necessarily cause the increase of the weights from $B$ to $A$. Moreover, our analysis can be naturally applied to other logical reasoning tasks such as chain-of-thought (COT) (Wei et al., 2022b). We show the necessity of COT, i.e., a model trained on ''$A \\to B$'' and ''$B \\to C$'' fails to directly conclude ''$A \\to C$'' without COT (also empirically observed by Allen-Zhu and Li (2023)), for one-layer transformers via training dynamics, which provides a new perspective different from previous work (Feng et al., 2024) that focuses on expressivity. Finally, we also conduct experiments to validate our theory on multi-layer transformers under different settings.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "40 pages, 15 figures"
    },
    {
        "paper id": "2405.04685",
        "abstract url": "https://arxiv.org/abs/2405.04685",
        "title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are becoming crucial across various fields, emphasizing the urgency for high-quality models in underrepresented languages. This study explores the unique challenges faced by low-resource languages, such as data scarcity, model selection, evaluation, and computational limitations, with a special focus on Turkish. We conduct an in-depth analysis to evaluate the impact of training strategies, model choices, and data availability on the performance of LLMs designed for underrepresented languages. Our approach includes two methodologies: (i) adapting existing LLMs originally pretrained in English to understand Turkish, and (ii) developing a model from the ground up using Turkish pretraining data, both supplemented with supervised fine-tuning on a novel Turkish instruction-tuning dataset aimed at enhancing reasoning capabilities. The relative performance of these methods is evaluated through the creation of a new leaderboard for Turkish LLMs, featuring benchmarks that assess different reasoning and knowledge skills. Furthermore, we conducted experiments on data and model scaling, both during pretraining and fine-tuning, simultaneously emphasizing the capacity for knowledge transfer across languages and addressing the challenges of catastrophic forgetting encountered during fine-tuning on a different language. Our goal is to offer a detailed guide for advancing the LLM framework in low-resource linguistic contexts, thereby making natural language processing (NLP) benefits more globally accessible.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04756",
        "abstract url": "https://arxiv.org/abs/2405.04756",
        "title": "BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "social biases"
            ],
            [
                "graph"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Modern large language models (LLMs) have a significant amount of world knowledge, which enables strong performance in commonsense reasoning and knowledge-intensive tasks when harnessed properly. The language model can also learn social biases, which has a significant potential for societal harm. There have been many mitigation strategies proposed for LLM safety, but it is unclear how effective they are for eliminating social biases. In this work, we propose a new methodology for attacking language models with knowledge graph augmented generation. We refactor natural language stereotypes into a knowledge graph, and use adversarial attacking strategies to induce biased responses from several open- and closed-source language models. We find our method increases bias in all models, even those trained with safety guardrails. This demonstrates the need for further research in AI safety, and further work in this new adversarial space.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04758",
        "abstract url": "https://arxiv.org/abs/2405.04758",
        "title": "Honeyfile Camouflage: Hiding Fake Files in Plain Sight",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Honeyfiles are a particularly useful type of honeypot: fake files deployed to detect and infer information from malicious behaviour. This paper considers the challenge of naming honeyfiles so they are camouflaged when placed amongst real files in a file system. Based on cosine distances in semantic vector spaces, we develop two metrics for filename camouflage: one based on simple averaging and one on clustering with mixture fitting. We evaluate and compare the metrics, showing that both perform well on a publicly available GitHub software repository dataset.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "3rd Workshop on the security implications of Deepfakes and Cheapfakes (WDC) co-located at ACM ASIACCS 2024"
    },
    {
        "paper id": "2405.04759",
        "abstract url": "https://arxiv.org/abs/2405.04759",
        "title": "Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In today's interconnected world, achieving reliable out-of-distribution (OOD) detection poses a significant challenge for machine learning models. While numerous studies have introduced improved approaches for multi-class OOD detection tasks, the investigation into multi-label OOD detection tasks has been notably limited. We introduce Spectral Normalized Joint Energy (SNoJoE), a method that consolidates label-specific information across multiple labels through the theoretically justified concept of an energy-based function. Throughout the training process, we employ spectral normalization to manage the model's feature space, thereby enhancing model efficacy and generalization, in addition to bolstering robustness. Our findings indicate that the application of spectral normalization to joint energy scores notably amplifies the model's capability for OOD detection. We perform OOD detection experiments utilizing PASCAL-VOC as the in-distribution dataset and ImageNet-22K or Texture as the out-of-distribution datasets. Our experimental results reveal that, in comparison to prior top performances, SNoJoE achieves 11% and 54% relative reductions in FPR95 on the respective OOD datasets, thereby defining the new state of the art in this field of study.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04782",
        "abstract url": "https://arxiv.org/abs/2405.04782",
        "title": "Dual-Image Enhanced CLIP for Zero-Shot Anomaly Detection",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image Anomaly Detection has been a challenging task in Computer Vision field. The advent of Vision-Language models, particularly the rise of CLIP-based frameworks, has opened new avenues for zero-shot anomaly detection. Recent studies have explored the use of CLIP by aligning images with normal and prompt descriptions. However, the exclusive dependence on textual guidance often falls short, highlighting the critical importance of additional visual references. In this work, we introduce a Dual-Image Enhanced CLIP approach, leveraging a joint vision-language scoring system. Our methods process pairs of images, utilizing each as a visual reference for the other, thereby enriching the inference process with visual context. This dual-image strategy markedly enhanced both anomaly classification and localization performances. Furthermore, we have strengthened our model with a test-time adaptation module that incorporates synthesized anomalies to refine localization capabilities. Our approach significantly exploits the potential of vision-language joint anomaly detection and demonstrates comparable performance with current SOTA methods across various datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04788",
        "abstract url": "https://arxiv.org/abs/2405.04788",
        "title": "DiffMatch: Visual-Language Guidance Makes Better Semi-supervised Change Detector",
        "rating": "1",
        "keywords": [
            [
                "Visual-Language",
                "VLMs"
            ],
            [
                "synthesize"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Change Detection (CD) aims to identify pixels with semantic changes between images. However, annotating massive numbers of pixel-level images is labor-intensive and costly, especially for multi-temporal images, which require pixel-wise comparisons by human experts. Considering the excellent performance of visual language models (VLMs) for zero-shot, open-vocabulary, etc. with prompt-based reasoning, it is promising to utilize VLMs to make better CD under limited labeled data. In this paper, we propose a VLM guidance-based semi-supervised CD method, namely DiffMatch. The insight of DiffMatch is to synthesize free change labels using VLMs to provide additional supervision signals for unlabeled data. However, almost all current VLMs are designed for single-temporal images and cannot be directly applied to bi- or multi-temporal images. Motivated by this, we first propose a VLM-based mixed change event generation (CEG) strategy to yield pseudo labels for unlabeled CD data. Since the additional supervised signals provided by these VLM-driven pseudo labels may conflict with the pseudo labels from the consistency regularization paradigm (e.g. FixMatch), we propose the dual projection head for de-entangling different signal sources. Further, we explicitly decouple the bi-temporal images semantic representation through two auxiliary segmentation decoders, which are also guided by VLM. Finally, to make the model more adequately capture change representations, we introduce metric-aware supervision by feature-level contrastive loss in auxiliary branches. Extensive experiments show the advantage of DiffMatch. For instance, DiffMatch improves the FixMatch baseline by +5.3 IoU on WHU-CD and by +2.4 IoU on LEVIR-CD with 5% labels. In addition, our CEG strategy, in an un-supervised manner, can achieve performance far superior to state-of-the-art un-supervised CD methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 4 figures"
    },
    {
        "paper id": "2405.04793",
        "abstract url": "https://arxiv.org/abs/2405.04793",
        "title": "Zero-shot LLM-guided Counterfactual Generation for Text",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Counterfactual examples are frequently used for model development and evaluation in many natural language processing (NLP) tasks. Although methods for automated counterfactual generation have been explored, such methods depend on models such as pre-trained language models that are then fine-tuned on auxiliary, often task-specific datasets. Collecting and annotating such datasets for counterfactual generation is labor intensive and therefore, infeasible in practice. Therefore, in this work, we focus on a novel problem setting: \\textit{zero-shot counterfactual generation}. To this end, we propose a structured way to utilize large language models (LLMs) as general purpose counterfactual example generators. We hypothesize that the instruction-following and textual understanding capabilities of recent LLMs can be effectively leveraged for generating high quality counterfactuals in a zero-shot manner, without requiring any training or fine-tuning. Through comprehensive experiments on various downstream tasks in natural language processing (NLP), we demonstrate the efficacy of LLMs as zero-shot counterfactual generators in evaluating and explaining black-box NLP models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2309.13340"
    },
    {
        "paper id": "2405.04807",
        "abstract url": "https://arxiv.org/abs/2405.04807",
        "title": "Transformer Architecture for NetsDB",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Transformers models have become the backbone of the current state-of-the-art models in language, vision, and multimodal domains. These models, at their core, utilize multi-head self-attention to selectively aggregate context, generating dynamic contextual embeddings and modeling long-range dependencies for a clear contextual understanding. Lixi et al. \\cite{zhou2022serving} proposed a method to use relational databases for deploying large-scale deep learning models and created an open-source implementation called NetsDB for the same. We build upon the previous work of these authors by creating an end-to-end implementation of the Encoder part of the transformer for model serving in NetsDB. Specifically, we construct a two-block encoder that includes Multi-Head Attention and its accompanying self-attention mechanism, Layer-Norm, Dropout, FeedForward Layers, and the necessary residual connections. We load out weights from our model for distributed processing, deployment, and efficient inferencing. To prove the efficacy of our implementation, we conduct a comprehensive performance analysis by comparing it with existing implementations in PyTorch, Tensorflow, Flax, and MxNet across key metrics such as inference time and model size.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04009",
        "abstract url": "https://arxiv.org/abs/2405.04009",
        "title": "Structured Click Control in Transformer-based Interactive Segmentation",
        "rating": "0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Click-point-based interactive segmentation has received widespread attention due to its efficiency. However, it's hard for existing algorithms to obtain precise and robust responses after multiple clicks. In this case, the segmentation results tend to have little change or are even worse than before. To improve the robustness of the response, we propose a structured click intent model based on graph neural networks, which adaptively obtains graph nodes via the global similarity of user-clicked Transformer tokens. Then the graph nodes will be aggregated to obtain structured interaction features. Finally, the dual cross-attention will be used to inject structured interaction features into vision Transformer features, thereby enhancing the control of clicks over segmentation results. Extensive experiments demonstrated the proposed algorithm can serve as a general structure in improving Transformer-based interactive segmenta?tion performance. The code and data will be released at https://github.com/hahamyt/scc.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "10 pages, 6 figures, submitted to NeurIPS 2024"
    },
    {
        "paper id": "2405.04017",
        "abstract url": "https://arxiv.org/abs/2405.04017",
        "title": "An Improved Finite-time Analysis of Temporal Difference Learning with Deep Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Temporal difference (TD) learning algorithms with neural network function parameterization have well-established empirical success in many practical large-scale reinforcement learning tasks. However, theoretical understanding of these algorithms remains challenging due to the nonlinearity of the action-value approximation. In this paper, we develop an improved non-asymptotic analysis of the neural TD method with a general $L$-layer neural network. New proof techniques are developed and an improved new $\\tilde{\\mathcal{O}}(\u03b5^{-1})$ sample complexity is derived. To our best knowledge, this is the first finite-time analysis of neural TD that achieves an $\\tilde{\\mathcal{O}}(\u03b5^{-1})$ complexity under the Markovian sampling, as opposed to the best known $\\tilde{\\mathcal{O}}(\u03b5^{-2})$ complexity in the existing literature.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04025",
        "abstract url": "https://arxiv.org/abs/2405.04025",
        "title": "Optimal Group Fair Classifiers from Linear Post-Processing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "We propose a post-processing algorithm for fair classification that mitigates model bias under a unified family of group fairness criteria covering statistical parity, equal opportunity, and equalized odds, applicable to multi-class problems and both attribute-aware and attribute-blind settings. It achieves fairness by re-calibrating the output score of the given base model with a \"fairness cost\" -- a linear combination of the (predicted) group memberships. Our algorithm is based on a representation result showing that the optimal fair classifier can be expressed as a linear post-processing of the loss function and the group predictor, derived via using these as sufficient statistics to reformulate the fair classification problem as a linear program. The parameters of the post-processor are estimated by solving the empirical LP. Experiments on benchmark datasets show the efficiency and effectiveness of our algorithm at reducing disparity compared to existing algorithms, including in-processing, especially on larger problems.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": "Code is at https://github.com/rxian/fair-classification"
    },
    {
        "paper id": "2405.04026",
        "abstract url": "https://arxiv.org/abs/2405.04026",
        "title": "Federated Control in Markov Decision Processes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study problems of federated control in Markov Decision Processes. To solve an MDP with large state space, multiple learning agents are introduced to collaboratively learn its optimal policy without communication of locally collected experience. In our settings, these agents have limited capabilities, which means they are restricted within different regions of the overall state space during the training process. In face of the difference among restricted regions, we firstly introduce concepts of leakage probabilities to understand how such heterogeneity affects the learning process, and then propose a novel communication protocol that we call Federated-Q protocol (FedQ), which periodically aggregates agents' knowledge of their restricted regions and accordingly modifies their learning problems for further training. In terms of theoretical analysis, we justify the correctness of FedQ as a communication protocol, then give a general result on sample complexity of derived algorithms FedQ-X with the RL oracle , and finally conduct a thorough study on the sample complexity of FedQ-SynQ. Specifically, FedQ-X has been shown to enjoy linear speedup in terms of sample complexity when workload is uniformly distributed among agents. Moreover, we carry out experiments in various environments to justify the efficiency of our methods.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04050",
        "abstract url": "https://arxiv.org/abs/2405.04050",
        "title": "Learning Linear Block Error Correction Codes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Error correction codes are a crucial part of the physical communication layer, ensuring the reliable transfer of data over noisy channels. The design of optimal linear block codes capable of being efficiently decoded is of major concern, especially for short block lengths. While neural decoders have recently demonstrated their advantage over classical decoding techniques, the neural design of the codes remains a challenge. In this work, we propose for the first time a unified encoder-decoder training of binary linear block codes. To this end, we adapt the coding setting to support efficient and differentiable training of the code for end-to-end optimization over the order two Galois field. We also propose a novel Transformer model in which the self-attention masking is performed in a differentiable fashion for the efficient backpropagation of the code gradient. Our results show that (i) the proposed decoder outperforms existing neural decoding on conventional codes, (ii) the suggested framework generates codes that outperform the {analogous} conventional codes, and (iii) the codes we developed not only excel with our decoder but also show enhanced performance with traditional decoding techniques.",
        "subjects": [
            "cs.IT",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04056",
        "abstract url": "https://arxiv.org/abs/2405.04056",
        "title": "Bidirectional Adversarial Autoencoders for the design of Plasmonic Metasurfaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Learning has been a critical part of designing inverse design methods that are computationally efficient and accurate. An example of this is the design of photonic metasurfaces by using their photoluminescent spectrum as the input data to predict their topology. One fundamental challenge of these systems is their ability to represent nonlinear relationships between sets of data that have different dimensionalities. Existing design methods often implement a conditional Generative Adversarial Network in order to solve this problem, but in many cases the solution is unable to generate structures that provide multiple peaks when validated. It is demonstrated that in response to the target spectrum, the Bidirectional Adversarial Autoencoder is able to generate structures that provide multiple peaks on several occasions. As a result the proposed model represents an important advance towards the generation of nonlinear photonic metasurfaces that can be used in advanced metasurface design.",
        "subjects": [
            "physics.optics",
            "cs.LG"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2405.04061",
        "abstract url": "https://arxiv.org/abs/2405.04061",
        "title": "Generalized Cauchy-Schwarz Divergence and Its Deep Learning Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Divergence measures play a central role in machine learning and become increasingly essential in deep learning. However, valid and computationally efficient divergence measures for multiple (more than two) distributions are scarcely investigated. This becomes particularly crucial in areas where the simultaneous management of multiple distributions is both unavoidable and essential. Examples include clustering, multi-source domain adaptation or generalization, and multi-view learning, among others. Although calculating the mean of pairwise distances between any two distributions serves as a common way to quantify the total divergence among multiple distributions, it is crucial to acknowledge that this approach is not straightforward and requires significant computational resources. In this study, we introduce a new divergence measure for multiple distributions named the generalized Cauchy-Schwarz divergence (GCSD), which is inspired by the classic Cauchy-Schwarz divergence. Additionally, we provide a closed-form sample estimator based on kernel density estimation, making it convenient and straightforward to use in various machine-learning applications. Finally, we apply the proposed GCSD to two challenging machine learning tasks, namely deep learning-based clustering and the problem of multi-source domain adaptation. The experimental results showcase the impressive performance of GCSD in both tasks, highlighting its potential application in machine-learning areas that involve quantifying multiple distributions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04066",
        "abstract url": "https://arxiv.org/abs/2405.04066",
        "title": "Characterizing Regional Importance in Cities with Human Mobility Motifs in Metro Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Uncovering higher-order spatiotemporal dependencies within human mobility networks offers valuable insights into the analysis of urban structures. In most existing studies, human mobility networks are typically constructed by aggregating all trips without distinguishing who takes which specific trip. Instead, we claim individual mobility motifs, higher-order structures generated by daily trips of people, as fundamental units of human mobility networks. In this paper, we propose two network construction frameworks at the level of mobility motifs in characterizing regional importance in cities. Firstly, we enhance the structural dependencies within mobility motifs and proceed to construct mobility networks based on the enhanced mobility motifs. Secondly, taking inspiration from PageRank, we speculate that people would allocate values of importance to destinations according to their trip intentions. A motif-wise network construction framework is proposed based on the established mechanism. Leveraging large-scale metro data across cities, we construct three types of human mobility networks and characterize the regional importance by node importance indicators. Our comparison results suggest that the motif-based mobility network outperforms the classic mobility network, thus highlighting the efficacy of the introduced human mobility motifs. Finally, we demonstrate that the performance in characterizing the regional importance is significantly improved by our motif-wise framework.",
        "subjects": [
            "cs.SI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04074",
        "abstract url": "https://arxiv.org/abs/2405.04074",
        "title": "A simple theory for training response of deep neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural networks give us a powerful method to model the training dataset's relationship between input and output. We can regard that as a complex adaptive system consisting of many artificial neurons that work as an adaptive memory as a whole. The network's behavior is training dynamics with a feedback loop from the evaluation of the loss function. We already know the training response can be constant or shows power law-like aging in some ideal situations. However, we still have gaps between those findings and other complex phenomena, like network fragility. To fill the gap, we introduce a very simple network and analyze it. We show the training response consists of some different factors based on training stages, activation functions, or training methods. In addition, we show feature space reduction as an effect of stochastic training dynamics, which can result in network fragility. Finally, we discuss some complex phenomena of deep networks.",
        "subjects": [
            "cond-mat.dis-nn",
            "cs.AI",
            "cs.LG",
            "nlin.AO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04081",
        "abstract url": "https://arxiv.org/abs/2405.04081",
        "title": "Counterfactual and Semifactual Explanations in Abstract Argumentation: Formal Foundations, Complexity and Computation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Explainable Artificial Intelligence and Formal Argumentation have received significant attention in recent years. Argumentation-based systems often lack explainability while supporting decision-making processes. Counterfactual and semifactual explanations are interpretability techniques that provide insights into the outcome of a model by generating alternative hypothetical instances. While there has been important work on counterfactual and semifactual explanations for Machine Learning models, less attention has been devoted to these kinds of problems in argumentation. In this paper, we explore counterfactual and semifactual reasoning in abstract Argumentation Framework. We investigate the computational complexity of counterfactual- and semifactual-based reasoning problems, showing that they are generally harder than classical argumentation problems such as credulous and skeptical acceptance. Finally, we show that counterfactual and semifactual queries can be encoded in weak-constrained Argumentation Framework, and provide a computational strategy through ASP solvers.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04095",
        "abstract url": "https://arxiv.org/abs/2405.04095",
        "title": "Going Proactive and Explanatory Against Malware Concept Drift",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep learning-based malware classifiers face significant challenges due to concept drift. The rapid evolution of malware, especially with new families, can depress classification accuracy to near-random levels. Previous research has primarily focused on detecting drift samples, relying on expert-led analysis and labeling for model retraining. However, these methods often lack a comprehensive understanding of malware concepts and provide limited guidance for effective drift adaptation, leading to unstable detection performance and high human labeling costs. To address these limitations, we introduce DREAM, a novel system designed to surpass the capabilities of existing drift detectors and to establish an explanatory drift adaptation process. DREAM enhances drift detection through model sensitivity and data autonomy. The detector, trained in a semi-supervised approach, proactively captures malware behavior concepts through classifier feedback. During testing, it utilizes samples generated by the detector itself, eliminating reliance on extensive training data. For drift adaptation, DREAM enlarges human intervention, enabling revisions of malware labels and concept explanations embedded within the detector's latent space. To ensure a comprehensive response to concept drift, it facilitates a coordinated update process for both the classifier and the detector. Our evaluation shows that DREAM can effectively improve the drift detection accuracy and reduce the expert analysis effort in adaptation across different malware datasets and classifiers.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04098",
        "abstract url": "https://arxiv.org/abs/2405.04098",
        "title": "Binarized Simplicial Convolutional Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks have a limitation of solely processing features on graph nodes, neglecting data on high-dimensional structures such as edges and triangles. Simplicial Convolutional Neural Networks (SCNN) represent higher-order structures using simplicial complexes to break this limitation albeit still lacking time efficiency. In this paper, we propose a novel neural network architecture on simplicial complexes named Binarized Simplicial Convolutional Neural Networks (Bi-SCNN) based on the combination of simplicial convolution with a binary-sign forward propagation strategy. The usage of the Hodge Laplacian on a binary-sign forward propagation enables Bi-SCNN to efficiently and effectively represent simplicial features that have higher-order structures than traditional graph node representations. Compared to the previous Simplicial Convolutional Neural Networks, the reduced model complexity of Bi-SCNN shortens the execution time without sacrificing the prediction performance and is less prone to the over-smoothing effect. Experimenting with real-world citation and ocean-drifter data confirmed that our proposed Bi-SCNN is efficient and accurate.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04108",
        "abstract url": "https://arxiv.org/abs/2405.04108",
        "title": "A2-DIDM: Privacy-preserving Accumulator-enabled Auditing for Distributed Identity of DNN Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent booming development of Generative Artificial Intelligence (GenAI) has facilitated an emerging model commercialization for the purpose of reinforcement on model performance, such as licensing or trading Deep Neural Network (DNN) models. However, DNN model trading may trigger concerns of the unauthorized replications or misuses over the model, so that the benefit of the model ownership will be violated. Model identity auditing is a challenging issue in protecting intellectual property of DNN models and verifying the integrity and ownership of models for guaranteeing trusts in transactions is one of the critical obstacles. In this paper, we focus on the above issue and propose a novel Accumulator-enabled Auditing for Distributed Identity of DNN Model (A2-DIDM) that utilizes blockchain and zero-knowledge techniques to protect data and function privacy while ensuring the lightweight on-chain ownership verification. The proposed model presents a scheme of identity records via configuring model weight checkpoints with corresponding zero-knowledge proofs, which incorporates predicates to capture incremental state changes in model weight checkpoints. Our scheme ensures both computational integrity of DNN training process and programmability, so that the uniqueness of the weight checkpoint sequence in a DNN model is preserved, ensuring the correctness of the model identity auditing. In addition, A2-DIDM also addresses privacy protections in distributed identity via a proposed method of accumulators. We systematically analyze the security and robustness of our proposed model and further evaluate the effectiveness and usability of auditing DNN model identities.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04134",
        "abstract url": "https://arxiv.org/abs/2405.04134",
        "title": "Geometry and Dynamics of LayerNorm",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A technical note aiming to offer deeper intuition for the LayerNorm function common in deep neural networks. LayerNorm is defined relative to a distinguished 'neural' basis, but it does more than just normalize the corresponding vector elements. Rather, it implements a composition -- of linear projection, nonlinear scaling, and then affine transformation -- on input activation vectors. We develop both a new mathematical expression and geometric intuition, to make the net effect more transparent. We emphasize that, when LayerNorm acts on an N-dimensional vector space, all outcomes of LayerNorm lie within the intersection of an (N-1)-dimensional hyperplane and the interior of an N-dimensional hyperellipsoid. This intersection is the interior of an (N-1)-dimensional hyperellipsoid, and typical inputs are mapped near its surface. We find the direction and length of the principal axes of this (N-1)-dimensional hyperellipsoid via the eigen-decomposition of a simply constructed matrix.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04138",
        "abstract url": "https://arxiv.org/abs/2405.04138",
        "title": "GPT-Enabled Cybersecurity Training: A Tailored Approach for Effective Awareness",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study explores the limitations of traditional Cybersecurity Awareness and Training (CSAT) programs and proposes an innovative solution using Generative Pre-Trained Transformers (GPT) to address these shortcomings. Traditional approaches lack personalization and adaptability to individual learning styles. To overcome these challenges, the study integrates GPT models to deliver highly tailored and dynamic cybersecurity learning expe-riences. Leveraging natural language processing capabilities, the proposed approach personalizes training modules based on individual trainee pro-files, helping to ensure engagement and effectiveness. An experiment using a GPT model to provide a real-time and adaptive CSAT experience through generating customized training content. The findings have demonstrated a significant improvement over traditional programs, addressing issues of en-gagement, dynamicity, and relevance. GPT-powered CSAT programs offer a scalable and effective solution to enhance cybersecurity awareness, provid-ing personalized training content that better prepares individuals to miti-gate cybersecurity risks in their specific roles within the organization.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04156",
        "abstract url": "https://arxiv.org/abs/2405.04156",
        "title": "How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformer-based language models are treated as black-boxes because of their large number of parameters and complex internal interactions, which is a serious safety concern. Mechanistic Interpretability (MI) intends to reverse-engineer neural network behaviors in terms of human-understandable components. In this work, we focus on understanding how GPT-2 Small performs the task of predicting three-letter acronyms. Previous works in the MI field have focused so far on tasks that predict a single token. To the best of our knowledge, this is the first work that tries to mechanistically understand a behavior involving the prediction of multiple consecutive tokens. We discover that the prediction is performed by a circuit composed of 8 attention heads (~5% of the total heads) which we classified in three groups according to their role. We also demonstrate that these heads concentrate the acronym prediction functionality. In addition, we mechanistically interpret the most relevant heads of the circuit and find out that they use positional information which is propagated via the causal mask mechanism. We expect this work to lay the foundation for understanding more complex behaviors involving multiple-token predictions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04206",
        "abstract url": "https://arxiv.org/abs/2405.04206",
        "title": "NOVA: NoC-based Vector Unit for Mapping Attention Layers on a CNN Accelerator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Attention mechanisms are becoming increasingly popular, being used in neural network models in multiple domains such as natural language processing (NLP) and vision applications, especially at the edge. However, attention layers are difficult to map onto existing neuro accelerators since they have a much higher density of non-linear operations, which lead to inefficient utilization of today's vector units. This work introduces NOVA, a NoC-based Vector Unit that can perform non-linear operations within the NoC of the accelerators, and can be overlaid onto existing neuro accelerators to map attention layers at the edge. Our results show that the NOVA architecture is up to 37.8x more power-efficient than state-of-the-art hardware approximators when running existing attention-based neural networks.",
        "subjects": [
            "cs.AR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "6 pages, 8 figures"
    },
    {
        "paper id": "2405.04212",
        "abstract url": "https://arxiv.org/abs/2405.04212",
        "title": "Green Tsetlin Redefining Efficiency in Tsetlin Machine Frameworks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Green Tsetlin (GT) is a Tsetlin Machine (TM) framework developed to solve real-world problems using TMs. Several frameworks already exist that provide access to TM implementations. However, these either lack features or have a research-first focus. GT is an easy-to-use framework that aims to lower the complexity and provide a production-ready TM implementation that is great for experienced practitioners and beginners. To this end, GT establishes a clear separation between training and inference. A C++ backend with a Python interface provides competitive training and inference performance, with the option of running in pure Python. It also integrates support for critical components such as exporting trained models, hyper-parameter search, and cross-validation out-of-the-box.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04215",
        "abstract url": "https://arxiv.org/abs/2405.04215",
        "title": "NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Today's classical planners are powerful, but modeling input tasks in formats such as PDDL is tedious and error-prone. In contrast, planning with Large Language Models (LLMs) allows for almost any input text, but offers no guarantees on plan quality or even soundness. In an attempt to merge the best of these two approaches, some work has begun to use LLMs to automate parts of the PDDL creation process. However, these methods still require various degrees of expert input. We present NL2Plan, the first domain-agnostic offline LLM-driven planning system. NL2Plan uses an LLM to incrementally extract the necessary information from a short text prompt before creating a complete PDDL description of both the domain and the problem, which is finally solved by a classical planner. We evaluate NL2Plan on four planning domains and find that it solves 10 out of 15 tasks - a clear improvement over a plain chain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover, in two out of the five failure cases, instead of returning an invalid plan, NL2Plan reports that it failed to solve the task. In addition to using NL2Plan in end-to-end mode, users can inspect and correct all of its intermediate results, such as the PDDL representation, increasing explainability and making it an assistive tool for PDDL creation.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted for the ICAPS 2024 Workshop on Human-Aware and Explainable Planning"
    },
    {
        "paper id": "2405.04260",
        "abstract url": "https://arxiv.org/abs/2405.04260",
        "title": "Verified Neural Compressed Sensing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We develop the first (to the best of our knowledge) provably correct neural networks for a precise computational task, with the proof of correctness generated by an automated verification algorithm without any human input. Prior work on neural network verification has focused on partial specifications that, even when satisfied, are not sufficient to ensure that a neural network never makes errors. We focus on applying neural network verification to computational tasks with a precise notion of correctness, where a verifiably correct neural network provably solves the task at hand with no caveats. In particular, we develop an approach to train and verify the first provably correct neural networks for compressed sensing, i.e., recovering sparse vectors from a number of measurements smaller than the dimension of the vector. We show that for modest problem dimensions (up to 50), we can train neural networks that provably recover a sparse vector from linear and binarized linear measurements. Furthermore, we show that the complexity of the network (number of neurons/layers) can be adapted to the problem difficulty and solve problems where traditional compressed sensing methods are not known to provably work.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04278",
        "abstract url": "https://arxiv.org/abs/2405.04278",
        "title": "Uncertainty Quantification Metrics for Deep Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "When deploying deep neural networks on robots or other physical systems, the learned model should reliably quantify predictive uncertainty. A reliable uncertainty allows downstream modules to reason about the safety of its actions. In this work, we address metrics for evaluating such an uncertainty. Specifically, we focus on regression tasks, and investigate Area Under Sparsification Error (AUSE), Calibration Error, Spearman's Rank Correlation, and Negative Log-Likelihood (NLL). Using synthetic regression datasets, we look into how those metrics behave under four typical types of uncertainty, their stability regarding the size of the test set, and reveal their strengths and weaknesses. Our results indicate that Calibration Error is the most stable and interpretable metric, but AUSE and NLL also have their respective use cases. We discourage the usage of Spearman's Rank Correlation for evaluating uncertainties and recommend replacing it with AUSE.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04285",
        "abstract url": "https://arxiv.org/abs/2405.04285",
        "title": "On the Foundations of Earth and Climate Foundation Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Foundation models have enormous potential in advancing Earth and climate sciences, however, current approaches may not be optimal as they focus on a few basic features of a desirable Earth and climate foundation model. Crafting the ideal Earth foundation model, we define eleven features which would allow such a foundation model to be beneficial for any geoscientific downstream application in an environmental- and human-centric manner.We further shed light on the way forward to achieve the ideal model and to evaluate Earth foundation models. What comes after foundation models? Energy efficient adaptation, adversarial defenses, and interpretability are among the emerging directions.",
        "subjects": [
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04294",
        "abstract url": "https://arxiv.org/abs/2405.04294",
        "title": "Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Structured finance, which involves restructuring diverse assets into securities like MBS, ABS, and CDOs, enhances capital market efficiency but presents significant due diligence challenges. This study explores the integration of artificial intelligence (AI) with traditional asset review processes to improve efficiency and accuracy in structured finance. Using both open-sourced and close-sourced large language models (LLMs), we demonstrate that AI can automate the verification of information between loan applications and bank statements effectively. While close-sourced models such as GPT-4 show superior performance, open-sourced models like LLAMA3 offer a cost-effective alternative. Dual-agent systems further increase accuracy, though this comes with higher operational costs. This research highlights AI's potential to minimize manual errors and streamline due diligence, suggesting a broader application of AI in financial document analysis and risk management.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04300",
        "abstract url": "https://arxiv.org/abs/2405.04300",
        "title": "Behaviour Planning: A Toolkit for Diverse Planning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Diverse planning is the problem of generating plans with distinct characteristics. This is valuable for many real-world scenarios, including applications related to plan recognition and business process automation. In this work, we introduce \\emph{Behaviour Planning}, a diverse planning toolkit that can characterise and generate diverse plans based on modular diversity models. We present a qualitative framework for describing diversity models, a planning approach for generating plans aligned with any given diversity model, and provide a practical implementation of an SMT-based behaviour planner. We showcase how the qualitative approach offered by Behaviour Planning allows it to overcome various challenges faced by previous approaches. Finally, the experimental evaluation shows the effectiveness of Behaviour Planning in generating diverse plans compared to state-of-the-art approaches.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04309",
        "abstract url": "https://arxiv.org/abs/2405.04309",
        "title": "Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment and Spatially-variant Deformation Modeling",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Even though Non-rigid Structure-from-Motion (NRSfM) has been extensively studied and great progress has been made, there are still key challenges that hinder their broad real-world applications: 1) the inherent motion/rotation ambiguity requires either explicit camera motion recovery with extra constraint or complex Procrustean Alignment; 2) existing low-rank modeling of the global shape can over-penalize drastic deformations in the 3D shape sequence. This paper proposes to resolve the above issues from a spatial-temporal modeling perspective. First, we propose a novel Temporally-smooth Procrustean Alignment module that estimates 3D deforming shapes and adjusts the camera motion by aligning the 3D shape sequence consecutively. Our new alignment module remedies the requirement of complex reference 3D shape during alignment, which is more conductive to non-isotropic deformation modeling. Second, we propose a spatial-weighted approach to enforce the low-rank constraint adaptively at different locations to accommodate drastic spatially-variant deformation reconstruction better. Our modeling outperform existing low-rank based methods, and extensive experiments across different datasets validate the effectiveness of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2405.04323",
        "abstract url": "https://arxiv.org/abs/2405.04323",
        "title": "Beyond human subjectivity and error: a novel AI grading system",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The grading of open-ended questions is a high-effort, high-impact task in education. Automating this task promises a significant reduction in workload for education professionals, as well as more consistent grading outcomes for students, by circumventing human subjectivity and error. While recent breakthroughs in AI technology might facilitate such automation, this has not been demonstrated at scale. It this paper, we introduce a novel automatic short answer grading (ASAG) system. The system is based on a fine-tuned open-source transformer model which we trained on large set of exam data from university courses across a large range of disciplines. We evaluated the trained model's performance against held-out test data in a first experiment and found high accuracy levels across a broad spectrum of unseen questions, even in unseen courses. We further compared the performance of our model with that of certified human domain experts in a second experiment: we first assembled another test dataset from real historical exams - the historic grades contained in that data were awarded to students in a regulated, legally binding examination process; we therefore considered them as ground truth for our experiment. We then asked certified human domain experts and our model to grade the historic student answers again without disclosing the historic grades. Finally, we compared the hence obtained grades with the historic grades (our ground truth). We found that for the courses examined, the model deviated less from the official historic grades than the human re-graders - the model's median absolute error was 44 % smaller than the human re-graders', implying that the model is more consistent than humans in grading. These results suggest that leveraging AI enhanced grading can reduce human subjectivity, improve consistency and thus ultimately increase fairness.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04333",
        "abstract url": "https://arxiv.org/abs/2405.04333",
        "title": "A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Since late 2022, generative AI has taken the world by storm, with widespread use of tools including ChatGPT, Gemini, and Claude. Generative AI and large language model (LLM) applications are transforming how individuals find and access data and knowledge. However, the intricate relationship between open data and generative AI, and the vast potential it holds for driving innovation in this field remain underexplored areas. This white paper seeks to unpack the relationship between open data and generative AI and explore possible components of a new Fourth Wave of Open Data: Is open data becoming AI ready? Is open data moving towards a data commons approach? Is generative AI making open data more conversational? Will generative AI improve open data quality and provenance? Towards this end, we provide a new Spectrum of Scenarios framework. This framework outlines a range of scenarios in which open data and generative AI could intersect and what is required from a data quality and provenance perspective to make open data ready for those specific scenarios. These scenarios include: pertaining, adaptation, inference and insight generation, data augmentation, and open-ended exploration. Through this process, we found that in order for data holders to embrace generative AI to improve open data access and develop greater insights from open data, they first must make progress around five key areas: enhance transparency and documentation, uphold quality and integrity, promote interoperability and standards, improve accessibility and useability, and address ethical considerations.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "58 pages"
    },
    {
        "paper id": "2405.04344",
        "abstract url": "https://arxiv.org/abs/2405.04344",
        "title": "Enhancing Scalability of Metric Differential Privacy via Secret Dataset Partitioning and Benders Decomposition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Metric Differential Privacy (mDP) extends the concept of Differential Privacy (DP) to serve as a new paradigm of data perturbation. It is designed to protect secret data represented in general metric space, such as text data encoded as word embeddings or geo-location data on the road network or grid maps. To derive an optimal data perturbation mechanism under mDP, a widely used method is linear programming (LP), which, however, might suffer from a polynomial explosion of decision variables, rendering it impractical in large-scale mDP. In this paper, our objective is to develop a new computation framework to enhance the scalability of the LP-based mDP. Considering the connections established by the mDP constraints among the secret records, we partition the original secret dataset into various subsets. Building upon the partition, we reformulate the LP problem for mDP and solve it via Benders Decomposition, which is composed of two stages: (1) a master program to manage the perturbation calculation across subsets and (2) a set of subproblems, each managing the perturbation derivation within a subset. Our experimental results on multiple datasets, including geo-location data in the road network/grid maps, text data, and synthetic data, underscore our proposed mechanism's superior scalability and efficiency.",
        "subjects": [
            "cs.AI",
            "cs.CR"
        ],
        "comment": "To be published in IJCAI 2024"
    },
    {
        "paper id": "2405.04346",
        "abstract url": "https://arxiv.org/abs/2405.04346",
        "title": "Revisiting character-level adversarial attacks",
        "rating": "0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Adversarial attacks in Natural Language Processing apply perturbations in the character or token levels. Token-level attacks, gaining prominence for their use of gradient-based methods, are susceptible to altering sentence semantics, leading to invalid adversarial examples. While character-level attacks easily maintain semantics, they have received less attention as they cannot easily adopt popular gradient-based methods, and are thought to be easy to defend. Challenging these beliefs, we introduce Charmer, an efficient query-based adversarial attack capable of achieving high attack success rate (ASR) while generating highly similar adversarial examples. Our method successfully targets both small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2, Charmer improves the ASR in 4.84% points and the USE similarity in 8% points with respect to the previous art. Our implementation is available in https://github.com/LIONS-EPFL/Charmer.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "comment": "Accepted in ICML 2024"
    },
    {
        "paper id": "2405.04372",
        "abstract url": "https://arxiv.org/abs/2405.04372",
        "title": "Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this study, explainable machine learning techniques are applied to predict the toxicity of mussels in the Gulf of Trieste (Adriatic Sea) caused by harmful algal blooms. By analysing a newly created 28-year dataset containing records of toxic phytoplankton in mussel farming areas and toxin concentrations in mussels (Mytilus galloprovincialis), we train and evaluate the performance of ML models to accurately predict diarrhetic shellfish poisoning (DSP) events. The random forest model provided the best prediction of positive toxicity results based on the F1 score. Explainability methods such as permutation importance and SHAP identified key species (Dinophysis fortii and D. caudata) and environmental factors (salinity, river discharge and precipitation) as the best predictors of DSP outbreaks. These findings are important for improving early warning systems and supporting sustainable aquaculture practices.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04376",
        "abstract url": "https://arxiv.org/abs/2405.04376",
        "title": "Towards Stability of Parameter-free Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hyperparameter tuning, particularly the selection of an appropriate learning rate in adaptive gradient training methods, remains a challenge. To tackle this challenge, in this paper, we propose a novel parameter-free optimizer, AdamG (Adam with the golden step size), designed to automatically adapt to diverse optimization problems without manual tuning. The core technique underlying AdamG is our golden step size derived for the AdaGrad-Norm algorithm, which is expected to help AdaGrad-Norm preserve the tuning-free convergence and approximate the optimal step size in expectation w.r.t. various optimization scenarios. To better evaluate tuning-free performance, we propose a novel evaluation criterion, stability, to comprehensively assess the efficacy of parameter-free optimizers in addition to classical performance criteria. Empirical results demonstrate that compared with other parameter-free baselines, AdamG achieves superior performance, which is consistently on par with Adam using a manually tuned learning rate across various optimization tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04377",
        "abstract url": "https://arxiv.org/abs/2405.04377",
        "title": "Choose What You Need: Disentangled Representation Learning for Scene Text Recognition, Removal and Editing",
        "rating": "0.5",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Scene text images contain not only style information (font, background) but also content information (character, texture). Different scene text tasks need different information, but previous representation learning methods use tightly coupled features for all tasks, resulting in sub-optimal performance. We propose a Disentangled Representation Learning framework (DARLING) aimed at disentangling these two types of features for improved adaptability in better addressing various downstream tasks (choose what you really need). Specifically, we synthesize a dataset of image pairs with identical style but different content. Based on the dataset, we decouple the two types of features by the supervision design. Clearly, we directly split the visual representation into style and content features, the content features are supervised by a text recognition loss, while an alignment loss aligns the style features in the image pairs. Then, style features are employed in reconstructing the counterpart image via an image decoder with a prompt that indicates the counterpart's content. Such an operation effectively decouples the features based on their distinctive properties. To the best of our knowledge, this is the first time in the field of scene text that disentangles the inherent properties of the text images. Our method achieves state-of-the-art performance in Scene Text Recognition, Removal, and Editing.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to CVPR 2024"
    },
    {
        "paper id": "2405.04386",
        "abstract url": "https://arxiv.org/abs/2405.04386",
        "title": "Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Artificial neural networks (ANNs) perform extraordinarily on numerous tasks including classification or prediction, e.g., speech processing and image classification. These new functions are based on a computational model that is enabled to select freely all necessary internal model parameters as long as it eventually delivers the functionality it is supposed to exhibit. Here, we review the connection between the model parameter selection in machine learning (ML) algorithms running on ANNs and the epistemological theory of neopragmatism focusing on the theory's utility and anti-representationalist aspects. To understand the consequences of the model parameter selection of an ANN, we suggest using neopragmatist theories whose implications are well studied. Incidentally, neopragmatism's notion of optimization is also based on utility considerations. This means that applying this approach elegantly reveals the inherent connections between optimization in ML, using a numerical method during the learning phase, and optimization in the ethical theory of consequentialism, where it occurs as a maxim of action. We suggest that these connections originate from the way relevance is calculated in ML systems. This could ultimately reveal a tendency for specific actions in ML systems.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2405.04393",
        "abstract url": "https://arxiv.org/abs/2405.04393",
        "title": "Efficient Online Set-valued Classification with Bandit Feedback",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Conformal prediction is a distribution-free method that wraps a given machine learning model and returns a set of plausible labels that contain the true label with a prescribed coverage rate. In practice, the empirical coverage achieved highly relies on fully observed label information from data both in the training phase for model fitting and the calibration phase for quantile estimation. This dependency poses a challenge in the context of online learning with bandit feedback, where a learner only has access to the correctness of actions (i.e., pulled an arm) but not the full information of the true label. In particular, when the pulled arm is incorrect, the learner only knows that the pulled one is not the true class label, but does not know which label is true. Additionally, bandit feedback further results in a smaller labeled dataset for calibration, limited to instances with correct actions, thereby affecting the accuracy of quantile estimation. To address these limitations, we propose Bandit Class-specific Conformal Prediction (BCCP), offering coverage guarantees on a class-specific granularity. Using an unbiased estimation of an estimand involving the true label, BCCP trains the model and makes set-valued inferences through stochastic gradient descent. Our approach overcomes the challenges of sparsely labeled data in each iteration and generalizes the reliability and applicability of conformal prediction to online decision-making environments.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04407",
        "abstract url": "https://arxiv.org/abs/2405.04407",
        "title": "Super-Exponential Regret for UCT, AlphaGo and Variants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We improve the proofs of the lower bounds of Coquelin and Munos (2007) that demonstrate that UCT can have $\\exp(\\dots\\exp(1)\\dots)$ regret (with $\u03a9(D)$ exp terms) on the $D$-chain environment, and that a `polynomial' UCT variant has $\\exp_2(\\exp_2(D - O(\\log D)))$ regret on the same environment -- the original proofs contain an oversight for rewards bounded in $[0, 1]$, which we fix in the present draft. We also adapt the proofs to AlphaGo's MCTS and its descendants (e.g., AlphaZero, Leela Zero) to also show $\\exp_2(\\exp_2(D - O(\\log D)))$ regret.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04443",
        "abstract url": "https://arxiv.org/abs/2405.04443",
        "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Aligning machine learning systems with human expectations is mostly attempted by training with manually vetted human behavioral samples, typically explicit feedback. This is done on a population level since the context that is capturing the subjective Point-Of-View (POV) of a concrete person in a specific situational context is not retained in the data. However, we argue that alignment on an individual level can boost the subjective predictive performance for the individual user interacting with the system considerably. Since perception differs for each person, the same situation is observed differently. Consequently, the basis for decision making and the subsequent reasoning processes and observable reactions differ. We hypothesize that individual perception patterns can be used for improving the alignment on an individual level. We test this, by integrating perception information into machine learning systems and measuring their predictive performance wrt.~individual subjective assessments. For our empirical study, we collect a novel data set of multimodal stimuli and corresponding eye tracking sequences for the novel task of Perception-Guided Crossmodal Entailment and tackle it with our Perception-Guided Multimodal Transformer. Our findings suggest that exploiting individual perception signals for the machine learning of subjective human assessments provides a valuable cue for individual alignment. It does not only improve the overall predictive performance from the point-of-view of the individual user but might also contribute to steering AI systems towards every person's individual expectations and values.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04480",
        "abstract url": "https://arxiv.org/abs/2405.04480",
        "title": "Concentration Tail-Bound Analysis of Coevolutionary and Bandit Learning Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Runtime analysis, as a branch of the theory of AI, studies how the number of iterations algorithms take before finding a solution (its runtime) depends on the design of the algorithm and the problem structure. Drift analysis is a state-of-the-art tool for estimating the runtime of randomised algorithms, such as evolutionary and bandit algorithms. Drift refers roughly to the expected progress towards the optimum per iteration. This paper considers the problem of deriving concentration tail-bounds on the runtime/regret of algorithms. It provides a novel drift theorem that gives precise exponential tail-bounds given positive, weak, zero and even negative drift. Previously, such exponential tail bounds were missing in the case of weak, zero, or negative drift. Our drift theorem can be used to prove a strong concentration of the runtime/regret of algorithms in AI. For example, we prove that the regret of the \\rwab bandit algorithm is highly concentrated, while previous analyses only considered the expected regret. This means that the algorithm obtains the optimum within a given time frame with high probability, i.e. a form of algorithm reliability. Moreover, our theorem implies that the time needed by the co-evolutionary algorithm RLS-PD to obtain a Nash equilibrium in a \\bilinear max-min-benchmark problem is highly concentrated. However, we also prove that the algorithm forgets the Nash equilibrium, and the time until this occurs is highly concentrated. This highlights a weakness in the RLS-PD which should be addressed by future work.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": "Accepted at International Joint Conference on Artificial Intelligence (IJCAI) 2024"
    },
    {
        "paper id": "2405.04484",
        "abstract url": "https://arxiv.org/abs/2405.04484",
        "title": "OptPDE: Discovering Novel Integrable Systems via AI-Human Collaboration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Integrable partial differential equation (PDE) systems are of great interest in natural science, but are exceedingly rare and difficult to discover. To solve this, we introduce OptPDE, a first-of-its-kind machine learning approach that Optimizes PDEs' coefficients to maximize their number of conserved quantities, $n_{\\rm CQ}$, and thus discover new integrable systems. We discover four families of integrable PDEs, one of which was previously known, and three of which have at least one conserved quantity but are new to the literature to the best of our knowledge. We investigate more deeply the properties of one of these novel PDE families, $u_t = (u_x+a^2u_{xxx})^3$. Our paper offers a promising schema of AI-human collaboration for integrable system discovery: machine learning generates interpretable hypotheses for possible integrable systems, which human scientists can verify and analyze, to truly close the discovery loop.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04517",
        "abstract url": "https://arxiv.org/abs/2405.04517",
        "title": "xLSTM: Extended Long Short-Term Memory",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models (LLMs). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing LSTMs at scale. We now raise a simple question: How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these LSTM extensions into residual block backbones yields xLSTM blocks that are then residually stacked into xLSTM architectures. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04561",
        "abstract url": "https://arxiv.org/abs/2405.04561",
        "title": "Inferring Discussion Topics about Exploitation of Vulnerabilities from Underground Hacking Forums",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "The increasing sophistication of cyber threats necessitates proactive measures to identify vulnerabilities and potential exploits. Underground hacking forums serve as breeding grounds for the exchange of hacking techniques and discussions related to exploitation. In this research, we propose an innovative approach using topic modeling to analyze and uncover key themes in vulnerabilities discussed within these forums. The objective of our study is to develop a machine learning-based model that can automatically detect and classify vulnerability-related discussions in underground hacking forums. By monitoring and analyzing the content of these forums, we aim to identify emerging vulnerabilities, exploit techniques, and potential threat actors. To achieve this, we collect a large-scale dataset consisting of posts and threads from multiple underground forums. We preprocess and clean the data to ensure accuracy and reliability. Leveraging topic modeling techniques, specifically Latent Dirichlet Allocation (LDA), we uncover latent topics and their associated keywords within the dataset. This enables us to identify recurring themes and prevalent discussions related to vulnerabilities, exploits, and potential targets.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2405.04614",
        "abstract url": "https://arxiv.org/abs/2405.04614",
        "title": "Multi-Margin Loss: Proposal and Application in Recommender Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recommender systems guide users through vast amounts of information by suggesting items based on their predicted preferences. Collaborative filtering-based deep learning techniques have regained popularity due to their straightforward nature, relying only on user-item interactions. Typically, these systems consist of three main components: an interaction module, a loss function, and a negative sampling strategy. Initially, researchers focused on enhancing performance by developing complex interaction modules. However, there has been a recent shift toward refining loss functions and negative sampling strategies. This shift has led to an increased interest in contrastive learning, which pulls similar pairs closer while pushing dissimilar ones apart. Contrastive learning involves key practices such as heavy data augmentation, large batch sizes, and hard-negative sampling, but these also bring challenges like high memory demands and under-utilization of some negative samples. The proposed Multi-Margin Loss (MML) addresses these challenges by introducing multiple margins and varying weights for negative samples. This allows MML to efficiently utilize not only the hardest negatives but also other non-trivial negatives, offering a simpler yet effective loss function that outperforms more complex methods, especially when resources are limited. Experiments on two well-known datasets demonstrated that MML achieved up to a 20% performance improvement compared to a baseline contrastive loss function when fewer number of negative samples are used.",
        "subjects": [
            "cs.LG",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04636",
        "abstract url": "https://arxiv.org/abs/2405.04636",
        "title": "Data-driven Error Estimation: Upper Bounding Multiple Errors with No Technical Debt",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We formulate the problem of constructing multiple simultaneously valid confidence intervals (CIs) as estimating a high probability upper bound on the maximum error for a class/set of estimate-estimand-error tuples, and refer to this as the error estimation problem. For a single such tuple, data-driven confidence intervals can often be used to bound the error in our estimate. However, for a class of estimate-estimand-error tuples, nontrivial high probability upper bounds on the maximum error often require class complexity as input -- limiting the practicality of such methods and often resulting in loose bounds. Rather than deriving theoretical class complexity-based bounds, we propose a completely data-driven approach to estimate an upper bound on the maximum error. The simple and general nature of our solution to this fundamental challenge lends itself to several applications including: multiple CI construction, multiple hypothesis testing, estimating excess risk bounds (a fundamental measure of uncertainty in machine learning) for any training/fine-tuning algorithm, and enabling the development of a contextual bandit pipeline that can leverage any reward model estimation procedure as input (without additional mathematical analysis).",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04645",
        "abstract url": "https://arxiv.org/abs/2405.04645",
        "title": "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The field of Artificial Intelligence in Education (AIED) focuses on the intersection of technology, education, and psychology, placing a strong emphasis on supporting learners' needs with compassion and understanding. The growing prominence of Large Language Models (LLMs) has led to the development of scalable solutions within educational settings, including generating different types of feedback in Intelligent Tutoring Systems. However, the approach to utilizing these models often involves directly formulating prompts to solicit specific information, lacking a solid theoretical foundation for prompt construction and empirical assessments of their impact on learning. This work advocates careful and caring AIED research by going through previous research on feedback generation in ITS, with emphasis on the theoretical frameworks they utilized and the efficacy of the corresponding design in empirical evaluations, and then suggesting opportunities to apply these evidence-based principles to the design, experiment, and evaluation phases of LLM-based feedback generation. The main contributions of this paper include: an avocation of applying more cautious, theoretically grounded methods in feedback generation in the era of generative AI; and practical suggestions on theory and evidence-based feedback design for LLM-powered ITS.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "Accepted to 25th International Conference on Artificial Intelligence in Education (AIED 2024) BlueSky special track"
    },
    {
        "paper id": "2405.04664",
        "abstract url": "https://arxiv.org/abs/2405.04664",
        "title": "Proximal Policy Optimization with Adaptive Exploration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Proximal Policy Optimization with Adaptive Exploration (axPPO) is introduced as a novel learning algorithm. This paper investigates the exploration-exploitation tradeoff within the context of reinforcement learning and aims to contribute new insights into reinforcement learning algorithm design. The proposed adaptive exploration framework dynamically adjusts the exploration magnitude during training based on the recent performance of the agent. Our proposed method outperforms standard PPO algorithms in learning efficiency, particularly when significant exploratory behavior is needed at the beginning of the learning process.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04671",
        "abstract url": "https://arxiv.org/abs/2405.04671",
        "title": "Interpretable Tensor Fusion",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Conventional machine learning methods are predominantly designed to predict outcomes based on a single data type. However, practical applications may encompass data of diverse types, such as text, images, and audio. We introduce interpretable tensor fusion (InTense), a multimodal learning method for training neural networks to simultaneously learn multimodal data representations and their interpretable fusion. InTense can separately capture both linear combinations and multiplicative interactions of diverse data types, thereby disentangling higher-order interactions from the individual effects of each modality. InTense provides interpretability out of the box by assigning relevance scores to modalities and their associations. The approach is theoretically grounded and yields meaningful relevance scores on multiple synthetic and real-world datasets. Experiments on six real-world datasets show that InTense outperforms existing state-of-the-art multimodal interpretable approaches in terms of accuracy and interpretability.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04677",
        "abstract url": "https://arxiv.org/abs/2405.04677",
        "title": "Responding to Generative AI Technologies with Research-through-Design: The Ryelands AI Lab as an Exploratory Study",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Generative AI technologies demand new practical and critical competencies, which call on design to respond to and foster these. We present an exploratory study guided by Research-through-Design, in which we partnered with a primary school to develop a constructionist curriculum centered on students interacting with a generative AI technology. We provide a detailed account of the design of and outputs from the curriculum and learning materials, finding centrally that the reflexive and prolonged `hands-on' approach led to a co-development of students' practical and critical competencies. From the study, we contribute guidance for designing constructionist approaches to generative AI technology education; further arguing to do so with `critical responsivity.' We then discuss how HCI researchers may leverage constructionist strategies in designing interactions with generative AI technologies; and suggest that Research-through-Design can play an important role as a `rapid response methodology' capable of reacting to fast-evolving, disruptive technologies such as generative AI.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "Conditionally Accepted at ACM DIS 2024"
    },
    {
        "paper id": "2405.04687",
        "abstract url": "https://arxiv.org/abs/2405.04687",
        "title": "Towards Human-AI Mutual Learning: A New Research Paradigm",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper describes a new research paradigm for studying human-AI collaboration, named \"human-AI mutual learning\", defined as the process where humans and AI agents preserve, exchange, and improve knowledge during human-AI collaboration. We describe relevant methodologies, motivations, domain examples, benefits, challenges, and future research agenda under this paradigm.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04700",
        "abstract url": "https://arxiv.org/abs/2405.04700",
        "title": "Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) deployed on edge devices learn through fine-tuning and updating a certain portion of their parameters. Although such learning methods can be optimized to reduce resource utilization, the overall required resources remain a heavy burden on edge devices. Instead, Retrieval-Augmented Generation (RAG), a resource-efficient LLM learning method, can improve the quality of the LLM-generated content without updating model parameters. However, the RAG-based LLM may involve repetitive searches on the profile data in every user-LLM interaction. This search can lead to significant latency along with the accumulation of user data. Conventional efforts to decrease latency result in restricting the size of saved user data, thus reducing the scalability of RAG as user data continuously grows. It remains an open question: how to free RAG from the constraints of latency and scalability on edge devices? In this paper, we propose a novel framework to accelerate RAG via Computing-in-Memory (CiM) architectures. It accelerates matrix multiplications by performing in-situ computation inside the memory while avoiding the expensive data transfer between the computing unit and memory. Our framework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive learning-based training method and noise-aware training, can enable RAG to efficiently search profile data with CiM. To the best of our knowledge, this is the first work utilizing CiM to accelerate RAG.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04706",
        "abstract url": "https://arxiv.org/abs/2405.04706",
        "title": "Guiding the Way: A Comprehensive Examination of AI Guidelines in Global Media",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "With the increasing adoption of artificial intelligence (AI) technologies in the news industry, media organizations have begun publishing guidelines that aim to promote the responsible, ethical, and unbiased implementation of AI-based technologies. These guidelines are expected to serve journalists and media workers by establishing best practices and a framework that helps them navigate ever-evolving AI tools. Drawing on institutional theory and digital inequality concepts, this study analyzes 37 AI guidelines for media purposes in 17 countries. Our analysis reveals key thematic areas, such as transparency, accountability, fairness, privacy, and the preservation of journalistic values. Results highlight shared principles and best practices that emerge from these guidelines, including the importance of human oversight, explainability of AI systems, disclosure of automated content, and protection of user data. However, the geographical distribution of these guidelines, highlighting the dominance of Western nations, particularly North America and Europe, can further ongoing concerns about power asymmetries in AI adoption and consequently isomorphism outside these regions. Our results may serve as a resource for news organizations, policymakers, and stakeholders looking to navigate the complex AI development toward creating a more inclusive and equitable digital future for the media industry worldwide.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "32 pages, 2 tables, 3 figures"
    },
    {
        "paper id": "2405.04710",
        "abstract url": "https://arxiv.org/abs/2405.04710",
        "title": "Untangling Lariats: Subgradient Following of Variationally Penalized Objectives",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We describe a novel subgradient following apparatus for calculating the optimum of convex problems with variational penalties. In this setting, we receive a sequence $y_i,\\ldots,y_n$ and seek a smooth sequence $x_1,\\ldots,x_n$. The smooth sequence attains the minimum Bregman divergence to an input sequence with additive variational penalties in the general form of $\\sum_i g_i(x_{i+1}-x_i)$. We derive, as special cases of our apparatus, known algorithms for the fused lasso and isotonic regression. Our approach also facilitates new variational penalties such as non-smooth barrier functions. We next derive and analyze multivariate problems in which $\\mathbf{x}_i,\\mathbf{y}_i\\in\\mathbb{R}^d$ and variational penalties that depend on $\\|\\mathbf{x}_{i+1}-\\mathbf{x}_i\\|$. The norms we consider are $\\ell_2$ and $\\ell_\\infty$ which promote group sparsity. Last but not least, we derive a lattice-based subgradient following for variational penalties characterized through the output of arbitrary convolutional filters. This paradigm yields efficient solvers for problems in which sparse high-order discrete derivatives such as acceleration and jerk are desirable.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04711",
        "abstract url": "https://arxiv.org/abs/2405.04711",
        "title": "Community detection in multi-layer bipartite networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The problem of community detection in multi-layer undirected networks has received considerable attention in recent years. However, practical scenarios often involve multi-layer bipartite networks, where each layer consists of two distinct types of nodes. Existing community detection algorithms tailored for multi-layer undirected networks are not directly applicable to multi-layer bipartite networks. To address this challenge, this paper introduces a novel multi-layer degree-corrected stochastic co-block model specifically designed to capture the underlying community structure within multi-layer bipartite networks. Within this framework, we propose an efficient debiased spectral co-clustering algorithm for detecting nodes' communities. We establish the consistent estimation property of our proposed algorithm and demonstrate that an increased number of layers in bipartite networks improves the accuracy of community detection. Through extensive numerical experiments, we showcase the superior performance of our algorithm compared to existing methods. Additionally, we validate our algorithm by applying it to real-world multi-layer network datasets, yielding meaningful and insightful results.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph",
            "stat.ME"
        ],
        "comment": "24 pages, 13 figures, 1 table"
    },
    {
        "paper id": "2405.04715",
        "abstract url": "https://arxiv.org/abs/2405.04715",
        "title": "Causality Pursuit from Heterogeneous Environments via Neural Adversarial Invariance Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Statistics suffers from a fundamental problem, \"the curse of endogeneity\" -- the regression function, or more broadly the prediction risk minimizer with infinite data, may not be the target we wish to pursue. This is because when complex data are collected from multiple sources, the biases deviated from the interested (causal) association inherited in individuals or sub-populations are not expected to be canceled. Traditional remedies are of hindsight and restrictive in being tailored to prior knowledge like untestable cause-effect structures, resulting in methods that risk model misspecification and lack scalable applicability. This paper seeks to offer a purely data-driven and universally applicable method that only uses the heterogeneity of the biases in the data rather than following pre-offered commandments. Such an idea is formulated as a nonparametric invariance pursuit problem, whose goal is to unveil the invariant conditional expectation $m^\\star(x)\\equiv \\mathbb{E}[Y^{(e)}|X_{S^\\star}^{(e)}=x_{S^\\star}]$ with unknown important variable set $S^\\star$ across heterogeneous environments $e\\in \\mathcal{E}$. Under the structural causal model framework, $m^\\star$ can be interpreted as certain data-driven causality in general. The paper contributes to proposing a novel framework, called Focused Adversarial Invariance Regularization (FAIR), formulated as a single minimax optimization program that can solve the general invariance pursuit problem. As illustrated by the unified non-asymptotic analysis, our adversarial estimation framework can attain provable sample-efficient estimation akin to standard regression under a minimal identification condition for various tasks and models. As an application, the FAIR-NN estimator realized by two Neural Network classes is highlighted as the first approach to attain statistically efficient estimation in general nonparametric invariance learning.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": "47 pages, 5 figures with appendix"
    },
    {
        "paper id": "2405.04732",
        "abstract url": "https://arxiv.org/abs/2405.04732",
        "title": "S-EQA: Tackling Situational Queries in Embodied Question Answering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present and tackle the problem of Embodied Question Answering (EQA) with Situational Queries (S-EQA) in a household environment. Unlike prior EQA work tackling simple queries that directly reference target objects and quantifiable properties pertaining them, EQA with situational queries (such as \"Is the bathroom clean and dry?\") is more challenging, as the agent needs to figure out not just what the target objects pertaining to the query are, but also requires a consensus on their states to be answerable. Towards this objective, we first introduce a novel Prompt-Generate-Evaluate (PGE) scheme that wraps around an LLM's output to create a dataset of unique situational queries, corresponding consensus object information, and predicted answers. PGE maintains uniqueness among the generated queries, using multiple forms of semantic similarity. We validate the generated dataset via a large scale user-study conducted on M-Turk, and introduce it as S-EQA, the first dataset tackling EQA with situational queries. Our user study establishes the authenticity of S-EQA with a high 97.26% of the generated queries being deemed answerable, given the consensus object data. Conversely, we observe a low correlation of 46.2% on the LLM-predicted answers to human-evaluated ones; indicating the LLM's poor capability in directly answering situational queries, while establishing S-EQA's usability in providing a human-validated consensus for an indirect solution. We evaluate S-EQA via Visual Question Answering (VQA) on VirtualHome, which unlike other simulators, contains several objects with modifiable states that also visually appear different upon modification -- enabling us to set a quantitative benchmark for S-EQA. To the best of our knowledge, this is the first work to introduce EQA with situational queries, and also the first to use a generative approach for query creation.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "8 Pages"
    },
    {
        "paper id": "2405.04741",
        "abstract url": "https://arxiv.org/abs/2405.04741",
        "title": "All in One Framework for Multimodal Re-identification in the Wild",
        "rating": "0.5",
        "keywords": [
            [
                "trajectory",
                "infrared"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In Re-identification (ReID), recent advancements yield noteworthy progress in both unimodal and cross-modal retrieval tasks. However, the challenge persists in developing a unified framework that could effectively handle varying multimodal data, including RGB, infrared, sketches, and textual information. Additionally, the emergence of large-scale models shows promising performance in various vision tasks but the foundation model in ReID is still blank. In response to these challenges, a novel multimodal learning paradigm for ReID is introduced, referred to as All-in-One (AIO), which harnesses a frozen pre-trained big model as an encoder, enabling effective multimodal retrieval without additional fine-tuning. The diverse multimodal data in AIO are seamlessly tokenized into a unified space, allowing the modality-shared frozen encoder to extract identity-consistent features comprehensively across all modalities. Furthermore, a meticulously crafted ensemble of cross-modality heads is designed to guide the learning trajectory. AIO is the \\textbf{first} framework to perform all-in-one ReID, encompassing four commonly used modalities. Experiments on cross-modal and multimodal ReID reveal that AIO not only adeptly handles various modal data but also excels in challenging contexts, showcasing exceptional performance in zero-shot and domain generalization scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 3 figure, CVPR 2024"
    },
    {
        "paper id": "2405.04769",
        "abstract url": "https://arxiv.org/abs/2405.04769",
        "title": "Inference With Combining Rules From Multiple Differentially Private Synthetic Datasets",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Differential privacy (DP) has been accepted as a rigorous criterion for measuring the privacy protection offered by random mechanisms used to obtain statistics or, as we will study here, synthetic datasets from confidential data. Methods to generate such datasets are increasingly numerous, using varied tools including Bayesian models, deep neural networks and copulas. However, little is still known about how to properly perform statistical inference with these differentially private synthetic (DIPS) datasets. The challenge is for the analyses to take into account the variability from the synthetic data generation in addition to the usual sampling variability. A similar challenge also occurs when missing data is imputed before analysis, and statisticians have developed appropriate inference procedures for this case, which we tend extended to the case of synthetic datasets for privacy. In this work, we study the applicability of these procedures, based on combining rules, to the analysis of DIPS datasets. Our empirical experiments show that the proposed combining rules may offer accurate inference in certain contexts, but not in all cases.",
        "subjects": [
            "stat.ME",
            "cs.CR",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04771",
        "abstract url": "https://arxiv.org/abs/2405.04771",
        "title": "Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "skeleton"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "To build a cross-modal latent space between 3D human motion and language, acquiring large-scale and high-quality human motion data is crucial. However, unlike the abundance of image data, the scarcity of motion data has limited the performance of existing motion-language models. To counter this, we introduce \"motion patches\", a new representation of motion sequences, and propose using Vision Transformers (ViT) as motion encoders via transfer learning, aiming to extract useful knowledge from the image domain and apply it to the motion domain. These motion patches, created by dividing and sorting skeleton joints based on body parts in motion sequences, are robust to varying skeleton structures, and can be regarded as color image patches in ViT. We find that transfer learning with pre-trained weights of ViT obtained through training with 2D image data can boost the performance of motion analysis, presenting a promising direction for addressing the issue of limited motion data. Our extensive experiments show that the proposed motion patches, used jointly with ViT, achieve state-of-the-art performance in the benchmarks of text-to-motion retrieval, and other novel challenging tasks, such as cross-skeleton recognition, zero-shot motion classification, and human interaction recognition, which are currently impeded by the lack of data.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to CVPR 2024, Project website: https://yu1ut.com/MotionPatches-HP/"
    },
    {
        "paper id": "2405.04776",
        "abstract url": "https://arxiv.org/abs/2405.04776",
        "title": "Chain of Thoughtlessness: An Analysis of CoT in Planning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language model (LLM) performance on reasoning problems typically does not generalize out of distribution. Previous work has claimed that this can be mitigated by modifying prompts to include examples with chains of thought--demonstrations of solution procedures--with the intuition that it is possible to in-context teach an LLM an algorithm for solving the problem. This paper presents a case study of chain of thought on problems from Blocksworld, a classical planning domain, and examine the performance of two state-of-the-art LLMs across two axes: generality of examples given in prompt, and complexity of problems queried with each prompt. While our problems are very simple, we only find meaningful performance improvements from chain of thought prompts when those prompts are exceedingly specific to their problem class, and that those improvements quickly deteriorate as the size n of the query-specified stack grows past the size of stacks shown in the examples. Our results hint that, contrary to previous claims in the literature, CoT's performance improvements do not stem from the model learning general algorithmic procedures via demonstrations and depend on carefully engineering highly problem specific prompts. This spotlights drawbacks of chain of thought, especially because of the sharp tradeoff between possible performance gains and the amount of human labor necessary to generate examples with correct reasoning traces.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2305.15771"
    },
    {
        "paper id": "2405.05285",
        "abstract url": "https://arxiv.org/abs/2405.05285",
        "title": "Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study investigates the metacognitive capabilities of Large Language Models relative to human metacognition in the context of the International Coaching Federation ICF mimicking exam, a situational judgment test related to coaching competencies. Using a mixed method approach, we assessed the metacognitive performance, including sensitivity, accuracy in probabilistic predictions, and bias, of human participants and five advanced LLMs (GPT-4, Claude-3-Opus 3, Mistral Large, Llama 3, and Gemini 1.5 Pro). The results indicate that LLMs outperformed humans across all metacognitive metrics, particularly in terms of reduced overconfidence, compared to humans. However, both LLMs and humans showed less adaptability in ambiguous scenarios, adhering closely to predefined decision frameworks. The study suggests that Generative AI can effectively engage in human-like metacognitive processing without conscious awareness. Implications of the study are discussed in relation to development of AI simulators that scaffold cognitive and metacognitive aspects of mastering coaching competencies. More broadly, implications of these results are discussed in relation to development of metacognitive modules that lead towards more autonomous and intuitive AI systems.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04041",
        "abstract url": "https://arxiv.org/abs/2405.04041",
        "title": "Feature Map Convergence Evaluation for Functional Module",
        "rating": "0",
        "keywords": [
            [
                "Autonomous driving"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Autonomous driving perception models are typically composed of multiple functional modules that interact through complex relationships to accomplish environment understanding. However, perception models are predominantly optimized as a black box through end-to-end training, lacking independent evaluation of functional modules, which poses difficulties for interpretability and optimization. Pioneering in the issue, we propose an evaluation method based on feature map analysis to gauge the convergence of model, thereby assessing functional modules' training maturity. We construct a quantitative metric named as the Feature Map Convergence Score (FMCS) and develop Feature Map Convergence Evaluation Network (FMCE-Net) to measure and predict the convergence degree of models respectively. FMCE-Net achieves remarkable predictive accuracy for FMCS across multiple image classification experiments, validating the efficacy and robustness of the introduced approach. To the best of our knowledge, this is the first independent evaluation method for functional modules, offering a new paradigm for the training assessment towards perception models.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04071",
        "abstract url": "https://arxiv.org/abs/2405.04071",
        "title": "IMU-Aided Event-based Stereo Visual Odometry",
        "rating": "0",
        "keywords": [
            [
                "6-DoF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Direct methods for event-based visual odometry solve the mapping and camera pose tracking sub-problems by establishing implicit data association in a way that the generative model of events is exploited. The main bottlenecks faced by state-of-the-art work in this field include the high computational complexity of mapping and the limited accuracy of tracking. In this paper, we improve our previous direct pipeline \\textit{Event-based Stereo Visual Odometry} in terms of accuracy and efficiency. To speed up the mapping operation, we propose an efficient strategy of edge-pixel sampling according to the local dynamics of events. The mapping performance in terms of completeness and local smoothness is also improved by combining the temporal stereo results and the static stereo results. To circumvent the degeneracy issue of camera pose tracking in recovering the yaw component of general 6-DoF motion, we introduce as a prior the gyroscope measurements via pre-integration. Experiments on publicly available datasets justify our improvement. We release our pipeline as an open-source software for future research in this field.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "10 pages, 7 figures, ICRA"
    },
    {
        "paper id": "2405.04100",
        "abstract url": "https://arxiv.org/abs/2405.04100",
        "title": "ESP: Extro-Spective Prediction for Long-term Behavior Reasoning in Emergency Scenarios",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Emergent-scene safety is the key milestone for fully autonomous driving, and reliable on-time prediction is essential to maintain safety in emergency scenarios. However, these emergency scenarios are long-tailed and hard to collect, which restricts the system from getting reliable predictions. In this paper, we build a new dataset, which aims at the long-term prediction with the inconspicuous state variation in history for the emergency event, named the Extro-Spective Prediction (ESP) problem. Based on the proposed dataset, a flexible feature encoder for ESP is introduced to various prediction methods as a seamless plug-in, and its consistent performance improvement underscores its efficacy. Furthermore, a new metric named clamped temporal error (CTE) is proposed to give a more comprehensive evaluation of prediction performance, especially in time-sensitive emergency events of subseconds. Interestingly, as our ESP features can be described in human-readable language naturally, the application of integrating into ChatGPT also shows huge potential. The ESP-dataset and all benchmarks are released at https://dingrui-wang.github.io/ESP-Dataset/.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by ICRA 2024 as Oral Presentation"
    },
    {
        "paper id": "2405.04103",
        "abstract url": "https://arxiv.org/abs/2405.04103",
        "title": "COM3D: Leveraging Cross-View Correspondence and Cross-Modal Mining for 3D Retrieval",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we investigate an open research task of cross-modal retrieval between 3D shapes and textual descriptions. Previous approaches mainly rely on point cloud encoders for feature extraction, which may ignore key inherent features of 3D shapes, including depth, spatial hierarchy, geometric continuity, etc. To address this issue, we propose COM3D, making the first attempt to exploit the cross-view correspondence and cross-modal mining to enhance the retrieval performance. Notably, we augment the 3D features through a scene representation transformer, to generate cross-view correspondence features of 3D shapes, which enrich the inherent features and enhance their compatibility with text matching. Furthermore, we propose to optimize the cross-modal matching process based on the semi-hard negative example mining method, in an attempt to improve the learning efficiency. Extensive quantitative and qualitative experiments demonstrate the superiority of our proposed COM3D, achieving state-of-the-art results on the Text2Shape dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICME 2024 oral"
    },
    {
        "paper id": "2405.04121",
        "abstract url": "https://arxiv.org/abs/2405.04121",
        "title": "ELiTe: Efficient Image-to-LiDAR Knowledge Transfer for Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "Parameter-Efficient",
                "Efficient Fine-Tuning"
            ],
            [
                "point cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cross-modal knowledge transfer enhances point cloud representation learning in LiDAR semantic segmentation. Despite its potential, the \\textit{weak teacher challenge} arises due to repetitive and non-diverse car camera images and sparse, inaccurate ground truth labels. To address this, we propose the Efficient Image-to-LiDAR Knowledge Transfer (ELiTe) paradigm. ELiTe introduces Patch-to-Point Multi-Stage Knowledge Distillation, transferring comprehensive knowledge from the Vision Foundation Model (VFM), extensively trained on diverse open-world images. This enables effective knowledge transfer to a lightweight student model across modalities. ELiTe employs Parameter-Efficient Fine-Tuning to strengthen the VFM teacher and expedite large-scale model training with minimal costs. Additionally, we introduce the Segment Anything Model based Pseudo-Label Generation approach to enhance low-quality image labels, facilitating robust semantic representations. Efficient knowledge transfer in ELiTe yields state-of-the-art results on the SemanticKITTI benchmark, outperforming real-time inference models. Our approach achieves this with significantly fewer parameters, confirming its effectiveness and efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 6 figures, ICME 2024 oral"
    },
    {
        "paper id": "2405.04133",
        "abstract url": "https://arxiv.org/abs/2405.04133",
        "title": "Exposing AI-generated Videos: A Benchmark Dataset and a Local-and-Global Temporal Defect Based Detection Method",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The generative model has made significant advancements in the creation of realistic videos, which causes security issues. However, this emerging risk has not been adequately addressed due to the absence of a benchmark dataset for AI-generated videos. In this paper, we first construct a video dataset using advanced diffusion-based video generation algorithms with various semantic contents. Besides, typical video lossy operations over network transmission are adopted to generate degraded samples. Then, by analyzing local and global temporal defects of current AI-generated videos, a novel detection framework by adaptively learning local motion information and global appearance variation is constructed to expose fake videos. Finally, experiments are conducted to evaluate the generalization and robustness of different spatial and temporal domain detection methods, where the results can serve as the baseline and demonstrate the research challenge for future studies.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04136",
        "abstract url": "https://arxiv.org/abs/2405.04136",
        "title": "Enriched BERT Embeddings for Scholarly Publication Classification",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the rapid expansion of academic literature and the proliferation of preprints, researchers face growing challenges in manually organizing and labeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses this challenge organized as a competition. The goal is to develop a classifier capable of predicting one of 123 predefined classes from the Open Research Knowledge Graph (ORKG) taxonomy of research fields for a given article.This paper presents our results. Initially, we enrich the dataset (containing English scholarly articles sourced from ORKG and arXiv), then leverage different pre-trained language Models (PLMs), specifically BERT, and explore their efficacy in transfer learning for this downstream task. Our experiments encompass feature-based and fine-tuned transfer learning approaches using diverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and SPECTER2. We conduct hyperparameter tuning and investigate the impact of data augmentation from bibliographic databases such as OpenAlex, Semantic Scholar, and Crossref. Our results demonstrate that fine-tuning pre-trained models substantially enhances classification performance, with SPECTER2 emerging as the most accurate model. Moreover, enriching the dataset with additional metadata improves classification outcomes significantly, especially when integrating information from S2AG, OpenAlex and Crossref. Our best-performing approach achieves a weighted F1-score of 0.7415. Overall, our study contributes to the advancement of reliable automated systems for scholarly publication categorization, offering a potential solution to the laborious manual curation process, thereby facilitating researchers in efficiently locating relevant resources.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "8 pages, 2 figures, NSLP2024 conference"
    },
    {
        "paper id": "2405.04180",
        "abstract url": "https://arxiv.org/abs/2405.04180",
        "title": "Sora Detector: A Unified Hallucination Detection for Large Text-to-Video Models",
        "rating": "0",
        "keywords": [
            [
                "synthesis",
                "Text-to-Video"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement in text-to-video (T2V) generative models has enabled the synthesis of high-fidelity video content guided by textual descriptions. Despite this significant progress, these models are often susceptible to hallucination, generating contents that contradict the input text, which poses a challenge to their reliability and practical deployment. To address this critical issue, we introduce the SoraDetector, a novel unified framework designed to detect hallucinations across diverse large T2V models, including the cutting-edge Sora model. Our framework is built upon a comprehensive analysis of hallucination phenomena, categorizing them based on their manifestation in the video content. Leveraging the state-of-the-art keyframe extraction techniques and multimodal large language models, SoraDetector first evaluates the consistency between extracted video content summary and textual prompts, then constructs static and dynamic knowledge graphs (KGs) from frames to detect hallucination both in single frames and across frames. Sora Detector provides a robust and quantifiable measure of consistency, static and dynamic hallucination. In addition, we have developed the Sora Detector Agent to automate the hallucination detection process and generate a complete video quality report for each input video. Lastly, we present a novel meta-evaluation benchmark, T2VHaluBench, meticulously crafted to facilitate the evaluation of advancements in T2V hallucination detection. Through extensive experiments on videos generated by Sora and other large T2V models, we demonstrate the efficacy of our approach in accurately detecting hallucinations. The code and dataset can be accessed via GitHub.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2306.08302, arXiv:2403.05131 by other authors"
    },
    {
        "paper id": "2405.04233",
        "abstract url": "https://arxiv.org/abs/2405.04233",
        "title": "Vidu: a Highly Consistent, Dynamic and Skilled Text-to-Video Generator with Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Video"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Vidu, a high-performance text-to-video generator that is capable of producing 1080p videos up to 16 seconds in a single generation. Vidu is a diffusion model with U-ViT as its backbone, which unlocks the scalability and the capability for handling long videos. Vidu exhibits strong coherence and dynamism, and is capable of generating both realistic and imaginative videos, as well as understanding some professional photography techniques, on par with Sora -- the most powerful reported text-to-video generator. Finally, we perform initial experiments on other controllable video generation, including canny-to-video generation, video prediction and subject-driven generation, which demonstrate promising results.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project page at https://www.shengshu-ai.com/vidu"
    },
    {
        "paper id": "2405.04299",
        "abstract url": "https://arxiv.org/abs/2405.04299",
        "title": "ViewFormer: Exploring Spatiotemporal Modeling for Multi-View 3D Occupancy Perception via View-Guided Transformers",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D occupancy, an advanced perception technology for driving scenarios, represents the entire scene without distinguishing between foreground and background by quantifying the physical space into a grid map. The widely adopted projection-first deformable attention, efficient in transforming image features into 3D representations, encounters challenges in aggregating multi-view features due to sensor deployment constraints. To address this issue, we propose our learning-first view attention mechanism for effective multi-view feature aggregation. Moreover, we showcase the scalability of our view attention across diverse multi-view 3D tasks, such as map construction and 3D object detection. Leveraging the proposed view attention as well as an additional multi-frame streaming temporal attention, we introduce ViewFormer, a vision-centric transformer-based framework for spatiotemporal feature aggregation. To further explore occupancy-level flow representation, we present FlowOcc3D, a benchmark built on top of existing high-quality datasets. Qualitative and quantitative analyses on this benchmark reveal the potential to represent fine-grained dynamic scenes. Extensive experiments show that our approach significantly outperforms prior state-of-the-art methods. The codes and benchmark will be released soon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04312",
        "abstract url": "https://arxiv.org/abs/2405.04312",
        "title": "Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have shown remarkable performance in image generation in recent years. However, due to a quadratic increase in memory during generating ultra-high-resolution images (e.g. 4096*4096), the resolution of generated images is often limited to 1024*1024. In this work. we propose a unidirectional block attention mechanism that can adaptively adjust the memory overhead during the inference process and handle global dependencies. Building on this module, we adopt the DiT structure for upsampling and develop an infinite super-resolution model capable of upsampling images of various shapes and resolutions. Comprehensive experiments show that our model achieves SOTA performance in generating ultra-high-resolution images in both machine and human evaluation. Compared to commonly used UNet structures, our model can save more than 5x memory when generating 4096*4096 images. The project URL is https://github.com/THUDM/Inf-DiT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04392",
        "abstract url": "https://arxiv.org/abs/2405.04392",
        "title": "BILTS: A novel bi-invariant local trajectory-shape descriptor for rigid-body motion",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Measuring the similarity between motions and established motion models is crucial for motion analysis, recognition, generation, and adaptation. To enhance similarity measurement across diverse contexts, invariant motion descriptors have been proposed. However, for rigid-body motion, few invariant descriptors exist that are bi-invariant, meaning invariant to both the body and world reference frames used to describe the motion. Moreover, their robustness to singularities is limited. This paper introduces a novel Bi-Invariant Local Trajectory-Shape descriptor (BILTS) and a corresponding dissimilarity measure. Mathematical relationships between BILTS and existing descriptors are derived, providing new insights into their properties. The paper also includes an algorithm to reproduce the motion from the BILTS descriptor, demonstrating its bidirectionality and usefulness for trajectory generation. Experimental validation using datasets of daily-life activities shows the higher robustness of the BILTS descriptor compared to the bi-invariant ISA descriptor. This higher robustness supports the further application of bi-invariant descriptors for motion recognition and generalization.",
        "subjects": [
            "cs.RO",
            "cs.CG",
            "cs.CV"
        ],
        "comment": "This work has been submitted as a regular research paper for consideration in the IEEE Transactions on Robotics. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2405.04453",
        "abstract url": "https://arxiv.org/abs/2405.04453",
        "title": "Towards Continual Knowledge Graph Embedding via Incremental Distillation",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Traditional knowledge graph embedding (KGE) methods typically require preserving the entire knowledge graph (KG) with significant training costs when new knowledge emerges. To address this issue, the continual knowledge graph embedding (CKGE) task has been proposed to train the KGE model by learning emerging knowledge efficiently while simultaneously preserving decent old knowledge. However, the explicit graph structure in KGs, which is critical for the above goal, has been heavily ignored by existing CKGE methods. On the one hand, existing methods usually learn new triples in a random order, destroying the inner structure of new KGs. On the other hand, old triples are preserved with equal priority, failing to alleviate catastrophic forgetting effectively. In this paper, we propose a competitive method for CKGE based on incremental distillation (IncDE), which considers the full use of the explicit graph structure in KGs. First, to optimize the learning order, we introduce a hierarchical strategy, ranking new triples for layer-by-layer learning. By employing the inter- and intra-hierarchical orders together, new triples are grouped into layers based on the graph structure features. Secondly, to preserve the old knowledge effectively, we devise a novel incremental distillation mechanism, which facilitates the seamless transfer of entity representations from the previous layer to the next one, promoting old knowledge preservation. Finally, we adopt a two-stage training paradigm to avoid the over-corruption of old knowledge influenced by under-trained new knowledge. Experimental results demonstrate the superiority of IncDE over state-of-the-art baselines. Notably, the incremental distillation mechanism contributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR) score.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted by AAAI 2024"
    },
    {
        "paper id": "2405.04457",
        "abstract url": "https://arxiv.org/abs/2405.04457",
        "title": "Towards Geographic Inclusion in the Evaluation of Text-to-Image Models",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "cs.CY",
                "cs.CV"
            ]
        ],
        "abstract": "Rapid progress in text-to-image generative models coupled with their deployment for visual content creation has magnified the importance of thoroughly evaluating their performance and identifying potential biases. In pursuit of models that generate images that are realistic, diverse, visually appealing, and consistent with the given prompt, researchers and practitioners often turn to automated metrics to facilitate scalable and cost-effective performance profiling. However, commonly-used metrics often fail to account for the full diversity of human preference; often even in-depth human evaluations face challenges with subjectivity, especially as interpretations of evaluation criteria vary across regions and cultures. In this work, we conduct a large, cross-cultural study to study how much annotators in Africa, Europe, and Southeast Asia vary in their perception of geographic representation, visual appeal, and consistency in real and generated images from state-of-the art public APIs. We collect over 65,000 image annotations and 20 survey responses. We contrast human annotations with common automated metrics, finding that human preferences vary notably across geographic location and that current metrics do not fully account for this diversity. For example, annotators in different locations often disagree on whether exaggerated, stereotypical depictions of a region are considered geographically representative. In addition, the utility of automatic evaluations is dependent on assumptions about their set-up, such as the alignment of feature extractors with human perception of object similarity or the definition of \"appeal\" captured in reference datasets used to ground evaluations. We recommend steps for improved automatic and human evaluations.",
        "subjects": [
            "cs.CV",
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04471",
        "abstract url": "https://arxiv.org/abs/2405.04471",
        "title": "Universal Spatial Audio Transcoder",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper addresses the challenges associated with both the conversion between different spatial audio formats and the decoding of a spatial audio format to a specific loudspeaker layout. Existing approaches often rely on layout remapping tools, which may not guarantee optimal conversion from a psychoacoustic perspective. To overcome these challenges, we present the Universal Spatial Audio Transcoder(USAT) method and its corresponding open source implementation. USAT generates an optimal decoder or transcoder for any input spatial audio format, adapting it to any output format or 2D/3D loudspeaker configuration. Drawing upon optimization techniques based on psychoacoustic principles, the algorithm maximizes the preservation of spatial information. We present examples of the decoding and transcoding of several audio formats, and show that USAT approach is advantageous compared to the most common methods in the field.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "12 pages, 8 figures. Accepted for presentation at the AES 156th Convention, Madrid, Spain (June 2024)"
    },
    {
        "paper id": "2405.04496",
        "abstract url": "https://arxiv.org/abs/2405.04496",
        "title": "Edit-Your-Motion: Space-Time Diffusion Decoupling Learning for Video Motion Editing",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "video editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing diffusion-based video editing methods have achieved impressive results in motion editing. Most of the existing methods focus on the motion alignment between the edited video and the reference video. However, these methods do not constrain the background and object content of the video to remain unchanged, which makes it possible for users to generate unexpected videos. In this paper, we propose a one-shot video motion editing method called Edit-Your-Motion that requires only a single text-video pair for training. Specifically, we design the Detailed Prompt-Guided Learning Strategy (DPL) to decouple spatio-temporal features in space-time diffusion models. DPL separates learning object content and motion into two training stages. In the first training stage, we focus on learning the spatial features (the features of object content) and breaking down the temporal relationships in the video frames by shuffling them. We further propose Recurrent-Causal Attention (RC-Attn) to learn the consistent content features of the object from unordered video frames. In the second training stage, we restore the temporal relationship in video frames to learn the temporal feature (the features of the background and object's motion). We also adopt the Noise Constraint Loss to smooth out inter-frame differences. Finally, in the inference stage, we inject the content features of the source object into the editing branch through a two-branch structure (editing branch and reconstruction branch). With Edit-Your-Motion, users can edit the motion of objects in the source video to generate more exciting and diverse videos. Comprehensive qualitative experiments, quantitative experiments and user preference studies demonstrate that Edit-Your-Motion performs better than other methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04520",
        "abstract url": "https://arxiv.org/abs/2405.04520",
        "title": "NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have manifested strong ability to generate codes for productive activities. However, current benchmarks for code synthesis, such as HumanEval, MBPP, and DS-1000, are predominantly oriented towards introductory tasks on algorithm and data science, insufficiently satisfying challenging requirements prevalent in real-world coding. To fill this gap, we propose NaturalCodeBench (NCB), a challenging code benchmark designed to mirror the complexity and variety of scenarios in real coding tasks. NCB comprises 402 high-quality problems in Python and Java, meticulously selected from natural user queries from online coding services, covering 6 different domains. Noting the extraordinary difficulty in creating testing cases for real-world queries, we also introduce a semi-automated pipeline to enhance the efficiency of test case construction. Comparing with manual solutions, it achieves an efficiency increase of more than 4 times. Our systematic experiments on 39 LLMs find that performance gaps on NCB between models with close HumanEval scores could still be significant, indicating a lack of focus on practical code synthesis scenarios or over-specified optimization on HumanEval. On the other hand, even the best-performing GPT-4 is still far from satisfying on NCB. The evaluation toolkit and development set are available at https://github.com/THUDM/NaturalCodeBench.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04533",
        "abstract url": "https://arxiv.org/abs/2405.04533",
        "title": "ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Numerous methods have been proposed to detect, estimate, and analyze properties of people in images, including the estimation of 3D pose, shape, contact, human-object interaction, emotion, and more. Each of these methods works in isolation instead of synergistically. Here we address this problem and build a language-driven human understanding system -- ChatHuman, which combines and integrates the skills of many different methods. To do so, we finetune a Large Language Model (LLM) to select and use a wide variety of existing tools in response to user inputs. In doing so, ChatHuman is able to combine information from multiple tools to solve problems more accurately than the individual tools themselves and to leverage tool output to improve its ability to reason about humans. The novel features of ChatHuman include leveraging academic publications to guide the application of 3D human-related tools, employing a retrieval-augmented generation model to generate in-context-learning examples for handling new tools, and discriminating and integrating tool results to enhance 3D human understanding. Our experiments show that ChatHuman outperforms existing models in both tool selection accuracy and performance across multiple 3D human-related tasks. ChatHuman is a step towards consolidating diverse methods for human analysis into a single, powerful, system for 3D human reasoning.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project page: https://chathuman.github.io"
    },
    {
        "paper id": "2405.04675",
        "abstract url": "https://arxiv.org/abs/2405.04675",
        "title": "TexControl: Sketch-Based Two-Stage Fashion Image Generation Using Diffusion Model",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning-based sketch-to-clothing image generation provides the initial designs and inspiration in the fashion design processes. However, clothing generation from freehand drawing is challenging due to the sparse and ambiguous information from the drawn sketches. The current generation models may have difficulty generating detailed texture information. In this work, we propose TexControl, a sketch-based fashion generation framework that uses a two-stage pipeline to generate the fashion image corresponding to the sketch input. First, we adopt ControlNet to generate the fashion image from sketch and keep the image outline stable. Then, we use an image-to-image method to optimize the detailed textures of the generated images and obtain the final results. The evaluation results show that TexControl can generate fashion images with high-quality texture as fine-grained image generation.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "5 pages, 8 figures, accepted in NICOGRAPH International 2024"
    },
    {
        "paper id": "2405.04682",
        "abstract url": "https://arxiv.org/abs/2405.04682",
        "title": "TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Text-to-Video"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in diffusion-based generative modeling have led to the development of text-to-video (T2V) models that can generate high-quality videos conditioned on a text prompt. Most of these T2V models often produce single-scene video clips that depict an entity performing a particular action (e.g., `a red panda climbing a tree'). However, it is pertinent to generate multi-scene videos since they are ubiquitous in the real-world (e.g., `a red panda climbing a tree' followed by `the red panda sleeps on the top of the tree'). To generate multi-scene videos from the pretrained T2V model, we introduce Time-Aligned Captions (TALC) framework. Specifically, we enhance the text-conditioning mechanism in the T2V architecture to recognize the temporal alignment between the video scenes and scene descriptions. For instance, we condition the visual features of the earlier and later scenes of the generated video with the representations of the first scene description (e.g., `a red panda climbing a tree') and second scene description (e.g., `the red panda sleeps on the top of the tree'), respectively. As a result, we show that the T2V model can generate multi-scene videos that adhere to the multi-scene text descriptions and be visually consistent (e.g., entity and background). Further, we finetune the pretrained T2V model with multi-scene video-text data using the TALC framework. We show that the TALC-finetuned model outperforms the baseline methods by 15.5 points in the overall score, which averages visual consistency and text adherence using human evaluation. The project website is https://talc-mst2v.github.io/.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "23 pages, 12 figures, 8 tables"
    },
    {
        "paper id": "2405.04752",
        "abstract url": "https://arxiv.org/abs/2405.04752",
        "title": "HILCodec: High Fidelity and Lightweight Neural Audio Codec",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The recent advancement of end-to-end neural audio codecs enables compressing audio at very low bitrates while reconstructing the output audio with high fidelity. Nonetheless, such improvements often come at the cost of increased model complexity. In this paper, we identify and address the problems of existing neural audio codecs. We show that the performance of Wave-U-Net does not increase consistently as the network depth increases. We analyze the root cause of such a phenomenon and suggest a variance-constrained design. Also, we reveal various distortions in previous waveform domain discriminators and propose a novel distortion-free discriminator. The resulting model, \\textit{HILCodec}, is a real-time streaming audio codec that demonstrates state-of-the-art quality across various bitrates and audio types.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04773",
        "abstract url": "https://arxiv.org/abs/2405.04773",
        "title": "Hypergraph-enhanced Dual Semi-supervised Graph Classification",
        "rating": "0",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In this paper, we study semi-supervised graph classification, which aims at accurately predicting the categories of graphs in scenarios with limited labeled graphs and abundant unlabeled graphs. Despite the promising capability of graph neural networks (GNNs), they typically require a large number of costly labeled graphs, while a wealth of unlabeled graphs fail to be effectively utilized. Moreover, GNNs are inherently limited to encoding local neighborhood information using message-passing mechanisms, thus lacking the ability to model higher-order dependencies among nodes. To tackle these challenges, we propose a Hypergraph-Enhanced DuAL framework named HEAL for semi-supervised graph classification, which captures graph semantics from the perspective of the hypergraph and the line graph, respectively. Specifically, to better explore the higher-order relationships among nodes, we design a hypergraph structure learning to adaptively learn complex node dependencies beyond pairwise relations. Meanwhile, based on the learned hypergraph, we introduce a line graph to capture the interaction between hyperedges, thereby better mining the underlying semantic structures. Finally, we develop a relational consistency learning to facilitate knowledge transfer between the two branches and provide better mutual guidance. Extensive experiments on real-world graph datasets verify the effectiveness of the proposed method against existing state-of-the-art methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IR",
            "cs.SI"
        ],
        "comment": "Accepted by Proceedings of the 41st International Conference on Machine Learning (ICML 2024)"
    },
    {
        "paper id": "2405.04778",
        "abstract url": "https://arxiv.org/abs/2405.04778",
        "title": "Teacher-Student Network for Real-World Face Super-Resolution with Progressive Embedding of Edge Information",
        "rating": "0",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Traditional face super-resolution (FSR) methods trained on synthetic datasets usually have poor generalization ability for real-world face images. Recent work has utilized complex degradation models or training networks to simulate the real degradation process, but this limits the performance of these methods due to the domain differences that still exist between the generated low-resolution images and the real low-resolution images. Moreover, because of the existence of a domain gap, the semantic feature information of the target domain may be affected when synthetic data and real data are utilized to train super-resolution models simultaneously. In this study, a real-world face super-resolution teacher-student model is proposed, which considers the domain gap between real and synthetic data and progressively includes diverse edge information by using the recurrent network's intermediate outputs. Extensive experiments demonstrate that our proposed approach surpasses state-of-the-art methods in obtaining high-quality face images for real-world FSR.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted by ICIP 2023"
    },
    {
        "paper id": "2405.04795",
        "abstract url": "https://arxiv.org/abs/2405.04795",
        "title": "Variational Schr\u00f6dinger Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Schr\u00f6dinger bridge (SB) has emerged as the go-to method for optimizing transportation plans in diffusion models. However, SB requires estimating the intractable forward score functions, inevitably resulting in the costly implicit training loss based on simulated trajectories. To improve the scalability while preserving efficient transportation plans, we leverage variational inference to linearize the forward score functions (variational scores) of SB and restore simulation-free properties in training backward scores. We propose the variational Schr\u00f6dinger diffusion model (VSDM), where the forward process is a multivariate diffusion and the variational scores are adaptively optimized for efficient transport. Theoretically, we use stochastic approximation to prove the convergence of the variational scores and show the convergence of the adaptively generated samples based on the optimal variational scores. Empirically, we test the algorithm in simulated examples and observe that VSDM is efficient in generations of anisotropic shapes and yields straighter sample trajectories compared to the single-variate diffusion. We also verify the scalability of the algorithm in real-world data and achieve competitive unconditional generation performance in CIFAR10 and conditional generation in time series modeling. Notably, VSDM no longer depends on warm-up initializations and has become tuning-friendly in training large-scale experiments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2405.04032",
        "abstract url": "https://arxiv.org/abs/2405.04032",
        "title": "Locally Differentially Private In-Context Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large pretrained language models (LLMs) have shown surprising In-Context Learning (ICL) ability. An important application in deploying large language models is to augment LLMs with a private database for some specific task. The main problem with this promising commercial use is that LLMs have been shown to memorize their training data and their prompt data are vulnerable to membership inference attacks (MIA) and prompt leaking attacks. In order to deal with this problem, we treat LLMs as untrusted in privacy and propose a locally differentially private framework of in-context learning(LDP-ICL) in the settings where labels are sensitive. Considering the mechanisms of in-context learning in Transformers by gradient descent, we provide an analysis of the trade-off between privacy and utility in such LDP-ICL for classification. Moreover, we apply LDP-ICL to the discrete distribution estimation problem. In the end, we perform several experiments to demonstrate our analysis results.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "This paper was published at LREC-Coling 2024"
    },
    {
        "paper id": "2405.04043",
        "abstract url": "https://arxiv.org/abs/2405.04043",
        "title": "Scalable Vertical Federated Learning via Data Augmentation and Amortized Inference",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Vertical federated learning (VFL) has emerged as a paradigm for collaborative model estimation across multiple clients, each holding a distinct set of covariates. This paper introduces the first comprehensive framework for fitting Bayesian models in the VFL setting. We propose a novel approach that leverages data augmentation techniques to transform VFL problems into a form compatible with existing Bayesian federated learning algorithms. We present an innovative model formulation for specific VFL scenarios where the joint likelihood factorizes into a product of client-specific likelihoods. To mitigate the dimensionality challenge posed by data augmentation, which scales with the number of observations and clients, we develop a factorized amortized variational approximation that achieves scalability independent of the number of observations. We showcase the efficacy of our framework through extensive numerical experiments on logistic regression, multilevel regression, and a novel hierarchical Bayesian split neural net model. Our work paves the way for privacy-preserving, decentralized Bayesian inference in vertically partitioned data scenarios, opening up new avenues for research and applications in various domains.",
        "subjects": [
            "stat.CO",
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": "30 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2405.04111",
        "abstract url": "https://arxiv.org/abs/2405.04111",
        "title": "Adaptive Least Mean pth Power Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the presence of impulsive noise, and missing observations, accurate online prediction of time-varying graph signals poses a crucial challenge in numerous application domains. We propose the Adaptive Least Mean $p^{th}$ Power Graph Neural Networks (LMP-GNN), a universal framework combining adaptive filter and graph neural network for online graph signal estimation. LMP-GNN retains the advantage of adaptive filtering in handling noise and missing observations as well as the online update capability. The incorporated graph neural network within the LMP-GNN can train and update filter parameters online instead of predefined filter parameters in previous methods, outputting more accurate prediction results. The adaptive update scheme of the LMP-GNN follows the solution of a $l_p$-norm optimization, rooting to the minimum dispersion criterion, and yields robust estimation results for time-varying graph signals under impulsive noise. A special case of LMP-GNN named the Sign-GNN is also provided and analyzed, Experiment results on two real-world datasets of temperature graph and traffic graph under four different noise distributions prove the effectiveness and robustness of our proposed LMP-GNN.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04114",
        "abstract url": "https://arxiv.org/abs/2405.04114",
        "title": "Acceleration Algorithms in GNNs: A Survey",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have demonstrated effectiveness in various graph-based tasks. However, their inefficiency in training and inference presents challenges for scaling up to real-world and large-scale graph applications. To address the critical challenges, a range of algorithms have been proposed to accelerate training and inference of GNNs, attracting increasing attention from the research community. In this paper, we present a systematic review of acceleration algorithms in GNNs, which can be categorized into three main topics based on their purpose: training acceleration, inference acceleration, and execution acceleration. Specifically, we summarize and categorize the existing approaches for each main topic, and provide detailed characterizations of the approaches within each category. Additionally, we review several libraries related to acceleration algorithms in GNNs and discuss our Scalable Graph Learning (SGL) library. Finally, we propose promising directions for future research. A complete summary is presented in our GitHub repository: https://github.com/PKU-DAIR/SGL/blob/main/Awsome-GNN-Acceleration.md.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "9 pages,3 figures"
    },
    {
        "paper id": "2405.04115",
        "abstract url": "https://arxiv.org/abs/2405.04115",
        "title": "A Stealthy Wrongdoer: Feature-Oriented Reconstruction Attack against Split Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Attack"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Split Learning (SL) is a distributed learning framework renowned for its privacy-preserving features and minimal computational requirements. Previous research consistently highlights the potential privacy breaches in SL systems by server adversaries reconstructing training data. However, these studies often rely on strong assumptions or compromise system utility to enhance attack performance. This paper introduces a new semi-honest Data Reconstruction Attack on SL, named Feature-Oriented Reconstruction Attack (FORA). In contrast to prior works, FORA relies on limited prior knowledge, specifically that the server utilizes auxiliary samples from the public without knowing any client's private information. This allows FORA to conduct the attack stealthily and achieve robust performance. The key vulnerability exploited by FORA is the revelation of the model representation preference in the smashed data output by victim client. FORA constructs a substitute client through feature-level transfer learning, aiming to closely mimic the victim client's representation preference. Leveraging this substitute client, the server trains the attack model to effectively reconstruct private data. Extensive experiments showcase FORA's superior performance compared to state-of-the-art methods. Furthermore, the paper systematically evaluates the proposed method's applicability across diverse settings and advanced defense strategies.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted to CVPR 2024"
    },
    {
        "paper id": "2405.04135",
        "abstract url": "https://arxiv.org/abs/2405.04135",
        "title": "In-context Learning for Automated Driving Scenarios",
        "rating": "-0.5",
        "keywords": [
            [
                "Automated Driving",
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "One of the key challenges in current Reinforcement Learning (RL)-based Automated Driving (AD) agents is achieving flexible, precise, and human-like behavior cost-effectively. This paper introduces an innovative approach utilizing Large Language Models (LLMs) to intuitively and effectively optimize RL reward functions in a human-centric way. We developed a framework where instructions and dynamic environment descriptions are input into the LLM. The LLM then utilizes this information to assist in generating rewards, thereby steering the behavior of RL agents towards patterns that more closely resemble human driving. The experimental results demonstrate that this approach not only makes RL agents more anthropomorphic but also reaches better performance. Additionally, various strategies for reward-proxy and reward-shaping are investigated, revealing the significant impact of prompt design on shaping an AD vehicle's behavior. These findings offer a promising direction for the development of more advanced and human-like automated driving systems. Our experimental data and source code can be found here.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "7 pages, 6 figures, 35 references"
    },
    {
        "paper id": "2405.04164",
        "abstract url": "https://arxiv.org/abs/2405.04164",
        "title": "Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation",
        "rating": "-0.5",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Automatic Sign Language Translation requires the integration of both computer vision and natural language processing to effectively bridge the communication gap between sign and spoken languages. However, the deficiency in large-scale training data to support sign language translation means we need to leverage resources from spoken language. We introduce, Sign2GPT, a novel framework for sign language translation that utilizes large-scale pretrained vision and language models via lightweight adapters for gloss-free sign language translation. The lightweight adapters are crucial for sign language translation, due to the constraints imposed by limited dataset sizes and the computational requirements when training with long sign videos. We also propose a novel pretraining strategy that directs our encoder to learn sign representations from automatically extracted pseudo-glosses without requiring gloss order information or annotations. We evaluate our approach on two public benchmark sign language translation datasets, namely RWTH-PHOENIX-Weather 2014T and CSL-Daily, and improve on state-of-the-art gloss-free translation performance with a significant margin.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ICLR2024"
    },
    {
        "paper id": "2405.04167",
        "abstract url": "https://arxiv.org/abs/2405.04167",
        "title": "Bridging the Synthetic-to-Authentic Gap: Distortion-Guided Unsupervised Domain Adaptation for Blind Image Quality Assessment",
        "rating": "-0.5",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "The annotation of blind image quality assessment (BIQA) is labor-intensive and time-consuming, especially for authentic images. Training on synthetic data is expected to be beneficial, but synthetically trained models often suffer from poor generalization in real domains due to domain gaps. In this work, we make a key observation that introducing more distortion types in the synthetic dataset may not improve or even be harmful to generalizing authentic image quality assessment. To solve this challenge, we propose distortion-guided unsupervised domain adaptation for BIQA (DGQA), a novel framework that leverages adaptive multi-domain selection via prior knowledge from distortion to match the data distribution between the source domains and the target domain, thereby reducing negative transfer from the outlier source domains. Extensive experiments on two cross-domain settings (synthetic distortion to authentic distortion and synthetic distortion to algorithmic distortion) have demonstrated the effectiveness of our proposed DGQA. Besides, DGQA is orthogonal to existing model-based BIQA methods, and can be used in combination with such models to improve performance with less training data.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "Accepted by CVPR2024"
    },
    {
        "paper id": "2405.04171",
        "abstract url": "https://arxiv.org/abs/2405.04171",
        "title": "FedStale: leveraging stale client updates in federated learning",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning algorithms, such as FedAvg, are negatively affected by data heterogeneity and partial client participation. To mitigate the latter problem, global variance reduction methods, like FedVARP, leverage stale model updates for non-participating clients. These methods are effective under homogeneous client participation. Yet, this paper shows that, when some clients participate much less than others, aggregating updates with different levels of staleness can detrimentally affect the training process. Motivated by this observation, we introduce FedStale, a novel algorithm that updates the global model in each round through a convex combination of \"fresh\" updates from participating clients and \"stale\" updates from non-participating ones. By adjusting the weight in the convex combination, FedStale interpolates between FedAvg, which only uses fresh updates, and FedVARP, which treats fresh and stale updates equally. Our analysis of FedStale convergence yields the following novel findings: i) it integrates and extends previous FedAvg and FedVARP analyses to heterogeneous client participation; ii) it underscores how the least participating client influences convergence error; iii) it provides practical guidelines to best exploit stale updates, showing that their usefulness diminishes as data heterogeneity decreases and participation heterogeneity increases. Extensive experiments featuring diverse levels of client data and participation heterogeneity not only confirm these findings but also show that FedStale outperforms both FedAvg and FedVARP in many settings.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "33 pages, 5 figures, preprint"
    },
    {
        "paper id": "2405.04245",
        "abstract url": "https://arxiv.org/abs/2405.04245",
        "title": "Exploring Correlations of Self-supervised Tasks for Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph self-supervised learning has sparked a research surge in training informative representations without accessing any labeled data. However, our understanding of graph self-supervised learning remains limited, and the inherent relationships between various self-supervised tasks are still unexplored. Our paper aims to provide a fresh understanding of graph self-supervised learning based on task correlations. Specifically, we evaluate the performance of the representations trained by one specific task on other tasks and define correlation values to quantify task correlations. Through this process, we unveil the task correlations between various self-supervised tasks and can measure their expressive capabilities, which are closely related to downstream performance. By analyzing the correlation values between tasks across various datasets, we reveal the complexity of task correlations and the limitations of existing multi-task learning methods. To obtain more capable representations, we propose Graph Task Correlation Modeling (GraphTCM) to illustrate the task correlations and utilize it to enhance graph self-supervised training. The experimental results indicate that our method significantly outperforms existing methods across various downstream tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04307",
        "abstract url": "https://arxiv.org/abs/2405.04307",
        "title": "Improving Offline Reinforcement Learning with Inaccurate Simulators",
        "rating": "-0.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Offline reinforcement learning (RL) provides a promising approach to avoid costly online interaction with the real environment. However, the performance of offline RL highly depends on the quality of the datasets, which may cause extrapolation error in the learning process. In many robotic applications, an inaccurate simulator is often available. However, the data directly collected from the inaccurate simulator cannot be directly used in offline RL due to the well-known exploration-exploitation dilemma and the dynamic gap between inaccurate simulation and the real environment. To address these issues, we propose a novel approach to combine the offline dataset and the inaccurate simulation data in a better manner. Specifically, we pre-train a generative adversarial network (GAN) model to fit the state distribution of the offline dataset. Given this, we collect data from the inaccurate simulator starting from the distribution provided by the generator and reweight the simulated data using the discriminator. Our experimental results in the D4RL benchmark and a real-world manipulation task confirm that our method can benefit more from both inaccurate simulator and limited offline datasets to achieve better performance than the state-of-the-art methods.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04371",
        "abstract url": "https://arxiv.org/abs/2405.04371",
        "title": "Community Detection for Heterogeneous Multiple Social Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "The community plays a crucial role in understanding user behavior and network characteristics in social networks. Some users can use multiple social networks at once for a variety of objectives. These users are called overlapping users who bridge different social networks. Detecting communities across multiple social networks is vital for interaction mining, information diffusion, and behavior migration analysis among networks. This paper presents a community detection method based on nonnegative matrix tri-factorization for multiple heterogeneous social networks, which formulates a common consensus matrix to represent the global fused community. Specifically, the proposed method involves creating adjacency matrices based on network structure and content similarity, followed by alignment matrices which distinguish overlapping users in different social networks. With the generated alignment matrices, the method could enhance the fusion degree of the global community by detecting overlapping user communities across networks. The effectiveness of the proposed method is evaluated with new metrics on Twitter, Instagram, and Tumblr datasets. The results of the experiments demonstrate its superior performance in terms of community quality and community fusion.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "This paper was accepted by IEEE Transactions on Computational Social Systems(TCSS)"
    },
    {
        "paper id": "2405.04373",
        "abstract url": "https://arxiv.org/abs/2405.04373",
        "title": "Leveraging LSTM and GAN for Modern Malware Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The malware booming is a cyberspace equal to the effect of climate change to ecosystems in terms of danger. In the case of significant investments in cybersecurity technologies and staff training, the global community has become locked up in the eternal war with cyber security threats. The multi-form and changing faces of malware are continuously pushing the boundaries of the cybersecurity practitioners employ various approaches like detection and mitigate in coping with this issue. Some old mannerisms like signature-based detection and behavioral analysis are slow to adapt to the speedy evolution of malware types. Consequently, this paper proposes the utilization of the Deep Learning Model, LSTM networks, and GANs to amplify malware detection accuracy and speed. A fast-growing, state-of-the-art technology that leverages raw bytestream-based data and deep learning architectures, the AI technology provides better accuracy and performance than the traditional methods. Integration of LSTM and GAN model is the technique that is used for the synthetic generation of data, leading to the expansion of the training datasets, and as a result, the detection accuracy is improved. The paper uses the VirusShare dataset which has more than one million unique samples of the malware as the training and evaluation set for the presented models. Through thorough data preparation including tokenization, augmentation, as well as model training, the LSTM and GAN models convey the better performance in the tasks compared to straight classifiers. The research outcomes come out with 98% accuracy that shows the efficiency of deep learning plays a decisive role in proactive cybersecurity defense. Aside from that, the paper studies the output of ensemble learning and model fusion methods as a way to reduce biases and lift model complexity.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2405.04396",
        "abstract url": "https://arxiv.org/abs/2405.04396",
        "title": "Predicting Transonic Flowfields in Non-Homogeneous Unstructured Grids Using Autoencoder Graph Convolutional Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper focuses on addressing challenges posed by non-homogeneous unstructured grids, commonly used in Computational Fluid Dynamics (CFD). Their prevalence in CFD scenarios has motivated the exploration of innovative approaches for generating reduced-order models. The core of our approach centers on geometric deep learning, specifically the utilization of graph convolutional network (GCN). The novel Autoencoder GCN architecture enhances prediction accuracy by propagating information to distant nodes and emphasizing influential points. This architecture, with GCN layers and encoding/decoding modules, reduces dimensionality based on pressure-gradient values. The autoencoder structure improves the network capability to identify key features, contributing to a more robust and accurate predictive model. To validate the proposed methodology, we analyzed two different test cases: wing-only model and wing--body configuration. Precise reconstruction of steady-state distributed quantities within a two-dimensional parametric space underscores the reliability and versatility of the implemented approach.",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04408",
        "abstract url": "https://arxiv.org/abs/2405.04408",
        "title": "DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks",
        "rating": "-0.5",
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Document image restoration is a crucial aspect of Document AI systems, as the quality of document images significantly influences the overall performance. Prevailing methods address distinct restoration tasks independently, leading to intricate systems and the incapability to harness the potential synergies of multi-task learning. To overcome this challenge, we propose DocRes, a generalist model that unifies five document image restoration tasks including dewarping, deshadowing, appearance enhancement, deblurring, and binarization. To instruct DocRes to perform various restoration tasks, we propose a novel visual prompt approach called Dynamic Task-Specific Prompt (DTSPrompt). The DTSPrompt for different tasks comprises distinct prior features, which are additional characteristics extracted from the input image. Beyond its role as a cue for task-specific execution, DTSPrompt can also serve as supplementary information to enhance the model's performance. Moreover, DTSPrompt is more flexible than prior visual prompt approaches as it can be seamlessly applied and adapted to inputs with high and variable resolutions. Experimental results demonstrate that DocRes achieves competitive or superior performance compared to existing state-of-the-art task-specific models. This underscores the potential of DocRes across a broader spectrum of document image restoration tasks. The source code is publicly available at https://github.com/ZZZHANG-jx/DocRes",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2405.04428",
        "abstract url": "https://arxiv.org/abs/2405.04428",
        "title": "BBK: a simpler, faster algorithm for enumerating maximal bicliques in large sparse bipartite graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Bipartite graphs are a prevalent modeling tool for real-world networks, capturing interactions between vertices of two different types. Within this framework, bicliques emerge as crucial structures when studying dense subgraphs: they are sets of vertices such that all vertices of the first type interact with all vertices of the second type. Therefore, they allow identifying groups of closely related vertices of the network, such as individuals with similar interests or webpages with similar contents. This article introduces a new algorithm designed for the exhaustive enumeration of maximal bicliques within a bipartite graph. This algorithm, called BBK for Bipartite Bron-Kerbosch, is a new extension to the bipartite case of the Bron-Kerbosch algorithm, which enumerates the maximal cliques in standard (non-bipartite) graphs. It is faster than the state-of-the-art algorithms and allows the enumeration on massive bipartite graphs that are not manageable with existing implementations. We analyze it theoretically to establish two complexity formulas: one as a function of the input and one as a function of the output characteristics of the algorithm. We also provide an open-access implementation of BBK in C++, which we use to experiment and validate its efficiency on massive real-world datasets and show that its execution time is shorter in practice than state-of-the art algorithms. These experiments also show that the order in which the vertices are processed, as well as the choice of one of the two types of vertices on which to initiate the enumeration have an impact on the computation time.",
        "subjects": [
            "cs.DS",
            "cs.CC",
            "cs.IR",
            "cs.SI"
        ],
        "comment": "21 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2405.04491",
        "abstract url": "https://arxiv.org/abs/2405.04491",
        "title": "TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters",
        "rating": "-0.5",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The training, testing, and deployment, of autonomous vehicles requires realistic and efficient simulators. Moreover, because of the high variability between different problems presented in different autonomous systems, these simulators need to be easy to use, and easy to modify. To address these problems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv. TorchDriveEnv is a lightweight reinforcement learning benchmark programmed entirely in Python, which can be modified to test a number of different factors in learned vehicle behavior, including the effect of varying kinematic models, agent types, and traffic control patterns. Most importantly unlike many replay based simulation approaches, TorchDriveEnv is fully integrated with a state of the art behavioral simulation API. This allows users to train and evaluate driving models alongside data driven Non-Playable Characters (NPC) whose initializations and driving behavior are reactive, realistic, and diverse. We illustrate the efficiency and simplicity of TorchDriveEnv by evaluating common reinforcement learning baselines in both training and validation environments. Our experiments show that TorchDriveEnv is easy to use, but difficult to solve.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04534",
        "abstract url": "https://arxiv.org/abs/2405.04534",
        "title": "Tactile-Augmented Radiance Fields",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "RGB-D",
                "Radiance Fields"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We present a scene representation, which we call a tactile-augmented radiance field (TaRF), that brings vision and touch into a shared 3D space. This representation can be used to estimate the visual and tactile signals for a given 3D position within a scene. We capture a scene's TaRF from a collection of photos and sparsely sampled touch probes. Our approach makes use of two insights: (i) common vision-based touch sensors are built on ordinary cameras and thus can be registered to images using methods from multi-view geometry, and (ii) visually and structurally similar regions of a scene share the same tactile features. We use these insights to register touch signals to a captured visual scene, and to train a conditional diffusion model that, provided with an RGB-D image rendered from a neural radiance field, generates its corresponding tactile signal. To evaluate our approach, we collect a dataset of TaRFs. This dataset contains more touch samples than previous real-world datasets, and it provides spatially aligned visual signals for each captured touch signal. We demonstrate the accuracy of our cross-modal generative model and the utility of the captured visual-tactile data on several downstream tasks. Project page: https://dou-yiming.github.io/TaRF",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR 2024, Project page: https://dou-yiming.github.io/TaRF, Code: https://github.com/Dou-Yiming/TaRF/"
    },
    {
        "paper id": "2405.04559",
        "abstract url": "https://arxiv.org/abs/2405.04559",
        "title": "Understanding High-Order Network Structure using Permissible Walks on Attributed Hypergraphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Hypergraphs have been a recent focus of study in mathematical data science as a tool to understand complex networks with high-order connections. One question of particular relevance is how to leverage information carried in hypergraph attributions when doing walk-based techniques. In this work, we focus on a new generalization of a walk in a network that recovers previous approaches and allows for a description of permissible walks in hypergraphs. Permissible walk graphs are constructed by intersecting the attributed $s$-line graph of a hypergraph with a relation respecting graph. The attribution of the hypergraph's line graph commonly carries over information from categorical and temporal attributions of the original hypergraph. To demonstrate this approach on a temporally attributed example, we apply our framework to a Reddit data set composed of hyperedges as threads and authors as nodes where post times are tracked.",
        "subjects": [
            "cs.SI",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04566",
        "abstract url": "https://arxiv.org/abs/2405.04566",
        "title": "Fast Decentralized Gradient Tracking for Federated Minimax Optimization with Local Updates",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) for minimax optimization has emerged as a powerful paradigm for training models across distributed nodes/clients while preserving data privacy and model robustness on data heterogeneity. In this work, we delve into the decentralized implementation of federated minimax optimization by proposing \\texttt{K-GT-Minimax}, a novel decentralized minimax optimization algorithm that combines local updates and gradient tracking techniques. Our analysis showcases the algorithm's communication efficiency and convergence rate for nonconvex-strongly-concave (NC-SC) minimax optimization, demonstrating a superior convergence rate compared to existing methods. \\texttt{K-GT-Minimax}'s ability to handle data heterogeneity and ensure robustness underscores its significance in advancing federated learning research and applications.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04691",
        "abstract url": "https://arxiv.org/abs/2405.04691",
        "title": "Carbon Filter: Real-time Alert Triage Using Large Scale Clustering and Fast Search",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "\"Alert fatigue\" is one of the biggest challenges faced by the Security Operations Center (SOC) today, with analysts spending more than half of their time reviewing false alerts. Endpoint detection products raise alerts by pattern matching on event telemetry against behavioral rules that describe potentially malicious behavior, but can suffer from high false positives that distract from actual attacks. While alert triage techniques based on data provenance may show promise, these techniques can take over a minute to inspect a single alert, while EDR customers may face tens of millions of alerts per day; the current reality is that these approaches aren't nearly scalable enough for production environments. We present Carbon Filter, a statistical learning based system that dramatically reduces the number of alerts analysts need to manually review. Our approach is based on the observation that false alert triggers can be efficiently identified and separated from suspicious behaviors by examining the process initiation context (e.g., the command line) that launched the responsible process. Through the use of fast-search algorithms for training and inference, our approach scales to millions of alerts per day. Through batching queries to the model, we observe a theoretical maximum throughput of 20 million alerts per hour. Based on the analysis of tens of million alerts from customer deployments, our solution resulted in a 6-fold improvement in the Signal-to-Noise ratio without compromising on alert triage performance.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04714",
        "abstract url": "https://arxiv.org/abs/2405.04714",
        "title": "RACER: Epistemic Risk-Sensitive RL Enables Fast Driving with Fewer Crashes",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning provides an appealing framework for robotic control due to its ability to learn expressive policies purely through real-world interaction. However, this requires addressing real-world constraints and avoiding catastrophic failures during training, which might severely impede both learning progress and the performance of the final policy. In many robotics settings, this amounts to avoiding certain \"unsafe\" states. The high-speed off-road driving task represents a particularly challenging instantiation of this problem: a high-return policy should drive as aggressively and as quickly as possible, which often requires getting close to the edge of the set of \"safe\" states, and therefore places a particular burden on the method to avoid frequent failures. To both learn highly performant policies and avoid excessive failures, we propose a reinforcement learning framework that combines risk-sensitive control with an adaptive action space curriculum. Furthermore, we show that our risk-sensitive objective automatically avoids out-of-distribution states when equipped with an estimator for epistemic uncertainty. We implement our algorithm on a small-scale rally car and show that it is capable of learning high-speed policies for a real-world off-road driving task. We show that our method greatly reduces the number of safety violations during the training process, and actually leads to higher-performance policies in both driving and non-driving simulation environments with similar challenges.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "In review, RSS 2024"
    },
    {
        "paper id": "2405.04755",
        "abstract url": "https://arxiv.org/abs/2405.04755",
        "title": "Conditional Local Feature Encoding for Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) have shown great success in learning from graph-based data. The key mechanism of current GNNs is message passing, where a node's feature is updated based on the information passing from its local neighbourhood. A limitation of this mechanism is that node features become increasingly dominated by the information aggregated from the neighbourhood as we use more rounds of message passing. Consequently, as the GNN layers become deeper, adjacent node features tends to be similar, making it more difficult for GNNs to distinguish adjacent nodes, thereby, limiting the performance of GNNs. In this paper, we propose conditional local feature encoding (CLFE) to help prevent the problem of node features being dominated by the information from local neighbourhood. The idea of our method is to extract the node hidden state embedding from message passing process and concatenate it with the nodes feature from previous stage, then we utilise linear transformation to form a CLFE based on the concatenated vector. The CLFE will form the layer output to better preserve node-specific information, thus help to improve the performance of GNN models. To verify the feasibility of our method, we conducted extensive experiments on seven benchmark datasets for four graph domain tasks: super-pixel graph classification, node classification, link prediction, and graph regression. The experimental results consistently demonstrate that our method improves model performance across a variety of baseline GNN models for all four tasks.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2405.04760",
        "abstract url": "https://arxiv.org/abs/2405.04760",
        "title": "Large Language Models for Cyber Security: A Systematic Literature Review",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rapid advancement of Large Language Models (LLMs) has opened up new opportunities for leveraging artificial intelligence in various domains, including cybersecurity. As the volume and sophistication of cyber threats continue to grow, there is an increasing need for intelligent systems that can automatically detect vulnerabilities, analyze malware, and respond to attacks. In this survey, we conduct a comprehensive review of the literature on the application of LLMs in cybersecurity (LLM4Security). By comprehensively collecting over 30K relevant papers and systematically analyzing 127 papers from top security and software engineering venues, we aim to provide a holistic view of how LLMs are being used to solve diverse problems across the cybersecurity domain. Through our analysis, we identify several key findings. First, we observe that LLMs are being applied to a wide range of cybersecurity tasks, including vulnerability detection, malware analysis, network intrusion detection, and phishing detection. Second, we find that the datasets used for training and evaluating LLMs in these tasks are often limited in size and diversity, highlighting the need for more comprehensive and representative datasets. Third, we identify several promising techniques for adapting LLMs to specific cybersecurity domains, such as fine-tuning, transfer learning, and domain-specific pre-training. Finally, we discuss the main challenges and opportunities for future research in LLM4Security, including the need for more interpretable and explainable models, the importance of addressing data privacy and security concerns, and the potential for leveraging LLMs for proactive defense and threat hunting. Overall, our survey provides a comprehensive overview of the current state-of-the-art in LLM4Security and identifies several promising directions for future research.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "46 pages,6 figures"
    },
    {
        "paper id": "2405.04765",
        "abstract url": "https://arxiv.org/abs/2405.04765",
        "title": "When Foresight Pruning Meets Zeroth-Order Optimization: Efficient Federated Learning for Low-Memory Devices",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Although Federated Learning (FL) enables collaborative learning in Artificial Intelligence of Things (AIoT) design, it fails to work on low-memory AIoT devices due to its heavy memory usage. To address this problem, various federated pruning methods are proposed to reduce memory usage during inference. However, few of them can substantially mitigate the memory burdens during pruning and training. As an alternative, zeroth-order or backpropagation-free (BP-Free) methods can partially alleviate the memory consumption, but they suffer from scaling up and large computation overheads, since the gradient estimation error and floating point operations (FLOPs) increase as the dimensionality of the model parameters grows. In this paper, we propose a federated foresight pruning method based on Neural Tangent Kernel (NTK), which can seamlessly integrate with federated BP-Free training frameworks. We present an approximation to the computation of federated NTK by using the local NTK matrices. Moreover, we demonstrate that the data-free property of our method can substantially reduce the approximation error in extreme data heterogeneity scenarios. Since our approach improves the performance of the vanilla BP-Free method with fewer FLOPs and truly alleviates memory pressure during training and inference, it makes FL more friendly to low-memory devices. Comprehensive experimental results obtained from simulation- and real test-bed-based platforms show that our federated foresight-pruning method not only preserves the ability of the dense model with a memory reduction up to 9x but also boosts the performance of the vanilla BP-Free method with dramatically fewer FLOPs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04767",
        "abstract url": "https://arxiv.org/abs/2405.04767",
        "title": "Test-Time Augmentation for Traveling Salesperson Problem",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We propose Test-Time Augmentation (TTA) as an effective technique for addressing combinatorial optimization problems, including the Traveling Salesperson Problem. In general, deep learning models possessing the property of invariance, where the output is uniquely determined regardless of the node indices, have been proposed to learn graph structures efficiently. In contrast, we interpret the permutation of node indices, which exchanges the elements of the distance matrix, as a TTA scheme. The results demonstrate that our method is capable of obtaining shorter solutions than the latest models. Furthermore, we show that the probability of finding a solution closer to an exact solution increases depending on the augmentation size.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04798",
        "abstract url": "https://arxiv.org/abs/2405.04798",
        "title": "From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Hierarchical control for robotics has long been plagued by the need to have a well defined interface layer to communicate between high-level task planners and low-level policies. With the advent of LLMs, language has been emerging as a prospective interface layer. However, this has several limitations. Not all tasks can be decomposed into steps that are easily expressible in natural language (e.g. performing a dance routine). Further, it makes end-to-end finetuning on embodied data challenging due to domain shift and catastrophic forgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB) -- as an alternate architecture to overcome these limitations. \\method~uses a learnable latent code to act as a bridge between LLMs and low-level policies. This enables LLMs to flexibly communicate goals in the task plan without being entirely constrained by language limitations. Additionally, it enables end-to-end finetuning without destroying the embedding space of word tokens learned during pre-training. Through experiments on Language Table and Calvin, two common language based benchmarks for embodied agents, we find that \\method~outperforms baselines (including those w/ GPT-4V) that leverage pure language as the interface layer on tasks that require reasoning and multi-step behaviors.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.05282",
        "abstract url": "https://arxiv.org/abs/2405.05282",
        "title": "The Detection of a Possible Exoplanet Orbiting KIC 1718360 Using Machine Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents the detection of a periodic dimming event in the lightcurve of the G1.5IV-V type star KIC 1718360. This is based on visible-light observations conducted by both the TESS and Kepler space telescopes. Analysis of the data points toward a possible orbiting body with a radius of approximately 1.048 Earth Radii with a period of 2.938 days, as well as a semi-major axis of 0.04 AU. The initial observation was made in Kepler Quarter 16 data using the One-Class SVM machine learning method. Subsequent observations by the TESS space telescope corroborate these findings. While still requiring further data to validate, these results may contribute to a growing body of data of Earthlike planets with short-period orbits.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.LG"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2405.04010",
        "abstract url": "https://arxiv.org/abs/2405.04010",
        "title": "Explainability-Informed Targeted Malware Misclassification",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In recent years, there has been a surge in malware attacks across critical infrastructures, requiring further research and development of appropriate response and remediation strategies in malware detection and classification. Several works have used machine learning models for malware classification into categories, and deep neural networks have shown promising results. However, these models have shown its vulnerabilities against intentionally crafted adversarial attacks, which yields misclassification of a malicious file. Our paper explores such adversarial vulnerabilities of neural network based malware classification system in the dynamic and online analysis environments. To evaluate our approach, we trained Feed Forward Neural Networks (FFNN) to classify malware categories based on features obtained from dynamic and online analysis environments. We use the state-of-the-art method, SHapley Additive exPlanations (SHAP), for the feature attribution for malware classification, to inform the adversarial attackers about the features with significant importance on classification decision. Using the explainability-informed features, we perform targeted misclassification adversarial white-box evasion attacks using the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks against the trained classifier. Our results demonstrated high evasion rate for some instances of attacks, showing a clear vulnerability of a malware classifier for such attacks. We offer recommendations for a balanced approach and a benchmark for much-needed future research into evasion attacks against malware classifiers, and develop more robust and trustworthy solutions.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04029",
        "abstract url": "https://arxiv.org/abs/2405.04029",
        "title": "Enabling Privacy-Preserving and Publicly Auditable Federated Learning",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Federated learning (FL) has attracted widespread attention because it supports the joint training of models by multiple participants without moving private dataset. However, there are still many security issues in FL that deserve discussion. In this paper, we consider three major issues: 1) how to ensure that the training process can be publicly audited by any third party; 2) how to avoid the influence of malicious participants on training; 3) how to ensure that private gradients and models are not leaked to third parties. Many solutions have been proposed to address these issues, while solving the above three problems simultaneously is seldom considered. In this paper, we propose a publicly auditable and privacy-preserving federated learning scheme that is resistant to malicious participants uploading gradients with wrong directions and enables anyone to audit and verify the correctness of the training process. In particular, we design a robust aggregation algorithm capable of detecting gradients with wrong directions from malicious participants. Then, we design a random vector generation algorithm and combine it with zero sharing and blockchain technologies to make the joint training process publicly auditable, meaning anyone can verify the correctness of the training. Finally, we conduct a series of experiments, and the experimental results show that the model generated by the protocol is comparable in accuracy to the original FL approach while keeping security advantages.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "ICC 2024 - 2024 IEEE International Conference on Communications Conference Program"
    },
    {
        "paper id": "2405.04064",
        "abstract url": "https://arxiv.org/abs/2405.04064",
        "title": "MFA-Net: Multi-Scale feature fusion attention network for liver tumor segmentation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "CT",
                "tumor"
            ],
            [
                "cs.AI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Segmentation of organs of interest in medical CT images is beneficial for diagnosis of diseases. Though recent methods based on Fully Convolutional Neural Networks (F-CNNs) have shown success in many segmentation tasks, fusing features from images with different scales is still a challenge: (1) Due to the lack of spatial awareness, F-CNNs share the same weights at different spatial locations. (2) F-CNNs can only obtain surrounding information through local receptive fields. To address the above challenge, we propose a new segmentation framework based on attention mechanisms, named MFA-Net (Multi-Scale Feature Fusion Attention Network). The proposed framework can learn more meaningful feature maps among multiple scales and result in more accurate automatic segmentation. We compare our proposed MFA-Net with SOTA methods on two 2D liver CT datasets. The experimental results show that our MFA-Net produces more precise segmentation on images with different scales.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024"
    },
    {
        "paper id": "2405.04078",
        "abstract url": "https://arxiv.org/abs/2405.04078",
        "title": "WISER: Weak supervISion and supErvised Representation learning to improve drug response prediction in cancer",
        "rating": "-1",
        "keywords": [
            [
                "biological",
                "cancer"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Cancer, a leading cause of death globally, occurs due to genomic changes and manifests heterogeneously across patients. To advance research on personalized treatment strategies, the effectiveness of various drugs on cells derived from cancers (`cell lines') is experimentally determined in laboratory settings. Nevertheless, variations in the distribution of genomic data and drug responses between cell lines and humans arise due to biological and environmental differences. Moreover, while genomic profiles of many cancer patients are readily available, the scarcity of corresponding drug response data limits the ability to train machine learning models that can predict drug response in patients effectively. Recent cancer drug response prediction methods have largely followed the paradigm of unsupervised domain-invariant representation learning followed by a downstream drug response classification step. Introducing supervision in both stages is challenging due to heterogeneous patient response to drugs and limited drug response data. This paper addresses these challenges through a novel representation learning method in the first phase and weak supervision in the second. Experimental results on real patient data demonstrate the efficacy of our method (WISER) over state-of-the-art alternatives on predicting personalized drug response.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.QM"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2405.04079",
        "abstract url": "https://arxiv.org/abs/2405.04079",
        "title": "Leveraging swarm capabilities to assist other systems",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Most studies in swarm robotics treat the swarm as an isolated system of interest. We argue that the prevailing view of swarms as self-sufficient, independent systems limits the scope of potential applications for swarm robotics. A robot swarm could act as a support in an heterogeneous system comprising other robots and/or human operators, in particular by quickly providing access to a large amount of data acquired in large unknown environments. Tasks such as target identification & tracking, scouting, or monitoring/surveillance could benefit from this approach.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Presented at the \"Breaking swarm stereotypes\" workshop at ICRA 2024"
    },
    {
        "paper id": "2405.04107",
        "abstract url": "https://arxiv.org/abs/2405.04107",
        "title": "Adaptive Graph Normalized Sign Algorithm",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Efficient and robust prediction of graph signals is challenging when the signals are under impulsive noise and have missing data. Exploiting graph signal processing (GSP) and leveraging the simplicity of the classical adaptive sign algorithm, we propose an adaptive algorithm on graphs named the Graph Normalized Sign (GNS). GNS approximated a normalization term into the update, therefore achieving faster convergence and lower error compared to previous adaptive GSP algorithms. In the task of the online prediction of multivariate temperature data under impulsive noise, GNS outputs fast and robust predictions.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04119",
        "abstract url": "https://arxiv.org/abs/2405.04119",
        "title": "Diameter of the inversion graph",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In an oriented graph $\\vec{G}$, the inversion of a subset $X$ of vertices consists in reversing the orientation of all arcs with both endvertices in $X$. The inversion graph of a labelled graph $G$, denoted by ${\\mathcal{I}}(G)$, is the graph whose vertices are the labelled orientations of $G$ in which two labelled orientations $\\vec{G}_1$ and $\\vec{G}_2$ of $G$ are adjacent if and only if there is an inversion $X$ transforming $\\vec{G}_1$ into $\\vec{G}_2$. In this paper, we study the inversion diameter of a graph which is the diameter of its inversion graph denoted by $diam(\\mathcal{I}(G))$. We show that the inversion diameter is tied to the star chromatic number, the acyclic chromatic number and the oriented chromatic number. Thus a graph class has bounded inversion diameter if and only if it also has bounded star chromatic number, acyclic chromatic number and oriented chromatic number. We give some upper bounds on the inversion diameter of a graph $G$ contained in one of the following graph classes: planar graphs ($diam(\\mathcal{I}(G)) \\leq 12$), planar graphs of girth 8 ($diam(\\mathcal{I}(G)) \\leq 3$), graphs with maximum degree $\u0394$ ($diam(\\mathcal{I}(G)) \\leq 2\u0394-1$), graphs with treewidth at mots $t$ ($diam(\\mathcal{I}(G)) \\leq 2t$). We also show that determining the inversion diameter of a given graph is NP-hard.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04128",
        "abstract url": "https://arxiv.org/abs/2405.04128",
        "title": "Fine-grained Speech Sentiment Analysis in Chinese Psychological Support Hotlines Based on Large-scale Pre-trained Model",
        "rating": "-1",
        "keywords": [
            [
                "healthcare",
                "clinical",
                "Psychological"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Suicide and suicidal behaviors remain significant challenges for public policy and healthcare. In response, psychological support hotlines have been established worldwide to provide immediate help to individuals in mental crises. The effectiveness of these hotlines largely depends on accurately identifying callers' emotional states, particularly underlying negative emotions indicative of increased suicide risk. However, the high demand for psychological interventions often results in a shortage of professional operators, highlighting the need for an effective speech emotion recognition model. This model would automatically detect and analyze callers' emotions, facilitating integration into hotline services. Additionally, it would enable large-scale data analysis of psychological support hotline interactions to explore psychological phenomena and behaviors across populations. Our study utilizes data from the Beijing psychological support hotline, the largest suicide hotline in China. We analyzed speech data from 105 callers containing 20,630 segments and categorized them into 11 types of negative emotions. We developed a negative emotion recognition model and a fine-grained multi-label classification model using a large-scale pre-trained model. Our experiments indicate that the negative emotion recognition model achieves a maximum F1-score of 76.96%. However, it shows limited efficacy in the fine-grained multi-label classification task, with the best model achieving only a 41.74% weighted F1-score. We conducted an error analysis for this task, discussed potential future improvements, and considered the clinical application possibilities of our study. All the codes are public available.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04163",
        "abstract url": "https://arxiv.org/abs/2405.04163",
        "title": "MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization",
        "rating": "-1",
        "keywords": [
            [
                "biomedical",
                "Medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for fine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and PEGASUS for improved medical text summarization. In contrast to existing domain adaptation approaches in summarization, MEDVOC treats vocabulary as an optimizable parameter and optimizes the PLM vocabulary based on fragment score conditioned only on the downstream task's reference summaries. Unlike previous works on vocabulary adaptation (limited only to classification tasks), optimizing vocabulary based on summarization tasks requires an extremely costly intermediate fine-tuning step on large summarization datasets. To that end, our novel fragment score-based hyperparameter search very significantly reduces this fine-tuning time -- from 450 days to less than 2 days on average. Furthermore, while previous works on vocabulary adaptation are often primarily tied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs (with varying model vocabulary sizes, pre-training objectives, and model sizes) -- bridging the limited vocabulary overlap between the biomedical literature domain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in zero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV) concentrations. Our human evaluation shows MEDVOC generates more faithful medical summaries (88% compared to 59% in baselines). We make the codebase publicly available at https://github.com/gb-kgp/MEDVOC.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "13 pages, Accepted to the 33rd International Joint Conference on Artificial Intelligence, IJCAI 2024 (Main) Track"
    },
    {
        "paper id": "2405.04168",
        "abstract url": "https://arxiv.org/abs/2405.04168",
        "title": "Three variations of Heads or Tails Game for Bitcoin",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "We present three very simple variants of the classic Heads or Tails game using chips, each of which contributes to our understanding of the Bitcoin protocol. The first variant addresses the issue of temporary Bitcoin forks, which occur when two miners discover blocks simultaneously. We determine the threshold at which an honest but temporarily ``Byzantine'' miner persists in mining on their fork to save his orphaned blocks. The second variant of Heads or Tails game is biased in favor of the player and helps to explain why the difficulty adjustment formula is vulnerable to attacks of Nakamoto's consensus. We derive directly and in a simple way, without relying on a Markov decision solver as was the case until now, the threshold beyond which a miner without connectivity finds it advantageous to adopt a deviant mining strategy on Bitcoin. The third variant of Heads or Tails game is unbiased and demonstrates that this issue in the Difficulty Adjustment formula can be fully rectified. Our results are in agreement with the existing literature that we clarify both qualitatively and quantitatively using very simple models and scripts that are easy to implement.",
        "subjects": [
            "cs.CR",
            "math.PR"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2405.04169",
        "abstract url": "https://arxiv.org/abs/2405.04169",
        "title": "D-TrAttUnet: Toward Hybrid CNN-Transformer Architecture for Generic and Subtle Segmentation in Medical Images",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Over the past two decades, machine analysis of medical imaging has advanced rapidly, opening up significant potential for several important medical applications. As complicated diseases increase and the number of cases rises, the role of machine-based imaging analysis has become indispensable. It serves as both a tool and an assistant to medical experts, providing valuable insights and guidance. A particularly challenging task in this area is lesion segmentation, a task that is challenging even for experienced radiologists. The complexity of this task highlights the urgent need for robust machine learning approaches to support medical staff. In response, we present our novel solution: the D-TrAttUnet architecture. This framework is based on the observation that different diseases often target specific organs. Our architecture includes an encoder-decoder structure with a composite Transformer-CNN encoder and dual decoders. The encoder includes two paths: the Transformer path and the Encoders Fusion Module path. The Dual-Decoder configuration uses two identical decoders, each with attention gates. This allows the model to simultaneously segment lesions and organs and integrate their segmentation losses. To validate our approach, we performed evaluations on the Covid-19 and Bone Metastasis segmentation tasks. We also investigated the adaptability of the model by testing it without the second decoder in the segmentation of glands and nuclei. The results confirmed the superiority of our approach, especially in Covid-19 infections and the segmentation of bone metastases. In addition, the hybrid encoder showed exceptional performance in the segmentation of glands and nuclei, solidifying its role in modern medical image analysis.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2303.15576"
    },
    {
        "paper id": "2405.04170",
        "abstract url": "https://arxiv.org/abs/2405.04170",
        "title": "D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have garnered significant attention and widespread usage due to their impressive performance in various tasks. However, they are not without their own set of challenges, including issues such as hallucinations, factual inconsistencies, and limitations in numerical-quantitative reasoning. Evaluating LLMs in miscellaneous reasoning tasks remains an active area of research. Prior to the breakthrough of LLMs, Transformers had already proven successful in the medical domain, effectively employed for various natural language understanding (NLU) tasks. Following this trend, LLMs have also been trained and utilized in the medical domain, raising concerns regarding factual accuracy, adherence to safety protocols, and inherent limitations. In this paper, we focus on evaluating the natural language inference capabilities of popular open-source and closed-source LLMs using clinical trial reports as the dataset. We present the performance results of each LLM and further analyze their performance on a development set, particularly focusing on challenging instances that involve medical abbreviations and require numerical-quantitative reasoning. Gemini, our leading LLM, achieved a test set F1-score of 0.748, securing the ninth position on the task scoreboard. Our work is the first of its kind, offering a thorough examination of the inference capabilities of LLMs within the medical domain.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "accepted to SemEval-2024, ranked 9th on Task 2"
    },
    {
        "paper id": "2405.04175",
        "abstract url": "https://arxiv.org/abs/2405.04175",
        "title": "Topicwise Separable Sentence Retrieval for Medical Report Generation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "X-ray",
                "clinical",
                "radiology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automated radiology reporting holds immense clinical potential in alleviating the burdensome workload of radiologists and mitigating diagnostic bias. Recently, retrieval-based report generation methods have garnered increasing attention due to their inherent advantages in terms of the quality and consistency of generated reports. However, due to the long-tail distribution of the training data, these models tend to learn frequently occurring sentences and topics, overlooking the rare topics. Regrettably, in many cases, the descriptions of rare topics often indicate critical findings that should be mentioned in the report. To address this problem, we introduce a Topicwise Separable Sentence Retrieval (Teaser) for medical report generation. To ensure comprehensive learning of both common and rare topics, we categorize queries into common and rare types to learn differentiated topics, and then propose Topic Contrastive Loss to effectively align topics and queries in the latent space. Moreover, we integrate an Abstractor module following the extraction of visual features, which aids the topic decoder in gaining a deeper understanding of the visual observational intent. Experiments on the MIMIC-CXR and IU X-ray datasets demonstrate that Teaser surpasses state-of-the-art models, while also validating its capability to effectively represent rare topics and establish more dependable correspondences between queries and topics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04189",
        "abstract url": "https://arxiv.org/abs/2405.04189",
        "title": "Artificial Intelligence-powered fossil shark tooth identification: Unleashing the potential of Convolutional Neural Networks",
        "rating": "-1",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "All fields of knowledge are being impacted by Artificial Intelligence. In particular, the Deep Learning paradigm enables the development of data analysis tools that support subject matter experts in a variety of sectors, from physics up to the recognition of ancient languages. Palaeontology is now observing this trend as well. This study explores the capability of Convolutional Neural Networks (CNNs), a particular class of Deep Learning algorithms specifically crafted for computer vision tasks, to classify images of isolated fossil shark teeth gathered from online datasets as well as from the authors$'$ experience on Peruvian Miocene and Italian Pliocene fossil assemblages. The shark taxa that are included in the final, composite dataset (which consists of more than one thousand images) are representative of both extinct and extant genera, namely, Carcharhinus, Carcharias, Carcharocles, Chlamydoselachus, Cosmopolitodus, Galeocerdo, Hemipristis, Notorynchus, Prionace and Squatina. We developed a CNN, named SharkNet-X, specifically tailored on our recognition task, reaching a 5-fold cross validated mean accuracy of 0.85 to identify images containing a single shark tooth. Furthermore, we elaborated a visualization of the features extracted from images using the last dense layer of the CNN, achieved through the application of the clustering technique t-SNE. In addition, in order to understand and explain the behaviour of the CNN while giving a paleontological point of view on the results, we introduced the explainability method SHAP. To the best of our knowledge, this is the first instance in which this method is applied to the field of palaeontology. The main goal of this work is to showcase how Deep Learning techniques can aid in identifying isolated fossil shark teeth, paving the way for developing new information tools for automating the recognition and classification of fossils.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "40 pages, 8 figures"
    },
    {
        "paper id": "2405.04225",
        "abstract url": "https://arxiv.org/abs/2405.04225",
        "title": "Long-term usage of the off-grid photovoltaic system with lithium-ion battery-based energy storage system on high mountains: A case study in Payiun Lodge on Mt. Jade in Taiwan",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Energy supply on high mountains remains an open issue since grid connection is unavailable. In the past, diesel generators with lead-acid battery energy storage systems (ESSs) are applied in most cases. Recently, photovoltaic (PV) system with lithium-ion (Li-ion) battery ESS is an appropriate method for solving this problem in a greener way. In 2016, an off-grid PV system with Li-ion battery ESS has been installed in Paiyun Lodge on Mt. Jade (the highest lodge in Taiwan). After operation for more than 7 years, the aging problem of the whole electric power system becomes a critical issue for long-term usage. In this work, a method is established for analyzing the massive energy data (over 7 million rows) and estimating the health of the Li-ion battery system, such as daily operation patterns as well as C-rate, temperature, and accumulated energy distributions. The accomplished electric power improvement project dealing with the power system aging is reported. Based on the long-term usage experience, a simple cost analysis model between lead-acid and Li-ion battery systems is built, explaining that the expensive Li-ion batteries can compete with the cheap lead-acid batteries for long-term usage on high mountains. This case study provides engineers and researchers a fundamental understanding of the long-term usage of off-grid PV ESSs and engineering on high mountains.",
        "subjects": [
            "eess.SY",
            "eess.IV",
            "eess.SP"
        ],
        "comment": "28 pages, 12 figures, 4 tables"
    },
    {
        "paper id": "2405.04257",
        "abstract url": "https://arxiv.org/abs/2405.04257",
        "title": "Insights from Basilisk: Are Open-Source EDA Tools Ready for a Multi-Million-Gate, Linux-Booting RV64 SoC Design?",
        "rating": "-1",
        "keywords": [
            [
                "synthesis"
            ]
        ],
        "abstract": "Designing complex, multi-million-gate application-specific integrated circuits requires robust and mature electronic design automation (EDA) tools. We describe our efforts in enhancing the open-source Yosys+Openroad EDA flow to implement Basilisk, a fully open-source, Linux-booting RV64GC system-on-chip (SoC) design. We analyze the quality-of-results impact of our enhancements to synthesis tools, interfaces between EDA tools, logic optimization scripts, and a newly open-sourced library of optimized arithmetic macro-operators. We also introduce a streamlined physical design flow with an improved power grid and cell placement integration. Our Basilisk SoC design was taped out in IHP's open 130 nm technology. It achieves an operating frequency of 77 MHz (51 logic levels) under typical conditions, a 2.3x improvement compared to the baseline open-source EDA flow, while also reducing logic area by 1.6x. Furthermore, tool runtime was reduced by 2.5x, and peak RAM usage decreased by 2.9x. Through collaboration with EDA tool developers and domain experts, Basilisk establishes solid \"proof of existence\" for a fully open-source EDA flow used in designing a competitive multi-million-gate digital SoC.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "8 pages, 6 figures, submitted at IWLS 2024"
    },
    {
        "paper id": "2405.04261",
        "abstract url": "https://arxiv.org/abs/2405.04261",
        "title": "Graph Reconstruction from Noisy Random Subgraphs",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "We consider the problem of reconstructing an undirected graph $G$ on $n$ vertices given multiple random noisy subgraphs or \"traces\". Specifically, a trace is generated by sampling each vertex with probability $p_v$, then taking the resulting induced subgraph on the sampled vertices, and then adding noise in the form of either (a) deleting each edge in the subgraph with probability $1-p_e$, or (b) deleting each edge with probability $f_e$ and transforming a non-edge into an edge with probability $f_e$. We show that, under mild assumptions on $p_v$, $p_e$ and $f_e$, if $G$ is selected uniformly at random, then $O(p_e^{-1} p_v^{-2} \\log n)$ or $O((f_e-1/2)^{-2} p_v^{-2} \\log n)$ traces suffice to reconstruct $G$ with high probability. In contrast, if $G$ is arbitrary, then $\\exp(\u03a9(n))$ traces are necessary even when $p_v=1, p_e=1/2$.",
        "subjects": [
            "cs.IT",
            "cs.DS"
        ],
        "comment": "6 pages, to appear in ISIT 2024"
    },
    {
        "paper id": "2405.04266",
        "abstract url": "https://arxiv.org/abs/2405.04266",
        "title": "Self-Stabilizing MIS Computation in the Beeping Model",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We consider self-stabilizing algorithms to compute a Maximal Independent Set (MIS) in the extremely weak beeping communication model. The model consists of an anonymous network with synchronous rounds. In each round, each vertex can optionally transmit a signal to all its neighbors (beep). After the transmission of a signal, each vertex can only differentiate between no signal received, or at least one signal received. We assume that vertices have some knowledge about the topology of the network. We revisit the not self-stabilizing algorithm proposed by Jeavons, Scott, and Xu (2013), which computes an MIS in the beeping model. We enhance this algorithm to be self-stabilizing, and explore two different variants, which differ in the knowledge about the topology available to the vertices. In the first variant, every vertex knows an upper bound on the maximum degree $\u0394$ of the graph. For this case, we prove that the proposed self-stabilizing version maintains the same run-time as the original algorithm, i.e. it stabilizes after $O(\\log n)$ rounds w.h.p. on any $n$-vertex graph. In the second variant, each vertex only knows an upper bound on its own degree. For this case, we prove that the algorithm stabilizes after $O(\\log n\\cdot \\log \\log n)$ rounds on any $n$-vertex graph, w.h.p.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04272",
        "abstract url": "https://arxiv.org/abs/2405.04272",
        "title": "BUDDy: Single-Channel Blind Unsupervised Dereverberation with Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we present an unsupervised single-channel method for joint blind dereverberation and room impulse response estimation, based on posterior sampling with diffusion models. We parameterize the reverberation operator using a filter with exponential decay for each frequency subband, and iteratively estimate the corresponding parameters as the speech utterance gets refined along the reverse diffusion trajectory. A measurement consistency criterion enforces the fidelity of the generated speech with the reverberant measurement, while an unconditional diffusion model implements a strong prior for clean speech generation. Without any knowledge of the room impulse response nor any coupled reverberant-anechoic data, we can successfully perform dereverberation in various acoustic scenarios. Our method significantly outperforms previous blind unsupervised baselines, and we demonstrate its increased robustness to unseen acoustic conditions in comparison to blind supervised methods. Audio samples and code are available online.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "Submitted to IWAENC 2024"
    },
    {
        "paper id": "2405.04295",
        "abstract url": "https://arxiv.org/abs/2405.04295",
        "title": "Semi-Supervised Disease Classification based on Limited Medical Image Data",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "diagnosis",
                "Disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, significant progress has been made in the field of learning from positive and unlabeled examples (PU learning), particularly in the context of advancing image and text classification tasks. However, applying PU learning to semi-supervised disease classification remains a formidable challenge, primarily due to the limited availability of labeled medical images. In the realm of medical image-aided diagnosis algorithms, numerous theoretical and practical obstacles persist. The research on PU learning for medical image-assisted diagnosis holds substantial importance, as it aims to reduce the time spent by professional experts in classifying images. Unlike natural images, medical images are typically accompanied by a scarcity of annotated data, while an abundance of unlabeled cases exists. Addressing these challenges, this paper introduces a novel generative model inspired by H\u00f6lder divergence, specifically designed for semi-supervised disease classification using positive and unlabeled medical image data. In this paper, we present a comprehensive formulation of the problem and establish its theoretical feasibility through rigorous mathematical analysis. To evaluate the effectiveness of our proposed approach, we conduct extensive experiments on five benchmark datasets commonly used in PU medical learning: BreastMNIST, PneumoniaMNIST, BloodMNIST, OCTMNIST, and AMD. The experimental results clearly demonstrate the superiority of our method over existing approaches based on KL divergence. Notably, our approach achieves state-of-the-art performance on all five disease classification benchmarks. By addressing the limitations imposed by limited labeled data and harnessing the untapped potential of unlabeled medical images, our novel generative model presents a promising direction for enhancing semi-supervised disease classification in the field of medical image analysis.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04311",
        "abstract url": "https://arxiv.org/abs/2405.04311",
        "title": "Cross-IQA: Unsupervised Learning for Image Quality Assessment",
        "rating": "-1",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Automatic perception of image quality is a challenging problem that impacts billions of Internet and social media users daily. To advance research in this field, we propose a no-reference image quality assessment (NR-IQA) method termed Cross-IQA based on vision transformer(ViT) model. The proposed Cross-IQA method can learn image quality features from unlabeled image data. We construct the pretext task of synthesized image reconstruction to unsupervised extract the image quality information based ViT block. The pretrained encoder of Cross-IQA is used to fine-tune a linear regression model for score prediction. Experimental results show that Cross-IQA can achieve state-of-the-art performance in assessing the low-frequency degradation information (e.g., color change, blurring, etc.) of images compared with the classical full-reference IQA and NR-IQA under the same datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04359",
        "abstract url": "https://arxiv.org/abs/2405.04359",
        "title": "A Personalizable Controller for the Walking Assistive omNi-Directional Exo-Robot (WANDER)",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Preserving and encouraging mobility in the elderly and adults with chronic conditions is of paramount importance. However, existing walking aids are either inadequate to provide sufficient support to users' stability or too bulky and poorly maneuverable to be used outside hospital environments. In addition, they all lack adaptability to individual requirements. To address these challenges, this paper introduces WANDER, a novel Walking Assistive omNi-Directional Exo-Robot. It consists of an omnidirectional platform and a robust aluminum structure mounted on top of it, which provides partial body weight support. A comfortable and minimally restrictive coupling interface embedded with a force/torque sensor allows to detect users' intentions, which are translated into command velocities by means of a variable admittance controller. An optimization technique based on users' preferences, i.e., Preference-Based Optimization (PBO) guides the choice of the admittance parameters (i.e., virtual mass and damping) to better fit subject-specific needs and characteristics. Experiments with twelve healthy subjects exhibited a significant decrease in energy consumption and jerk when using WANDER with PBO parameters as well as improved user performance and comfort. The great interpersonal variability in the optimized parameters highlights the importance of personalized control settings when walking with an assistive device, aiming to enhance users' comfort and mobility while ensuring reliable physical support.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages, 4 figures, IEEE International Conference on Robotics and Automation (2024)"
    },
    {
        "paper id": "2405.04363",
        "abstract url": "https://arxiv.org/abs/2405.04363",
        "title": "Some Notes on the Sample Complexity of Approximate Channel Simulation",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "Channel simulation algorithms can efficiently encode random samples from a prescribed target distribution $Q$ and find applications in machine learning-based lossy data compression. However, algorithms that encode exact samples usually have random runtime, limiting their applicability when a consistent encoding time is desirable. Thus, this paper considers approximate schemes with a fixed runtime instead. First, we strengthen a result of Agustsson and Theis and show that there is a class of pairs of target distribution $Q$ and coding distribution $P$, for which the runtime of any approximate scheme scales at least super-polynomially in $D_\\infty[Q \\Vert P]$. We then show, by contrast, that if we have access to an unnormalised Radon-Nikodym derivative $r \\propto dQ/dP$ and knowledge of $D_{KL}[Q \\Vert P]$, we can exploit global-bound, depth-limited A* coding to ensure $\\mathrm{TV}[Q \\Vert P] \\leq \u03b5$ and maintain optimal coding performance with a sample complexity of only $\\exp_2\\big((D_{KL}[Q \\Vert P] + o(1)) \\big/ \u03b5\\big)$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Accepted as a spotlight paper at the first 'Learn to Compress' Workshop@ ISIT 2024"
    },
    {
        "paper id": "2405.04378",
        "abstract url": "https://arxiv.org/abs/2405.04378",
        "title": "$\\textbf{Splat-MOVER}$: Multi-Stage, Open-Vocabulary Robotic Manipulation via Editable Gaussian Splatting",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present Splat-MOVER, a modular robotics stack for open-vocabulary robotic manipulation, which leverages the editability of Gaussian Splatting (GSplat) scene representations to enable multi-stage manipulation tasks. Splat-MOVER consists of: (i) $\\textit{ASK-Splat}$, a GSplat representation that distills latent codes for language semantics and grasp affordance into the 3D scene. ASK-Splat enables geometric, semantic, and affordance understanding of 3D scenes, which is critical for many robotics tasks; (ii) $\\textit{SEE-Splat}$, a real-time scene-editing module using 3D semantic masking and infilling to visualize the motions of objects that result from robot interactions in the real-world. SEE-Splat creates a \"digital twin\" of the evolving environment throughout the manipulation task; and (iii) $\\textit{Grasp-Splat}$, a grasp generation module that uses ASK-Splat and SEE-Splat to propose candidate grasps for open-world objects. ASK-Splat is trained in real-time from RGB images in a brief scanning phase prior to operation, while SEE-Splat and Grasp-Splat run in real-time during operation. We demonstrate the superior performance of Splat-MOVER in hardware experiments on a Kinova robot compared to two recent baselines in four single-stage, open-vocabulary manipulation tasks, as well as in four multi-stage manipulation tasks using the edited scene to reflect scene changes due to prior manipulation stages, which is not possible with the existing baselines. Code for this project and a link to the project page will be made available soon.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04420",
        "abstract url": "https://arxiv.org/abs/2405.04420",
        "title": "Fully Automated Selfish Mining Analysis in Efficient Proof Systems Blockchains",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "We study selfish mining attacks in longest-chain blockchains like Bitcoin, but where the proof of work is replaced with efficient proof systems -- like proofs of stake or proofs of space -- and consider the problem of computing an optimal selfish mining attack which maximizes expected relative revenue of the adversary, thus minimizing the chain quality. To this end, we propose a novel selfish mining attack that aims to maximize this objective and formally model the attack as a Markov decision process (MDP). We then present a formal analysis procedure which computes an $\u03b5$-tight lower bound on the optimal expected relative revenue in the MDP and a strategy that achieves this $\u03b5$-tight lower bound, where $\u03b5>0$ may be any specified precision. Our analysis is fully automated and provides formal guarantees on the correctness. We evaluate our selfish mining attack and observe that it achieves superior expected relative revenue compared to two considered baselines. In concurrent work [Sarenche FC'24] does an automated analysis on selfish mining in predictable longest-chain blockchains based on efficient proof systems. Predictable means the randomness for the challenges is fixed for many blocks (as used e.g., in Ouroboros), while we consider unpredictable (Bitcoin-like) chains where the challenge is derived from the previous block.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04478",
        "abstract url": "https://arxiv.org/abs/2405.04478",
        "title": "Exploration of Novel Neuromorphic Methodologies for Materials Applications",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "graph"
            ]
        ],
        "abstract": "Many of today's most interesting questions involve understanding and interpreting complex relationships within graph-based structures. For instance, in materials science, predicting material properties often relies on analyzing the intricate network of atomic interactions. Graph neural networks (GNNs) have emerged as a popular approach for these tasks; however, they suffer from limitations such as inefficient hardware utilization and over-smoothing. Recent advancements in neuromorphic computing offer promising solutions to these challenges. In this work, we evaluate two such neuromorphic strategies known as reservoir computing and hyperdimensional computing. We compare the performance of both approaches for bandgap classification and regression using a subset of the Materials Project dataset. Our results indicate recent advances in hyperdimensional computing can be applied effectively to better represent molecular graphs.",
        "subjects": [
            "cs.ET"
        ],
        "comment": "5 pages, 2 figures, 1 table"
    },
    {
        "paper id": "2405.04494",
        "abstract url": "https://arxiv.org/abs/2405.04494",
        "title": "Representation Learning of Daily Movement Data Using Text Encoders",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Time-series representation learning is a key area of research for remote healthcare monitoring applications. In this work, we focus on a dataset of recordings of in-home activity from people living with Dementia. We design a representation learning method based on converting activity to text strings that can be encoded using a language model fine-tuned to transform data from the same participants within a $30$-day window to similar embeddings in the vector space. This allows for clustering and vector searching over participants and days, and the identification of activity deviations to aid with personalised delivery of care.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at ICLR 2024 Workshop on Learning from Time Series For Health: https://openreview.net/forum?id=mmxNNwxvWG"
    },
    {
        "paper id": "2405.04519",
        "abstract url": "https://arxiv.org/abs/2405.04519",
        "title": "Local Advice and Local Decompression",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Algorithms with advice have received ample attention in the distributed and online settings, and they have recently proven useful also in dynamic settings. In this work we study local computation with advice: the goal is to solve a graph problem $\u03a0$ with a distributed algorithm in $f(\u0394)$ communication rounds, for some function $f$ that only depends on the maximum degree $\u0394$ of the graph, and the key question is how many bits of advice per node are needed. Our main results are: - Any locally checkable labeling problem can be solved in graphs with sub-exponential growth with only $1$ bit of advice per node. Moreover, we can make the set of nodes that carry advice bits arbitrarily sparse, that is, we can make arbitrarily small the ratio between nodes carrying a 1 and the nodes carrying a 0. - The assumption of sub-exponential growth is necessary: assuming the Exponential-Time Hypothesis, there are LCLs that cannot be solved in general with any constant number of bits per node. - In any graph we can find an almost-balanced orientation (indegrees and outdegrees differ by at most one) with $1$ bit of advice per node, and again we can make the advice arbitrarily sparse. - As a corollary, we can also compress an arbitrary subset of edges so that a node of degree $d$ stores only $d/2 + 2$ bits, and we can decompress it locally, in $f(\u0394)$ rounds. - In any graph of maximum degree $\u0394$, we can find a $\u0394$-coloring (if it exists) with $1$ bit of advice per node, and again, we can make the advice arbitrarily sparse. - In any $3$-colorable graph, we can find a $3$-coloring with $1$ bit of advice per node. Here, it remains open whether we can make the advice arbitrarily sparse. Our work shows that for many problems the key threshold is not whether we can achieve, say, $1$ bit of advice per node, but whether we can make the advice arbitrarily sparse.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04589",
        "abstract url": "https://arxiv.org/abs/2405.04589",
        "title": "A Novel Wide-Area Multiobject Detection System with High-Probability Region Searching",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, wide-area visual surveillance systems have been widely applied in various industrial and transportation scenarios. These systems, however, face significant challenges when implementing multi-object detection due to conflicts arising from the need for high-resolution imaging, efficient object searching, and accurate localization. To address these challenges, this paper presents a hybrid system that incorporates a wide-angle camera, a high-speed search camera, and a galvano-mirror. In this system, the wide-angle camera offers panoramic images as prior information, which helps the search camera capture detailed images of the targeted objects. This integrated approach enhances the overall efficiency and effectiveness of wide-area visual detection systems. Specifically, in this study, we introduce a wide-angle camera-based method to generate a panoramic probability map (PPM) for estimating high-probability regions of target object presence. Then, we propose a probability searching module that uses the PPM-generated prior information to dynamically adjust the sampling range and refine target coordinates based on uncertainty variance computed by the object detector. Finally, the integration of PPM and the probability searching module yields an efficient hybrid vision system capable of achieving 120 fps multi-object search and detection. Extensive experiments are conducted to verify the system's effectiveness and robustness.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted by ICRA 2024"
    },
    {
        "paper id": "2405.04605",
        "abstract url": "https://arxiv.org/abs/2405.04605",
        "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Health",
                "diagnosis",
                "CT",
                "cancer"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "BACKGROUND: Lung cancer's high mortality rate can be mitigated by early detection, which is increasingly reliant on artificial intelligence (AI) for diagnostic imaging. However, the performance of AI models is contingent upon the datasets used for their training and validation. METHODS: This study developed and validated the DLCSD-mD and LUNA16-mD models utilizing the Duke Lung Cancer Screening Dataset (DLCSD), encompassing over 2,000 CT scans with more than 3,000 annotations. These models were rigorously evaluated against the internal DLCSD and external LUNA16 and NLST datasets, aiming to establish a benchmark for imaging-based performance. The assessment focused on creating a standardized evaluation framework to facilitate consistent comparison with widely utilized datasets, ensuring a comprehensive validation of the model's efficacy. Diagnostic accuracy was assessed using free-response receiver operating characteristic (FROC) and area under the curve (AUC) analyses. RESULTS: On the internal DLCSD set, the DLCSD-mD model achieved an AUC of 0.93 (95% CI:0.91-0.94), demonstrating high accuracy. Its performance was sustained on the external datasets, with AUCs of 0.97 (95% CI: 0.96-0.98) on LUNA16 and 0.75 (95% CI: 0.73-0.76) on NLST. Similarly, the LUNA16-mD model recorded an AUC of 0.96 (95% CI: 0.95-0.97) on its native dataset and showed transferable diagnostic performance with AUCs of 0.91 (95% CI: 0.89-0.93) on DLCSD and 0.71 (95% CI: 0.70-0.72) on NLST. CONCLUSION: The DLCSD-mD model exhibits reliable performance across different datasets, establishing the DLCSD as a robust benchmark for lung cancer detection and diagnosis. Through the provision of our models and code to the public domain, we aim to accelerate the development of AI-based diagnostic tools and encourage reproducibility and collaborative advancements within the medical machine-learning (ML) field.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "16 pages, 2 tables, 5 figures"
    },
    {
        "paper id": "2405.04610",
        "abstract url": "https://arxiv.org/abs/2405.04610",
        "title": "Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "diagnosis",
                "Cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Lung and colon cancer are serious worldwide health challenges that require early and precise identification to reduce mortality risks. However, diagnosis, which is mostly dependent on histopathologists' competence, presents difficulties and hazards when expertise is insufficient. While diagnostic methods like imaging and blood markers contribute to early detection, histopathology remains the gold standard, although time-consuming and vulnerable to inter-observer mistakes. Limited access to high-end technology further limits patients' ability to receive immediate medical care and diagnosis. Recent advances in deep learning have generated interest in its application to medical imaging analysis, specifically the use of histopathological images to diagnose lung and colon cancer. The goal of this investigation is to use and adapt existing pre-trained CNN-based models, such as Xception, DenseNet201, ResNet101, InceptionV3, DenseNet121, DenseNet169, ResNet152, and InceptionResNetV2, to enhance classification through better augmentation strategies. The results show tremendous progress, with all eight models reaching impressive accuracy ranging from 97% to 99%. Furthermore, attention visualization techniques such as GradCAM, GradCAM++, ScoreCAM, Faster Score-CAM, and LayerCAM, as well as Vanilla Saliency and SmoothGrad, are used to provide insights into the models' classification decisions, thereby improving interpretability and understanding of malignant and benign image classification.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted in 4th International Conference on Computing and Communication Networks (ICCCNet-2024)"
    },
    {
        "paper id": "2405.04621",
        "abstract url": "https://arxiv.org/abs/2405.04621",
        "title": "NACSOS-nexus: NLP Assisted Classification, Synthesis and Online Screening with New and EXtended Usage Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "NACSOS is a web-based platform for curating data used in systematic maps. It contains several (experimental) features that aid the evidence synthesis process from finding and ingesting primary data (mainly scientific publications), basic search and exploration thereof, but mainly the handling of managing the manual and automated annotations. The platform supports prioritised screening algorithms and is the first to fully implement statistical stopping criteria. Annotations by multiple coders can be resolved and customisable quality metrics are computed on-the-fly. In its current state, the annotations are performed on document level. The ecosystem around NACSOS offers packages for accessing the underlying database and practical utility functions that have proven useful in a multitude of projects. Further, it provides the backbone of living maps, review ecosystems, and our public literature hub for sharing high-quality curated corpora.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04634",
        "abstract url": "https://arxiv.org/abs/2405.04634",
        "title": "FRACTAL: An Ultra-Large-Scale Aerial Lidar Dataset for 3D Semantic Segmentation of Diverse Landscapes",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Lidar"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Mapping agencies are increasingly adopting Aerial Lidar Scanning (ALS) as a new tool to monitor territory and support public policies. Processing ALS data at scale requires efficient point classification methods that perform well over highly diverse territories. To evaluate them, researchers need large annotated Lidar datasets, however, current Lidar benchmark datasets have restricted scope and often cover a single urban area. To bridge this data gap, we present the FRench ALS Clouds from TArgeted Landscapes (FRACTAL) dataset: an ultra-large-scale aerial Lidar dataset made of 100,000 dense point clouds with high-quality labels for 7 semantic classes and spanning 250 km$^2$. FRACTAL is built upon France's nationwide open Lidar data. It achieves spatial and semantic diversity via a sampling scheme that explicitly concentrates rare classes and challenging landscapes from five French regions. It should support the development of 3D deep learning approaches for large-scale land monitoring. We describe the nature of the source data, the sampling workflow, the content of the resulting dataset, and provide an initial evaluation of segmentation performance using a performant 3D neural architecture.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "15 pages | 9 figures | 8 tables | Dataset is available at https://huggingface.co/datasets/IGNF/FRACTAL/tree/main | Trained model is available at https://huggingface.co/IGNF/FRACTAL-LidarHD_7cl_randlanet | Deep learning code repository is on Gihtub at https://github.com/IGNF/myria3d | Data engineering code repository is on Github at https://github.com/IGNF/pacasam"
    },
    {
        "paper id": "2405.04648",
        "abstract url": "https://arxiv.org/abs/2405.04648",
        "title": "Simpler and More General Distributed Coloring Based on Simple List Defective Coloring Algorithms",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper, we give list coloring variants of simple iterative defective coloring algorithms. Formally, in a list defective coloring instance, each node $v$ of a graph is given a list $L_v$ of colors and a list of allowed defects $d_v(x)$ for the colors. Each node $v$ needs to be colored with a color $x\\in L_v$ such that at most $d_v(x)$ neighbors of $v$ also pick the same color $x$. For a defect parameter $d$, it is known that by making two sweeps in opposite order over the nodes of an edge-oriented graph with maximum outdegree $\u03b2$, one can compute a coloring with $O(\u03b2^2/d^2)$ colors such that every node has at most $d$ outneighbors of the same color. We generalize this and show that if all nodes have lists of size $p^2$ and $\\forall v:\\sum_{x\\in L_v}(d_v(x)+1)>p\\cdot\u03b2$, we can make two sweeps of the nodes such that at the end, each node $v$ has chosen a color $x\\in L_v$ for which at most $d_v(x)$ outneighbors of $v$ are colored with color $x$. Our algorithm is simpler and computationally significantly more efficient than existing algorithms for similar list defective coloring problems. We show that the above result can in particular be used to obtain an alternative $\\tilde{O}(\\sqrt\u0394)+O(\\log^* n)$-round algorithm for the $(\u0394+1)$-coloring problem in the CONGEST model. The neighborhood independence $\u03b8$ of a graph is the maximum number of pairwise non-adjacent neighbors of some node of the graph. It is known that by doing a single sweep over the nodes of a graph of neighborhood independence $\u03b8$, one can compute a $d$-defective coloring with $O(\u03b8\\cdot \u0394/d)$ colors. We extend this approach to the list defective coloring setting and use it to obtain an efficient recursive coloring algorithm for graphs of neighborhood independence $\u03b8$. In particular, if $\u03b8=O(1)$, we get an $(\\log\u0394)^{O(\\log\\log\u0394)}+O(\\log^* n)$-round algorithm.",
        "subjects": [
            "cs.DS",
            "cs.DC",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04650",
        "abstract url": "https://arxiv.org/abs/2405.04650",
        "title": "A Self-Supervised Method for Body Part Segmentation and Keypoint Detection of Rat Images",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recognition of individual components and keypoint detection supported by instance segmentation is crucial to analyze the behavior of agents on the scene. Such systems could be used for surveillance, self-driving cars, and also for medical research, where behavior analysis of laboratory animals is used to confirm the aftereffects of a given medicine. A method capable of solving the aforementioned tasks usually requires a large amount of high-quality hand-annotated data, which takes time and money to produce. In this paper, we propose a method that alleviates the need for manual labeling of laboratory rats. To do so, first, we generate initial annotations with a computer vision-based approach, then through extensive augmentation, we train a deep neural network on the generated data. The final system is capable of instance segmentation, keypoint detection, and body part segmentation even when the objects are heavily occluded.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04722",
        "abstract url": "https://arxiv.org/abs/2405.04722",
        "title": "Detecting and Refining HiRISE Image Patches Obscured by Atmospheric Dust",
        "rating": "-1",
        "keywords": [
            [
                "GAN"
            ],
            [
                "flight"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "HiRISE (High-Resolution Imaging Science Experiment) is a camera onboard the Mars Reconnaissance orbiter responsible for photographing vast areas of the Martian surface in unprecedented detail. It can capture millions of incredible closeup images in minutes. However, Mars suffers from frequent regional and local dust storms hampering this data-collection process, and pipeline, resulting in loss of effort and crucial flight time. Removing these images manually requires a large amount of manpower. I filter out these images obstructed by atmospheric dust automatically by using a Dust Image Classifier fine-tuned on Resnet-50 with an accuracy of 94.05%. To further facilitate the seamless filtering of Images I design a prediction pipeline that classifies and stores these dusty patches. I also denoise partially obstructed images using an Auto Encoder-based denoiser and Pix2Pix GAN with 0.75 and 0.99 SSIM Index respectively.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04777",
        "abstract url": "https://arxiv.org/abs/2405.04777",
        "title": "Empathy Through Multimodality in Conversational Interfaces",
        "rating": "-1",
        "keywords": [
            [
                "Health",
                "healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Agents represent one of the most emerging applications of Large Language Models (LLMs) and Generative AI, with their effectiveness hinging on multimodal capabilities to navigate complex user environments. Conversational Health Agents (CHAs), a prime example of this, are redefining healthcare by offering nuanced support that transcends textual analysis to incorporate emotional intelligence. This paper introduces an LLM-based CHA engineered for rich, multimodal dialogue-especially in the realm of mental health support. It adeptly interprets and responds to users' emotional states by analyzing multimodal cues, thus delivering contextually aware and empathetically resonant verbal responses. Our implementation leverages the versatile openCHA framework, and our comprehensive evaluation involves neutral prompts expressed in diverse emotional tones: sadness, anger, and joy. We evaluate the consistency and repeatability of the planning capability of the proposed CHA. Furthermore, human evaluators critique the CHA's empathic delivery, with findings revealing a striking concordance between the CHA's outputs and evaluators' assessments. These results affirm the indispensable role of vocal (soon multimodal) emotion recognition in strengthening the empathetic connection built by CHAs, cementing their place at the forefront of interactive, compassionate digital health solutions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "7 pages, 2 figures, 2 tables, conference paper"
    },
    {
        "paper id": "2405.04790",
        "abstract url": "https://arxiv.org/abs/2405.04790",
        "title": "Quantifying Smooth Muscles Regional Organization in the Rat Bladder Using Immunohistochemistry, Multiphoton Microscopy and Machine Learning",
        "rating": "-1",
        "keywords": [
            [
                "biomechanical",
                "CT"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The smooth muscle bundles (SMBs) in the bladder act as contractile elements which enable the bladder to void effectively. In contrast to skeletal muscles, these bundles are not highly aligned, rather they are oriented more heterogeneously throughout the bladder wall. In this work, for the first time, this regional orientation of the SMBs is quantified across the whole bladder, without the need for optical clearing or cryosectioning. Immunohistochemistry staining was utilized to visualize smooth muscle cell actin in multiphoton microscopy (MPM) images of bladder smooth muscle bundles (SMBs). Feature vectors for each pixel were generated using a range of filters, including Gaussian blur, Gaussian gradient magnitude, Laplacian of Gaussian, Hessian eigenvalues, structure tensor eigenvalues, Gabor, and Sobel gradients. A Random Forest classifier was subsequently trained to automate the segmentation of SMBs in the MPM images. Finally, the orientation of SMBs in each bladder region was quantified using the CT-FIRE package. This information is essential for biomechanical models of the bladder that include contractile elements.",
        "subjects": [
            "q-bio.TO",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04800",
        "abstract url": "https://arxiv.org/abs/2405.04800",
        "title": "DeepDamageNet: A two-step deep-learning model for multi-disaster building damage segmentation and classification using satellite imagery",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Satellite imagery has played an increasingly important role in post-disaster building damage assessment. Unfortunately, current methods still rely on manual visual interpretation, which is often time-consuming and can cause very low accuracy. To address the limitations of manual interpretation, there has been a significant increase in efforts to automate the process. We present a solution that performs the two most important tasks in building damage assessment, segmentation and classification, through deep-learning models. We show our results submitted as part of the xView2 Challenge, a competition to design better models for identifying buildings and their damage level after exposure to multiple kinds of natural disasters. Our best model couples a building identification semantic segmentation convolutional neural network (CNN) to a building damage classification CNN, with a combined F1 score of 0.66, surpassing the xView2 challenge baseline F1 score of 0.28. We find that though our model was able to identify buildings with relatively high accuracy, building damage classification across various disaster types is a difficult task due to the visual similarity between different damage levels and different damage distribution between disaster types, highlighting the fact that it may be important to have a probabilistic prior estimate regarding disaster damage in order to obtain accurate predictions.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04812",
        "abstract url": "https://arxiv.org/abs/2405.04812",
        "title": "General Place Recognition Survey: Towards Real-World Autonomy",
        "rating": "-1",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "robotics",
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of robotics, the quest for achieving real-world autonomy, capable of executing large-scale and long-term operations, has positioned place recognition (PR) as a cornerstone technology. Despite the PR community's remarkable strides over the past two decades, garnering attention from fields like computer vision and robotics, the development of PR methods that sufficiently support real-world robotic systems remains a challenge. This paper aims to bridge this gap by highlighting the crucial role of PR within the framework of Simultaneous Localization and Mapping (SLAM) 2.0. This new phase in robotic navigation calls for scalable, adaptable, and efficient PR solutions by integrating advanced artificial intelligence (AI) technologies. For this goal, we provide a comprehensive review of the current state-of-the-art (SOTA) advancements in PR, alongside the remaining challenges, and underscore its broad applications in robotics. This paper begins with an exploration of PR's formulation and key research challenges. We extensively review literature, focusing on related methods on place representation and solutions to various PR challenges. Applications showcasing PR's potential in robotics, key PR datasets, and open-source libraries are discussed. We also emphasizes our open-source package, aimed at new development and benchmark for general PR. We conclude with a discussion on PR's future directions, accompanied by a summary of the literature covered and access to our open-source library, available to the robotics community at: https://github.com/MetaSLAM/GPRS.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "20 pages, 12 figures, under review"
    },
    {
        "paper id": "2405.04147",
        "abstract url": "https://arxiv.org/abs/2405.04147",
        "title": "Multiparameter regularization and aggregation in the context of polynomial functional regression",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Most of the recent results in polynomial functional regression have been focused on an in-depth exploration of single-parameter regularization schemes. In contrast, in this study we go beyond that framework by introducing an algorithm for multiple parameter regularization and presenting a theoretically grounded method for dealing with the associated parameters. This method facilitates the aggregation of models with varying regularization parameters. The efficacy of the proposed approach is assessed through evaluations on both synthetic and some real-world medical data, revealing promising results.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.NA",
            "math.ST"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2405.04161",
        "abstract url": "https://arxiv.org/abs/2405.04161",
        "title": "Opportunities for machine learning in scientific discovery",
        "rating": "-1.5",
        "keywords": [
            [
                "biochemistry"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Technological advancements have substantially increased computational power and data availability, enabling the application of powerful machine-learning (ML) techniques across various fields. However, our ability to leverage ML methods for scientific discovery, {\\it i.e.} to obtain fundamental and formalized knowledge about natural processes, is still in its infancy. In this review, we explore how the scientific community can increasingly leverage ML techniques to achieve scientific discoveries. We observe that the applicability and opportunity of ML depends strongly on the nature of the problem domain, and whether we have full ({\\it e.g.}, turbulence), partial ({\\it e.g.}, computational biochemistry), or no ({\\it e.g.}, neuroscience) {\\it a-priori} knowledge about the governing equations and physical properties of the system. Although challenges remain, principled use of ML is opening up new avenues for fundamental scientific discoveries. Throughout these diverse fields, there is a theme that ML is enabling researchers to embrace complexity in observational data that was previously intractable to classic analysis and numerical investigations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04230",
        "abstract url": "https://arxiv.org/abs/2405.04230",
        "title": "Unveiling the optimization process of Physics Informed Neural Networks: How accurate and competitive can PINNs be?",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study investigates the potential accuracy boundaries of physics-informed neural networks, contrasting their approach with previous similar works and traditional numerical methods. We find that selecting improved optimization algorithms significantly enhances the accuracy of the results. Simple modifications to the loss function may also improve precision, offering an additional avenue for enhancement. Despite optimization algorithms having a greater impact on convergence than adjustments to the loss function, practical considerations often favor tweaking the latter due to ease of implementation. On a global scale, the integration of an enhanced optimizer and a marginally adjusted loss function enables a reduction in the loss function by several orders of magnitude across diverse physical problems. Consequently, our results obtained using compact networks (typically comprising 2 or 3 layers of 20-30 neurons) achieve accuracies comparable to finite difference schemes employing thousands of grid points. This study encourages the continued advancement of PINNs and associated optimization techniques for broader applications across various fields.",
        "subjects": [
            "physics.comp-ph",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "46 pages, 13 figures, submitted for publication in JCP"
    },
    {
        "paper id": "2405.04235",
        "abstract url": "https://arxiv.org/abs/2405.04235",
        "title": "LTLDoG: Satisfying Temporally-Extended Symbolic Constraints for Safe Diffusion-based Planning",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Operating effectively in complex environments while complying with specified constraints is crucial for the safe and successful deployment of robots that interact with and operate around people. In this work, we focus on generating long-horizon trajectories that adhere to novel static and temporally-extended constraints/instructions at test time. We propose a data-driven diffusion-based framework, LTLDoG, that modifies the inference steps of the reverse process given an instruction specified using finite linear temporal logic ($\\text{LTL}_f$). LTLDoG leverages a satisfaction value function on $\\text{LTL}_f$ and guides the sampling steps using its gradient field. This value function can also be trained to generalize to new instructions not observed during training, enabling flexible test-time adaptability. Experiments in robot navigation and manipulation illustrate that the method is able to generate trajectories that satisfy formulae that specify obstacle avoidance and visitation sequences.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04252",
        "abstract url": "https://arxiv.org/abs/2405.04252",
        "title": "VAEneu: A New Avenue for VAE Application on Probabilistic Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents VAEneu, an innovative autoregressive method for multistep ahead univariate probabilistic time series forecasting. We employ the conditional VAE framework and optimize the lower bound of the predictive distribution likelihood function by adopting the Continuous Ranked Probability Score (CRPS), a strictly proper scoring rule, as the loss function. This novel pipeline results in forecasting sharp and well-calibrated predictive distribution. Through a comprehensive empirical study, VAEneu is rigorously benchmarked against 12 baseline models across 12 datasets. The results unequivocally demonstrate VAEneu's remarkable forecasting performance. VAEneu provides a valuable tool for quantifying future uncertainties, and our extensive empirical study lays the foundation for future comparative studies for univariate multistep ahead probabilistic forecasting.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04357",
        "abstract url": "https://arxiv.org/abs/2405.04357",
        "title": "Global Scale Self-Supervised Channel Charting with Sensor Fusion",
        "rating": "-1.5",
        "keywords": [
            [
                "6G",
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The sensing and positioning capabilities foreseen in 6G have great potential for technology advancements in various domains, such as future smart cities and industrial use cases. Channel charting has emerged as a promising technology in recent years for radio frequency-based sensing and localization. However, the accuracy of these techniques is yet far behind the numbers envisioned in 6G. To reduce this gap, in this paper, we propose a novel channel charting technique capitalizing on the time of arrival measurements from surrounding Transmission Reception Points (TRPs) along with their locations and leveraging sensor fusion in channel charting by incorporating laser scanner data during the training phase of our algorithm. The proposed algorithm remains self-supervised during training and test phases, requiring no geometrical models or user position ground truth. Simulation results validate the achievement of a sub-meter level localization accuracy using our algorithm 90% of the time, outperforming the state-of-the-art channel charting techniques and the traditional triangulation-based approaches.",
        "subjects": [
            "cs.IT",
            "cs.AI"
        ],
        "comment": "This paper is submitted to the Globecom 2024 conference"
    },
    {
        "paper id": "2405.04657",
        "abstract url": "https://arxiv.org/abs/2405.04657",
        "title": "ACEGEN: Reinforcement learning of generative chemical agents for drug discovery",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, reinforcement learning (RL) has emerged as a valuable tool in drug design, offering the potential to propose and optimize molecules with desired properties. However, striking a balance between capability, flexibility, and reliability remains challenging due to the complexity of advanced RL algorithms and the significant reliance on specialized code. In this work, we introduce ACEGEN, a comprehensive and streamlined toolkit tailored for generative drug design, built using TorchRL, a modern decision-making library that offers efficient and thoroughly tested reusable components. ACEGEN provides a robust, flexible, and efficient platform for molecular design. We validate its effectiveness by benchmarking it across various algorithms and conducting multiple drug discovery case studies. ACEGEN is accessible at https://github.com/acellera/acegen-open.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04716",
        "abstract url": "https://arxiv.org/abs/2405.04716",
        "title": "Physics-based deep learning reveals rising heating demand heightens air pollution in Norwegian cities",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Policymakers frequently analyze air quality and climate change in isolation, disregarding their interactions. This study explores the influence of specific climate factors on air quality by contrasting a regression model with K-Means Clustering, Hierarchical Clustering, and Random Forest techniques. We employ Physics-based Deep Learning (PBDL) and Long Short-Term Memory (LSTM) to examine the air pollution predictions. Our analysis utilizes ten years (2009-2018) of daily traffic, weather, and air pollution data from three major cities in Norway. Findings from feature selection reveal a correlation between rising heating degree days and heightened air pollution levels, suggesting increased heating activities in Norway are a contributing factor to worsening air quality. PBDL demonstrates superior accuracy in air pollution predictions compared to LSTM. This paper contributes to the growing literature on PBDL methods for more accurate air pollution predictions using environmental variables, aiding policymakers in formulating effective data-driven climate policies.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "52 pages, 23 figures"
    },
    {
        "paper id": "2405.04753",
        "abstract url": "https://arxiv.org/abs/2405.04753",
        "title": "AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Attack knowledge graph construction seeks to convert textual cyber threat intelligence (CTI) reports into structured representations, portraying the evolutionary traces of cyber attacks. Even though previous research has proposed various methods to construct attack knowledge graphs, they generally suffer from limited generalization capability to diverse knowledge types as well as requirement of expertise in model design and tuning. Addressing these limitations, we seek to utilize Large Language Models (LLMs), which have achieved enormous success in a broad range of tasks given exceptional capabilities in both language understanding and zero-shot task fulfillment. Thus, we propose a fully automatic LLM-based framework to construct attack knowledge graphs named: AttacKG+. Our framework consists of four consecutive modules: rewriter, parser, identifier, and summarizer, each of which is implemented by instruction prompting and in-context learning empowered by LLMs. Furthermore, we upgrade the existing attack knowledge schema and propose a comprehensive version. We represent a cyber attack as a temporally unfolding event, each temporal step of which encapsulates three layers of representation, including behavior graph, MITRE TTP labels, and state summary. Extensive evaluation demonstrates that: 1) our formulation seamlessly satisfies the information needs in threat event analysis, 2) our construction framework is effective in faithfully and accurately extracting the information defined by AttacKG+, and 3) our attack graph directly benefits downstream security practices such as attack reconstruction. All the code and datasets will be released upon acceptance.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "20 pages, 5 figures"
    },
    {
        "paper id": "2405.04012",
        "abstract url": "https://arxiv.org/abs/2405.04012",
        "title": "Latency and Energy Minimization in NOMA-Assisted MEC Network: A Federated Deep Reinforcement Learning Approach",
        "rating": "-2",
        "keywords": [
            [
                "6G",
                "IoT"
            ]
        ],
        "abstract": "Multi-access edge computing (MEC) is seen as a vital component of forthcoming 6G wireless networks, aiming to support emerging applications that demand high service reliability and low latency. However, ensuring the ultra-reliable and low-latency performance of MEC networks poses a significant challenge due to uncertainties associated with wireless links, constraints imposed by communication and computing resources, and the dynamic nature of network traffic. Enabling ultra-reliable and low-latency MEC mandates efficient load balancing jointly with resource allocation. In this paper, we investigate the joint optimization problem of offloading decisions, computation and communication resource allocation to minimize the expected weighted sum of delivery latency and energy consumption in a non-orthogonal multiple access (NOMA)-assisted MEC network. Given the formulated problem is a mixed-integer non-linear programming (MINLP), a new multi-agent federated deep reinforcement learning (FDRL) solution based on double deep Q-network (DDQN) is developed to efficiently optimize the offloading strategies across the MEC network while accelerating the learning process of the Internet-of-Thing (IoT) devices. Simulation results show that the proposed FDRL scheme can effectively reduce the weighted sum of delivery latency and energy consumption of IoT devices in the MEC network and outperform the baseline approaches.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04023",
        "abstract url": "https://arxiv.org/abs/2405.04023",
        "title": "Lumbar Spine Tumor Segmentation and Localization in T2 MRI Images Using AI",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "MRI",
                "clinical",
                "Tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In medical imaging, segmentation and localization of spinal tumors in three-dimensional (3D) space pose significant computational challenges, primarily stemming from limited data availability. In response, this study introduces a novel data augmentation technique, aimed at automating spine tumor segmentation and localization through AI approaches. Leveraging a fusion of fuzzy c-means clustering and Random Forest algorithms, the proposed method achieves successful spine tumor segmentation based on predefined masks initially delineated by domain experts in medical imaging. Subsequently, a Convolutional Neural Network (CNN) architecture is employed for tumor classification. Moreover, 3D vertebral segmentation and labeling techniques are used to help pinpoint the exact location of the tumors in the lumbar spine. Results indicate a remarkable performance, with 99% accuracy for tumor segmentation, 98% accuracy for tumor classification, and 99% accuracy for tumor localization achieved with the proposed approach. These metrics surpass the efficacy of existing state-of-the-art techniques, as evidenced by superior Dice Score, Class Accuracy, and Intersection over Union (IOU) on class accuracy metrics. This innovative methodology holds promise for enhancing the diagnostic capabilities in detecting and characterizing spinal tumors, thereby facilitating more effective clinical decision-making.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "9 pages, 12 figures"
    },
    {
        "paper id": "2405.04052",
        "abstract url": "https://arxiv.org/abs/2405.04052",
        "title": "Minimizing the Minimizers via Alphabet Reordering",
        "rating": "-2",
        "keywords": [
            [
                "Bioinformatics"
            ]
        ],
        "abstract": "Minimizers sampling is one of the most widely-used mechanisms for sampling strings [Roberts et al., Bioinformatics 2004]. Let $S=S[1]\\ldots S[n]$ be a string over a totally ordered alphabet $\u03a3$. Further let $w\\geq 2$ and $k\\geq 1$ be two integers. The minimizer of $S[i\\mathinner{.\\,.} i+w+k-2]$ is the smallest position in $[i,i+w-1]$ where the lexicographically smallest length-$k$ substring of $S[i\\mathinner{.\\,.} i+w+k-2]$ starts. The set of minimizers over all $i\\in[1,n-w-k+2]$ is the set $\\mathcal{M}_{w,k}(S)$ of the minimizers of $S$. We consider the following basic problem: Given $S$, $w$, and $k$, can we efficiently compute a total order on $\u03a3$ that minimizes $|\\mathcal{M}_{w,k}(S)|$? We show that this is unlikely by proving that the problem is NP-hard for any $w\\geq 2$ and $k\\geq 1$. Our result provides theoretical justification as to why there exist no exact algorithms for minimizing the minimizers samples, while there exists a plethora of heuristics for the same purpose.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "Extended version of a paper accepted at CPM 2024"
    },
    {
        "paper id": "2405.04072",
        "abstract url": "https://arxiv.org/abs/2405.04072",
        "title": "Quantum Unpredictability",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Unpredictable functions (UPFs) play essential roles in classical cryptography, including message authentication codes (MACs) and digital signatures. In this paper, we introduce a quantum analog of UPFs, which we call unpredictable state generators (UPSGs). UPSGs are implied by pseudorandom function-like states generators (PRFSs), which are a quantum analog of pseudorandom functions (PRFs), and therefore UPSGs could exist even if one-way functions do not exist, similar to other recently introduced primitives like pseudorandom state generators (PRSGs), one-way state generators (OWSGs), and EFIs. In classical cryptography, UPFs are equivalent to PRFs, but in the quantum case, the equivalence is not clear, and UPSGs could be weaker than PRFSs. Despite this, we demonstrate that all known applications of PRFSs are also achievable with UPSGs. They include IND-CPA-secure secret-key encryption and EUF-CMA-secure MACs with unclonable tags. Our findings suggest that, for many applications, quantum unpredictability, rather than quantum pseudorandomness, is sufficient.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": "38 pages, 1 figure"
    },
    {
        "paper id": "2405.04080",
        "abstract url": "https://arxiv.org/abs/2405.04080",
        "title": "Derisking of subsynchronous torsional oscillations in power systems with conventional and inverter-based generation",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "This article proposes an application of a derisking methodology of subsynchronous torsional oscillations considering a realistic use case. The main objective is to summarize and draft a synthetic paper clarifying the complete methodology highlighting the main information needed step-by-step. For exemplification, a real model from a decommissioned oil power plant is adopted, where a fictitious high voltage direct current power link is connected. In this article, stress is laid on details of the application of the derisking methods: the unit interaction factor and the complex torque coefficients method. Then, the different steps to obtain results are explicitly explained. Moreover, the design and tuning process of supplementary subsynchronous damping controller is discussed. This mitigation section uses minimal information to correctly damp the unstable oscillations, as one would expect from industrial projects where the data sharing may be limited. Finally, the resources needed to perform each step of the study were summarized.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04082",
        "abstract url": "https://arxiv.org/abs/2405.04082",
        "title": "Logic-Skill Programming: An Optimization-based Approach to Sequential Skill Planning",
        "rating": "-2",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Recent advances in robot skill learning have unlocked the potential to construct task-agnostic skill libraries, facilitating the seamless sequencing of multiple simple manipulation primitives (aka. skills) to tackle significantly more complex tasks. Nevertheless, determining the optimal sequence for independently learned skills remains an open problem, particularly when the objective is given solely in terms of the final geometric configuration rather than a symbolic goal. To address this challenge, we propose Logic-Skill Programming (LSP), an optimization-based approach that sequences independently learned skills to solve long-horizon tasks. We formulate a first-order extension of a mathematical program to optimize the overall cumulative reward of all skills within a plan, abstracted by the sum of value functions. To solve such programs, we leverage the use of Tensor Train to construct the value function space, and rely on alternations between symbolic search and skill value optimization to find the appropriate skill skeleton and optimal subgoal sequence. Experimental results indicate that the obtained value functions provide a superior approximation of cumulative rewards compared to state-of-the-art Reinforcement Learning methods. Furthermore, we validate LSP in three manipulation domains, encompassing both prehensile and non-prehensile primitives. The results demonstrate its capability to identify the optimal solution over the full logic and geometric path. The real-robot experiments showcase the effectiveness of our approach to cope with contact uncertainty and external disturbances in the real world.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04099",
        "abstract url": "https://arxiv.org/abs/2405.04099",
        "title": "Effect of realistic oscillator phase noise on the performance of cell-free networks",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "To keep supporting 6G requirements, the radio access infrastructure will increasingly densify. Cell-free (CF) networks offer extreme flexibility by coherently serving users with multiple Access points (APs). This paradigm requires precise and stable phase synchronization. In this article, we adapt the standardized 5G NR setup (subcarrier spacing, OFDM symbol duration and allocation) to investigate the effect of Phase Noise (PN) on the simulated performance of scalable CF networks. In contrast to the prior literature relying on the simplified model of a free-running oscillator with the Wiener process, we deploy a realistic hardware-inspired phase noise model reproducing the Local Oscillator (LO) phase drift. Our results demonstrate that even affordable LOs offer sufficient stability to ensure negligible loss of uplink Spectral Efficiency (SE) on the time scale of the standardized 5G Transmission Time Interval of 1 ms. This study substantiates the feasibility of CF networks based on 5G standards.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04109",
        "abstract url": "https://arxiv.org/abs/2405.04109",
        "title": "The Malware as a Service ecosystem",
        "rating": "-2",
        "keywords": [
            [
                "crime"
            ]
        ],
        "abstract": "The goal of this chapter is to illuminate the operational frameworks, key actors, and significant cybersecurity implications of the Malware as a Service (MaaS) ecosystem. Highlighting the transformation of malware proliferation into a service-oriented model, the chapter discusses how MaaS democratises access to sophisticated cyberattack capabilities, enabling even those with minimal technical knowledge to execute catastrophic cyberattacks. The discussion extends to the roles within the MaaS ecosystem, including malware developers, affiliates, initial access brokers, and the essential infrastructure providers that support these nefarious activities. The study emphasises the profound challenges MaaS poses to traditional cybersecurity defences, rendered ineffective against the constantly evolving and highly adaptable threats generated by MaaS platforms. With the increase in malware sophistication, there is a parallel call for a paradigm shift in defensive strategies, advocating for dynamic analysis, behavioural detection, and the integration of AI and machine learning techniques. By exploring the intricacies of the MaaS ecosystem, including the economic motivations driving its growth and the blurred lines between legitimate service models and cyber crime, the chapter presents a comprehensive overview intended to foster a deeper understanding among researchers and cybersecurity professionals. The ultimate goal is to aid in developing more effective strategies for combating the spread of commoditised malware threats and safeguarding against the increasing accessibility and scalability of cyberattacks facilitated by the MaaS model.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "To appear in D Gritzalis, KKR Choo, C Patsakis, \"Malware - Handbook of Prevention and Detection\", Springer (Advances in Information Security)"
    },
    {
        "paper id": "2405.04146",
        "abstract url": "https://arxiv.org/abs/2405.04146",
        "title": "pFedLVM: A Large Vision Model (LVM)-Driven and Latent Feature-Based Personalized Federated Learning Framework in Autonomous Driving",
        "rating": "-2",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Deep learning-based Autonomous Driving (AD) models often exhibit poor generalization due to data heterogeneity in an ever domain-shifting environment. While Federated Learning (FL) could improve the generalization of an AD model (known as FedAD system), conventional models often struggle with under-fitting as the amount of accumulated training data progressively increases. To address this issue, instead of conventional small models, employing Large Vision Models (LVMs) in FedAD is a viable option for better learning of representations from a vast volume of data. However, implementing LVMs in FedAD introduces three challenges: (I) the extremely high communication overheads associated with transmitting LVMs between participating vehicles and a central server; (II) lack of computing resource to deploy LVMs on each vehicle; (III) the performance drop due to LVM focusing on shared features but overlooking local vehicle characteristics. To overcome these challenges, we propose pFedLVM, a LVM-Driven, Latent Feature-Based Personalized Federated Learning framework. In this approach, the LVM is deployed only on central server, which effectively alleviates the computational burden on individual vehicles. Furthermore, the exchange between central server and vehicles are the learned features rather than the LVM parameters, which significantly reduces communication overhead. In addition, we utilize both shared features from all participating vehicles and individual characteristics from each vehicle to establish a personalized learning mechanism. This enables each vehicle's model to learn features from others while preserving its personalized characteristics, thereby outperforming globally shared models trained in general FL. Extensive experiments demonstrate that pFedLVM outperforms the existing state-of-the-art approaches.",
        "subjects": [
            "cs.RO",
            "cs.DC"
        ],
        "comment": "This paper was submitted to IEEE Transactions on Mobile Computing (TMC) on Apr. 6th, 2024"
    },
    {
        "paper id": "2405.04188",
        "abstract url": "https://arxiv.org/abs/2405.04188",
        "title": "Behavioral Manifolds: Representing the Landscape of Grasp Affordances in the Relative Pose Space",
        "rating": "-2",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "trajectory"
            ]
        ],
        "abstract": "The use of machine learning to investigate grasp affordances has received extensive attention over the past several decades. The existing literature provides a robust basis to build upon, though a number of aspects may be improved. Results commonly work in terms of grasp configuration, with little consideration for the manner in which the grasp may be (re-)produced from a reachability and trajectory planning perspective. In addition, the majority of existing learning approaches focus of producing a single viable grasp, offering little transparency on how the result was reached, or insights on its robustness. We propose a different perspective on grasp affordance learning, explicitly accounting for grasp synthesis; that is, the manner in which manipulator kinematics are used to allow materialization of grasps. The approach allows to explicitly map the grasp policy space in terms of generated grasp types and associated grasp quality. Results of numerical simulations illustrate merit of the method and highlight the manner in which it may promote a greater degree of explainability for otherwise intransparent reinforcement processes.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2405.04192",
        "abstract url": "https://arxiv.org/abs/2405.04192",
        "title": "Quantum software experiments: A reporting and laboratory package structure guidelines",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Background. In the realm of software engineering, there are widely accepted guidelines for reporting and creating laboratory packages. Unfortunately, the landscape differs considerably in the emerging field of quantum computing. To the best of our knowledge, no standardized guidelines exist for describing experiments or outlining the necessary structures for quantum software laboratory packages. Aims. This paper endeavors to enhance the replicability and verifiability of quantum software experiments. Method. This objective is pursued through the proposition of guidelines for reporting and the delineation of a structure for laboratory packages tailored to quantum computing experiments. Specifically, we advocate for an extension and adaption of established guidelines in experimental software engineering, integrating novel elements to address the specific requirements of quantum software engineering. Results. In validating the utility and effectiveness of the proposed guidelines, we conducted a review encompassing 11 works (5 focusing on reporting guidelines and 6 on laboratory packages). In particular, this review highlighted the absence of standardized guidelines and structure of laboratory packages for quantum software experiments. Conclusions. Our assessment revealed gaps in information and opportunities for enhancement within the evaluated papers and laboratory packages. Our proposal contributes to the advancement of quantum software engineering research, taking a fundamental step toward fostering rigorous and reliable scientific research in this emerging paradigm.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "10 pages, 1 figure, and 6 tables"
    },
    {
        "paper id": "2405.04211",
        "abstract url": "https://arxiv.org/abs/2405.04211",
        "title": "Breast Histopathology Image Retrieval by Attention-based Adversarially Regularized Variational Graph Autoencoder with Contrastive Learning-Based Feature Extraction",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "medical",
                "health",
                "diagnosis",
                "cancer",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Breast cancer is a significant global health concern, particularly for women. Early detection and appropriate treatment are crucial in mitigating its impact, with histopathology examinations playing a vital role in swift diagnosis. However, these examinations often require a substantial workforce and experienced medical experts for proper recognition and cancer grading. Automated image retrieval systems have the potential to assist pathologists in identifying cancerous tissues, thereby accelerating the diagnostic process. Nevertheless, due to considerable variability among the tissue and cell patterns in histological images, proposing an accurate image retrieval model is very challenging. This work introduces a novel attention-based adversarially regularized variational graph autoencoder model for breast histological image retrieval. Additionally, we incorporated cluster-guided contrastive learning as the graph feature extractor to boost the retrieval performance. We evaluated the proposed model's performance on two publicly available datasets of breast cancer histological images and achieved superior or very competitive retrieval performance, with average mAP scores of 96.5% for the BreakHis dataset and 94.7% for the BACH dataset, and mVP scores of 91.9% and 91.3%, respectively. Our proposed retrieval model has the potential to be used in clinical settings to enhance diagnostic performance and ultimately benefit patients.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2405.04218",
        "abstract url": "https://arxiv.org/abs/2405.04218",
        "title": "Deep Reinforcement Learning for Multi-User RF Charging with Non-linear Energy Harvesters",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Radio frequency (RF) wireless power transfer (WPT) is a promising technology for sustainable support of massive Internet of Things (IoT). However, RF-WPT systems are characterized by low efficiency due to channel attenuation, which can be mitigated by precoders that adjust the transmission directivity. This work considers a multi-antenna RF-WPT system with multiple non-linear energy harvesting (EH) nodes with energy demands changing over discrete time slots. This leads to the charging scheduling problem, which involves choosing the precoders at each slot to minimize the total energy consumption and meet the EH requirements. We model the problem as a Markov decision process and propose a solution relying on a low-complexity beamforming and deep deterministic policy gradient (DDPG). The results show that the proposed beamforming achieves near-optimal performance with low computational complexity, and the DDPG-based approach converges with the number of episodes and reduces the system's power consumption, while the outage probability and the power consumption increase with the number of devices.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2405.04246",
        "abstract url": "https://arxiv.org/abs/2405.04246",
        "title": "Dataset and Models for Item Recommendation Using Multi-Modal User Interactions",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "While recommender systems with multi-modal item representations (image, audio, and text), have been widely explored, learning recommendations from multi-modal user interactions (e.g., clicks and speech) remains an open problem. We study the case of multi-modal user interactions in a setting where users engage with a service provider through multiple channels (website and call center). In such cases, incomplete modalities naturally occur, since not all users interact through all the available channels. To address these challenges, we publish a real-world dataset that allows progress in this under-researched area. We further present and benchmark various methods for leveraging multi-modal user interactions for item recommendations, and propose a novel approach that specifically deals with missing modalities by mapping user interactions to a common feature space. Our analysis reveals important interactions between the different modalities and that a frequently occurring modality can enhance learning from a less frequent one.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04263",
        "abstract url": "https://arxiv.org/abs/2405.04263",
        "title": "Energy-Efficient Deployment of Stateful FaaS Vertical Applications on Edge Data Networks",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "5G and beyond support the deployment of vertical applications, which is particularly appealing in combination with network slicing and edge computing to create a logically isolated environment for executing customer services. Even if serverless computing has gained significant interest as a cloud-native technology its adoption at the edge is lagging, especially because of the need to support stateful tasks, which are commonplace in, e.g., cognitive services, but not fully amenable to being deployed on limited and decentralized computing infrastructures. In this work, we study the emerging paradigm of stateful Function as a Service (FaaS) with lightweight task abstractions in WebAssembly. Specifically, we assess the implications of deploying inter-dependent tasks with an internal state on edge computing resources using a stateless vs. stateful approach and then derive a mathematical model to estimate the energy consumption of a workload with given characteristics, considering the power used for both processing and communication. The model is used in extensive simulations to determine the impact of key factors and assess the energy trade-offs of stateless vs. stateful.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted for presentation at IEEE ICCCN 2024"
    },
    {
        "paper id": "2405.04274",
        "abstract url": "https://arxiv.org/abs/2405.04274",
        "title": "Group-aware Parameter-efficient Updating for Content-Adaptive Neural Video Compression",
        "rating": "-2",
        "keywords": [
            [
                "Parameter-efficient"
            ],
            [
                "medical"
            ],
            [
                "neural codec"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Content-adaptive compression is crucial for enhancing the adaptability of the pre-trained neural codec for various contents. Although these methods have been very practical in neural image compression (NIC), their application in neural video compression (NVC) is still limited due to two main aspects: 1), video compression relies heavily on temporal redundancy, therefore updating just one or a few frames can lead to significant errors accumulating over time; 2), NVC frameworks are generally more complex, with many large components that are not easy to update quickly during encoding. To address the previously mentioned challenges, we have developed a content-adaptive NVC technique called Group-aware Parameter-Efficient Updating (GPU). Initially, to minimize error accumulation, we adopt a group-aware approach for updating encoder parameters. This involves adopting a patch-based Group of Pictures (GoP) training strategy to segment a video into patch-based GoPs, which will be updated to facilitate a globally optimized domain-transferable solution. Subsequently, we introduce a parameter-efficient delta-tuning strategy, which is achieved by integrating several light-weight adapters into each coding component of the encoding process by both serial and parallel configuration. Such architecture-agnostic modules stimulate the components with large parameters, thereby reducing both the update cost and the encoding time. We incorporate our GPU into the latest NVC framework and conduct comprehensive experiments, whose results showcase outstanding video compression efficiency across four video benchmarks and adaptability of one medical image benchmark.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04282",
        "abstract url": "https://arxiv.org/abs/2405.04282",
        "title": "CoqPyt: Proof Navigation in Python in the Era of LLMs",
        "rating": "-2",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Proof assistants enable users to develop machine-checked proofs regarding software-related properties. Unfortunately, the interactive nature of these proof assistants imposes most of the proof burden on the user, making formal verification a complex, and time-consuming endeavor. Recent automation techniques based on neural methods address this issue, but require good programmatic support for collecting data and interacting with proof assistants. This paper presents CoqPyt, a Python tool for interacting with the Coq proof assistant. CoqPyt improves on other Coq-related tools by providing novel features, such as the extraction of rich premise data. We expect our work to aid development of tools and techniques, especially LLM-based, designed for proof synthesis and repair. A video describing and demonstrating CoqPyt is available at: https://youtu.be/fk74o0rePM8.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted to FSE '24 Demonstrations Track"
    },
    {
        "paper id": "2405.04283",
        "abstract url": "https://arxiv.org/abs/2405.04283",
        "title": "PDCCH Scheduling via Maximum Independent Set",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "In 5G, the Physical Downlink Control CHannel (PDCCH) carries crucial information enabling the User Equipment (UE) to connect in UL and DL. UEs are unaware of the frequency location at which PDCCH is encoded, hence they need to perform blind decoding over a limited set of possible candidates. We address the problem faced by the gNodeB of selecting PDCCH candidates for each UE to optimize data transmission. We formulate it as a Maximum Weighted Independent Set (MWIS) problem, that is known to be an NP-hard problem and cannot even be approximated. A solution method called Weight-to-Degree Ratio (WDR) Greedy emerges as a strong contender for practical implementations due to its favorable performance-to-complexity trade-off and theoretical performance guarantees.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04286",
        "abstract url": "https://arxiv.org/abs/2405.04286",
        "title": "Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Grammar",
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The efficacy of an large language model (LLM) generated text detector depends substantially on the availability of sizable training data. White-box zero-shot detectors, which require no such data, are nonetheless limited by the accessibility of the source model of the LLM-generated text. In this paper, we propose an simple but effective black-box zero-shot detection approach, predicated on the observation that human-written texts typically contain more grammatical errors than LLM-generated texts. This approach entails computing the Grammar Error Correction Score (GECScore) for the given text to distinguish between human-written and LLM-generated text. Extensive experimental results show that our method outperforms current state-of-the-art (SOTA) zero-shot and supervised methods, achieving an average AUROC of 98.7% and showing strong robustness against paraphrase and adversarial perturbation attacks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04354",
        "abstract url": "https://arxiv.org/abs/2405.04354",
        "title": "A transversality theorem for semi-algebraic sets with application to signal recovery from the second moment and cryo-EM",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Semi-algebraic priors are ubiquitous in signal processing and machine learning. Prevalent examples include a) linear models where the signal lies in a low-dimensional subspace; b) sparse models where the signal can be represented by only a few coefficients under a suitable basis; and c) a large family of neural network generative models. In this paper, we prove a transversality theorem for semi-algebraic sets in orthogonal or unitary representations of groups: with a suitable dimension bound, a generic translate of any semi-algebraic set is transverse to the orbits of the group action. This, in turn, implies that if a signal lies in a low-dimensional semi-algebraic set, then it can be recovered uniquely from measurements that separate orbits. As an application, we consider the implications of the transversality theorem to the problem of recovering signals that are translated by random group actions from their second moment. As a special case, we discuss cryo-EM: a leading technology to constitute the spatial structure of biological molecules, which serves as our prime motivation. In particular, we derive explicit bounds for recovering a molecular structure from the second moment under a semi-algebraic prior and deduce information-theoretic implications. We also obtain information-theoretic bounds for three additional applications: factoring Gram matrices, multi-reference alignment, and phase retrieval. Finally, we deduce bounds for designing permutation invariant separators in machine learning.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.AG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04355",
        "abstract url": "https://arxiv.org/abs/2405.04355",
        "title": "SmmPack: Obfuscation for SMM Modules with TPM Sealed Key",
        "rating": "-2",
        "keywords": [
            [
                "BIOS"
            ]
        ],
        "abstract": "System Management Mode (SMM) is the highest-privileged operating mode of x86 and x86-64 processors. Through SMM exploitation, attackers can tamper with the Unified Extensible Firmware Interface (UEFI) firmware, disabling the security mechanisms implemented by the operating system and hypervisor. Vulnerabilities enabling SMM code execution are often reported as Common Vulnerabilities and Exposures (CVEs); however, no security mechanisms currently exist to prevent attackers from analyzing those vulnerabilities. To increase the cost of vulnerability analysis of SMM modules, we introduced SmmPack. The core concept of SmmPack involves encrypting an SMM module with the key securely stored in a Trusted Platform Module (TPM). We assessed the effectiveness of SmmPack in preventing attackers from obtaining and analyzing SMM modules using various acquisition methods. Our results show that SmmPack significantly increases the cost by narrowing down the means of module acquisition. Furthermore, we demonstrated that SmmPack operates without compromising the performance of the original SMM modules. We also clarified the management and adoption methods of SmmPack, as well as the procedure for applying BIOS updates, and demonstrated that the implementation of SmmPack is realistic.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "21 pages, 7 figures, 4 tables. Accepted at the 21st Conference on Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA 2024)"
    },
    {
        "paper id": "2405.04431",
        "abstract url": "https://arxiv.org/abs/2405.04431",
        "title": "Optimizing Information Freshness in IoT Systems with Update Rate Constraints: A Token-Based Approach",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "In Internet of Things (IoT) status update systems, where information is sampled and subsequently transmitted from a source to a destination node, the imperative necessity lies in maintaining the timeliness of information and updating the system with optimal frequency. Optimizing information freshness in resource-limited status update systems often involves Constrained Markov Decision Process (CMDP) problems with update rate constraints. Solving CMDP problems, especially with multiple constraints, is a challenging task. To address this, we present a token-based approach that transforms CMDP into an unconstrained MDP, simplifying the solution process. We apply this approach to systems with one and two update rate constraints for optimizing Age of Incorrect Information (AoII) and Age of Information (AoI) metrics, respectively, and explore the analytical and numerical aspects. Additionally, we introduce an iterative triangle bisection method for solving the CMDP problems with two constraints, comparing its results with the token-based MDP approach. Our findings show that the token-based approach yields superior performance over baseline policies, converging to the optimal policy as the maximum number of tokens increases.",
        "subjects": [
            "cs.IT",
            "cs.NI"
        ],
        "comment": "IFIP/IEEE Networking 2024"
    },
    {
        "paper id": "2405.04432",
        "abstract url": "https://arxiv.org/abs/2405.04432",
        "title": "Designing the Network Intelligence Stratum for 6G Networks",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "As network complexity escalates, there is an increasing need for more sophisticated methods to manage and operate these networks, focusing on enhancing efficiency, reliability, and security. A wide range of Artificial Intelligence (AI)/Machine Learning (ML) models are being developed in response. These models are pivotal in automating decision-making, conducting predictive analyses, managing networks proactively, enhancing security, and optimizing network performance. They are foundational in shaping the future of networks, collectively forming what is known as Network Intelligence (NI). Prominent Standard-Defining Organizations (SDOs) are integrating NI into future network architectures, particularly emphasizing the closed-loop approach. However, existing methods for seamlessly integrating NI into network architectures are not yet fully effective. This paper introduces an in-depth architectural design for a Network Intelligence Stratum (NI Stratum). This stratum is supported by a novel end-to-end NI orchestrator that supports closed-loop NI operations across various network domains. The primary goal of this design is to streamline the deployment and coordination of NI throughout the entire network infrastructure, tackling issues related to scalability, conflict resolution, and effective data management. We detail exhaustive workflows for managing the NI lifecycle and demonstrate a reference implementation of the NI Stratum, focusing on its compatibility and integration with current network systems and open-source platforms such as Kubernetes and Kubeflow, as well as on its validation on real-world environments. The paper also outlines major challenges and open issues in deploying and managing NI.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04441",
        "abstract url": "https://arxiv.org/abs/2405.04441",
        "title": "Designing, Developing, and Validating Network Intelligence for Scaling in Service-Based Architectures based on Deep Reinforcement Learning",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Automating network processes without human intervention is crucial for the complex 6G environment. This requires zero-touch management and orchestration, the integration of Network Intelligence (NI) into the network architecture, and the efficient lifecycle management of intelligent functions. Reinforcement Learning (RL) plays a key role in this context, offering intelligent decision-making capabilities suited to networks' dynamic nature. Despite its potential, integrating RL poses challenges in model development and application. To tackle those issues, we delve into designing, developing, and validating RL algorithms for scaling network functions in service-based network architectures such as Open Radio Access Network (O-RAN). It builds upon and expands previous research on RL lifecycle management by proposing several RL algorithms and Reward Functions (RFns). Our proposed methodology is anchored on a dual approach: firstly, it evaluates the training performance of these algorithms under varying RFns, and secondly, it validates their performance after being trained to discern the practical applicability in real-world settings. We show that, despite significant progress, the development stage of RL techniques for networking applications, particularly in scaling scenarios, still leaves room for significant improvements. This study underscores the importance of ongoing research and development to enhance the practicality and resilience of RL techniques in real-world networking environments.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04463",
        "abstract url": "https://arxiv.org/abs/2405.04463",
        "title": "Large-Scale MPC: Scaling Private Iris Code Uniqueness Checks to Millions of Users",
        "rating": "-2",
        "keywords": [
            [
                "biometric"
            ]
        ],
        "abstract": "In this work we tackle privacy concerns in biometric verification systems that typically require server-side processing of sensitive data (e.g., fingerprints and Iris Codes). Concretely, we design a solution that allows us to query whether a given Iris Code is similar to one contained in a given database, while all queries and datasets are being protected using secure multiparty computation (MPC). Addressing the substantial performance demands of operational systems like World ID and aid distributions by the Red Cross, we propose new protocols to improve performance by more than three orders of magnitude compared to the recent state-of-the-art system Janus (S&P 24). Our final protocol can achieve a throughput of over a million Iris Code comparisons per second on a single CPU core, while protecting the privacy of both the query and database Iris Codes. We additionally investigate GPU acceleration for some building blocks of our protocol, which results in further speedups of over 38x compared to the respective multi-threaded CPU implementation.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04490",
        "abstract url": "https://arxiv.org/abs/2405.04490",
        "title": "Resource-Efficient and Self-Adaptive Quantum Search in a Quantum-Classical Hybrid System",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Over the past decade, the rapid advancement of deep learning and big data applications has been driven by vast datasets and high-performance computing systems. However, as we approach the physical limits of semiconductor fabrication in the post-Moore's Law era, questions arise about the future of these applications. In parallel, quantum computing has made significant progress with the potential to break limits. Major companies like IBM, Google, and Microsoft provide access to noisy intermediate-scale quantum (NISQ) computers. Despite the theoretical promise of Shor's and Grover's algorithms, practical implementation on current quantum devices faces challenges, such as demanding additional resources and a high number of controlled operations. To tackle these challenges and optimize the utilization of limited onboard qubits, we introduce ReSaQuS, a resource-efficient index-value searching system within a quantum-classical hybrid framework. Building on Grover's algorithm, ReSaQuS employs an automatically managed iterative search approach. This method analyzes problem size, filters fewer probable data points, and progressively reduces the dataset with decreasing qubit requirements. Implemented using Qiskit and evaluated through extensive experiments, ReSaQuS has demonstrated a substantial reduction, up to 86.36\\% in cumulative qubit consumption and 72.72\\% in active periods, reinforcing its potential in optimizing quantum computing application deployment.",
        "subjects": [
            "cs.DC",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04498",
        "abstract url": "https://arxiv.org/abs/2405.04498",
        "title": "Generative Planning with Fast Collision Checks for High Speed Navigation",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Reasoning about large numbers of diverse plans to achieve high speed navigation in cluttered environments remains a challenge for robotic systems even in the case of perfect perceptual information. Often, this is tackled by methods that iteratively optimize around a prior seeded trajectory and consequently restrict to local optima. We present a novel planning method using normalizing flows (NFs) to encode expert-styled motion primitives. We also present an accelerated collision checking framework that enables rejecting samples from the prior distribution before running them through the NF model for rapid sampling of collision-free trajectories. The choice of an NF as the generator permits a flexible way to encode diverse multi-modal behavior distributions while maintaining a smooth relation to the input space which allows approximating collision checks on NF inputs rather than outputs. We show comparable performance to model predictive path integral control in random cluttered environments and improved exit rates in a cul-de-sac environment. We conclude by discussing our plans for future work to improve both safety and performance of our controller.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Presented at Agile Robotics ICRA 2024 workshop"
    },
    {
        "paper id": "2405.04514",
        "abstract url": "https://arxiv.org/abs/2405.04514",
        "title": "Scalable Circuit Cutting and Scheduling in a Resource-constrained and Distributed Quantum System",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Despite quantum computing's rapid development, current systems remain limited in practical applications due to their limited qubit count and quality. Various technologies, such as superconducting, trapped ions, and neutral atom quantum computing technologies are progressing towards a fault tolerant era, however they all face a diverse set of challenges in scalability and control. Recent efforts have focused on multi-node quantum systems that connect multiple smaller quantum devices to execute larger circuits. Future demonstrations hope to use quantum channels to couple systems, however current demonstrations can leverage classical communication with circuit cutting techniques. This involves cutting large circuits into smaller subcircuits and reconstructing them post-execution. However, existing cutting methods are hindered by lengthy search times as the number of qubits and gates increases. Additionally, they often fail to effectively utilize the resources of various worker configurations in a multi-node system. To address these challenges, we introduce FitCut, a novel approach that transforms quantum circuits into weighted graphs and utilizes a community-based, bottom-up approach to cut circuits according to resource constraints, e.g., qubit counts, on each worker. FitCut also includes a scheduling algorithm that optimizes resource utilization across workers. Implemented with Qiskit and evaluated extensively, FitCut significantly outperforms the Qiskit Circuit Knitting Toolbox, reducing time costs by factors ranging from 3 to 2000 and improving resource utilization rates by up to 3.88 times on the worker side, achieving a system-wide improvement of 2.86 times.",
        "subjects": [
            "quant-ph",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04595",
        "abstract url": "https://arxiv.org/abs/2405.04595",
        "title": "An Advanced Features Extraction Module for Remote Sensing Image Super-Resolution",
        "rating": "-2",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, convolutional neural networks (CNNs) have achieved remarkable advancement in the field of remote sensing image super-resolution due to the complexity and variability of textures and structures in remote sensing images (RSIs), which often repeat in the same images but differ across others. Current deep learning-based super-resolution models focus less on high-frequency features, which leads to suboptimal performance in capturing contours, textures, and spatial information. State-of-the-art CNN-based methods now focus on the feature extraction of RSIs using attention mechanisms. However, these methods are still incapable of effectively identifying and utilizing key content attention signals in RSIs. To solve this problem, we proposed an advanced feature extraction module called Channel and Spatial Attention Feature Extraction (CSA-FE) for effectively extracting the features by using the channel and spatial attention incorporated with the standard vision transformer (ViT). The proposed method trained over the UCMerced dataset on scales 2, 3, and 4. The experimental results show that our proposed method helps the model focus on the specific channels and spatial locations containing high-frequency information so that the model can focus on relevant features and suppress irrelevant ones, which enhances the quality of super-resolved images. Our model achieved superior performance compared to various existing models.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Preprint of paper from The 21st International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology or ECTI-CON 2024, Khon Kaen, Thailand"
    },
    {
        "paper id": "2405.04629",
        "abstract url": "https://arxiv.org/abs/2405.04629",
        "title": "ResNCT: A Deep Learning Model for the Synthesis of Nephrographic Phase Images in CT Urography",
        "rating": "-2",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "CT"
            ],
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: To develop and evaluate a transformer-based deep learning model for the synthesis of nephrographic phase images in CT urography (CTU) examinations from the unenhanced and urographic phases. Materials and Methods: This retrospective study was approved by the local Institutional Review Board. A dataset of 119 patients (mean $\\pm$ SD age, 65 $\\pm$ 12 years; 75/44 males/females) with three-phase CT urography studies was curated for deep learning model development. The three phases for each patient were aligned with an affine registration algorithm. A custom model, coined Residual transformer model for Nephrographic phase CT image synthesis (ResNCT), was developed and implemented with paired inputs of non-contrast and urographic sets of images trained to produce the nephrographic phase images, that were compared with the corresponding ground truth nephrographic phase images. The synthesized images were evaluated with multiple performance metrics, including peak signal to noise ratio (PSNR), structural similarity index (SSIM), normalized cross correlation coefficient (NCC), mean absolute error (MAE), and root mean squared error (RMSE). Results: The ResNCT model successfully generated synthetic nephrographic images from non-contrast and urographic image inputs. With respect to ground truth nephrographic phase images, the images synthesized by the model achieved high PSNR (27.8 $\\pm$ 2.7 dB), SSIM (0.88 $\\pm$ 0.05), and NCC (0.98 $\\pm$ 0.02), and low MAE (0.02 $\\pm$ 0.005) and RMSE (0.042 $\\pm$ 0.016). Conclusion: The ResNCT model synthesized nephrographic phase CT images with high similarity to ground truth images. The ResNCT model provides a means of eliminating the acquisition of the nephrographic phase with a resultant 33% reduction in radiation dose for CTU examinations.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "physics.med-ph"
        ],
        "comment": "19 pages, 5 Figures,2 Tables"
    },
    {
        "paper id": "2405.04652",
        "abstract url": "https://arxiv.org/abs/2405.04652",
        "title": "AffirmativeAI: Towards LGBTQ+ Friendly Audit Frameworks for Large Language Models",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "LGBTQ+ community face disproportionate mental health challenges, including higher rates of depression, anxiety, and suicidal ideation. Research has shown that LGBTQ+ people have been using large language model-based chatbots, such as ChatGPT, for their mental health needs. Despite the potential for immediate support and anonymity these chatbots offer, concerns regarding their capacity to provide empathetic, accurate, and affirming responses remain. In response to these challenges, we propose a framework for evaluating the affirmativeness of LLMs based on principles of affirmative therapy, emphasizing the need for attitudes, knowledge, and actions that support and validate LGBTQ+ experiences. We propose a combination of qualitative and quantitative analyses, hoping to establish benchmarks for \"Affirmative AI,\" ensuring that LLM-based chatbots can provide safe, supportive, and effective mental health support to LGBTQ+ individuals. We benchmark LLM affirmativeness not as a mental health solution for LGBTQ+ individuals or to claim it resolves their mental health issues, as we highlight the need to consider complex discrimination in the LGBTQ+ community when designing technological aids. Our goal is to evaluate LLMs for LGBTQ+ mental health support since many in the community already use them, aiming to identify potential harms of using general-purpose LLMs in this context.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04678",
        "abstract url": "https://arxiv.org/abs/2405.04678",
        "title": "Pipe Routing with Topology Control for UAV Networks",
        "rating": "-2",
        "keywords": [
            [
                "UAV"
            ]
        ],
        "abstract": "Routing protocols help in transmitting the sensed data from UAVs monitoring the targets (called target UAVs) to the BS. However, the highly dynamic nature of an autonomous, decentralized UAV network leads to frequent route breaks or traffic disruptions. Traditional routing schemes cannot quickly adapt to dynamic UAV networks and/or incur large control overhead and delays. To establish stable, high-quality routes from target UAVs to the BS, we design a hybrid reactive routing scheme called pipe routing that is mobility, congestion, and energy-aware. The pipe routing scheme discovers routes on-demand and proactively switches to alternate high-quality routes within a limited region around the active routes (called the pipe) when needed, reducing the number of route breaks and increasing data throughput. We then design a novel topology control-based pipe routing scheme to maintain robust connectivity in the pipe region around the active routes, leading to improved route stability and increased throughput with minimal impact on the coverage performance of the UAV network.",
        "subjects": [
            "cs.NI",
            "cs.MA",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04707",
        "abstract url": "https://arxiv.org/abs/2405.04707",
        "title": "A wearable anti-gravity supplement to therapy does not improve arm function in chronic stroke: a randomized trial",
        "rating": "-2",
        "keywords": [
            [
                "Clinical"
            ]
        ],
        "abstract": "Background: Gravity confounds arm movement ability in post-stroke hemiparesis. Reducing its influence allows effective practice leading to recovery. Yet, there is a scarcity of wearable devices suitable for personalized use across diverse therapeutic activities in the clinic. Objective: In this study, we investigated the safety, feasibility, and efficacy of anti-gravity therapy using the ExoNET device in post-stroke participants. Methods: Twenty chronic stroke survivors underwent six, 45-minute occupational therapy sessions while wearing the ExoNET, randomized into either the treatment (ExoNET tuned to gravity-support) or control group (ExoNET tuned to slack condition). Clinical outcomes were evaluated by a blinded-rater at baseline, post, and six-week follow-up sessions. Kinetic, kinematic, and patient experience outcomes were also assessed. Results: Mixed-effect models showed a significant improvement in Box and Blocks scores in the post-intervention session for the treatment group (effect size: 2.1, p = .04). No significant effects were found between the treatment and control groups for ARAT scores and other clinical metrics. Direct kinetic effects revealed a significant reduction in muscle activity during free exploration with an effect size of (-7.12%, p< 005). There were no significant longitudinal kinetic or kinematic trends. Subject feedback suggested a generally positive perception of the anti-gravity therapy. Conclusions: Anti-gravity therapy with the ExoNET is a safe and feasible treatment for post-stroke rehabilitation. The device provided anti-gravity forces, did not encumber range of motion, and clinical metrics of anti-gravity therapy demonstrated improvements in gross manual dexterity. Further research is required to explore potential benefits in broader clinical metrics.",
        "subjects": [
            "cs.RO",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04717",
        "abstract url": "https://arxiv.org/abs/2405.04717",
        "title": "Remote Diffusion",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "remote sensing",
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "I explored adapting Stable Diffusion v1.5 for generating domain-specific satellite and aerial images in remote sensing. Recognizing the limitations of existing models like Midjourney and Stable Diffusion, trained primarily on natural RGB images and lacking context for remote sensing, I used the RSICD dataset to train a Stable Diffusion model with a loss of 0.2. I incorporated descriptive captions from the dataset for text-conditioning. Additionally, I created a synthetic dataset for a Land Use Land Classification (LULC) task, employing prompting techniques with RAG and ChatGPT and fine-tuning a specialized remote sensing LLM. However, I faced challenges with prompt quality and model performance. I trained a classification model (ResNet18) on the synthetic dataset achieving 49.48% test accuracy in TorchGeo to create a baseline. Quantitative evaluation through FID scores and qualitative feedback from domain experts assessed the realism and quality of the generated images and dataset. Despite extensive fine-tuning and dataset iterations, results indicated subpar image quality and realism, as indicated by high FID scores and domain-expert evaluation. These findings call attention to the potential of diffusion models in remote sensing while highlighting significant challenges related to insufficient pretraining data and computational resources.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04726",
        "abstract url": "https://arxiv.org/abs/2405.04726",
        "title": "Learning Phonotactics from Linguistic Informants",
        "rating": "-2",
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "grammar"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose an interactive approach to language learning that utilizes linguistic acceptability judgments from an informant (a competent language user) to learn a grammar. Given a grammar formalism and a framework for synthesizing data, our model iteratively selects or synthesizes a data-point according to one of a range of information-theoretic policies, asks the informant for a binary judgment, and updates its own parameters in preparation for the next query. We demonstrate the effectiveness of our model in the domain of phonotactics, the rules governing what kinds of sound-sequences are acceptable in a language, and carry out two experiments, one with typologically-natural linguistic data and another with a range of procedurally-generated languages. We find that the information-theoretic policies that our model uses to select items to query the informant achieve sample efficiency comparable to, and sometimes greater than, fully supervised approaches.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04735",
        "abstract url": "https://arxiv.org/abs/2405.04735",
        "title": "Cryptanalysis of the SIMON Cypher Using Neo4j",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The exponential growth in the number of Internet of Things (IoT) devices has seen the introduction of several Lightweight Encryption Algorithms (LEA). While LEAs are designed to enhance the integrity, privacy and security of data collected and transmitted by IoT devices, it is hazardous to assume that all LEAs are secure and exhibit similar levels of protection. To improve encryption strength, cryptanalysts and algorithm designers routinely probe LEAs using various cryptanalysis techniques to identify vulnerabilities and limitations of LEAs. Despite recent improvements in the efficiency of cryptanalysis utilising heuristic methods and a Partial Difference Distribution Table (PDDT), the process remains inefficient, with the random nature of the heuristic inhibiting reproducible results. However, the use of a PDDT presents opportunities to identify relationships between differentials utilising knowledge graphs, leading to the identification of efficient paths throughout the PDDT. This paper introduces the novel use of knowledge graphs to identify intricate relationships between differentials in the SIMON LEA, allowing for the identification of optimal paths throughout the differentials, and increasing the effectiveness of the differential security analyses of SIMON.",
        "subjects": [
            "cs.CR",
            "cs.DS",
            "cs.IR"
        ],
        "comment": "10 pages, 10 figures, 2 algorithms, accepted by the 4th International Conference on Electrical, Computer and Energy Technologies (ICECET) to be presented in July 2024"
    },
    {
        "paper id": "2405.04783",
        "abstract url": "https://arxiv.org/abs/2405.04783",
        "title": "GoalGrasp: Grasping Goals in Partially Occluded Scenarios without Grasp Training",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "6-DOF"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "We present GoalGrasp, a simple yet effective 6-DOF robot grasp pose detection method that does not rely on grasp pose annotations and grasp training. Our approach enables user-specified object grasping in partially occluded scenes. By combining 3D bounding boxes and simple human grasp priors, our method introduces a novel paradigm for robot grasp pose detection. First, we employ a 3D object detector named RCV, which requires no 3D annotations, to achieve rapid 3D detection in new scenes. Leveraging the 3D bounding box and human grasp priors, our method achieves dense grasp pose detection. The experimental evaluation involves 18 common objects categorized into 7 classes based on shape. Without grasp training, our method generates dense grasp poses for 1000 scenes. We compare our method's grasp poses to existing approaches using a novel stability metric, demonstrating significantly higher grasp pose stability. In user-specified robot grasping experiments, our approach achieves a 94% grasp success rate. Moreover, in user-specified grasping experiments under partial occlusion, the success rate reaches 92%.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2405.04796",
        "abstract url": "https://arxiv.org/abs/2405.04796",
        "title": "Persistent homology of featured time series data and its applications",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "anomaly detection"
            ]
        ],
        "abstract": "Recent studies have actively employed persistent homology (PH), a topological data analysis technique, to analyze the topological information in time series data. Many successful studies have utilized graph representations of time series data for PH calculation. Given the diverse nature of time series data, it is crucial to have mechanisms that can adjust the PH calculations by incorporating domain-specific knowledge. In this context, we introduce a methodology that allows the adjustment of PH calculations by reflecting relevant domain knowledge in specific fields. We introduce the concept of featured time series, which is the pair of a time series augmented with specific features such as domain knowledge, and an influence vector that assigns a value to each feature to fine-tune the results of the PH. We then prove the stability theorem of the proposed method, which states that adjusting the influence vectors grants stability to the PH calculations. The proposed approach enables the tailored analysis of a time series based on the graph representation methodology, which makes it applicable to real-world domains. We consider two examples to verify the proposed method's advantages: anomaly detection of stock data and topological analysis of music data.",
        "subjects": [
            "math.AT",
            "cs.CG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04804",
        "abstract url": "https://arxiv.org/abs/2405.04804",
        "title": "WixUp: A General Data Augmentation Framework for Wireless Perception in Tracking of Humans",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "Recent advancements in wireless perception technologies, including mmWave, WiFi, and acoustics, have expanded their application in human motion tracking and health monitoring. They are promising alternatives to traditional camera-based perception systems, thanks to their efficacy under diverse conditions or occlusions, and enhanced privacy. However, the integration of deep learning within this field introduces new challenges such as the need for extensive training data and poor model generalization, especially with sparse and noisy wireless point clouds. As a remedy, data augmentation is one solution well-explored in other deep learning fields, but they are not directly applicable to the unique characteristics of wireless signals. This motivates us to propose a custom data augmentation framework, WixUp, tailored for wireless perception. Moreover, we aim to make it a general framework supporting various datasets, model architectures, sensing modalities, and tasks; while previous wireless data augmentation or generative simulations do not exhibit this generalizability, only limited to certain use cases. More specifically, WixUp can reverse-transform lossy coordinates into dense range profiles using Gaussian mixture and probability tricks, making it capable of in-depth data diversity enhancement; and its mixing-based method enables unsupervised domain adaptation via self-training, allowing training of the model with no labels from new users or environments in practice. In summary, our extensive evaluation experiments show that WixUp provides consistent performance improvement across various scenarios and outperforms the baselines.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04806",
        "abstract url": "https://arxiv.org/abs/2405.04806",
        "title": "A leadless power transfer and wireless telemetry solutions for an endovascular electrocorticography",
        "rating": "-2",
        "keywords": [
            [
                "medical",
                "clinical"
            ]
        ],
        "abstract": "Endovascular brain-computer interfaces (eBCIs) offer a minimally invasive way to connect the brain to external devices, merging neuroscience, engineering, and medical technology. Achieving wireless data and power transmission is crucial for the clinical viability of these implantable devices. Typically, solutions for endovascular electrocorticography (ECoG) include a sensing stent with multiple electrodes (e.g. in the superior sagittal sinus) in the brain, a subcutaneous chest implant for wireless energy harvesting and data telemetry, and a long (tens of centimetres) cable with a set of wires in between. This long cable presents risks and limitations, especially for younger patients or those with fragile vasculature. This work introduces a wireless and leadless telemetry and power transfer solution for endovascular ECoG. The proposed solution includes an optical telemetry module and a focused ultrasound (FUS) power transfer system. The proposed system can be miniaturised to fit in an endovascular stent. Our solution uses optical telemetry for high-speed data transmission (over 2 Mbit/s, capable of transmitting 41 ECoG channels at a 2 kHz sampling rate and 24-bit resolution) and the proposed power transferring scheme provides up to 10mW power budget into the site of the endovascular implants under the safety limit. Tests on bovine tissues confirmed the system's effectiveness, suggesting that future custom circuit designs could further enhance eBCI applications by removing wires and auxiliary implants, minimising complications.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "17 Pages, 12 figures"
    },
    {
        "paper id": "2405.05117",
        "abstract url": "https://arxiv.org/abs/2405.05117",
        "title": "(In)Security of Mobile Apps in Developing Countries: A Systematic Literature Review",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "In developing countries, several key sectors, including education, finance, agriculture, and healthcare, mainly deliver their services via mobile app technology on handheld devices. As a result, mobile app security has emerged as a paramount issue in developing countries. In this paper, we investigate the state of research on mobile app security, focusing on developing countries. More specifically, we performed a systematic literature review exploring the research directions taken by existing works, the different security concerns addressed, and the techniques used by researchers to highlight or address app security issues. Our main findings are: (1) the literature includes only a few studies on mobile app security in the context of developing countries ; (2) among the different security concerns that researchers study, vulnerability detection appears to be the leading research topic; (3) FinTech apps are revealed as the main target in the relevant literature. Overall, our work highlights that there is largely room for developing further specialized techniques addressing mobile app security in the context of developing countries.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages, 1 figure, submitted to a well-known journal"
    },
    {
        "paper id": "2405.04049",
        "abstract url": "https://arxiv.org/abs/2405.04049",
        "title": "Watermarking Neuromorphic Brains: Intellectual Property Protection in Spiking Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As spiking neural networks (SNNs) gain traction in deploying neuromorphic computing solutions, protecting their intellectual property (IP) has become crucial. Without adequate safeguards, proprietary SNN architectures are at risk of theft, replication, or misuse, which could lead to significant financial losses for the owners. While IP protection techniques have been extensively explored for artificial neural networks (ANNs), their applicability and effectiveness for the unique characteristics of SNNs remain largely unexplored. In this work, we pioneer an investigation into adapting two prominent watermarking approaches, namely, fingerprint-based and backdoor-based mechanisms to secure proprietary SNN architectures. We conduct thorough experiments to evaluate the impact on fidelity, resilience against overwrite threats, and resistance to compression attacks when applying these watermarking techniques to SNNs, drawing comparisons with their ANN counterparts. This study lays the groundwork for developing neuromorphic-aware IP protection strategies tailored to the distinctive dynamics of SNNs.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "7 pages, 7 figures"
    },
    {
        "paper id": "2405.04241",
        "abstract url": "https://arxiv.org/abs/2405.04241",
        "title": "Exploring the Potential of Robot-Collected Data for Training Gesture Classification Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "diagnosing"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Sensors and Artificial Intelligence (AI) have revolutionized the analysis of human movement, but the scarcity of specific samples presents a significant challenge in training intelligent systems, particularly in the context of diagnosing neurodegenerative diseases. This study investigates the feasibility of utilizing robot-collected data to train classification systems traditionally trained with human-collected data. As a proof of concept, we recorded a database of numeric characters using an ABB robotic arm and an Apple Watch. We compare the classification performance of the trained systems using both human-recorded and robot-recorded data. Our primary objective is to determine the potential for accurate identification of human numeric characters wearing a smartwatch using robotic movement as training data. The findings of this study offer valuable insights into the feasibility of using robot-collected data for training classification systems. This research holds broad implications across various domains that require reliable identification, particularly in scenarios where access to human-specific data is limited.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04249",
        "abstract url": "https://arxiv.org/abs/2405.04249",
        "title": "Federated Learning for Cooperative Inference Systems: The Case of Early Exit Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "IoT"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "As Internet of Things (IoT) technology advances, end devices like sensors and smartphones are progressively equipped with AI models tailored to their local memory and computational constraints. Local inference reduces communication costs and latency; however, these smaller models typically underperform compared to more sophisticated models deployed on edge servers or in the cloud. Cooperative Inference Systems (CISs) address this performance trade-off by enabling smaller devices to offload part of their inference tasks to more capable devices. These systems often deploy hierarchical models that share numerous parameters, exemplified by Deep Neural Networks (DNNs) that utilize strategies like early exits or ordered dropout. In such instances, Federated Learning (FL) may be employed to jointly train the models within a CIS. Yet, traditional training methods have overlooked the operational dynamics of CISs during inference, particularly the potential high heterogeneity in serving rates across clients. To address this gap, we propose a novel FL approach designed explicitly for use in CISs that accounts for these variations in serving rates. Our framework not only offers rigorous theoretical guarantees, but also surpasses state-of-the-art (SOTA) training algorithms for CISs, especially in scenarios where inference request rates or data availability are uneven among clients.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04321",
        "abstract url": "https://arxiv.org/abs/2405.04321",
        "title": "Molecular Identification via Molecular Fingerprint extraction from Atomic Force Microscopy images",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Non--Contact Atomic Force Microscopy with CO--functionalized metal tips (referred to as HR-AFM) provides access to the internal structure of individual molecules adsorbed on a surface with totally unprecedented resolution. Previous works have shown that deep learning (DL) models can retrieve the chemical and structural information encoded in a 3D stack of constant-height HR--AFM images, leading to molecular identification. In this work, we overcome their limitations by using a well-established description of the molecular structure in terms of topological fingerprints, the 1024--bit Extended Connectivity Chemical Fingerprints of radius 2 (ECFP4), that were developed for substructure and similarity searching. ECFPs provide local structural information of the molecule, each bit correlating with a particular substructure within the molecule. Our DL model is able to extract this optimized structural descriptor from the 3D HR--AFM stacks and use it, through virtual screening, to identify molecules from their predicted ECFP4 with a retrieval accuracy on theoretical images of 95.4\\%. Furthermore, this approach, unlike previous DL models, assigns a confidence score, the Tanimoto similarity, to each of the candidate molecules, thus providing information on the reliability of the identification. By construction, the number of times a certain substructure is present in the molecule is lost during the hashing process, necessary to make them useful for machine learning applications. We show that it is possible to complement the fingerprint-based virtual screening with global information provided by another DL model that predicts from the same HR--AFM stacks the chemical formula, boosting the identification accuracy up to a 97.6\\%. Finally, we perform a limited test with experimental images, obtaining promising results towards the application of this pipeline under real conditions",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04356",
        "abstract url": "https://arxiv.org/abs/2405.04356",
        "title": "Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "GAN"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We present a new multi-modal face image generation method that converts a text prompt and a visual input, such as a semantic mask or scribble map, into a photo-realistic face image. To do this, we combine the strengths of Generative Adversarial networks (GANs) and diffusion models (DMs) by employing the multi-modal features in the DM into the latent space of the pre-trained GANs. We present a simple mapping and a style modulation network to link two models and convert meaningful representations in feature maps and attention maps into latent codes. With GAN inversion, the estimated latent codes can be used to generate 2D or 3D-aware facial images. We further present a multi-step training strategy that reflects textual and structural representations into the generated image. Our proposed network produces realistic 2D, multi-view, and stylized face images, which align well with inputs. We validate our method by using pre-trained 2D and 3D GANs, and our results outperform existing methods. Our project page is available at https://github.com/1211sh/Diffusion-driven_GAN-Inversion/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2405.04390",
        "abstract url": "https://arxiv.org/abs/2405.04390",
        "title": "DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "forecasting"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Vision-centric autonomous driving has recently raised wide attention due to its lower cost. Pre-training is essential for extracting a universal representation. However, current vision-centric pre-training typically relies on either 2D or 3D pre-text tasks, overlooking the temporal characteristics of autonomous driving as a 4D scene understanding task. In this paper, we address this challenge by introducing a world model-based autonomous driving 4D representation learning framework, dubbed \\emph{DriveWorld}, which is capable of pre-training from multi-camera driving videos in a spatio-temporal fashion. Specifically, we propose a Memory State-Space Model for spatio-temporal modelling, which consists of a Dynamic Memory Bank module for learning temporal-aware latent dynamics to predict future changes and a Static Scene Propagation module for learning spatial-aware latent statics to offer comprehensive scene contexts. We additionally introduce a Task Prompt to decouple task-aware features for various downstream tasks. The experiments demonstrate that DriveWorld delivers promising results on various autonomous driving tasks. When pre-trained with the OpenScene dataset, DriveWorld achieves a 7.5% increase in mAP for 3D object detection, a 3.0% increase in IoU for online mapping, a 5.0% increase in AMOTA for multi-object tracking, a 0.1m decrease in minADE for motion forecasting, a 3.0% increase in IoU for occupancy prediction, and a 0.34m reduction in average L2 error for planning.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR2024"
    },
    {
        "paper id": "2405.04592",
        "abstract url": "https://arxiv.org/abs/2405.04592",
        "title": "Integrating knowledge-guided symbolic regression and model-based design of experiments to automate process flow diagram development",
        "rating": "-2.5",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "New products must be formulated rapidly to succeed in the global formulated product market; however, key product indicators (KPIs) can be complex, poorly understood functions of the chemical composition and processing history. Consequently, scale-up must currently undergo expensive trial-and-error campaigns. To accelerate process flow diagram (PFD) optimisation and knowledge discovery, this work proposed a novel digital framework to automatically quantify process mechanisms by integrating symbolic regression (SR) within model-based design of experiments (MBDoE). Each iteration, SR proposed a Pareto front of interpretable mechanistic expressions, and then MBDoE designed a new experiment to discriminate between them while balancing PFD optimisation. To investigate the framework's performance, a new process model capable of simulating general formulated product synthesis was constructed to generate in-silico data for different case studies. The framework could effectively discover ground-truth process mechanisms within a few iterations, indicating its great potential for use within the general chemical industry for digital manufacturing and product innovation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04746",
        "abstract url": "https://arxiv.org/abs/2405.04746",
        "title": "SVD-AE: Simple Autoencoders for Collaborative Filtering",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Collaborative filtering (CF) methods for recommendation systems have been extensively researched, ranging from matrix factorization and autoencoder-based to graph filtering-based methods. Recently, lightweight methods that require almost no training have been recently proposed to reduce overall computation. However, existing methods still have room to improve the trade-offs among accuracy, efficiency, and robustness. In particular, there are no well-designed closed-form studies for \\emph{balanced} CF in terms of the aforementioned trade-offs. In this paper, we design SVD-AE, a simple yet effective singular vector decomposition (SVD)-based linear autoencoder, whose closed-form solution can be defined based on SVD for CF. SVD-AE does not require iterative training processes as its closed-form solution can be calculated at once. Furthermore, given the noisy nature of the rating matrix, we explore the robustness against such noisy interactions of existing CF methods and our SVD-AE. As a result, we demonstrate that our simple design choice based on truncated SVD can be used to strengthen the noise robustness of the recommendation while improving efficiency. Code is available at https://github.com/seoyoungh/svd-ae.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted by IJCAI 2024"
    },
    {
        "paper id": "2405.05286",
        "abstract url": "https://arxiv.org/abs/2405.05286",
        "title": "Tiny Deep Ensemble: Uncertainty Estimation in Edge AI Accelerators via Ensembling Normalization Layers with Shared Weights",
        "rating": "-2.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "medical",
                "diagnosis"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The applications of artificial intelligence (AI) are rapidly evolving, and they are also commonly used in safety-critical domains, such as autonomous driving and medical diagnosis, where functional safety is paramount. In AI-driven systems, uncertainty estimation allows the user to avoid overconfidence predictions and achieve functional safety. Therefore, the robustness and reliability of model predictions can be improved. However, conventional uncertainty estimation methods, such as the deep ensemble method, impose high computation and, accordingly, hardware (latency and energy) overhead because they require the storage and processing of multiple models. Alternatively, Monte Carlo dropout (MC-dropout) methods, although having low memory overhead, necessitate numerous ($\\sim 100$) forward passes, leading to high computational overhead and latency. Thus, these approaches are not suitable for battery-powered edge devices with limited computing and memory resources. In this paper, we propose the Tiny-Deep Ensemble approach, a low-cost approach for uncertainty estimation on edge devices. In our approach, only normalization layers are ensembled $M$ times, with all ensemble members sharing common weights and biases, leading to a significant decrease in storage requirements and latency. Moreover, our approach requires only one forward pass in a hardware architecture that allows batch processing for inference and uncertainty estimation. Furthermore, it has approximately the same memory overhead compared to a single model. Therefore, latency and memory overhead are reduced by a factor of up to $\\sim M\\times$. Nevertheless, our method does not compromise accuracy, with an increase in inference accuracy of up to $\\sim 1\\%$ and a reduction in RMSE of $17.17\\%$ in various benchmark datasets, tasks, and state-of-the-art architectures.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.05288",
        "abstract url": "https://arxiv.org/abs/2405.05288",
        "title": "Learning Social Graph for Inactive User Recommendation",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Social relations have been widely incorporated into recommender systems to alleviate data sparsity problem. However, raw social relations don't always benefit recommendation due to their inferior quality and insufficient quantity, especially for inactive users, whose interacted items are limited. In this paper, we propose a novel social recommendation method called LSIR (\\textbf{L}earning \\textbf{S}ocial Graph for \\textbf{I}nactive User \\textbf{R}ecommendation) that learns an optimal social graph structure for social recommendation, especially for inactive users. LSIR recursively aggregates user and item embeddings to collaboratively encode item and user features. Then, graph structure learning (GSL) is employed to refine the raw user-user social graph, by removing noisy edges and adding new edges based on the enhanced embeddings. Meanwhile, mimic learning is implemented to guide active users in mimicking inactive users during model training, which improves the construction of new edges for inactive users. Extensive experiments on real-world datasets demonstrate that LSIR achieves significant improvements of up to 129.58\\% on NDCG in inactive user recommendation. Our code is available at~\\url{https://github.com/liun-online/LSIR}.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "comment": "This paper has been received by DASFAA 2024"
    },
    {
        "paper id": "2405.04021",
        "abstract url": "https://arxiv.org/abs/2405.04021",
        "title": "Robust and Reusable Fuzzy Extractors for Low-entropy Rate Randomness Sources",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "biometric"
            ]
        ],
        "abstract": "Fuzzy extractors (FE) are cryptographic primitives that extract reliable cryptographic key from noisy real world random sources such as biometric sources. The FE generation algorithm takes a source sample, extracts a key and generates some helper data that will be used by the reproduction algorithm to recover the key. Reusability of FE guarantees that security holds when FE is used multiple times with the same source, and robustness of FE requires tampering with the helper data be detectable. In this paper, we consider information theoretic FEs, define a strong notion of reusability, and propose strongly robust and reusable FEs (srrFE) that provides the strongest combined notion of reusability and robustness for FEs. We give two constructions, one for reusable FEs and one for srrFE with information theoretic (IT) security for structured sources. The constructions are for structured sources and use sample-then-lock approach. We discuss each construction and show their unique properties in relation to existing work. Construction 2 is the first robust and reusable FE with IT-security without assuming random oracle. The robustness is achieved by using an IT-secure MAC with security against key-shift attack, which can be of independent interest.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04028",
        "abstract url": "https://arxiv.org/abs/2405.04028",
        "title": "Masked Graph Transformer for Large-Scale Recommendation",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Graph Transformers have garnered significant attention for learning graph-structured data, thanks to their superb ability to capture long-range dependencies among nodes. However, the quadratic space and time complexity hinders the scalability of Graph Transformers, particularly for large-scale recommendation. Here we propose an efficient Masked Graph Transformer, named MGFormer, capable of capturing all-pair interactions among nodes with a linear complexity. To achieve this, we treat all user/item nodes as independent tokens, enhance them with positional embeddings, and feed them into a kernelized attention module. Additionally, we incorporate learnable relative degree information to appropriately reweigh the attentions. Experimental results show the superior performance of our MGFormer, even with a single attention layer.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04030",
        "abstract url": "https://arxiv.org/abs/2405.04030",
        "title": "Uncovering implementable dormant pruning decisions from three different stakeholder perspectives",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "agricultural"
            ]
        ],
        "abstract": "Dormant pruning, or the removal of unproductive portions of a tree while a tree is not actively growing, is an important orchard task to help maintain yield, requiring years to build expertise. Because of long training periods and an increasing labor shortage in agricultural jobs, pruning could benefit from robotic automation. However, to program robots to prune branches, we first need to understand how pruning decisions are made, and what variables in the environment (e.g., branch size and thickness) we need to capture. Working directly with three pruning stakeholders -- horticulturists, growers, and pruners -- we find that each group of human experts approaches pruning decision-making differently. To capture this knowledge, we present three studies and two extracted pruning protocols from field work conducted in Prosser, Washington in January 2022 and 2023. We interviewed six stakeholders (two in each group) and observed pruning across three cultivars -- Bing Cherries, Envy Apples, and Jazz Apples -- and two tree architectures -- Upright Fruiting Offshoot and V-Trellis. Leveraging participant interviews and video data, this analysis uses grounded coding to extract pruning terminology, discover horticultural contexts that influence pruning decisions, and find implementable pruning heuristics for autonomous systems. The results include a validated terminology set, which we offer for use by both pruning stakeholders and roboticists, to communicate general pruning concepts and heuristics. The results also highlight seven pruning heuristics utilizing this terminology set that would be relevant for use by future autonomous robot pruning systems, and characterize three discovered horticultural contexts (i.e., environmental management, crop-load management, and replacement wood) across all three cultivars.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "36 pages; 21 figures"
    },
    {
        "paper id": "2405.04046",
        "abstract url": "https://arxiv.org/abs/2405.04046",
        "title": "MBCT: A Monero-Based Covert Transmission Approach with On-chain Dynamic Session Key Negotiation",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "CT"
            ]
        ],
        "abstract": "Traditional covert transmission (CT) approaches have been hindering CT application while blockchain technology offers new avenue. Current blockchain-based CT approaches require off-chain negotiation of critical information and often overlook the dynamic session keys updating, which increases the risk of message and key leakage. Additionally, in some approaches the covert transactions exhibit obvious characteristics that can be easily detected by third-parties. Moreover, most approaches do not address the issue of decreased reliability of message transmission in blockchain attack scenarios. Bitcoin- and Ethereum-based approaches also have the issue of transaction linkability, which can be tackled by Monero-based approaches because of the privacy protection mechanisms in Monero. However, Monero-based CT has the problem of sender repudiation. In this paper, we propose a novel Monero-Based CT approach (MBCT), which enables on-chain session key dynamically updating without off-chain negotiation. MBCT can assure non-repudiation of transmission participants, confidentiality of keys, reliability of message transmission and less observable characteristics. There are achieved by the three components in MBCT, namely, a sender authentication method, a dynamically on-chain session key updating method and a state feedback method. We implement MBCT in Monero-0.18.1.0 and the experiment results demonstrate its high embedding capacity of MBCT.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04370",
        "abstract url": "https://arxiv.org/abs/2405.04370",
        "title": "Diff-IP2D: Diffusion-Based Hand-Object Interaction Prediction on Egocentric Videos",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robot"
            ],
            [
                "forecast"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding how humans would behave during hand-object interaction is vital for applications in service robot manipulation and extended reality. To achieve this, some recent works have been proposed to simultaneously predict hand trajectories and object affordances on human egocentric videos. They are regarded as the representation of future hand-object interactions, indicating potential human motion and motivation. However, the existing approaches mostly adopt the autoregressive paradigm for unidirectional prediction, which lacks mutual constraints within the holistic future sequence, and accumulates errors along the time axis. Meanwhile, these works basically overlook the effect of camera egomotion on first-person view predictions. To address these limitations, we propose a novel diffusion-based interaction prediction method, namely Diff-IP2D, to forecast future hand trajectories and object affordances concurrently in an iterative non-autoregressive manner. We transform the sequential 2D images into latent feature space and design a denoising diffusion model to predict future latent interaction features conditioned on past ones. Motion features are further integrated into the conditional denoising process to enable Diff-IP2D aware of the camera wearer's dynamics for more accurate interaction prediction. The experimental results show that our method significantly outperforms the state-of-the-art baselines on both the off-the-shelf metrics and our proposed new evaluation protocol. This highlights the efficacy of leveraging a generative paradigm for 2D hand-object interaction prediction. The code of Diff-IP2D will be released at https://github.com/IRMVLab/Diff-IP2D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04387",
        "abstract url": "https://arxiv.org/abs/2405.04387",
        "title": "Parallelized Multi-Agent Bayesian Optimization in Lava",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "In parallel with the continuously increasing parameter space dimensionality, search and optimization algorithms should support distributed parameter evaluations to reduce cumulative runtime. Intel's neuromorphic optimization library, Lava-Optimization, was introduced as an abstract optimization system compatible with neuromorphic systems developed in the broader Lava software framework. In this work, we introduce Lava Multi-Agent Optimization (LMAO) with native support for distributed parameter evaluations communicating with a central Bayesian optimization system. LMAO provides an abstract framework for deploying distributed optimization and search algorithms within the Lava software framework. Moreover, LMAO introduces support for random and grid search along with process connections across multiple levels of mathematical precision. We evaluate the algorithmic performance of LMAO with a traditional non-convex optimization problem, a fixed-precision transductive spiking graph neural network for citation graph classification, and a neuromorphic satellite scheduling problem. Our results highlight LMAO's efficient scaling to multiple processes, reducing cumulative runtime and minimizing the likelihood of converging to local optima.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "4 pages, 2 figures, 2 algorithms, 2 tables"
    },
    {
        "paper id": "2405.04404",
        "abstract url": "https://arxiv.org/abs/2405.04404",
        "title": "Vision Mamba: A Comprehensive Survey and Taxonomy",
        "rating": "-3",
        "keywords": [
            [
                "medical"
            ],
            [
                "remote sensing"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "State Space Model (SSM) is a mathematical model used to describe and analyze the behavior of dynamic systems. This model has witnessed numerous applications in several fields, including control theory, signal processing, economics and machine learning. In the field of deep learning, state space models are used to process sequence data, such as time series analysis, natural language processing (NLP) and video understanding. By mapping sequence data to state space, long-term dependencies in the data can be better captured. In particular, modern SSMs have shown strong representational capabilities in NLP, especially in long sequence modeling, while maintaining linear time complexity. Notably, based on the latest state-space models, Mamba merges time-varying parameters into SSMs and formulates a hardware-aware algorithm for efficient training and inference. Given its impressive efficiency and strong long-range dependency modeling capability, Mamba is expected to become a new AI architecture that may outperform Transformer. Recently, a number of works have attempted to study the potential of Mamba in various fields, such as general vision, multi-modal, medical image analysis and remote sensing image analysis, by extending Mamba from natural language domain to visual domain. To fully understand Mamba in the visual domain, we conduct a comprehensive survey and present a taxonomy study. This survey focuses on Mamba's application to a variety of visual tasks and data types, and discusses its predecessors, recent advances and far-reaching impact on a wide range of domains. Since Mamba is now on an upward trend, please actively notice us if you have new findings, and new progress on Mamba will be included in this survey in a timely manner and updated on the Mamba project at https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy"
    },
    {
        "paper id": "2405.04503",
        "abstract url": "https://arxiv.org/abs/2405.04503",
        "title": "Physics-data hybrid dynamic model of a multi-axis manipulator for sensorless dexterous manipulation and high-performance motion planning",
        "rating": "-3",
        "keywords": [
            [
                "time-efficient"
            ],
            [
                "industrial"
            ],
            [
                "Physics"
            ]
        ],
        "abstract": "We report on the development of an implementable physics-data hybrid dynamic model for an articulated manipulator to plan and operate in various scenarios. Meanwhile, the physics-based and data-driven dynamic models are studied in this research to select the best model for planning. The physics-based model is constructed using the Lagrangian method, and the loss terms include inertia loss, viscous loss, and friction loss. As for the data-driven model, three methods are explored, including DNN, LSTM, and XGBoost. Our modeling results demonstrate that, after comprehensive hyperparameter optimization, the XGBoost architecture outperforms DNN and LSTM in accurately representing manipulator dynamics. The hybrid model with physics-based and data-driven terms has the best performance among all models based on the RMSE criteria, and it only needs about 24k of training data. In addition, we developed a virtual force sensor of a manipulator using the observed external torque derived from the dynamic model and designed a motion planner through the physics-data hybrid dynamic model. The external torque contributes to forces and torque on the end effector, facilitating interaction with the surroundings, while the internal torque governs manipulator motion dynamics and compensates for internal losses. By estimating external torque via the difference between measured joint torque and internal losses, we implement a sensorless control strategy which is demonstrated through a peg-in-hole task. Lastly, a learning-based motion planner based on the hybrid dynamic model assists in planning time-efficient trajectories for the manipulator. This comprehensive approach underscores the efficacy of integrating physics-based and data-driven models for advanced manipulator control and planning in industrial environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "26 pages, 16 figures"
    },
    {
        "paper id": "2405.04507",
        "abstract url": "https://arxiv.org/abs/2405.04507",
        "title": "New allometric models for the USA create a step-change in forest carbon estimation, modeling, and mapping",
        "rating": "-3",
        "keywords": [
            [
                "biomass"
            ],
            [
                "satellite"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The United States national forest inventory (NFI) serves as the foundation for forest aboveground biomass (AGB) and carbon accounting across the nation. These data enable design-based estimates of forest carbon stocks and stock-changes at state and regional levels, but also serve as inputs to model-based approaches for characterizing forest carbon stocks and stock-changes at finer resolutions. Although NFI tree and plot-level data are often treated as truth in these models, they are in fact estimates based on regional species-group models known collectively as the Component Ratio Method (CRM). In late 2023 the Forest Inventory and Analysis (FIA) program introduced a new National Scale Volume and Biomass Estimators (NSVB) system to replace CRM nationwide and offer more precise and accurate representations of forest AGB and carbon. Given the prevalence of model-based AGB studies relying on FIA, there is concern about the transferability of methods from CRM to NSVB models, as well as the comparability of existing CRM AGB products (e.g. maps) to new and forthcoming NSVB AGB products. To begin addressing these concerns we compared previously published CRM AGB maps to new maps produced using identical methods with NSVB AGB reference data. Our results suggest that models relying on passive satellite imagery (e.g. Landsat) provide acceptable estimates of point-in-time NSVB AGB and carbon stocks, but fail to accurately quantify growth in mature closed-canopy forests. We highlight that existing estimates, models, and maps based on FIA reference data are no longer compatible with NSVB, and recommend new methods as well as updated models and maps for accommodating this step-change. Our collective ability to adopt NSVB in our modeling and mapping workflows will help us provide the most accurate spatial forest carbon data possible in order to better inform local management and decision making.",
        "subjects": [
            "stat.AP",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Manuscript: 16 pages, 7 figures; Supplements: 3 pages, 2 figures; Submitted to: Remote Sensing of Environment"
    },
    {
        "paper id": "2405.04591",
        "abstract url": "https://arxiv.org/abs/2405.04591",
        "title": "Visually Guided Swarm Motion Coordination via Insect-inspired Small Target Motion Reactions",
        "rating": "-3",
        "keywords": [
            [
                "flight"
            ],
            [
                "bio-inspired"
            ]
        ],
        "abstract": "Despite progress developing experimentally-consistent models of insect in-flight sensing and feedback for individual agents, a lack of systematic understanding of the multi-agent and group performance of the resulting bio-inspired sensing and feedback approaches remains a barrier to robotic swarm implementations. This study introduces the small-target motion reactive (STMR) swarming approach by designing a concise engineering model of the small target motion detector (STMD) neurons found in insect lobula complexes. The STMD neuron model identifies the bearing angle at which peak optic flow magnitude occurs, and this angle is used to design an output feedback switched control system. A theoretical stability analysis provides bi-agent stability and state boundedness in group contexts. The approach is simulated and implemented on ground vehicles for validation and behavioral studies. The results indicate despite having the lowest connectivity of contemporary approaches (each agent instantaneously regards only a single neighbor), collective group motion can be achieved. STMR group level metric analysis also highlights continuously varying polarization and decreasing heading variance.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "12 pages journal, submitted for peer review"
    },
    {
        "paper id": "2405.04662",
        "abstract url": "https://arxiv.org/abs/2405.04662",
        "title": "Radar Fields: Frequency-Space Neural Scene Representations for FMCW Radar",
        "rating": "-3",
        "keywords": [
            [
                "synthesize"
            ],
            [
                "LiDAR",
                "Radar"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural fields have been broadly investigated as scene representations for the reproduction and novel generation of diverse outdoor scenes, including those autonomous vehicles and robots must handle. While successful approaches for RGB and LiDAR data exist, neural reconstruction methods for radar as a sensing modality have been largely unexplored. Operating at millimeter wavelengths, radar sensors are robust to scattering in fog and rain, and, as such, offer a complementary modality to active and passive optical sensing techniques. Moreover, existing radar sensors are highly cost-effective and deployed broadly in robots and vehicles that operate outdoors. We introduce Radar Fields - a neural scene reconstruction method designed for active radar imagers. Our approach unites an explicit, physics-informed sensor model with an implicit neural geometry and reflectance model to directly synthesize raw radar measurements and extract scene occupancy. The proposed method does not rely on volume rendering. Instead, we learn fields in Fourier frequency space, supervised with raw radar data. We validate the effectiveness of the method across diverse outdoor scenarios, including urban scenes with dense vehicles and infrastructure, and in harsh weather scenarios, where mm-wavelength sensing is especially favorable.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 6 figures, to be published in SIGGRAPH 2024"
    },
    {
        "paper id": "2405.04015",
        "abstract url": "https://arxiv.org/abs/2405.04015",
        "title": "Certified Policy Verification and Synthesis for MDPs under Distributional Reach-avoidance Properties",
        "rating": "-3.5",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "robot"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Markov Decision Processes (MDPs) are a classical model for decision making in the presence of uncertainty. Often they are viewed as state transformers with planning objectives defined with respect to paths over MDP states. An increasingly popular alternative is to view them as distribution transformers, giving rise to a sequence of probability distributions over MDP states. For instance, reachability and safety properties in modeling robot swarms or chemical reaction networks are naturally defined in terms of probability distributions over states. Verifying such distributional properties is known to be hard and often beyond the reach of classical state-based verification techniques. In this work, we consider the problems of certified policy (i.e. controller) verification and synthesis in MDPs under distributional reach-avoidance specifications. By certified we mean that, along with a policy, we also aim to synthesize a (checkable) certificate ensuring that the MDP indeed satisfies the property. Thus, given the target set of distributions and an unsafe set of distributions over MDP states, our goal is to either synthesize a certificate for a given policy or synthesize a policy along with a certificate, proving that the target distribution can be reached while avoiding unsafe distributions. To solve this problem, we introduce the novel notion of distributional reach-avoid certificates and present automated procedures for (1) synthesizing a certificate for a given policy, and (2) synthesizing a policy together with the certificate, both providing formal guarantees on certificate correctness. Our experimental evaluation demonstrates the ability of our method to solve several non-trivial examples, including a multi-agent robot-swarm model, to synthesize certified policies and to certify existing policies.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": "Extended version of a paper accepted at IJCAI 2024"
    },
    {
        "paper id": "2405.04151",
        "abstract url": "https://arxiv.org/abs/2405.04151",
        "title": "Gas Source Localization Using physics Guided Neural Networks",
        "rating": "-3.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work discusses a novel method for estimating the location of a gas source based on spatially distributed concentration measurements taken, e.g., by a mobile robot or flying platform that follows a predefined trajectory to collect samples. The proposed approach uses a Physics-Guided Neural Network to approximate the gas dispersion with the source location as an additional network input. After an initial offline training phase, the neural network can be used to efficiently solve the inverse problem of localizing the gas source based on measurements. The proposed approach allows avoiding rather costly numerical simulations of gas physics needed for solving inverse problems. Our experiments show that the method localizes the source well, even when dealing with measurements affected by noise.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submission to the International Symposium of Electronic Nose (ISOEN)"
    },
    {
        "paper id": "2405.04718",
        "abstract url": "https://arxiv.org/abs/2405.04718",
        "title": "Metaverse Survey & Tutorial: Exploring Key Requirements, Technologies, Standards, Applications, Challenges, and Perspectives",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we present a comprehensive survey of the metaverse, envisioned as a transformative dimension of next-generation Internet technologies. This study not only outlines the structural components of our survey but also makes a substantial scientific contribution by elucidating the foundational concepts underlying the emergence of the metaverse. We analyze its architecture by defining key characteristics and requirements, thereby illuminating the nascent reality set to revolutionize digital interactions. Our analysis emphasizes the importance of collaborative efforts in developing metaverse standards, thereby fostering a unified understanding among industry stakeholders, organizations, and regulatory bodies. We extend our scrutiny to critical technologies integral to the metaverse, including interactive experiences, communication technologies, ubiquitous computing, digital twins, artificial intelligence, and cybersecurity measures. For each technological domain, we rigorously assess current contributions, principal techniques, and representative use cases, providing a nuanced perspective on their potential impacts. Furthermore, we delve into the metaverse's diverse applications across education, healthcare, business, social interactions, industrial sectors, defense, and mission-critical operations, highlighting its extensive utility. Each application is thoroughly analyzed, demonstrating its value and addressing associated challenges. The survey concludes with an overview of persistent challenges and future directions, offering insights into essential considerations and strategies necessary to harness the full potential of the metaverse. Through this detailed investigation, our goal is to articulate the scientific contributions of this survey paper, transcending a mere structural overview to highlight the transformative implications of the metaverse.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04275",
        "abstract url": "https://arxiv.org/abs/2405.04275",
        "title": "Grey-box Recursive Parameter Identification of a Nonlinear Dynamic Model for Mineral Flotation",
        "rating": "-4",
        "keywords": [
            [
                "Mineral"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "This study presents a grey-box recursive identification technique to estimate key parameters in a mineral flotation process across two scenarios. The method is applied to a nonlinear physics-based dynamic model validated at a laboratory scale, allowing real-time updates of two model parameters, n and C, in response to changing conditions. The proposed approach effectively adapts to process variability and allows for continuous adjustments based on operational fluctuations, resulting in a significantly improved estimation of concentrate grade - one key performance indicator. In Scenario 1, parameters n and C achieved fit metrics of 97.99 and 96.86, respectively, with concentrate grade estimations improving from 75.1 to 98.69 using recursive identification. In Scenario 2, the fit metrics for n and C were 96.27 and 95.48, respectively, with the concentrate grade estimations increasing from 96.27 to 99.45 with recursive identification. The results demonstrate the effectiveness of the proposed grey-box recursive identification method in accurately estimating parameters and predicting concentrate grade in a mineral flotation process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04345",
        "abstract url": "https://arxiv.org/abs/2405.04345",
        "title": "Novel View Synthesis with Neural Radiance Fields for Industrial Robot Applications",
        "rating": "-4",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "Synthesis"
            ],
            [
                "Robot"
            ],
            [
                "Industrial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRFs) have become a rapidly growing research field with the potential to revolutionize typical photogrammetric workflows, such as those used for 3D scene reconstruction. As input, NeRFs require multi-view images with corresponding camera poses as well as the interior orientation. In the typical NeRF workflow, the camera poses and the interior orientation are estimated in advance with Structure from Motion (SfM). But the quality of the resulting novel views, which depends on different parameters such as the number and distribution of available images, as well as the accuracy of the related camera poses and interior orientation, is difficult to predict. In addition, SfM is a time-consuming pre-processing step, and its quality strongly depends on the image content. Furthermore, the undefined scaling factor of SfM hinders subsequent steps in which metric information is required. In this paper, we evaluate the potential of NeRFs for industrial robot applications. We propose an alternative to SfM pre-processing: we capture the input images with a calibrated camera that is attached to the end effector of an industrial robot and determine accurate camera poses with metric scale based on the robot kinematics. We then investigate the quality of the novel views by comparing them to ground truth, and by computing an internal quality measure based on ensemble methods. For evaluation purposes, we acquire multiple datasets that pose challenges for reconstruction typical of industrial applications, like reflective objects, poor texture, and fine structures. We show that the robot-based pose determination reaches similar accuracy as SfM in non-demanding cases, while having clear advantages in more challenging scenarios. Finally, we present first results of applying the ensemble method to estimate the quality of the synthetic novel view in the absence of a ground truth.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "8 pages, 8 figures, accepted for publication in The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences (ISPRS Archives) 2024"
    },
    {
        "paper id": "2405.04803",
        "abstract url": "https://arxiv.org/abs/2405.04803",
        "title": "Blockchains for Internet of Things: Fundamentals, Applications, and Challenges",
        "rating": "-4",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Internet of Things (IoT) services necessitate the storage, transmission, and analysis of diverse data for inference, autonomy, and control. Blockchains, with their inherent properties of decentralization and security, offer efficient database solutions for these devices through consensus-based data sharing. However, it's essential to recognize that not every blockchain system is suitable for specific IoT applications, and some might be more beneficial when excluded with privacy concerns. For example, public blockchains are not suitable for storing sensitive data. This paper presents a detailed review of three distinct blockchains tailored for enhancing IoT applications. We initially delve into the foundational aspects of three blockchain systems, highlighting their strengths, limitations, and implementation needs. Additionally, we discuss the security issues in different blockchains. Subsequently, we explore the blockchain's application in three pivotal IoT areas: edge AI, communications, and healthcare. We underscore potential challenges and the future directions for integrating different blockchains in IoT. Ultimately, this paper aims to offer a comprehensive perspective on the synergies between blockchains and the IoT ecosystem, highlighting the opportunities and complexities involved.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04336",
        "abstract url": "https://arxiv.org/abs/2405.04336",
        "title": "Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction",
        "rating": "-4.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "health"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Predicting Remaining Useful Life (RUL) plays a crucial role in the prognostics and health management of industrial systems that involve a variety of interrelated sensors. Given a constant stream of time series sensory data from such systems, deep learning models have risen to prominence at identifying complex, nonlinear temporal dependencies in these data. In addition to the temporal dependencies of individual sensors, spatial dependencies emerge as important correlations among these sensors, which can be naturally modelled by a temporal graph that describes time-varying spatial relationships. However, the majority of existing studies have relied on capturing discrete snapshots of this temporal graph, a coarse-grained approach that leads to loss of temporal information. Moreover, given the variety of heterogeneous sensors, it becomes vital that such inherent heterogeneity is leveraged for RUL prediction in temporal sensor graphs. To capture the nuances of the temporal and spatial relationships and heterogeneous characteristics in an interconnected graph of sensors, we introduce a novel model named Temporal and Heterogeneous Graph Neural Networks (THGNN). Specifically, THGNN aggregates historical data from neighboring nodes to accurately capture the temporal dynamics and spatial correlations within the stream of sensor data in a fine-grained manner. Moreover, the model leverages Feature-wise Linear Modulation (FiLM) to address the diversity of sensor types, significantly improving the model's capacity to learn the heterogeneity in the data sources. Finally, we have validated the effectiveness of our approach through comprehensive experiments. Our empirical findings demonstrate significant advancements on the N-CMAPSS dataset, achieving improvements of up to 19.2% and 31.6% in terms of two different evaluation metrics over state-of-the-art methods.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2405.04290",
        "abstract url": "https://arxiv.org/abs/2405.04290",
        "title": "Bayesian Simultaneous Localization and Multi-Lane Tracking Using Onboard Sensors and a SD Map",
        "rating": "-5",
        "keywords": [
            [
                "3D",
                "6D"
            ],
            [
                "autonomous driving",
                "trajectory",
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "High-definition map with accurate lane-level information is crucial for autonomous driving, but the creation of these maps is a resource-intensive process. To this end, we present a cost-effective solution to create lane-level roadmaps using only the global navigation satellite system (GNSS) and a camera on customer vehicles. Our proposed solution utilizes a prior standard-definition (SD) map, GNSS measurements, visual odometry, and lane marking edge detection points, to simultaneously estimate the vehicle's 6D pose, its position within a SD map, and also the 3D geometry of traffic lines. This is achieved using a Bayesian simultaneous localization and multi-object tracking filter, where the estimation of traffic lines is formulated as a multiple extended object tracking problem, solved using a trajectory Poisson multi-Bernoulli mixture (TPMBM) filter. In TPMBM filtering, traffic lines are modeled using B-spline trajectories, and each trajectory is parameterized by a sequence of control points. The proposed solution has been evaluated using experimental data collected by a test vehicle driving on highway. Preliminary results show that the traffic line estimates, overlaid on the satellite image, generally align with the lane markings up to some lateral offsets.",
        "subjects": [
            "cs.RO",
            "eess.SP"
        ],
        "comment": "27th International Conference on Information Fusion"
    },
    {
        "paper id": "2405.04305",
        "abstract url": "https://arxiv.org/abs/2405.04305",
        "title": "A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields",
        "rating": "-5",
        "keywords": [
            [
                "health"
            ],
            [
                "chemical"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Aphid infestations are one of the primary causes of extensive damage to wheat and sorghum fields and are one of the most common vectors for plant viruses, resulting in significant agricultural yield losses. To address this problem, farmers often employ the inefficient use of harmful chemical pesticides that have negative health and environmental impacts. As a result, a large amount of pesticide is wasted on areas without significant pest infestation. This brings to attention the urgent need for an intelligent autonomous system that can locate and spray sufficiently large infestations selectively within the complex crop canopies. We have developed a large multi-scale dataset for aphid cluster detection and segmentation, collected from actual sorghum fields and meticulously annotated to include clusters of aphids. Our dataset comprises a total of 54,742 image patches, showcasing a variety of viewpoints, diverse lighting conditions, and multiple scales, highlighting its effectiveness for real-world applications. In this study, we trained and evaluated four real-time semantic segmentation models and three object detection models specifically for aphid cluster segmentation and detection. Considering the balance between accuracy and efficiency, Fast-SCNN delivered the most effective segmentation results, achieving 80.46% mean precision, 81.21% mean recall, and 91.66 frames per second (FPS). For object detection, RT-DETR exhibited the best overall performance with a 61.63% mean average precision (mAP), 92.6% mean recall, and 72.55 on an NVIDIA V100 GPU. Our experiments further indicate that aphid cluster segmentation is more suitable for assessing aphid infestations than using detection models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04020",
        "abstract url": "https://arxiv.org/abs/2405.04020",
        "title": "Metric Distortion of Line-up Elections: The Right Person for the Right Job",
        "rating": "-10",
        "keywords": [],
        "abstract": "We provide mechanisms and new metric distortion bounds for line-up elections. In such elections, a set of $n$ voters, $k$ candidates, and $\\ell$ positions are all located in a metric space. The goal is to choose a set of candidates and assign them to different positions, so as to minimize the total cost of the voters. The cost of each voter consists of the distances from itself to the chosen candidates (measuring how much the voter likes the chosen candidates, or how similar it is to them), as well as the distances from the candidates to the positions they are assigned to (measuring the fitness of the candidates for their positions). Our mechanisms, however, do not know the exact distances, and instead produce good outcomes while only using a smaller amount of information, resulting in small distortion. We consider several different types of information: ordinal voter preferences, ordinal position preferences, and knowing the exact locations of candidates and positions, but not those of voters. In each of these cases, we provide constant distortion bounds, thus showing that only a small amount of information is enough to form outcomes close to optimum in line-up elections.",
        "subjects": [
            "cs.GT",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04022",
        "abstract url": "https://arxiv.org/abs/2405.04022",
        "title": "On $n$-Dimensional Sequences. I",
        "rating": "-10",
        "keywords": [],
        "abstract": "Let $R$ be a commutative ring and let $n \\geq 1.$ We study $\u0393(s)$, the generating function and Ann$(s)$, the ideal of characteristic polynomials of $s$, an $n$--dimensional sequence over $R$. We express $f(X_1,\\ldots,X_n) \\cdot \u0393(s)(X_1^{-1},\\ldots ,X_n^{-1})$ as a partitioned sum. That is, we give (i) a $2^n$--fold ``border'' partition (ii) an explicit expression for the product as a $2^n$--fold sum; the support of each summand is contained in precisely one member of the partition. A key summand is $\u03b2_0(f,s)$, the ``border polynomial'' of $f$ and $s$, which is divisible by $X_1\\cdots X_n$. We say that $s$ is {\\em eventually rectilinear} if the elimination ideals Ann$(s)\\cap R[X_i]$ contain an $f_i(X_i)$ for $1 \\leq i \\leq n$. In this case, we show that $\\mbox{Ann}(s)$ is the ideal quotient $(\\sum_{i=1}^n(f_i)\\ :\\ \u03b2_0(f,s)/(X_1\\cdots X_n)).$ When $R$ and $R[[X_1,X_2, \\ldots ,X_n]]$ are factorial domains (e.g. $R$ a principal ideal domain or ${\\Bbb F}[X_1,\\ldots,X_n]$), we compute {\\em the monic generator} $\u03b3_i$ of $\\mbox{Ann}(s) \\cap R[X_i]$ from known $f_i \\in \\mbox{Ann}(s) \\cap R[X_i]$ or from a finite number of $1$--dimensional linear recurring sequences over $R$. Over a field ${\\Bbb F}$ this gives an $O(\\prod_{i=1}^n \u03b4\u03b3_i^3)$ algorithm to compute an ${\\Bbb F}$--basis for $\\mbox{Ann}(s)$.",
        "subjects": [
            "math.AC",
            "cs.SC"
        ],
        "comment": "This is my original latex document submitted to Journal of Symbolic Computation without the typographical errors which were introduced: 'The Journal apologizes for the typographical errors in Norton (1995) introduced in the subediting process'; see this journal, (1995)20, 769-770"
    },
    {
        "paper id": "2405.04027",
        "abstract url": "https://arxiv.org/abs/2405.04027",
        "title": "Joint Visibility Region Detection and Channel Estimation for XL-MIMO Systems via Alternating MAP",
        "rating": "-10",
        "keywords": [],
        "abstract": "We investigate a joint visibility region (VR) detection and channel estimation problem in extremely large-scale multiple-input-multiple-output (XL-MIMO) systems, where near-field propagation and spatial non-stationary effects exist. In this case, each scatterer can only see a subset of antennas, i.e., it has a certain VR over the antennas. Because of the spatial correlation among adjacent sub-arrays, VR of scatterers exhibits a two-dimensional (2D) clustered sparsity. We design a 2D Markov prior model to capture such a structured sparsity. Based on this, a novel alternating maximum a posteriori (MAP) framework is developed for high-accuracy VR detection and channel estimation. The alternating MAP framework consists of three basic modules: a channel estimation module, a VR detection module, and a grid update module. Specifically, the first module is a low-complexity inverse-free variational Bayesian inference (IF-VBI) algorithm that avoids the matrix inverse via minimizing a relaxed Kullback-Leibler (KL) divergence. The second module is a structured expectation propagation (EP) algorithm which has the ability to deal with complicated prior information. And the third module refines polar-domain grid parameters via gradient ascent. Simulations demonstrate the superiority of the proposed algorithm in both VR detection and channel estimation.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 14 figures, submitted to IEEE TSP"
    },
    {
        "paper id": "2405.04036",
        "abstract url": "https://arxiv.org/abs/2405.04036",
        "title": "uTNT: Unikernels for Efficient and Flexible Internet Probing",
        "rating": "-10",
        "keywords": [],
        "abstract": "The last twenty years have seen the development and popularity of network measurement infrastructures. Internet measurement platforms have become common and have demonstrated their relevance in Internet understanding and security observation. However, despite their popularity, those platforms lack of flexibility and reactivity, as they are usually used for longitudinal measurements. As a consequence, they may miss detecting events that are security or Internet-related. During the same period, operating systems have evolved to virtual machines (VMs) as self-contained units for running applications, with the recent rise of unikernels, ultra-lightweight VMs tailored for specific applications, eliminating the need for a host OS. In this paper, we advocate that measurement infrastructures could take advantage of unikernels to become more flexible and efficient. We propose uTNT, a proof-of-concept unikernel-based implementation of TNT, a traceroute extension able to reveal MPLS tunnels. This paper documents the full toolchain for porting TNT into a unikernel and evaluates uTNT performance with respect to more traditional approaches. The paper also discusses a use case in which uTNT could find a suitable usage. uTNT source code is publicly available on Gitlab.",
        "subjects": [
            "cs.OS",
            "cs.NI"
        ],
        "comment": "10 pages, 11 figures, IFIP extended-abstract"
    },
    {
        "paper id": "2405.04038",
        "abstract url": "https://arxiv.org/abs/2405.04038",
        "title": "Self-Replicating and Self-Employed Smart Contract on Ethereum Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "Blockchain is the underlying technology for cryptocurrencies such as Bitcoin. Blockchain is a robust distributed ledger that uses consensus algorithms to approve transactions in a decentralized manner, making malicious tampering extremely difficult. Ethereum, one of the blockchains, can be seen as an unstoppable computer which shared by users around the world that can run Turing-complete programs. In order to run any program on Ethereum, Ether (currency on Ethereum) is required. In other words, Ether can be seen as a kind of energy in the Ethereum world. We developed self-replicating and self-employed agents who earn the energy by themselves to replicate them, on the Ethereum blockchain. The agents can issued their token and gain Ether each time the tokens are sold. When a certain amount of Ether is accumulated, the agent replicates itself and leaves offspring. The goal of this project is to implement artificial agents that lives for itself, not as a tool for humans, in the open cyber space connected to the real world.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "This paper was originally written in 2022 for submission to ALIFE 2022"
    },
    {
        "paper id": "2405.04051",
        "abstract url": "https://arxiv.org/abs/2405.04051",
        "title": "On the quantization goodness of polar lattices",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we prove that polar lattices, when tailored for lossy compression, are quantization-good in the sense that their normalized second moments approach $\\frac{1}{2\u03c0e}$ as the dimension of lattices increases. It has been predicted by Zamir et al. \\cite{ZamirQZ96} that the Entropy Coded Dithered Quantization (ECDQ) system using quantization-good lattices can achieve the rate-distortion bound of i.i.d. Gaussian sources. In our previous work \\cite{LingQZ}, we established that polar lattices are indeed capable of attaining the same objective. It is reasonable to conjecture that polar lattices also demonstrate quantization goodness in the context of lossy compression. This study confirms this hypothesis.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "12 pages, 5 figures, submitted to IEEE for possible publication"
    },
    {
        "paper id": "2405.04054",
        "abstract url": "https://arxiv.org/abs/2405.04054",
        "title": "What Impacts the Quality of the User Answers when Asked about the Current Context?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Sensor data provide an objective view of reality but fail to capture the subjective motivations behind an individual's behavior. This latter information is crucial for learning about the various dimensions of the personal context, thus increasing predictability. The main limitation is the human input, which is often not of the quality that is needed. The work so far has focused on the usually high number of missing answers. The focus of this paper is on \\textit{the number of mistakes} made when answering questions. Three are the main contributions of this paper. First, we show that the user's reaction time, i.e., the time before starting to respond, is the main cause of a low answer quality, where its effects are both direct and indirect, the latter relating to its impact on the completion time, i.e., the time taken to compile the response. Second, we identify the specific exogenous (e.g., the situational or temporal context) and endogenous (e.g., mood, personality traits) factors which have an influence on the reaction time, as well as on the completion time. Third, we show how reaction and completion time compose their effects on the answer quality. The paper concludes with a set of actionable recommendations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "25 pages, 16 figures, under review by Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies"
    },
    {
        "paper id": "2405.04063",
        "abstract url": "https://arxiv.org/abs/2405.04063",
        "title": "xNose: A Test Smell Detector for C#",
        "rating": "-10",
        "keywords": [],
        "abstract": "Test smells, similar to code smells, can negatively impact both the test code and the production code being tested. Despite extensive research on test smells in languages like Java, Scala, and Python, automated tools for detecting test smells in C# are lacking. This paper aims to bridge this gap by extending the study of test smells to C#, and developing a tool (xNose) to identify test smells in this language and analyze their distribution across projects. We identified 16 test smells from prior studies that were language-independent and had equivalent features in C# and evaluated xNose, achieving a precision score of 96.97% and a recall score of 96.03%. In addition, we conducted an empirical study to determine the prevalence of test smells in xUnit-based C# projects. This analysis sheds light on the frequency and distribution of test smells, deepening our understanding of their impact on C# projects and test suites. The development of xNose and our analysis of test smells in C# code aim to assist developers in maintaining code quality by addressing potential issues early in the development process.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Full report of our ICSE'24 poster"
    },
    {
        "paper id": "2405.04068",
        "abstract url": "https://arxiv.org/abs/2405.04068",
        "title": "An Improved Reversible Data Hiding Algorithm Based on Reconstructed Mapping for PVO-k",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reversible Data Hiding (RDH) is a practical and efficient technique for information encryption. Among its methods, the Pixel-Value Ordering (PVO) algorithm and its variants primarily modify prediction errors to embed information. However, both the classic PVO and its improved versions, such as IPVO and PVO-k, share a common limitation: their maximum data embedding capacity for a given grayscale image is relatively low. This poses a challenge when large amounts of data need to be embedded into an image. In response to these issues, this paper proposes an improved design targeting the PVO-k algorithm. We have reconstructed the mapping scheme of the PVO-k algorithm to maximize the number of pixels that can embed encrypted information. Experimental validations show that our proposed scheme significantly surpasses previous algorithms in terms of the maximum data embedding capacity. For instance, when embedding information into a grayscale image of an airplane, our method's capacity exceeds that of PVO-k by 11,207 bits, PVO by 8,004 bits, and IPVO by 4,562 bits. The results demonstrate that our algorithm holds substantial advantages over existing methods and introduces innovative mapping ideas, laying a foundation for future research in reversible data hiding in images.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04102",
        "abstract url": "https://arxiv.org/abs/2405.04102",
        "title": "Analysis of Markovian Arrivals and Service with Applications to Intermittent Overload",
        "rating": "-10",
        "keywords": [],
        "abstract": "Almost all queueing analysis assumes i.i.d. arrivals and service. In reality, arrival and service rates fluctuate over time. In particular, it is common for real systems to intermittently experience overload, where the arrival rate temporarily exceeds the service rate, which an i.i.d. model cannot capture. We consider the MAMS system, where the arrival and service rates each vary according to an arbitrary finite-state Markov chain, allowing intermittent overload to be modeled. We derive the first explicit characterization of mean queue length in the MAMS system, with explicit bounds for all arrival and service chains at all loads. Our bounds are tight in heavy traffic. We prove even stronger bounds for the important special case of two-level arrivals with intermittent overload. Our key contribution is an extension to the drift method, based on the novel concepts of relative arrivals and relative completions. These quantities allow us to tractably capture the transient correlational effect of the arrival and service processes on the mean queue length.",
        "subjects": [
            "cs.PF",
            "math.PR"
        ],
        "comment": "27 pages"
    },
    {
        "paper id": "2405.04120",
        "abstract url": "https://arxiv.org/abs/2405.04120",
        "title": "Movable Antennas-Enabled Two-User Multicasting: Do We Really Need Alternating Optimization for Minimum Rate Maximization?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Movable antenna (MA) technology, which can reconfigure wireless channels by flexibly moving antenna positions in a specified region, has great potential for improving communication performance. In this paper, we consider a new setup of MAs-enabled multicasting, where we adopt a simple setting in which a linear MA array-enabled source (${\\rm{S}}$) transmits a common message to two single-antenna users ${\\rm{U}}_1$ and ${\\rm{U}}_2$. We aim to maximize the minimum rate among these two users, by jointly optimizing the transmit beamforming and antenna positions at ${\\rm{S}}$. Instead of utilizing the widely-used alternating optimization (AO) approach, we reveal, with rigorous proof, that the above two variables can be optimized separately: i) the optimal antenna positions can be firstly determined via the successive convex approximation technique, based on the rule of maximizing the correlation between ${\\rm{S}}$-${\\rm{U}}_1$ and ${\\rm{S}}$-${\\rm{U}}_2$ channels; ii) afterwards, the optimal closed-form transmit beamforming can be derived via simple arguments. Compared to AO, this new approach yields the same performance but reduces the computational complexities significantly. Moreover, it can provide insightful conclusions which are not possible with AO.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04125",
        "abstract url": "https://arxiv.org/abs/2405.04125",
        "title": "Optimizing Prosumer Policies in Periodic Double Auctions Inspired by Equilibrium Analysis (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a periodic double auction (PDA) wherein the main participants are wholesale suppliers and brokers representing retailers. The suppliers are represented by a composite supply curve and the brokers are represented by individual bids. Additionally, the brokers can participate in small-scale selling by placing individual asks; hence, they act as prosumers. Specifically, in a PDA, the prosumers who are net buyers have multiple opportunities to buy or sell multiple units of a commodity with the aim of minimizing the cost of buying across multiple rounds of the PDA. Formulating optimal bidding strategies for such a PDA setting involves planning across current and future rounds while considering the bidding strategies of other agents. In this work, we propose Markov perfect Nash equilibrium (MPNE) policies for a setup where multiple prosumers with knowledge of the composite supply curve compete to procure commodities. Thereafter, the MPNE policies are used to develop an algorithm called MPNE-BBS for the case wherein the prosumers need to re-construct an approximate composite supply curve using past auction information. The efficacy of the proposed algorithm is demonstrated on the PowerTAC wholesale market simulator against several baselines and state-of-the-art bidding policies.",
        "subjects": [
            "eess.SY",
            "cs.GT"
        ],
        "comment": "A small typo removed - A sentence in Section 5 first paragraph is removed, since it was refer to the same extended version of the paper"
    },
    {
        "paper id": "2405.04144",
        "abstract url": "https://arxiv.org/abs/2405.04144",
        "title": "Lossy Compression with Data, Perception, and Classification Constraints",
        "rating": "-10",
        "keywords": [],
        "abstract": "Balancing diverse task objectives under limited rate is crucial for developing robust multi-task deep learning (DL) models and improving performance across various domains. In this paper, we consider the lossy compression problem with human-centric and task-oriented metrics, such as perceptual quality and classification accuracy. We investigate two ternary relationships, namely, the rate-distortion-classification (RDC) and rate-perception-classification (RPC). For both RDC and RPC functions, we derive the closed-form expressions of the optimal rate for both binary and Gaussian sources. Notably, both RDC and RPC relationships exhibit distinct characteristics compared to the previous RDP tradeoff proposed by Blau et al. Then, we conduct experiments by implementing a DL-based image compression framework, incorporating rate, distortion, perception, and classification constraints. The experimental results verify the theoretical characteristics of RDC and RPC tradeoffs, providing information-theoretical insights into the design of loss functions to balance diverse task objectives in deep learning.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "10 pages, in part submitted to ITW 2024"
    },
    {
        "paper id": "2405.04152",
        "abstract url": "https://arxiv.org/abs/2405.04152",
        "title": "CAKE: Sharing Slices of Confidential Data on Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cooperative information systems typically involve various entities in a collaborative process within a distributed environment. Blockchain technology offers a mechanism for automating such processes, even when only partial trust exists among participants. The data stored on the blockchain is replicated across all nodes in the network, ensuring accessibility to all participants. While this aspect facilitates traceability, integrity, and persistence, it poses challenges for adopting public blockchains in enterprise settings due to confidentiality issues. In this paper, we present a software tool named Control Access via Key Encryption (CAKE), designed to ensure data confidentiality in scenarios involving public blockchains. After outlining its core components and functionalities, we showcase the application of CAKE in the context of a real-world cyber-security project within the logistics domain.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04157",
        "abstract url": "https://arxiv.org/abs/2405.04157",
        "title": "Two-dimensional Kripke Semantics I: Presheaves",
        "rating": "-10",
        "keywords": [],
        "abstract": "The study of modal logic has witnessed tremendous development following the introduction of Kripke semantics. However, recent developments in programming languages and type theory have led to a second way of studying modalities, namely through their categorical semantics. We show how the two correspond.",
        "subjects": [
            "cs.LO",
            "math.CT",
            "math.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04172",
        "abstract url": "https://arxiv.org/abs/2405.04172",
        "title": "An efficient active-set method with applications to sparse approximations and risk minimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we present an efficient active-set method for the solution of convex quadratic programming problems with general piecewise-linear terms in the objective, with applications to sparse approximations and risk-minimization. The algorithm is derived by combining a proximal method of multipliers (PMM) with a standard semismooth Newton method (SSN), and is shown to be globally convergent under minimal assumptions. Further local linear (and potentially superlinear) convergence is shown under standard additional conditions. The major computational bottleneck of the proposed approach arises from the solution of the associated SSN linear systems. These are solved using a Krylov-subspace method, accelerated by certain novel general-purpose preconditioners which are shown to be optimal with respect to the proximal penalty parameters. The preconditioners are easy to store and invert, since they exploit the structure of the nonsmooth terms appearing in the problem's objective to significantly reduce their memory requirements. We showcase the efficiency, robustness, and scalability of the proposed solver on a variety of problems arising in risk-averse portfolio selection, $L^1$-regularized partial differential equation constrained optimization, quantile regression, and binary classification via linear support vector machines. We provide computational evidence, on real-world datasets, to demonstrate the ability of the solver to efficiently and competitively handle a diverse set of medium- and large-scale optimization instances.",
        "subjects": [
            "math.OC",
            "cs.MS"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2302.14497, arXiv:2201.10211"
    },
    {
        "paper id": "2405.04177",
        "abstract url": "https://arxiv.org/abs/2405.04177",
        "title": "A 49.8mm2 Fully Integrated, 1.5m Transmission-Range, High-Data-Rate IR-UWB Transmitter for Brain Implants",
        "rating": "-10",
        "keywords": [],
        "abstract": "To address the challenge of extending the transmission range of implantable TXs while also minimizing their size and power consumption, this paper introduces a transcutaneous, high data-rate, fully integrated IR-UWB transmitter that employs a novel co-designed power amplifier (PA) and antenna interface for enhanced performance. With the co-designed interface, we achieved the smallest footprint of 49.8mm2 and the longest transmission range of 1.5m compared to the state-of-the-art IR-UWB TXs.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04198",
        "abstract url": "https://arxiv.org/abs/2405.04198",
        "title": "Enhancing Physical Layer Communication Security through Generative AI with Mixture of Experts",
        "rating": "-10",
        "keywords": [],
        "abstract": "AI technologies have become more widely adopted in wireless communications. As an emerging type of AI technologies, the generative artificial intelligence (GAI) gains lots of attention in communication security. Due to its powerful learning ability, GAI models have demonstrated superiority over conventional AI methods. However, GAI still has several limitations, including high computational complexity and limited adaptability. Mixture of Experts (MoE), which uses multiple expert models for prediction through a gate mechanism, proposes possible solutions. Firstly, we review GAI model's applications in physical layer communication security, discuss limitations, and explore how MoE can help GAI overcome these limitations. Furthermore, we propose an MoE-enabled GAI framework for network optimization problems for communication security. To demonstrate the framework's effectiveness, we provide a case study in a cooperative friendly jamming scenario. The experimental results show that the MoE-enabled framework effectively assists the GAI algorithm, solves its limitations, and enhances communication security.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "9 pages, 4 figures"
    },
    {
        "paper id": "2405.04236",
        "abstract url": "https://arxiv.org/abs/2405.04236",
        "title": "Semantic API Alignment: Linking High-level User Goals to APIs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Models (LLMs) are becoming key in automating and assisting various software development tasks, including text-based tasks in requirements engineering but also in coding. Typically, these models are used to automate small portions of existing tasks, but we present a broader vision to span multiple steps from requirements engineering to implementation using existing libraries. This approach, which we call Semantic API Alignment (SEAL), aims to bridge the gap between a user's high-level goals and the specific functions of one or more APIs. In this position paper, we propose a system architecture where a set of LLM-powered ``agents'' match such high-level objectives with appropriate API calls. This system could facilitate automated programming by finding matching links or, alternatively, explaining mismatches to guide manual intervention or further development. As an initial pilot, our paper demonstrates this concept by applying LLMs to Goal-Oriented Requirements Engineering (GORE), via sub-goal analysis, for aligning with REST API specifications, specifically through a case study involving a GitHub statistics API. We discuss the potential of our approach to enhance complex tasks in software development and requirements engineering and outline future directions for research.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04237",
        "abstract url": "https://arxiv.org/abs/2405.04237",
        "title": "QR factorization of ill-conditioned tall-and-skinny matrices on distributed-memory systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we present a novel algorithm developed for computing the QR factorisation of extremely ill-conditioned tall-and-skinny matrices on distributed memory systems. The algorithm is based on the communication-avoiding CholeskyQR2 algorithm and its block Gram-Schmidt variant. The latter improves the numerical stability of the CholeskyQR2 algorithm and significantly reduces the loss of orthogonality even for matrices with condition numbers up to $10^{15}$. Currently, there is no distributed GPU version of this algorithm available in the literature which prevents the application of this method to very large matrices. In our work we provide a distributed implementation of this algorithm and also introduce a modified version that improves the performance, especially in the case of extremely ill-conditioned matrices. The main innovation of our approach lies in the interleaving of the CholeskyQR steps with the Gram-Schmidt orthogonalisation, which ensures that update steps are performed with fully orthogonalised panels. The obtained orthogonality and numerical stability of our modified algorithm is equivalent to CholeskyQR2 with Gram-Schmidt and other state-of-the-art methods. Weak scaling tests performed with our test matrices show significant performance improvements. In particular, our algorithm outperforms state-of-the-art Householder-based QR factorisation algorithms available in ScaLAPACK by a factor of $6$ on CPU-only systems and up to $80\\times$ on GPU-based systems with distributed memory.",
        "subjects": [
            "cs.DC",
            "cs.DS",
            "cs.PF"
        ],
        "comment": "12 pages, 10 figures, 2 tables"
    },
    {
        "paper id": "2405.04250",
        "abstract url": "https://arxiv.org/abs/2405.04250",
        "title": "Weighted Least-Squares PARSIM",
        "rating": "-10",
        "keywords": [],
        "abstract": "Subspace identification methods (SIMs) have proven very powerful for estimating linear state-space models. To overcome the deficiencies of classical SIMs, a significant number of algorithms has appeared over the last two decades, where most of them involve a common intermediate step, that is to estimate the range space of the extended observability matrix. In this contribution, an optimized version of the parallel and parsimonious SIM (PARSIM), PARSIM\\textsubscript{opt}, is proposed by using weighted least-squares. It not only inherits all the benefits of PARSIM but also attains the best linear unbiased estimator for the above intermediate step. Furthermore, inspired by SIMs based on the predictor form, consistent estimates of the optimal weighting matrix for weighted least-squares are derived. Essential similarities, differences and simulated comparisons of some key SIMs related to our method are also presented.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04253",
        "abstract url": "https://arxiv.org/abs/2405.04253",
        "title": "Fermat Number Transform Based Chromatic Dispersion Compensation and Adaptive Equalization Algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "By introducing the Fermat number transform into chromatic dispersion compensation and adaptive equalization, the computational complexity has been reduced by 68% compared with the con?ventional implementation. Experimental results validate its transmission performance with only 0.8 dB receiver sensitivity penalty in a 75 km-40 GBaud-PDM-16QAM system.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04258",
        "abstract url": "https://arxiv.org/abs/2405.04258",
        "title": "A Weighted Least-Squares Method for Non-Asymptotic Identification of Markov Parameters from Multiple Trajectories",
        "rating": "-10",
        "keywords": [],
        "abstract": "Markov parameters play a key role in system identification. There exists many algorithms where these parameters are estimated using least-squares in a first, pre-processing, step, including subspace identification and multi-step least-squares algorithms, such as Weighted Null-Space Fitting. Recently, there has been an increasing interest in non-asymptotic analysis of estimation algorithms. In this contribution we identify the Markov parameters using weighted least-squares and present non-asymptotic analysis for such estimator. To cover both stable and unstable systems, multiple trajectories are collected. We show that with the optimal weighting matrix, weighted least-squares gives a tighter error bound than ordinary least-squares for the case of non-uniformly distributed measurement errors. Moreover, as the optimal weighting matrix depends on the system's true parameters, we introduce two methods to consistently estimate the optimal weighting matrix, where the convergence rate of these estimates is also provided. Numerical experiments demonstrate improvements of weighted least-squares over ordinary least-squares in finite sample settings.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04279",
        "abstract url": "https://arxiv.org/abs/2405.04279",
        "title": "Task Presentation and Human Perception in Interactive Video Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "Interactive video retrieval is a cooperative process between humans and retrieval systems. Large-scale evaluation campaigns, however, often overlook human factors, such as the effects of perception, attention, and memory, when assessing media retrieval systems. Consequently, their setups fall short of emulating realistic retrieval scenarios. In this paper, we design novel task presentation modes based on concepts in media memorability, implement the pipelines necessary for processing target video segments, and build a custom experimental platform for the final evaluation. In order to study the effects of different task representation schemes, we conduct a large crowdsourced experiment. Our findings demonstrate that the way in which the target of a video retrieval task is presented has a substantial influence on the difficulty of the retrieval task and that individuals can successfully retrieve a target video segment despite reducing or even altering the provided hints, opening up a discussion around future evaluation protocols in the domain of interactive media retrieval.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04280",
        "abstract url": "https://arxiv.org/abs/2405.04280",
        "title": "Modal Folding: Discovering Smooth Folding Patterns for Sheet Materials using Strain-Space Modes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Folding can transform mundane objects such as napkins into stunning works of art. However, finding new folding transformations for sheet materials is a challenging problem that requires expertise and real-world experimentation. In this paper, we present Modal Folding -- an automated approach for discovering energetically optimal folding transformations, i.e., large deformations that require little mechanical work. For small deformations, minimizing internal energy for fixed displacement magnitudes leads to the well-known elastic eigenmodes. While linear modes provide promising directions for bending, they cannot capture the rotational motion required for folding. To overcome this limitation, we introduce strain-space modes -- nonlinear analogues of elastic eigenmodes that operate on per-element curvatures instead of vertices. Using strain-space modes to determine target curvatures for bending elements, we can generate complex nonlinear folding motions by simply minimizing the sheet's internal energy. Our modal folding approach offers a systematic and automated way to create complex designs. We demonstrate the effectiveness of our method with simulation results for a range of shapes and materials, and validate our designs with physical prototypes.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "9 pages, SIGGRAPH 2024 Conference"
    },
    {
        "paper id": "2405.04287",
        "abstract url": "https://arxiv.org/abs/2405.04287",
        "title": "Asymmetry of Frequency Distribution in Power Systems: Sources, Impact and Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "This letter analyses the sources of asymmetry of frequency probability distributions (PDs) and their impact on the dynamic behaviour of power systems. The letter also discusses on how secondary control can reduce this asymmetry. We also propose an asymmetry index based on the difference between the left and right-hand side standard deviations of the frequency PDs. The IEEE 9-bus system and real-world data obtained from the Irish transmission system serve to show that losses, saturation's and wind generation lead to asymmetric PDs. A relevant result is that the droop-based frequency support provided by wind generation using a tight deadband of 15 mHz leads to significantly increase the asymmetry of the frequency PDs.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04297",
        "abstract url": "https://arxiv.org/abs/2405.04297",
        "title": "Certifying Phase Abstraction",
        "rating": "-10",
        "keywords": [],
        "abstract": "Certification helps to increase trust in formal verification of safety-critical systems which require assurance on their correctness. In hardware model checking, a widely used formal verification technique, phase abstraction is considered one of the most commonly used preprocessing techniques. We present an approach to certify an extended form of phase abstraction using a generic certificate format. As in earlier works our approach involves constructing a witness circuit with an inductive invariant property that certifies the correctness of the entire model checking process, which is then validated by an independent certificate checker. We have implemented and evaluated the proposed approach including certification for various preprocessing configurations on hardware model checking competition benchmarks. As an improvement on previous work in this area, the proposed method is able to efficiently complete certification with an overhead of a fraction of model checking time.",
        "subjects": [
            "cs.SC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04308",
        "abstract url": "https://arxiv.org/abs/2405.04308",
        "title": "Quality with Just Enough Diversity in Evolutionary Policy Search",
        "rating": "-10",
        "keywords": [],
        "abstract": "Evolution Strategies (ES) are effective gradient-free optimization methods that can be competitive with gradient-based approaches for policy search. ES only rely on the total episodic scores of solutions in their population, from which they estimate fitness gradients for their update with no access to true gradient information. However this makes them sensitive to deceptive fitness landscapes, and they tend to only explore one way to solve a problem. Quality-Diversity methods such as MAP-Elites introduced additional information with behavior descriptors (BD) to return a population of diverse solutions, which helps exploration but leads to a large part of the evaluation budget not being focused on finding the best performing solution. Here we show that behavior information can also be leveraged to find the best policy by identifying promising search areas which can then be efficiently explored with ES. We introduce the framework of Quality with Just Enough Diversity (JEDi) which learns the relationship between behavior and fitness to focus evaluations on solutions that matter. When trying to reach higher fitness values, JEDi outperforms both QD and ES methods on hard exploration tasks like mazes and on complex control problems with large policies.",
        "subjects": [
            "cs.NE",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04319",
        "abstract url": "https://arxiv.org/abs/2405.04319",
        "title": "GLIDS: A Global Latency Information Dissemination System",
        "rating": "-10",
        "keywords": [],
        "abstract": "A recent advance in networking is the deployment of path-aware multipath network architectures, where network endpoints are given multiple network paths to send their data on. In this work, we tackle the challenge of selecting paths for latency-sensitive applications. Even today's path-aware networks, which are much smaller than the current Internet, already offer dozens and in several cases over a hundred paths to a given destination, making it impractical to measure all path latencies to find the lowest latency path. Furthermore, for short flows, performing latency measurements may not provide benefits as the flow may finish before completing the measurements. To overcome these issues, we argue that endpoints should be provided with a latency estimate before sending any packets, enabling latency-aware path choice for the first packet sent. As we cannot predict the end-to-end latency due to dynamically changing queuing delays, we measure and disseminate the propagation latency, enabling novel use cases and solving concrete problems in current network protocols. We present the Global Latency Information Dissemination System (GLIDS), which is a step toward global latency transparency through the dissemination of propagation latency information.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Extended version of the 7-page conference paper \"Toward Global Latency Transparency\" published at the IFIP Networking 2024 Conference"
    },
    {
        "paper id": "2405.04322",
        "abstract url": "https://arxiv.org/abs/2405.04322",
        "title": "Genetic Drift Regularization: on preventing Actor Injection from breaking Evolution Strategies",
        "rating": "-10",
        "keywords": [],
        "abstract": "Evolutionary Algorithms (EA) have been successfully used for the optimization of neural networks for policy search, but they still remain sample inefficient and underperforming in some cases compared to gradient-based reinforcement learning (RL). Various methods combine the two approaches, many of them training a RL algorithm on data from EA evaluations and injecting the RL actor into the EA population. However, when using Evolution Strategies (ES) as the EA, the RL actor can drift genetically far from the the ES distribution and injection can cause a collapse of the ES performance. Here, we highlight the phenomenon of genetic drift where the actor genome and the ES population distribution progressively drift apart, leading to injection having a negative impact on the ES. We introduce Genetic Drift Regularization (GDR), a simple regularization method in the actor training loss that prevents the actor genome from drifting away from the ES. We show that GDR can improve ES convergence on problems where RL learns well, but also helps RL training on other tasks, , fixes the injection issues better than previous controlled injection methods.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04326",
        "abstract url": "https://arxiv.org/abs/2405.04326",
        "title": "A Calibratable Model for Fast Energy Estimation of MVM Operations on RRAM Crossbars",
        "rating": "-10",
        "keywords": [],
        "abstract": "The surge in AI usage demands innovative power reduction strategies. Novel Compute-in-Memory (CIM) architectures, leveraging advanced memory technologies, hold the potential for significantly lowering energy consumption by integrating storage with parallel Matrix-Vector-Multiplications (MVMs). This study addresses the 1T1R RRAM crossbar, a core component in numerous CIM architectures. We introduce an abstract model and a calibration methodology for estimating operational energy. Our tool condenses circuit-level behaviour into a few parameters, facilitating energy assessments for DNN workloads. Validation against low-level SPICE simulations demonstrates speedups of up to 1000x and energy estimations with errors below 1%.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Presented at AICAS 2024, Abu Dhabi, UAE. 5 pages, 6 figures"
    },
    {
        "paper id": "2405.04332",
        "abstract url": "https://arxiv.org/abs/2405.04332",
        "title": "WALLETRADAR: Towards Automating the Detection of Vulnerabilities in Browser-based Cryptocurrency Wallets",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cryptocurrency wallets, acting as fundamental infrastructure to the blockchain ecosystem, have seen significant user growth, particularly among browser-based wallets (i.e., browser extensions). However, this expansion accompanies security challenges, making these wallets prime targets for malicious activities. Despite a substantial user base, there is not only a significant gap in comprehensive security analysis but also a pressing need for specialized tools that can aid developers in reducing vulnerabilities during the development process. To fill the void, we present a comprehensive security analysis of browser-based wallets in this paper, along with the development of an automated tool designed for this purpose. We first compile a taxonomy of security vulnerabilities resident in cryptocurrency wallets by harvesting historical security reports. Based on this, we design WALLETRADAR, an automated detection framework that can accurately identify security issues based on static and dynamic analysis. Evaluation of 96 popular browser-based wallets shows WALLETRADAR's effectiveness, by successfully automating the detection process in 90% of these wallets with high precision. This evaluation has led to the discovery of 116 security vulnerabilities corresponding to 70 wallets. By the time of this paper, we have received confirmations of 10 vulnerabilities from 8 wallet developers, with over $2,000 bug bounties. Further, we observed that 12 wallet developers have silently fixed 16 vulnerabilities after our disclosure. WALLETRADAR can effectively automate the identification of security risks in cryptocurrency wallets, thereby enhancing software development quality and safety in the blockchain ecosystem.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Just accepted by the Automated Software Engineering Journal"
    },
    {
        "paper id": "2405.04380",
        "abstract url": "https://arxiv.org/abs/2405.04380",
        "title": "Preserving Nonlinear Constraints in Variational Flow Filtering Data Assimilation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data assimilation aims to estimate the states of a dynamical system by optimally combining sparse and noisy observations of the physical system with uncertain forecasts produced by a computational model. The states of many dynamical systems of interest obey nonlinear physical constraints, and the corresponding dynamics is confined to a certain sub-manifold of the state space. Standard data assimilation techniques applied to such systems yield posterior states lying outside the manifold, violating the physical constraints. This work focuses on particle flow filters which use stochastic differential equations to evolve state samples from a prior distribution to samples from an observation-informed posterior distribution. The variational Fokker-Planck (VFP) -- a generic particle flow filtering framework -- is extended to incorporate non-linear, equality state constraints in the analysis. To this end, two algorithmic approaches that modify the VFP stochastic differential equation are discussed: (i) VFPSTAB, to inexactly preserve constraints with the addition of a stabilizing drift term, and (ii) VFPDAE, to exactly preserve constraints by treating the VFP dynamics as a stochastic differential-algebraic equation (SDAE). Additionally, an implicit-explicit time integrator is developed to evolve the VFPDAE dynamics. The strength of the proposed approach for constraint preservation in data assimilation is demonstrated on three test problems: the double pendulum, Korteweg-de-Vries, and the incompressible Navier-Stokes equations.",
        "subjects": [
            "math.OC",
            "cs.CE",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04382",
        "abstract url": "https://arxiv.org/abs/2405.04382",
        "title": "Large Language Models Cannot Explain Themselves",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models can be prompted to produce text. They can also be prompted to produce \"explanations\" of their output. But these are not really explanations, because they do not accurately reflect the mechanical process underlying the prediction. The illusion that they reflect the reasoning process can result in significant harms. These \"explanations\" can be valuable, but for promoting critical thinking rather than for understanding the model. I propose a recontextualisation of these \"explanations\", using the term \"exoplanations\" to draw attention to their exogenous nature. I discuss some implications for design and technology, such as the inclusion of appropriate guardrails and responses when models are prompted to generate explanations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "In Proceedings of the ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI 2024)"
    },
    {
        "paper id": "2405.04385",
        "abstract url": "https://arxiv.org/abs/2405.04385",
        "title": "A Random Walk Approach to Broadcasting on Random Recursive Trees",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the broadcasting problem on trees, a $\\{0,1\\}$-message originating in an unknown node is passed along the tree with a certain error probability $q$. The goal is to estimate the original message without knowing the order in which the nodes were informed. A variation of the problem is considering this broadcasting process on a randomly growing tree, which Addario-Berry et al. have investigated for uniform and linear preferential attachment recursive trees. We extend their studies of the majority estimator to the entire group of very simple increasing trees as well as shape exchangeable trees using the connection to inhomogeneous random walks and other stochastic processes with memory effects such as P\u00f3lya Urns.",
        "subjects": [
            "math.PR",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04395",
        "abstract url": "https://arxiv.org/abs/2405.04395",
        "title": "PACIFISTA: Conflict Evaluation and Management in Open RAN",
        "rating": "-10",
        "keywords": [],
        "abstract": "The O-RAN ALLIANCE is defining architectures, interfaces, operations, and security requirements for cellular networks based on Open Radio Access Network (RAN) principles. In this context, O-RAN introduced the RAN Intelligent Controllers (RICs) to enable dynamic control of cellular networks via data-driven applications referred to as rApps and xApps. RICs enable for the first time truly intelligent and self-organizing cellular networks. However, enabling the execution of many Artificial Intelligence (AI) algorithms taking autonomous control decisions to fulfill diverse (and possibly conflicting) goals poses unprecedented challenges. For instance, the execution of one xApp aiming at maximizing throughput and one aiming at minimizing energy consumption would inevitably result in diametrically opposed resource allocation strategies. Therefore, conflict management becomes a crucial component of any functional intelligent O-RAN system. This article studies the problem of conflict mitigation in O-RAN and proposes PACIFISTA, a framework to detect, characterize, and mitigate conflicts. PACIFISTA leverages a profiling pipeline to tests O-RAN applications in a sandbox environment, and combines hierarchical graphs with statistical models to detect the existence of conflicts and evaluate their severity. Experiments on Colosseum and OpenRAN Gym demonstrate PACIFISTA's ability to predict conflicts and provide valuable information before potentially conflicting xApps are deployed in production systems. We demonstrate that even O-RAN applications with similar goals can result in 16% throughput loss, and show how applications with conflicting goals might cause severe instability and result in up to 30% performance degradation. We also show that PACIFISTA can help operators to identify coexisting applications and maintain performance degradation below a tolerable threshold.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "12 pages, 15 figures, 7 tables"
    },
    {
        "paper id": "2405.04400",
        "abstract url": "https://arxiv.org/abs/2405.04400",
        "title": "Decentralized Algorithms for Out-of-System Interference Suppression in Distributed MIMO",
        "rating": "-10",
        "keywords": [],
        "abstract": "Out-of-system (OoS) interference is a potential limitation for distributed networks that operate in unlicensed spectrum or in a spectrum sharing scenario. The OoS interference differs from the in-system interference in that OoS signals and their associated channels (or even their statistics) are completely unknown. In this paper, we propose a novel distributed algorithm that can mitigate OoS interference in the uplink and suppress the signal transmission in the OoS direction in the downlink. To estimate the OoS interference, each access point (AP), upon receiving an estimate of OoS interference from a previous AP, computes a better estimate of OoS interference by rotate-and-average using Procrustes method and forwards the estimates to the next AP. This process continues until the central processing unit (CPU) receives the final estimate. Our method has comparable performance to that of a fully centralized interference rejection combining algorithm and has much lower fronthaul load requirements.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5 pages, 2 figures, to be published in IEEE Wireless Communications Letters"
    },
    {
        "paper id": "2405.04402",
        "abstract url": "https://arxiv.org/abs/2405.04402",
        "title": "Utility-driven Optimization of TTL Cache Hierarchies under Network Delays",
        "rating": "-10",
        "keywords": [],
        "abstract": "We optimize hierarchies of Time-to-Live (TTL) caches under random network delays. A TTL cache assigns individual eviction timers to cached objects that are usually refreshed upon a hit where upon a miss the object requires a random time to be fetched from a parent cache. Due to their object decoupling property, TTL caches are of particular interest since the optimization of a per-object utility enables service differentiation. However, state-of-the-art exact TTL cache optimization does not extend beyond single TTL caches, especially under network delays. In this paper, we leverage the object decoupling effect to formulate the non-linear utility maximization problem for TTL cache hierarchies in terms of the exact object hit probability under random network delays. We iteratively solve the utility maximization problem to find the optimal per-object TTLs. Further, we show that the exact model suffers from tractability issues for large hierarchies and propose a machine learning approach to estimate the optimal TTL values for large systems. Finally, we provide numerical and data center trace-based evaluations for both methods showing the significant offloading improvement due to TTL optimization considering the network delays.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04406",
        "abstract url": "https://arxiv.org/abs/2405.04406",
        "title": "R\u00e9nyi divergence guarantees for hashing with linear codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider the problem of distilling uniform random bits from an unknown source with a given $p$-entropy using linear hashing. As our main result, we estimate the expected $p$-divergence from the uniform distribution over the ensemble of random linear codes for all integer $p\\ge 2$. The proof relies on analyzing how additive noise, determined by a random element of the code from the ensemble, acts on the source distribution. This action leads to the transformation of the source distribution into an approximately uniform one, a process commonly referred to as distribution smoothing. We also show that hashing with Reed-Muller matrices reaches intrinsic randomness of memoryless Bernoulli sources in the $l_p$ sense for all integer $p\\ge 2$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04445",
        "abstract url": "https://arxiv.org/abs/2405.04445",
        "title": "Realistic Channel and Delay Coefficient Generation for Dual Mobile Space-Ground Links - A Tutorial-",
        "rating": "-10",
        "keywords": [],
        "abstract": "Channel and delay coefficient are two essential parameters for the characterization of a multipath propagation environment. It is crucial to generate realistic channel and delay coefficient in order to study the channel characteristics that involves signals propagating through environments with severe multipath effects. While many deterministic channel models, such as ray-tracing (RT), face challenges like high computational complexity, data requirements for geometrical information, and inapplicability for space-ground links, and nongeometry-based stochastic channel models (NGSCMs) might lack spatial consistency and offer lower accuracy, we present a scalable tutorial for the channel modeling of dual mobile space-ground links in urban areas, utilizing the Quasi Deterministic Radio Channel Generator (QuaDRiGa), which adopts a geometry-based stochastic channel model (GSCM), in conjunction with an International Telecommunication Union (ITU) provided state duration model. This tutorial allows for the generation of realistic channel and delay coefficients in a multipath environment for dual mobile space-ground links. We validate the accuracy of the work by analyzing the generated channel and delay coefficient from several aspects, such as received signal power and amplitude, multipath delay distribution, delay spread and Doppler spectrum.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages, 45 figures including bio images"
    },
    {
        "paper id": "2405.04467",
        "abstract url": "https://arxiv.org/abs/2405.04467",
        "title": "Online List Labeling with Near-Logarithmic Writes",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the Online List Labeling problem, a set of $n \\leq N$ elements from a totally ordered universe must be stored in sorted order in an array with $m=N+\\lceil\\varepsilon N \\rceil$ slots, where $\\varepsilon \\in (0,1]$ is constant, while an adversary chooses elements that must be inserted and deleted from the set. We devise a skip-list based algorithm for maintaining order against an oblivious adversary and show that the expected amortized number of writes is $O(\\varepsilon^{-1}\\log (n) \\operatorname{poly}(\\log \\log n))$ per update.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "12 pages, 1 figure. Improved version of a rejected draft"
    },
    {
        "paper id": "2405.04477",
        "abstract url": "https://arxiv.org/abs/2405.04477",
        "title": "Designing an Objective-Driven Test Method for the Comparative Performance Evaluation of Commercial DTI Solutions for Counter UAS systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Unmanned Aerial Systems (UASs) or drones become more and more commercially available and cheap. There has been much emphasis on developing and deploying Counter-UAS systems (UASs) with Detection Tracking and Identification (DTI) solutions. However, the capabilities of these systems are hard to benchmark. Performance claims of these systems are currently not supported by evidence. In addition, no standard test methodologies are available for these DTI systems and different test methodologies make comparison of these systems hard or impossible. We report on the definition, development and verification of an objective-driven test method and corresponding comparative performance evaluation for commercial DTI solutions for C-UASs. The developed methodology is based on end-user scenarios that are operationally relevant. The test methodology is based on a generic DTI system lay-out and is detailed towards detection, tracking and identification, taking into account contextual information and end-user input. The comparative performance evaluation is developed to enable the use of the methodology in a relevant environment, thereby taking into account any potential environmental aspect that might influence DTI system performance. Validation of the work in a relevant environment has been done in three operational trials. The operational trial results show that the method allows for performance evaluation at component level (i.e., detection, tracking or identification component) and at system level (combinations of these components and integrated DTI system of system solutions).",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Published to make content available online, though this is still work in progress and subject to additions and change"
    },
    {
        "paper id": "2405.04518",
        "abstract url": "https://arxiv.org/abs/2405.04518",
        "title": "Competition between self- and other-regarding preferences in resolving social dilemmas",
        "rating": "-10",
        "keywords": [],
        "abstract": "Evolutionary game theory assumes that individuals maximize their benefits when choosing strategies. However, an alternative perspective proposes that individuals seek to maximize the benefits of others. To explore the relationship between these perspectives, we develop a model where self- and other-regarding preferences compete in public goods games. We find that other-regarding preferences are more effective in promoting cooperation, even when self-regarding preferences are more productive. Cooperators with different preferences can coexist in a new phase where two classic solutions invade each other, resulting in a dynamical equilibrium. As a consequence, a lower productivity of self-regarding cooperation can provide a higher cooperation level. Our results, which are also valid in a well-mixed population, may explain why other-regarding preferences could be a viable and frequently observed attitude in human society.",
        "subjects": [
            "physics.soc-ph",
            "cond-mat.stat-mech",
            "cs.GT"
        ],
        "comment": "22 pages, 6 figures, accepted for publication at New Journal of Physics"
    },
    {
        "paper id": "2405.04525",
        "abstract url": "https://arxiv.org/abs/2405.04525",
        "title": "Comparing Ways of Obtaining Candidate Orderings from Approval Ballots",
        "rating": "-10",
        "keywords": [],
        "abstract": "To understand and summarize approval preferences and other binary evaluation data, it is useful to order the items on an axis which explains the data. In a political election using approval voting, this could be an ideological left-right axis such that each voter approves adjacent candidates, an analogue of single-peakedness. In a perfect axis, every approval set would be an interval, which is usually not possible, and so we need to choose an axis that gets closest to this ideal. The literature has developed algorithms for optimizing several objective functions (e.g., minimize the number of added approvals needed to get a perfect axis), but provides little help with choosing among different objectives. In this paper, we take a social choice approach and compare 5 different axis selection rules axiomatically, by studying the properties they satisfy. We establish some impossibility theorems, and characterize (within the class of scoring rules) the rule that chooses the axes that maximize the number of votes that form intervals, using the axioms of ballot monotonicity and resistance to cloning. Finally, we study the behavior of the rules on data from French election surveys, on the votes of justices of the US Supreme Court, and on synthetic data.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "43 pages including appendix, accepted to IJCAI 2024"
    },
    {
        "paper id": "2405.04526",
        "abstract url": "https://arxiv.org/abs/2405.04526",
        "title": "PoW Security-Latency under Random Delays and the Effect of Transaction Fees",
        "rating": "-10",
        "keywords": [],
        "abstract": "Safety guarantees and security-latency problem of Nakamoto consensus have been extensively studied in the last decade with a bounded delay model. Recent studies have shown that PoW protocol is secure under random delay models as well. In this paper, we analyze the security-latency problem, i.e., how secure a block is, after it becomes k-deep in the blockchain, under general random delay distributions. We provide tight and explicit bounds which only require determining the distribution of the number of Poisson arrivals during the random delay. We further consider potential effects of recent Bitcoin halving on the security-latency problem by extending our results.",
        "subjects": [
            "cs.CR",
            "cs.DC",
            "cs.DM",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04558",
        "abstract url": "https://arxiv.org/abs/2405.04558",
        "title": "A Reference Model for Information Quality in an IT Governance Context",
        "rating": "-10",
        "keywords": [],
        "abstract": "IT Governance systems are increasingly required to keep todays organizations functioning. IT Governance requires a holistic system of interacting components, including processes, organizational structures, information, and others. Performance management of IT Governance systems is of utmost importance to maintain their effectiveness. Capability models are used to assess and manage IT Governance process performance, whereas similar mechanisms are lacking for other types of IT Governance system components, e.g. information. In this paper, we focus on how to define the quality of IT Governance information, as a proxy for the performance of the information component of the IT Governance system. Using a Design Science approach, we iteratively develop, based on theory, and empirically evaluate, based on expert validation, a reference model for IT Governance information quality, i.e., the Information Quality Reference Model that can be used for assessing the quality of IT Governance information items. The model is comprehensive yet manageable and provides a basis for building a capability model for IT Governance information.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "69 pages including appendices Submitted to Information Systems Management Journal"
    },
    {
        "paper id": "2405.04600",
        "abstract url": "https://arxiv.org/abs/2405.04600",
        "title": "Contextual API Completion for Unseen Repositories Using LLMs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models have made substantial progress in addressing diverse code-related tasks. However, their adoption is hindered by inconsistencies in generating output due to the lack of real-world, domain-specific information, such as for intra-repository API calls for unseen software projects. We introduce a novel technique to mitigate hallucinations by leveraging global and local contextual information within a code repository for API completion tasks. Our approach is tailored to refine code completion tasks, with a focus on optimizing local API completions. We examine relevant import statements during API completion to derive insights into local APIs, drawing from their method signatures. For API token completion, we analyze the inline variables and correlate them with the appropriate imported modules, thereby allowing our approach to rank the most contextually relevant suggestions from the available local APIs. Further, for conversational API completion, we gather APIs that are most relevant to the developer query with a retrieval-based search across the project. We employ our tool, LANCE, within the framework of our proposed benchmark, APIEval, encompassing two different programming languages. Our evaluation yields an average accuracy of 82.6% for API token completion and 76.9% for conversational API completion tasks. On average, LANCE surpasses Copilot by 143% and 142% for API token completion and conversational API completion, respectively. The implications of our findings are substantial for developers, suggesting that our lightweight context analysis can be applied to multilingual environments without language-specific training or fine-tuning, allowing for efficient implementation with minimal examples and effort.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04602",
        "abstract url": "https://arxiv.org/abs/2405.04602",
        "title": "An Empirical Study of Kotlin-Java Interactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Background: Since Google introduced Kotlin as an official programming language for developing Android apps in 2017, Kotlin has gained widespread adoption in Android development. The interoperability of Java and Kotlin's design nature allows them to coexist and interact with each other smoothly within a project. Aims: However, there is limited research on how Java and Kotlin interact with each other in real-world projects and what challenges are faced during these interactions. The answers to these questions are key to understanding these kinds of cross-language software systems. Methods: In this paper, we implemented a tool named DependExtractor, which can extract 11 kinds of Kotlin-Java dependencies, and conducted an empirical study of 23 Kotlin-Java real-world projects with 3,227 Java and 8,630 Kotlin source files. Results: Our findings revealed that Java and Kotlin frequently interact with each other in these cross-language projects, with access and call dependency types being the most dominant. Compared to files interacting with other files in the same language, Java/Kotlin source files, which participate in the cross-language interactions, undergo more commits. Additionally, among all Kotlin-Java problematic interactions, we identified seven common mistakes, along with their fixing strategies. Conclusions: The findings of this study can help developers understand and address the challenges in Kotlin-Java projects.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04603",
        "abstract url": "https://arxiv.org/abs/2405.04603",
        "title": "Neural network based approach for solving problems in plane wave duct acoustics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Neural networks have emerged as a tool for solving differential equations in many branches of engineering and science. But their progress in frequency domain acoustics is limited by the vanishing gradient problem that occurs at higher frequencies. This paper discusses a formulation that can address this issue. The problem of solving the governing differential equation along with the boundary conditions is posed as an unconstrained optimization problem. The acoustic field is approximated to the output of a neural network which is constructed in such a way that it always satisfies the boundary conditions. The applicability of the formulation is demonstrated on popular problems in plane wave acoustic theory. The predicted solution from the neural network formulation is compared with those obtained from the analytical solution. A good agreement is observed between the two solutions. The method of transfer learning to calculate the particle velocity from the existing acoustic pressure field is demonstrated with and without mean flow effects. The sensitivity of the training process to the choice of the activation function and the number of collocation points is studied.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "Published Journal Article"
    },
    {
        "paper id": "2405.04606",
        "abstract url": "https://arxiv.org/abs/2405.04606",
        "title": "Probabilistic Byzantine Fault Tolerance (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "Consensus is a fundamental building block for constructing reliable and fault-tolerant distributed services. Many Byzantine fault-tolerant consensus protocols designed for partially synchronous systems adopt a pessimistic approach when dealing with adversaries, ensuring safety in a deterministic way even under the worst-case scenarios that adversaries can create. Following this approach typically results in either an increase in the message complexity (e.g., PBFT) or an increase in the number of communication steps (e.g., HotStuff). In practice, however, adversaries are not as powerful as the ones assumed by these protocols. Furthermore, it might suffice to ensure safety and liveness properties with high probability. In order to accommodate more realistic and optimistic adversaries and improve the scalability of the BFT consensus, we propose ProBFT (Probabilistic Byzantine Fault Tolerance). ProBFT is a leader-based probabilistic consensus protocol with a message complexity of $O(n\\sqrt{n})$ and an optimal number of communication steps that tolerates Byzantine faults in permissioned partially synchronous systems. It is built on top of well-known primitives, such as probabilistic Byzantine quorums and verifiable random functions. ProBFT guarantees safety and liveness with high probabilities even with faulty leaders, as long as a supermajority of replicas is correct, and using only a fraction of messages employed in PBFT (e.g., $20\\%$). We provide a detailed description of ProBFT's protocol and its analysis.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04609",
        "abstract url": "https://arxiv.org/abs/2405.04609",
        "title": "Learning Distributional Demonstration Spaces for Task-Specific Cross-Pose Estimation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Relative placement tasks are an important category of tasks in which one object needs to be placed in a desired pose relative to another object. Previous work has shown success in learning relative placement tasks from just a small number of demonstrations when using relational reasoning networks with geometric inductive biases. However, such methods cannot flexibly represent multimodal tasks, like a mug hanging on any of n racks. We propose a method that incorporates additional properties that enable learning multimodal relative placement solutions, while retaining the provably translation-invariant and relational properties of prior work. We show that our method is able to learn precise relative placement tasks with only 10-20 multimodal demonstrations with no human annotations across a diverse set of objects within a category.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for ICRA 2024"
    },
    {
        "paper id": "2405.04612",
        "abstract url": "https://arxiv.org/abs/2405.04612",
        "title": "Numerical Fuzz: A Type System for Rounding Error Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Algorithms operating on real numbers are implemented as floating-point computations in practice, but floating-point operations introduce roundoff errors that can degrade the accuracy of the result. We propose $\u039b_{num}$, a functional programming language with a type system that can express quantitative bounds on roundoff error. Our type system combines a sensitivity analysis, enforced through a linear typing discipline, with a novel graded monad to track the accumulation of roundoff errors. We prove that our type system is sound by relating the denotational semantics of our language to the exact and floating-point operational semantics. To demonstrate our system, we instantiate $\u039b_{num}$ with error metrics proposed in the numerical analysis literature and we show how to incorporate rounding operations that faithfully model aspects of the IEEE 754 floating-point standard. To show that $\u039b_{num}$ can be a useful tool for automated error analysis, we develop a prototype implementation for $\u039b_{num}$ that infers error bounds that are competitive with existing tools, while often running significantly faster. Finally, we consider semantic extensions of our graded monad to bound error under more complex rounding behaviors, such as non-deterministic and randomized rounding.",
        "subjects": [
            "cs.PL",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04622",
        "abstract url": "https://arxiv.org/abs/2405.04622",
        "title": "Bounds on the Statistical Leakage-Resilience of Shamir's Secret Sharing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Secret sharing is an instrumental tool for sharing secret keys in distributed systems. In a classical threshold setting, this involves a dealer who has a secret/key, a set of parties/users to which shares of the secret are sent, and a threshold on the number of users whose presence is needed in order to recover the secret. In secret sharing, secure links with no leakage are often assumed between the involved parties. However, when the users are nodes in a communication network and all the links are physical links, e.g., wireless, such assumptions are not valid anymore. In order to study this critical problem, we propose a statistical leakage model of secret sharing, where some noisy versions of all the secret shares might be independently leaked to an adversary. We then study the resilience of the seminal Shamir's secret sharing scheme with statistical leakage, and bound certain measures of security (i.e., semantic security, mutual information security), given other parameters of the system including the amount of leakage from each secret share. We show that for an extreme scenario of Shamir's scheme, in particular when the underlying field characteristic is $2$, the security of each bit of the secret against leakage improves exponentially with the number of users. To the best of our knowledge, this is the first attempt towards understanding secret sharing under general statistical noisy leakage.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04656",
        "abstract url": "https://arxiv.org/abs/2405.04656",
        "title": "Corporate Communication Companion (CCC): An LLM-empowered Writing Assistant for Workplace Social Media",
        "rating": "-10",
        "keywords": [],
        "abstract": "Workplace social media platforms enable employees to cultivate their professional image and connect with colleagues in a semi-formal environment. While semi-formal corporate communication poses a unique set of challenges, large language models (LLMs) have shown great promise in helping users draft and edit their social media posts. However, LLMs may fail to capture individualized tones and voices in such workplace use cases, as they often generate text using a \"one-size-fits-all\" approach that can be perceived as generic and bland. In this paper, we present Corporate Communication Companion (CCC), an LLM-empowered interactive system that helps people compose customized and individualized workplace social media posts. Using need-finding interviews to motivate our system design, CCC decomposes the writing process into two core functions, outline and edit: First, it suggests post outlines based on users' job status and previous posts, and next provides edits with attributions that users can contextually customize. We conducted a within-subjects user study asking participants both to write posts and evaluate posts written by others. The results show that CCC enhances users' writing experience, and audience members rate CCC-enhanced posts as higher quality than posts written using a non-customized writing assistant. We conclude by discussing the implications of LLM-empowered corporate communication.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04674",
        "abstract url": "https://arxiv.org/abs/2405.04674",
        "title": "Towards Accurate and Efficient Document Analytics with Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Unstructured data formats account for over 80% of the data currently stored, and extracting value from such formats remains a considerable challenge. In particular, current approaches for managing unstructured documents do not support ad-hoc analytical queries on document collections. Moreover, Large Language Models (LLMs) directly applied to the documents themselves, or on portions of documents through a process of Retrieval-Augmented Generation (RAG), fail to provide high accuracy query results, and in the LLM-only case, additionally incur high costs. Since many unstructured documents in a collection often follow similar templates that impart a common semantic structure, we introduce ZenDB, a document analytics system that leverages this semantic structure, coupled with LLMs, to answer ad-hoc SQL queries on document collections. ZenDB efficiently extracts semantic hierarchical structures from such templatized documents, and introduces a novel query engine that leverages these structures for accurate and cost-effective query execution. Users can impose a schema on their documents, and query it, all via SQL. Extensive experiments on three real-world document collections demonstrate ZenDB's benefits, achieving up to 30% cost savings compared to LLM-based baselines, while maintaining or improving accuracy, and surpassing RAG-based baselines by up to 61% in precision and 80% in recall, at a marginally higher cost.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04696",
        "abstract url": "https://arxiv.org/abs/2405.04696",
        "title": "Nearly Tight Bounds on Approximate Equilibria in Spatial Competition on the Line",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Hotelling's model of spatial competition, a unit mass of voters is distributed in the interval $[0,1]$ (with their location corresponding to their political persuasion), and each of $m$ candidates selects as a strategy his distinct position in this interval. Each voter votes for the nearest candidate, and candidates choose their strategy to maximize their votes. It is known that if there are more than two candidates, equilibria may not exist in this model. It was unknown, however, how close to an equilibrium one could get. Our work studies approximate equilibria in this model, where a strategy profile is an (additive) $\u03b5$-equilibria if no candidate can increase their votes by $\u03b5$, and provides tight or nearly-tight bounds on the approximation $\u03b5$ achievable. We show that for 3 candidates, for any distribution of the voters, $\u03b5\\ge 1/12$. Thus, somewhat surprisingly, for any distribution of the voters and any strategy profile of the candidates, at least $1/12$th of the total votes is always left ``on the table.'' Extending this, we show that in the worst case, there exist voter distributions for which $\u03b5\\ge 1/6$, and this is tight: one can always compute a $1/6$-approximate equilibria. We then study the general case of $m$ candidates, and show that as $m$ grows large, we get closer to an exact equilibrium: one can always obtain an $1/(m+1)$-approximate equilibria in polynomial time. We show this bound is asymptotically tight, by giving voter distributions for which $\u03b5\\ge 1/(m+3)$.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04697",
        "abstract url": "https://arxiv.org/abs/2405.04697",
        "title": "The Existential Theory of the Reals with Summation Operators",
        "rating": "-10",
        "keywords": [],
        "abstract": "To characterize the computational complexity of satisfiability problems for probabilistic and causal reasoning within the Pearl's Causal Hierarchy, arXiv:2305.09508 [cs.AI] introduce a new natural class, named succ-$\\exists$R. This class can be viewed as a succinct variant of the well-studied class $\\exists$R based on the Existential Theory of the Reals (ETR). Analogously to $\\exists$R, succ-$\\exists$R is an intermediate class between NEXP and EXPSPACE, the exponential versions of NP and PSPACE. The main contributions of this work are threefold. Firstly, we characterize the class succ-$\\exists$R in terms of nondeterministic real RAM machines and develop structural complexity theoretic results for real RAMs, including translation and hierarchy theorems. Notably, we demonstrate the separation of $\\exists$R and succ-$\\exists$R. Secondly, we examine the complexity of model checking and satisfiability of fragments of existential second-order logic and probabilistic independence logic. We show succ-$\\exists$R- completeness of several of these problems, for which the best-known complexity lower and upper bounds were previously NEXP-hardness and EXPSPACE, respectively. Thirdly, while succ-$\\exists$R is characterized in terms of ordinary (non-succinct) ETR instances enriched by exponential sums and a mechanism to index exponentially many variables, in this paper, we prove that when only exponential sums are added, the corresponding class $\\exists$R^\u03a3 is contained in PSPACE. We conjecture that this inclusion is strict, as this class is equivalent to adding a VNP-oracle to a polynomial time nondeterministic real RAM. Conversely, the addition of exponential products to ETR, yields PSPACE. Additionally, we study the satisfiability problem for probabilistic reasoning, with the additional requirement of a small model and prove that this problem is complete for $\\exists$R^\u03a3.",
        "subjects": [
            "cs.CC",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04702",
        "abstract url": "https://arxiv.org/abs/2405.04702",
        "title": "Mitigating Negative Side Effects in Multi-Agent Systems Using Blame Assignment",
        "rating": "-10",
        "keywords": [],
        "abstract": "When agents that are independently trained (or designed) to complete their individual tasks are deployed in a shared environment, their joint actions may produce negative side effects (NSEs). As their training does not account for the behavior of other agents or their joint action effects on the environment, the agents have no prior knowledge of the NSEs of their actions. We model the problem of mitigating NSEs in a cooperative multi-agent system as a Lexicographic Decentralized Markov Decision Process with two objectives. The agents must optimize the completion of their assigned tasks while mitigating NSEs. We assume independence of transitions and rewards with respect to the agents' tasks but the joint NSE penalty creates a form of dependence in this setting. To improve scalability, the joint NSE penalty is decomposed into individual penalties for each agent using credit assignment, which facilitates decentralized policy computation. Our results in simulation on three domains demonstrate the effectiveness and scalability of our approach in mitigating NSEs by updating the policies of a subset of agents in the system.",
        "subjects": [
            "cs.MA",
            "cs.RO"
        ],
        "comment": "10 pages, 5 figures"
    },
    {
        "paper id": "2405.04704",
        "abstract url": "https://arxiv.org/abs/2405.04704",
        "title": "System Identification of the Upgraded LHPOST6 Reaction Mass at the University of California San Diego",
        "rating": "-10",
        "keywords": [],
        "abstract": "Upon completing the upgrade from one to six degrees of freedom of the Outdoor Shake Table at UCSD in 2019, forced vibration tests were carried out to identify the dynamic characteristics of the reaction mass and soil system. This report describes the motivation, execution, and results from such tests, which independently excited the reaction mass in four degrees of freedom: longitudinal, transverse, yaw, and vertical. The report discusses the frequency response curves and deformation patterns from which the natural frequencies, damping ratio, mode shapes, and rigid body motion were determined. The first objective of the study was to investigate if the dynamic properties of the system had dramatically changed after the upgrade by comparing the results to those from forced vibration tests performed 20 years ago, during the construction of the facility. In addition, most recent tests also contributed with results from the vertical degree of freedom, which had never been tested. The second objective was to obtain high-quality response data of the system that will be used to develop a high-fidelity computational model of the reaction mass in future research. A comparison of results showed a slight difference of 0.5Hz in the natural frequency of 2 degrees of freedom. Moreover, maximum displacements in the recent tests were overall larger than the previous ones with few exceptions. The report thoroughly discusses the several sources of discrepancy between the past and most recent results. Finally, test results allowed us to estimate the system's response if the shake table actuators were to be used at their maximum nominal capacity. Small displacement and high damping results were consistent with those of previous tests and further validated the design of the reaction mass.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "38 pages, 35 figures"
    },
    {
        "paper id": "2405.04713",
        "abstract url": "https://arxiv.org/abs/2405.04713",
        "title": "Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue",
        "rating": "-10",
        "keywords": [],
        "abstract": "Knowledge retrieval is one of the major challenges in building a knowledge-grounded dialogue system. A common method is to use a neural retriever with a distributed approximate nearest-neighbor database to quickly find the relevant knowledge sentences. In this work, we propose an approach that utilizes topic modeling on the knowledge base to further improve retrieval accuracy and as a result, improve response generation. Additionally, we experiment with a large language model, ChatGPT, to take advantage of the improved retrieval performance to further improve the generation results. Experimental results on two datasets show that our approach can increase retrieval and generation performance. The results also indicate that ChatGPT is a better response generator for knowledge-grounded dialogue when relevant knowledge is provided.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "LREC-COLING 2024"
    },
    {
        "paper id": "2405.04727",
        "abstract url": "https://arxiv.org/abs/2405.04727",
        "title": "LLMs Can Patch Up Missing Relevance Judgments in Evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Unjudged documents or holes in information retrieval benchmarks are considered non-relevant in evaluation, yielding no gains in measuring effectiveness. However, these missing judgments may inadvertently introduce biases into the evaluation as their prevalence for a retrieval model is heavily contingent on the pooling process. Thus, filling holes becomes crucial in ensuring reliable and accurate evaluation. Collecting human judgment for all documents is cumbersome and impractical. In this paper, we aim at leveraging large language models (LLMs) to automatically label unjudged documents. Our goal is to instruct an LLM using detailed instructions to assign fine-grained relevance judgments to holes. To this end, we systematically simulate scenarios with varying degrees of holes by randomly dropping relevant documents from the relevance judgment in TREC DL tracks. Our experiments reveal a strong correlation between our LLM-based method and ground-truth relevance judgments. Based on our simulation experiments conducted on three TREC DL datasets, in the extreme scenario of retaining only 10% of judgments, our method achieves a Kendall tau correlation of 0.87 and 0.92 on an average for Vicu\u00f1a-7B and GPT-3.5 Turbo respectively.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2405.04733",
        "abstract url": "https://arxiv.org/abs/2405.04733",
        "title": "One-Bit Phase Retrieval: Optimal Rates and Efficient Algorithms",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we study the sample complexity and develop efficient optimal algorithms for 1-bit phase retrieval: recovering a signal $\\mathbf{x}\\in\\mathbb{R}^n$ from $m$ phaseless bits $\\{\\mathrm{sign}(|\\mathbf{a}_i^\\top\\mathbf{x}|-\u03c4)\\}_{i=1}^m$ generated by standard Gaussian $\\mathbf{a}_i$s. By investigating a phaseless version of random hyperplane tessellation, we show that (constrained) hamming distance minimization uniformly recovers all unstructured signals with Euclidean norm bounded away from zero and infinity to the error $\\mathcal{O}((n/m)\\log(m/n))$, and $\\mathcal{O}((k/m)\\log(mn/k^2))$ when restricting to $k$-sparse signals. Both error rates are shown to be information-theoretically optimal, up to a logarithmic factor. Intriguingly, the optimal rate for sparse recovery matches that of 1-bit compressed sensing, suggesting that the phase information is non-essential for 1-bit compressed sensing. We also develop efficient algorithms for 1-bit (sparse) phase retrieval that can achieve these error rates. Specifically, we prove that (thresholded) gradient descent with respect to the one-sided $\\ell_1$-loss, when initialized via spectral methods, converges linearly and attains the near optimal reconstruction error, with sample complexity $\\mathcal{O}(n)$ for unstructured signals and $\\mathcal{O}(k^2\\log(n)\\log^2(m/k))$ for $k$-sparse signals. Our proof is based upon the observation that a certain local (restricted) approximate invertibility condition is respected by Gaussian measurements. To show this, we utilize a delicate covering argument and derive tight concentration bounds for the directional gradients by properly conditioning on the index set of phaseless hyperplane separations, which may be of independent interests and useful for other related problems.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04743",
        "abstract url": "https://arxiv.org/abs/2405.04743",
        "title": "Off-Road Autonomy Validation Using Scalable Digital Twin Simulations Within High-Performance Computing Clusters",
        "rating": "-10",
        "keywords": [],
        "abstract": "Off-road autonomy validation presents unique challenges due to the unpredictable and dynamic nature of off-road environments. Traditional methods focusing on sequentially sweeping across the parameter space for variability analysis struggle to comprehensively assess the performance and safety of off-road autonomous systems within the imposed time constraints. This paper proposes leveraging scalable digital twin simulations within high-performance computing (HPC) clusters to address this challenge. By harnessing the computational power of HPC clusters, our approach aims to provide a scalable and efficient means to validate off-road autonomy algorithms, enabling rapid iteration and testing of autonomy algorithms under various conditions. We demonstrate the effectiveness of our framework through performance evaluations of the HPC cluster in terms of simulation parallelization and present the systematic variability analysis of a candidate off-road autonomy algorithm to identify potential vulnerabilities in the autonomy stack's perception, planning and control modules.",
        "subjects": [
            "cs.RO",
            "cs.DC"
        ],
        "comment": "Accepted at Ground Vehicle Systems Engineering and Technology Symposium (GVSETS) 2024. Distribution Statement A. Approved for public release; distribution is unlimited. OPSEC #8451. arXiv admin note: text overlap with arXiv:2402.12670, arXiv:2402.14739"
    },
    {
        "paper id": "2405.04757",
        "abstract url": "https://arxiv.org/abs/2405.04757",
        "title": "Communication-efficient and Differentially-private Distributed Nash Equilibrium Seeking with Linear Convergence",
        "rating": "-10",
        "keywords": [],
        "abstract": "The distributed computation of a Nash equilibrium (NE) for non-cooperative games is gaining increased attention recently. Due to the nature of distributed systems, privacy and communication efficiency are two critical concerns. Traditional approaches often address these critical concerns in isolation. This work introduces a unified framework, named CDP-NES, designed to improve communication efficiency in the privacy-preserving NE seeking algorithm for distributed non-cooperative games over directed graphs. Leveraging both general compression operators and the noise adding mechanism, CDP-NES perturbs local states with Laplacian noise and applies difference compression prior to their exchange among neighbors. We prove that CDP-NES not only achieves linear convergence to a neighborhood of the NE in games with restricted monotone mappings but also guarantees $\u03b5$-differential privacy, addressing privacy and communication efficiency simultaneously. Finally, simulations are provided to illustrate the effectiveness of the proposed method.",
        "subjects": [
            "eess.SY",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04762",
        "abstract url": "https://arxiv.org/abs/2405.04762",
        "title": "Nearly-Optimal Consensus Tolerating Adaptive Omissions: Why is a Lot of Randomness is Needed?",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of reaching agreement in a synchronous distributed system by $n$ autonomous parties, when the communication links from/to faulty parties can omit messages. The faulty parties are selected and controlled by an adaptive, full-information, computationally unbounded adversary. We design a randomized algorithm that works in $O(\\sqrt{n}\\log^2 n)$ rounds and sends $O(n^2\\log^3 n)$ communication bits, where the number of faulty parties is $\u0398(n)$. Our result is simultaneously tight for both these measures within polylogarithmic factors: due to the $\u03a9(n^2)$ lower bound on communication by Abraham et al. (PODC'19) and $\u03a9(\\sqrt{n/\\log n})$ lower bound on the number of rounds by Bar-Joseph and Ben-Or (PODC'98). We also quantify how much randomness is necessary and sufficient to reduce time complexity to a certain value, while keeping the communication complexity (nearly) optimal. We prove that no MC algorithm can work in less than $\u03a9(\\frac{n^2}{\\max\\{R,n\\}\\log n})$ rounds if it uses less than $O(R)$ calls to a random source, assuming a constant fraction of faulty parties. This can be contrasted with a long line of work on consensus against an {\\em adversary limited to polynomial computation time}, thus unable to break cryptographic primitives, culminating in a work by Ghinea et al. (EUROCRYPT'22), where an optimal $O(r)$-round solution with probability $1-(cr)^{-r}$ is given. Our lower bound strictly separates these two regimes, by excluding such results if the adversary is computationally unbounded. On the upper bound side, we show that for $R\\in\\tilde{O}(n^{3/2})$ there exists an algorithm solving consensus in $\\tilde{O}(\\frac{n^2}{R})$ rounds with high probability, where tilde notation hides a polylogarithmic factor. The communication complexity of the algorithm does not depend on the amount of randomness $R$ and stays optimal within polylogarithmic factor.",
        "subjects": [
            "cs.DC",
            "cs.CR",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04775",
        "abstract url": "https://arxiv.org/abs/2405.04775",
        "title": "Determining Recoverable Consensus Numbers",
        "rating": "-10",
        "keywords": [],
        "abstract": "Herlihy's wait-free consensus hierarchy classifies the power of object types in asynchronous shared memory systems where processes can permanently crash (i.e. stop taking steps). In this hierarchy, a type has consensus number $n$ if objects of that type can be used along with (read/write) registers to solve consensus among $n$ processes that can permanently crash, but not among $n+1$ or more processes. In systems where processes can recover after crashing, the power of an object type to solve consensus may be different. Golab's recoverable consensus hierarchy classifies the power of object types in such a system. In the recoverable consensus hierarchy, a type has recoverable consensus number $n$ if objects of that type can be used along with registers to solve consensus among $n$ processes that can recover after crashing, but not among $n+1$ or more processes. In this paper, we prove that the recoverable consensus hierarchy of deterministic, readable types is robust, i.e., if consensus can be solved among $n$ processes that can recover after crashing using a collection of objects of deterministic, readable types, then one of these types has recoverable consensus number at least $n$. This is important for comparing the relative computational power of different deterministic, readable types, because it implies that one cannot combine various objects to obtain an algorithm that is better at solving recoverable consensus than any of the individual object types. Our result can be used to show that, for all $n \\geq 4$, there exists a readable type with consensus number $n$ and recoverable consensus number $n-2$. We also show that, for all $n > n' \\geq 1$, there exists a non-readable type that has consensus number $n$ and recoverable consensus number $n'$.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04787",
        "abstract url": "https://arxiv.org/abs/2405.04787",
        "title": "The Impact of Human Aspects on the Interactions Between Software Developers and End-Users in Software Engineering: A Systematic Literature Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context: Research on human aspects within the field of software engineering (SE) has been steadily gaining prominence in recent years. These human aspects have a significant impact on SE due to the inherently interactive and collaborative nature of the discipline. Objective: In this paper, we present a systematic literature review (SLR) on human aspects affecting developer-user interactions. The objective of this SLR is to plot the current landscape of primary studies by examining the human aspects that influence developer-user interactions, their implications, interrelationships, and how existing studies address these implications. Method: We conducted this SLR following the guidelines proposed by Kitchenham et al. We performed a comprehensive search in six digital databases, and an exhaustive backward and forward snowballing process. We selected 46 primary studies for data extraction. Results: We identified various human aspects affecting developer-user interactions in SE, assessed their interrelationships, identified their positive impacts and mitigation strategies for negative effects. We present specific recommendations derived from the identified research gaps. Conclusion: Our findings suggest the importance of leveraging positive effects and addressing negative effects in developer-user interactions through the implementation of effective mitigation strategies. These insights may benefit software practitioners for effective user interactions, and the recommendations proposed by this SLR may aid the research community in further human aspects related studies.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2405.04791",
        "abstract url": "https://arxiv.org/abs/2405.04791",
        "title": "The Impact of Perceived Tone, Age, and Gender on Voice Assistant Persuasiveness in the Context of Product Recommendations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Voice Assistants (VAs) can assist users in various everyday tasks, but many users are reluctant to rely on VAs for intricate tasks like online shopping. This study aims to examine whether the vocal characteristics of VAs can serve as an effective tool to persuade users and increase user engagement with VAs in online shopping. Prior studies have demonstrated that the perceived tone, age, and gender of a voice influence the perceived persuasiveness of the speaker in interpersonal interactions. Furthermore, persuasion in product communication has been shown to affect purchase decisions in online shopping. We investigate whether variations in a VA voice's perceived tone, age, and gender characteristics can persuade users, and ultimately affect their purchase decisions. Our experimental study showed that participants were more persuaded to make purchase decisions by VA voices having positive or neutral tones as well as middle-aged male or younger female voices. Our results suggest that VA designers should offer users the ability to easily customize VA voices with a range of tones, ages, and genders. This customization can enhance user comfort and enjoyment, potentially leading to higher engagement with VAs. Additionally, we discuss the boundaries of ethical persuasion, emphasizing the importance of safeguarding users' interests against unwarranted manipulation.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "ACM Conversational User Interface 2024"
    },
    {
        "paper id": "2405.05284",
        "abstract url": "https://arxiv.org/abs/2405.05284",
        "title": "A Study on Cognitive Effects of Canvas Size for Augmenting Drawing Skill",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, the field of generative artificial intelligence, particularly in the domain of image generation, has exerted a profound influence on society. Despite the capability of AI to produce images of high quality, the augmentation of users' drawing abilities through the provision of drawing support systems emerges as a challenging issue. In this study, we propose that a cognitive factor, specifically, the size of the canvas, may exert a considerable influence on the outcomes of imitative drawing sketches when utilizing reference images. To investigate this hypothesis, a web based drawing interface was utilized, designed specifically to evaluate the effect of the canvas size's proportionality to the reference image on the fidelity of the drawings produced. The findings from our research lend credence to the hypothesis that a drawing interface, featuring a canvas whose dimensions closely match those of the reference image, markedly improves the precision of user-generated sketches.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": "5 pages, 6 figures, accepted in NICOGRAPH International 2024"
    }
]