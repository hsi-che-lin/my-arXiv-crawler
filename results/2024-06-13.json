[
    {
        "paper id": "2406.09117",
        "abstract url": "https://arxiv.org/abs/2406.09117",
        "title": "PC-LoRA: Low-Rank Adaptation for Progressive Model Compression with Knowledge Distillation",
        "rating": "2.5",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Low-rank adaption (LoRA) is a prominent method that adds a small number of learnable parameters to the frozen pre-trained weights for parameter-efficient fine-tuning. Prompted by the question, ``Can we make its representation enough with LoRA weights solely at the final phase of finetuning without the pre-trained weights?'' In this work, we introduce Progressive Compression LoRA~(PC-LoRA), which utilizes low-rank adaptation (LoRA) to simultaneously perform model compression and fine-tuning. The PC-LoRA method gradually removes the pre-trained weights during the training process, eventually leaving only the low-rank adapters in the end. Thus, these low-rank adapters replace the whole pre-trained weights, achieving the goals of compression and fine-tuning at the same time. Empirical analysis across various models demonstrates that PC-LoRA achieves parameter and FLOPs compression rates of 94.36%/89.1% for vision models, e.g., ViT-B, and 93.42%/84.2% parameters and FLOPs compressions for language models, e.g., BERT.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted at T4V@CVPR"
    },
    {
        "paper id": "2406.09156",
        "abstract url": "https://arxiv.org/abs/2406.09156",
        "title": "Towards Multilingual Audio-Visual Question Answering",
        "rating": "2.5",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "In this paper, we work towards extending Audio-Visual Question Answering (AVQA) to multilingual settings. Existing AVQA research has predominantly revolved around English and replicating it for addressing AVQA in other languages requires a substantial allocation of resources. As a scalable solution, we leverage machine translation and present two multilingual AVQA datasets for eight languages created from existing benchmark AVQA datasets. This prevents extra human annotation efforts of collecting questions and answers manually. To this end, we propose, MERA framework, by leveraging state-of-the-art (SOTA) video, audio, and textual foundation models for AVQA in multiple languages. We introduce a suite of models namely MERA-L, MERA-C, MERA-T with varied model architectures to benchmark the proposed datasets. We believe our work will open new research directions and act as a reference benchmark for future works in multilingual AVQA.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted to Interspeech 2024"
    },
    {
        "paper id": "2406.09296",
        "abstract url": "https://arxiv.org/abs/2406.09296",
        "title": "Parameter-Efficient Active Learning for Foundational models",
        "rating": "2.5",
        "keywords": [
            [
                "Parameter-Efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Foundational vision transformer models have shown impressive few shot performance on many vision tasks. This research presents a novel investigation into the application of parameter efficient fine-tuning methods within an active learning (AL) framework, to advance the sampling selection process in extremely budget constrained classification tasks. The focus on image datasets, known for their out-of-distribution characteristics, adds a layer of complexity and relevance to our study. Through a detailed evaluation, we illustrate the improved AL performance on these challenging datasets, highlighting the strategic advantage of merging parameter efficient fine tuning methods with foundation models. This contributes to the broader discourse on optimizing AL strategies, presenting a promising avenue for future exploration in leveraging foundation models for efficient and effective data annotation in specialized domains.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted for CVPR2024 Transformers for Vision Workshop"
    },
    {
        "paper id": "2406.09388",
        "abstract url": "https://arxiv.org/abs/2406.09388",
        "title": "Exploring the Spectrum of Visio-Linguistic Compositionality and Recognition",
        "rating": "2.5",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Vision and language models (VLMs) such as CLIP have showcased remarkable zero-shot recognition abilities yet face challenges in visio-linguistic compositionality, particularly in linguistic comprehension and fine-grained image-text alignment. This paper explores the intricate relationship between compositionality and recognition -- two pivotal aspects of VLM capability. We conduct a comprehensive evaluation of existing VLMs, covering both pre-training approaches aimed at recognition and the fine-tuning methods designed to improve compositionality. Our evaluation employs 12 benchmarks for compositionality, along with 21 zero-shot classification and two retrieval benchmarks for recognition. In our analysis from 274 CLIP model checkpoints, we reveal patterns and trade-offs that emerge between compositional understanding and recognition accuracy. Ultimately, this necessitates strategic efforts towards developing models that improve both capabilities, as well as the meticulous formulation of benchmarks for compositionality. We open our evaluation framework at https://github.com/ytaek-oh/vl_compo.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to CVPRW 2024 on 'What is Next in Multimodal Foundation Models?'. Code: https://github.com/ytaek-oh/vl_compo"
    },
    {
        "paper id": "2406.08840",
        "abstract url": "https://arxiv.org/abs/2406.08840",
        "title": "Conceptual Learning via Embedding Approximations for Reinforcing Interpretability and Transparency",
        "rating": "2",
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Concept bottleneck models (CBMs) have emerged as critical tools in domains where interpretability is paramount. These models rely on predefined textual descriptions, referred to as concepts, to inform their decision-making process and offer more accurate reasoning. As a result, the selection of concepts used in the model is of utmost significance. This study proposes \\underline{\\textbf{C}}onceptual \\underline{\\textbf{L}}earning via \\underline{\\textbf{E}}mbedding \\underline{\\textbf{A}}pproximations for \\underline{\\textbf{R}}einforcing Interpretability and Transparency, abbreviated as CLEAR, a framework for constructing a CBM for image classification. Using score matching and Langevin sampling, we approximate the embedding of concepts within the latent space of a vision-language model (VLM) by learning the scores associated with the joint distribution of images and concepts. A concept selection process is then employed to optimize the similarity between the learned embeddings and the predefined ones. The derived bottleneck offers insights into the CBM's decision-making process, enabling more comprehensive interpretations. Our approach was evaluated through extensive experiments and achieved state-of-the-art performance on various benchmarks. The code for our experiments is available at https://github.com/clearProject/CLEAR/tree/main",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08903",
        "abstract url": "https://arxiv.org/abs/2406.08903",
        "title": "Delta-CoMe: Training-Free Delta-Compression with Mixed-Precision for Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Fine-tuning is a crucial process for adapting large language models (LLMs) to diverse applications. In certain scenarios, such as multi-tenant serving, deploying multiple LLMs becomes necessary to meet complex demands. Recent studies suggest decomposing a fine-tuned LLM into a base model and corresponding delta weights, which are then compressed using low-rank or low-bit approaches to reduce costs. In this work, we observe that existing low-rank and low-bit compression methods can significantly harm the model performance for task-specific fine-tuned LLMs (e.g., WizardMath for math problems). Motivated by the long-tail distribution of singular values in the delta weights, we propose a delta quantization approach using mixed-precision. This method employs higher-bit representation for singular vectors corresponding to larger singular values. We evaluate our approach on various fine-tuned LLMs, including math LLMs, code LLMs, chat LLMs, and even VLMs. Experimental results demonstrate that our approach performs comparably to full fine-tuned LLMs, surpassing both low-rank and low-bit baselines by a considerable margin. Additionally, we show that our method is compatible with various backbone LLMs, such as Llama-2, Llama-3, and Mistral, highlighting its generalizability.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2406.09044",
        "abstract url": "https://arxiv.org/abs/2406.09044",
        "title": "MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "Efficient finetuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Efficient finetuning of large language models (LLMs) aims to adapt the LLMs with reduced computation and memory cost. Previous LoRA-based approaches initialize the low-rank matrices with gaussian distribution and zero values, while keeping the original weight matrices frozen. However, the trainable model parameters optimized in an unguided subspace might have interference with the well-learned subspace of the pretrained weight matrix. In this paper, we propose MiLoRA, a simple yet effective LLM finetuning approach that only updates the minor singular components of the weight matrix while keeping the principle singular components frozen. It is observed that the minor matrix corresponds to the noisy or long-tail information, while the principle matrix contains important knowledge. The MiLoRA initializes the low-rank matrices within a subspace that is orthogonal to the principle matrix, thus the pretrained knowledge is expected to be well preserved. During finetuning, MiLoRA makes the most use of the less-optimized subspace for learning the finetuning dataset. Extensive experiments on commonsense reasoning, math reasoning and instruction following benchmarks present the superior performance of our method.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09067",
        "abstract url": "https://arxiv.org/abs/2406.09067",
        "title": "How structured are the representations in transformer-based vision encoders? An analysis of multi-object representations in vision-language models",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Forming and using symbol-like structured representations for reasoning has been considered essential for generalising over novel inputs. The primary tool that allows generalisation outside training data distribution is the ability to abstract away irrelevant information into a compact form relevant to the task. An extreme form of such abstract representations is symbols. Humans make use of symbols to bind information while abstracting away irrelevant parts to utilise the information consistently and meaningfully. This work estimates the state of such structured representations in vision encoders. Specifically, we evaluate image encoders in large vision-language pre-trained models to address the question of which desirable properties their representations lack by applying the criteria of symbolic structured reasoning described for LLMs to the image models. We test the representation space of image encoders like VIT, BLIP, CLIP, and FLAVA to characterise the distribution of the object representations in these models. In particular, we create decoding tasks using multi-object scenes from the COCO dataset, relating the token space to its input content for various objects in the scene. We use these tasks to characterise the network's token and layer-wise information modelling. Our analysis highlights that the CLS token, used for the downstream task, only focuses on a few objects necessary for the trained downstream task. Still, other individual objects are well-modelled separately by the tokens in the network originating from those objects. We further observed a widespread distribution of scene information. This demonstrates that information is far more entangled in tokens than optimal for representing objects similar to symbols. Given these symbolic properties, we show the network dynamics that cause failure modes of these models on basic downstream tasks in a multi-object scene.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09121",
        "abstract url": "https://arxiv.org/abs/2406.09121",
        "title": "MMRel: A Relation Understanding Dataset and Benchmark in the MLLM Era",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the recent advancements in Multi-modal Large Language Models (MLLMs), understanding inter-object relations, i.e., interactions or associations between distinct objects, remains a major challenge for such models. This issue significantly hinders their advanced reasoning capabilities and is primarily due to the lack of large-scale, high-quality, and diverse multi-modal data essential for training and evaluating MLLMs. In this paper, we provide a taxonomy of inter-object relations and introduce Multi-Modal Relation Understanding (MMRel), a comprehensive dataset designed to bridge this gap by providing large-scale, high-quality and diverse data for studying inter-object relations with MLLMs. MMRel features three distinctive attributes: (i) It includes over 15K question-answer pairs, which are sourced from three distinct domains, ensuring large scale and high diversity; (ii) It contains a subset featuring highly unusual relations, on which MLLMs often fail due to hallucinations, thus are very challenging; (iii) It provides manually verified high-quality labels for inter-object relations. Thanks to these features, MMRel is ideal for evaluating MLLMs on relation understanding, as well as being used to fine-tune MLLMs to enhance relation understanding and even benefit overall performance in various vision-language tasks. Extensive experiments on various popular MLLMs validate the effectiveness of MMRel. Both MMRel dataset and the complete labeling scripts have been made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09135",
        "abstract url": "https://arxiv.org/abs/2406.09135",
        "title": "AdaRevD: Adaptive Patch Exiting Reversible Decoder Pushes the Limit of Image Deblurring",
        "rating": "2",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the recent progress in enhancing the efficacy of image deblurring, the limited decoding capability constrains the upper limit of State-Of-The-Art (SOTA) methods. This paper proposes a pioneering work, Adaptive Patch Exiting Reversible Decoder (AdaRevD), to explore their insufficient decoding capability. By inheriting the weights of the well-trained encoder, we refactor a reversible decoder which scales up the single-decoder training to multi-decoder training while remaining GPU memory-friendly. Meanwhile, we show that our reversible structure gradually disentangles high-level degradation degree and low-level blur pattern (residual of the blur image and its sharp counterpart) from compact degradation representation. Besides, due to the spatially-variant motion blur kernels, different blur patches have various deblurring difficulties. We further introduce a classifier to learn the degradation degree of image patches, enabling them to exit at different sub-decoders for speedup. Experiments show that our AdaRevD pushes the limit of image deblurring, e.g., achieving 34.60 dB in PSNR on GoPro dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09295",
        "abstract url": "https://arxiv.org/abs/2406.09295",
        "title": "AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Evaluating the alignment capabilities of large Vision-Language Models (VLMs) is essential for determining their effectiveness as helpful assistants. However, existing benchmarks primarily focus on basic abilities using nonverbal methods, such as yes-no and multiple-choice questions. In this paper, we address this gap by introducing AlignMMBench, a comprehensive alignment benchmark specifically designed for emerging Chinese VLMs. This benchmark is meticulously curated from real-world scenarios and Chinese Internet sources, encompassing thirteen specific tasks across three categories, and includes both single-turn and multi-turn dialogue scenarios. Incorporating a prompt rewrite strategy, AlignMMBench encompasses 1,054 images and 4,978 question-answer pairs. To facilitate the evaluation pipeline, we propose CritiqueVLM, a rule-calibrated evaluator that exceeds GPT-4's evaluation ability. Finally, we report the performance of representative VLMs on AlignMMBench, offering insights into the capabilities and limitations of different VLM architectures. All evaluation codes and data are available on https://alignmmbench.github.io.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09353",
        "abstract url": "https://arxiv.org/abs/2406.09353",
        "title": "Enhancing Domain Adaptation through Prompt Gradient Alignment",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Prior Unsupervised Domain Adaptation (UDA) methods often aim to train a domain-invariant feature extractor, which may hinder the model from learning sufficiently discriminative features. To tackle this, a line of works based on prompt learning leverages the power of large-scale pre-trained vision-language models to learn both domain-invariant and specific features through a set of domain-agnostic and domain-specific learnable prompts. Those studies typically enforce invariant constraints on representation, output, or prompt space to learn such prompts. Differently, we cast UDA as a multiple-objective optimization problem in which each objective is represented by a domain loss. Under this new framework, we propose aligning per-objective gradients to foster consensus between them. Additionally, to prevent potential overfitting when fine-tuning this deep learning architecture, we penalize the norm of these gradients. To achieve these goals, we devise a practical gradient update procedure that can work under both single-source and multi-source UDA. Empirically, our method consistently surpasses other prompt-based baselines by a large margin on different UDA benchmarks",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "26 pages, 4 figures, 4 tables"
    },
    {
        "paper id": "2406.09384",
        "abstract url": "https://arxiv.org/abs/2406.09384",
        "title": "Reflecting on the State of Rehearsal-free Continual Learning with Pretrained Models",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "PEFT",
                "efficient finetuning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With the advent and recent ubiquity of foundation models, continual learning (CL) has recently shifted from continual training from scratch to the continual adaptation of pretrained models, seeing particular success on rehearsal-free CL benchmarks (RFCL). To achieve this, most proposed methods adapt and restructure parameter-efficient finetuning techniques (PEFT) to suit the continual nature of the problem. Based most often on input-conditional query-mechanisms or regularizations on top of prompt- or adapter-based PEFT, these PEFT-style RFCL (P-RFCL) approaches report peak performances; often convincingly outperforming existing CL techniques. However, on the other end, critical studies have recently highlighted competitive results by training on just the first task or via simple non-parametric baselines. Consequently, questions arise about the relationship between methodological choices in P-RFCL and their reported high benchmark scores. In this work, we tackle these questions to better understand the true drivers behind strong P-RFCL performances, their placement w.r.t. recent first-task adaptation studies, and their relation to preceding CL standards such as EWC or SI. In particular, we show: (1) P-RFCL techniques relying on input-conditional query mechanisms work not because, but rather despite them by collapsing towards standard PEFT shortcut solutions. (2) Indeed, we show how most often, P-RFCL techniques can be matched by a simple and lightweight PEFT baseline. (3) Using this baseline, we identify the implicit bound on tunable parameters when deriving RFCL approaches from PEFT methods as a potential denominator behind P-RFCL efficacy. Finally, we (4) better disentangle continual versus first-task adaptation, and (5) motivate standard RFCL techniques s.a. EWC or SI in light of recent P-RFCL methods.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "3rd Conference on Lifelong Learning Agents (CoLLAs) 2024"
    },
    {
        "paper id": "2406.09385",
        "abstract url": "https://arxiv.org/abs/2406.09385",
        "title": "Towards Vision-Language Geo-Foundation Model: A Survey",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-Language Foundation Models (VLFMs) have made remarkable progress on various multimodal tasks, such as image captioning, image-text retrieval, visual question answering, and visual grounding. However, most methods rely on training with general image datasets, and the lack of geospatial data leads to poor performance on earth observation. Numerous geospatial image-text pair datasets and VLFMs fine-tuned on them have been proposed recently. These new approaches aim to leverage large-scale, multimodal geospatial data to build versatile intelligent models with diverse geo-perceptive capabilities, which we refer to as Vision-Language Geo-Foundation Models (VLGFMs). This paper thoroughly reviews VLGFMs, summarizing and analyzing recent developments in the field. In particular, we introduce the background and motivation behind the rise of VLGFMs, highlighting their unique research significance. Then, we systematically summarize the core technologies employed in VLGFMs, including data construction, model architectures, and applications of various multimodal geospatial tasks. Finally, we conclude with insights, issues, and discussions regarding future research directions. To the best of our knowledge, this is the first comprehensive literature review of VLGFMs. We keep tracing related works at https://github.com/zytx121/Awesome-VLGFM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 4 figures"
    },
    {
        "paper id": "2406.09396",
        "abstract url": "https://arxiv.org/abs/2406.09396",
        "title": "Too Many Frames, not all Useful:Efficient Strategies for Long-Form Video QA",
        "rating": "2",
        "keywords": [
            [
                "vision language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Long-form videos that span across wide temporal intervals are highly information redundant and contain multiple distinct events or entities that are often loosely-related. Therefore, when performing long-form video question answering (LVQA),all information necessary to generate a correct response can often be contained within a small subset of frames. Recent literature explore the use of large language models (LLMs) in LVQA benchmarks, achieving exceptional performance, while relying on vision language models (VLMs) to convert all visual content within videos into natural language. Such VLMs often independently caption a large number of frames uniformly sampled from long videos, which is not efficient and can mostly be redundant. Questioning these decision choices, we explore optimal strategies for key-frame selection and sequence-aware captioning, that can significantly reduce these redundancies. We propose two novel approaches that improve each of aspects, namely Hierarchical Keyframe Selector and Sequential Visual LLM. Our resulting framework termed LVNet achieves state-of-the-art performance across three benchmark LVQA datasets. Our code will be released publicly.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08859",
        "abstract url": "https://arxiv.org/abs/2406.08859",
        "title": "Fusion of regional and sparse attention in Vision Transformers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Modern vision transformers leverage visually inspired local interaction between pixels through attention computed within window or grid regions, in contrast to the global attention employed in the original ViT. Regional attention restricts pixel interactions within specific regions, while sparse attention disperses them across sparse grids. These differing approaches pose a challenge between maintaining hierarchical relationships vs. capturing a global context. In this study, drawing inspiration from atrous convolution, we propose Atrous Attention, a blend of regional and sparse attention that dynamically integrates both local and global information while preserving hierarchical structures. Based on this, we introduce a versatile, hybrid vision transformer backbone called ACC-ViT, tailored for standard vision tasks. Our compact model achieves approximately 84% accuracy on ImageNet-1K with fewer than 28.5 million parameters, outperforming the state-of-the-art MaxViT by 0.42% while requiring 8.4% fewer parameters.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted as a Workshop Paper at T4V@CVPR2024. arXiv admin note: substantial text overlap with arXiv:2403.04200"
    },
    {
        "paper id": "2406.08904",
        "abstract url": "https://arxiv.org/abs/2406.08904",
        "title": "AdaPTwin: Low-Cost Adaptive Compression of Product Twins in Transformers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "While large transformer-based models have exhibited remarkable performance in speaker-independent speech recognition, their large size and computational requirements make them expensive or impractical to use in resource-constrained settings. In this work, we propose a low-rank adaptive compression technique called AdaPTwin that jointly compresses product-dependent pairs of weight matrices in the transformer attention layer. Our approach can prioritize the compressed model's performance on a specific speaker while maintaining generalizability to new speakers and acoustic conditions. Notably, our technique requires only 8 hours of speech data for fine-tuning, which can be accomplished in under 20 minutes, making it highly cost-effective compared to other compression methods. We demonstrate the efficacy of our approach by compressing the Whisper and Distil-Whisper models by up to 45% while incurring less than a 2% increase in word error rate.",
        "subjects": [
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "12 pages, 3 figures, submitted to NeurIPS 2024"
    },
    {
        "paper id": "2406.08911",
        "abstract url": "https://arxiv.org/abs/2406.08911",
        "title": "An Initial Investigation of Language Adaptation for TTS Systems under Low-resource Scenarios",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Self-supervised learning (SSL) representations from massively multilingual models offer a promising solution for low-resource language speech tasks. Despite advancements, language adaptation in TTS systems remains an open problem. This paper explores the language adaptation capability of ZMM-TTS, a recent SSL-based multilingual TTS system proposed in our previous work. We conducted experiments on 12 languages using limited data with various fine-tuning configurations. We demonstrate that the similarity in phonetics between the pre-training and target languages, as well as the language category, affects the target language's adaptation performance. Additionally, we find that the fine-tuning dataset size and number of speakers influence adaptability. Surprisingly, we also observed that using paired data for fine-tuning is not always optimal compared to audio-only data. Beyond speech intelligibility, our analysis covers speaker similarity, language identification, and predicted MOS.",
        "subjects": [
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Accepted to Interspeech 2024"
    },
    {
        "paper id": "2406.08914",
        "abstract url": "https://arxiv.org/abs/2406.08914",
        "title": "Transcription-Free Fine-Tuning of Speech Separation Models for Noisy and Reverberant Multi-Speaker Automatic Speech Recognition",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "One solution to automatic speech recognition (ASR) of overlapping speakers is to separate speech and then perform ASR on the separated signals. Commonly, the separator produces artefacts which often degrade ASR performance. Addressing this issue typically requires reference transcriptions to jointly train the separation and ASR networks. This is often not viable for training on real-world in-domain audio where reference transcript information is not always available. This paper proposes a transcription-free method for joint training using only audio signals. The proposed method uses embedding differences of pre-trained ASR encoders as a loss with a proposed modification to permutation invariant training (PIT) called guided PIT (GPIT). The method achieves a 6.4% improvement in word error rate (WER) measures over a signal-level loss and also shows enhancement improvements in perceptual measures such as short-time objective intelligibility (STOI).",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "5 pages, 3 Figures, 3 Tables, Accepted for Interspeech 2024"
    },
    {
        "paper id": "2406.09153",
        "abstract url": "https://arxiv.org/abs/2406.09153",
        "title": "LASER: Learning by Aligning Self-supervised Representations of Speech for Improving Content-related Tasks",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Self-supervised learning (SSL)-based speech models are extensively used for full-stack speech processing. However, it has been observed that improving SSL-based speech representations using unlabeled speech for content-related tasks is challenging and computationally expensive. Recent attempts have been made to address this issue with cost-effective self-supervised fine-tuning (SSFT) approaches. Continuing in this direction, a cost-effective SSFT method named \"LASER: Learning by Aligning Self-supervised Representations\" is presented. LASER is based on the soft-DTW alignment loss with temporal regularisation term. Experiments are conducted with HuBERT and WavLM models and evaluated on the SUPERB benchmark for two content-related tasks: automatic speech recognition (ASR) and phoneme recognition (PR). A relative improvement of 3.7% and 8.2% for HuBERT, and 4.1% and 11.7% for WavLM are observed, for the ASR and PR tasks respectively, with only < 3 hours of fine-tuning on a single GPU.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted at Interspeech 2024"
    },
    {
        "paper id": "2406.09196",
        "abstract url": "https://arxiv.org/abs/2406.09196",
        "title": "Adaptive Slot Attention: Object Discovery with Dynamic Slot Number",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Object-centric learning (OCL) extracts the representation of objects with slots, offering an exceptional blend of flexibility and interpretability for abstracting low-level perceptual features. A widely adopted method within OCL is slot attention, which utilizes attention mechanisms to iteratively refine slot representations. However, a major drawback of most object-centric models, including slot attention, is their reliance on predefining the number of slots. This not only necessitates prior knowledge of the dataset but also overlooks the inherent variability in the number of objects present in each instance. To overcome this fundamental limitation, we present a novel complexity-aware object auto-encoder framework. Within this framework, we introduce an adaptive slot attention (AdaSlot) mechanism that dynamically determines the optimal number of slots based on the content of the data. This is achieved by proposing a discrete slot sampling module that is responsible for selecting an appropriate number of slots from a candidate list. Furthermore, we introduce a masked slot decoder that suppresses unselected slots during the decoding process. Our framework, tested extensively on object discovery tasks with various datasets, shows performance matching or exceeding top fixed-slot models. Moreover, our analysis substantiates that our method exhibits the capability to dynamically adapt the slot number according to each instance's complexity, offering the potential for further exploration in slot attention research. Project will be available at https://kfan21.github.io/AdaSlot/",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2406.09200",
        "abstract url": "https://arxiv.org/abs/2406.09200",
        "title": "Orthogonality and isotropy of speaker and phonetic information in self-supervised speech representations",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Self-supervised speech representations can hugely benefit downstream speech technologies, yet the properties that make them useful are still poorly understood. Two candidate properties related to the geometry of the representation space have been hypothesized to correlate well with downstream tasks: (1) the degree of orthogonality between the subspaces spanned by the speaker centroids and phone centroids, and (2) the isotropy of the space, i.e., the degree to which all dimensions are effectively utilized. To study them, we introduce a new measure, Cumulative Residual Variance (CRV), which can be used to assess both properties. Using linear classifiers for speaker and phone ID to probe the representations of six different self-supervised models and two untrained baselines, we ask whether either orthogonality or isotropy correlate with linear probing accuracy. We find that both measures correlate with phonetic probing accuracy, though our results on isotropy are more nuanced.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to Interspeech"
    },
    {
        "paper id": "2406.09290",
        "abstract url": "https://arxiv.org/abs/2406.09290",
        "title": "Exploring Spoken Language Identification Strategies for Automatic Transcription of Multilingual Broadcast and Institutional Speech",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This paper addresses spoken language identification (SLI) and speech recognition of multilingual broadcast and institutional speech, real application scenarios that have been rarely addressed in the SLI literature. Observing that in these domains language changes are mostly associated with speaker changes, we propose a cascaded system consisting of speaker diarization and language identification and compare it with more traditional language identification and language diarization systems. Results show that the proposed system often achieves lower language classification and language diarization error rates (up to 10% relative language diarization error reduction and 60% relative language confusion reduction) and leads to lower WERs on multilingual test sets (more than 8% relative WER reduction), while at the same time does not negatively affect speech recognition on monolingual audio (with an absolute WER increase between 0.1% and 0.7% w.r.t. monolingual ASR).",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.SD"
        ],
        "comment": "Accepted to Interspeech 2024"
    },
    {
        "paper id": "2406.09494",
        "abstract url": "https://arxiv.org/abs/2406.09494",
        "title": "The Second DISPLACE Challenge : DIarization of SPeaker and LAnguage in Conversational Environments",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "The DIarization of SPeaker and LAnguage in Conversational Environments (DISPLACE) 2024 challenge is the second in the series of DISPLACE challenges, which involves tasks of speaker diarization (SD) and language diarization (LD) on a challenging multilingual conversational speech dataset. In the DISPLACE 2024 challenge, we also introduced the task of automatic speech recognition (ASR) on this dataset. The dataset containing 158 hours of speech, consisting of both supervised and unsupervised mono-channel far-field recordings, was released for LD and SD tracks. Further, 12 hours of close-field mono-channel recordings were provided for the ASR track conducted on 5 Indian languages. The details of the dataset, baseline systems and the leader board results are highlighted in this paper. We have also compared our baseline models and the team's performances on evaluation data of DISPLACE-2023 to emphasize the advancements made in this second version of the challenge.",
        "subjects": [
            "eess.AS",
            "cs.LG"
        ],
        "comment": "5 pages, 3 figures, Interspeech 2024"
    },
    {
        "paper id": "2406.09589",
        "abstract url": "https://arxiv.org/abs/2406.09589",
        "title": "Multi-Channel Multi-Speaker ASR Using Target Speaker's Solo Segment",
        "rating": "1.5",
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "In the field of multi-channel, multi-speaker Automatic Speech Recognition (ASR), the task of discerning and accurately transcribing a target speaker's speech within background noise remains a formidable challenge. Traditional approaches often rely on microphone array configurations and the information of the target speaker's location or voiceprint. This study introduces the Solo Spatial Feature (Solo-SF), an innovative method that utilizes a target speaker's isolated speech segment to enhance ASR performance, thereby circumventing the need for conventional inputs like microphone array layouts. We explore effective strategies for selecting optimal solo segments, a crucial aspect for Solo-SF's success. Through evaluations conducted on the AliMeeting dataset and AISHELL-1 simulations, Solo-SF demonstrates superior performance over existing techniques, significantly lowering Character Error Rates (CER) in various test conditions. Our findings highlight Solo-SF's potential as an effective solution for addressing the complexities of multi-channel, multi-speaker ASR tasks.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Accepted for presentation at Interspeech 2024"
    },
    {
        "paper id": "2406.09617",
        "abstract url": "https://arxiv.org/abs/2406.09617",
        "title": "Multimodal Large Language Models with Fusion Low Rank Adaptation for Device Directed Speech Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Although Large Language Models (LLMs) have shown promise for human-like conversations, they are primarily pre-trained on text data. Incorporating audio or video improves performance, but collecting large-scale multimodal data and pre-training multimodal LLMs is challenging. To this end, we propose a Fusion Low Rank Adaptation (FLoRA) technique that efficiently adapts a pre-trained unimodal LLM to consume new, previously unseen modalities via low rank adaptation. For device-directed speech detection, using FLoRA, the multimodal LLM achieves 22% relative reduction in equal error rate (EER) over the text-only approach and attains performance parity with its full fine-tuning (FFT) counterpart while needing to tune only a fraction of its parameters. Furthermore, with the newly introduced adapter dropout, FLoRA is robust to missing data, improving over FFT by 20% lower EER and 56% lower false accept rate. The proposed approach scales well for model sizes from 16M to 3B parameters.",
        "subjects": [
            "cs.CL",
            "cs.HC",
            "eess.AS"
        ],
        "comment": "Accepted at Interspeech 2024"
    },
    {
        "paper id": "2406.09679",
        "abstract url": "https://arxiv.org/abs/2406.09679",
        "title": "Exploring Training on Heterogeneous Data with Mixture of Low-rank Adapters",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Training a unified model to take multiple targets into account is a trend towards artificial general intelligence. However, how to efficiently mitigate the training conflicts among heterogeneous data collected from different domains or tasks remains under-explored. In this study, we explore to leverage Mixture of Low-rank Adapters (MoLA) to mitigate conflicts in heterogeneous data training, which requires to jointly train the multiple low-rank adapters and their shared backbone. Specifically, we introduce two variants of MoLA, namely, MoLA-Grad and MoLA-Router, to respectively handle the target-aware and target-agnostic scenarios during inference. The former uses task identifiers to assign personalized low-rank adapters to each task, disentangling task-specific knowledge towards their adapters, thereby mitigating heterogeneity conflicts. The latter uses a novel Task-wise Decorrelation (TwD) loss to intervene the router to learn oriented weight combinations of adapters to homogeneous tasks, achieving similar effects. We conduct comprehensive experiments to verify the superiority of MoLA over previous state-of-the-art methods and present in-depth analysis on its working mechanism. Source code is available at: https://github.com/MediaBrain-SJTU/MoLA",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICML2024"
    },
    {
        "paper id": "2406.09706",
        "abstract url": "https://arxiv.org/abs/2406.09706",
        "title": "A Multimodal Framework for the Assessment of the Schizophrenia Spectrum",
        "rating": "1.5",
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This paper presents a novel multimodal framework to distinguish between different symptom classes of subjects in the schizophrenia spectrum and healthy controls using audio, video, and text modalities. We implemented Convolution Neural Network and Long Short Term Memory based unimodal models and experimented on various multimodal fusion approaches to come up with the proposed framework. We utilized a minimal Gated multimodal unit (mGMU) to obtain a bi-modal intermediate fusion of the features extracted from the input modalities before finally fusing the outputs of the bimodal fusions to perform subject-wise classifications. The use of mGMU units in the multimodal framework improved the performance in both weighted f1-score and weighted AUC-ROC scores.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Accepted to be presented at Interspeech 2024"
    },
    {
        "paper id": "2406.08809",
        "abstract url": "https://arxiv.org/abs/2406.08809",
        "title": "Are we there yet? A brief survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Deep learning models for music have advanced drastically in the last few years. But how good are machine learning models at capturing emotion these days and what challenges are researchers facing? In this paper, we provide a comprehensive overview of the available music-emotion datasets and discuss evaluation standards as well as competitions in the field. We also provide a brief overview of various types of music emotion prediction models that have been built over the years, offering insights into the diverse approaches within the field. Through this examination, we highlight the challenges that persist in accurately capturing emotion in music. Recognizing the dynamic nature of this field, we have complemented our findings with an accompanying GitHub repository. This repository contains a comprehensive list of music emotion datasets and recent predictive models.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08811",
        "abstract url": "https://arxiv.org/abs/2406.08811",
        "title": "Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are typically fine-tuned on diverse and extensive datasets sourced from various origins to develop a comprehensive range of skills, such as writing, reasoning, chatting, coding, and more. Each skill has unique characteristics, and these datasets are often heterogeneous and imbalanced, making the fine-tuning process highly challenging. Balancing the development of each skill while ensuring the model maintains its overall performance requires sophisticated techniques and careful dataset curation. In this work, we propose a general, model-agnostic, reinforcement learning framework, Mixture-of-Skills (MoS), that learns to optimize data usage automatically during the fine-tuning process. This framework ensures the optimal comprehensive skill development of LLMs by dynamically adjusting the focus on different datasets based on their current learning state. To validate the effectiveness of MoS, we conduct extensive experiments using three diverse LLM backbones on two widely used benchmarks and demonstrate that MoS substantially enhances model performance. Building on the success of MoS, we propose MoSpec, an adaptation for task-specific fine-tuning, which harnesses the utilities of various datasets for a specific purpose. Our work underlines the significance of dataset rebalancing and present MoS as a powerful, general solution for optimizing data usage in the fine-tuning of LLMs for various purposes.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in progress; 15 pages, 7 tables, 4 figures"
    },
    {
        "paper id": "2406.08814",
        "abstract url": "https://arxiv.org/abs/2406.08814",
        "title": "Skim then Focus: Integrating Contextual and Fine-grained Views for Repetitive Action Counting",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The key to action counting is accurately locating each video's repetitive actions. Instead of estimating the probability of each frame belonging to an action directly, we propose a dual-branch network, i.e., SkimFocusNet, working in a two-step manner. The model draws inspiration from empirical observations indicating that humans typically engage in coarse skimming of entire sequences to grasp the general action pattern initially, followed by a finer, frame-by-frame focus to determine if it aligns with the target action. Specifically, SkimFocusNet incorporates a skim branch and a focus branch. The skim branch scans the global contextual information throughout the sequence to identify potential target action for guidance. Subsequently, the focus branch utilizes the guidance to diligently identify repetitive actions using a long-short adaptive guidance (LSAG) block. Additionally, we have observed that videos in existing datasets often feature only one type of repetitive action, which inadequately represents real-world scenarios. To more accurately describe real-life situations, we establish the Multi-RepCount dataset, which includes videos containing multiple repetitive motions. On Multi-RepCount, our SkimFoucsNet can perform specified action counting, that is, to enable counting a particular action type by referencing an exemplary video. This capability substantially exhibits the robustness of our method. Extensive experiments demonstrate that SkimFocusNet achieves state-of-the-art performances with significant improvements. We also conduct a thorough ablation study to evaluate the network components. The source code will be published upon acceptance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2406.08818",
        "abstract url": "https://arxiv.org/abs/2406.08818",
        "title": "Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "We present a large-scale study of linguistic bias exhibited by ChatGPT covering ten dialects of English (Standard American English, Standard British English, and eight widely spoken non-\"standard\" varieties from around the world). We prompted GPT-3.5 Turbo and GPT-4 with text by native speakers of each variety and analyzed the responses via detailed linguistic feature annotation and native speaker evaluation. We find that the models default to \"standard\" varieties of English; based on evaluation by native speakers, we also find that model responses to non-\"standard\" varieties consistently exhibit a range of issues: lack of comprehension (10% worse compared to \"standard\" varieties), stereotyping (16% worse), demeaning content (22% worse), and condescending responses (12% worse). We also find that if these models are asked to imitate the writing style of prompts in non-\"standard\" varieties, they produce text that exhibits lower comprehension of the input and is especially prone to stereotyping. GPT-4 improves on GPT-3.5 in terms of comprehension, warmth, and friendliness, but it also results in a marked increase in stereotyping (+17%). The results suggest that GPT-3.5 Turbo and GPT-4 exhibit linguistic discrimination in ways that can exacerbate harms for speakers of non-\"standard\" varieties.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08822",
        "abstract url": "https://arxiv.org/abs/2406.08822",
        "title": "Computer vision-based model for detecting turning lane features on Florida's public roadways",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Efficient and current roadway geometry data collection is critical to transportation agencies in road planning, maintenance, design, and rehabilitation. Data collection methods are divided into land-based and aerial-based. Land-based methods for extensive highway networks are tedious, costly, pose safety risks. Therefore, there is the need for efficient, safe, and economical data acquisition methodologies. The rise of computer vision and object detection technologies have made automated extraction of roadway geometry features feasible. This study detects roadway features on Florida's public roads from high-resolution aerial images using AI. The developed model achieved an average accuracy of 80.4 percent when compared with ground truth data. The extracted roadway geometry data can be integrated with crash and traffic data to provide valuable insights to policymakers and roadway users.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08835",
        "abstract url": "https://arxiv.org/abs/2406.08835",
        "title": "A Single-Step Non-Autoregressive Automatic Speech Recognition Architecture with High Accuracy and Inference Speed",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Non-autoregressive (NAR) automatic speech recognition (ASR) models predict tokens independently and simultaneously, bringing high inference speed. However, there is still a gap in the accuracy of the NAR models compared to the autoregressive (AR) models. To further narrow the gap between the NAR and AR models, we propose a single-step NAR ASR architecture with high accuracy and inference speed, called EfficientASR. It uses an Index Mapping Vector (IMV) based alignment generator to generate alignments during training, and an alignment predictor to learn the alignments for inference. It can be trained end-to-end (E2E) with cross-entropy loss combined with alignment loss. The proposed EfficientASR achieves competitive results on the AISHELL-1 and AISHELL-2 benchmarks compared to the state-of-the-art (SOTA) models. Specifically, it achieves character error rates (CER) of 4.26%/4.62% on the AISHELL-1 dev/test dataset, which outperforms the SOTA AR Conformer with about 30x inference speedup.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08838",
        "abstract url": "https://arxiv.org/abs/2406.08838",
        "title": "Research on Optimization of Natural Language Processing Model Based on Multimodal Deep Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This project intends to study the image representation based on attention mechanism and multimodal data. By adding multiple pattern layers to the attribute model, the semantic and hidden layers of image content are integrated. The word vector is quantified by the Word2Vec method and then evaluated by a word embedding convolutional neural network. The published experimental results of the two groups were tested. The experimental results show that this method can convert discrete features into continuous characters, thus reducing the complexity of feature preprocessing. Word2Vec and natural language processing technology are integrated to achieve the goal of direct evaluation of missing image features. The robustness of the image feature evaluation model is improved by using the excellent feature analysis characteristics of a convolutional neural network. This project intends to improve the existing image feature identification methods and eliminate the subjective influence in the evaluation process. The findings from the simulation indicate that the novel approach has developed is viable, effectively augmenting the features within the produced representations.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08847",
        "abstract url": "https://arxiv.org/abs/2406.08847",
        "title": "Roping in Uncertainty: Robustness and Regularization in Markov Games",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "We study robust Markov games (RMG) with $s$-rectangular uncertainty. We show a general equivalence between computing a robust Nash equilibrium (RNE) of a $s$-rectangular RMG and computing a Nash equilibrium (NE) of an appropriately constructed regularized MG. The equivalence result yields a planning algorithm for solving $s$-rectangular RMGs, as well as provable robustness guarantees for policies computed using regularized methods. However, we show that even for just reward-uncertain two-player zero-sum matrix games, computing an RNE is PPAD-hard. Consequently, we derive a special uncertainty structure called efficient player-decomposability and show that RNE for two-player zero-sum RMG in this class can be provably solved in polynomial time. This class includes commonly used uncertainty sets such as $L_1$ and $L_\\infty$ ball uncertainty sets.",
        "subjects": [
            "cs.GT",
            "cs.DS",
            "cs.LG"
        ],
        "comment": "Accepted to ICML 2024"
    },
    {
        "paper id": "2406.08848",
        "abstract url": "https://arxiv.org/abs/2406.08848",
        "title": "An Approach to Build Zero-Shot Slot-Filling System for Industry-Grade Conversational Assistants",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We present an approach to build Large Language Model (LLM) based slot-filling system to perform Dialogue State Tracking in conversational assistants serving across a wide variety of industry-grade applications. Key requirements of this system include: 1) usage of smaller-sized models to meet low latency requirements and to enable convenient and cost-effective cloud and customer premise deployments, and 2) zero-shot capabilities to serve across a wide variety of domains, slot types and conversational scenarios. We adopt a fine-tuning approach where a pre-trained LLM is fine-tuned into a slot-filling model using task specific data. The fine-tuning data is prepared carefully to cover a wide variety of slot-filling task scenarios that the model is expected to face across various domains. We give details of the data preparation and model building process. We also give a detailed analysis of the results of our experimental evaluations. Results show that our prescribed approach for slot-filling model building has resulted in 6.9% relative improvement of F1 metric over the best baseline on a realistic benchmark, while at the same time reducing the latency by 57%. More over, the data we prepared has helped improve F1 on an average by 4.2% relative across various slot-types.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08850",
        "abstract url": "https://arxiv.org/abs/2406.08850",
        "title": "COVE: Unleashing the Diffusion Feature Correspondence for Consistent Video Editing",
        "rating": "1",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "Diffusion",
                "Video Editing",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video editing is an emerging task, in which most current methods adopt the pre-trained text-to-image (T2I) diffusion model to edit the source video in a zero-shot manner. Despite extensive efforts, maintaining the temporal consistency of edited videos remains challenging due to the lack of temporal constraints in the regular T2I diffusion model. To address this issue, we propose COrrespondence-guided Video Editing (COVE), leveraging the inherent diffusion feature correspondence to achieve high-quality and consistent video editing. Specifically, we propose an efficient sliding-window-based strategy to calculate the similarity among tokens in the diffusion features of source videos, identifying the tokens with high correspondence across frames. During the inversion and denoising process, we sample the tokens in noisy latent based on the correspondence and then perform self-attention within them. To save GPU memory usage and accelerate the editing process, we further introduce the temporal-dimensional token merging strategy, which can effectively reduce redundancy. COVE can be seamlessly integrated into the pre-trained T2I diffusion model without the need for extra training or optimization. Extensive experiment results demonstrate that COVE achieves the start-of-the-art performance in various video editing scenarios, outperforming existing methods both quantitatively and qualitatively. The code will be release at https://github.com/wangjiangshan0725/COVE",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08858",
        "abstract url": "https://arxiv.org/abs/2406.08858",
        "title": "OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present OmniH2O (Omni Human-to-Humanoid), a learning-based system for whole-body humanoid teleoperation and autonomy. Using kinematic pose as a universal control interface, OmniH2O enables various ways for a human to control a full-sized humanoid with dexterous hands, including using real-time teleoperation through VR headset, verbal instruction, and RGB camera. OmniH2O also enables full autonomy by learning from teleoperated demonstrations or integrating with frontier models such as GPT-4. OmniH2O demonstrates versatility and dexterity in various real-world whole-body tasks through teleoperation or autonomy, such as playing multiple sports, moving and manipulating objects, and interacting with humans. We develop an RL-based sim-to-real pipeline, which involves large-scale retargeting and augmentation of human motion datasets, learning a real-world deployable policy with sparse sensor input by imitating a privileged teacher policy, and reward designs to enhance robustness and stability. We release the first humanoid whole-body control dataset, OmniH2O-6, containing six everyday tasks, and demonstrate humanoid whole-body skill learning from teleoperated datasets.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Project page: https://omni.human2humanoid.com/"
    },
    {
        "paper id": "2406.08860",
        "abstract url": "https://arxiv.org/abs/2406.08860",
        "title": "Plan, Generate and Complicate: Improving Low-resource Dialogue State Tracking via Easy-to-Difficult Zero-shot Data Augmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Data augmentation methods have been a promising direction to improve the performance of small models for low-resource dialogue state tracking. However, traditional methods rely on pre-defined user goals and neglect the importance of data complexity in this task. In this paper, we propose EDZ-DA, an Easy-to-Difficult Zero-shot Data Augmentation framework for low-resource dialogue state tracking that utilizes large language models to automatically catch the relationships of different domains and then generate the dialogue data. We also complicate the dialogues based on the domain relation to enhance the model's capability for co-reference slot tracking. Furthermore, we permute slot values to mitigate the influence of output orders and the problem of incomplete value generation. Experimental results illustrate the superiority of our proposed method compared to previous strong data augmentation baselines on MultiWOZ.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ACL 2024 Findings"
    },
    {
        "paper id": "2406.08866",
        "abstract url": "https://arxiv.org/abs/2406.08866",
        "title": "Zoom and Shift are All You Need",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Feature alignment serves as the primary mechanism for fusing multimodal data. We put forth a feature alignment approach that achieves full integration of multimodal information. This is accomplished via an alternating process of shifting and expanding feature representations across modalities to obtain a consistent unified representation in a joint feature space. The proposed technique can reliably capture high-level interplay between features originating from distinct modalities. Consequently, substantial gains in multimodal learning performance are attained. Additionally, we demonstrate the superiority of our approach over other prevalent multimodal fusion schemes on a range of tasks. Extensive experimental evaluation conducted on multimodal datasets comprising time series, image, and text demonstrates that our method achieves state-of-the-art results.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2406.08877",
        "abstract url": "https://arxiv.org/abs/2406.08877",
        "title": "EgoExo-Fitness: Towards Egocentric and Exocentric Full-Body Action Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present EgoExo-Fitness, a new full-body action understanding dataset, featuring fitness sequence videos recorded from synchronized egocentric and fixed exocentric (third-person) cameras. Compared with existing full-body action understanding datasets, EgoExo-Fitness not only contains videos from first-person perspectives, but also provides rich annotations. Specifically, two-level temporal boundaries are provided to localize single action videos along with sub-steps of each action. More importantly, EgoExo-Fitness introduces innovative annotations for interpretable action judgement--including technical keypoint verification, natural language comments on action execution, and action quality scores. Combining all of these, EgoExo-Fitness provides new resources to study egocentric and exocentric full-body action understanding across dimensions of \"what\", \"when\", and \"how well\". To facilitate research on egocentric and exocentric full-body action understanding, we construct benchmarks on a suite of tasks (i.e., action classification, action localization, cross-view sequence verification, cross-view skill determination, and a newly proposed task of guidance-based execution verification), together with detailed analysis. Code and data will be available at https://github.com/iSEE-Laboratory/EgoExo-Fitness/tree/main.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "33 pages, 9 figures"
    },
    {
        "paper id": "2406.08900",
        "abstract url": "https://arxiv.org/abs/2406.08900",
        "title": "On Improving Error Resilience of Neural End-to-End Speech Coders",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Error resilient tools like Packet Loss Concealment (PLC) and Forward Error Correction (FEC) are essential to maintain a reliable speech communication for applications like Voice over Internet Protocol (VoIP), where packets are frequently delayed and lost. In recent times, end-to-end neural speech codecs have seen a significant rise, due to their ability to transmit speech signal at low bitrates but few considerations were made about their error resilience in a real system. Recently introduced Neural End-to-End Speech Codec (NESC) can reproduce high quality natural speech at low bitrates. We extend its robustness to packet losses by adding a low complexity network to predict the codebook indices in latent space. Furthermore, we propose a method to add an in-band FEC at an additional bitrate of 0.8 kbps. Both subjective and objective assessment indicate the effectiveness of proposed methods, and demonstrate that coupling PLC and FEC provide significant robustness against packet losses.",
        "subjects": [
            "eess.AS",
            "cs.SD",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08918",
        "abstract url": "https://arxiv.org/abs/2406.08918",
        "title": "Beyond the Calibration Point: Mechanism Comparison in Differential Privacy",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In differentially private (DP) machine learning, the privacy guarantees of DP mechanisms are often reported and compared on the basis of a single $(\\varepsilon, \u03b4)$-pair. This practice overlooks that DP guarantees can vary substantially \\emph{even between mechanisms sharing a given $(\\varepsilon, \u03b4)$}, and potentially introduces privacy vulnerabilities which can remain undetected. This motivates the need for robust, rigorous methods for comparing DP guarantees in such cases. Here, we introduce the $\u0394$-divergence between mechanisms which quantifies the worst-case excess privacy vulnerability of choosing one mechanism over another in terms of $(\\varepsilon, \u03b4)$, $f$-DP and in terms of a newly presented Bayesian interpretation. Moreover, as a generalisation of the Blackwell theorem, it is endowed with strong decision-theoretic foundations. Through application examples, we show that our techniques can facilitate informed decision-making and reveal gaps in the current understanding of privacy risks, as current practices in DP-SGD often result in choosing mechanisms with high excess privacy vulnerabilities.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2406.08922",
        "abstract url": "https://arxiv.org/abs/2406.08922",
        "title": "Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "With the launch of ChatGPT, large language models (LLMs) have attracted global attention. In the realm of article writing, LLMs have witnessed extensive utilization, giving rise to concerns related to intellectual property protection, personal privacy, and academic integrity. In response, AI-text detection has emerged to distinguish between human and machine-generated content. However, recent research indicates that these detection systems often lack robustness and struggle to effectively differentiate perturbed texts. Currently, there is a lack of systematic evaluations regarding detection performance in real-world applications, and a comprehensive examination of perturbation techniques and detector robustness is also absent. To bridge this gap, our work simulates real-world scenarios in both informal and professional writing, exploring the out-of-the-box performance of current detectors. Additionally, we have constructed 12 black-box text perturbation methods to assess the robustness of current detection models across various perturbation granularities. Furthermore, through adversarial learning experiments, we investigate the impact of perturbation data augmentation on the robustness of AI-text detectors. We have released our code and data at https://github.com/zhouying20/ai-text-detector-evaluation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted by ACL 2024, Main Conference"
    },
    {
        "paper id": "2406.08924",
        "abstract url": "https://arxiv.org/abs/2406.08924",
        "title": "Learning Images Across Scales Using Adversarial Training",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The real world exhibits rich structure and detail across many scales of observation. It is difficult, however, to capture and represent a broad spectrum of scales using ordinary images. We devise a novel paradigm for learning a representation that captures an orders-of-magnitude variety of scales from an unstructured collection of ordinary images. We treat this collection as a distribution of scale-space slices to be learned using adversarial training, and additionally enforce coherency across slices. Our approach relies on a multiscale generator with carefully injected procedural frequency content, which allows to interactively explore the emerging continuous scale space. Training across vastly different scales poses challenges regarding stability, which we tackle using a supervision scheme that involves careful sampling of scales. We show that our generator can be used as a multiscale generative model, and for reconstructions of scale spaces from unstructured patches. Significantly outperforming the state of the art, we demonstrate zoom-in factors of up to 256x at high quality and scale consistency.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "SIGGRAPH 2024; project page: https://scalespacegan.mpi-inf.mpg.de/"
    },
    {
        "paper id": "2406.08931",
        "abstract url": "https://arxiv.org/abs/2406.08931",
        "title": "Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Advent of modern deep learning techniques has given rise to advancements in the field of Speech Emotion Recognition (SER). However, most systems prevalent in the field fail to generalize to speakers not seen during training. This study focuses on handling challenges of multilingual SER, specifically on unseen speakers. We introduce CAMuLeNet, a novel architecture leveraging co-attention based fusion and multitask learning to address this problem. Additionally, we benchmark pretrained encoders of Whisper, HuBERT, Wav2Vec2.0, and WavLM using 10-fold leave-speaker-out cross-validation on five existing multilingual benchmark datasets: IEMOCAP, RAVDESS, CREMA-D, EmoDB and CaFE and, release a novel dataset for SER on the Hindi language (BhavVani). CAMuLeNet shows an average improvement of approximately 8% over all benchmarks on unseen speakers determined by our cross-validation strategy.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "5 pages, Accepted to INTERSPEECH 2024"
    },
    {
        "paper id": "2406.08957",
        "abstract url": "https://arxiv.org/abs/2406.08957",
        "title": "Tool Wear Prediction in CNC Turning Operations using Ultrasonic Microphone Arrays and CNNs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces a novel method for predicting tool wear in CNC turning operations, combining ultrasonic microphone arrays and convolutional neural networks (CNNs). High-frequency acoustic emissions between 0 kHz and 60 kHz are enhanced using beamforming techniques to improve the signal- to-noise ratio. The processed acoustic data is then analyzed by a CNN, which predicts the Remaining Useful Life (RUL) of cutting tools. Trained on data from 350 workpieces machined with a single carbide insert, the model can accurately predict the RUL of the carbide insert. Our results demonstrate the potential gained by integrating advanced ultrasonic sensors with deep learning for accurate predictive maintenance tasks in CNC machining.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08974",
        "abstract url": "https://arxiv.org/abs/2406.08974",
        "title": "Cascaded noise reduction and acoustic echo cancellation based on an extended noise reduction",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In many speech recording applications, the recorded desired speech is corrupted by both noise and acoustic echo, such that combined noise reduction (NR) and acoustic echo cancellation (AEC) is called for. A common cascaded design corresponds to NR filters preceding AEC filters. These NR filters aim at reducing the near-end room noise (and possibly partially the echo) and operate on the microphones only, consequently requiring the AEC filters to model both the echo paths and the NR filters. In this paper, however, we propose a design with extended NR (NRext) filters preceding AEC filters under the assumption of the echo paths being additive maps, thus preserving the addition operation. Here, the NRext filters aim at reducing both the near-end room noise and the far-end room noise component in the echo, and operate on both the microphones and loudspeakers. We show that the succeeding AEC filters remarkably become independent of the NRext filters, such that the AEC filters are only required to model the echo paths, improving the AEC performance. Further, the degrees of freedom in the NRext filters scale with the number of loudspeakers, which is not the case for the NR filters, resulting in an improved NR performance.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted for publication in EUSIPCO 2024"
    },
    {
        "paper id": "2406.08979",
        "abstract url": "https://arxiv.org/abs/2406.08979",
        "title": "Multi-Agent Software Development through Cross-Team Collaboration",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The latest breakthroughs in Large Language Models (LLMs), eg., ChatDev, have catalyzed profound transformations, particularly through multi-agent collaboration for software development. LLM agents can collaborate in teams like humans, and follow the waterfall model to sequentially work on requirements analysis, development, review, testing, and other phases to perform autonomous software generation. However, for an agent team, each phase in a single development process yields only one possible outcome. This results in the completion of only one development chain, thereby losing the opportunity to explore multiple potential decision paths within the solution space. Consequently, this may lead to obtaining suboptimal results. To address this challenge, we introduce Cross-Team Collaboration (CTC), a scalable multi-team framework that enables orchestrated teams to jointly propose various decisions and communicate with their insights in a cross-team collaboration environment for superior content generation. Experimental results in software development reveal a notable increase in quality compared to state-of-the-art baselines, underscoring the efficacy of our framework. The significant improvements in story generation demonstrate the promising generalization ability of our framework across various domains. We anticipate that our work will guide LLM agents towards a cross-team paradigm and contribute to their significant growth in but not limited to software development. The code and data will be available at https://github.com/OpenBMB/ChatDev.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.MA",
            "cs.SE"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2406.09003",
        "abstract url": "https://arxiv.org/abs/2406.09003",
        "title": "Enhancing Cross-Modal Fine-Tuning with Gradually Intermediate Modality Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale pretrained models have proven immensely valuable in handling data-intensive modalities like text and image. However, fine-tuning these models for certain specialized modalities, such as protein sequence and cosmic ray, poses challenges due to the significant modality discrepancy and scarcity of labeled data. In this paper, we propose an end-to-end method, PaRe, to enhance cross-modal fine-tuning, aiming to transfer a large-scale pretrained model to various target modalities. PaRe employs a gating mechanism to select key patches from both source and target data. Through a modality-agnostic Patch Replacement scheme, these patches are preserved and combined to construct data-rich intermediate modalities ranging from easy to hard. By gradually intermediate modality generation, we can not only effectively bridge the modality gap to enhance stability and transferability of cross-modal fine-tuning, but also address the challenge of limited data in the target modality by leveraging enriched intermediate modality data. Compared with hand-designed, general-purpose, task-specific, and state-of-the-art cross-modal fine-tuning approaches, PaRe demonstrates superior performance across three challenging benchmarks, encompassing more than ten modalities.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09008",
        "abstract url": "https://arxiv.org/abs/2406.09008",
        "title": "LLM Reading Tea Leaves: Automatically Evaluating Topic Models with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Topic modeling has been a widely used tool for unsupervised text analysis. However, comprehensive evaluations of a topic model remain challenging. Existing evaluation methods are either less comparable across different models (e.g., perplexity) or focus on only one specific aspect of a model (e.g., topic quality or document representation quality) at a time, which is insufficient to reflect the overall model performance. In this paper, we propose WALM (Words Agreement with Language Model), a new evaluation method for topic modeling that comprehensively considers the semantic quality of document representations and topics in a joint manner, leveraging the power of large language models (LLMs). With extensive experiments involving different types of topic models, WALM is shown to align with human judgment and can serve as a complementary evaluation method to the existing ones, bringing a new perspective to topic modeling. Our software package will be available at https://github.com/Xiaohao-Yang/Topic_Model_Evaluation, which can be integrated with many widely used topic models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09012",
        "abstract url": "https://arxiv.org/abs/2406.09012",
        "title": "Bayesian Statistical Modeling with Predictors from LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "State of the art large language models (LLMs) have shown impressive performance on a variety of benchmark tasks and are increasingly used as components in larger applications, where LLM-based predictions serve as proxies for human judgements or decision. This raises questions about the human-likeness of LLM-derived information, alignment with human intuition, and whether LLMs could possibly be considered (parts of) explanatory models of (aspects of) human cognition or language use. To shed more light on these issues, we here investigate the human-likeness of LLMs' predictions for multiple-choice decision tasks from the perspective of Bayesian statistical modeling. Using human data from a forced-choice experiment on pragmatic language use, we find that LLMs do not capture the variance in the human data at the item-level. We suggest different ways of deriving full distributional predictions from LLMs for aggregate, condition-level data, and find that some, but not all ways of obtaining condition-level predictions yield adequate fits to human data. These results suggests that assessment of LLM performance depends strongly on seemingly subtle choices in methodology, and that LLMs are at best predictors of human behavior at the aggregate, condition-level, for which they are, however, not designed to, or usually used to, make predictions in the first place.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "20 pages, 10 figures, parallel submission to a journal"
    },
    {
        "paper id": "2406.09015",
        "abstract url": "https://arxiv.org/abs/2406.09015",
        "title": "AMSA-UNet: An Asymmetric Multiple Scales U-net Based on Self-attention for Deblurring",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The traditional ingle-scale U-Net often leads to the loss of spatial information during deblurring, which affects the deblurring accracy. Additionally, due to the convolutional method's limitation in capturing long-range dependencies, the quality of the recovered image is degraded. To address the above problems, an asymmetric multiple scales U-net based on self-attention (AMSA-UNet) is proposed to improve the accuracy and computational complexity. By introducing a multiple-scales U shape architecture, the network can focus on blurry regions at the global level and better recover image details at the local level. In order to overcome the limitations of traditional convolutional methods in capturing the long-range dependencies of information, a self-attention mechanism is introduced into the decoder part of the backbone network, which significantly increases the model's receptive field, enabling it to pay more attention to semantic information of the image, thereby producing more accurate and visually pleasing deblurred images. What's more, a frequency domain-based computation method was introduced to reduces the computation amount. The experimental results demonstrate that the proposed method exhibits significant improvements in both accuracy and speed compared to eight excellent methods",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15pages, 6figures"
    },
    {
        "paper id": "2406.09041",
        "abstract url": "https://arxiv.org/abs/2406.09041",
        "title": "ME-Switch: A Memory-Efficient Expert Switching Framework for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The typical process for developing LLMs involves pre-training a general foundation model on massive data, followed by fine-tuning on task-specific data to create specialized experts. Serving these experts poses challenges, as loading all experts onto devices is impractical, and frequent switching between experts in response to user requests incurs substantial I/O costs, increasing latency and expenses. Previous approaches decompose expert weights into pre-trained model weights and residual delta weights, then quantize the delta weights to reduce model size. However, these methods often lead to significant quantization errors at extremely low bitwidths and assume the appropriate model for a user request is known in advance, which is not practical. To address these issues, we introduce ME-Switch, a memory-efficient expert switching framework for LLM serving. ME-Switch uses mixed-precision quantization, selectively quantizing non-salient input channels of delta weights to extremely low bits while keeping salient ones intact, significantly reducing storage demands while maintaining performance. Additionally, we develop a routing method that efficiently directs user queries to the most suitable expert by transforming the model selection problem into a domain classification problem. Extensive experiments show ME-Switch's promising memory efficiency and routing performance. For example, when serving three models from the Mistral-7B family, ME-Switch reduces model size by 1.74x while maintaining nearly lossless performance on instruction, mathematical reasoning, and code generation tasks. Furthermore, ME-Switch can efficiently serve 16 models from the Mistral-7B family on a single NVIDIA A100 GPU.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Tech report"
    },
    {
        "paper id": "2406.09043",
        "abstract url": "https://arxiv.org/abs/2406.09043",
        "title": "Language Models are Crossword Solvers",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Crosswords are a form of word puzzle that require a solver to demonstrate a high degree of proficiency in natural language understanding, wordplay, reasoning, and world knowledge, along with adherence to character and length constraints. In this paper we tackle the challenge of solving crosswords with Large Language Models (LLMs). We demonstrate that the current generation of state-of-the art (SoTA) language models show significant competence at deciphering cryptic crossword clues, and outperform previously reported SoTA results by a factor of 2-3 in relevant benchmarks. We also develop a search algorithm that builds off this performance to tackle the problem of solving full crossword grids with LLMs for the very first time, achieving an accuracy of 93\\% on New York Times crossword puzzles. Contrary to previous work in this area which concluded that LLMs lag human expert performance significantly, our research suggests this gap is a lot narrower.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09056",
        "abstract url": "https://arxiv.org/abs/2406.09056",
        "title": "CUDRT: Benchmarking the Detection of Human vs. Large Language Models Generated Texts",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The proliferation of large language models (LLMs) has significantly enhanced text generation capabilities across various industries. However, these models' ability to generate human-like text poses substantial challenges in discerning between human and AI authorship. Despite the effectiveness of existing AI-generated text detectors, their development is hindered by the lack of comprehensive, publicly available benchmarks. Current benchmarks are limited to specific scenarios, such as question answering and text polishing, and predominantly focus on English texts, failing to capture the diverse applications and linguistic nuances of LLMs. To address these limitations, this paper constructs a comprehensive bilingual benchmark in both Chinese and English to evaluate mainstream AI-generated text detectors. We categorize LLM text generation into five distinct operations: Create, Update, Delete, Rewrite, and Translate (CUDRT), encompassing all current LLMs activities. We also establish a robust benchmark evaluation framework to support scalable and reproducible experiments. For each CUDRT category, we have developed extensive datasets to thoroughly assess detector performance. By employing the latest mainstream LLMs specific to each language, our datasets provide a thorough evaluation environment. Extensive experimental results offer critical insights for optimizing AI-generated text detectors and suggest future research directions to improve detection accuracy and generalizability across various scenarios.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "32 pages"
    },
    {
        "paper id": "2406.09072",
        "abstract url": "https://arxiv.org/abs/2406.09072",
        "title": "Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Temporal reasoning is fundamental for large language models (LLMs) to comprehend the world. Current temporal reasoning datasets are limited to questions about single or isolated events, falling short in mirroring the realistic temporal characteristics involving concurrent nature and intricate temporal interconnections. In this paper, we introduce CoTempQA, a comprehensive co-temporal Question Answering (QA) benchmark containing four co-temporal scenarios (Equal, Overlap, During, Mix) with 4,748 samples for evaluating the co-temporal comprehension and reasoning abilities of LLMs. Our extensive experiments reveal a significant gap between the performance of current LLMs and human-level reasoning on CoTempQA tasks. Even when enhanced with Chain of Thought (CoT) methodologies, models consistently struggle with our task. In our preliminary exploration, we discovered that mathematical reasoning plays a significant role in handling co-temporal events and proposed a strategy to boost LLMs' co-temporal reasoning from a mathematical perspective. We hope that our CoTempQA datasets will encourage further advancements in improving the co-temporal reasoning capabilities of LLMs. Our code is available at https://github.com/zhaochen0110/Cotempqa.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper has been accepted to the ACL 2024 main conference"
    },
    {
        "paper id": "2406.09076",
        "abstract url": "https://arxiv.org/abs/2406.09076",
        "title": "3M: Multi-modal Multi-task Multi-teacher Learning for Game Event Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Esports has rapidly emerged as a global phenomenon with an ever-expanding audience via platforms, like YouTube. Due to the inherent complexity nature of the game, it is challenging for newcomers to comprehend what the event entails. The chaotic nature of online chat, the fast-paced speech of the game commentator, and the game-specific user interface further compound the difficulty for users in comprehending the gameplay. To overcome these challenges, it is crucial to integrate the Multi-Modal (MM) information from the platform and understand the event. The paper introduces a new MM multi-teacher-based game event detection framework, with the ultimate goal of constructing a comprehensive framework that enhances the comprehension of the ongoing game situation. While conventional MM models typically prioritise aligning MM data through concurrent training towards a unified objective, our framework leverages multiple teachers trained independently on different tasks to accomplish the Game Event Detection. The experiment clearly shows the effectiveness of the proposed MM multi-teacher framework.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09087",
        "abstract url": "https://arxiv.org/abs/2406.09087",
        "title": "Suitability of KANs for Computer Vision: A preliminary investigation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Kolmogorov-Arnold Networks (KANs) introduce a paradigm of neural modeling that implements learnable functions on the edges of the networks, diverging from the traditional node-centric activations in neural networks. This work assesses the applicability and efficacy of KANs in visual modeling, focusing on the image recognition task. We mainly analyze the performance and efficiency of different network architectures built using KAN concepts along with conventional building blocks of convolutional and linear layers, enabling a comparative analysis with the conventional models. Our findings are aimed at contributing to understanding the potential of KANs in computer vision, highlighting both their strengths and areas for further research. Our evaluation shows that whereas KAN-based architectures perform in-line with the original claims of KAN paper for performance and model-complexity in the case of simpler vision datasets like MNIST, the advantages seem to diminish even for slightly more complex datasets like CIFAR-10.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09095",
        "abstract url": "https://arxiv.org/abs/2406.09095",
        "title": "Modeling Comparative Logical Relation with Contrastive Learning for Text Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Data-to-Text Generation (D2T), a classic natural language generation problem, aims at producing fluent descriptions for structured input data, such as a table. Existing D2T works mainly focus on describing the superficial associative relations among entities, while ignoring the deep comparative logical relations, such as A is better than B in a certain aspect with a corresponding opinion, which is quite common in our daily life. In this paper, we introduce a new D2T task named comparative logical relation generation (CLRG). Additionally, we propose a Comparative Logic (CoLo) based text generation method, which generates texts following specific comparative logical relations with contrastive learning. Specifically, we first construct various positive and negative samples by fine-grained perturbations in entities, aspects and opinions. Then, we perform contrastive learning in the encoder layer to have a better understanding of the comparative logical relations, and integrate it in the decoder layer to guide the model to correctly generate the relations. Noting the data scarcity problem, we construct a Chinese Comparative Logical Relation Dataset (CLRD), which is a high-quality human-annotated dataset and challenging for text generation with descriptions of multiple entities and annotations on their comparative logical relations. Extensive experiments show that our method achieves impressive performance in both automatic and human evaluations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09112",
        "abstract url": "https://arxiv.org/abs/2406.09112",
        "title": "Large-Scale Evaluation of Open-Set Image Classification Techniques",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The goal for classification is to correctly assign labels to unseen samples. However, most methods misclassify samples with unseen labels and assign them to one of the known classes. Open-Set Classification (OSC) algorithms aim to maximize both closed and open-set recognition capabilities. Recent studies showed the utility of such algorithms on small-scale data sets, but limited experimentation makes it difficult to assess their performances in real-world problems. Here, we provide a comprehensive comparison of various OSC algorithms, including training-based (SoftMax, Garbage, EOS) and post-processing methods (Maximum SoftMax Scores, Maximum Logit Scores, OpenMax, EVM, PROSER), the latter are applied on features from the former. We perform our evaluation on three large-scale protocols that mimic real-world challenges, where we train on known and negative open-set samples, and test on known and unknown instances. Our results show that EOS helps to improve performance of almost all post-processing algorithms. Particularly, OpenMax and PROSER are able to exploit better-trained networks, demonstrating the utility of hybrid models. However, while most algorithms work well on negative test samples -- samples of open-set classes seen during training -- they tend to perform poorly when tested on samples of previously unseen unknown classes, especially in challenging conditions.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09128",
        "abstract url": "https://arxiv.org/abs/2406.09128",
        "title": "CoastTerm: a Corpus for Multidisciplinary Term Extraction in Coastal Scientific Literature",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The growing impact of climate change on coastal areas, particularly active but fragile regions, necessitates collaboration among diverse stakeholders and disciplines to formulate effective environmental protection policies. We introduce a novel specialized corpus comprising 2,491 sentences from 410 scientific abstracts concerning coastal areas, for the Automatic Term Extraction (ATE) and Classification (ATC) tasks. Inspired by the ARDI framework, focused on the identification of Actors, Resources, Dynamics and Interactions, we automatically extract domain terms and their distinct roles in the functioning of coastal systems by leveraging monolingual and multilingual transformer models. The evaluation demonstrates consistent results, achieving an F1 score of approximately 80\\% for automated term extraction and F1 of 70\\% for extracting terms and their labels. These findings are promising and signify an initial step towards the development of a specialized Knowledge Base dedicated to coastal areas.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09133",
        "abstract url": "https://arxiv.org/abs/2406.09133",
        "title": "RH-SQL: Refined Schema and Hardness Prompt for Text-to-SQL",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Text-to-SQL is a technology that converts natural language queries into the structured query language SQL. A novel research approach that has recently gained attention focuses on methods based on the complexity of SQL queries, achieving notable performance improvements. However, existing methods entail significant storage and training costs, which hampers their practical application. To address this issue, this paper introduces a method for Text-to-SQL based on Refined Schema and Hardness Prompt. By filtering out low-relevance schema information with a refined schema and identifying query hardness through a Language Model (LM) to form prompts, this method reduces storage and training costs while maintaining performance. It's worth mentioning that this method is applicable to any sequence-to-sequence (seq2seq) LM. Our experiments on the Spider dataset, specifically with large-scale LMs, achieved an exceptional Execution accuracy (EX) of 82.6%, demonstrating the effectiveness and greater suitability of our method for real-world applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "4 pages, 2 figures, 2024 6th International Conference on Electronic Engineering and Informatics (EEI 2024)"
    },
    {
        "paper id": "2406.09136",
        "abstract url": "https://arxiv.org/abs/2406.09136",
        "title": "Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The recent development of chain-of-thought (CoT) decoding has enabled large language models (LLMs) to generate explicit logical reasoning paths for complex problem-solving. However, research indicates that these paths are not always deliberate and optimal. The tree-of-thought (ToT) method employs tree-searching to extensively explore the reasoning space and find better reasoning paths that CoT decoding might overlook. This deliberation, however, comes at the cost of significantly increased inference complexity. In this work, we demonstrate that fine-tuning LLMs leveraging the search tree constructed by ToT allows CoT to achieve similar or better performance, thereby avoiding the substantial inference burden. This is achieved through Chain of Preference Optimization (CPO), where LLMs are fine-tuned to align each step of the CoT reasoning paths with those of ToT using the inherent preference information in the tree-search process. Extensive experimental results show that CPO significantly improves LLM performance in solving a variety of complex problems, including question answering, fact verification, and arithmetic reasoning, demonstrating its effectiveness. Our code is available at https://github.com/sail-sg/CPO.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09137",
        "abstract url": "https://arxiv.org/abs/2406.09137",
        "title": "Dynamic Correlation Clustering in Sublinear Update Time",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "We study the classic problem of correlation clustering in dynamic node streams. In this setting, nodes are either added or randomly deleted over time, and each node pair is connected by a positive or negative edge. The objective is to continuously find a partition which minimizes the sum of positive edges crossing clusters and negative edges within clusters. We present an algorithm that maintains an $O(1)$-approximation with $O$(polylog $n$) amortized update time. Prior to our work, Behnezhad, Charikar, Ma, and L. Tan achieved a $5$-approximation with $O(1)$ expected update time in edge streams which translates in node streams to an $O(D)$-update time where $D$ is the maximum possible degree. Finally we complement our theoretical analysis with experiments on real world data.",
        "subjects": [
            "cs.DS",
            "cs.LG"
        ],
        "comment": "ICML'24 (spotlight)"
    },
    {
        "paper id": "2406.09138",
        "abstract url": "https://arxiv.org/abs/2406.09138",
        "title": "Leveraging Explicit Reasoning for Inference Integration in Commonsense-Augmented Dialogue Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Open-domain dialogue systems need to grasp social commonsense to understand and respond effectively to human users. Commonsense-augmented dialogue models have been proposed that aim to infer commonsense knowledge from dialogue contexts in order to improve response quality. However, existing approaches to commonsense-augmented dialogue rely on implicit reasoning to integrate commonsense inferences during response generation. In this study, we explore the impact of explicit reasoning against implicit reasoning over commonsense for dialogue response generation. Our findings demonstrate that separating commonsense reasoning into explicit steps for generating, selecting, and integrating commonsense into responses leads to better dialogue interactions, improving naturalness, engagement, specificity, and overall quality. Subsequent analyses of these findings unveil insights into the effectiveness of various types of commonsense in generating responses and the particular response traits enhanced through explicit reasoning for commonsense integration. Our work advances research in open-domain dialogue by achieving a new state-of-the-art in commonsense-augmented response generation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09140",
        "abstract url": "https://arxiv.org/abs/2406.09140",
        "title": "Investigating the translation capabilities of Large Language Models trained on parallel data only",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, Large Language Models (LLMs) have demonstrated exceptional proficiency across a broad spectrum of Natural Language Processing (NLP) tasks, including Machine Translation. However, previous methods predominantly relied on iterative processes such as instruction fine-tuning or continual pre-training, leaving unexplored the challenges of training LLMs solely on parallel data. In this work, we introduce PLUME (Parallel Language Model), a collection of three 2B LLMs featuring varying vocabulary sizes (32k, 128k, and 256k) trained exclusively on Catalan-centric parallel examples. These models perform comparably to previous encoder-decoder architectures on 16 supervised translation directions and 56 zero-shot ones. Utilizing this set of models, we conduct a thorough investigation into the translation capabilities of LLMs, probing their performance, the impact of the different elements of the prompt, and their cross-lingual representation space.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "We release our code at: https://github.com/projecte-aina/Plume"
    },
    {
        "paper id": "2406.09155",
        "abstract url": "https://arxiv.org/abs/2406.09155",
        "title": "DefAn: Definitive Answer Dataset for LLMs Hallucination Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities, revolutionizing the integration of AI in daily life applications. However, they are prone to hallucinations, generating claims that contradict established facts, deviating from prompts, and producing inconsistent responses when the same prompt is presented multiple times. Addressing these issues is challenging due to the lack of comprehensive and easily assessable benchmark datasets. Most existing datasets are small and rely on multiple-choice questions, which are inadequate for evaluating the generative prowess of LLMs. To measure hallucination in LLMs, this paper introduces a comprehensive benchmark dataset comprising over 75,000 prompts across eight domains. These prompts are designed to elicit definitive, concise, and informative answers. The dataset is divided into two segments: one publicly available for testing and assessing LLM performance and a hidden segment for benchmarking various LLMs. In our experiments, we tested six LLMs-GPT-3.5, LLama 2, LLama 3, Gemini, Mixtral, and Zephyr-revealing that overall factual hallucination ranges from 59% to 82% on the public dataset and 57% to 76% in the hidden benchmark. Prompt misalignment hallucination ranges from 6% to 95% in the public dataset and 17% to 94% in the hidden counterpart. Average consistency ranges from 21% to 61% and 22% to 63%, respectively. Domain-wise analysis shows that LLM performance significantly deteriorates when asked for specific numeric information while performing moderately with person, location, and date queries. Our dataset demonstrates its efficacy and serves as a comprehensive benchmark for LLM performance evaluation. Our dataset and LLMs responses are available at \\href{https://github.com/ashikiut/DefAn}{https://github.com/ashikiut/DefAn}.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09166",
        "abstract url": "https://arxiv.org/abs/2406.09166",
        "title": "Fine-Grained Domain Generalization with Feature Structuralization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Fine-grained domain generalization (FGDG) is a more challenging task due to its small inter-class variations and relatively large intra-class disparities. When domain distribution changes, the fragility of subtle features leads to a pronounced deterioration in model performance.Nevertheless, humans inherently demonstrate the capacity for generalizing to out-of-distribution data, leveraging structured multi-granularity knowledge that emerges from discerning both the commonality and specificity within categories.Likewise, we propose a Feature Structuralized Domain Generalization (FSDG) model, wherein features experience structuralization into common, specific, and confounding segments, harmoniously aligned with their relevant semantic concepts, to elevate performance in FGDG. Specifically, feature structuralization (FS) is achieved through a decorrelation function on disentangled segments, constraints on common feature consistency, specific feature distinctiveness, and a prediction calibration operation across granularities. By imposing these stipulations, FSDG is prompted to disentangle and align features based on multi-granularity knowledge, facilitating robust subtle distinctions among categories. Extensive experimentation on three benchmarks consistently validates the superiority of FSDG over state-of-the-art counterparts, with an average improvement of 6.1% in terms of FGDG performance. Beyond that, the explainability analysis and experiments on various mainstream model architectures confirm the validity of FS.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09167",
        "abstract url": "https://arxiv.org/abs/2406.09167",
        "title": "Vision Transformer Segmentation for Visual Bird Sound Denoising",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Audio denoising, especially in the context of bird sounds, remains a challenging task due to persistent residual noise. Traditional and deep learning methods often struggle with artificial or low-frequency noise. In this work, we propose ViTVS, a novel approach that leverages the power of the vision transformer (ViT) architecture. ViTVS adeptly combines segmentation techniques to disentangle clean audio from complex signal mixtures. Our key contributions encompass the development of ViTVS, introducing comprehensive, long-range, and multi-scale representations. These contributions directly tackle the limitations inherent in conventional approaches. Extensive experiments demonstrate that ViTVS outperforms state-of-the-art methods, positioning it as a benchmark solution for real-world bird sound denoising applications. Source code is available at: https://github.com/aiai-4/ViVTS.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "INTERSPEECH 2024"
    },
    {
        "paper id": "2406.09170",
        "abstract url": "https://arxiv.org/abs/2406.09170",
        "title": "Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have showcased remarkable reasoning capabilities, yet they remain susceptible to errors, particularly in temporal reasoning tasks involving complex temporal logic. Existing research has explored LLM performance on temporal reasoning using diverse datasets and benchmarks. However, these studies often rely on real-world data that LLMs may have encountered during pre-training or employ anonymization techniques that can inadvertently introduce factual inconsistencies. In this work, we address these limitations by introducing novel synthetic datasets specifically designed to assess LLM temporal reasoning abilities in various scenarios. The diversity of question types across these datasets enables systematic investigation into the impact of the problem structure, size, question type, fact order, and other factors on LLM performance. Our findings provide valuable insights into the strengths and weaknesses of current LLMs in temporal reasoning tasks. To foster further research in this area, we are open-sourcing the datasets and evaluation framework used in our experiments: https://huggingface.co/datasets/baharef/ToT.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09188",
        "abstract url": "https://arxiv.org/abs/2406.09188",
        "title": "Reducing Task Discrepancy of Text Encoders for Zero-Shot Composed Image Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Composed Image Retrieval (CIR) aims to retrieve a target image based on a reference image and conditioning text, enabling controllable searches. Due to the expensive dataset construction cost for CIR triplets, a zero-shot (ZS) CIR setting has been actively studied to eliminate the need for human-collected triplet datasets. The mainstream of ZS-CIR employs an efficient projection module that projects a CLIP image embedding to the CLIP text token embedding space, while fixing the CLIP encoders. Using the projected image embedding, these methods generate image-text composed features by using the pre-trained text encoder. However, their CLIP image and text encoders suffer from the task discrepancy between the pre-training task (text $\\leftrightarrow$ image) and the target CIR task (image + text $\\leftrightarrow$ image). Conceptually, we need expensive triplet samples to reduce the discrepancy, but we use cheap text triplets instead and update the text encoder. To that end, we introduce the Reducing Task Discrepancy of text encoders for Composed Image Retrieval (RTD), a plug-and-play training scheme for the text encoder that enhances its capability using a novel target-anchored text contrastive learning. We also propose two additional techniques to improve the proposed learning scheme: a hard negatives-based refined batch sampling strategy and a sophisticated concatenation scheme. Integrating RTD into the state-of-the-art projection-based ZS-CIR methods significantly improves performance across various datasets and backbones, demonstrating its efficiency and generalizability.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2406.09198",
        "abstract url": "https://arxiv.org/abs/2406.09198",
        "title": "CLIP-Driven Cloth-Agnostic Feature Learning for Cloth-Changing Person Re-Identification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Contrastive Language-Image Pre-Training (CLIP) has shown impressive performance in short-term Person Re-Identification (ReID) due to its ability to extract high-level semantic features of pedestrians, yet its direct application to Cloth-Changing Person Re-Identification (CC-ReID) faces challenges due to CLIP's image encoder overly focusing on clothes clues. To address this, we propose a novel framework called CLIP-Driven Cloth-Agnostic Feature Learning (CCAF) for CC-ReID. Accordingly, two modules were custom-designed: the Invariant Feature Prompting (IFP) and the Clothes Feature Minimization (CFM). These modules guide the model to extract cloth-agnostic features positively and attenuate clothes-related features negatively. Specifically, IFP is designed to extract fine-grained semantic features unrelated to clothes from the raw image, guided by the cloth-agnostic text prompts. This module first covers the clothes in the raw image at the pixel level to obtain the shielding image and then utilizes CLIP's knowledge to generate cloth-agnostic text prompts. Subsequently, it aligns the raw image-text and the raw image-shielding image in the feature space, emphasizing discriminative clues related to identity but unrelated to clothes. Furthermore, CFM is designed to examine and weaken the image encoder's ability to extract clothes features. It first generates text prompts corresponding to clothes pixels. Then, guided by these clothes text prompts, it iteratively examines and disentangles clothes features from pedestrian features, ultimately retaining inherent discriminative features. Extensive experiments have demonstrated the effectiveness of the proposed CCAF, achieving new state-of-the-art performance on several popular CC-ReID benchmarks without any additional inference time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09201",
        "abstract url": "https://arxiv.org/abs/2406.09201",
        "title": "Enhanced Object Detection: A Study on Vast Vocabulary Object Detection Track for V3Det Challenge 2024",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this technical report, we present our findings from the research conducted on the Vast Vocabulary Visual Detection (V3Det) dataset for Supervised Vast Vocabulary Visual Detection task. How to deal with complex categories and detection boxes has become a difficulty in this track. The original supervised detector is not suitable for this task. We have designed a series of improvements, including adjustments to the network structure, changes to the loss function, and design of training strategies. Our model has shown improvement over the baseline and achieved excellent rankings on the Leaderboard for both the Vast Vocabulary Object Detection (Supervised) track and the Open Vocabulary Object Detection (OVD) track of the V3Det Challenge 2024.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09202",
        "abstract url": "https://arxiv.org/abs/2406.09202",
        "title": "Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn't",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We investigate what linguistic factors affect the performance of Automatic Speech Recognition (ASR) models. We hypothesize that orthographic and phonological complexities both degrade accuracy. To examine this, we fine-tune the multilingual self-supervised pretrained model Wav2Vec2-XLSR-53 on 25 languages with 15 writing systems, and we compare their ASR accuracy, number of graphemes, unigram grapheme entropy, logographicity (how much word/morpheme-level information is encoded in the writing system), and number of phonemes. The results demonstrate that orthographic complexities significantly correlate with low ASR accuracy, while phonological complexity shows no significant correlation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "11 pages, 5 figures, 5 tables, submitted to ACL 2024"
    },
    {
        "paper id": "2406.09205",
        "abstract url": "https://arxiv.org/abs/2406.09205",
        "title": "ReadCtrl: Personalizing text generation with readability-controlled instruction learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Content generation conditioning on users's readability is an important application for personalization. In an era of large language models (LLMs), readability-controlled text generation based on LLMs has become increasingly important. This paper introduces a novel methodology called \"Readability-Controlled Instruction Learning (ReadCtrl),\" which aims to instruction-tune LLMs to tailor users' readability levels. Unlike the traditional methods, which primarily focused on categorical readability adjustments typically classified as high, medium, and low or expert and layperson levels with limited success, ReadCtrl introduces a dynamic framework that enables LLMs to generate content at various (near continuous level) complexity levels, thereby enhancing their versatility across different applications. Our results show that the ReadCtrl-Mistral-7B models significantly outperformed strong baseline models such as GPT-4 and Claude-3, with a win rate of 52.1%:35.7% against GPT-4 in human evaluations. Furthermore, Read-Ctrl has shown significant improvements in automatic evaluations, as evidenced by better readability metrics (e.g., FOG, FKGL) and generation quality metrics (e.g., BLEU, SARI, SummaC-Factuality, UniEval-Consistency and Coherence). These results underscore Read-Ctrl's effectiveness and tenacity in producing high-quality, contextually appropriate outputs that closely align with targeted readability levels, marking a significant advancement in personalized content generation using LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2406.09206",
        "abstract url": "https://arxiv.org/abs/2406.09206",
        "title": "Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Active learning is an iterative labeling process that is used to obtain a small labeled subset, despite the absence of labeled data, thereby enabling to train a model for supervised tasks such as text classification. While active learning has made considerable progress in recent years due to improvements provided by pre-trained language models, there is untapped potential in the often neglected unlabeled portion of the data, although it is available in considerably larger quantities than the usually small set of labeled data. Here we investigate how self-training, a semi-supervised approach where a model is used to obtain pseudo-labels from the unlabeled data, can be used to improve the efficiency of active learning for text classification. Starting with an extensive reproduction of four previous self-training approaches, some of which are evaluated for the first time in the context of active learning or natural language processing, we devise HAST, a new and effective self-training strategy, which is evaluated on four text classification benchmarks, on which it outperforms the reproduced self-training approaches and reaches classification results comparable to previous experiments for three out of four datasets, using only 25% of the data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09211",
        "abstract url": "https://arxiv.org/abs/2406.09211",
        "title": "WildlifeReID-10k: Wildlife re-identification dataset with 10k individual animals",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a new wildlife re-identification dataset WildlifeReID-10k with more than 214k images of 10k individual animals. It is a collection of 30 existing wildlife re-identification datasets with additional processing steps. WildlifeReID-10k contains animals as diverse as marine turtles, primates, birds, African herbivores, marine mammals and domestic animals. Due to the ubiquity of similar images in datasets, we argue that the standard (random) splits into training and testing sets are inadequate for wildlife re-identification and propose a new similarity-aware split based on the similarity of extracted features. To promote fair method comparison, we include similarity-aware splits both for closed-set and open-set settings, use MegaDescriptor - a foundational model for wildlife re-identification - for baseline performance and host a leaderboard with the best results. We publicly publish the dataset and the codes used to create it in the wildlife-datasets library, making WildlifeReID-10k both highly curated and easy to use.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09229",
        "abstract url": "https://arxiv.org/abs/2406.09229",
        "title": "MGRQ: Post-Training Quantization For Vision Transformer With Mixed Granularity Reconstruction",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Post-training quantization (PTQ) efficiently compresses vision models, but unfortunately, it accompanies a certain degree of accuracy degradation. Reconstruction methods aim to enhance model performance by narrowing the gap between the quantized model and the full-precision model, often yielding promising results. However, efforts to significantly improve the performance of PTQ through reconstruction in the Vision Transformer (ViT) have shown limited efficacy. In this paper, we conduct a thorough analysis of the reasons for this limited effectiveness and propose MGRQ (Mixed Granularity Reconstruction Quantization) as a solution to address this issue. Unlike previous reconstruction schemes, MGRQ introduces a mixed granularity reconstruction approach. Specifically, MGRQ enhances the performance of PTQ by introducing Extra-Block Global Supervision and Intra-Block Local Supervision, building upon Optimized Block-wise Reconstruction. Extra-Block Global Supervision considers the relationship between block outputs and the model's output, aiding block-wise reconstruction through global supervision. Meanwhile, Intra-Block Local Supervision reduces generalization errors by aligning the distribution of outputs at each layer within a block. Subsequently, MGRQ is further optimized for reconstruction through Mixed Granularity Loss Fusion. Extensive experiments conducted on various ViT models illustrate the effectiveness of MGRQ. Notably, MGRQ demonstrates robust performance in low-bit quantization, thereby enhancing the practicality of the quantized model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by 2024 IEEE International Conference on Image Processing"
    },
    {
        "paper id": "2406.09240",
        "abstract url": "https://arxiv.org/abs/2406.09240",
        "title": "Comparison Visual Instruction Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Comparing two images in terms of Commonalities and Differences (CaD) is a fundamental human capability that forms the basis of advanced visual reasoning and interpretation. It is essential for the generation of detailed and contextually relevant descriptions, performing comparative analysis, novelty detection, and making informed decisions based on visual data. However, surprisingly, little attention has been given to these fundamental concepts in the best current mimic of human visual intelligence - Large Multimodal Models (LMMs). We develop and contribute a new two-phase approach CaD-VI for collecting synthetic visual instructions, together with an instruction-following dataset CaD-Inst containing 349K image pairs with CaD instructions collected using CaD-VI. Our approach significantly improves the CaD spotting capabilities in LMMs, advancing the SOTA on a diverse set of related tasks by up to 17.5%. It is also complementary to existing difference-only instruction datasets, allowing automatic targeted refinement of those resources increasing their effectiveness for CaD tuning by up to 10%. Additionally, we propose an evaluation benchmark with 7.5K open-ended QAs to assess the CaD understanding abilities of LMMs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://wlin-at.github.io/cad_vi ; Huggingface dataset repo: https://huggingface.co/datasets/wlin21at/CaD-Inst"
    },
    {
        "paper id": "2406.09241",
        "abstract url": "https://arxiv.org/abs/2406.09241",
        "title": "What is the long-run distribution of stochastic gradient descent? A large deviations analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In this paper, we examine the long-run distribution of stochastic gradient descent (SGD) in general, non-convex problems. Specifically, we seek to understand which regions of the problem's state space are more likely to be visited by SGD, and by how much. Using an approach based on the theory of large deviations and randomly perturbed dynamical systems, we show that the long-run distribution of SGD resembles the Boltzmann-Gibbs distribution of equilibrium thermodynamics with temperature equal to the method's step-size and energy levels determined by the problem's objective and the statistics of the noise. In particular, we show that, in the long run, (a) the problem's critical region is visited exponentially more often than any non-critical region; (b) the iterates of SGD are exponentially concentrated around the problem's minimum energy state (which does not always coincide with the global minimum of the objective); (c) all other connected components of critical points are visited with frequency that is exponentially proportional to their energy level; and, finally (d) any component of local maximizers or saddle points is \"dominated\" by a component of local minimizers which is visited exponentially more often.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "comment": "70 pages, 3 figures; to be published in the proceedings of ICML 2024"
    },
    {
        "paper id": "2406.09257",
        "abstract url": "https://arxiv.org/abs/2406.09257",
        "title": "Assessing Model Generalization in Vicinity",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper evaluates the generalization ability of classification models on out-of-distribution test sets without depending on ground truth labels. Common approaches often calculate an unsupervised metric related to a specific model property, like confidence or invariance, which correlates with out-of-distribution accuracy. However, these metrics are typically computed for each test sample individually, leading to potential issues caused by spurious model responses, such as overly high or low confidence. To tackle this challenge, we propose incorporating responses from neighboring test samples into the correctness assessment of each individual sample. In essence, if a model consistently demonstrates high correctness scores for nearby samples, it increases the likelihood of correctly predicting the target sample, and vice versa. The resulting scores are then averaged across all test samples to provide a holistic indication of model accuracy. Developed under the vicinal risk formulation, this approach, named vicinal risk proxy (VRP), computes accuracy without relying on labels. We show that applying the VRP method to existing generalization indicators, such as average confidence and effective invariance, consistently improves over these baselines both methodologically and experimentally. This yields a stronger correlation with model accuracy, especially on challenging out-of-distribution test sets.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09264",
        "abstract url": "https://arxiv.org/abs/2406.09264",
        "title": "Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in general-purpose AI have highlighted the importance of guiding AI systems towards the intended goals, ethical principles, and values of individuals and groups, a concept broadly recognized as alignment. However, the lack of clarified definitions and scopes of human-AI alignment poses a significant obstacle, hampering collaborative efforts across research domains to achieve this alignment. In particular, ML- and philosophy-oriented alignment research often views AI alignment as a static, unidirectional process (i.e., aiming to ensure that AI systems' objectives match humans) rather than an ongoing, mutual alignment problem [429]. This perspective largely neglects the long-term interaction and dynamic changes of alignment. To understand these gaps, we introduce a systematic review of over 400 papers published between 2019 and January 2024, spanning multiple domains such as Human-Computer Interaction (HCI), Natural Language Processing (NLP), Machine Learning (ML), and others. We characterize, define and scope human-AI alignment. From this, we present a conceptual framework of \"Bidirectional Human-AI Alignment\" to organize the literature from a human-centered perspective. This framework encompasses both 1) conventional studies of aligning AI to humans that ensures AI produces the intended outcomes determined by humans, and 2) a proposed concept of aligning humans to AI, which aims to help individuals and society adjust to AI advancements both cognitively and behaviorally. Additionally, we articulate the key findings derived from literature analysis, including discussions about human values, interaction techniques, and evaluations. To pave the way for future studies, we envision three key challenges for future directions and propose examples of potential future solutions.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "56 pages"
    },
    {
        "paper id": "2406.09265",
        "abstract url": "https://arxiv.org/abs/2406.09265",
        "title": "Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multilingual large language models (LLMs) have greatly increased the ceiling of performance on non-English tasks. However the mechanisms behind multilingualism in these LLMs are poorly understood. Of particular interest is the degree to which internal representations are shared between languages. Recent work on neuron analysis of LLMs has focused on the monolingual case, and the limited work on the multilingual case has not considered the interaction between tasks and linguistic representations. In our work, we investigate how neuron activation is shared across languages by categorizing neurons into four distinct groups according to their responses across different languages for a particular input: all-shared, partial-shared, specific, and non-activated. This categorization is combined with a study of neuron attribution, i.e. the importance of a neuron w.r.t an output. Our analysis reveals the following insights: (i) the linguistic sharing patterns are strongly affected by the type of task, but neuron behaviour changes across different inputs even for the same task; (ii) all-shared neurons play a key role in generating correct responses; (iii) boosting multilingual alignment by increasing all-shared neurons can enhance accuracy on multilingual tasks. The code is available at https://github.com/weixuan-wang123/multilingual-neurons.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09272",
        "abstract url": "https://arxiv.org/abs/2406.09272",
        "title": "Action2Sound: Ambient-Aware Generation of Action Sounds from Egocentric Videos",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Generating realistic audio for human interactions is important for many applications, such as creating sound effects for films or virtual reality games. Existing approaches implicitly assume total correspondence between the video and audio during training, yet many sounds happen off-screen and have weak to no correspondence with the visuals -- resulting in uncontrolled ambient sounds or hallucinations at test time. We propose a novel ambient-aware audio generation model, AV-LDM. We devise a novel audio-conditioning mechanism to learn to disentangle foreground action sounds from the ambient background sounds in in-the-wild training videos. Given a novel silent video, our model uses retrieval-augmented generation to create audio that matches the visual content both semantically and temporally. We train and evaluate our model on two in-the-wild egocentric video datasets Ego4D and EPIC-KITCHENS. Our model outperforms an array of existing methods, allows controllable generation of the ambient sound, and even shows promise for generalizing to computer graphics game clips. Overall, our work is the first to focus video-to-audio generation faithfully on the observed visual content despite training from uncurated clips with natural background sounds.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Project page: https://vision.cs.utexas.edu/projects/action2sound"
    },
    {
        "paper id": "2406.09277",
        "abstract url": "https://arxiv.org/abs/2406.09277",
        "title": "End-to-end Streaming model for Low-Latency Speech Anonymization",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Speaker anonymization aims to conceal cues to speaker identity while preserving linguistic content. Current machine learning based approaches require substantial computational resources, hindering real-time streaming applications. To address these concerns, we propose a streaming model that achieves speaker anonymization with low latency. The system is trained in an end-to-end autoencoder fashion using a lightweight content encoder that extracts HuBERT-like information, a pretrained speaker encoder that extract speaker identity, and a variance encoder that injects pitch and energy information. These three disentangled representations are fed to a decoder that resynthesizes the speech signal. We present evaluation results from two implementations of our system, a full model that achieves a latency of 230ms, and a lite version (0.1x in size) that further reduces latency to 66ms while maintaining state-of-the-art performance in naturalness, intelligibility, and privacy preservation.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09279",
        "abstract url": "https://arxiv.org/abs/2406.09279",
        "title": "Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Learning from preference feedback has emerged as an essential step for improving the generation quality and performance of modern language models (LMs). Despite its widespread use, the way preference-based learning is applied varies wildly, with differing data, learning algorithms, and evaluations used, making disentangling the impact of each aspect difficult. In this work, we identify four core aspects of preference-based learning: preference data, learning algorithm, reward model, and policy training prompts, systematically investigate the impact of these components on downstream model performance, and suggest a recipe for strong learning for preference feedback. Our findings indicate that all aspects are important for performance, with better preference data leading to the largest improvements, followed by the choice of learning algorithm, the use of improved reward models, and finally the use of additional unlabeled prompts for policy training. Notably, PPO outperforms DPO by up to 2.5% in math and 1.2% in general domains. High-quality preference data leads to improvements of up to 8% in instruction following and truthfulness. Despite significant gains of up to 5% in mathematical evaluation when scaling up reward models, we surprisingly observe marginal improvements in other categories. We publicly release the code used for training (https://github.com/hamishivi/EasyLM) and evaluating (https://github.com/allenai/open-instruct) our models, along with the models and datasets themselves (https://huggingface.co/collections/allenai/tulu-v25-suite-66676520fd578080e126f618).",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2406.09282",
        "abstract url": "https://arxiv.org/abs/2406.09282",
        "title": "On the Effects of Heterogeneous Data Sources on Speech-to-Text Foundation Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The Open Whisper-style Speech Model (OWSM) series was introduced to achieve full transparency in building advanced speech-to-text (S2T) foundation models. To this end, OWSM models are trained on 25 public speech datasets, which are heterogeneous in multiple ways. In this study, we advance the OWSM series by introducing OWSM v3.2, which improves on prior models by investigating and addressing the impacts of this data heterogeneity. Our study begins with a detailed analysis of each dataset, from which we derive two key strategies: data filtering with proxy task to enhance data quality, and the incorporation of punctuation and true-casing using an open large language model (LLM). With all other configurations staying the same, OWSM v3.2 improves performance over the OWSM v3.1 baseline while using 15% less training data.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09286",
        "abstract url": "https://arxiv.org/abs/2406.09286",
        "title": "FlowAVSE: Efficient Audio-Visual Speech Enhancement with Conditional Flow Matching",
        "rating": "1",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "diffusion"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This work proposes an efficient method to enhance the quality of corrupted speech signals by leveraging both acoustic and visual cues. While existing diffusion-based approaches have demonstrated remarkable quality, their applicability is limited by slow inference speeds and computational complexity. To address this issue, we present FlowAVSE which enhances the inference speed and reduces the number of learnable parameters without degrading the output quality. In particular, we employ a conditional flow matching algorithm that enables the generation of high-quality speech in a single sampling step. Moreover, we increase efficiency by optimizing the underlying U-net architecture of diffusion-based systems. Our experiments demonstrate that FlowAVSE achieves 22 times faster inference speed and reduces the model size by half while maintaining the output quality. The demo page is available at: https://cyongong.github.io/FlowAVSE.github.io/",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "INTERSPEECH 2024"
    },
    {
        "paper id": "2406.09289",
        "abstract url": "https://arxiv.org/abs/2406.09289",
        "title": "Understanding Jailbreak Success: A Study of Latent Space Dynamics in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Conversational Large Language Models are trained to refuse to answer harmful questions. However, emergent jailbreaking techniques can still elicit unsafe outputs, presenting an ongoing challenge for model alignment. To better understand how different jailbreak types circumvent safeguards, this paper analyses model activations on different jailbreak inputs. We find that it is possible to extract a jailbreak vector from a single class of jailbreaks that works to mitigate jailbreak effectiveness from other classes. This may indicate that different kinds of effective jailbreaks operate via similar internal mechanisms. We investigate a potential common mechanism of harmfulness feature suppression, and provide evidence for its existence by looking at the harmfulness vector component. These findings offer actionable insights for developing more robust jailbreak countermeasures and lay the groundwork for a deeper, mechanistic understanding of jailbreak dynamics in language models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09294",
        "abstract url": "https://arxiv.org/abs/2406.09294",
        "title": "You Don't Need Data-Augmentation in Self-Supervised Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Self-Supervised learning (SSL) with Joint-Embedding Architectures (JEA) has led to outstanding performances. All instantiations of this paradigm were trained using strong and well-established hand-crafted data augmentations, leading to the general belief that they are required for the proper training and performance of such models. On the other hand, generative reconstruction-based models such as BEIT and MAE or Joint-Embedding Predictive Architectures such as I-JEPA have shown strong performance without using data augmentations except masking. In this work, we challenge the importance of invariance and data-augmentation in JEAs at scale. By running a case-study on a recent SSL foundation model - DINOv2 - we show that strong image representations can be obtained with JEAs and only cropping without resizing provided the training data is large enough, reaching state-of-the-art results and using the least amount of augmentation in the literature. Through this study, we also discuss the impact of compute constraints on the outcomes of experimental deep learning research, showing that they can lead to very different conclusions.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09315",
        "abstract url": "https://arxiv.org/abs/2406.09315",
        "title": "Vertical LoRA: Dense Expectation-Maximization Interpretation of Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we show how Transformers can be interpreted as dense Expectation-Maximization algorithms performed on Bayesian Nets. Based on the above interpretation, we propose a new model design paradigm, namely Vertical LoRA (VLoRA), which reduces the parameter count dramatically while preserving performance. In VLoRA, a model consists of layers, each of which recursively learns an increment based on the previous layer. We then apply LoRA decomposition to the increments. VLoRA works on the base model, which is orthogonal to LoRA, meaning they can be used together. We do experiments on various tasks and models. The results show that 1) with VLoRA, the Transformer model parameter count can be reduced dramatically and 2) the performance of the original model is preserved. The source code is available at \\url{https://github.com/neverUseThisName/vlora}",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09320",
        "abstract url": "https://arxiv.org/abs/2406.09320",
        "title": "Khmer Semantic Search Engine: Digital Information Access and Document Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The search engine process is crucial for document content retrieval. For Khmer documents, a tool is needed to extract essential keywords. Despite the daily generation of significant Khmer content, Cambodians struggle to find necessary documents due to the lack of an effective semantic searching tool. Even Google does not deliver high accuracy for Khmer content. Semantic search engines improve search results by employing advanced algorithms to understand various content types. With the rise in Khmer digital content such as reports, articles, and social media feedback enhanced search capabilities are essential. This research proposes the first Khmer Semantic Search Engine (KSE), designed to improve traditional Khmer search methods. Utilizing semantic matching techniques and formally annotated semantic content, our tool extracts meaningful keywords from user queries performs precise matching, and provides the best matching offline documents and online URL documents. We propose two semantic search frameworks based on keyword extraction and semantic search matching. Additionally, we developed tools for data preparation, including document addition and manual keyword extraction. To evaluate performance, we created a ground truth dataset and discussed issues related to searching and semantic search. Our findings show how understanding search term semantics can lead to more accurate results.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09330",
        "abstract url": "https://arxiv.org/abs/2406.09330",
        "title": "Learning from Natural Language Explanations for Generalizable Entity Matching",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Entity matching is the task of linking records from different sources that refer to the same real-world entity. Past work has primarily treated entity linking as a standard supervised learning problem. However, supervised entity matching models often do not generalize well to new data, and collecting exhaustive labeled training data is often cost prohibitive. Further, recent efforts have adopted LLMs for this task in few/zero-shot settings, exploiting their general knowledge. But LLMs are prohibitively expensive for performing inference at scale for real-world entity matching tasks. As an efficient alternative, we re-cast entity matching as a conditional generation task as opposed to binary classification. This enables us to \"distill\" LLM reasoning into smaller entity matching models via natural language explanations. This approach achieves strong performance, especially on out-of-domain generalization tests (10.85% F-1) where standalone generative methods struggle. We perform ablations that highlight the importance of explanations, both for performance and model robustness.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09334",
        "abstract url": "https://arxiv.org/abs/2406.09334",
        "title": "ProxyLM: Predicting Language Model Performance on Multilingual Tasks via Proxy Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Performance prediction is a method to estimate the performance of Language Models (LMs) on various Natural Language Processing (NLP) tasks, mitigating computational costs associated with model capacity and data for fine-tuning. Our paper introduces ProxyLM, a scalable framework for predicting LM performance using proxy models in multilingual tasks. These proxy models act as surrogates, approximating the performance of the LM of interest. By leveraging proxy models, ProxyLM significantly reduces computational overhead on task evaluations, achieving up to a 37.08x speedup compared to traditional methods, even with our smallest proxy models. Additionally, our methodology showcases adaptability to previously unseen languages in pre-trained LMs, outperforming the state-of-the-art performance by 1.89x as measured by root-mean-square error (RMSE). This framework streamlines model selection, enabling efficient deployment and iterative LM enhancements without extensive computational resources.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2406.09345",
        "abstract url": "https://arxiv.org/abs/2406.09345",
        "title": "DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech Units for Spoken Language Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The integration of pre-trained text-based large language models (LLM) with speech input has enabled instruction-following capabilities for diverse speech tasks. This integration requires the use of a speech encoder, a speech adapter, and an LLM, trained on diverse tasks. We propose the use of discrete speech units (DSU), rather than continuous-valued speech encoder outputs, that are converted to the LLM token embedding space using the speech adapter. We generate DSU using a self-supervised speech encoder followed by k-means clustering. The proposed model shows robust performance on speech inputs from seen/unseen domains and instruction-following capability in spoken question answering. We also explore various types of DSU extracted from different layers of the self-supervised speech encoder, as well as Mel frequency Cepstral Coefficients (MFCC). Our findings suggest that the ASR task and datasets are not crucial in instruction-tuning for spoken question answering tasks.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09366",
        "abstract url": "https://arxiv.org/abs/2406.09366",
        "title": "Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Maximum Manifold Capacity Representations (MMCR) is a recent multi-view self-supervised learning (MVSSL) method that matches or surpasses other leading MVSSL methods. MMCR is intriguing because it does not fit neatly into any of the commonplace MVSSL lineages, instead originating from a statistical mechanical perspective on the linear separability of data manifolds. In this paper, we seek to improve our understanding and our utilization of MMCR. To better understand MMCR, we leverage tools from high dimensional probability to demonstrate that MMCR incentivizes alignment and uniformity of learned embeddings. We then leverage tools from information theory to show that such embeddings maximize a well-known lower bound on mutual information between views, thereby connecting the geometric perspective of MMCR to the information-theoretic perspective commonly discussed in MVSSL. To better utilize MMCR, we mathematically predict and experimentally confirm non-monotonic changes in the pretraining loss akin to double descent but with respect to atypical hyperparameters. We also discover compute scaling laws that enable predicting the pretraining loss as a function of gradients steps, batch size, embedding dimension and number of views. We then show that MMCR, originally applied to image data, is performant on multimodal image-text data. By more deeply understanding the theoretical and empirical behavior of MMCR, our work reveals insights on improving MVSSL methods.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09367",
        "abstract url": "https://arxiv.org/abs/2406.09367",
        "title": "Needle In A Video Haystack: A Scalable Synthetic Framework for Benchmarking Video MLLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video understanding is a crucial next step for multimodal large language models (MLLMs). To probe specific aspects of video understanding ability, existing video benchmarks typically require careful video selection based on the target capability, along with laborious annotation of query-response pairs to match the specific video content. This process is both challenging and resource-intensive. In this paper, we propose VideoNIAH (Video Needle In A Haystack), a benchmark construction framework through synthetic video generation. VideoNIAH decouples test video content from their query-responses by inserting unrelated image/text 'needles' into original videos. It generates annotations solely from these needles, ensuring diversity in video sources and a variety of query-responses. Additionally, by inserting multiple needles, VideoNIAH rigorously evaluates the temporal understanding capabilities of models. We utilized VideoNIAH to compile a video benchmark VNBench, including tasks such as retrieval, ordering, and counting. VNBench can efficiently evaluate the fine-grained understanding ability and spatio-temporal modeling ability of a video model, while also supporting the long-context evaluation. Additionally, we evaluated recent video-centric multimodal large language models (MLLMs), both open-source and proprietary, providing a comprehensive analysis. We found that although proprietary models have significant advantages over open-source models, all existing video models still perform poorly on long-distance dependency tasks. VideoNIAH is a simple yet highly scalable benchmark construction framework, and we believe it will inspire future video benchmark works. The code and data are available at https://github.com/joez17/VideoNIAH.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09393",
        "abstract url": "https://arxiv.org/abs/2406.09393",
        "title": "Improving Autoregressive Training with Dynamic Oracles",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Many tasks within NLP can be framed as sequential decision problems, ranging from sequence tagging to text generation. However, for many tasks, the standard training methods, including maximum likelihood (teacher forcing) and scheduled sampling, suffer from exposure bias and a mismatch between metrics employed during training and inference. DAgger provides a solution to mitigate these problems, yet it requires a metric-specific dynamic oracle algorithm, which does not exist for many common metrics like span-based F1, ROUGE, and BLEU. In this paper, we develop these novel dynamic oracles and show they maintain DAgger's no-regret guarantee for decomposable metrics like span-based F1. We evaluate the algorithm's performance on named entity recognition (NER), text summarization, and machine translation (MT). While DAgger with dynamic oracle yields less favorable results in our MT experiments, it outperforms the baseline techniques in NER and text summarization.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09397",
        "abstract url": "https://arxiv.org/abs/2406.09397",
        "title": "Aligning Vision Models with Human Aesthetics in Retrieval: Benchmarks and Algorithms",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Modern vision models are trained on very large noisy datasets. While these models acquire strong capabilities, they may not follow the user's intent to output the desired results in certain aspects, e.g., visual aesthetic, preferred style, and responsibility. In this paper, we target the realm of visual aesthetics and aim to align vision models with human aesthetic standards in a retrieval system. Advanced retrieval systems usually adopt a cascade of aesthetic models as re-rankers or filters, which are limited to low-level features like saturation and perform poorly when stylistic, cultural or knowledge contexts are involved. We find that utilizing the reasoning ability of large language models (LLMs) to rephrase the search query and extend the aesthetic expectations can make up for this shortcoming. Based on the above findings, we propose a preference-based reinforcement learning method that fine-tunes the vision models to distill the knowledge from both LLMs reasoning and the aesthetic models to better align the vision models with human aesthetics. Meanwhile, with rare benchmarks designed for evaluating retrieval systems, we leverage large multi-modality model (LMM) to evaluate the aesthetic performance with their strong abilities. As aesthetic assessment is one of the most subjective tasks, to validate the robustness of LMM, we further propose a novel dataset named HPIR to benchmark the alignment with human aesthetics. Experiments demonstrate that our method significantly enhances the aesthetic behaviors of the vision models, under several metrics. We believe the proposed algorithm can be a general practice for aligning vision models with human values.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "28 pages, 26 figures, under review"
    },
    {
        "paper id": "2406.09398",
        "abstract url": "https://arxiv.org/abs/2406.09398",
        "title": "Real-Time Deepfake Detection in the Real-World",
        "rating": "1",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "synthesizing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent improvements in generative AI made synthesizing fake images easy; as they can be used to cause harm, it is crucial to develop accurate techniques to identify them. This paper introduces \"Locally Aware Deepfake Detection Algorithm\" (LaDeDa), that accepts a single 9x9 image patch and outputs its deepfake score. The image deepfake score is the pooled score of its patches. With merely patch-level information, LaDeDa significantly improves over the state-of-the-art, achieving around 99% mAP on current benchmarks. Owing to the patch-level structure of LaDeDa, we hypothesize that the generation artifacts can be detected by a simple model. We therefore distill LaDeDa into Tiny-LaDeDa, a highly efficient model consisting of only 4 convolutional layers. Remarkably, Tiny-LaDeDa has 375x fewer FLOPs and is 10,000x more parameter-efficient than LaDeDa, allowing it to run efficiently on edge devices with a minor decrease in accuracy. These almost-perfect scores raise the question: is the task of deepfake detection close to being solved? Perhaps surprisingly, our investigation reveals that current training protocols prevent methods from generalizing to real-world deepfakes extracted from social media. To address this issue, we introduce WildRF, a new deepfake detection dataset curated from several popular social networks. Our method achieves the top performance of 93.7% mAP on WildRF, however the large gap from perfect accuracy shows that reliable real-world deepfake detection is still unsolved.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09400",
        "abstract url": "https://arxiv.org/abs/2406.09400",
        "title": "Yo'LLaVA: Your Personalized Language and Vision Assistant",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Large Multimodal Models (LMMs) have shown remarkable capabilities across a variety of tasks (e.g., image captioning, visual question answering). While broad, their knowledge remains generic (e.g., recognizing a dog), and they are unable to handle personalized subjects (e.g., recognizing a user's pet dog). Human reasoning, in contrast, typically operates within the context of specific subjects in our surroundings. For example, one might ask, \"What should I buy for my dog's birthday?\"; as opposed to a generic inquiry about \"What should I buy for a dog's birthday?\". Similarly, when looking at a friend's image, the interest lies in seeing their activities (e.g., \"my friend is holding a cat\"), rather than merely observing generic human actions (e.g., \"a man is holding a cat\"). In this paper, we introduce the novel task of personalizing LMMs, so that they can have conversations about a specific subject. We propose Yo'LLaVA, which learns to embed a personalized subject into a set of latent tokens given a handful of example images of the subject. Our qualitative and quantitative analyses reveal that Yo'LLaVA can learn the concept more efficiently using fewer tokens and more effectively encode the visual attributes compared to strong prompting baselines (e.g., LLaVA).",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project page: https://thaoshibe.github.io/YoLLaVA"
    },
    {
        "paper id": "2406.09401",
        "abstract url": "https://arxiv.org/abs/2406.09401",
        "title": "MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations",
        "rating": "1",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "With the emergence of LLMs and their integration with other data modalities, multi-modal 3D perception attracts more attention due to its connectivity to the physical world and makes rapid progress. However, limited by existing datasets, previous works mainly focus on understanding object properties or inter-object spatial relationships in a 3D scene. To tackle this problem, this paper builds the first largest ever multi-modal 3D scene dataset and benchmark with hierarchical grounded language annotations, MMScan. It is constructed based on a top-down logic, from region to object level, from a single target to inter-target relationships, covering holistic aspects of spatial and attribute understanding. The overall pipeline incorporates powerful VLMs via carefully designed prompts to initialize the annotations efficiently and further involve humans' correction in the loop to ensure the annotations are natural, correct, and comprehensive. Built upon existing 3D scanning data, the resulting multi-modal 3D dataset encompasses 1.4M meta-annotated captions on 109k objects and 7.7k regions as well as over 3.04M diverse samples for 3D visual grounding and question-answering benchmarks. We evaluate representative baselines on our benchmarks, analyze their capabilities in different aspects, and showcase the key problems to be addressed in the future. Furthermore, we use this high-quality dataset to train state-of-the-art 3D visual grounding and LLMs and obtain remarkable performance improvement both on existing benchmarks and in-the-wild evaluation. Codes, datasets, and benchmarks will be available at https://github.com/OpenRobotLab/EmbodiedScan.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Follow-up of EmbodiedScan. A multi-modal 3D dataset with the most-ever comprehensive language annotations for 3D-LLMs. Project page: https://tai-wang.github.io/mmscan/"
    },
    {
        "paper id": "2406.09406",
        "abstract url": "https://arxiv.org/abs/2406.09406",
        "title": "4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Current multimodal and multitask foundation models like 4M or UnifiedIO show promising results, but in practice their out-of-the-box abilities to accept diverse inputs and perform diverse tasks are limited by the (usually rather small) number of modalities and tasks they are trained on. In this paper, we expand upon the capabilities of them by training a single model on tens of highly diverse modalities and by performing co-training on large-scale multimodal datasets and text corpora. This includes training on several semantic and geometric modalities, feature maps from recent state of the art models like DINOv2 and ImageBind, pseudo labels of specialist models like SAM and 4DHumans, and a range of new modalities that allow for novel ways to interact with the model and steer the generation, for example image metadata or color palettes. A crucial step in this process is performing discrete tokenization on various modalities, whether they are image-like, neural network feature maps, vectors, structured data like instance segmentation or human poses, or data that can be represented as text. Through this, we expand on the out-of-the-box capabilities of multimodal models and specifically show the possibility of training one model to solve at least 3x more tasks/modalities than existing ones and doing so without a loss in performance. This enables more fine-grained and controllable multimodal generation capabilities and allows us to study the distillation of models trained on diverse data and objectives into a unified model. We successfully scale the training to a three billion parameter model using tens of modalities and different datasets. The resulting models and training code are open sourced at 4m.epfl.ch.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Project page at 4m.epfl.ch"
    },
    {
        "paper id": "2406.09411",
        "abstract url": "https://arxiv.org/abs/2406.09411",
        "title": "MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce MuirBench, a comprehensive benchmark that focuses on robust multi-image understanding capabilities of multimodal LLMs. MuirBench consists of 12 diverse multi-image tasks (e.g., scene understanding, ordering) that involve 10 categories of multi-image relations (e.g., multiview, temporal relations). Comprising 11,264 images and 2,600 multiple-choice questions, MuirBench is created in a pairwise manner, where each standard instance is paired with an unanswerable variant that has minimal semantic differences, in order for a reliable assessment. Evaluated upon 20 recent multi-modal LLMs, our results reveal that even the best-performing models like GPT-4o and Gemini Pro find it challenging to solve MuirBench, achieving 68.0% and 49.3% in accuracy. Open-source multimodal LLMs trained on single images can hardly generalize to multi-image questions, hovering below 33.3% in accuracy. These results highlight the importance of MuirBench in encouraging the community to develop multimodal LLMs that can look beyond a single image, suggesting potential pathways for future improvements.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09412",
        "abstract url": "https://arxiv.org/abs/2406.09412",
        "title": "Explore the Limits of Omni-modal Pretraining at Scale",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We propose to build omni-modal intelligence, which is capable of understanding any modality and learning universal representations. In specific, we propose a scalable pretraining paradigm, named Multimodal Context (MiCo), which can scale up the numbers of modalities and amount of data, together with the model parameters, in the pretraining process. With MiCo, the pretrained models show significant emergent abilities in multimodal learning, which are evaluated on the following tasks: i) single-modality perception benchmarks of 10 different modalities, ii) 25 cross-modality understanding tasks of retrieval, question-answering, captioning, and iii) 18 multimodal large language model benchmarks. Our models establish 37 new records for state-of-the-art performance. We hope that our research could contribute to the development of omni-modal intelligence. Code and Models are at https://github.com/invictus717/MiCo",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "Project Website: https://invictus717.github.io/MiCo/"
    },
    {
        "paper id": "2406.09416",
        "abstract url": "https://arxiv.org/abs/2406.09416",
        "title": "Alleviating Distortion in Image Generation via Multi-Resolution Diffusion Models",
        "rating": "1",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents innovative enhancements to diffusion models by integrating a novel multi-resolution network and time-dependent layer normalization. Diffusion models have gained prominence for their effectiveness in high-fidelity image generation. While conventional approaches rely on convolutional U-Net architectures, recent Transformer-based designs have demonstrated superior performance and scalability. However, Transformer architectures, which tokenize input data (via \"patchification\"), face a trade-off between visual fidelity and computational complexity due to the quadratic nature of self-attention operations concerning token length. While larger patch sizes enable attention computation efficiency, they struggle to capture fine-grained visual details, leading to image distortions. To address this challenge, we propose augmenting the Diffusion model with the Multi-Resolution network (DiMR), a framework that refines features across multiple resolutions, progressively enhancing detail from low to high resolution. Additionally, we introduce Time-Dependent Layer Normalization (TD-LN), a parameter-efficient approach that incorporates time-dependent parameters into layer normalization to inject time information and achieve superior performance. Our method's efficacy is demonstrated on the class-conditional ImageNet generation benchmark, where DiMR-XL variants outperform prior diffusion models, setting new state-of-the-art FID scores of 1.70 on ImageNet 256 x 256 and 2.89 on ImageNet 512 x 512. Project page: https://qihao067.github.io/projects/DiMR",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Introducing DiMR, a new diffusion backbone that surpasses all existing image generation models of various sizes on ImageNet 256 with only 505M parameters. Project page: https://qihao067.github.io/projects/DiMR"
    },
    {
        "paper id": "2406.09418",
        "abstract url": "https://arxiv.org/abs/2406.09418",
        "title": "VideoGPT+: Integrating Image and Video Encoders for Enhanced Video Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Building on the advances of language models, Large Multimodal Models (LMMs) have contributed significant improvements in video understanding. While the current video LMMs utilize advanced Large Language Models (LLMs), they rely on either image or video encoders to process visual inputs, each of which has its own limitations. Image encoders excel at capturing rich spatial details from frame sequences but lack explicit temporal context, which can be important in videos with intricate action sequences. On the other hand, video encoders provide temporal context but are often limited by computational constraints that lead to processing only sparse frames at lower resolutions, resulting in reduced contextual and spatial understanding. To this end, we introduce VideoGPT+, which combines the complementary benefits of the image encoder (for detailed spatial understanding) and the video encoder (for global temporal context modeling). The model processes videos by dividing them into smaller segments and applies an adaptive pooling strategy on features extracted by both image and video encoders. Our architecture showcases improved performance across multiple video benchmarks, including VCGBench, MVBench and Zero-shot question-answering. Further, we develop 112K video-instruction set using a novel semi-automatic annotation pipeline which further improves the model performance. Additionally, to comprehensively evaluate video LMMs, we present VCGBench-Diverse, covering 18 broad video categories such as lifestyle, sports, science, gaming, and surveillance videos. This benchmark with 4,354 question-answer pairs evaluates the generalization of existing LMMs on dense video captioning, spatial and temporal understanding, and complex reasoning, ensuring comprehensive assessment across diverse video types and dynamics. Code: https://github.com/mbzuai-oryx/VideoGPT-plus.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2406.09486",
        "abstract url": "https://arxiv.org/abs/2406.09486",
        "title": "SeMOPO: Learning High-quality Model and Policy from Low-quality Offline Visual Datasets",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Model-based offline reinforcement Learning (RL) is a promising approach that leverages existing data effectively in many real-world applications, especially those involving high-dimensional inputs like images and videos. To alleviate the distribution shift issue in offline RL, existing model-based methods heavily rely on the uncertainty of learned dynamics. However, the model uncertainty estimation becomes significantly biased when observations contain complex distractors with non-trivial dynamics. To address this challenge, we propose a new approach - \\emph{Separated Model-based Offline Policy Optimization} (SeMOPO) - decomposing latent states into endogenous and exogenous parts via conservative sampling and estimating model uncertainty on the endogenous states only. We provide a theoretical guarantee of model uncertainty and performance bound of SeMOPO. To assess the efficacy, we construct the Low-Quality Vision Deep Data-Driven Datasets for RL (LQV-D4RL), where the data are collected by non-expert policy and the observations include moving distractors. Experimental results show that our method substantially outperforms all baseline methods, and further analytical experiments validate the critical designs in our method. The project website is \\href{https://sites.google.com/view/semopo}{https://sites.google.com/view/semopo}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "23 pages, 10 figures"
    },
    {
        "paper id": "2406.09490",
        "abstract url": "https://arxiv.org/abs/2406.09490",
        "title": "Newswire: A Large-Scale Structured Database of a Century of Historical News",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the U.S. historically, local newspapers drew their content largely from newswires like the Associated Press. Historians argue that newswires played a pivotal role in creating a national identity and shared understanding of the world, but there is no comprehensive archive of the content sent over newswires. We reconstruct such an archive by applying a customized deep learning pipeline to hundreds of terabytes of raw image scans from thousands of local newspapers. The resulting dataset contains 2.7 million unique public domain U.S. newswire articles, written between 1878 and 1977. Locations in these articles are georeferenced, topics are tagged using customized neural topic classification, named entities are recognized, and individuals are disambiguated to Wikipedia using a novel entity disambiguation model. To construct the Newswire dataset, we first recognize newspaper layouts and transcribe around 138 millions structured article texts from raw image scans. We then use a customized neural bi-encoder model to de-duplicate reproduced articles, in the presence of considerable abridgement and noise, quantifying how widely each article was reproduced. A text classifier is used to ensure that we only include newswire articles, which historically are in the public domain. The structured data that accompany the texts provide rich information about the who (disambiguated individuals), what (topics), and where (georeferencing) of the news that millions of Americans read over the course of a century. We also include Library of Congress metadata information about the newspapers that ran the articles on their front pages. The Newswire dataset is useful both for large language modeling - expanding training data beyond what is available from modern web texts - and for studying a diversity of questions in computational linguistics, social science, and the digital humanities.",
        "subjects": [
            "cs.CL",
            "econ.GN"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2306.17810, arXiv:2308.12477"
    },
    {
        "paper id": "2406.09519",
        "abstract url": "https://arxiv.org/abs/2406.09519",
        "title": "Talking Heads: Understanding Inter-layer Communication in Transformer Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Although it is known that transformer language models (LMs) pass features from early layers to later layers, it is not well understood how this information is represented and routed by the model. By analyzing particular mechanism LMs use to accomplish this, we find that it is also used to recall items from a list, and show that this mechanism can explain an otherwise arbitrary-seeming sensitivity of the model to the order of items in the prompt. Specifically, we find that models write into low-rank subspaces of the residual stream to represent features which are then read out by specific later layers, forming low-rank communication channels between layers. By decomposing attention head weight matrices with the Singular Value Decomposition (SVD), we find that previously described interactions between heads separated by one or more layers can be predicted via analysis of their weight matrices. We show that it is possible to manipulate the internal model representations as well as edit model weights based on the mechanism we discover in order to significantly improve performance on our synthetic Laundry List task, which requires recall from a list, often improving task accuracy by over 20%. Our analysis reveals a surprisingly intricate interpretable structure learned from language model pretraining, and helps us understand why sophisticated LMs sometimes fail in simple domains, facilitating future analysis of more complex behaviors.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09520",
        "abstract url": "https://arxiv.org/abs/2406.09520",
        "title": "A Systematic Review of Generative AI for Teaching and Learning Practice",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The use of generative artificial intelligence (GenAI) in academia is a subjective and hotly debated topic. Currently, there are no agreed guidelines towards the usage of GenAI systems in higher education (HE) and, thus, it is still unclear how to make effective use of the technology for teaching and learning practice. This paper provides an overview of the current state of research on GenAI for teaching and learning in HE. To this end, this study conducted a systematic review of relevant studies indexed by Scopus, using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines. The search criteria revealed a total of 625 research papers, of which 355 met the final inclusion criteria. The findings from the review showed the current state and the future trends in documents, citations, document sources/authors, keywords, and co-authorship. The research gaps identified suggest that while some authors have looked at understanding the detection of AI-generated text, it may be beneficial to understand how GenAI can be incorporated into supporting the educational curriculum for assessments, teaching, and learning delivery. Furthermore, there is a need for additional interdisciplinary, multidimensional studies in HE through collaboration. This will strengthen the awareness and understanding of students, tutors, and other stakeholders, which will be instrumental in formulating guidelines, frameworks, and policies for GenAI usage.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "20 pages, 10 figures, article published in Education Sciences"
    },
    {
        "paper id": "2406.09556",
        "abstract url": "https://arxiv.org/abs/2406.09556",
        "title": "$S^3$ -- Semantic Signal Separation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Topic models are useful tools for discovering latent semantic structures in large textual corpora. Topic modeling historically relied on bag-of-words representations of language. This approach makes models sensitive to the presence of stop words and noise, and does not utilize potentially useful contextual information. Recent efforts have been oriented at incorporating contextual neural representations in topic modeling and have been shown to outperform classical topic models. These approaches are, however, typically slow, volatile and still require preprocessing for optimal results. We present Semantic Signal Separation ($S^3$), a theory-driven topic modeling approach in neural embedding spaces. $S^3$ conceptualizes topics as independent axes of semantic space, and uncovers these with blind-source separation. Our approach provides the most diverse, highly coherent topics, requires no preprocessing, and is demonstrated to be the fastest contextually sensitive topic model to date. We offer an implementation of $S^3$, among other approaches, in the Turftopic Python package.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "stat.ML"
        ],
        "comment": "26 pages, 9 figures (main manuscript has 9 pages and 4 figures)"
    },
    {
        "paper id": "2406.09559",
        "abstract url": "https://arxiv.org/abs/2406.09559",
        "title": "Decoding the Diversity: A Review of the Indic AI Research Landscape",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This review paper provides a comprehensive overview of large language model (LLM) research directions within Indic languages. Indic languages are those spoken in the Indian subcontinent, including India, Pakistan, Bangladesh, Sri Lanka, Nepal, and Bhutan, among others. These languages have a rich cultural and linguistic heritage and are spoken by over 1.5 billion people worldwide. With the tremendous market potential and growing demand for natural language processing (NLP) based applications in diverse languages, generative applications for Indic languages pose unique challenges and opportunities for research. Our paper deep dives into the recent advancements in Indic generative modeling, contributing with a taxonomy of research directions, tabulating 84 recent publications. Research directions surveyed in this paper include LLM development, fine-tuning existing LLMs, development of corpora, benchmarking and evaluation, as well as publications around specific techniques, tools, and applications. We found that researchers across the publications emphasize the challenges associated with limited data availability, lack of standardization, and the peculiar linguistic complexities of Indic languages. This work aims to serve as a valuable resource for researchers and practitioners working in the field of NLP, particularly those focused on Indic languages, and contributes to the development of more accurate and efficient LLM applications for these languages.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "27 pages, 1 figure"
    },
    {
        "paper id": "2406.09564",
        "abstract url": "https://arxiv.org/abs/2406.09564",
        "title": "Towards Domain Adaptive Neural Contextual Bandits",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Contextual bandit algorithms are essential for solving real-world decision making problems. In practice, collecting a contextual bandit's feedback from different domains may involve different costs. For example, measuring drug reaction from mice (as a source domain) and humans (as a target domain). Unfortunately, adapting a contextual bandit algorithm from a source domain to a target domain with distribution shift still remains a major challenge and largely unexplored. In this paper, we introduce the first general domain adaptation method for contextual bandits. Our approach learns a bandit model for the target domain by collecting feedback from the source domain. Our theoretical analysis shows that our algorithm maintains a sub-linear regret bound even adapting across domains. Empirical results show that our approach outperforms the state-of-the-art contextual bandit algorithms on real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "cs.CV",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09569",
        "abstract url": "https://arxiv.org/abs/2406.09569",
        "title": "Speech ReaLLM -- Real-time Streaming Speech Recognition with Multimodal LLMs by Teaching the Flow of Time",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We introduce Speech ReaLLM, a new ASR architecture that marries \"decoder-only\" ASR with the RNN-T to make multimodal LLM architectures capable of real-time streaming. This is the first \"decoder-only\" ASR architecture designed to handle continuous audio without explicit end-pointing. Speech ReaLLM is a special case of the more general ReaLLM (\"real-time LLM\") approach, also introduced here for the first time. The idea is inspired by RNN-T: Instead of generating a response only at the end of a user prompt, generate after every input token received in real time (it is often empty). On Librispeech \"test\", an 80M Speech ReaLLM achieves WERs of 3.0% and 7.4% in real time (without an external LM or auxiliary loss). This is only slightly above a 3x larger Attention-Encoder-Decoder baseline. We also show that this way, an LLM architecture can learn to represent and reproduce the flow of time; and that a pre-trained 7B LLM can be fine-tuned to do reasonably well on this task.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09573",
        "abstract url": "https://arxiv.org/abs/2406.09573",
        "title": "Analyzing Gender Polarity in Short Social Media Texts with BERT: The Role of Emojis and Emoticons",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this effort we fine tuned different models based on BERT to detect the gender polarity of twitter accounts. We specially focused on analyzing the effect of using emojis and emoticons in performance of our model in classifying task. We were able to demonstrate that the use of these none word inputs alongside the mention of other accounts in a short text format like tweet has an impact in detecting the account holder's gender.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09575",
        "abstract url": "https://arxiv.org/abs/2406.09575",
        "title": "CARLOR @ Ego4D Step Grounding Challenge: Bayesian temporal-order priors for test time refinement",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The goal of the Step Grounding task is to locate temporal boundaries of activities based on natural language descriptions. This technical report introduces a Bayesian-VSLNet to address the challenge of identifying such temporal segments in lengthy, untrimmed egocentric videos. Our model significantly improves upon traditional models by incorporating a novel Bayesian temporal-order prior during inference, enhancing the accuracy of moment predictions. This prior adjusts for cyclic and repetitive actions within videos. Our evaluations demonstrate superior performance over existing methods, achieving state-of-the-art results on the Ego4D Goal-Step dataset with a 35.18 Recall Top-1 at 0.3 IoU and 20.48 Recall Top-1 at 0.5 IoU on the test set.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09618",
        "abstract url": "https://arxiv.org/abs/2406.09618",
        "title": "Multi-Modal Retrieval For Large Language Model Based Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Retrieval is a widely adopted approach for improving language models leveraging external information. As the field moves towards multi-modal large language models, it is important to extend the pure text based methods to incorporate other modalities in retrieval as well for applications across the wide spectrum of machine learning tasks and data types. In this work, we propose multi-modal retrieval with two approaches: kNN-LM and cross-attention techniques. We demonstrate the effectiveness of our retrieval approaches empirically by applying them to automatic speech recognition tasks with access to external information. Under this setting, we show that speech-based multi-modal retrieval outperforms text based retrieval, and yields up to 50 % improvement in word error rate over the multi-modal language model baseline. Furthermore, we achieve state-of-the-art recognition results on the Spoken-Squad question answering dataset.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09630",
        "abstract url": "https://arxiv.org/abs/2406.09630",
        "title": "Muharaf: Manuscripts of Handwritten Arabic Dataset for Cursive Text Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present the Manuscripts of Handwritten Arabic~(Muharaf) dataset, which is a machine learning dataset consisting of more than 1,600 historic handwritten page images transcribed by experts in archival Arabic. Each document image is accompanied by spatial polygonal coordinates of its text lines as well as basic page elements. This dataset was compiled to advance the state of the art in handwritten text recognition (HTR), not only for Arabic manuscripts but also for cursive text in general. The Muharaf dataset includes diverse handwriting styles and a wide range of document types, including personal letters, diaries, notes, poems, church records, and legal correspondences. In this paper, we describe the data acquisition pipeline, notable dataset features, and statistics. We also provide a preliminary baseline result achieved by training convolutional neural networks using this data.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09646",
        "abstract url": "https://arxiv.org/abs/2406.09646",
        "title": "A Survey of Video Datasets for Grounded Event Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "While existing video benchmarks largely consider specialized downstream tasks like retrieval or question-answering (QA), contemporary multimodal AI systems must be capable of well-rounded common-sense reasoning akin to human visual understanding. A critical component of human temporal-visual perception is our ability to identify and cognitively model \"things happening\", or events. Historically, video benchmark tasks have implicitly tested for this ability (e.g., video captioning, in which models describe visual events with natural language), but they do not consider video event understanding as a task in itself. Recent work has begun to explore video analogues to textual event extraction but consists of competing task definitions and datasets limited to highly specific event types. Therefore, while there is a rich domain of event-centric video research spanning the past 10+ years, it is unclear how video event understanding should be framed and what resources we have to study it. In this paper, we survey 105 video datasets that require event understanding capability, consider how they contribute to the study of robust event understanding in video, and assess proposed video event extraction tasks in the context of this body of research. We propose suggestions informed by this survey for dataset curation and task framing, with an emphasis on the uniquely temporal nature of video events and ambiguity in visual content.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09671",
        "abstract url": "https://arxiv.org/abs/2406.09671",
        "title": "Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI's most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil's 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam's open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model's reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. The involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model's accuracy and ensuring the fairness of high-stakes educational exams. The paper's research materials are publicly available at https://github.com/nabormendonca/gpt-4v-enade-cs-2021.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Accepted for publication"
    },
    {
        "paper id": "2406.09676",
        "abstract url": "https://arxiv.org/abs/2406.09676",
        "title": "Optimizing Byte-level Representation for End-to-end ASR",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "We propose a novel approach to optimizing a byte-level representation for end-to-end automatic speech recognition (ASR). Byte-level representation is often used by large scale multilingual ASR systems when the character set of the supported languages is large. The compactness and universality of byte-level representation allow the ASR models to use smaller output vocabularies and therefore, provide more flexibility. UTF-8 is a commonly used byte-level representation for multilingual ASR, but it is not designed to optimize machine learning tasks directly. By using auto-encoder and vector quantization, we show that we can optimize a byte-level representation for ASR and achieve better accuracy. Our proposed framework can incorporate information from different modalities, and provides an error correction mechanism. In an English/Mandarin dictation task, we show that a bilingual ASR model built with this approach can outperform UTF-8 representation by 5% relative in error rate.",
        "subjects": [
            "eess.AS",
            "cs.CL"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2406.09688",
        "abstract url": "https://arxiv.org/abs/2406.09688",
        "title": "FreeCtrl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Controllable text generation (CTG) seeks to craft texts adhering to specific attributes, traditionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. These approaches, while effective, demand extensive computational and data resources. In contrast, some proposed learning-free alternatives circumvent learning but often yield inferior results, exemplifying the fundamental machine learning trade-off between computational expense and model efficacy. To overcome these limitations, we propose FreeCtrl, a learning-free approach that dynamically adjusts the weights of selected feedforward neural network (FFN) vectors to steer the outputs of large language models (LLMs). FreeCtrl hinges on the principle that the weights of different FFN vectors influence the likelihood of different tokens appearing in the output. By identifying and adaptively adjusting the weights of attribute-related FFN vectors, FreeCtrl can control the output likelihood of attribute keywords in the generated content. Extensive experiments on single- and multi-attribute control reveal that the learning-free FreeCtrl outperforms other learning-free and learning-based methods, successfully resolving the dilemma between learning costs and model performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ACL 2024"
    },
    {
        "paper id": "2406.09702",
        "abstract url": "https://arxiv.org/abs/2406.09702",
        "title": "Detecting Response Generation Not Requiring Factual Judgment",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the remarkable development of large language models (LLMs), ensuring the factuality of output has become a challenge. However, having all the contents of the response with given knowledge or facts is not necessarily a good thing in dialogues. This study aimed to achieve both attractiveness and factuality in a dialogue response for which a task was set to predict sentences that do not require factual correctness judgment such as agreeing, or personal opinions/feelings. We created a dataset, dialogue dataset annotated with fact-check-needed label (DDFC), for this task via crowdsourcing, and classification tasks were performed on several models using this dataset. The model with the highest classification accuracy could yield about 88% accurate classification results.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09710",
        "abstract url": "https://arxiv.org/abs/2406.09710",
        "title": "Fine-Grained Urban Flow Inference with Multi-scale Representation Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Fine-grained urban flow inference (FUFI) is a crucial transportation service aimed at improving traffic efficiency and safety. FUFI can infer fine-grained urban traffic flows based solely on observed coarse-grained data. However, most of existing methods focus on the influence of single-scale static geographic information on FUFI, neglecting the interactions and dynamic information between different-scale regions within the city. Different-scale geographical features can capture redundant information from the same spatial areas. In order to effectively learn multi-scale information across time and space, we propose an effective fine-grained urban flow inference model called UrbanMSR, which uses self-supervised contrastive learning to obtain dynamic multi-scale representations of neighborhood-level and city-level geographic information, and fuses multi-scale representations to improve fine-grained accuracy. The fusion of multi-scale representations enhances fine-grained. We validate the performance through extensive experiments on three real-world datasets. The resutls compared with state-of-the-art methods demonstrate the superiority of the proposed model.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09717",
        "abstract url": "https://arxiv.org/abs/2406.09717",
        "title": "UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with Optimized Embeddings and Vocabulary), a comprehensive approach developed to improve the effectiveness of Cross-Lingual Transfer Learning, particularly in languages with limited resources. Our approach tackles two essential elements of a language model: the initialization of embeddings and the optimal vocabulary size. Specifically, we propose a novel embedding initialization method that leverages both lexical and semantic alignment for a language. In addition, we present a method for systematically searching for the optimal vocabulary size, ensuring a balance between model complexity and linguistic coverage. Our experiments across multilingual datasets show that our approach greatly improves the F1-Score in several languages. UniBridge is a robust and adaptable solution for cross-lingual systems in various languages, highlighting the significance of initializing embeddings and choosing the right vocabulary size in cross-lingual environments.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2406.08812",
        "abstract url": "https://arxiv.org/abs/2406.08812",
        "title": "Generating Speakers by Prompting Listener Impressions for Pre-trained Multi-Speaker Text-to-Speech Systems",
        "rating": "0.5",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This paper proposes a speech synthesis system that allows users to specify and control the acoustic characteristics of a speaker by means of prompts describing the speaker's traits of synthesized speech. Unlike previous approaches, our method utilizes listener impressions to construct prompts, which are easier to collect and align more naturally with everyday descriptions of speaker traits. We adopt the Low-rank Adaptation (LoRA) technique to swiftly tailor a pre-trained language model to our needs, facilitating the extraction of speaker-related traits from the prompt text. Besides, different from other prompt-driven text-to-speech (TTS) systems, we separate the prompt-to-speaker module from the multi-speaker TTS system, enhancing system flexibility and compatibility with various pre-trained multi-speaker TTS systems. Moreover, for the prompt-to-speaker characteristic module, we also compared the discriminative method and flow-matching based generative method and we found that combining both methods can help the system simultaneously capture speaker-related information from prompts better and generate speech with higher fidelity.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted for presentation at Interspeech 2024 (with more analysis in the final Appendix part)"
    },
    {
        "paper id": "2406.08816",
        "abstract url": "https://arxiv.org/abs/2406.08816",
        "title": "ToSA: Token Selective Attention for Efficient Vision Transformers",
        "rating": "0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In this paper, we propose a novel token selective attention approach, ToSA, which can identify tokens that need to be attended as well as those that can skip a transformer layer. More specifically, a token selector parses the current attention maps and predicts the attention maps for the next layer, which are then used to select the important tokens that should participate in the attention operation. The remaining tokens simply bypass the next layer and are concatenated with the attended ones to re-form a complete set of tokens. In this way, we reduce the quadratic computation and memory costs as fewer tokens participate in self-attention while maintaining the features for all the image patches throughout the network, which allows it to be used for dense prediction tasks. Our experiments show that by applying ToSA, we can significantly reduce computation costs while maintaining accuracy on the ImageNet classification benchmark. Furthermore, we evaluate on the dense prediction task of monocular depth estimation on NYU Depth V2, and show that we can achieve similar depth prediction accuracy using a considerably lighter backbone with ToSA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at CVPRW 2024"
    },
    {
        "paper id": "2406.08819",
        "abstract url": "https://arxiv.org/abs/2406.08819",
        "title": "AIM: Attributing, Interpreting, Mitigating Data Unfairness",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Data collected in the real world often encapsulates historical discrimination against disadvantaged groups and individuals. Existing fair machine learning (FairML) research has predominantly focused on mitigating discriminative bias in the model prediction, with far less effort dedicated towards exploring how to trace biases present in the data, despite its importance for the transparency and interpretability of FairML. To fill this gap, we investigate a novel research problem: discovering samples that reflect biases/prejudices from the training data. Grounding on the existing fairness notions, we lay out a sample bias criterion and propose practical algorithms for measuring and countering sample bias. The derived bias score provides intuitive sample-level attribution and explanation of historical bias in data. On this basis, we further design two FairML strategies via sample-bias-informed minimal data editing. They can mitigate both group and individual unfairness at the cost of minimal or zero predictive utility loss. Extensive experiments and analyses on multiple real-world datasets demonstrate the effectiveness of our methods in explaining and mitigating unfairness. Code is available at https://github.com/ZhiningLiu1998/AIM.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "12 pages, 6 figures, accepted by ACM SIGKDD 2024"
    },
    {
        "paper id": "2406.08825",
        "abstract url": "https://arxiv.org/abs/2406.08825",
        "title": "Interpretable Temporal Class Activation Representation for Audio Spoofing Detection",
        "rating": "0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Explaining the decisions made by audio spoofing detection models is crucial for fostering trust in detection outcomes. However, current research on the interpretability of detection models is limited to applying XAI tools to post-trained models. In this paper, we utilize the wav2vec 2.0 model and attentive utterance-level features to integrate interpretability directly into the model's architecture, thereby enhancing transparency of the decision-making process. Specifically, we propose a class activation representation to localize the discriminative frames contributing to detection. Furthermore, we demonstrate that multi-label training based on spoofing types, rather than binary labels as bonafide and spoofed, enables the model to learn distinct characteristics of different attacks, significantly improving detection performance. Our model achieves state-of-the-art results, with an EER of 0.51% and a min t-DCF of 0.0165 on the ASVspoof2019-LA set.",
        "subjects": [
            "cs.SD",
            "cs.CR",
            "eess.AS"
        ],
        "comment": "10 pages, 5 figures, Accepted to Interspeech2024"
    },
    {
        "paper id": "2406.08828",
        "abstract url": "https://arxiv.org/abs/2406.08828",
        "title": "Estimating Difficulty Levels of Programming Problems with Pre-trained Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "As the demand for programming skills grows across industries and academia, students often turn to Programming Online Judge (POJ) platforms for coding practice and competition. The difficulty level of each programming problem serves as an essential reference for guiding students' adaptive learning. However, current methods of determining difficulty levels either require extensive expert annotations or take a long time to accumulate enough student solutions for each problem. To address this issue, we formulate the problem of automatic difficulty level estimation of each programming problem, given its textual description and a solution example of code. For tackling this problem, we propose to couple two pre-trained models, one for text modality and the other for code modality, into a unified model. We built two POJ datasets for the task and the results demonstrate the effectiveness of the proposed approach and the contributions of both modalities.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08830",
        "abstract url": "https://arxiv.org/abs/2406.08830",
        "title": "Center-Sensitive Kernel Optimization for Efficient On-Device Incremental Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "To facilitate the evolution of edge intelligence in ever-changing environments, we study on-device incremental learning constrained in limited computation resource in this paper. Current on-device training methods just focus on efficient training without considering the catastrophic forgetting, preventing the model getting stronger when continually exploring the world. To solve this problem, a direct solution is to involve the existing incremental learning mechanisms into the on-device training framework. Unfortunately, such a manner cannot work well as those mechanisms usually introduce large additional computational cost to the network optimization process, which would inevitably exceed the memory capacity of the edge devices. To address this issue, this paper makes an early effort to propose a simple but effective edge-friendly incremental learning framework. Based on an empirical study on the knowledge intensity of the kernel elements of the neural network, we find that the center kernel is the key for maximizing the knowledge intensity for learning new data, while freezing the other kernel elements would get a good balance on the model's capacity for overcoming catastrophic forgetting. Upon this finding, we further design a center-sensitive kernel optimization framework to largely alleviate the cost of the gradient computation and back-propagation. Besides, a dynamic channel element selection strategy is also proposed to facilitate a sparse orthogonal gradient projection for further reducing the optimization complexity, upon the knowledge explored from the new task data. Extensive experiments validate our method is efficient and effective, e.g., our method achieves average accuracy boost of 38.08% with even less memory and approximate computation compared to existing on-device training methods, indicating its significant potential for on-device incremental learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08839",
        "abstract url": "https://arxiv.org/abs/2406.08839",
        "title": "NeRF Director: Revisiting View Selection in Neural Volume Rendering",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Neural Rendering representations have significantly contributed to the field of 3D computer vision. Given their potential, considerable efforts have been invested to improve their performance. Nonetheless, the essential question of selecting training views is yet to be thoroughly investigated. This key aspect plays a vital role in achieving high-quality results and aligns with the well-known tenet of deep learning: \"garbage in, garbage out\". In this paper, we first illustrate the importance of view selection by demonstrating how a simple rotation of the test views within the most pervasive NeRF dataset can lead to consequential shifts in the performance rankings of state-of-the-art techniques. To address this challenge, we introduce a unified framework for view selection methods and devise a thorough benchmark to assess its impact. Significant improvements can be achieved without leveraging error or uncertainty estimation but focusing on uniform view coverage of the reconstructed object, resulting in a training-free approach. Using this technique, we show that high-quality renderings can be achieved faster by using fewer views. We conduct extensive experiments on both synthetic datasets and realistic data to demonstrate the effectiveness of our proposed method compared with random, conventional error-based, and uncertainty-guided view selection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVPR2024"
    },
    {
        "paper id": "2406.08853",
        "abstract url": "https://arxiv.org/abs/2406.08853",
        "title": "Assessment of Uncertainty Quantification in Universal Differential Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scientific Machine Learning is a new class of approaches that integrate physical knowledge and mechanistic models with data-driven techniques for uncovering governing equations of complex processes. Among the available approaches, Universal Differential Equations (UDEs) are used to combine prior knowledge in the form of mechanistic formulations with universal function approximators, like neural networks. Integral to the efficacy of UDEs is the joint estimation of parameters within mechanistic formulations and the universal function approximators using empirical data. The robustness and applicability of resultant models, however, hinge upon the rigorous quantification of uncertainties associated with these parameters, as well as the predictive capabilities of the overall model or its constituent components. With this work, we provide a formalisation of uncertainty quantification (UQ) for UDEs and investigate important frequentist and Bayesian methods. By analysing three synthetic examples of varying complexity, we evaluate the validity and efficiency of ensembles, variational inference and Markov chain Monte Carlo sampling as epistemic UQ methods for UDEs.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": "Shared last authorship between W.W. and J.H"
    },
    {
        "paper id": "2406.08862",
        "abstract url": "https://arxiv.org/abs/2406.08862",
        "title": "Cognitively Inspired Energy-Based World Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "One of the predominant methods for training world models is autoregressive prediction in the output space of the next element of a sequence. In Natural Language Processing (NLP), this takes the form of Large Language Models (LLMs) predicting the next token; in Computer Vision (CV), this takes the form of autoregressive models predicting the next frame/token/pixel. However, this approach differs from human cognition in several respects. First, human predictions about the future actively influence internal cognitive processes. Second, humans naturally evaluate the plausibility of predictions regarding future states. Based on this capability, and third, by assessing when predictions are sufficient, humans allocate a dynamic amount of time to make a prediction. This adaptive process is analogous to System 2 thinking in psychology. All these capabilities are fundamental to the success of humans at high-level reasoning and planning. Therefore, to address the limitations of traditional autoregressive models lacking these human-like capabilities, we introduce Energy-Based World Models (EBWM). EBWM involves training an Energy-Based Model (EBM) to predict the compatibility of a given context and a predicted future state. In doing so, EBWM enables models to achieve all three facets of human cognition described. Moreover, we developed a variant of the traditional autoregressive transformer tailored for Energy-Based models, termed the Energy-Based Transformer (EBT). Our results demonstrate that EBWM scales better with data and GPU Hours than traditional autoregressive transformers in CV, and that EBWM offers promising early scaling in NLP. Consequently, this approach offers an exciting path toward training future models capable of System 2 thinking and intelligently searching across state spaces.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "23 pages, 6 figures"
    },
    {
        "paper id": "2406.08905",
        "abstract url": "https://arxiv.org/abs/2406.08905",
        "title": "SingOMD: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models",
        "rating": "0.5",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Discrete representation has shown advantages in speech generation tasks, wherein discrete tokens are derived by discretizing hidden features from self-supervised learning (SSL) pre-trained models. However, the direct application of speech SSL models to singing generation encounters domain gaps between speech and singing. Furthermore, singing generation necessitates a more refined representation than typical speech. To address these challenges, we introduce SingOMD, a novel method to extract singing-oriented multi-resolution discrete representations from speech SSL models. Specifically, we first adapt the features from speech SSL through a resynthesis task and incorporate multi-resolution modules based on resampling to better serve singing generation. These adapted multi-resolution features are then discretized via clustering. Extensive experiments demonstrate the robustness, efficiency, and effectiveness of these representations in singing vocoders and singing voice synthesis.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by Interspeech 2024"
    },
    {
        "paper id": "2406.08917",
        "abstract url": "https://arxiv.org/abs/2406.08917",
        "title": "Predicting Fault-Ride-Through Probability of Inverter-Dominated Power Grids using Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Due to the increasing share of renewables, the analysis of the dynamical behavior of power grids gains importance. Effective risk assessments necessitate the analysis of large number of fault scenarios. The computational costs inherent in dynamic simulations impose constraints on the number of configurations that can be analyzed. Machine Learning (ML) has proven to efficiently predict complex power grid properties. Hence, we analyze the potential of ML for predicting dynamic stability of future power grids with large shares of inverters. For this purpose, we generate a new dataset consisting of synthetic power grid models and perform dynamical simulations. As targets for the ML training, we calculate the fault-ride-through probability, which we define as the probability of staying within a ride-through curve after a fault at a bus has been cleared. Importantly, we demonstrate that ML models accurately predict the fault-ride-through probability of synthetic power grids. Finally, we also show that the ML models generalize to an IEEE-96 Test System, which emphasizes the potential of deploying ML methods to study probabilistic stability of power grids.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": "11 pages, 6 figures"
    },
    {
        "paper id": "2406.08943",
        "abstract url": "https://arxiv.org/abs/2406.08943",
        "title": "Neural NeRF Compression",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRFs) have emerged as powerful tools for capturing detailed 3D scenes through continuous volumetric representations. Recent NeRFs utilize feature grids to improve rendering quality and speed; however, these representations introduce significant storage overhead. This paper presents a novel method for efficiently compressing a grid-based NeRF model, addressing the storage overhead concern. Our approach is based on the non-linear transform coding paradigm, employing neural compression for compressing the model's feature grids. Due to the lack of training data involving many i.i.d scenes, we design an encoder-free, end-to-end optimized approach for individual scenes, using lightweight decoders. To leverage the spatial inhomogeneity of the latent feature grids, we introduce an importance-weighted rate-distortion objective and a sparse entropy model employing a masking mechanism. Our experimental results validate that our proposed method surpasses existing works in terms of grid-based NeRF compression efficacy and reconstruction quality.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted to ICML 2024"
    },
    {
        "paper id": "2406.08966",
        "abstract url": "https://arxiv.org/abs/2406.08966",
        "title": "Separation Power of Equivariant Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The separation power of a machine learning model refers to its capacity to distinguish distinct inputs, and it is often employed as a proxy for its expressivity. In this paper, we propose a theoretical framework to investigate the separation power of equivariant neural networks with point-wise activations. Using the proposed framework, we can derive an explicit description of inputs indistinguishable by a family of neural networks with given architecture, demonstrating that it remains unaffected by the choice of non-polynomial activation function employed. We are able to understand the role played by activation functions in separability. Indeed, we show that all non-polynomial activations, such as ReLU and sigmoid, are equivalent in terms of expressivity, and that they reach maximum discrimination capacity. We demonstrate how assessing the separation power of an equivariant neural network can be simplified to evaluating the separation power of minimal representations. We conclude by illustrating how these minimal components form a hierarchy in separation power.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "9 pages of main text, 2 figures"
    },
    {
        "paper id": "2406.08973",
        "abstract url": "https://arxiv.org/abs/2406.08973",
        "title": "XLand-100B: A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Following the success of the in-context learning paradigm in large-scale language and computer vision models, the recently emerging field of in-context reinforcement learning is experiencing a rapid growth. However, its development has been held back by the lack of challenging benchmarks, as all the experiments have been carried out in simple environments and on small-scale datasets. We present \\textbf{XLand-100B}, a large-scale dataset for in-context reinforcement learning based on the XLand-MiniGrid environment, as a first step to alleviate this problem. It contains complete learning histories for nearly $30,000$ different tasks, covering $100$B transitions and $2.5$B episodes. It took $50,000$ GPU hours to collect the dataset, which is beyond the reach of most academic labs. Along with the dataset, we provide the utilities to reproduce or expand it even further. With this substantial effort, we aim to democratize research in the rapidly growing field of in-context reinforcement learning and provide a solid foundation for further scaling. The code is open-source and available under Apache 2.0 licence at https://github.com/dunno-lab/xland-minigrid-datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08996",
        "abstract url": "https://arxiv.org/abs/2406.08996",
        "title": "Introducing Brain-like Concepts to Embodied Hand-crafted Dialog Management System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Along with the development of chatbot, language models and speech technologies, there is a growing possibility and interest of creating systems able to interface with humans seamlessly through natural language or directly via speech. In this paper, we want to demonstrate that placing the research on dialog system in the broader context of embodied intelligence allows to introduce concepts taken from neurobiology and neuropsychology to define behavior architecture that reconcile hand-crafted design and artificial neural network and open the gate to future new learning approaches like imitation or learning by instruction. To do so, this paper presents a neural behavior engine that allows creation of mixed initiative dialog and action generation based on hand-crafted models using a graphical language. A demonstration of the usability of such brain-like inspired architecture together with a graphical dialog model is described through a virtual receptionist application running on a semi-public space.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "29 pages, 18 figures"
    },
    {
        "paper id": "2406.09030",
        "abstract url": "https://arxiv.org/abs/2406.09030",
        "title": "CUER: Corrected Uniform Experience Replay for Off-Policy Continuous Deep Reinforcement Learning Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The utilization of the experience replay mechanism enables agents to effectively leverage their experiences on several occasions. In previous studies, the sampling probability of the transitions was modified based on their relative significance. The process of reassigning sample probabilities for every transition in the replay buffer after each iteration is considered extremely inefficient. Hence, in order to enhance computing efficiency, experience replay prioritization algorithms reassess the importance of a transition as it is sampled. However, the relative importance of the transitions undergoes dynamic adjustments when the agent's policy and value function are iteratively updated. Furthermore, experience replay is a mechanism that retains the transitions generated by the agent's past policies, which could potentially diverge significantly from the agent's most recent policy. An increased deviation from the agent's most recent policy results in a greater frequency of off-policy updates, which has a negative impact on the agent's performance. In this paper, we develop a novel algorithm, Corrected Uniform Experience Replay (CUER), which stochastically samples the stored experience while considering the fairness among all other experiences without ignoring the dynamic nature of the transition importance by making sampled state distribution more on-policy. CUER provides promising improvements for off-policy continuous control algorithms in terms of sample efficiency, final performance, and stability of the policy during the training.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09035",
        "abstract url": "https://arxiv.org/abs/2406.09035",
        "title": "How Decentralization Affects User Agency on Social Platforms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Mainstream social media platforms function as \"walled garden\" ecosystems that restrict user agency, control, and data portability. They have demonstrated a lack of transparency that contributes to a multitude of online harms. Our research investigates how decentralization might present promise as an alternative model to walled garden platforms. Specifically, we describe the user-driven content moderation through blocks as an expression of agency on Bluesky, a decentralized social platform. We examine the impact of providing users with more granular control over their online experiences, including what they post, who can see it, and whose content they are exposed to. We describe the patterns identified in user-driven content moderation and suggest directions for further research.",
        "subjects": [
            "cs.CY",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09038",
        "abstract url": "https://arxiv.org/abs/2406.09038",
        "title": "CGP++ : A Modern C++ Implementation of Cartesian Genetic Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The reference implementation of Cartesian Genetic Programming (CGP) was written in the C programming language. C inherently follows a procedural programming paradigm, which entails challenges in providing a reusable and scalable implementation model for complex structures and methods. Moreover, due to the limiting factors of C, the reference implementation of CGP does not provide a generic framework and is therefore restricted to a set of predefined evaluation types. Besides the reference implementation, we also observe that other existing implementations are limited with respect to the features provided. In this work, we therefore propose the first version of a modern C++ implementation of CGP that pursues object-oriented design and generic programming paradigm to provide an efficient implementation model that can facilitate the discovery of new problem domains and the implementation of complex advanced methods that have been proposed for CGP over time. With the proposal of our new implementation, we aim to generally promote interpretability, accessibility and reproducibility in the field of CGP.",
        "subjects": [
            "cs.NE",
            "cs.LG"
        ],
        "comment": "Accepted as a full paper in the BBSR track at the Genetic and Evolutionary Computation Conference (GECCO'24), July 14-18, 2024, Melbourne, Australia"
    },
    {
        "paper id": "2406.09062",
        "abstract url": "https://arxiv.org/abs/2406.09062",
        "title": "State-Space Modeling in Long Sequence Processing: A Survey on Recurrence in the Transformer Era",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Effectively learning from sequential data is a longstanding goal of Artificial Intelligence, especially in the case of long sequences. From the dawn of Machine Learning, several researchers engaged in the search of algorithms and architectures capable of processing sequences of patterns, retaining information about the past inputs while still leveraging the upcoming data, without losing precious long-term dependencies and correlations. While such an ultimate goal is inspired by the human hallmark of continuous real-time processing of sensory information, several solutions simplified the learning paradigm by artificially limiting the processed context or dealing with sequences of limited length, given in advance. These solutions were further emphasized by the large ubiquity of Transformers, that have initially shaded the role of Recurrent Neural Nets. However, recurrent networks are facing a strong recent revival due to the growing popularity of (deep) State-Space models and novel instances of large-context Transformers, which are both based on recurrent computations to go beyond several limits of currently ubiquitous technologies. In fact, the fast development of Large Language Models enhanced the interest in efficient solutions to process data over time. This survey provides an in-depth summary of the latest approaches that are based on recurrent models for sequential data processing. A complete taxonomy over the latest trends in architectural and algorithmic solutions is reported and discussed, guiding researchers in this appealing research field. The emerging picture suggests that there is room for thinking of novel routes, constituted by learning algorithms which depart from the standard Backpropagation Through Time, towards a more realistic scenario where patterns are effectively processed online, leveraging local-forward computations, opening to further research on this topic.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Currently under review"
    },
    {
        "paper id": "2406.09068",
        "abstract url": "https://arxiv.org/abs/2406.09068",
        "title": "Dispelling the Mirage of Progress in Offline MARL through Standardised Baselines and Evaluation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Offline multi-agent reinforcement learning (MARL) is an emerging field with great promise for real-world applications. Unfortunately, the current state of research in offline MARL is plagued by inconsistencies in baselines and evaluation protocols, which ultimately makes it difficult to accurately assess progress, trust newly proposed innovations, and allow researchers to easily build upon prior work. In this paper, we firstly identify significant shortcomings in existing methodologies for measuring the performance of novel algorithms through a representative study of published offline MARL work. Secondly, by directly comparing to this prior work, we demonstrate that simple, well-implemented baselines can achieve state-of-the-art (SOTA) results across a wide range of tasks. Specifically, we show that on 35 out of 47 datasets used in prior work (almost 75% of cases), we match or surpass the performance of the current purported SOTA. Strikingly, our baselines often substantially outperform these more sophisticated algorithms. Finally, we correct for the shortcomings highlighted from this prior work by introducing a straightforward standardised methodology for evaluation and by providing our baseline implementations with statistically robust results across several scenarios, useful for comparisons in future work. Our proposal includes simple and sensible steps that are easy to adopt, which in combination with solid baselines and comparative results, could substantially improve the overall rigour of empirical science in offline MARL moving forward.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09069",
        "abstract url": "https://arxiv.org/abs/2406.09069",
        "title": "On the Robustness of Global Feature Effect Explanations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the robustness of global post-hoc explanations for predictive models trained on tabular data. Effects of predictor features in black-box supervised learning are an essential diagnostic tool for model debugging and scientific discovery in applied sciences. However, how vulnerable they are to data and model perturbations remains an open research question. We introduce several theoretical bounds for evaluating the robustness of partial dependence plots and accumulated local effects. Our experimental results with synthetic and real-world datasets quantify the gap between the best and worst-case scenarios of (mis)interpreting machine learning predictions globally.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Accepted at ECML PKDD 2024"
    },
    {
        "paper id": "2406.09079",
        "abstract url": "https://arxiv.org/abs/2406.09079",
        "title": "Latent Assistance Networks: Rediscovering Hyperbolic Tangents in RL",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Activation functions are one of the key components of a neural network. The most commonly used activation functions can be classed into the category of continuously differentiable (e.g. tanh) and linear-unit functions (e.g. ReLU), both having their own strengths and drawbacks with respect to downstream performance and representation capacity through learning (e.g. measured by the number of dead neurons and the effective rank). In reinforcement learning, the performance of continuously differentiable activations often falls short as compared to linear-unit functions. From the perspective of the activations in the last hidden layer, this paper provides insights regarding this sub-optimality and explores how activation functions influence the occurrence of dead neurons and the magnitude of the effective rank. Additionally, a novel neural architecture is proposed that leverages the product of independent activation values. In the Atari domain, we show faster learning, a reduction in dead neurons and increased effective rank.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "22 pages, 17 figures, 4 tables"
    },
    {
        "paper id": "2406.09116",
        "abstract url": "https://arxiv.org/abs/2406.09116",
        "title": "Injective Flows for parametric hypersurfaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Normalizing Flows (NFs) are powerful and efficient models for density estimation. When modeling densities on manifolds, NFs can be generalized to injective flows but the Jacobian determinant becomes computationally prohibitive. Current approaches either consider bounds on the log-likelihood or rely on some approximations of the Jacobian determinant. In contrast, we propose injective flows for parametric hypersurfaces and show that for such manifolds we can compute the Jacobian determinant exactly and efficiently, with the same cost as NFs. Furthermore, we show that for the subclass of star-like manifolds we can extend the proposed framework to always allow for a Cartesian representation of the density. We showcase the relevance of modeling densities on hypersurfaces in two settings. Firstly, we introduce a novel Objective Bayesian approach to penalized likelihood models by interpreting level-sets of the penalty as star-like manifolds. Secondly, we consider Bayesian mixture models and introduce a general method for variational inference by defining the posterior of mixture weights on the probability simplex.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09123",
        "abstract url": "https://arxiv.org/abs/2406.09123",
        "title": "PSN: Persian Social Norms Dataset for Cross-Cultural AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Datasets capturing cultural norms are essential for developing globally aware AI systems. We present Persian Social Norms (PSN) a novel dataset of over 1.7k Persian social norms, including environments, contexts, and cultural labels, alongside English translations. Leveraging large language models and prompt-engineering techniques, we generated potential norms that were reviewed by native speakers for quality and ethical compliance. As the first Persian dataset of its kind, this resource enables computational modeling of norm adaptation, a crucial challenge for cross-cultural AI informed by diverse cultural perspectives.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "4 pages, 2 figures, 2 tables"
    },
    {
        "paper id": "2406.09141",
        "abstract url": "https://arxiv.org/abs/2406.09141",
        "title": "Optimal Control of Agent-Based Dynamics under Deep Galerkin Feedback Laws",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Ever since the concepts of dynamic programming were introduced, one of the most difficult challenges has been to adequately address high-dimensional control problems. With growing dimensionality, the utilisation of Deep Neural Networks promises to circumvent the issue of an otherwise exponentially increasing complexity. The paper specifically investigates the sampling issues the Deep Galerkin Method is subjected to. It proposes a drift relaxation-based sampling approach to alleviate the symptoms of high-variance policy approximations. This is validated on mean-field control problems; namely, the variations of the opinion dynamics presented by the Sznajd and the Hegselmann-Krause model. The resulting policies induce a significant cost reduction over manually optimised control functions and show improvements on the Linear-Quadratic Regulator problem over the Deep FBSDE approach.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09169",
        "abstract url": "https://arxiv.org/abs/2406.09169",
        "title": "Empirical Networks are Sparse: Enhancing Multi-Edge Models with Zero-Inflation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Real-world networks are sparse. As we show in this article, even when a large number of interactions is observed most node pairs remain disconnected. We demonstrate that classical multi-edge network models, such as the $G(N,p)$, configuration models, and stochastic block models, fail to accurately capture this phenomenon. To mitigate this issue, zero-inflation must be integrated into these traditional models. Through zero-inflation, we incorporate a mechanism that accounts for the excess number of zeroes (disconnected pairs) observed in empirical data. By performing an analysis on all the datasets from the Sociopatterns repository, we illustrate how zero-inflated models more accurately reflect the sparsity and heavy-tailed edge count distributions observed in empirical data. Our findings underscore that failing to account for these ubiquitous properties in real-world networks inadvertently leads to biased models which do not accurately represent complex systems and their dynamics.",
        "subjects": [
            "cs.SI",
            "math.ST",
            "physics.soc-ph",
            "stat.ME"
        ],
        "comment": "18 pages article + 9 pages SI, 4 figures"
    },
    {
        "paper id": "2406.09172",
        "abstract url": "https://arxiv.org/abs/2406.09172",
        "title": "Generative vs. Discriminative modeling under the lens of uncertainty quantification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Learning a parametric model from a given dataset indeed enables to capture intrinsic dependencies between random variables via a parametric conditional probability distribution and in turn predict the value of a label variable given observed variables. In this paper, we undertake a comparative analysis of generative and discriminative approaches which differ in their construction and the structure of the underlying inference problem. Our objective is to compare the ability of both approaches to leverage information from various sources in an epistemic uncertainty aware inference via the posterior predictive distribution. We assess the role of a prior distribution, explicit in the generative case and implicit in the discriminative case, leading to a discussion about discriminative models suffering from imbalanced dataset. We next examine the double role played by the observed variables in the generative case, and discuss the compatibility of both approaches with semi-supervised learning. We also provide with practical insights and we examine how the modeling choice impacts the sampling from the posterior predictive distribution. With regard to this, we propose a general sampling scheme enabling supervised learning for both approaches, as well as semi-supervised learning when compatible with the considered modeling approach. Throughout this paper, we illustrate our arguments and conclusions using the example of affine regression, and validate our comparative analysis through classification simulations using neural network based models.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09182",
        "abstract url": "https://arxiv.org/abs/2406.09182",
        "title": "Federated Contrastive Learning for Personalized Semantic Communication",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this letter, we design a federated contrastive learning (FedCL) framework aimed at supporting personalized semantic communication. Our FedCL enables collaborative training of local semantic encoders across multiple clients and a global semantic decoder owned by the base station. This framework supports heterogeneous semantic encoders since it does not require client-side model aggregation. Furthermore, to tackle the semantic imbalance issue arising from heterogeneous datasets across distributed clients, we employ contrastive learning to train a semantic centroid generator (SCG). This generator obtains representative global semantic centroids that exhibit intra-semantic compactness and inter-semantic separability. Consequently, it provides superior supervision for learning discriminative local semantic features. Additionally, we conduct theoretical analysis to quantify the convergence performance of FedCL. Simulation results verify the superiority of the proposed FedCL framework compared to other distributed learning benchmarks in terms of task performance and robustness under different numbers of clients and channel conditions, especially in low signal-to-noise ratio and highly heterogeneous data scenarios.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "IEEE Communications Letters"
    },
    {
        "paper id": "2406.09183",
        "abstract url": "https://arxiv.org/abs/2406.09183",
        "title": "Ridge interpolators in correlated factor regression models -- exact risk analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider correlated \\emph{factor} regression models (FRM) and analyze the performance of classical ridge interpolators. Utilizing powerful \\emph{Random Duality Theory} (RDT) mathematical engine, we obtain \\emph{precise} closed form characterizations of the underlying optimization problems and all associated optimizing quantities. In particular, we provide \\emph{excess prediction risk} characterizations that clearly show the dependence on all key model parameters, covariance matrices, loadings, and dimensions. As a function of the over-parametrization ratio, the generalized least squares (GLS) risk also exhibits the well known \\emph{double-descent} (non-monotonic) behavior. Similarly to the classical linear regression models (LRM), we demonstrate that such FRM phenomenon can be smoothened out by the optimally tuned ridge regularization. The theoretical results are supplemented by numerical simulations and an excellent agrement between the two is observed. Moreover, we note that ``ridge smootenhing'' is often of limited effect already for over-parametrization ratios above $5$ and of virtually no effect for those above $10$. This solidifies the notion that one of the recently most popular neural networks paradigms -- \\emph{zero-training (interpolating) generalizes well} -- enjoys wider applicability, including the one within the FRM estimation/prediction context.",
        "subjects": [
            "stat.ML",
            "cs.IT",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09199",
        "abstract url": "https://arxiv.org/abs/2406.09199",
        "title": "Precise analysis of ridge interpolators under heavy correlations -- a Random Duality Theory view",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider fully row/column-correlated linear regression models and study several classical estimators (including minimum norm interpolators (GLS), ordinary least squares (LS), and ridge regressors). We show that \\emph{Random Duality Theory} (RDT) can be utilized to obtain precise closed form characterizations of all estimators related optimizing quantities of interest, including the \\emph{prediction risk} (testing or generalization error). On a qualitative level out results recover the risk's well known non-monotonic (so-called double-descent) behavior as the number of features/sample size ratio increases. On a quantitative level, our closed form results show how the risk explicitly depends on all key model parameters, including the problem dimensions and covariance matrices. Moreover, a special case of our results, obtained when intra-sample (or time-series) correlations are not present, precisely match the corresponding ones obtained via spectral methods in [6,16,17,24].",
        "subjects": [
            "stat.ML",
            "cs.IT",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09214",
        "abstract url": "https://arxiv.org/abs/2406.09214",
        "title": "Applying Multi-Agent Negotiation to Solve the Production Routing Problem With Privacy Preserving",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents a novel approach to address the Production Routing Problem with Privacy Preserving (PRPPP) in supply chain optimization. The integrated optimization of production, inventory, distribution, and routing decisions in real-world industry applications poses several challenges, including increased complexity, discrepancies between planning and execution, and constraints on information sharing. To mitigate these challenges, this paper proposes the use of intelligent agent negotiation within a hybrid Multi-Agent System (MAS) integrated with optimization algorithms. The MAS facilitates communication and coordination among entities, encapsulates private information, and enables negotiation. This, along with optimization algorithms, makes it a compelling framework for establishing optimal solutions. The approach is supported by real-world applications and synergies between MAS and optimization methods, demonstrating its effectiveness in addressing complex supply chain optimization problems.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": "The 15th Workshop on Optimization and Learning in Multiagent Systems"
    },
    {
        "paper id": "2406.09242",
        "abstract url": "https://arxiv.org/abs/2406.09242",
        "title": "Towards a Characterisation of Monte-Carlo Tree Search Performance in Different Games",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Many enhancements to Monte-Carlo Tree Search (MCTS) have been proposed over almost two decades of general game playing and other artificial intelligence research. However, our ability to characterise and understand which variants work well or poorly in which games is still lacking. This paper describes work on an initial dataset that we have built to make progress towards such an understanding: 268,386 plays among 61 different agents across 1494 distinct games. We describe a preliminary analysis and work on training predictive models on this dataset, as well as lessons learned and future plans for a new and improved version of the dataset.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted for publication in the Proceedings of the 2024 IEEE Conference on Games"
    },
    {
        "paper id": "2406.09297",
        "abstract url": "https://arxiv.org/abs/2406.09297",
        "title": "MLKV: Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Auto-regressive inference of transformers benefit greatly from Key-Value (KV) caching, but can lead to major memory bottlenecks as model size, batch size, and sequence length grow at scale. We introduce Multi-Layer Key-Value (MLKV) sharing, a novel approach extending KV sharing across transformer layers to reduce memory usage beyond what was possible with Multi-Query Attention (MQA) and Grouped-Query Attention (GQA). Evaluations on various NLP benchmarks and inference metrics using uptrained Pythia-160M variants demonstrate that MLKV significantly reduces memory usage with minimal performance loss, reducing KV cache size down to a factor of 6x compared to MQA. These results highlight MLKV's potential for efficient deployment of transformer models at scale. We provide code at https://github.com/zaydzuhri/pythia-mlkv",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09308",
        "abstract url": "https://arxiv.org/abs/2406.09308",
        "title": "Transformers meet Neural Algorithmic Reasoners",
        "rating": "0.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Transformers have revolutionized machine learning with their simple yet effective architecture. Pre-training Transformers on massive text datasets from the Internet has led to unmatched generalization for natural language understanding (NLU) tasks. However, such language models remain fragile when tasked with algorithmic forms of reasoning, where computations must be precise and robust. To address this limitation, we propose a novel approach that combines the Transformer's language understanding with the robustness of graph neural network (GNN)-based neural algorithmic reasoners (NARs). Such NARs proved effective as generic solvers for algorithmic tasks, when specified in graph form. To make their embeddings accessible to a Transformer, we propose a hybrid architecture with a two-phase training procedure, allowing the tokens in the language model to cross-attend to the node embeddings from the NAR. We evaluate our resulting TransNAR model on CLRS-Text, the text-based version of the CLRS-30 benchmark, and demonstrate significant gains over Transformer-only models for algorithmic reasoning, both in and out of distribution.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "To appear at CVPR 2024 Multimodal Algorithmic Reasoning (MAR) Workshop. 10 pages, 5 figures"
    },
    {
        "paper id": "2406.09310",
        "abstract url": "https://arxiv.org/abs/2406.09310",
        "title": "Neural networks in non-metric spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Leveraging the infinite dimensional neural network architecture we proposed in arXiv:2109.13512v4 and which can process inputs from Fr\u00e9chet spaces, and using the universal approximation property shown therein, we now largely extend the scope of this architecture by proving several universal approximation theorems for a vast class of input and output spaces. More precisely, the input space $\\mathfrak X$ is allowed to be a general topological space satisfying only a mild condition (\"quasi-Polish\"), and the output space can be either another quasi-Polish space $\\mathfrak Y$ or a topological vector space $E$. Similarly to arXiv:2109.13512v4, we show furthermore that our neural network architectures can be projected down to \"finite dimensional\" subspaces with any desirable accuracy, thus obtaining approximating networks that are easy to implement and allow for fast computation and fitting. The resulting neural network architecture is therefore applicable for prediction tasks based on functional data. To the best of our knowledge, this is the first result which deals with such a wide class of input/output spaces and simultaneously guarantees the numerical feasibility of the ensuing architectures. Finally, we prove an obstruction result which indicates that the category of quasi-Polish spaces is in a certain sense the correct category to work with if one aims at constructing approximating architectures on infinite-dimensional spaces $\\mathfrak X$ which, at the same time, have sufficient expressive power to approximate continuous functions on $\\mathfrak X$, are specified by a finite number of parameters only and are \"stable\" with respect to these parameters.",
        "subjects": [
            "math.FA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09318",
        "abstract url": "https://arxiv.org/abs/2406.09318",
        "title": "Characterising Interventions in Causal Games",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Causal games are probabilistic graphical models that enable causal queries to be answered in multi-agent settings. They extend causal Bayesian networks by specifying decision and utility variables to represent the agents' degrees of freedom and objectives. In multi-agent settings, whether each agent decides on their policy before or after knowing the causal intervention is important as this affects whether they can respond to the intervention by adapting their policy. Consequently, previous work in causal games imposed chronological constraints on permissible interventions. We relax this by outlining a sound and complete set of primitive causal interventions so the effect of any arbitrarily complex interventional query can be studied in multi-agent settings. We also demonstrate applications to the design of safe AI systems by considering causal mechanism design and commitment.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "Accepted to the 40th Conference on Uncertainty in Artificial Intelligence (UAI-2024)"
    },
    {
        "paper id": "2406.09322",
        "abstract url": "https://arxiv.org/abs/2406.09322",
        "title": "Active Inference Meeting Energy-Efficient Control of Parallel and Identical Machines",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the application of active inference in developing energy-efficient control agents for manufacturing systems. Active inference, rooted in neuroscience, provides a unified probabilistic framework integrating perception, learning, and action, with inherent uncertainty quantification elements. Our study explores deep active inference, an emerging field that combines deep learning with the active inference decision-making framework. Leveraging a deep active inference agent, we focus on controlling parallel and identical machine workstations to enhance energy efficiency. We address challenges posed by the problem's stochastic nature and delayed policy response by introducing tailored enhancements to existing agent architectures. Specifically, we introduce multi-step transition and hybrid horizon methods to mitigate the need for complex planning. Our experimental results demonstrate the effectiveness of these enhancements and highlight the potential of the active inference-based approach.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09329",
        "abstract url": "https://arxiv.org/abs/2406.09329",
        "title": "Is Value Learning Really the Main Bottleneck in Offline RL?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "While imitation learning requires access to high-quality data, offline reinforcement learning (RL) should, in principle, perform similarly or better with substantially lower data quality by using a value function. However, current results indicate that offline RL often performs worse than imitation learning, and it is often unclear what holds back the performance of offline RL. Motivated by this observation, we aim to understand the bottlenecks in current offline RL algorithms. While poor performance of offline RL is typically attributed to an imperfect value function, we ask: is the main bottleneck of offline RL indeed in learning the value function, or something else? To answer this question, we perform a systematic empirical study of (1) value learning, (2) policy extraction, and (3) policy generalization in offline RL problems, analyzing how these components affect performance. We make two surprising observations. First, we find that the choice of a policy extraction algorithm significantly affects the performance and scalability of offline RL, often more so than the value learning objective. For instance, we show that common value-weighted behavioral cloning objectives (e.g., AWR) do not fully leverage the learned value function, and switching to behavior-constrained policy gradient objectives (e.g., DDPG+BC) often leads to substantial improvements in performance and scalability. Second, we find that a big barrier to improving offline RL performance is often imperfect policy generalization on test-time states out of the support of the training data, rather than policy learning on in-distribution states. We then show that the use of suboptimal but high-coverage data or test-time policy training techniques can address this generalization issue in practice. Specifically, we propose two simple test-time policy improvement methods and show that these methods lead to better performance.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09347",
        "abstract url": "https://arxiv.org/abs/2406.09347",
        "title": "Separations in the Representational Capabilities of Transformers and Recurrent Architectures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformer architectures have been widely adopted in foundation models. Due to their high inference costs, there is renewed interest in exploring the potential of efficient recurrent architectures (RNNs). In this paper, we analyze the differences in the representational capabilities of Transformers and RNNs across several tasks of practical relevance, including index lookup, nearest neighbor, recognizing bounded Dyck languages, and string equality. For the tasks considered, our results show separations based on the size of the model required for different architectures. For example, we show that a one-layer Transformer of logarithmic width can perform index lookup, whereas an RNN requires a hidden state of linear size. Conversely, while constant-size RNNs can recognize bounded Dyck languages, we show that one-layer Transformers require a linear size for this task. Furthermore, we show that two-layer Transformers of logarithmic size can perform decision tasks such as string equality or disjointness, whereas both one-layer Transformers and recurrent models require linear size for these tasks. We also show that a log-size two-layer Transformer can implement the nearest neighbor algorithm in its forward pass; on the other hand recurrent models require linear size. Our constructions are based on the existence of $N$ nearly orthogonal vectors in $O(\\log N)$ dimensional space and our lower bounds are based on reductions from communication complexity problems. We supplement our theoretical results with experiments that highlight the differences in the performance of these architectures on practical-size sequences.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2406.09363",
        "abstract url": "https://arxiv.org/abs/2406.09363",
        "title": "ElicitationGPT: Text Elicitation Mechanisms via Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Scoring rules evaluate probabilistic forecasts of an unknown state against the realized state and are a fundamental building block in the incentivized elicitation of information and the training of machine learning models. This paper develops mechanisms for scoring elicited text against ground truth text using domain-knowledge-free queries to a large language model (specifically ChatGPT) and empirically evaluates their alignment with human preferences. The empirical evaluation is conducted on peer reviews from a peer-grading dataset and in comparison to manual instructor scores for the peer reviews.",
        "subjects": [
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09370",
        "abstract url": "https://arxiv.org/abs/2406.09370",
        "title": "Data-dependent and Oracle Bounds on Forgetting in Continual Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In continual learning, knowledge must be preserved and re-used between tasks, maintaining good transfer to future tasks and minimizing forgetting of previously learned ones. While several practical algorithms have been devised for this setting, there have been few theoretical works aiming to quantify and bound the degree of Forgetting in general settings. We provide both data-dependent and oracle upper bounds that apply regardless of model and algorithm choice, as well as bounds for Gibbs posteriors. We derive an algorithm inspired by our bounds and demonstrate empirically that our approach yields improved forward and backward transfer.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09375",
        "abstract url": "https://arxiv.org/abs/2406.09375",
        "title": "Learning conditional distributions on continuous spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate sample-based learning of conditional distributions on multi-dimensional unit boxes, allowing for different dimensions of the feature and target spaces. Our approach involves clustering data near varying query points in the feature space to create empirical measures in the target space. We employ two distinct clustering schemes: one based on a fixed-radius ball and the other on nearest neighbors. We establish upper bounds for the convergence rates of both methods and, from these bounds, deduce optimal configurations for the radius and the number of neighbors. We propose to incorporate the nearest neighbors method into neural network training, as our empirical analysis indicates it has better performance in practice. For efficiency, our training process utilizes approximate nearest neighbors search with random binary space partitioning. Additionally, we employ the Sinkhorn algorithm and a sparsity-enforced transport plan. Our empirical findings demonstrate that, with a suitably designed structure, the neural network has the ability to adapt to a suitable level of Lipschitz continuity locally. For reproducibility, our code is available at \\url{https://github.com/zcheng-a/LCD_kNN}.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09405",
        "abstract url": "https://arxiv.org/abs/2406.09405",
        "title": "Why Warmup the Learning Rate? Underlying Mechanisms and Improvements",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "It is common in deep learning to warm up the learning rate $\u03b7$, often by a linear schedule between $\u03b7_{\\text{init}} = 0$ and a predetermined target $\u03b7_{\\text{trgt}}$. In this paper, we show through systematic experiments using SGD and Adam that the overwhelming benefit of warmup arises from allowing the network to tolerate larger $\u03b7_{\\text{trgt}}$ by forcing the network to more well-conditioned areas of the loss landscape. The ability to handle larger $\u03b7_{\\text{trgt}}$ makes hyperparameter tuning more robust while improving the final performance. We uncover different regimes of operation during the warmup period, depending on whether training starts off in a progressive sharpening or sharpness reduction phase, which in turn depends on the initialization and parameterization. Using these insights, we show how $\u03b7_{\\text{init}}$ can be properly chosen by utilizing the loss catapult mechanism, which saves on the number of warmup steps, in some cases completely eliminating the need for warmup. We also suggest an initialization for the variance in Adam which provides benefits similar to warmup.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "stat.ML"
        ],
        "comment": "11+22 pages, 7+24 figures"
    },
    {
        "paper id": "2406.09474",
        "abstract url": "https://arxiv.org/abs/2406.09474",
        "title": "Lightning-Fast Thunderstorm Warnings: Predicting Severe Convective Environments with Global Neural Weather Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The recently released suite of AI weather models can produce multi-day, medium-range forecasts within seconds, with a skill on par with state-of-the-art operational forecasts. Traditional AI model evaluation predominantly targets global scores on single levels. Specific prediction tasks, such as severe convective environments, require much more precision on a local scale and with the correct vertical gradients between levels. With a focus on the convective season of global hotspots in 2020, we assess the skill of three top-performing AI models (Pangu-Weather, GraphCast, FourCastNet) for Convective Available Potential Energy (CAPE) and Deep Layer Shear (DLS) at lead-times of up to 10 days against the ERA-5 reanalysis and the IFS operational numerical weather prediction model. Looking at the example of a US tornado outbreak on April 12 and 13, 2020, all models predict elevated CAPE and DLS values multiple days in advance. The spatial structures in the AI models are smoothed in comparison to IFS and ERA-5. The models show differing biases in the prediction of CAPE values, with GraphCast capturing the value distribution the most accurately and FourCastNet showing a consistent underestimation. In seasonal analyses around the globe, we generally see the highest performance by GraphCast and Pangu-Weather, which match or even exceed the performance of IFS. CAPE derived from vertically coarse pressure levels of neural weather models lacks the precision of the vertically fine resolution of numerical models. The promising results here indicate that a direct prediction of CAPE in AI models is likely to be skillful. This would open unprecedented opportunities for fast and inexpensive predictions of severe weather phenomena. By advancing the assessment of AI models towards process-based evaluations we lay the foundation for hazard-driven applications of AI-based weather forecasts.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": "23 pages, 7 Figures. In preparation for submission to Environmental Research Letters"
    },
    {
        "paper id": "2406.09477",
        "abstract url": "https://arxiv.org/abs/2406.09477",
        "title": "Q-S5: Towards Quantized State Space Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the quest for next-generation sequence modeling architectures, State Space Models (SSMs) have emerged as a potent alternative to transformers, particularly for their computational efficiency and suitability for dynamical systems. This paper investigates the effect of quantization on the S5 model to understand its impact on model performance and to facilitate its deployment to edge and resource-constrained platforms. Using quantization-aware training (QAT) and post-training quantization (PTQ), we systematically evaluate the quantization sensitivity of SSMs across different tasks like dynamical systems modeling, Sequential MNIST (sMNIST) and most of the Long Range Arena (LRA). We present fully quantized S5 models whose test accuracy drops less than 1% on sMNIST and most of the LRA. We find that performance on most tasks degrades significantly for recurrent weights below 8-bit precision, but that other components can be compressed further without significant loss of performance. Our results further show that PTQ only performs well on language-based LRA tasks whereas all others require QAT. Our investigation provides necessary insights for the continued development of efficient and hardware-optimized SSMs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09478",
        "abstract url": "https://arxiv.org/abs/2406.09478",
        "title": "Distributed genetic algorithm for application placement in the compute continuum leveraging infrastructure nodes for optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The increasing complexity of fog computing environments calls for efficient resource optimization techniques. In this paper, we propose and evaluate three distributed designs of a genetic algorithm (GA) for resource optimization in fog computing, within an increasing degree of distribution. The designs leverage the execution of the GA in the fog devices themselves by dealing with the specific features of this domain: constrained resources and widely geographical distribution of the devices. For their evaluation, we implemented a benchmark case using the NSGA-II for the specific problem of optimizing the fog service placement, according to the guidelines of our three distributed designs. These three experimental scenarios were compared with a control case, a traditional centralized version of this GA algorithm, considering solution quality and network overhead. The results show that the design with the lowest distribution degree, which keeps centralized storage of the objective space, achieves comparable solution quality to the traditional approach but incurs a higher network load. The second design, which completely distributes the population between the workers, reduces network overhead but exhibits lower solution diversity while keeping enough good results in terms of optimization objective minimization. Finally, the proposal with a distributed population and that only interchanges solution between the workers' neighbors achieves the lowest network load but with compromised solution quality.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09534",
        "abstract url": "https://arxiv.org/abs/2406.09534",
        "title": "FeatNavigator: Automatic Feature Augmentation on Tabular Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data-centric AI focuses on understanding and utilizing high-quality, relevant data in training machine learning (ML) models, thereby increasing the likelihood of producing accurate and useful results. Automatic feature augmentation, aiming to augment the initial base table with useful features from other tables, is critical in data preparation as it improves model performance, robustness, and generalizability. While recent works have investigated automatic feature augmentation, most of them have limited capabilities in utilizing all useful features as many of them are in candidate tables not directly joinable with the base table. Worse yet, with numerous join paths leading to these distant features, existing solutions fail to fully exploit them within a reasonable compute budget. We present FeatNavigator, an effective and efficient framework that explores and integrates high-quality features in relational tables for ML models. FeatNavigator evaluates a feature from two aspects: (1) the intrinsic value of a feature towards an ML task (i.e., feature importance) and (2) the efficacy of a join path connecting the feature to the base table (i.e., integration quality). FeatNavigator strategically selects a small set of available features and their corresponding join paths to train a feature importance estimation model and an integration quality prediction model. Furthermore, FeatNavigator's search algorithm exploits both estimated feature importance and integration quality to identify the optimized feature augmentation plan. Our experimental results show that FeatNavigator outperforms state-of-the-art solutions on five public datasets by up to 40.1% in ML model performance.",
        "subjects": [
            "cs.DB",
            "cs.LG"
        ],
        "comment": "15 pages, 41 figures"
    },
    {
        "paper id": "2406.09535",
        "abstract url": "https://arxiv.org/abs/2406.09535",
        "title": "CircuitVAE: Efficient and Scalable Latent Circuit Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Automatically designing fast and space-efficient digital circuits is challenging because circuits are discrete, must exactly implement the desired logic, and are costly to simulate. We address these challenges with CircuitVAE, a search algorithm that embeds computation graphs in a continuous space and optimizes a learned surrogate of physical simulation by gradient descent. By carefully controlling overfitting of the simulation surrogate and ensuring diverse exploration, our algorithm is highly sample-efficient, yet gracefully scales to large problem instances and high sample budgets. We test CircuitVAE by designing binary adders across a large range of sizes, IO timing constraints, and sample budgets. Our method excels at designing large circuits, where other algorithms struggle: compared to reinforcement learning and genetic algorithms, CircuitVAE typically finds 64-bit adders which are smaller and faster using less than half the sample budget. We also find CircuitVAE can design state-of-the-art adders in a real-world chip, demonstrating that our method can outperform commercial tools in a realistic setting.",
        "subjects": [
            "cs.LG",
            "cs.AR"
        ],
        "comment": "Design Automation Conference (DAC) 2024; the first two authors contributed equally"
    },
    {
        "paper id": "2406.09551",
        "abstract url": "https://arxiv.org/abs/2406.09551",
        "title": "Embedding machine-learnt sub-grid variability improves climate model biases",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The under-representation of cloud formation is a long-standing bias associated with climate simulations. Parameterisation schemes are required to capture cloud processes within current climate models but have known biases. We overcome these biases by embedding a Multi-Output Gaussian Process (MOGP) trained on high resolution Unified Model simulations to represent the variability of temperature and specific humidity within a climate model. A trained MOGP model is coupled in-situ with a simplified Atmospheric General Circulation Model named SPEEDY. The temperature and specific humidity profiles of SPEEDY are perturbed at fixed intervals according to the variability predicted from the MOGP. Ten-year predictions are generated for both control and ML-hybrid models. The hybrid model reduces the global precipitation bias by 18\\% and over the tropics by 22\\%. To further understand the drivers of these improvements, physical quantities of interest are explored, such as the distribution of lifted index values and the alteration of the Hadley cell. The control and hybrid set-ups are also run in a plus 4K sea-surface temperature experiment to explore the effects of the approach on patterns relating to cloud cover and precipitation in a warmed climate setting.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09553",
        "abstract url": "https://arxiv.org/abs/2406.09553",
        "title": "My Body My Choice: Human-Centric Full-Body Anonymization",
        "rating": "0.5",
        "keywords": [
            [
                "diffusion",
                "GAN",
                "inpainting"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In an era of increasing privacy concerns for our online presence, we propose that the decision to appear in a piece of content should only belong to the owner of the body. Although some automatic approaches for full-body anonymization have been proposed, human-guided anonymization can adapt to various contexts, such as cultural norms, personal relations, esthetic concerns, and security issues. ''My Body My Choice'' (MBMC) enables physical and adversarial anonymization by removal and swapping approaches aimed for four tasks, designed by single or multi, ControlNet or GAN modules, combining several diffusion models. We evaluate anonymization on seven datasets; compare with SOTA inpainting and anonymization methods; evaluate by image, adversarial, and generative metrics; and conduct reidentification experiments.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "AI for Content Creation Workshop @ CVPR 2024"
    },
    {
        "paper id": "2406.09567",
        "abstract url": "https://arxiv.org/abs/2406.09567",
        "title": "Causal Fine-Tuning and Effect Calibration of Non-Causal Predictive Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes techniques to enhance the performance of non-causal models for causal inference using data from randomized experiments. In domains like advertising, customer retention, and precision medicine, non-causal models that predict outcomes under no intervention are often used to score individuals and rank them according to the expected effectiveness of an intervention (e.g, an ad, a retention incentive, a nudge). However, these scores may not perfectly correspond to intervention effects due to the inherent non-causal nature of the models. To address this limitation, we propose causal fine-tuning and effect calibration, two techniques that leverage experimental data to refine the output of non-causal models for different causal tasks, including effect estimation, effect ordering, and effect classification. They are underpinned by two key advantages. First, they can effectively integrate the predictive capabilities of general non-causal models with the requirements of a causal task in a specific context, allowing decision makers to support diverse causal applications with a \"foundational\" scoring model. Second, through simulations and an empirical example, we demonstrate that they can outperform the alternative of building a causal-effect model from scratch, particularly when the available experimental data is limited and the non-causal scores already capture substantial information about the relative sizes of causal effects. Overall, this research underscores the practical advantages of combining experimental data with non-causal models to support causal applications.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09574",
        "abstract url": "https://arxiv.org/abs/2406.09574",
        "title": "Online Bandit Learning with Offline Preference Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning with Human Feedback (RLHF) is at the core of fine-tuning methods for generative AI models for language and images. Such feedback is often sought as rank or preference feedback from human raters, as opposed to eliciting scores since the latter tends to be very noisy. On the other hand, RL theory and algorithms predominantly assume that a reward feedback is available. In particular, approaches for online learning that can be helpful in adaptive data collection via active learning cannot incorporate offline preference data. In this paper, we adopt a finite-armed linear bandit model as a prototypical model of online learning. We consider an offline preference dataset to be available generated by an expert of unknown 'competence'. We propose $\\texttt{warmPref-PS}$, a posterior sampling algorithm for online learning that can be warm-started with an offline dataset with noisy preference feedback. We show that by modeling the competence of the expert that generated it, we are able to use such a dataset most effectively. We support our claims with novel theoretical analysis of its Bayesian regret, as well as extensive empirical evaluation of an approximate algorithm which performs substantially better (almost 25 to 50% regret reduction in our studies) as compared to baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09581",
        "abstract url": "https://arxiv.org/abs/2406.09581",
        "title": "A Review of 315 Benchmark and Test Functions for Machine Learning Optimization Algorithms and Metaheuristics with Mathematical and Visual Descriptions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the rapidly evolving optimization and metaheuristics domains, the efficacy of algorithms is crucially determined by the benchmark (test) functions. While several functions have been developed and derived over the past decades, little information is available on the mathematical and visual description, range of suitability, and applications of many such functions. To bridge this knowledge gap, this review provides an exhaustive survey of more than 300 benchmark functions used in the evaluation of optimization and metaheuristics algorithms. This review first catalogs benchmark and test functions based on their characteristics, complexity, properties, visuals, and domain implications to offer a wide view that aids in selecting appropriate benchmarks for various algorithmic challenges. This review also lists the 25 most commonly used functions in the open literature and proposes two new, highly dimensional, dynamic and challenging functions that could be used for testing new algorithms. Finally, this review identifies gaps in current benchmarking practices and suggests directions for future research.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09592",
        "abstract url": "https://arxiv.org/abs/2406.09592",
        "title": "On Value Iteration Convergence in Connected MDPs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper establishes that an MDP with a unique optimal policy and ergodic associated transition matrix ensures the convergence of various versions of the Value Iteration algorithm at a geometric rate that exceeds the discount factor \u03b3 for both discounted and average-reward criteria.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 1 figure"
    },
    {
        "paper id": "2406.09657",
        "abstract url": "https://arxiv.org/abs/2406.09657",
        "title": "ScaLES: Scalable Latent Exploration Score for Pre-Trained Generative Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop Scalable Latent Exploration Score (ScaLES) to mitigate over-exploration in Latent Space Optimization (LSO), a popular method for solving black-box discrete optimization problems. LSO utilizes continuous optimization within the latent space of a Variational Autoencoder (VAE) and is known to be susceptible to over-exploration, which manifests in unrealistic solutions that reduce its practicality. ScaLES is an exact and theoretically motivated method leveraging the trained decoder's approximation of the data distribution. ScaLES can be calculated with any existing decoder, e.g. from a VAE, without additional training, architectural changes, or access to the training data. Our evaluation across five LSO benchmark tasks and three VAE architectures demonstrates that ScaLES enhances the quality of the solutions while maintaining high objective values, leading to improvements over existing solutions. We believe that new avenues to LSO will be opened by ScaLES ability to identify out of distribution areas, differentiability, and computational tractability. Open source code for ScaLES is available at https://github.com/OmerRonen/scales.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09661",
        "abstract url": "https://arxiv.org/abs/2406.09661",
        "title": "Temporal Planning via Interval Logic Satisfiability for Autonomous Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Many automated planning methods and formulations rely on suitably designed abstractions or simplifications of the constrained dynamics associated with agents to attain computational scalability. We consider formulations of temporal planning where intervals are associated with both action and fluent atoms, and relations between these are given as sentences in Allen's Interval Logic. We propose a notion of planning graphs that can account for complex concurrency relations between actions and fluents as a Constraint Programming (CP) model. We test an implementation of our algorithm on a state-of-the-art framework for CP and compare it with PDDL 2.1 planners that capture plans requiring complex concurrent interactions between agents. We demonstrate our algorithm outperforms existing PDDL 2.1 planners in the case studies. Still, scalability remains challenging when plans must comply with intricate concurrent interactions and the sequencing of actions.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "eess.SY"
        ],
        "comment": "This publication is an extended version of a manuscript submitted to ICAPS-24 (and rejected). Please contact the first author for queries, comments or discussion of the paper"
    },
    {
        "paper id": "2406.09664",
        "abstract url": "https://arxiv.org/abs/2406.09664",
        "title": "Frequency-mix Knowledge Distillation for Fake Speech Detection",
        "rating": "0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "In the telephony scenarios, the fake speech detection (FSD) task to combat speech spoofing attacks is challenging. Data augmentation (DA) methods are considered effective means to address the FSD task in telephony scenarios, typically divided into time domain and frequency domain stages. While each has its advantages, both can result in information loss. To tackle this issue, we propose a novel DA method, Frequency-mix (Freqmix), and introduce the Freqmix knowledge distillation (FKD) to enhance model information extraction and generalization abilities. Specifically, we use Freqmix-enhanced data as input for the teacher model, while the student model's input undergoes time-domain DA method. We use a multi-level feature distillation approach to restore information and improve the model's generalization capabilities. Our approach achieves state-of-the-art results on ASVspoof 2021 LA dataset, showing a 31\\% improvement over baseline and performs competitively on ASVspoof 2021 DF dataset.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by Interspeech 2024"
    },
    {
        "paper id": "2406.09684",
        "abstract url": "https://arxiv.org/abs/2406.09684",
        "title": "Explainable AI for Comparative Analysis of Intrusion Detection Models",
        "rating": "0.5",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Explainable Artificial Intelligence (XAI) has become a widely discussed topic, the related technologies facilitate better understanding of conventional black-box models like Random Forest, Neural Networks and etc. However, domain-specific applications of XAI are still insufficient. To fill this gap, this research analyzes various machine learning models to the tasks of binary and multi-class classification for intrusion detection from network traffic on the same dataset using occlusion sensitivity. The models evaluated include Linear Regression, Logistic Regression, Linear Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest, Decision Trees, and Multi-Layer Perceptrons (MLP). We trained all models to the accuracy of 90\\% on the UNSW-NB15 Dataset. We found that most classifiers leverage only less than three critical features to achieve such accuracies, indicating that effective feature engineering could actually be far more important for intrusion detection than applying complicated models. We also discover that Random Forest provides the best performance in terms of accuracy, time efficiency and robustness. Data and code available at https://github.com/pcwhy/XML-IntrusionDetection.git",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "Submitted to IEEE MeditCom 2024 - WS-05"
    },
    {
        "paper id": "2406.09694",
        "abstract url": "https://arxiv.org/abs/2406.09694",
        "title": "An Efficient Approach to Regression Problems with Tensor Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a tensor neural network (TNN) to address nonparametric regression problems. Characterized by its distinct sub-network structure, the TNN effectively facilitates variable separation, thereby enhancing the approximation of complex, unknown functions. Our comparative analysis reveals that the TNN outperforms conventional Feed-Forward Networks (FFN) and Radial Basis Function Networks (RBN) in terms of both approximation accuracy and generalization potential, despite a similar scale of parameters. A key innovation of our approach is the integration of statistical regression and numerical integration within the TNN framework. This integration allows for the efficient computation of high-dimensional integrals associated with the regression function. The implications of this advancement extend to a broader range of applications, particularly in scenarios demanding precise high-dimensional data analysis and prediction.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09713",
        "abstract url": "https://arxiv.org/abs/2406.09713",
        "title": "Meta-Learning Loss Functions for Deep Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Humans can often quickly and efficiently solve complex new learning tasks given only a small set of examples. In contrast, modern artificially intelligent systems often require thousands or millions of observations in order to solve even the most basic tasks. Meta-learning aims to resolve this issue by leveraging past experiences from similar learning tasks to embed the appropriate inductive biases into the learning system. Historically methods for meta-learning components such as optimizers, parameter initializations, and more have led to significant performance increases. This thesis aims to explore the concept of meta-learning to improve performance, through the often-overlooked component of the loss function. The loss function is a vital component of a learning system, as it represents the primary learning objective, where success is determined and quantified by the system's ability to optimize for that objective successfully.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE"
        ],
        "comment": "PhD thesis"
    },
    {
        "paper id": "2406.09714",
        "abstract url": "https://arxiv.org/abs/2406.09714",
        "title": "Large language model validity via enhanced conformal prediction methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop new conformal inference methods for obtaining validity guarantees on the output of large language models (LLMs). Prior work in conformal language modeling identifies a subset of the text that satisfies a high-probability guarantee of correctness. These methods work by filtering claims from the LLM's original response if a scoring function evaluated on the claim fails to exceed a threshold calibrated via split conformal prediction. Existing methods in this area suffer from two deficiencies. First, the guarantee stated is not conditionally valid. The trustworthiness of the filtering step may vary based on the topic of the response. Second, because the scoring function is imperfect, the filtering step can remove many valuable and accurate claims. We address both of these challenges via two new conformal methods. First, we generalize the conditional conformal procedure of Gibbs et al. (2023) in order to adaptively issue weaker guarantees when they are required to preserve the utility of the output. Second, we show how to systematically improve the quality of the scoring function via a novel algorithm for differentiating through the conditional conformal procedure. We demonstrate the efficacy of our approach on both synthetic and real-world datasets.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": "20 pages, 8 figures"
    },
    {
        "paper id": "2406.09716",
        "abstract url": "https://arxiv.org/abs/2406.09716",
        "title": "Speed-up of Data Analysis with Kernel Trick in Encrypted Domain",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Homomorphic encryption (HE) is pivotal for secure computation on encrypted data, crucial in privacy-preserving data analysis. However, efficiently processing high-dimensional data in HE, especially for machine learning and statistical (ML/STAT) algorithms, poses a challenge. In this paper, we present an effective acceleration method using the kernel method for HE schemes, enhancing time performance in ML/STAT algorithms within encrypted domains. This technique, independent of underlying HE mechanisms and complementing existing optimizations, notably reduces costly HE multiplications, offering near constant time complexity relative to data dimension. Aimed at accessibility, this method is tailored for data scientists and developers with limited cryptography background, facilitating advanced data analysis in secure environments.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.DC",
            "cs.LG"
        ],
        "comment": "Submitted as a preprint"
    },
    {
        "paper id": "2406.08810",
        "abstract url": "https://arxiv.org/abs/2406.08810",
        "title": "Few-Shot Anomaly Detection via Category-Agnostic Registration Learning",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most existing anomaly detection methods require a dedicated model for each category. Such a paradigm, despite its promising results, is computationally expensive and inefficient, thereby failing to meet the requirements for real-world applications. Inspired by how humans detect anomalies, by comparing a query image to known normal ones, this paper proposes a novel few-shot anomaly detection (FSAD) framework. Using a training set of normal images from various categories, registration, aiming to align normal images of the same categories, is leveraged as the proxy task for self-supervised category-agnostic representation learning. At test time, an image and its corresponding support set, consisting of a few normal images from the same category, are supplied, and anomalies are identified by comparing the registered features of the test image to its corresponding support image features. Such a setup enables the model to generalize to novel test categories. It is, to our best knowledge, the first FSAD method that requires no model fine-tuning for novel categories: enabling a single model to be applied to all categories. Extensive experiments demonstrate the effectiveness of the proposed method. Particularly, it improves the current state-of-the-art for FSAD by 11.3% and 8.3% on the MVTec and MPDD benchmarks, respectively. The source code is available at https://github.com/Haoyan-Guan/CAReg.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08820",
        "abstract url": "https://arxiv.org/abs/2406.08820",
        "title": "DisfluencySpeech -- Single-Speaker Conversational Speech Dataset with Paralanguage",
        "rating": "0",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Laughing, sighing, stuttering, and other forms of paralanguage do not contribute any direct lexical meaning to speech, but they provide crucial propositional context that aids semantic and pragmatic processes such as irony. It is thus important for artificial social agents to both understand and be able to generate speech with semantically-important paralanguage. Most speech datasets do not include transcribed non-lexical speech sounds and disfluencies, while those that do are typically multi-speaker datasets where each speaker provides relatively little audio. This makes it challenging to train conversational Text-to-Speech (TTS) synthesis models that include such paralinguistic components. We thus present DisfluencySpeech, a studio-quality labeled English speech dataset with paralanguage. A single speaker recreates nearly 10 hours of expressive utterances from the Switchboard-1 Telephone Speech Corpus (Switchboard), simulating realistic informal conversations. To aid the development of a TTS model that is able to predictively synthesise paralanguage from text without such components, we provide three different transcripts at different levels of information removal (removal of non-speech events, removal of non-sentence elements, and removal of false starts), as well as benchmark TTS models trained on each of these levels.",
        "subjects": [
            "eess.AS",
            "cs.CL"
        ],
        "comment": "4 pages, 1 figure, submitted to IEEE TENCON 2024"
    },
    {
        "paper id": "2406.08824",
        "abstract url": "https://arxiv.org/abs/2406.08824",
        "title": "LLM-Driven Robots Risk Enacting Discrimination, Violence, and Unlawful Actions",
        "rating": "0",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Members of the Human-Robot Interaction (HRI) and Artificial Intelligence (AI) communities have proposed Large Language Models (LLMs) as a promising resource for robotics tasks such as natural language interactions, doing household and workplace tasks, approximating `common sense reasoning', and modeling humans. However, recent research has raised concerns about the potential for LLMs to produce discriminatory outcomes and unsafe behaviors in real-world robot experiments and applications. To address these concerns, we conduct an HRI-based evaluation of discrimination and safety criteria on several highly-rated LLMs. Our evaluation reveals that LLMs currently lack robustness when encountering people across a diverse range of protected identity characteristics (e.g., race, gender, disability status, nationality, religion, and their intersections), producing biased outputs consistent with directly discriminatory outcomes -- e.g. `gypsy' and `mute' people are labeled untrustworthy, but not `european' or `able-bodied' people. Furthermore, we test models in settings with unconstrained natural language (open vocabulary) inputs, and find they fail to act safely, generating responses that accept dangerous, violent, or unlawful instructions -- such as incident-causing misstatements, taking people's mobility aids, and sexual predation. Our results underscore the urgent need for systematic, routine, and comprehensive risk assessments and assurances to improve outcomes and ensure LLMs only operate on robots when it is safe, effective, and just to do so. Data and code will be made available.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL",
            "cs.CY"
        ],
        "comment": "40 pages (52 with references), 21 Figures, 6 Tables"
    },
    {
        "paper id": "2406.08829",
        "abstract url": "https://arxiv.org/abs/2406.08829",
        "title": "Improving Adversarial Robustness via Feature Pattern Consistency Constraint",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Convolutional Neural Networks (CNNs) are well-known for their vulnerability to adversarial attacks, posing significant security concerns. In response to these threats, various defense methods have emerged to bolster the model's robustness. However, most existing methods either focus on learning from adversarial perturbations, leading to overfitting to the adversarial examples, or aim to eliminate such perturbations during inference, inevitably increasing computational burdens. Conversely, clean training, which strengthens the model's robustness by relying solely on clean examples, can address the aforementioned issues. In this paper, we align with this methodological stream and enhance its generalizability to unknown adversarial examples. This enhancement is achieved by scrutinizing the behavior of latent features within the network. Recognizing that a correct prediction relies on the correctness of the latent feature's pattern, we introduce a novel and effective Feature Pattern Consistency Constraint (FPCC) method to reinforce the latent feature's capacity to maintain the correct feature pattern. Specifically, we propose Spatial-wise Feature Modification and Channel-wise Feature Selection to enhance latent features. Subsequently, we employ the Pattern Consistency Loss to constrain the similarity between the feature pattern of the latent features and the correct feature pattern. Our experiments demonstrate that the FPCC method empowers latent features to uphold correct feature patterns even in the face of adversarial examples, resulting in inherent adversarial robustness surpassing state-of-the-art models.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08842",
        "abstract url": "https://arxiv.org/abs/2406.08842",
        "title": "ContraSolver: Self-Alignment of Language Models by Resolving Internal Preference Contradictions",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While substantial advancements have been made in developing large language models (LLMs), achieving control over their behavior can be difficult. Direct preference optimization (DPO) assumes the existence of a latent reward function to evaluate the responses of LLMs. This assumption indicates a strict preference ordering of different responses to the same input. However, there always exist contradictions of preference in LLMs according to our experimental observations. In this paper, we construct a graph structure of the preference relationship among different responses with self-annotation to find contradictions in the preference order. We propose ContraSolver, an algorithm that traverses all edges on the preference graph to identify those that might cause contradictions. ContraSolver initializes the graph with a maximum spanning tree and identifies contradictory edges, prioritizing the resolution of low-confidence preferences while preserving high-confidence ones. Experimental results on four different generation tasks show that the performance of different LLMs can be largely improved through our completely unsupervised self-alignment. Furthermore, by analyzing the preference graphs of LLMs with and without self-alignment by ContraSolver, we quantify the reduction in contradictions, suggesting that resolving preference contradictions is crucial for achieving better alignment performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08845",
        "abstract url": "https://arxiv.org/abs/2406.08845",
        "title": "Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing Reliability,Reproducibility, and Practicality",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent text-to-video (T2V) technology advancements, as demonstrated by models such as Gen2, Pika, and Sora, have significantly broadened its applicability and popularity. Despite these strides, evaluating these models poses substantial challenges. Primarily, due to the limitations inherent in automatic metrics, manual evaluation is often considered a superior method for assessing T2V generation. However, existing manual evaluation protocols face reproducibility, reliability, and practicality issues. To address these challenges, this paper introduces the Text-to-Video Human Evaluation (T2VHE) protocol, a comprehensive and standardized protocol for T2V models. The T2VHE protocol includes well-defined metrics, thorough annotator training, and an effective dynamic evaluation module. Experimental results demonstrate that this protocol not only ensures high-quality annotations but can also reduce evaluation costs by nearly 50%. We will open-source the entire setup of the T2VHE protocol, including the complete protocol workflow, the dynamic evaluation component details, and the annotation interface code. This will help communities establish more sophisticated human assessment protocols.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08896",
        "abstract url": "https://arxiv.org/abs/2406.08896",
        "title": "Blind Super-Resolution via Meta-learning and Markov Chain Monte Carlo Simulation",
        "rating": "0",
        "keywords": [
            [
                "synthesis",
                "Super-Resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Learning-based approaches have witnessed great successes in blind single image super-resolution (SISR) tasks, however, handcrafted kernel priors and learning based kernel priors are typically required. In this paper, we propose a Meta-learning and Markov Chain Monte Carlo (MCMC) based SISR approach to learn kernel priors from organized randomness. In concrete, a lightweight network is adopted as kernel generator, and is optimized via learning from the MCMC simulation on random Gaussian distributions. This procedure provides an approximation for the rational blur kernel, and introduces a network-level Langevin dynamics into SISR optimization processes, which contributes to preventing bad local optimal solutions for kernel estimation. Meanwhile, a meta-learning-based alternating optimization procedure is proposed to optimize the kernel generator and image restorer, respectively. In contrast to the conventional alternating minimization strategy, a meta-learning-based framework is applied to learn an adaptive optimization strategy, which is less-greedy and results in better convergence performance. These two procedures are iteratively processed in a plug-and-play fashion, for the first time, realizing a learning-based but plug-and-play blind SISR solution in unsupervised inference. Extensive simulations demonstrate the superior performance and generalization ability of the proposed approach when comparing with state-of-the-arts on synthesis and real-world datasets. The code is available at https://github.com/XYLGroup/MLMC.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "This paper has been accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence (2024)"
    },
    {
        "paper id": "2406.08907",
        "abstract url": "https://arxiv.org/abs/2406.08907",
        "title": "Dual Attribute-Spatial Relation Alignment for 3D Visual Grounding",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D visual grounding is an emerging research area dedicated to making connections between the 3D physical world and natural language, which is crucial for achieving embodied intelligence. In this paper, we propose DASANet, a Dual Attribute-Spatial relation Alignment Network that separately models and aligns object attributes and spatial relation features between language and 3D vision modalities. We decompose both the language and 3D point cloud input into two separate parts and design a dual-branch attention module to separately model the decomposed inputs while preserving global context in attribute-spatial feature fusion by cross attentions. Our DASANet achieves the highest grounding accuracy 65.1% on the Nr3D dataset, 1.3% higher than the best competitor. Besides, the visualization of the two branches proves that our method is efficient and highly interpretable.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08909",
        "abstract url": "https://arxiv.org/abs/2406.08909",
        "title": "A Label-Free and Non-Monotonic Metric for Evaluating Denoising in Event Cameras",
        "rating": "0",
        "keywords": [
            [
                "Event Cameras"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Event cameras are renowned for their high efficiency due to outputting a sparse, asynchronous stream of events. However, they are plagued by noisy events, especially in low light conditions. Denoising is an essential task for event cameras, but evaluating denoising performance is challenging. Label-dependent denoising metrics involve artificially adding noise to clean sequences, complicating evaluations. Moreover, the majority of these metrics are monotonic, which can inflate scores by removing substantial noise and valid events. To overcome these limitations, we propose the first label-free and non-monotonic evaluation metric, the area of the continuous contrast curve (AOCC), which utilizes the area enclosed by event frame contrast curves across different time intervals. This metric is inspired by how events capture the edge contours of scenes or objects with high temporal resolution. An effective denoising method removes noise without eliminating these edge-contour events, thus preserving the contrast of event frames. Consequently, contrast across various time ranges serves as a metric to assess denoising effectiveness. As the time interval lengthens, the curve will initially rise and then fall. The proposed metric is validated through both theoretical and experimental evidence.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08920",
        "abstract url": "https://arxiv.org/abs/2406.08920",
        "title": "AV-GS: Learning Material and Geometry Aware Priors for Novel View Acoustic Synthesis",
        "rating": "0",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "3D",
                "Gaussian Splatting",
                "NeRF"
            ],
            [
                "Synthesis"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Novel view acoustic synthesis (NVAS) aims to render binaural audio at any target viewpoint, given a mono audio emitted by a sound source at a 3D scene. Existing methods have proposed NeRF-based implicit models to exploit visual cues as a condition for synthesizing binaural audio. However, in addition to low efficiency originating from heavy NeRF rendering, these methods all have a limited ability of characterizing the entire scene environment such as room geometry, material properties, and the spatial relation between the listener and sound source. To address these issues, we propose a novel Audio-Visual Gaussian Splatting (AV-GS) model. To obtain a material-aware and geometry-aware condition for audio synthesis, we learn an explicit point-based scene representation with an audio-guidance parameter on locally initialized Gaussian points, taking into account the space relation from the listener and sound source. To make the visual scene model audio adaptive, we propose a point densification and pruning strategy to optimally distribute the Gaussian points, with the per-point contribution in sound propagation (e.g., more points needed for texture-less wall surfaces as they affect sound path diversion). Extensive experiments validate the superiority of our AV-GS over existing alternatives on the real-world RWAS and simulation-based SoundSpaces datasets.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08928",
        "abstract url": "https://arxiv.org/abs/2406.08928",
        "title": "Multiple Prior Representation Learning for Self-Supervised Monocular Depth Estimation via Hybrid Transformer",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Self-supervised monocular depth estimation aims to infer depth information without relying on labeled data. However, the lack of labeled information poses a significant challenge to the model's representation, limiting its ability to capture the intricate details of the scene accurately. Prior information can potentially mitigate this issue, enhancing the model's understanding of scene structure and texture. Nevertheless, solely relying on a single type of prior information often falls short when dealing with complex scenes, necessitating improvements in generalization performance. To address these challenges, we introduce a novel self-supervised monocular depth estimation model that leverages multiple priors to bolster representation capabilities across spatial, context, and semantic dimensions. Specifically, we employ a hybrid transformer and a lightweight pose network to obtain long-range spatial priors in the spatial dimension. Then, the context prior attention is designed to improve generalization, particularly in complex structures or untextured areas. In addition, semantic priors are introduced by leveraging semantic boundary loss, and semantic prior attention is supplemented, further refining the semantic features extracted by the decoder. Experiments on three diverse datasets demonstrate the effectiveness of the proposed model. It integrates multiple priors to comprehensively enhance the representation ability, improving the accuracy and reliability of depth estimation. Codes are available at: \\url{https://github.com/MVME-HBUT/MPRLNet}",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "28 pages, 12 figures"
    },
    {
        "paper id": "2406.08929",
        "abstract url": "https://arxiv.org/abs/2406.08929",
        "title": "Step-by-Step Diffusion: An Elementary Tutorial",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present an accessible first course on diffusion models and flow matching for machine learning, aimed at a technical audience with no diffusion experience. We try to simplify the mathematical details as much as possible (sometimes heuristically), while retaining enough precision to derive correct algorithms.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "stat.ML"
        ],
        "comment": "35 pages, 11 figures"
    },
    {
        "paper id": "2406.08989",
        "abstract url": "https://arxiv.org/abs/2406.08989",
        "title": "ToneUnit: A Speech Discretization Approach for Tonal Language Speech Synthesis",
        "rating": "0",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Representing speech as discretized units has numerous benefits in supporting downstream spoken language processing tasks. However, the approach has been less explored in speech synthesis of tonal languages like Mandarin Chinese. Our preliminary experiments on Chinese speech synthesis reveal the issue of \"tone shift\", where a synthesized speech utterance contains correct base syllables but incorrect tones. To address the issue, we propose the ToneUnit framework, which leverages annotated data with tone labels as CTC supervision to learn tone-aware discrete speech units for Mandarin Chinese speech. Our findings indicate that the discrete units acquired through the TonUnit resolve the \"tone shift\" issue in synthesized Chinese speech and yield favorable results in English synthesis. Moreover, the experimental results suggest that finite scalar quantization enhances the effectiveness of ToneUnit. Notably, ToneUnit can work effectively even with minimal annotated data.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08997",
        "abstract url": "https://arxiv.org/abs/2406.08997",
        "title": "Adaptive Temporal Motion Guided Graph Convolution Network for Micro-expression Recognition",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Micro-expressions serve as essential cues for understanding individuals' genuine emotional states. Recognizing micro-expressions attracts increasing research attention due to its various applications in fields such as business negotiation and psychotherapy. However, the intricate and transient nature of micro-expressions poses a significant challenge to their accurate recognition. Most existing works either neglect temporal dependencies or suffer from redundancy issues in clip-level recognition. In this work, we propose a novel framework for micro-expression recognition, named the Adaptive Temporal Motion Guided Graph Convolution Network (ATM-GCN). Our framework excels at capturing temporal dependencies between frames across the entire clip, thereby enhancing micro-expression recognition at the clip level. Specifically, the integration of Adaptive Temporal Motion layers empowers our method to aggregate global and local motion features inherent in micro-expressions. Experimental results demonstrate that ATM-GCN not only surpasses existing state-of-the-art methods, particularly on the Composite dataset, but also achieves superior performance on the latest micro-expression dataset CAS(ME)$^3$.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICME 2024"
    },
    {
        "paper id": "2406.09070",
        "abstract url": "https://arxiv.org/abs/2406.09070",
        "title": "EquiPrompt: Debiasing Diffusion Models via Iterative Bootstrapping in Chain of Thoughts",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In the domain of text-to-image generative models, the inadvertent propagation of biases inherent in training datasets poses significant ethical challenges, particularly in the generation of socially sensitive content. This paper introduces EquiPrompt, a novel method employing Chain of Thought (CoT) reasoning to reduce biases in text-to-image generative models. EquiPrompt uses iterative bootstrapping and bias-aware exemplar selection to balance creativity and ethical responsibility. It integrates iterative reasoning refinement with controlled evaluation techniques, addressing zero-shot CoT issues in sensitive contexts. Experiments on several generation tasks show EquiPrompt effectively lowers bias while maintaining generative quality, advancing ethical AI and socially responsible creative processes.Code will be publically available.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09154",
        "abstract url": "https://arxiv.org/abs/2406.09154",
        "title": "Diffusion Gaussian Mixture Audio Denoise",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent diffusion models have achieved promising performances in audio-denoising tasks. The unique property of the reverse process could recover clean signals. However, the distribution of real-world noises does not comply with a single Gaussian distribution and is even unknown. The sampling of Gaussian noise conditions limits its application scenarios. To overcome these challenges, we propose a DiffGMM model, a denoising model based on the diffusion and Gaussian mixture models. We employ the reverse process to estimate parameters for the Gaussian mixture model. Given a noisy audio signal, we first apply a 1D-U-Net to extract features and train linear layers to estimate parameters for the Gaussian mixture model, and we approximate the real noise distributions. The noisy signal is continuously subtracted from the estimated noise to output clean audio signals. Extensive experimental results demonstrate that the proposed DiffGMM model achieves state-of-the-art performance.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "INTERSPEECH 2024"
    },
    {
        "paper id": "2406.09161",
        "abstract url": "https://arxiv.org/abs/2406.09161",
        "title": "Complex Image-Generative Diffusion Transformer for Audio Denoising",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The audio denoising technique has captured widespread attention in the deep neural network field. Recently, the audio denoising problem has been converted into an image generation task, and deep learning-based approaches have been applied to tackle this problem. However, its performance is still limited, leaving room for further improvement. In order to enhance audio denoising performance, this paper introduces a complex image-generative diffusion transformer that captures more information from the complex Fourier domain. We explore a novel diffusion transformer by integrating the transformer with a diffusion model. Our proposed model demonstrates the scalability of the transformer and expands the receptive field of sparse attention using attention diffusion. Our work is among the first to utilize diffusion transformers to deal with the image generation task for audio denoising. Extensive experiments on two benchmark datasets demonstrate that our proposed model outperforms state-of-the-art methods.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "INTERSPEECH 2024"
    },
    {
        "paper id": "2406.09162",
        "abstract url": "https://arxiv.org/abs/2406.09162",
        "title": "EMMA: Your Text-to-Image Diffusion Model Can Secretly Accept Multi-Modal Prompts",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in image generation have enabled the creation of high-quality images from text conditions. However, when facing multi-modal conditions, such as text combined with reference appearances, existing methods struggle to balance multiple conditions effectively, typically showing a preference for one modality over others. To address this challenge, we introduce EMMA, a novel image generation model accepting multi-modal prompts built upon the state-of-the-art text-to-image (T2I) diffusion model, ELLA. EMMA seamlessly incorporates additional modalities alongside text to guide image generation through an innovative Multi-modal Feature Connector design, which effectively integrates textual and supplementary modal information using a special attention mechanism. By freezing all parameters in the original T2I diffusion model and only adjusting some additional layers, we reveal an interesting finding that the pre-trained T2I diffusion model can secretly accept multi-modal prompts. This interesting property facilitates easy adaptation to different existing frameworks, making EMMA a flexible and effective tool for producing personalized and context-aware images and even videos. Additionally, we introduce a strategy to assemble learned EMMA modules to produce images conditioned on multiple modalities simultaneously, eliminating the need for additional training with mixed multi-modal prompts. Extensive experiments demonstrate the effectiveness of EMMA in maintaining high fidelity and detail in generated images, showcasing its potential as a robust solution for advanced multi-modal conditional image generation tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "https://tencentqqgylab.github.io/EMMA"
    },
    {
        "paper id": "2406.09177",
        "abstract url": "https://arxiv.org/abs/2406.09177",
        "title": "Scalable and Flexible Causal Discovery with an Efficient Test for Adjacency",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "To make accurate predictions, understand mechanisms, and design interventions in systems of many variables, we wish to learn causal graphs from large scale data. Unfortunately the space of all possible causal graphs is enormous so scalably and accurately searching for the best fit to the data is a challenge. In principle we could substantially decrease the search space, or learn the graph entirely, by testing the conditional independence of variables. However, deciding if two variables are adjacent in a causal graph may require an exponential number of tests. Here we build a scalable and flexible method to evaluate if two variables are adjacent in a causal graph, the Differentiable Adjacency Test (DAT). DAT replaces an exponential number of tests with a provably equivalent relaxed problem. It then solves this problem by training two neural networks. We build a graph learning method based on DAT, DAT-Graph, that can also learn from data with interventions. DAT-Graph can learn graphs of 1000 variables with state of the art accuracy. Using the graph learned by DAT-Graph, we also build models that make much more accurate predictions of the effects of interventions on large scale RNA sequencing data.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "ICML 2024; Code at https://github.com/AlanNawzadAmin/DAT-graph"
    },
    {
        "paper id": "2406.09203",
        "abstract url": "https://arxiv.org/abs/2406.09203",
        "title": "Optimizing Visual Question Answering Models for Driving: Bridging the Gap Between Human and Machine Attention Patterns",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual Question Answering (VQA) models play a critical role in enhancing the perception capabilities of autonomous driving systems by allowing vehicles to analyze visual inputs alongside textual queries, fostering natural interaction and trust between the vehicle and its occupants or other road users. This study investigates the attention patterns of humans compared to a VQA model when answering driving-related questions, revealing disparities in the objects observed. We propose an approach integrating filters to optimize the model's attention mechanisms, prioritizing relevant objects and improving accuracy. Utilizing the LXMERT model for a case study, we compare attention patterns of the pre-trained and Filter Integrated models, alongside human answers using images from the NuImages dataset, gaining insights into feature prioritization. We evaluated the models using a Subjective scoring framework which shows that the integration of the feature encoder filter has enhanced the performance of the VQA model by refining its attention mechanisms.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09250",
        "abstract url": "https://arxiv.org/abs/2406.09250",
        "title": "MirrorCheck: Efficient Adversarial Defense for Vision-Language Models",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "Text-to-Image"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Vision-Language Models (VLMs) are becoming increasingly vulnerable to adversarial attacks as various novel attack strategies are being proposed against these models. While existing defenses excel in unimodal contexts, they currently fall short in safeguarding VLMs against adversarial threats. To mitigate this vulnerability, we propose a novel, yet elegantly simple approach for detecting adversarial samples in VLMs. Our method leverages Text-to-Image (T2I) models to generate images based on captions produced by target VLMs. Subsequently, we calculate the similarities of the embeddings of both input and generated images in the feature space to identify adversarial samples. Empirical evaluations conducted on different datasets validate the efficacy of our approach, outperforming baseline methods adapted from image classification domains. Furthermore, we extend our methodology to classification tasks, showcasing its adaptability and model-agnostic nature. Theoretical analyses and empirical findings also show the resilience of our approach against adaptive attacks, positioning it as an excellent defense mechanism for real-world deployment against adversarial threats.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09293",
        "abstract url": "https://arxiv.org/abs/2406.09293",
        "title": "StableMaterials: Enhancing Diversity in Material Generation via Semi-Supervised Learning",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce StableMaterials, a novel approach for generating photorealistic physical-based rendering (PBR) materials that integrate semi-supervised learning with Latent Diffusion Models (LDMs). Our method employs adversarial training to distill knowledge from existing large-scale image generation models, minimizing the reliance on annotated data and enhancing the diversity in generation. This distillation approach aligns the distribution of the generated materials with that of image textures from an SDXL model, enabling the generation of novel materials that are not present in the initial training dataset. Furthermore, we employ a diffusion-based refiner model to improve the visual quality of the samples and achieve high-resolution generation. Finally, we distill a latent consistency model for fast generation in just four steps and propose a new tileability technique that removes visual artifacts typically associated with fewer diffusion steps. We detail the architecture and training process of StableMaterials, the integration of semi-supervised training within existing LDM frameworks and show the advantages of our approach. Comparative evaluations with state-of-the-art methods show the effectiveness of StableMaterials, highlighting its potential applications in computer graphics and beyond. StableMaterials is publicly available at https://gvecchio.com/stablematerials.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09305",
        "abstract url": "https://arxiv.org/abs/2406.09305",
        "title": "Toffee: Efficient Million-Scale Dataset Construction for Subject-Driven Text-to-Image Generation",
        "rating": "0",
        "keywords": [
            [
                "image editing",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In subject-driven text-to-image generation, recent works have achieved superior performance by training the model on synthetic datasets containing numerous image pairs. Trained on these datasets, generative models can produce text-aligned images for specific subject from arbitrary testing image in a zero-shot manner. They even outperform methods which require additional fine-tuning on testing images. However, the cost of creating such datasets is prohibitive for most researchers. To generate a single training pair, current methods fine-tune a pre-trained text-to-image model on the subject image to capture fine-grained details, then use the fine-tuned model to create images for the same subject based on creative text prompts. Consequently, constructing a large-scale dataset with millions of subjects can require hundreds of thousands of GPU hours. To tackle this problem, we propose Toffee, an efficient method to construct datasets for subject-driven editing and generation. Specifically, our dataset construction does not need any subject-level fine-tuning. After pre-training two generative models, we are able to generate infinite number of high-quality samples. We construct the first large-scale dataset for subject-driven image editing and generation, which contains 5 million image pairs, text prompts, and masks. Our dataset is 5 times the size of previous largest dataset, yet our cost is tens of thousands of GPU hours lower. To test the proposed dataset, we also propose a model which is capable of both subject-driven image editing and generation. By simply training the model on our proposed dataset, it obtains competitive results, illustrating the effectiveness of the proposed dataset construction framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09317",
        "abstract url": "https://arxiv.org/abs/2406.09317",
        "title": "Common and Rare Fundus Diseases Identification Using Vision-Language Foundation Model with Knowledge of Over 400 Diseases",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "disease",
                "clinical",
                "retinal"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The current retinal artificial intelligence models were trained using data with a limited category of diseases and limited knowledge. In this paper, we present a retinal vision-language foundation model (RetiZero) with knowledge of over 400 fundus diseases. Specifically, we collected 341,896 fundus images paired with text descriptions from 29 publicly available datasets, 180 ophthalmic books, and online resources, encompassing over 400 fundus diseases across multiple countries and ethnicities. RetiZero achieved outstanding performance across various downstream tasks, including zero-shot retinal disease recognition, image-to-image retrieval, internal domain and cross-domain retinal disease classification, and few-shot fine-tuning. Specially, in the zero-shot scenario, RetiZero achieved a Top5 score of 0.8430 and 0.7561 on 15 and 52 fundus diseases respectively. In the image-retrieval task, RetiZero achieved a Top5 score of 0.9500 and 0.8860 on 15 and 52 retinal diseases respectively. Furthermore, clinical evaluations by ophthalmology experts from different countries demonstrate that RetiZero can achieve performance comparable to experienced ophthalmologists using zero-shot and image retrieval methods without requiring model retraining. These capabilities of retinal disease identification strengthen our RetiZero foundation model in clinical implementation.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09321",
        "abstract url": "https://arxiv.org/abs/2406.09321",
        "title": "JailbreakEval: An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Jailbreak attacks aim to induce Large Language Models (LLMs) to generate harmful responses for forbidden instructions, presenting severe misuse threats to LLMs. Up to now, research into jailbreak attacks and defenses is emerging, however, there is (surprisingly) no consensus on how to evaluate whether a jailbreak attempt is successful. In other words, the methods to assess the harmfulness of an LLM's response are varied, such as manual annotation or prompting GPT-4 in specific ways. Each approach has its own set of strengths and weaknesses, impacting their alignment with human values, as well as the time and financial cost. This diversity in evaluation presents challenges for researchers in choosing suitable evaluation methods and conducting fair comparisons across different jailbreak attacks and defenses. In this paper, we conduct a comprehensive analysis of jailbreak evaluation methodologies, drawing from nearly ninety jailbreak research released between May 2023 and April 2024. Our study introduces a systematic taxonomy of jailbreak evaluators, offering in-depth insights into their strengths and weaknesses, along with the current status of their adaptation. Moreover, to facilitate subsequent research, we propose JailbreakEval, a user-friendly toolkit focusing on the evaluation of jailbreak attempts. It includes various well-known evaluators out-of-the-box, so that users can obtain evaluation results with only a single command. JailbreakEval also allows users to customize their own evaluation workflow in a unified framework with the ease of development and comparison. In summary, we regard JailbreakEval to be a catalyst that simplifies the evaluation process in jailbreak research and fosters an inclusive standard for jailbreak evaluation within the community.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Our code is available at https://github.com/ThuCCSLab/JailbreakEval"
    },
    {
        "paper id": "2406.09324",
        "abstract url": "https://arxiv.org/abs/2406.09324",
        "title": "Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Although Large Language Models (LLMs) have demonstrated significant capabilities in executing complex tasks in a zero-shot manner, they are susceptible to jailbreak attacks and can be manipulated to produce harmful outputs. Recently, a growing body of research has categorized jailbreak attacks into token-level and prompt-level attacks. However, previous work primarily overlooks the diverse key factors of jailbreak attacks, with most studies concentrating on LLM vulnerabilities and lacking exploration of defense-enhanced LLMs. To address these issues, we evaluate the impact of various attack settings on LLM performance and provide a baseline benchmark for jailbreak attacks, encouraging the adoption of a standardized evaluation framework. Specifically, we evaluate the eight key factors of implementing jailbreak attacks on LLMs from both target-level and attack-level perspectives. We further conduct seven representative jailbreak attacks on six defense methods across two widely used datasets, encompassing approximately 320 experiments with about 50,000 GPU hours on A800-80G. Our experimental results highlight the need for standardized benchmarking to evaluate these attacks on defense-enhanced LLMs. Our code is available at https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09356",
        "abstract url": "https://arxiv.org/abs/2406.09356",
        "title": "CMC-Bench: Towards a New Paradigm of Visual Signal Compression",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Ultra-low bitrate image compression is a challenging and demanding topic. With the development of Large Multimodal Models (LMMs), a Cross Modality Compression (CMC) paradigm of Image-Text-Image has emerged. Compared with traditional codecs, this semantic-level compression can reduce image data size to 0.1\\% or even lower, which has strong potential applications. However, CMC has certain defects in consistency with the original image and perceptual quality. To address this problem, we introduce CMC-Bench, a benchmark of the cooperative performance of Image-to-Text (I2T) and Text-to-Image (T2I) models for image compression. This benchmark covers 18,000 and 40,000 images respectively to verify 6 mainstream I2T and 12 T2I models, including 160,000 subjective preference scores annotated by human experts. At ultra-low bitrates, this paper proves that the combination of some I2T and T2I models has surpassed the most advanced visual signal codecs; meanwhile, it highlights where LMMs can be further optimized toward the compression task. We encourage LMM developers to participate in this test to promote the evolution of visual signal codec protocols.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09368",
        "abstract url": "https://arxiv.org/abs/2406.09368",
        "title": "CLIPAway: Harmonizing Focused Embeddings for Removing Objects via Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "GAN",
                "inpainting",
                "image editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Advanced image editing techniques, particularly inpainting, are essential for seamlessly removing unwanted elements while preserving visual integrity. Traditional GAN-based methods have achieved notable success, but recent advancements in diffusion models have produced superior results due to their training on large-scale datasets, enabling the generation of remarkably realistic inpainted images. Despite their strengths, diffusion models often struggle with object removal tasks without explicit guidance, leading to unintended hallucinations of the removed object. To address this issue, we introduce CLIPAway, a novel approach leveraging CLIP embeddings to focus on background regions while excluding foreground elements. CLIPAway enhances inpainting accuracy and quality by identifying embeddings that prioritize the background, thus achieving seamless object removal. Unlike other methods that rely on specialized training datasets or costly manual annotations, CLIPAway provides a flexible, plug-and-play solution compatible with various diffusion-based inpainting techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://yigitekin.github.io/CLIPAway/"
    },
    {
        "paper id": "2406.09374",
        "abstract url": "https://arxiv.org/abs/2406.09374",
        "title": "Scale-Invariant Monocular Depth Estimation via SSI Depth",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing methods for scale-invariant monocular depth estimation (SI MDE) often struggle due to the complexity of the task, and limited and non-diverse datasets, hindering generalizability in real-world scenarios. This is while shift-and-scale-invariant (SSI) depth estimation, simplifying the task and enabling training with abundant stereo datasets achieves high performance. We present a novel approach that leverages SSI inputs to enhance SI depth estimation, streamlining the network's role and facilitating in-the-wild generalization for SI depth estimation while only using a synthetic dataset for training. Emphasizing the generation of high-resolution details, we introduce a novel sparse ordinal loss that substantially improves detail generation in SSI MDE, addressing critical limitations in existing approaches. Through in-the-wild qualitative examples and zero-shot evaluation we substantiate the practical utility of our approach in computational photography applications, showcasing its ability to generate highly detailed SI depth maps and achieve generalization in diverse scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To appear in Proc. SIGGRAPH, 2024. Project webpage: https://yaksoy.github.io/sidepth/"
    },
    {
        "paper id": "2406.09390",
        "abstract url": "https://arxiv.org/abs/2406.09390",
        "title": "LLAVIDAL: Benchmarking Large Language Vision Models for Daily Activities of Living",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "skeletons"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Large Language Vision Models (LLVMs) have demonstrated effectiveness in processing internet videos, yet they struggle with the visually perplexing dynamics present in Activities of Daily Living (ADL) due to limited pertinent datasets and models tailored to relevant cues. To this end, we propose a framework for curating ADL multiview datasets to fine-tune LLVMs, resulting in the creation of ADL-X, comprising 100K RGB video-instruction pairs, language descriptions, 3D skeletons, and action-conditioned object trajectories. We introduce LLAVIDAL, an LLVM capable of incorporating 3D poses and relevant object trajectories to understand the intricate spatiotemporal relationships within ADLs. Furthermore, we present a novel benchmark, ADLMCQ, for quantifying LLVM effectiveness in ADL scenarios. When trained on ADL-X, LLAVIDAL consistently achieves state-of-the-art performance across all ADL evaluation metrics. Qualitative analysis reveals LLAVIDAL's temporal reasoning capabilities in understanding ADL. The link to the dataset is provided at: https://adl-x.github.io/",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09399",
        "abstract url": "https://arxiv.org/abs/2406.09399",
        "title": "OmniTokenizer: A Joint Image-Video Tokenizer for Visual Generation",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "synthesis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Tokenizer, serving as a translator to map the intricate visual data into a compact latent space, lies at the core of visual generative models. Based on the finding that existing tokenizers are tailored to image or video inputs, this paper presents OmniTokenizer, a transformer-based tokenizer for joint image and video tokenization. OmniTokenizer is designed with a spatial-temporal decoupled architecture, which integrates window and causal attention for spatial and temporal modeling. To exploit the complementary nature of image and video data, we further propose a progressive training strategy, where OmniTokenizer is first trained on image data on a fixed resolution to develop the spatial encoding capacity and then jointly trained on image and video data on multiple resolutions to learn the temporal dynamics. OmniTokenizer, for the first time, handles both image and video inputs within a unified framework and proves the possibility of realizing their synergy. Extensive experiments demonstrate that OmniTokenizer achieves state-of-the-art (SOTA) reconstruction performance on various image and video datasets, e.g., 1.11 reconstruction FID on ImageNet and 42 reconstruction FVD on UCF-101, beating the previous SOTA methods by 13% and 26%, respectively. Additionally, we also show that when integrated with OmniTokenizer, both language model-based approaches and diffusion models can realize advanced visual synthesis performance, underscoring the superiority and versatility of our method. Code is available at https://github.com/FoundationVision/OmniTokenizer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09403",
        "abstract url": "https://arxiv.org/abs/2406.09403",
        "title": "Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Humans draw to facilitate reasoning: we draw auxiliary lines when solving geometry problems; we mark and circle when reasoning on maps; we use sketches to amplify our ideas and relieve our limited-capacity working memory. However, such actions are missing in current multimodal language models (LMs). Current chain-of-thought and tool-use paradigms only use text as intermediate reasoning steps. In this work, we introduce Sketchpad, a framework that gives multimodal LMs a visual sketchpad and tools to draw on the sketchpad. The LM conducts planning and reasoning according to the visual artifacts it has drawn. Different from prior work, which uses text-to-image models to enable LMs to draw, Sketchpad enables LMs to draw with lines, boxes, marks, etc., which is closer to human sketching and better facilitates reasoning. Sketchpad can also use specialist vision models during the sketching process (e.g., draw bounding boxes with object detection models, draw masks with segmentation models), to further enhance visual perception and reasoning. We experiment with a wide range of math tasks (including geometry, functions, graphs, and chess) and complex visual reasoning tasks. Sketchpad substantially improves performance on all tasks over strong base models with no sketching, yielding an average gain of 12.7% on math tasks, and 8.6% on vision tasks. GPT-4o with Sketchpad sets a new state of the art on all tasks, including V*Bench (80.3%), BLINK spatial reasoning (83.9%), and visual correspondence (80.8%). All codes and data are in https://visualsketchpad.github.io/.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2406.09407",
        "abstract url": "https://arxiv.org/abs/2406.09407",
        "title": "Towards Evaluating the Robustness of Visual State Space Models",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision State Space Models (VSSMs), a novel architecture that combines the strengths of recurrent neural networks and latent variable models, have demonstrated remarkable performance in visual perception tasks by efficiently capturing long-range dependencies and modeling complex visual dynamics. However, their robustness under natural and adversarial perturbations remains a critical concern. In this work, we present a comprehensive evaluation of VSSMs' robustness under various perturbation scenarios, including occlusions, image structure, common corruptions, and adversarial attacks, and compare their performance to well-established architectures such as transformers and Convolutional Neural Networks. Furthermore, we investigate the resilience of VSSMs to object-background compositional changes on sophisticated benchmarks designed to test model performance in complex visual scenes. We also assess their robustness on object detection and segmentation tasks using corrupted datasets that mimic real-world scenarios. To gain a deeper understanding of VSSMs' adversarial robustness, we conduct a frequency analysis of adversarial attacks, evaluating their performance against low-frequency and high-frequency perturbations. Our findings highlight the strengths and limitations of VSSMs in handling complex visual corruptions, offering valuable insights for future research and improvements in this promising field. Our code and models will be available at https://github.com/HashmatShadab/MambaRobustness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09409",
        "abstract url": "https://arxiv.org/abs/2406.09409",
        "title": "CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth",
                "Event Cameras"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Point-spread-function (PSF) engineering is a well-established computational imaging technique that uses phase masks and other optical elements to embed extra information (e.g., depth) into the images captured by conventional CMOS image sensors. To date, however, PSF-engineering has not been applied to neuromorphic event cameras; a powerful new image sensing technology that responds to changes in the log-intensity of light. This paper establishes theoretical limits (Cram\u00e9r Rao bounds) on 3D point localization and tracking with PSF-engineered event cameras. Using these bounds, we first demonstrate that existing Fisher phase masks are already near-optimal for localizing static flashing point sources (e.g., blinking fluorescent molecules). We then demonstrate that existing designs are sub-optimal for tracking moving point sources and proceed to use our theory to design optimal phase masks and binary amplitude masks for this task. To overcome the non-convexity of the design problem, we leverage novel implicit neural representation based parameterizations of the phase and amplitude masks. We demonstrate the efficacy of our designs through extensive simulations. We also validate our method with a simple prototype.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09413",
        "abstract url": "https://arxiv.org/abs/2406.09413",
        "title": "Interpreting the Weight Space of Customized Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We investigate the space of weights spanned by a large collection of customized diffusion models. We populate this space by creating a dataset of over 60,000 models, each of which is a base model fine-tuned to insert a different person's visual identity. We model the underlying manifold of these weights as a subspace, which we term weights2weights. We demonstrate three immediate applications of this space -- sampling, editing, and inversion. First, as each point in the space corresponds to an identity, sampling a set of weights from it results in a model encoding a novel identity. Next, we find linear directions in this space corresponding to semantic edits of the identity (e.g., adding a beard). These edits persist in appearance across generated samples. Finally, we show that inverting a single image into this space reconstructs a realistic identity, even if the input image is out of distribution (e.g., a painting). Our results indicate that the weight space of fine-tuned diffusion models behaves as an interpretable latent space of identities.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "Project Page: https://snap-research.github.io/weights2weights"
    },
    {
        "paper id": "2406.09415",
        "abstract url": "https://arxiv.org/abs/2406.09415",
        "title": "An Image is Worth More Than 16x16 Patches: Exploring Transformers on Individual Pixels",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This work does not introduce a new method. Instead, we present an interesting finding that questions the necessity of the inductive bias -- locality in modern computer vision architectures. Concretely, we find that vanilla Transformers can operate by directly treating each individual pixel as a token and achieve highly performant results. This is substantially different from the popular design in Vision Transformer, which maintains the inductive bias from ConvNets towards local neighborhoods (e.g. by treating each 16x16 patch as a token). We mainly showcase the effectiveness of pixels-as-tokens across three well-studied tasks in computer vision: supervised learning for object classification, self-supervised learning via masked autoencoding, and image generation with diffusion models. Although directly operating on individual pixels is less computationally practical, we believe the community must be aware of this surprising piece of knowledge when devising the next generation of neural architectures for computer vision.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Technical report, 23 pages"
    },
    {
        "paper id": "2406.09481",
        "abstract url": "https://arxiv.org/abs/2406.09481",
        "title": "ELF-UA: Efficient Label-Free User Adaptation in Gaze Estimation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We consider the problem of user-adaptive 3D gaze estimation. The performance of person-independent gaze estimation is limited due to interpersonal anatomical differences. Our goal is to provide a personalized gaze estimation model specifically adapted to a target user. Previous work on user-adaptive gaze estimation requires some labeled images of the target person data to fine-tune the model at test time. However, this can be unrealistic in real-world applications, since it is cumbersome for an end-user to provide labeled images. In addition, previous work requires the training data to have both gaze labels and person IDs. This data requirement makes it infeasible to use some of the available data. To tackle these challenges, this paper proposes a new problem called efficient label-free user adaptation in gaze estimation. Our model only needs a few unlabeled images of a target user for the model adaptation. During offline training, we have some labeled source data without person IDs and some unlabeled person-specific data. Our proposed method uses a meta-learning approach to learn how to adapt to a new user with only a few unlabeled images. Our key technical innovation is to use a generalization bound from domain adaptation to define the loss function in meta-learning, so that our method can effectively make use of both the labeled source data and the unlabeled person-specific data during training. Extensive experiments validate the effectiveness of our method on several challenging benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "This paper has been accepted by IJCAI'24"
    },
    {
        "paper id": "2406.09484",
        "abstract url": "https://arxiv.org/abs/2406.09484",
        "title": "Is Diffusion Model Safe? Severe Data Leakage via Gradient-Guided Diffusion Model",
        "rating": "0",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "Diffusion"
            ],
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Gradient leakage has been identified as a potential source of privacy breaches in modern image processing systems, where the adversary can completely reconstruct the training images from leaked gradients. However, existing methods are restricted to reconstructing low-resolution images where data leakage risks of image processing systems are not sufficiently explored. In this paper, by exploiting diffusion models, we propose an innovative gradient-guided fine-tuning method and introduce a new reconstruction attack that is capable of stealing private, high-resolution images from image processing systems through leaked gradients where severe data leakage encounters. Our attack method is easy to implement and requires little prior knowledge. The experimental results indicate that current reconstruction attacks can steal images only up to a resolution of $128 \\times 128$ pixels, while our attack method can successfully recover and steal images with resolutions up to $512 \\times 512$ pixels. Our attack method significantly outperforms the SOTA attack baselines in terms of both pixel-wise accuracy and time efficiency of image reconstruction. Furthermore, our attack can render differential privacy ineffective to some extent.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09570",
        "abstract url": "https://arxiv.org/abs/2406.09570",
        "title": "Improving Consistency Models with Generator-Induced Coupling",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Consistency models are promising generative models as they distill the multi-step sampling of score-based diffusion in a single forward pass of a neural network. Without access to sampling trajectories of a pre-trained diffusion model, consistency training relies on proxy trajectories built on an independent coupling between the noise and data distributions. Refining this coupling is a key area of improvement to make it more adapted to the task and reduce the resulting randomness in the training process. In this work, we introduce a novel coupling associating the input noisy data with their generated output from the consistency model itself, as a proxy to the inaccessible diffusion flow output. Our affordable approach exploits the inherent capacity of consistency models to compute the transport map in a single step. We provide intuition and empirical evidence of the relevance of our generator-induced coupling (GC), which brings consistency training closer to score distillation. Consequently, our method not only accelerates consistency training convergence by significant amounts but also enhances the resulting performance. The code is available at: https://github.com/thibautissenhuth/consistency_GC.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09588",
        "abstract url": "https://arxiv.org/abs/2406.09588",
        "title": "Color Equivariant Network",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Group equivariant convolutional neural networks have been designed for a variety of geometric transformations from 2D and 3D rotation groups, to semi-groups such as scale. Despite the improved interpretability, accuracy and generalizability afforded by these architectures, group equivariant networks have seen limited application in the context of perceptual quantities such as hue and saturation, even though their variation can lead to significant reductions in classification performance. In this paper, we introduce convolutional neural networks equivariant to variations in hue and saturation by design. To achieve this, we leverage the observation that hue and saturation transformations can be identified with the 2D rotation and 1D translation groups respectively. Our hue-, saturation-, and fully color-equivariant networks achieve equivariance to these perceptual transformations without an increase in network parameters. We demonstrate the utility of our networks on synthetic and real world datasets where color and lighting variations are commonplace.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "15 pages, 6 figures"
    },
    {
        "paper id": "2406.09598",
        "abstract url": "https://arxiv.org/abs/2406.09598",
        "title": "Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce HOT3D, a publicly available dataset for egocentric hand and object tracking in 3D. The dataset offers over 833 minutes (more than 3.7M images) of multi-view RGB/monochrome image streams showing 19 subjects interacting with 33 diverse rigid objects, multi-modal signals such as eye gaze or scene point clouds, as well as comprehensive ground truth annotations including 3D poses of objects, hands, and cameras, and 3D models of hands and objects. In addition to simple pick-up/observe/put-down actions, HOT3D contains scenarios resembling typical actions in a kitchen, office, and living room environment. The dataset is recorded by two head-mounted devices from Meta: Project Aria, a research prototype of light-weight AR/AI glasses, and Quest 3, a production VR headset sold in millions of units. Ground-truth poses were obtained by a professional motion-capture system using small optical markers attached to hands and objects. Hand annotations are provided in the UmeTrack and MANO formats and objects are represented by 3D meshes with PBR materials obtained by an in-house scanner. We aim to accelerate research on egocentric hand-object interaction by making the HOT3D dataset publicly available and by co-organizing public challenges on the dataset at ECCV 2024. The dataset can be downloaded from the project website: https://facebookresearch.github.io/hot3d/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09601",
        "abstract url": "https://arxiv.org/abs/2406.09601",
        "title": "Turns Out I'm Not Real: Towards Robust Detection of AI-Generated Videos",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "GAN"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The impressive achievements of generative models in creating high-quality videos have raised concerns about digital integrity and privacy vulnerabilities. Recent works to combat Deepfakes videos have developed detectors that are highly accurate at identifying GAN-generated samples. However, the robustness of these detectors on diffusion-generated videos generated from video creation tools (e.g., SORA by OpenAI, Runway Gen-2, and Pika, etc.) is still unexplored. In this paper, we propose a novel framework for detecting videos synthesized from multiple state-of-the-art (SOTA) generative models, such as Stable Video Diffusion. We find that the SOTA methods for detecting diffusion-generated images lack robustness in identifying diffusion-generated videos. Our analysis reveals that the effectiveness of these detectors diminishes when applied to out-of-domain videos, primarily because they struggle to track the temporal features and dynamic variations between frames. To address the above-mentioned challenge, we collect a new benchmark video dataset for diffusion-generated videos using SOTA video creation tools. We extract representation within explicit knowledge from the diffusion model for video frames and train our detector with a CNN + LSTM architecture. The evaluation shows that our framework can well capture the temporal features between frames, achieves 93.7% detection accuracy for in-domain videos, and improves the accuracy of out-domain videos by up to 16 points.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09613",
        "abstract url": "https://arxiv.org/abs/2406.09613",
        "title": "ImageNet3D: Towards General-Purpose Object-Level 3D Understanding",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A vision model with general-purpose object-level 3D understanding should be capable of inferring both 2D (e.g., class name and bounding box) and 3D information (e.g., 3D location and 3D viewpoint) for arbitrary rigid objects in natural images. This is a challenging task, as it involves inferring 3D information from 2D signals and most importantly, generalizing to rigid objects from unseen categories. However, existing datasets with object-level 3D annotations are often limited by the number of categories or the quality of annotations. Models developed on these datasets become specialists for certain categories or domains, and fail to generalize. In this work, we present ImageNet3D, a large dataset for general-purpose object-level 3D understanding. ImageNet3D augments 200 categories from the ImageNet dataset with 2D bounding box, 3D pose, 3D location annotations, and image captions interleaved with 3D information. With the new annotations available in ImageNet3D, we could (i) analyze the object-level 3D awareness of visual foundation models, and (ii) study and develop general-purpose models that infer both 2D and 3D information for arbitrary rigid objects in natural images, and (iii) integrate unified 3D models with large language models for 3D-related reasoning.. We consider two new tasks, probing of object-level 3D awareness and open vocabulary pose estimation, besides standard classification and pose estimation. Experimental results on ImageNet3D demonstrate the potential of our dataset in building vision models with stronger general-purpose object-level 3D understanding.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09634",
        "abstract url": "https://arxiv.org/abs/2406.09634",
        "title": "Efficient Personalization of Amplification in Hearing Aids via Multi-band Bayesian Machine Learning",
        "rating": "0",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "clinical"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "Personalization of the amplification function of hearing aids has been shown to be of benefit to hearing aid users in previous studies. Several machine learning-based personalization approaches have been introduced in the literature. This paper presents a machine learning personalization approach with the advantage of being efficient in its training based on paired comparisons which makes it practical and field deployable. The training efficiency of this approach is the result of treating frequency bands independent of one another and by simultaneously carrying out Bayesian machine learning in each band across all of the frequency bands. Simulation results indicate that this approach leads to an estimated hearing preference function close to the true hearing preference function in fewer number of paired comparisons relative to the previous machine learning approaches. In addition, a clinical experiment conducted on eight subjects with hearing impairment indicate that this training efficient personalization approach provides personalized gain settings which are on average six times more preferred over the standard prescriptive gain settings.",
        "subjects": [
            "eess.AS",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09681",
        "abstract url": "https://arxiv.org/abs/2406.09681",
        "title": "Asymmetrical Siamese Network for Point Clouds Normal Estimation",
        "rating": "0",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, deep learning-based point cloud normal estimation has made great progress. However, existing methods mainly rely on the PCPNet dataset, leading to overfitting. In addition, the correlation between point clouds with different noise scales remains unexplored, resulting in poor performance in cross-domain scenarios. In this paper, we explore the consistency of intrinsic features learned from clean and noisy point clouds using an Asymmetric Siamese Network architecture. By applying reasonable constraints between features extracted from different branches, we enhance the quality of normal estimation. Moreover, we introduce a novel multi-view normal estimation dataset that includes a larger variety of shapes with different noise levels. Evaluation of existing methods on this new dataset reveals their inability to adapt to different types of shapes, indicating a degree of overfitting. Extensive experiments show that the proposed dataset poses significant challenges for point cloud normal estimation and that our feature constraint mechanism effectively improves upon existing methods and reduces overfitting in current architectures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08878",
        "abstract url": "https://arxiv.org/abs/2406.08878",
        "title": "CIMRL: Combining IMitiation and Reinforcement Learning for Safe Autonomous Driving",
        "rating": "-0.5",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern approaches to autonomous driving rely heavily on learned components trained with large amounts of human driving data via imitation learning. However, these methods require large amounts of expensive data collection and even then face challenges with safely handling long-tail scenarios and compounding errors over time. At the same time, pure Reinforcement Learning (RL) methods can fail to learn performant policies in sparse, constrained, and challenging-to-define reward settings like driving. Both of these challenges make deploying purely cloned policies in safety critical applications like autonomous vehicles challenging. In this paper we propose Combining IMitation and Reinforcement Learning (CIMRL) approach -- a framework that enables training driving policies in simulation through leveraging imitative motion priors and safety constraints. CIMRL does not require extensive reward specification and improves on the closed loop behavior of pure cloning methods. By combining RL and imitation, we demonstrate that our method achieves state-of-the-art results in closed loop simulation driving benchmarks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08897",
        "abstract url": "https://arxiv.org/abs/2406.08897",
        "title": "Motif-driven Subgraph Structure Learning for Graph Classification",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "To mitigate the suboptimal nature of graph structure, Graph Structure Learning (GSL) has emerged as a promising approach to improve graph structure and boost performance in downstream tasks. Despite the proposal of numerous GSL methods, the progresses in this field mostly concentrated on node-level tasks, while graph-level tasks (e.g., graph classification) remain largely unexplored. Notably, applying node-level GSL to graph classification is non-trivial due to the lack of find-grained guidance for intricate structure learning. Inspired by the vital role of subgraph in graph classification, in this paper we explore the potential of subgraph structure learning for graph classification by tackling the challenges of key subgraph selection and structure optimization. We propose a novel Motif-driven Subgraph Structure Learning method for Graph Classification (MOSGSL). Specifically, MOSGSL incorporates a subgraph structure learning module which can adaptively select important subgraphs. A motif-driven structure guidance module is further introduced to capture key subgraph-level structural patterns (motifs) and facilitate personalized structure learning. Extensive experiments demonstrate a significant and consistent improvement over baselines, as well as its flexibility and generalizability for various backbones and learning procedures.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 8 figures"
    },
    {
        "paper id": "2406.08933",
        "abstract url": "https://arxiv.org/abs/2406.08933",
        "title": "LaCoOT: Layer Collapse through Optimal Transport",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although deep neural networks are well-known for their remarkable performance in tackling complex tasks, their hunger for computational resources remains a significant hurdle, posing energy-consumption issues and restricting their deployment on resource-constrained devices, which stalls their widespread adoption. In this paper, we present an optimal transport method to reduce the depth of over-parametrized deep neural networks, alleviating their computational burden. More specifically, we propose a new regularization strategy based on the Max-Sliced Wasserstein distance to minimize the distance between the intermediate feature distributions in the neural network. We show that minimizing this distance enables the complete removal of intermediate layers in the network, with almost no performance loss and without requiring any finetuning. We assess the effectiveness of our method on traditional image classification setups. We commit to releasing the source code upon acceptance of the article.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08980",
        "abstract url": "https://arxiv.org/abs/2406.08980",
        "title": "From Theory to Therapy: Reframing SBDD Model Evaluation via Practical Metrics",
        "rating": "-0.5",
        "keywords": [
            [
                "synthesizing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in structure-based drug design (SBDD) have significantly enhanced the efficiency and precision of drug discovery by generating molecules tailored to bind specific protein pockets. Despite these technological strides, their practical application in real-world drug development remains challenging due to the complexities of synthesizing and testing these molecules. The reliability of the Vina docking score, the current standard for assessing binding abilities, is increasingly questioned due to its susceptibility to overfitting. To address these limitations, we propose a comprehensive evaluation framework that includes assessing the similarity of generated molecules to known active compounds, introducing a virtual screening-based metric for practical deployment capabilities, and re-evaluating binding affinity more rigorously. Our experiments reveal that while current SBDD models achieve high Vina scores, they fall short in practical usability metrics, highlighting a significant gap between theoretical predictions and real-world applicability. Our proposed metrics and dataset aim to bridge this gap, enhancing the practical applicability of future SBDD models and aligning them more closely with the needs of pharmaceutical research and development.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09023",
        "abstract url": "https://arxiv.org/abs/2406.09023",
        "title": "Schur's Positive-Definite Network: Deep Learning in the SPD cone with structure",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Estimating matrices in the symmetric positive-definite (SPD) cone is of interest for many applications ranging from computer vision to graph learning. While there exist various convex optimization-based estimators, they remain limited in expressivity due to their model-based approach. The success of deep learning has thus led many to use neural networks to learn to estimate SPD matrices in a data-driven fashion. For learning structured outputs, one promising strategy involves architectures designed by unrolling iterative algorithms, which potentially benefit from inductive bias properties. However, designing correct unrolled architectures for SPD learning is difficult: they either do not guarantee that their output has all the desired properties, rely on heavy computations, or are overly restrained to specific matrices which hinders their expressivity. In this paper, we propose a novel and generic learning module with guaranteed SPD outputs called SpodNet, that also enables learning a larger class of functions than existing approaches. Notably, it solves the challenging task of learning jointly SPD and sparse matrices. Our experiments demonstrate the versatility of SpodNet layers.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "13 pages, 7 figures"
    },
    {
        "paper id": "2406.09073",
        "abstract url": "https://arxiv.org/abs/2406.09073",
        "title": "Are we making progress in unlearning? Findings from the first NeurIPS unlearning competition",
        "rating": "-0.5",
        "keywords": [
            [
                "unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present the findings of the first NeurIPS competition on unlearning, which sought to stimulate the development of novel algorithms and initiate discussions on formal and robust evaluation methodologies. The competition was highly successful: nearly 1,200 teams from across the world participated, and a wealth of novel, imaginative solutions with different characteristics were contributed. In this paper, we analyze top solutions and delve into discussions on benchmarking unlearning, which itself is a research problem. The evaluation methodology we developed for the competition measures forgetting quality according to a formal notion of unlearning, while incorporating model utility for a holistic evaluation. We analyze the effectiveness of different instantiations of this evaluation framework vis-a-vis the associated compute cost, and discuss implications for standardizing evaluation. We find that the ranking of leading methods remains stable under several variations of this framework, pointing to avenues for reducing the cost of evaluation. Overall, our findings indicate progress in unlearning, with top-performing competition entries surpassing existing algorithms under our evaluation framework. We analyze trade-offs made by different algorithms and strengths or weaknesses in terms of generalizability to new datasets, paving the way for advancing both benchmarking and algorithm development in this important area.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09082",
        "abstract url": "https://arxiv.org/abs/2406.09082",
        "title": "Data-driven modeling and supervisory control system optimization for plug-in hybrid electric vehicles",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Learning-based intelligent energy management systems for plug-in hybrid electric vehicles (PHEVs) are crucial for achieving efficient energy utilization. However, their application faces system reliability challenges in the real world, which prevents widespread acceptance by original equipment manufacturers (OEMs). This paper begins by establishing a PHEV model based on physical and data-driven models, focusing on the high-fidelity training environment. It then proposes a real-vehicle application-oriented control framework, combining horizon-extended reinforcement learning (RL)-based energy management with the equivalent consumption minimization strategy (ECMS) to enhance practical applicability, and improves the flawed method of equivalent factor evaluation based on instantaneous driving cycle and powertrain states found in existing research. Finally, comprehensive simulation and hardware-in-the-loop validation are carried out which demonstrates the advantages of the proposed control framework in fuel economy over adaptive-ECMS and rule-based strategies. Compared to conventional RL architectures that directly control powertrain components, the proposed control method not only achieves similar optimality but also significantly enhances the disturbance resistance of the energy management system, providing an effective control framework for RL-based energy management strategies aimed at real-vehicle applications by OEMs.",
        "subjects": [
            "eess.SY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09084",
        "abstract url": "https://arxiv.org/abs/2406.09084",
        "title": "Operator-informed score matching for Markov diffusion models",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models are typically trained using score matching, yet score matching is agnostic to the particular forward process that defines the model. This paper argues that Markov diffusion models enjoy an advantage over other types of diffusion model, as their associated operators can be exploited to improve the training process. In particular, (i) there exists an explicit formal solution to the forward process as a sequence of time-dependent kernel mean embeddings; and (ii) the derivation of score-matching and related estimators can be streamlined. Building upon (i), we propose Riemannian diffusion kernel smoothing, which ameliorates the need for neural score approximation, at least in the low-dimensional context; Building upon (ii), we propose operator-informed score matching, a variance reduction technique that is straightforward to implement in both low- and high-dimensional diffusion modeling and is demonstrated to improve score matching in an empirical proof-of-concept.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "Preprint; 19 pages, 5 figures"
    },
    {
        "paper id": "2406.09089",
        "abstract url": "https://arxiv.org/abs/2406.09089",
        "title": "DiffPoGAN: Diffusion Policies with Generative Adversarial Networks for Offline Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Offline reinforcement learning (RL) can learn optimal policies from pre-collected offline datasets without interacting with the environment, but the sampled actions of the agent cannot often cover the action distribution under a given state, resulting in the extrapolation error issue. Recent works address this issue by employing generative adversarial networks (GANs). However, these methods often suffer from insufficient constraints on policy exploration and inaccurate representation of behavior policies. Moreover, the generator in GANs fails in fooling the discriminator while maximizing the expected returns of a policy. Inspired by the diffusion, a generative model with powerful feature expressiveness, we propose a new offline RL method named Diffusion Policies with Generative Adversarial Networks (DiffPoGAN). In this approach, the diffusion serves as the policy generator to generate diverse distributions of actions, and a regularization method based on maximum likelihood estimation (MLE) is developed to generate data that approximate the distribution of behavior policies. Besides, we introduce an additional regularization term based on the discriminator output to effectively constrain policy exploration for policy improvement. Comprehensive experiments are conducted on the datasets for deep data-driven reinforcement learning (D4RL), and experimental results show that DiffPoGAN outperforms state-of-the-art methods in offline RL.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09126",
        "abstract url": "https://arxiv.org/abs/2406.09126",
        "title": "Auto-Vocabulary Segmentation for LiDAR Points",
        "rating": "-0.5",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Existing perception methods for autonomous driving fall short of recognizing unknown entities not covered in the training data. Open-vocabulary methods offer promising capabilities in detecting any object but are limited by user-specified queries representing target classes. We propose AutoVoc3D, a framework for automatic object class recognition and open-ended segmentation. Evaluation on nuScenes showcases AutoVoc3D's ability to generate precise semantic classes and accurate point-wise segmentation. Moreover, we introduce Text-Point Semantic Similarity, a new metric to assess the semantic similarity between text and point cloud without eliminating novel classes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024 OpenSun3D Workshop"
    },
    {
        "paper id": "2406.09131",
        "abstract url": "https://arxiv.org/abs/2406.09131",
        "title": "OLGA: One-cLass Graph Autoencoder",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "One-class learning (OCL) comprises a set of techniques applied when real-world problems have a single class of interest. The usual procedure for OCL is learning a hypersphere that comprises instances of this class and, ideally, repels unseen instances from any other classes. Besides, several OCL algorithms for graphs have been proposed since graph representation learning has succeeded in various fields. These methods may use a two-step strategy, initially representing the graph and, in a second step, classifying its nodes. On the other hand, end-to-end methods learn the node representations while classifying the nodes in one learning process. We highlight three main gaps in the literature on OCL for graphs: (i) non-customized representations for OCL; (ii) the lack of constraints on hypersphere parameters learning; and (iii) the methods' lack of interpretability and visualization. We propose One-cLass Graph Autoencoder (OLGA). OLGA is end-to-end and learns the representations for the graph nodes while encapsulating the interest instances by combining two loss functions. We propose a new hypersphere loss function to encapsulate the interest instances. OLGA combines this new hypersphere loss with the graph autoencoder reconstruction loss to improve model learning. OLGA achieved state-of-the-art results and outperformed six other methods with a statistically significant difference from five methods. Moreover, OLGA learns low-dimensional representations maintaining the classification performance with an interpretable model representation learning and results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09147",
        "abstract url": "https://arxiv.org/abs/2406.09147",
        "title": "Weakly-supervised anomaly detection for multimodal data distributions",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Weakly-supervised anomaly detection can outperform existing unsupervised methods with the assistance of a very small number of labeled anomalies, which attracts increasing attention from researchers. However, existing weakly-supervised anomaly detection methods are limited as these methods do not factor in the multimodel nature of the real-world data distribution. To mitigate this, we propose the Weakly-supervised Variational-mixture-model-based Anomaly Detector (WVAD). WVAD excels in multimodal datasets. It consists of two components: a deep variational mixture model, and an anomaly score estimator. The deep variational mixture model captures various features of the data from different clusters, then these features are delivered to the anomaly score estimator to assess the anomaly levels. Experimental results on three real-world datasets demonstrate WVAD's superiority.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 3 figures. Accepted by 2024 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)"
    },
    {
        "paper id": "2406.09179",
        "abstract url": "https://arxiv.org/abs/2406.09179",
        "title": "Unlearning with Control: Assessing Real-world Utility for Large Language Model Unlearning",
        "rating": "-0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The compelling goal of eradicating undesirable data behaviors, while preserving usual model functioning, underscores the significance of machine unlearning within the domain of large language models (LLMs). Recent research has begun to approach LLM unlearning via gradient ascent (GA) -- increasing the prediction risk for those training strings targeted to be unlearned, thereby erasing their parameterized responses. Despite their simplicity and efficiency, we suggest that GA-based methods face the propensity towards excessive unlearning, resulting in various undesirable model behaviors, such as catastrophic forgetting, that diminish their practical utility. In this paper, we suggest a set of metrics that can capture multiple facets of real-world utility and propose several controlling methods that can regulate the extent of excessive unlearning. Accordingly, we suggest a general framework to better reflect the practical efficacy of various unlearning methods -- we begin by controlling the unlearning procedures/unlearned models such that no excessive unlearning occurs and follow by the evaluation for unlearning efficacy. Our experimental analysis on established benchmarks revealed that GA-based methods are far from perfect in practice, as strong unlearning is at the high cost of hindering the model utility. We conclude that there is still a long way towards practical and effective LLM unlearning, and more efforts are required in this field.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09180",
        "abstract url": "https://arxiv.org/abs/2406.09180",
        "title": "Detection-Rate-Emphasized Multi-objective Evolutionary Feature Selection for Network Intrusion Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Network intrusion detection is one of the most important issues in the field of cyber security, and various machine learning techniques have been applied to build intrusion detection systems. However, since the number of features to describe the network connections is often large, where some features are redundant or noisy, feature selection is necessary in such scenarios, which can both improve the efficiency and accuracy. Recently, some researchers focus on using multi-objective evolutionary algorithms (MOEAs) to select features. But usually, they only consider the number of features and classification accuracy as the objectives, resulting in unsatisfactory performance on a critical metric, detection rate. This will lead to the missing of many real attacks and bring huge losses to the network system. In this paper, we propose DR-MOFS to model the feature selection problem in network intrusion detection as a three-objective optimization problem, where the number of features, accuracy and detection rate are optimized simultaneously, and use MOEAs to solve it. Experiments on two popular network intrusion detection datasets NSL-KDD and UNSW-NB15 show that in most cases the proposed method can outperform previous methods, i.e., lead to fewer features, higher accuracy and detection rate.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09246",
        "abstract url": "https://arxiv.org/abs/2406.09246",
        "title": "OpenVLA: An Open-Source Vision-Language-Action Model",
        "rating": "-0.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Diffusion"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large policies pretrained on a combination of Internet-scale vision-language data and diverse robot demonstrations have the potential to change how we teach robots new skills: rather than training new behaviors from scratch, we can fine-tune such vision-language-action (VLA) models to obtain robust, generalizable policies for visuomotor control. Yet, widespread adoption of VLAs for robotics has been challenging as 1) existing VLAs are largely closed and inaccessible to the public, and 2) prior work fails to explore methods for efficiently fine-tuning VLAs for new tasks, a key component for adoption. Addressing these challenges, we introduce OpenVLA, a 7B-parameter open-source VLA trained on a diverse collection of 970k real-world robot demonstrations. OpenVLA builds on a Llama 2 language model combined with a visual encoder that fuses pretrained features from DINOv2 and SigLIP. As a product of the added data diversity and new model components, OpenVLA demonstrates strong results for generalist manipulation, outperforming closed models such as RT-2-X (55B) by 16.5% in absolute task success rate across 29 tasks and multiple robot embodiments, with 7x fewer parameters. We further show that we can effectively fine-tune OpenVLA for new settings, with especially strong generalization results in multi-task environments involving multiple objects and strong language grounding abilities, and outperform expressive from-scratch imitation learning methods such as Diffusion Policy by 20.4%. We also explore compute efficiency; as a separate contribution, we show that OpenVLA can be fine-tuned on consumer GPUs via modern low-rank adaptation methods and served efficiently via quantization without a hit to downstream success rate. Finally, we release model checkpoints, fine-tuning notebooks, and our PyTorch codebase with built-in support for training VLAs at scale on Open X-Embodiment datasets.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Website: https://openvla.github.io/"
    },
    {
        "paper id": "2406.09253",
        "abstract url": "https://arxiv.org/abs/2406.09253",
        "title": "Deep Sketched Output Kernel Regression for Structured Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "By leveraging the kernel trick in the output space, kernel-induced losses provide a principled way to define structured output prediction tasks for a wide variety of output modalities. In particular, they have been successfully used in the context of surrogate non-parametric regression, where the kernel trick is typically exploited in the input space as well. However, when inputs are images or texts, more expressive models such as deep neural networks seem more suited than non-parametric methods. In this work, we tackle the question of how to train neural networks to solve structured output prediction tasks, while still benefiting from the versatility and relevance of kernel-induced losses. We design a novel family of deep neural architectures, whose last layer predicts in a data-dependent finite-dimensional subspace of the infinite-dimensional output feature space deriving from the kernel-induced loss. This subspace is chosen as the span of the eigenfunctions of a randomly-approximated version of the empirical kernel covariance operator. Interestingly, this approach unlocks the use of gradient descent algorithms (and consequently of any neural architecture) for structured prediction. Experiments on synthetic tasks as well as real-world supervised graph prediction problems show the relevance of our method.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09262",
        "abstract url": "https://arxiv.org/abs/2406.09262",
        "title": "Flexible Heteroscedastic Count Regression with Deep Double Poisson Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural networks that can produce accurate, input-conditional uncertainty representations are critical for real-world applications. Recent progress on heteroscedastic continuous regression has shown great promise for calibrated uncertainty quantification on complex tasks, like image regression. However, when these methods are applied to discrete regression tasks, such as crowd counting, ratings prediction, or inventory estimation, they tend to produce predictive distributions with numerous pathologies. We propose to address these issues by training a neural network to output the parameters of a Double Poisson distribution, which we call the Deep Double Poisson Network (DDPN). In contrast to existing methods that are trained to minimize Gaussian negative log likelihood (NLL), DDPNs produce a proper probability mass function over discrete output. Additionally, DDPNs naturally model under-, over-, and equi-dispersion, unlike networks trained with the more rigid Poisson and Negative Binomial parameterizations. We show DDPNs 1) vastly outperform existing discrete models; 2) meet or exceed the accuracy and flexibility of networks trained with Gaussian NLL; 3) produce proper predictive distributions over discrete counts; and 4) exhibit superior out-of-distribution detection. DDPNs can easily be applied to a variety of count regression datasets including tabular, image, point cloud, and text data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09291",
        "abstract url": "https://arxiv.org/abs/2406.09291",
        "title": "A Flexible, Equivariant Framework for Subgraph GNNs via Graph Products and Graph Coarsening",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Subgraph Graph Neural Networks (Subgraph GNNs) enhance the expressivity of message-passing GNNs by representing graphs as sets of subgraphs. They have shown impressive performance on several tasks, but their complexity limits applications to larger graphs. Previous approaches suggested processing only subsets of subgraphs, selected either randomly or via learnable sampling. However, they make suboptimal subgraph selections or can only cope with very small subset sizes, inevitably incurring performance degradation. This paper introduces a new Subgraph GNNs framework to address these issues. We employ a graph coarsening function to cluster nodes into super-nodes with induced connectivity. The product between the coarsened and the original graph reveals an implicit structure whereby subgraphs are associated with specific sets of nodes. By running generalized message-passing on such graph product, our method effectively implements an efficient, yet powerful Subgraph GNN. Controlling the coarsening function enables meaningful selection of any number of subgraphs while, contrary to previous methods, being fully compatible with standard training techniques. Notably, we discover that the resulting node feature tensor exhibits new, unexplored permutation symmetries. We leverage this structure, characterize the associated linear equivariant layers and incorporate them into the layers of our Subgraph GNN architecture. Extensive experiments on multiple graph learning benchmarks demonstrate that our method is significantly more flexible than previous approaches, as it can seamlessly handle any number of subgraphs, while consistently outperforming baseline approaches.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preprint, under review"
    },
    {
        "paper id": "2406.09338",
        "abstract url": "https://arxiv.org/abs/2406.09338",
        "title": "Learning the Influence Graph of a High-Dimensional Markov Process with Memory",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Motivated by multiple applications in social networks, nervous systems, and financial risk analysis, we consider the problem of learning the underlying (directed) influence graph or causal graph of a high-dimensional multivariate discrete-time Markov process with memory. At any discrete time instant, each observed variable of the multivariate process is a binary string of random length, which is parameterized by an unobservable or hidden [0,1]-valued scalar. The hidden scalars corresponding to the variables evolve according to discrete-time linear stochastic dynamics dictated by the underlying influence graph whose nodes are the variables. We extend an existing algorithm for learning i.i.d. graphical models to this Markovian setting with memory and prove that it can learn the influence graph based on the binary observations using logarithmic (in number of variables or nodes) samples when the degree of the influence graph is bounded. The crucial analytical contribution of this work is the derivation of the sample complexity result by upper and lower bounding the rate of convergence of the observed Markov process with memory to its stationary distribution in terms of the parameters of the influence graph.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09351",
        "abstract url": "https://arxiv.org/abs/2406.09351",
        "title": "On the Expressibility of the Reconstructional Color Refinement",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "One of the most basic facts related to the famous Ulam reconstruction conjecture is that the connectedness of a graph can be determined by the deck of its vertex-deleted subgraphs, which are considered up to isomorphism. We strengthen this result by proving that connectedness can still be determined when the subgraphs in the deck are given up to equivalence under the color refinement isomorphism test. Consequently, this implies that connectedness is recognizable by Reconstruction Graph Neural Networks, a recently introduced GNN architecture inspired by the reconstruction conjecture (Cotta, Morris, Ribeiro 2021).",
        "subjects": [
            "cs.CC",
            "cs.DM",
            "cs.LG",
            "math.CO"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2406.09373",
        "abstract url": "https://arxiv.org/abs/2406.09373",
        "title": "Efficient Discrepancy Testing for Learning with Distribution Shift",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A fundamental notion of distance between train and test distributions from the field of domain adaptation is discrepancy distance. While in general hard to compute, here we provide the first set of provably efficient algorithms for testing localized discrepancy distance, where discrepancy is computed with respect to a fixed output classifier. These results imply a broad set of new, efficient learning algorithms in the recently introduced model of Testable Learning with Distribution Shift (TDS learning) due to Klivans et al. (2023). Our approach generalizes and improves all prior work on TDS learning: (1) we obtain universal learners that succeed simultaneously for large classes of test distributions, (2) achieve near-optimal error rates, and (3) give exponential improvements for constant depth circuits. Our methods further extend to semi-parametric settings and imply the first positive results for low-dimensional convex sets. Additionally, we separate learning and testing phases and obtain algorithms that run in fully polynomial time at test time.",
        "subjects": [
            "cs.DS",
            "cs.LG"
        ],
        "comment": "45 pages, 3 figures"
    },
    {
        "paper id": "2406.09383",
        "abstract url": "https://arxiv.org/abs/2406.09383",
        "title": "Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "vehicle"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Large-scale datasets have fueled recent advancements in AI-based autonomous vehicle research. However, these datasets are usually collected from a single vehicle's one-time pass of a certain location, lacking multiagent interactions or repeated traversals of the same place. Such information could lead to transformative enhancements in autonomous vehicles' perception, prediction, and planning capabilities. To bridge this gap, in collaboration with the self-driving company May Mobility, we present the MARS dataset which unifies scenarios that enable MultiAgent, multitraveRSal, and multimodal autonomous vehicle research. More specifically, MARS is collected with a fleet of autonomous vehicles driving within a certain geographical area. Each vehicle has its own route and different vehicles may appear at nearby locations. Each vehicle is equipped with a LiDAR and surround-view RGB cameras. We curate two subsets in MARS: one facilitates collaborative driving with multiple vehicles simultaneously present at the same location, and the other enables memory retrospection through asynchronous traversals of the same location by multiple vehicles. We conduct experiments in place recognition and neural reconstruction. More importantly, MARS introduces new research opportunities and challenges such as multitraversal 3D reconstruction, multiagent perception, and unsupervised object discovery. Our data and codes can be found at https://ai4ce.github.io/MARS/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CVPR 2024"
    },
    {
        "paper id": "2406.09391",
        "abstract url": "https://arxiv.org/abs/2406.09391",
        "title": "A More Practical Approach to Machine Unlearning",
        "rating": "-0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models often incorporate vast amounts of data, raising significant privacy concerns. Machine unlearning, the ability to remove the influence of specific data points from a trained model, addresses these concerns. This paper explores practical methods for implementing machine unlearning, focusing on a first-epoch gradient-ascent approach. Key findings include: 1. Single vs. Multi-Epoch Unlearning: First-epoch gradient unlearning is more effective than multi-epoch gradients. 2. Layer-Based Unlearning: The embedding layer in GPT-2 is crucial for effective unlearning. Gradients from the output layers (11 and 12) have no impact. Efficient unlearning can be achieved using only the embedding layer, halving space complexity. 3. Influence Functions & Scoring: Techniques like Hessian Vector Product and the dot product of activations and tensors are used for quantifying unlearning. 4. Gradient Ascent Considerations: Calibration is necessary to avoid overexposing the model to specific data points during unlearning, which could prematurely terminate the process. 5. Fuzzy Matching vs. Iterative Unlearning: Fuzzy matching techniques shift the model to a new optimum, while iterative unlearning provides a more complete modality. Our empirical evaluation confirms that first-epoch gradient ascent for machine unlearning is more effective than whole-model gradient ascent. These results highlight the potential of machine unlearning for enhancing data privacy and compliance with regulations such as GDPR and CCPA. The study underscores the importance of formal methods to comprehensively evaluate the unlearning process.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09402",
        "abstract url": "https://arxiv.org/abs/2406.09402",
        "title": "Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Diffusion",
                "video editing"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "This paper proposes Instruct 4D-to-4D that achieves 4D awareness and spatial-temporal consistency for 2D diffusion models to generate high-quality instruction-guided dynamic scene editing results. Traditional applications of 2D diffusion models in dynamic scene editing often result in inconsistency, primarily due to their inherent frame-by-frame editing methodology. Addressing the complexities of extending instruction-guided editing to 4D, our key insight is to treat a 4D scene as a pseudo-3D scene, decoupled into two sub-problems: achieving temporal consistency in video editing and applying these edits to the pseudo-3D scene. Following this, we first enhance the Instruct-Pix2Pix (IP2P) model with an anchor-aware attention module for batch processing and consistent editing. Additionally, we integrate optical flow-guided appearance propagation in a sliding window fashion for more precise frame-to-frame editing and incorporate depth-based projection to manage the extensive data of pseudo-3D scenes, followed by iterative editing to achieve convergence. We extensively evaluate our approach in various scenes and editing instructions, and demonstrate that it achieves spatially and temporally consistent editing results, with significantly enhanced detail and sharpness over the prior art. Notably, Instruct 4D-to-4D is general and applicable to both monocular and challenging multi-camera scenes. Code and more results are available at immortalco.github.io/Instruct-4D-to-4D.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2406.09404",
        "abstract url": "https://arxiv.org/abs/2406.09404",
        "title": "ConsistDreamer: 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "This paper proposes ConsistDreamer - a novel framework that lifts 2D diffusion models with 3D awareness and 3D consistency, thus enabling high-fidelity instruction-guided scene editing. To overcome the fundamental limitation of missing 3D consistency in 2D diffusion models, our key insight is to introduce three synergetic strategies that augment the input of the 2D diffusion model to become 3D-aware and to explicitly enforce 3D consistency during the training process. Specifically, we design surrounding views as context-rich input for the 2D diffusion model, and generate 3D-consistent, structured noise instead of image-independent noise. Moreover, we introduce self-supervised consistency-enforcing training within the per-scene editing procedure. Extensive evaluation shows that our ConsistDreamer achieves state-of-the-art performance for instruction-guided scene editing across various scenes and editing instructions, particularly in complicated large-scale indoor scenes from ScanNet++, with significantly improved sharpness and fine-grained textures. Notably, ConsistDreamer stands as the first work capable of successfully editing complex (e.g., plaid/checkered) patterns. Our project page is at immortalco.github.io/ConsistDreamer.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "CVPR 2024"
    },
    {
        "paper id": "2406.09495",
        "abstract url": "https://arxiv.org/abs/2406.09495",
        "title": "Fair Data Generation via Score-based Diffusion Model",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The fairness of AI decision-making has garnered increasing attention, leading to the proposal of numerous fairness algorithms. In this paper, we aim not to address this issue by directly introducing fair learning algorithms, but rather by generating entirely new, fair synthetic data from biased datasets for use in any downstream tasks. Additionally, the distribution of test data may differ from that of the training set, potentially impacting the performance of the generated synthetic data in downstream tasks. To address these two challenges, we propose a diffusion model-based framework, FADM: Fairness-Aware Diffusion with Meta-training. FADM introduces two types of gradient induction during the sampling phase of the diffusion model: one to ensure that the generated samples belong to the desired target categories, and another to make the sensitive attributes of the generated samples difficult to classify into any specific sensitive attribute category. To overcome data distribution shifts in the test environment, we train the diffusion model and the two classifiers used for induction within a meta-learning framework. Compared to other baselines, FADM allows for flexible control over the categories of the generated samples and exhibits superior generalization capability. Experiments on real datasets demonstrate that FADM achieves better accuracy and optimal fairness in downstream tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09496",
        "abstract url": "https://arxiv.org/abs/2406.09496",
        "title": "You are what you eat? Feeding foundation models a regionally diverse food dataset of World Wide Dishes",
        "rating": "-0.5",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Foundation models are increasingly ubiquitous in our daily lives, used in everyday tasks such as text-image searches, interactions with chatbots, and content generation. As use increases, so does concern over the disparities in performance and fairness of these models for different people in different parts of the world. To assess these growing regional disparities, we present World Wide Dishes, a mixed text and image dataset consisting of 765 dishes, with dish names collected in 131 local languages. World Wide Dishes has been collected purely through human contribution and decentralised means, by creating a website widely distributed through social networks. Using the dataset, we demonstrate a novel means of operationalising capability and representational biases in foundation models such as language models and text-to-image generative models. We enrich these studies with a pilot community review to understand, from a first-person perspective, how these models generate images for people in five African countries and the United States. We find that these models generally do not produce quality text and image outputs of dishes specific to different regions. This is true even for the US, which is typically considered to be more well-resourced in training data - though the generation of US dishes does outperform that of the investigated African countries. The models demonstrate a propensity to produce outputs that are inaccurate as well as culturally misrepresentative, flattening, and insensitive. These failures in capability and representational bias have the potential to further reinforce stereotypes and disproportionately contribute to erasure based on region. The dataset and code are available at https://github.com/oxai/world-wide-dishes/.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09509",
        "abstract url": "https://arxiv.org/abs/2406.09509",
        "title": "CleanDiffuser: An Easy-to-use Modularized Library for Diffusion Models in Decision Making",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Leveraging the powerful generative capability of diffusion models (DMs) to build decision-making agents has achieved extensive success. However, there is still a demand for an easy-to-use and modularized open-source library that offers customized and efficient development for DM-based decision-making algorithms. In this work, we introduce CleanDiffuser, the first DM library specifically designed for decision-making algorithms. By revisiting the roles of DMs in the decision-making domain, we identify a set of essential sub-modules that constitute the core of CleanDiffuser, allowing for the implementation of various DM algorithms with simple and flexible building blocks. To demonstrate the reliability and flexibility of CleanDiffuser, we conduct comprehensive evaluations of various DM algorithms implemented with CleanDiffuser across an extensive range of tasks. The analytical experiments provide a wealth of valuable design choices and insights, reveal opportunities and challenges, and lay a solid groundwork for future research. CleanDiffuser will provide long-term support to the decision-making community, enhancing reproducibility and fostering the development of more robust solutions. The code and documentation of CleanDiffuser are open-sourced on the https://github.com/CleanDiffuserTeam/CleanDiffuser.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "The first two authors contribute equally to this work. Code and documentation: https://github.com/CleanDiffuserTeam/CleanDiffuser"
    },
    {
        "paper id": "2406.09513",
        "abstract url": "https://arxiv.org/abs/2406.09513",
        "title": "Fair GLASSO: Estimating Fair Graphical Models with Unbiased Statistical Behavior",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose estimating Gaussian graphical models (GGMs) that are fair with respect to sensitive nodal attributes. Many real-world models exhibit unfair discriminatory behavior due to biases in data. Such discrimination is known to be exacerbated when data is equipped with pairwise relationships encoded in a graph. Additionally, the effect of biased data on graphical models is largely underexplored. We thus introduce fairness for graphical models in the form of two bias metrics to promote balance in statistical similarities across nodal groups with different sensitive attributes. Leveraging these metrics, we present Fair GLASSO, a regularized graphical lasso approach to obtain sparse Gaussian precision matrices with unbiased statistical dependencies across groups. We also propose an efficient proximal gradient algorithm to obtain the estimates. Theoretically, we express the tradeoff between fair and accurate estimated precision matrices. Critically, this includes demonstrating when accuracy can be preserved in the presence of a fairness regularizer. On top of this, we study the complexity of Fair GLASSO and demonstrate that our algorithm enjoys a fast convergence rate. Our empirical validation includes synthetic and real-world simulations that illustrate the value and effectiveness of our proposed optimization problem and iterative algorithm.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09529",
        "abstract url": "https://arxiv.org/abs/2406.09529",
        "title": "Differentiable Reasoning about Knowledge Graphs with Region-based Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Methods for knowledge graph (KG) completion need to capture semantic regularities and use these regularities to infer plausible knowledge that is not explicitly stated. Most embedding-based methods are opaque in the kinds of regularities they can capture, although region-based KG embedding models have emerged as a more transparent alternative. By modeling relations as geometric regions in high-dimensional vector spaces, such models can explicitly capture semantic regularities in terms of the spatial arrangement of these regions. Unfortunately, existing region-based approaches are severely limited in the kinds of rules they can capture. We argue that this limitation arises because the considered regions are defined as the Cartesian product of two-dimensional regions. As an alternative, in this paper, we propose RESHUFFLE, a simple model based on ordering constraints that can faithfully capture a much larger class of rule bases than existing approaches. Moreover, the embeddings in our framework can be learned by a monotonic Graph Neural Network (GNN), which effectively acts as a differentiable rule base. This approach has the important advantage that embeddings can be easily updated as new knowledge is added to the KG. At the same time, since the resulting representations can be used similarly to standard KG embeddings, our approach is significantly more efficient than existing approaches to differentiable reasoning.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09547",
        "abstract url": "https://arxiv.org/abs/2406.09547",
        "title": "FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) enables model development by leveraging data distributed across numerous edge devices without transferring local data to a central server. However, existing FL methods still face challenges when dealing with scarce and label-skewed data across devices, resulting in local model overfitting and drift, consequently hindering the performance of the global model. In response to these challenges, we propose a pioneering framework called FLea, incorporating the following key components: i) A global feature buffer that stores activation-target pairs shared from multiple clients to support local training. This design mitigates local model drift caused by the absence of certain classes; ii) A feature augmentation approach based on local and global activation mix-ups for local training. This strategy enlarges the training samples, thereby reducing the risk of local overfitting; iii) An obfuscation method to minimize the correlation between intermediate activations and the source data, enhancing the privacy of shared features. To verify the superiority of FLea, we conduct extensive experiments using a wide range of data modalities, simulating different levels of local data scarcity and label skew. The results demonstrate that FLea consistently outperforms state-of-the-art FL counterparts (among 13 of the experimented 18 settings, the improvement is over 5% while concurrently mitigating the privacy vulnerabilities associated with shared features. Code is available at https://github.com/XTxiatong/FLea.git.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "This paper has been accepted by KDD 2024. arXiv admin note: text overlap with arXiv:2312.02327"
    },
    {
        "paper id": "2406.09548",
        "abstract url": "https://arxiv.org/abs/2406.09548",
        "title": "Between Randomness and Arbitrariness: Some Lessons for Reliable Machine Learning at Scale",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "To develop rigorous knowledge about ML models -- and the systems in which they are embedded -- we need reliable measurements. But reliable measurement is fundamentally challenging, and touches on issues of reproducibility, scalability, uncertainty quantification, epistemology, and more. This dissertation addresses criteria needed to take reliability seriously: both criteria for designing meaningful metrics, and for methodologies that ensure that we can dependably and efficiently measure these metrics at scale and in practice. In doing so, this dissertation articulates a research vision for a new field of scholarship at the intersection of machine learning, law, and policy. Within this frame, we cover topics that fit under three different themes: (1) quantifying and mitigating sources of arbitrariness in ML, (2) taming randomness in uncertainty estimation and optimization algorithms, in order to achieve scalability without sacrificing reliability, and (3) providing methods for evaluating generative-AI systems, with specific focuses on quantifying memorization in language models and training latent diffusion models on open-licensed data. By making contributions in these three themes, this dissertation serves as an empirical proof by example that research on reliable measurement for machine learning is intimately and inescapably bound up with research in law and policy. These different disciplines pose similar research questions about reliable measurement in machine learning. They are, in fact, two complementary sides of the same research vision, which, broadly construed, aims to construct machine-learning systems that cohere with broader societal values.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY",
            "stat.ML"
        ],
        "comment": "Ph.D. Dissertation"
    },
    {
        "paper id": "2406.09561",
        "abstract url": "https://arxiv.org/abs/2406.09561",
        "title": "Label Noise Robustness for Domain-Agnostic Fair Corrections via Nearest Neighbors Label Spreading",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Last-layer retraining methods have emerged as an efficient framework for correcting existing base models. Within this framework, several methods have been proposed to deal with correcting models for subgroup fairness with and without group membership information. Importantly, prior work has demonstrated that many methods are susceptible to noisy labels. To this end, we propose a drop-in correction for label noise in last-layer retraining, and demonstrate that it achieves state-of-the-art worst-group accuracy for a broad range of symmetric label noise and across a wide variety of datasets exhibiting spurious correlations. Our proposed approach uses label spreading on a latent nearest neighbors graph and has minimal computational overhead compared to existing methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09563",
        "abstract url": "https://arxiv.org/abs/2406.09563",
        "title": "e-COP : Episodic Constrained Optimization of Policies",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present the $\\texttt{e-COP}$ algorithm, the first policy optimization algorithm for constrained Reinforcement Learning (RL) in episodic (finite horizon) settings. Such formulations are applicable when there are separate sets of optimization criteria and constraints on a system's behavior. We approach this problem by first establishing a policy difference lemma for the episodic setting, which provides the theoretical foundation for the algorithm. Then, we propose to combine a set of established and novel solution ideas to yield the $\\texttt{e-COP}$ algorithm that is easy to implement and numerically stable, and provide a theoretical guarantee on optimality under certain scaling assumptions. Through extensive empirical analysis using benchmarks in the Safety Gym suite, we show that our algorithm has similar or better performance than SoTA (non-episodic) algorithms adapted for the episodic setting. The scalability of the algorithm opens the door to its application in safety-constrained Reinforcement Learning from Human Feedback for Large Language or Diffusion Models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09612",
        "abstract url": "https://arxiv.org/abs/2406.09612",
        "title": "Automated Molecular Concept Generation and Labeling with Large Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Artificial intelligence (AI) is significantly transforming scientific research. Explainable AI methods, such as concept-based models (CMs), are promising for driving new scientific discoveries because they make predictions based on meaningful concepts and offer insights into the prediction process. In molecular science, however, explainable CMs are not as common compared to black-box models like Graph Neural Networks (GNNs), primarily due to their requirement for predefined concepts and manual label for each instance, which demand domain knowledge and can be labor-intensive. This paper introduces a novel framework for Automated Molecular Concept (AutoMolCo) generation and labeling. AutoMolCo leverages the knowledge in Large Language Models (LLMs) to automatically generate predictive molecular concepts and label them for each molecule. Such procedures are repeated through iterative interactions with LLMs to refine concepts, enabling simple linear models on the refined concepts to outperform GNNs and LLM in-context learning on several benchmarks. The whole AutoMolCo framework is automated without any human knowledge inputs in either concept generation, labeling, or refinement, thereby surpassing the limitations of extant CMs while maintaining their explainability and allowing easy intervention. Through systematic experiments on MoleculeNet and High-Throughput Experimentation (HTE) datasets, we demonstrate that the AutoMolCo-induced explainable CMs are beneficial and promising for molecular science research.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09624",
        "abstract url": "https://arxiv.org/abs/2406.09624",
        "title": "DrivAerNet++: A Large-Scale Multimodal Car Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present DrivAerNet++, the largest and most comprehensive multimodal dataset for aerodynamic car design. DrivAerNet++ comprises 8,000 diverse car designs modeled with high-fidelity computational fluid dynamics (CFD) simulations. The dataset includes diverse car configurations such as fastback, notchback, and estateback, with different underbody and wheel designs to represent both internal combustion engines and electric vehicles. Each entry in the dataset features detailed 3D meshes, parametric models, aerodynamic coefficients, and extensive flow and surface field data, along with segmented parts for car classification and point cloud data. This dataset supports a wide array of machine learning applications including data-driven design optimization, generative modeling, surrogate model training, CFD simulation acceleration, and geometric classification. With more than 39 TB of publicly available engineering data, DrivAerNet++ fills a significant gap in available resources, providing high-quality, diverse data to enhance model training, promote generalization, and accelerate automotive design processes. Along with rigorous dataset validation, we also provide ML benchmarking results on the task of aerodynamic drag prediction, showcasing the breadth of applications supported by our dataset. This dataset is set to significantly impact automotive design and broader engineering disciplines by fostering innovation and improving the fidelity of aerodynamic evaluations.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09627",
        "abstract url": "https://arxiv.org/abs/2406.09627",
        "title": "RobustSAM: Segment Anything Robustly on Degraded Images",
        "rating": "-0.5",
        "keywords": [
            [
                "dehazing"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Segment Anything Model (SAM) has emerged as a transformative approach in image segmentation, acclaimed for its robust zero-shot segmentation capabilities and flexible prompting system. Nonetheless, its performance is challenged by images with degraded quality. Addressing this limitation, we propose the Robust Segment Anything Model (RobustSAM), which enhances SAM's performance on low-quality images while preserving its promptability and zero-shot generalization. Our method leverages the pre-trained SAM model with only marginal parameter increments and computational requirements. The additional parameters of RobustSAM can be optimized within 30 hours on eight GPUs, demonstrating its feasibility and practicality for typical research laboratories. We also introduce the Robust-Seg dataset, a collection of 688K image-mask pairs with different degradations designed to train and evaluate our model optimally. Extensive experiments across various segmentation tasks and datasets confirm RobustSAM's superior performance, especially under zero-shot conditions, underscoring its potential for extensive real-world application. Additionally, our method has been shown to effectively improve the performance of SAM-based downstream tasks such as single image dehazing and deblurring.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "comment": "Accepted by CVPR2024 (Highlight); Project Page: https://robustsam.github.io/"
    },
    {
        "paper id": "2406.09638",
        "abstract url": "https://arxiv.org/abs/2406.09638",
        "title": "RASPNet: A Benchmark Dataset for Radar Adaptive Signal Processing Applications",
        "rating": "-0.5",
        "keywords": [
            [
                "Radar"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work presents a large-scale dataset for radar adaptive signal processing (RASP) applications, aimed at supporting the development of data-driven models within the radar community. The dataset, called RASPNet, consists of 100 realistic scenarios compiled over a variety of topographies and land types from across the contiguous United States, designed to reflect a diverse array of real-world environments. Within each scenario, RASPNet consists of 10,000 clutter realizations from an airborne radar setting, which can be utilized for radar algorithm development and evaluation. RASPNet intends to fill a prominent gap in the availability of a large-scale, realistic dataset that standardizes the evaluation of adaptive radar processing techniques. We describe its construction, organization, and several potential applications, which includes a transfer learning example to demonstrate how RASPNet can be leveraged for realistic adaptive radar processing scenarios.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09639",
        "abstract url": "https://arxiv.org/abs/2406.09639",
        "title": "TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Multi-relational temporal graphs are powerful tools for modeling real-world data, capturing the evolving and interconnected nature of entities over time. Recently, many novel models are proposed for ML on such graphs intensifying the need for robust evaluation and standardized benchmark datasets. However, the availability of such resources remains scarce and evaluation faces added complexity due to reproducibility issues in experimental protocols. To address these challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel benchmarking framework tailored for evaluating methods for predicting future links on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a focus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0 facilitates comprehensive evaluations by presenting eight novel datasets spanning five domains with up to 53 million edges. TGB 2.0 datasets are significantly larger than existing datasets in terms of number of nodes, edges, or timestamps. In addition, TGB 2.0 provides a reproducible and realistic evaluation pipeline for multi-relational temporal graphs. Through extensive experimentation, we observe that 1) leveraging edge-type information is crucial to obtain high performance, 2) simple heuristic baselines are often competitive with more complex methods, 3) most methods fail to run on our largest datasets, highlighting the need for research on more scalable methods.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": "27 pages, 8 figures"
    },
    {
        "paper id": "2406.09675",
        "abstract url": "https://arxiv.org/abs/2406.09675",
        "title": "Benchmarking Spectral Graph Neural Networks: A Comprehensive Study on Effectiveness and Efficiency",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "With the recent advancements in graph neural networks (GNNs), spectral GNNs have received increasing popularity by virtue of their specialty in capturing graph signals in the frequency domain, demonstrating promising capability in specific tasks. However, few systematic studies have been conducted on assessing their spectral characteristics. This emerging family of models also varies in terms of designs and settings, leading to difficulties in comparing their performance and deciding on the suitable model for specific scenarios, especially for large-scale tasks. In this work, we extensively benchmark spectral GNNs with a focus on the frequency perspective. We analyze and categorize over 30 GNNs with 27 corresponding filters. Then, we implement these spectral models under a unified framework with dedicated graph computations and efficient training schemes. Thorough experiments are conducted on the spectral models with inclusive metrics on effectiveness and efficiency, offering practical guidelines on evaluating and selecting spectral GNNs with desirable performance. Our implementation enables application on larger graphs with comparable performance and less overhead, which is available at: https://github.com/gdmnl/Spectral-GNN-Benchmark.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09711",
        "abstract url": "https://arxiv.org/abs/2406.09711",
        "title": "AnimalFormer: Multimodal Vision Framework for Behavior-based Precision Livestock Farming",
        "rating": "-0.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We introduce a multimodal vision framework for precision livestock farming, harnessing the power of GroundingDINO, HQSAM, and ViTPose models. This integrated suite enables comprehensive behavioral analytics from video data without invasive animal tagging. GroundingDINO generates accurate bounding boxes around livestock, while HQSAM segments individual animals within these boxes. ViTPose estimates key body points, facilitating posture and movement analysis. Demonstrated on a sheep dataset with grazing, running, sitting, standing, and walking activities, our framework extracts invaluable insights: activity and grazing patterns, interaction dynamics, and detailed postural evaluations. Applicable across species and video resolutions, this framework revolutionizes non-invasive livestock monitoring for activity detection, counting, health assessments, and posture analyses. It empowers data-driven farm management, optimizing animal welfare and productivity through AI-powered behavioral understanding.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2024"
    },
    {
        "paper id": "2406.08817",
        "abstract url": "https://arxiv.org/abs/2406.08817",
        "title": "Automated Essay Scoring Using Grammatical Variety and Errors with Multi-Task Learning and Item Response Theory",
        "rating": "-1",
        "keywords": [
            [
                "grammar",
                "Grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study examines the effect of grammatical features in automatic essay scoring (AES). We use two kinds of grammatical features as input to an AES model: (1) grammatical items that writers used correctly in essays, and (2) the number of grammatical errors. Experimental results show that grammatical features improve the performance of AES models that predict the holistic scores of essays. Multi-task learning with the holistic and grammar scores, alongside using grammatical features, resulted in a larger improvement in model performance. We also show that a model using grammar abilities estimated using Item Response Theory (IRT) as the labels for the auxiliary task achieved comparable performance to when we used grammar scores assigned by human raters. In addition, we weight the grammatical features using IRT to consider the difficulty of grammatical items and writers' grammar abilities. We found that weighting grammatical features with the difficulty led to further improvement in performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to BEA2024"
    },
    {
        "paper id": "2406.08837",
        "abstract url": "https://arxiv.org/abs/2406.08837",
        "title": "Research on Deep Learning Model of Feature Extraction Based on Convolutional Neural Network",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Neural networks with relatively shallow layers and simple structures may have limited ability in accurately identifying pneumonia. In addition, deep neural networks also have a large demand for computing resources, which may cause convolutional neural networks to be unable to be implemented on terminals. Therefore, this paper will carry out the optimal classification of convolutional neural networks. Firstly, according to the characteristics of pneumonia images, AlexNet and InceptionV3 were selected to obtain better image recognition results. Combining the features of medical images, the forward neural network with deeper and more complex structure is learned. Finally, knowledge extraction technology is used to extract the obtained data into the AlexNet model to achieve the purpose of improving computing efficiency and reducing computing costs. The results showed that the prediction accuracy, specificity, and sensitivity of the trained AlexNet model increased by 4.25 percentage points, 7.85 percentage points, and 2.32 percentage points, respectively. The graphics processing usage has decreased by 51% compared to the InceptionV3 mode.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08863",
        "abstract url": "https://arxiv.org/abs/2406.08863",
        "title": "Self-supervised Graph Neural Network for Mechanical CAD Retrieval",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "CAD (Computer-Aided Design) plays a crucial role in mechanical industry, where large numbers of similar-shaped CAD parts are often created. Efficiently reusing these parts is key to reducing design and production costs for enterprises. Retrieval systems are vital for achieving CAD reuse, but the complex shapes of CAD models are difficult to accurately describe using text or keywords, making traditional retrieval methods ineffective. While existing representation learning approaches have been developed for CAD, manually labeling similar samples in these methods is expensive. Additionally, CAD models' unique parameterized data structure presents challenges for applying existing 3D shape representation learning techniques directly. In this work, we propose GC-CAD, a self-supervised contrastive graph neural network-based method for mechanical CAD retrieval that directly models parameterized CAD raw files. GC-CAD consists of two key modules: structure-aware representation learning and contrastive graph learning framework. The method leverages graph neural networks to extract both geometric and topological information from CAD models, generating feature representations. We then introduce a simple yet effective contrastive graph learning framework approach, enabling the model to train without manual labels and generate retrieval-ready representations. Experimental results on four datasets including human evaluation demonstrate that the proposed method achieves significant accuracy improvements and up to 100 times efficiency improvement over the baseline methods.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08881",
        "abstract url": "https://arxiv.org/abs/2406.08881",
        "title": "No perspective, no perception!! Perspective-aware Healthcare Answer Summarization",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "Healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Healthcare Community Question Answering (CQA) forums offer an accessible platform for individuals seeking information on various healthcare-related topics. People find such platforms suitable for self-disclosure, seeking medical opinions, finding simplified explanations for their medical conditions, and answering others' questions. However, answers on these forums are typically diverse and prone to off-topic discussions. It can be challenging for readers to sift through numerous answers and extract meaningful insights, making answer summarization a crucial task for CQA forums. While several efforts have been made to summarize the community answers, most of them are limited to the open domain and overlook the different perspectives offered by these answers. To address this problem, this paper proposes a novel task of perspective-specific answer summarization. We identify various perspectives, within healthcare-related responses and frame a perspective-driven abstractive summary covering all responses. To achieve this, we annotate 3167 CQA threads with 6193 perspective-aware summaries in our PUMA dataset. Further, we propose PLASMA, a prompt-driven controllable summarization model. To encapsulate the perspective-specific conditions, we design an energy-controlled loss function for the optimization. We also leverage the prefix tuner to learn the intricacies of the health-care perspective summarization. Our evaluation against five baselines suggests the superior performance of PLASMA by a margin of 1.5-21% improvement. We supplement our experiments with ablation and qualitative analysis.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ACL 2024 Findings"
    },
    {
        "paper id": "2406.08887",
        "abstract url": "https://arxiv.org/abs/2406.08887",
        "title": "Low-Overhead Channel Estimation via 3D Extrapolation for TDD mmWave Massive MIMO Systems Under High-Mobility Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "In TDD mmWave massive MIMO systems, the downlink CSI can be attained through uplink channel estimation thanks to the uplink-downlink channel reciprocity. However, the channel aging issue is significant under high-mobility scenarios and thus necessitates frequent uplink channel estimation. In addition, large amounts of antennas and subcarriers lead to high-dimensional CSI matrices, aggravating the pilot training overhead. To systematically reduce the pilot overhead, a spatial, frequency, and temporal domain (3D) channel extrapolation framework is proposed in this paper. Considering the marginal effects of pilots in the spatial and frequency domains and the effectiveness of traditional knowledge-driven channel estimation methods, we first propose a knowledge-and-data driven spatial-frequency channel extrapolation network (KDD-SFCEN) for uplink channel estimation by exploiting the least square estimator for coarse channel estimation and joint spatial-frequency channel extrapolation to reduce the spatial-frequency domain pilot overhead. Then, resorting to the uplink-downlink channel reciprocity and temporal domain dependencies of downlink channels, a temporal uplink-downlink channel extrapolation network (TUDCEN) is proposed for slot-level channel extrapolation, aiming to enlarge the pilot signal period and thus reduce the temporal domain pilot overhead under high-mobility scenarios. Specifically, we propose the spatial-frequency sampling embedding module to reduce the representation dimension and consequent computational complexity, and we propose to exploit the autoregressive generative Transformer for generating downlink channels autoregressively. Numerical results demonstrate the superiority of the proposed framework in significantly reducing the pilot training overhead by more than 16 times and improving the system's spectral efficiency under high-mobility scenarios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures, 3 tables. This paper has been submitted to IEEE journal for possible publication"
    },
    {
        "paper id": "2406.08913",
        "abstract url": "https://arxiv.org/abs/2406.08913",
        "title": "Maximizing the Maximum Degree in Ordered Yao Graphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "For an ordered point set in a Euclidean space or, more generally, in an abstract metric space, the ordered Yao graph is obtained by connecting each of the points to its closest predecessor by a directed edge. We show that for every set of $n$ points in $\\mathbb{R}^d$, there exists an order such that the corresponding ordered Yao graph has maximum degree at least $\\log{n}/(4d)$. Apart from the $1/(4d)$ factor, this bound is the best possible. As for the abstract setting, we show that for every $n$-element metric space, there exists an order such that the corresponding ordered Yao graph has maximum degree $\u03a9(\\sqrt{\\log{n}/\\log\\log{n}})$.",
        "subjects": [
            "math.CO",
            "cs.CG",
            "math.MG"
        ],
        "comment": "9 pages, 1 figure"
    },
    {
        "paper id": "2406.08940",
        "abstract url": "https://arxiv.org/abs/2406.08940",
        "title": "Word Order in English-Japanese Simultaneous Interpretation: Analyses and Evaluation using Chunk-wise Monotonic Translation",
        "rating": "-1",
        "keywords": [
            [
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper analyzes the features of monotonic translations, which follow the word order of the source language, in simultaneous interpreting (SI). The word order differences are one of the biggest challenges in SI, especially for language pairs with significant structural differences like English and Japanese. We analyzed the characteristics of monotonic translations using the NAIST English-to-Japanese Chunk-wise Monotonic Translation Evaluation Dataset and found some grammatical structures that make monotonic translation difficult in English-Japanese SI. We further investigated the features of monotonic translations through evaluating the output from the existing speech translation (ST) and simultaneous speech translation (simulST) models on NAIST English-to-Japanese Chunk-wise Monotonic Translation Evaluation Dataset as well as on existing test sets. The results suggest that the existing SI-based test set underestimates the model performance. We also found that the monotonic-translation-based dataset would better evaluate simulST models, while using an offline-based test set for evaluating simulST models underestimates the model performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to IWSLT2024"
    },
    {
        "paper id": "2406.08946",
        "abstract url": "https://arxiv.org/abs/2406.08946",
        "title": "Human-Robot Interface for Teleoperated Robotized Planetary Sample Collection and Assembly",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "As human space exploration evolves toward longer voyages farther from our home planet, in-situ resource utilization (ISRU) becomes increasingly important. Haptic teleoperations are one of the technologies by which such activities can be carried out remotely by humans, whose expertise is still necessary for complex activities. In order to perform precision tasks with effectiveness, the operator must experience ease of use and accuracy. The same features are demanded to reduce the complexity of the training procedures and the associated learning time for operators without a specific background in robotic teleoperations. Haptic teleoperation systems, that allow for a natural feeling of forces, need to cope with the trade-off between accurate movements and workspace extension. Clearly, both of them are required for typical ISRU tasks. In this work, we develop a new concept of operations and suitable human-robot interfaces to achieve sample collection and assembly with ease of use and accuracy. In the proposed operational concept, the teleoperation space is extended by executing automated trajectories, offline planned at the control station. In three different experimental scenarios, we validate the end-to-end system involving the control station and the robotic asset, by assessing the contribution of haptics to mission success, the system robustness to consistent delays, and the ease of training new operators.",
        "subjects": [
            "cs.RO",
            "cs.HC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08953",
        "abstract url": "https://arxiv.org/abs/2406.08953",
        "title": "Preserving Identity with Variational Score for General-purpose 3D Editing",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "diffusion",
                "image editing"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present Piva (Preserving Identity with Variational Score Distillation), a novel optimization-based method for editing images and 3D models based on diffusion models. Specifically, our approach is inspired by the recently proposed method for 2D image editing - Delta Denoising Score (DDS). We pinpoint the limitations in DDS for 2D and 3D editing, which causes detail loss and over-saturation. To address this, we propose an additional score distillation term that enforces identity preservation. This results in a more stable editing process, gradually optimizing NeRF models to match target prompts while retaining crucial input characteristics. We demonstrate the effectiveness of our approach in zero-shot image and neural field editing. Our method successfully alters visual attributes, adds both subtle and substantial structural elements, translates shapes, and achieves competitive results on standard 2D and 3D editing benchmarks. Additionally, our method imposes no constraints like masking or pre-training, making it compatible with a wide range of pre-trained diffusion models. This allows for versatile editing without needing neural field-to-mesh conversion, offering a more user-friendly experience.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "22 pages, 14 figures"
    },
    {
        "paper id": "2406.08960",
        "abstract url": "https://arxiv.org/abs/2406.08960",
        "title": "AirPlanes: Accurate Plane Estimation via 3D-Consistent Embeddings",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Extracting planes from a 3D scene is useful for downstream tasks in robotics and augmented reality. In this paper we tackle the problem of estimating the planar surfaces in a scene from posed images. Our first finding is that a surprisingly competitive baseline results from combining popular clustering algorithms with recent improvements in 3D geometry estimation. However, such purely geometric methods are understandably oblivious to plane semantics, which are crucial to discerning distinct planes. To overcome this limitation, we propose a method that predicts multi-view consistent plane embeddings that complement geometry when clustering points into planes. We show through extensive evaluation on the ScanNetV2 dataset that our new method outperforms existing approaches and our strong geometric baseline for the task of plane estimation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08985",
        "abstract url": "https://arxiv.org/abs/2406.08985",
        "title": "The Behavior of Tree-Width and Path-Width under Graph Operations and Graph Transformations",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Tree-width and path-width are well-known graph parameters. Many NP-hard graph problems allow polynomial-time solutions, when restricted to graphs of bounded tree-width or bounded path-width. In this work, we study the behavior of tree-width and path-width under various unary and binary graph transformations. Doing so, for considered transformations we provide upper and lower bounds for the tree-width and path-width of the resulting graph in terms of the tree-width and path-width of the initial graphs or argue why such bounds are impossible to specify. Among the studied, unary transformations are vertex addition, vertex deletion, edge addition, edge deletion, subgraphs, vertex identification, edge contraction, edge subdivision, minors, powers of graphs, line graphs, edge complements, local complements, Seidel switching, and Seidel complementation. Among the studied, binary transformations we consider the disjoint union, join, union, substitution, graph product, 1-sum, and corona of two graphs.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "34 pages"
    },
    {
        "paper id": "2406.09005",
        "abstract url": "https://arxiv.org/abs/2406.09005",
        "title": "Privacy Aware Memory Forensics",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In recent years, insider threats and attacks have been increasing in terms of frequency and cost to the corporate business. The utilization of end-to-end encrypted instant messaging applications (WhatsApp, Telegram, VPN) by malicious insiders raised data breach incidents exponentially. The Securities and Exchange Board of India (SEBI) investigated reports on such data leak incidents and reported about twelve companies where earnings data and financial information were leaked using WhatsApp messages. Recent surveys indicate that 60% of data breaches are primarily caused by malicious insider threats. Especially, in the case of the defense environment, information leaks by insiders will jeopardize the countrys national security. Sniffing of network and host-based activities will not work in an insider threat detection environment due to end-to-end encryption. Memory forensics allows access to the messages sent or received over an end-to-end encrypted environment but with a total compromise of the users privacy. In this research, we present a novel solution to detect data leakages by insiders in an organization. Our approach captures the RAM of the insiders device and analyses it for sensitive information leaks from a host system while maintaining the users privacy. Sensitive data leaks are identified with context using a deep learning model. The feasibility and effectiveness of the proposed idea have been demonstrated with the help of a military use case. The proposed architecture can however be used across various use cases with minor modifications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09017",
        "abstract url": "https://arxiv.org/abs/2406.09017",
        "title": "A PCA based Keypoint Tracking Approach to Automated Facial Expressions Encoding",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Facial Action Coding System (FACS) for studying facial expressions is manual and requires significant effort and expertise. This paper explores the use of automated techniques to generate Action Units (AUs) for studying facial expressions. We propose an unsupervised approach based on Principal Component Analysis (PCA) and facial keypoint tracking to generate data-driven AUs called PCA AUs using the publicly available DISFA dataset. The PCA AUs comply with the direction of facial muscle movements and are capable of explaining over 92.83 percent of the variance in other public test datasets (BP4D-Spontaneous and CK+), indicating their capability to generalize facial expressions. The PCA AUs are also comparable to a keypoint-based equivalence of FACS AUs in terms of variance explained on the test datasets. In conclusion, our research demonstrates the potential of automated techniques to be an alternative to manual FACS labeling which could lead to efficient real-time analysis of facial expressions in psychology and related fields. To promote further research, we have made code repository publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in [LNCS,volume 14301], and is available online at https://doi.org/10.1007/978-3-031-45170-6_85"
    },
    {
        "paper id": "2406.09103",
        "abstract url": "https://arxiv.org/abs/2406.09103",
        "title": "Chain-of-Though (CoT) prompting strategies for medical error detection and correction",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper describes our submission to the MEDIQA-CORR 2024 shared task for automatically detecting and correcting medical errors in clinical notes. We report results for three methods of few-shot In-Context Learning (ICL) augmented with Chain-of-Thought (CoT) and reason prompts using a large language model (LLM). In the first method, we manually analyse a subset of train and validation dataset to infer three CoT prompts by examining error types in the clinical notes. In the second method, we utilise the training dataset to prompt the LLM to deduce reasons about their correctness or incorrectness. The constructed CoTs and reasons are then augmented with ICL examples to solve the tasks of error detection, span identification, and error correction. Finally, we combine the two methods using a rule-based ensemble method. Across the three sub-tasks, our ensemble method achieves a ranking of 3rd for both sub-task 1 and 2, while securing 7th place in sub-task 3 among all submissions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "accepted as NAACL workshop"
    },
    {
        "paper id": "2406.09120",
        "abstract url": "https://arxiv.org/abs/2406.09120",
        "title": "Direct Imitation Learning-based Visual Servoing using the Large Projection Formulation",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Today robots must be safe, versatile, and user-friendly to operate in unstructured and human-populated environments. Dynamical system-based imitation learning enables robots to perform complex tasks stably and without explicit programming, greatly simplifying their real-world deployment. To exploit the full potential of these systems it is crucial to implement closed loops that use visual feedback. Vision permits to cope with environmental changes, but is complex to handle due to the high dimension of the image space. This study introduces a dynamical system-based imitation learning for direct visual servoing. It leverages off-the-shelf deep learning-based perception backbones to extract robust features from the raw input image, and an imitation learning strategy to execute sophisticated robot motions. The learning blocks are integrated using the large projection task priority formulation. As demonstrated through extensive experimental analysis, the proposed method realizes complex tasks with a robotic manipulator.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "First two authors contributed equally"
    },
    {
        "paper id": "2406.09160",
        "abstract url": "https://arxiv.org/abs/2406.09160",
        "title": "Beyond the Frontier: Predicting Unseen Walls from Occupancy Grids by Learning from Floor Plans",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "LIDAR"
            ],
            [
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we tackle the challenge of predicting the unseen walls of a partially observed environment as a set of 2D line segments, conditioned on occupancy grids integrated along the trajectory of a 360\u00b0 LIDAR sensor. A dataset of such occupancy grids and their corresponding target wall segments is collected by navigating a virtual robot between a set of randomly sampled waypoints in a collection of office-scale floor plans from a university campus. The line segment prediction task is formulated as an autoregressive sequence prediction task, and an attention-based deep network is trained on the dataset. The sequence-based autoregressive formulation is evaluated through predicted information gain, as in frontier-based autonomous exploration, demonstrating significant improvements over both non-predictive estimation and convolution-based image prediction found in the literature. Ablations on key components are evaluated, as well as sensor range and the occupancy grid's metric area. Finally, model generality is validated by predicting walls in a novel floor plan reconstructed on-the-fly in a real-world office environment.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "RA-L, 8 pages"
    },
    {
        "paper id": "2406.09175",
        "abstract url": "https://arxiv.org/abs/2406.09175",
        "title": "ReMI: A Dataset for Reasoning with Multiple Images",
        "rating": "-1",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "With the continuous advancement of large language models (LLMs), it is essential to create new benchmarks to effectively evaluate their expanding capabilities and identify areas for improvement. This work focuses on multi-image reasoning, an emerging capability in state-of-the-art LLMs. We introduce ReMI, a dataset designed to assess LLMs' ability to Reason with Multiple Images. This dataset encompasses a diverse range of tasks, spanning various reasoning domains such as math, physics, logic, code, table/chart understanding, and spatial and temporal reasoning. It also covers a broad spectrum of characteristics found in multi-image reasoning scenarios. We have benchmarked several cutting-edge LLMs using ReMI and found a substantial gap between their performance and human-level proficiency. This highlights the challenges in multi-image reasoning and the need for further research. Our analysis also reveals the strengths and weaknesses of different models, shedding light on the types of reasoning that are currently attainable and areas where future models require improvement. To foster further research in this area, we are releasing ReMI publicly: https://huggingface.co/datasets/mehrankazemi/ReMI.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09181",
        "abstract url": "https://arxiv.org/abs/2406.09181",
        "title": "A Large-scale Universal Evaluation Benchmark For Face Forgery Detection",
        "rating": "-1",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "With the rapid development of AI-generated content (AIGC) technology, the production of realistic fake facial images and videos that deceive human visual perception has become possible. Consequently, various face forgery detection techniques have been proposed to identify such fake facial content. However, evaluating the effectiveness and generalizability of these detection techniques remains a significant challenge. To address this, we have constructed a large-scale evaluation benchmark called DeepFaceGen, aimed at quantitatively assessing the effectiveness of face forgery detection and facilitating the iterative development of forgery detection technology. DeepFaceGen consists of 776,990 real face image/video samples and 773,812 face forgery image/video samples, generated using 34 mainstream face generation techniques. During the construction process, we carefully consider important factors such as content diversity, fairness across ethnicities, and availability of comprehensive labels, in order to ensure the versatility and convenience of DeepFaceGen. Subsequently, DeepFaceGen is employed in this study to evaluate and analyze the performance of 13 mainstream face forgery detection techniques from various perspectives. Through extensive experimental analysis, we derive significant findings and propose potential directions for future research. The code and dataset for DeepFaceGen are available at https://github.com/HengruiLou/DeepFaceGen.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This is a paper about constructing a large-scale universal evaluation benchmark for face forgery detection.The full text is 30 pages"
    },
    {
        "paper id": "2406.09185",
        "abstract url": "https://arxiv.org/abs/2406.09185",
        "title": "Thoracic Surgery Video Analysis for Surgical Phase Recognition",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Surgical",
                "Surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents an approach for surgical phase recognition using video data, aiming to provide a comprehensive understanding of surgical procedures for automated workflow analysis. The advent of robotic surgery, digitized operating rooms, and the generation of vast amounts of data have opened doors for the application of machine learning and computer vision in the analysis of surgical videos. Among these advancements, Surgical Phase Recognition(SPR) stands out as an emerging technology that has the potential to recognize and assess the ongoing surgical scenario, summarize the surgery, evaluate surgical skills, offer surgical decision support, and facilitate medical training. In this paper, we analyse and evaluate both frame-based and video clipping-based phase recognition on thoracic surgery dataset consisting of 11 classes of phases. Specifically, we utilize ImageNet ViT for image-based classification and VideoMAE as the baseline model for video-based classification. We show that Masked Video Distillation(MVD) exhibits superior performance, achieving a top-1 accuracy of 72.9%, compared to 52.31% achieved by ImageNet ViT. These findings underscore the efficacy of video-based classifiers over their image-based counterparts in surgical phase recognition tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "2 pages, 2 figures"
    },
    {
        "paper id": "2406.09233",
        "abstract url": "https://arxiv.org/abs/2406.09233",
        "title": "C2HLSC: Can LLMs Bridge the Software-to-Hardware Design Gap?",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "High Level Synthesis (HLS) tools offer rapid hardware design from C code, but their compatibility is limited by code constructs. This paper investigates Large Language Models (LLMs) for refactoring C code into HLS-compatible formats. We present several case studies by using an LLM to rewrite C code for NIST 800-22 randomness tests, a QuickSort algorithm and AES-128 into HLS-synthesizable c. The LLM iteratively transforms the C code guided by user prompts, implementing functions like streaming data and hardware-specific signals. This evaluation demonstrates the LLM's potential to assist hardware design refactoring regular C code into HLS synthesizable C code.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Accepted at The First IEEE International Workshop on LLM-Aided Design"
    },
    {
        "paper id": "2406.09238",
        "abstract url": "https://arxiv.org/abs/2406.09238",
        "title": "Near-Field Multiuser Communications based on Sparse Arrays",
        "rating": "-1",
        "keywords": [
            [
                "super-resolution"
            ]
        ],
        "abstract": "This paper considers near-field multiuser communications based on sparse arrays (SAs). First, for the uniform SAs (USAs), we analyze the beam gains of channel steering vectors, which shows that increasing the antenna spacings can effectively improve the spatial resolution of the antenna arrays to enhance the sum rate of multiuser communications. Then, we investigate nonuniform SAs (NSAs) to mitigate the high multiuser interference from the grating lobes of the USAs. To maximize the sum rate of near-field multiuser communications, we optimize the antenna positions of the NSAs, where a successive convex approximation-based antenna position optimization algorithm is proposed. Moreover, we find that the channels of both the USAs and the NSAs show uniform sparsity in the defined surrogate distance-angle (SD-A) domain. Based on the channel sparsity, an on-grid SD-A-domain orthogonal matching pursuit (SDA-OMP) algorithm is developed to estimate multiuser channels. To further improve the resolution of the SDA-OMP, we also design an off-grid SD-A-domain iterative super-resolution channel estimation algorithm. Simulation results demonstrate the superior performance of the proposed methods.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09239",
        "abstract url": "https://arxiv.org/abs/2406.09239",
        "title": "EHAZOP: A Proof of Concept Ethical Hazard Analysis of an Assistive Robot",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "The use of assistive robots in domestic environments can raise significant ethical concerns, from the risk of individual ethical harm to wider societal ethical impacts including culture flattening and compromise of human dignity. It is therefore essential to ensure that technological development of these robots is informed by robust and inclusive techniques for mitigating ethical concerns. This paper presents EHAZOP, a method for conducting an ethical hazard analysis on an assistive robot. EHAZOP draws upon collaborative, creative and structured processes originating within safety engineering, using these to identify ethical concerns associated with the operation of a given assistive robot. We present the results of a proof of concept study of EHAZOP, demonstrating the potential for this process to identify diverse ethical hazards in these systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Presented in ICRA 2024 WORKSHOP ON ROBOT ETHICS Ethical, Legal and User Perspectives in Robotics & Automation WOROBET: https://sites.google.com/view/icra2024-robot-ethics"
    },
    {
        "paper id": "2406.09292",
        "abstract url": "https://arxiv.org/abs/2406.09292",
        "title": "Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "Synthesis",
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We address the problem of multi-object 3D pose control in image diffusion models. Instead of conditioning on a sequence of text tokens, we propose to use a set of per-object representations, Neural Assets, to control the 3D pose of individual objects in a scene. Neural Assets are obtained by pooling visual representations of objects from a reference image, such as a frame in a video, and are trained to reconstruct the respective objects in a different image, e.g., a later frame in the video. Importantly, we encode object visuals from the reference image while conditioning on object poses from the target frame. This enables learning disentangled appearance and pose features. Combining visual and 3D pose representations in a sequence-of-tokens format allows us to keep the text-to-image architecture of existing models, with Neural Assets in place of text tokens. By fine-tuning a pre-trained text-to-image diffusion model with this information, our approach enables fine-grained 3D pose and placement control of individual objects in a scene. We further demonstrate that Neural Assets can be transferred and recomposed across different scenes. Our model achieves state-of-the-art multi-object editing results on both synthetic 3D scene datasets, as well as two real-world video datasets (Objectron, Waymo Open).",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Additional details and video results are available at https://neural-assets-paper.github.io/"
    },
    {
        "paper id": "2406.09301",
        "abstract url": "https://arxiv.org/abs/2406.09301",
        "title": "Hands-free teleoperation of a nearby manipulator through a virtual body-to-robot link",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper introduces an innovative control approach for teleoperating a robot in close proximity to a human operator, which could be useful to control robots embedded on wheelchairs. The method entails establishing a virtual connection between a specific body part and the robot's end-effector, visually displayed through an Augmented Reality (AR) headset. This linkage enables the transformation of body rotations into amplified effector translations, extending the robot's workspace beyond the capabilities of direct one-to-one mapping. Moreover, the linkage can be reconfigured using a joystick, resulting in a hybrid position/velocity control mode using the body/joystick motions respectively. After providing a comprehensive overview of the control methodology, we present the results of an experimental campaign designed to elucidate the advantages and drawbacks of our approach compared to the conventional joystick-based teleoperation method. The body-link control demonstrates slightly faster task completion and is naturally preferred over joystick velocity control, albeit being more physically demanding for tasks with a large range. The hybrid mode, where participants could simultaneously utilize both modes, emerges as a compromise, combining the intuitiveness of the body mode with the extensive task range of the velocity mode. Finally, we provide preliminary observations on potential assistive applications using head motions, especially for operators with limited range of motion in their bodies.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to IEEE BioRob2024"
    },
    {
        "paper id": "2406.09323",
        "abstract url": "https://arxiv.org/abs/2406.09323",
        "title": "Master of Disaster: A Disaster-Related Event Monitoring System From News Streams",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The need for a disaster-related event monitoring system has arisen due to the societal and economic impact caused by the increasing number of severe disaster events. An event monitoring system should be able to extract event-related information from texts, and discriminates event instances. We demonstrate our open-source event monitoring system, namely, Master of Disaster (MoD), which receives news streams, extracts event information, links extracted information to a knowledge graph (KG), in this case Wikidata, and discriminates event instances visually. The goal of event visualization is to group event mentions referring to the same real-world event instance so that event instance discrimination can be achieved by visual screening.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2406.09325",
        "abstract url": "https://arxiv.org/abs/2406.09325",
        "title": "REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space",
        "rating": "-1",
        "keywords": [
            [
                "model editing",
                "Unlearning"
            ],
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) risk inadvertently memorizing and divulging sensitive or personally identifiable information (PII) seen in training data, causing privacy concerns. Current approaches to address this issue involve costly dataset scrubbing, or model filtering through unlearning and model editing, which can be bypassed through extraction attacks. We propose REVS, a novel model editing method for unlearning sensitive information from LLMs. REVS identifies and modifies a small subset of neurons relevant for each piece of sensitive information. By projecting these neurons to the vocabulary space (unembedding), we pinpoint the components driving its generation. We then compute a model edit based on the pseudo-inverse of the unembedding matrix, and apply it to de-promote generation of the targeted sensitive data. To adequately evaluate our method on truly sensitive information, we curate two datasets: an email dataset inherently memorized by GPT-J, and a synthetic social security number dataset that we tune the model to memorize. Compared to other state-of-the-art model editing methods, REVS demonstrates superior performance in both eliminating sensitive information and robustness to extraction attacks, while retaining integrity of the underlying model. The code and a demo notebook are available at https://technion-cs-nlp.github.io/REVS.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages, 3 figures"
    },
    {
        "paper id": "2406.09326",
        "abstract url": "https://arxiv.org/abs/2406.09326",
        "title": "PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance",
        "rating": "-1",
        "keywords": [
            [
                "bird's-eye view"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recently, artificial intelligence techniques for education have been received increasing attentions, while it still remains an open problem to design the effective music instrument instructing systems. Although key presses can be directly derived from sheet music, the transitional movements among key presses require more extensive guidance in piano performance. In this work, we construct a piano-hand motion generation benchmark to guide hand movements and fingerings for piano playing. To this end, we collect an annotated dataset, PianoMotion10M, consisting of 116 hours of piano playing videos from a bird's-eye view with 10 million annotated hand poses. We also introduce a powerful baseline model that generates hand motions from piano audios through a position predictor and a position-guided gesture generator. Furthermore, a series of evaluation metrics are designed to assess the performance of the baseline model, including motion similarity, smoothness, positional accuracy of left and right hands, and overall fidelity of movement distribution. Despite that piano key presses with respect to music scores or audios are already accessible, PianoMotion10M aims to provide guidance on piano fingering for instruction purposes. The dataset and source code can be accessed at https://agnjason.github.io/PianoMotion-page.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CV",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "Codes and Dataset: https://agnjason.github.io/PianoMotion-page"
    },
    {
        "paper id": "2406.09333",
        "abstract url": "https://arxiv.org/abs/2406.09333",
        "title": "Memory-Efficient Sparse Pyramid Attention Networks for Whole Slide Image Analysis",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "Whole Slide",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Whole Slide Images (WSIs) are crucial for modern pathological diagnosis, yet their gigapixel-scale resolutions and sparse informative regions pose significant computational challenges. Traditional dense attention mechanisms, widely used in computer vision and natural language processing, are impractical for WSI analysis due to the substantial data scale and the redundant processing of uninformative areas. To address these challenges, we propose Memory-Efficient Sparse Pyramid Attention Networks with Shifted Windows (SPAN), drawing inspiration from state-of-the-art sparse attention techniques in other domains. SPAN introduces a sparse pyramid attention architecture that hierarchically focuses on informative regions within the WSI, aiming to reduce memory overhead while preserving critical features. Additionally, the incorporation of shifted windows enables the model to capture long-range contextual dependencies essential for accurate classification. We evaluated SPAN on multiple public WSI datasets, observing its competitive performance. Unlike existing methods that often struggle to model spatial and contextual information due to memory constraints, our approach enables the accurate modeling of these crucial features. Our study also highlights the importance of key design elements in attention mechanisms, such as the shifted-window scheme and the hierarchical structure, which contribute substantially to the effectiveness of SPAN in WSI analysis. The potential of SPAN for memory-efficient and effective analysis of WSI data is thus demonstrated, and the code will be made publicly available following the publication of this work.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09355",
        "abstract url": "https://arxiv.org/abs/2406.09355",
        "title": "Can't Hide Behind the API: Stealing Black-Box Commercial Embedding Models",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Embedding models that generate representation vectors from natural language text are widely used, reflect substantial investments, and carry significant commercial value. Companies such as OpenAI and Cohere have developed competing embedding models accessed through APIs that require users to pay for usage. In this architecture, the models are \"hidden\" behind APIs, but this does not mean that they are \"well guarded\". We present, to our knowledge, the first effort to \"steal\" these models for retrieval by training local models on text-embedding pairs obtained from the commercial APIs. Our experiments show using standard benchmarks that it is possible to efficiently replicate the retrieval effectiveness of the commercial embedding models using an attack that costs only around $200 to train (presumably) smaller models with fewer dimensions. Our findings raise important considerations for deploying commercial embedding models and suggest measures to mitigate the risk of model theft.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09371",
        "abstract url": "https://arxiv.org/abs/2406.09371",
        "title": "LRM-Zero: Training Large Reconstruction Models with Synthesized Data",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "synthesis"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present LRM-Zero, a Large Reconstruction Model (LRM) trained entirely on synthesized 3D data, achieving high-quality sparse-view 3D reconstruction. The core of LRM-Zero is our procedural 3D dataset, Zeroverse, which is automatically synthesized from simple primitive shapes with random texturing and augmentations (e.g., height fields, boolean differences, and wireframes). Unlike previous 3D datasets (e.g., Objaverse) which are often captured or crafted by humans to approximate real 3D data, Zeroverse completely ignores realistic global semantics but is rich in complex geometric and texture details that are locally similar to or even more intricate than real objects. We demonstrate that our LRM-Zero, trained with our fully synthesized Zeroverse, can achieve high visual quality in the reconstruction of real-world objects, competitive with models trained on Objaverse. We also analyze several critical design choices of Zeroverse that contribute to LRM-Zero's capability and training stability. Our work demonstrates that 3D reconstruction, one of the core tasks in 3D vision, can potentially be addressed without the semantics of real-world objects. The Zeroverse's procedural synthesis code and interactive visualization are available at: https://desaixie.github.io/lrm-zero/.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "23 pages, 8 figures. Our code and interactive visualization are available at: https://desaixie.github.io/lrm-zero/"
    },
    {
        "paper id": "2406.09377",
        "abstract url": "https://arxiv.org/abs/2406.09377",
        "title": "GGHead: Fast and Generalizable 3D Gaussian Heads",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "GAN",
                "superresolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Learning 3D head priors from large 2D image collections is an important step towards high-quality 3D-aware human modeling. A core requirement is an efficient architecture that scales well to large-scale datasets and large image resolutions. Unfortunately, existing 3D GANs struggle to scale to generate samples at high resolutions due to their relatively slow train and render speeds, and typically have to rely on 2D superresolution networks at the expense of global 3D consistency. To address these challenges, we propose Generative Gaussian Heads (GGHead), which adopts the recent 3D Gaussian Splatting representation within a 3D GAN framework. To generate a 3D representation, we employ a powerful 2D CNN generator to predict Gaussian attributes in the UV space of a template head mesh. This way, GGHead exploits the regularity of the template's UV layout, substantially facilitating the challenging task of predicting an unstructured set of 3D Gaussians. We further improve the geometric fidelity of the generated 3D representations with a novel total variation loss on rendered UV coordinates. Intuitively, this regularization encourages that neighboring rendered pixels should stem from neighboring Gaussians in the template's UV space. Taken together, our pipeline can efficiently generate 3D heads trained only from single-view 2D image observations. Our proposed framework matches the quality of existing 3D head GANs on FFHQ while being both substantially faster and fully 3D consistent. As a result, we demonstrate real-time generation and rendering of high-quality 3D-consistent heads at $1024^2$ resolution for the first time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://tobias-kirschstein.github.io/gghead/ ; YouTube Video: https://www.youtube.com/watch?v=1iyC74neQXc"
    },
    {
        "paper id": "2406.09394",
        "abstract url": "https://arxiv.org/abs/2406.09394",
        "title": "WonderWorld: Interactive 3D Scene Generation from a Single Image",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present WonderWorld, a novel framework for interactive 3D scene extrapolation that enables users to explore and shape virtual environments based on a single input image and user-specified text. While significant improvements have been made to the visual quality of scene generation, existing methods are run offline, taking tens of minutes to hours to generate a scene. By leveraging Fast Gaussian Surfels and a guided diffusion-based depth estimation method, WonderWorld generates geometrically consistent extrapolation while significantly reducing computational time. Our framework generates connected and diverse 3D scenes in less than 10 seconds on a single A6000 GPU, enabling real-time user interaction and exploration. We demonstrate the potential of WonderWorld for applications in virtual reality, gaming, and creative design, where users can quickly generate and navigate immersive, potentially infinite virtual worlds from a single image. Our approach represents a significant advancement in interactive 3D scene generation, opening up new possibilities for user-driven content creation and exploration in virtual environments. We will release full code and software for reproducibility. Project website: https://WonderWorld-2024.github.io/",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project website: https://WonderWorld-2024.github.io/"
    },
    {
        "paper id": "2406.09408",
        "abstract url": "https://arxiv.org/abs/2406.09408",
        "title": "Data Attribution for Text-to-Image Models by Unlearning Synthesized Images",
        "rating": "-1",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "Unlearning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The goal of data attribution for text-to-image models is to identify the training images that most influence the generation of a new image. We can define \"influence\" by saying that, for a given output, if a model is retrained from scratch without that output's most influential images, the model should then fail to generate that output image. Unfortunately, directly searching for these influential images is computationally infeasible, since it would require repeatedly retraining from scratch. We propose a new approach that efficiently identifies highly-influential images. Specifically, we simulate unlearning the synthesized image, proposing a method to increase the training loss on the output image, without catastrophic forgetting of other, unrelated concepts. Then, we find training images that are forgotten by proxy, identifying ones with significant loss deviations after the unlearning process, and label these as influential. We evaluate our method with a computationally intensive but \"gold-standard\" retraining from scratch and demonstrate our method's advantages over previous methods.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project page: https://peterwang512.github.io/AttributeByUnlearning Code: https://github.com/PeterWang512/AttributeByUnlearning"
    },
    {
        "paper id": "2406.09414",
        "abstract url": "https://arxiv.org/abs/2406.09414",
        "title": "Depth Anything V2",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This work presents Depth Anything V2. Without pursuing fancy techniques, we aim to reveal crucial findings to pave the way towards building a powerful monocular depth estimation model. Notably, compared with V1, this version produces much finer and more robust depth predictions through three key practices: 1) replacing all labeled real images with synthetic images, 2) scaling up the capacity of our teacher model, and 3) teaching student models via the bridge of large-scale pseudo-labeled real images. Compared with the latest models built on Stable Diffusion, our models are significantly more efficient (more than 10x faster) and more accurate. We offer models of different scales (ranging from 25M to 1.3B params) to support extensive scenarios. Benefiting from their strong generalization capability, we fine-tune them with metric depth labels to obtain our metric depth models. In addition to our models, considering the limited diversity and frequent noise in current test sets, we construct a versatile evaluation benchmark with precise annotations and diverse scenes to facilitate future research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://depth-anything-v2.github.io"
    },
    {
        "paper id": "2406.09417",
        "abstract url": "https://arxiv.org/abs/2406.09417",
        "title": "Rethinking Score Distillation as a Bridge Between Image Distributions",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Score distillation sampling (SDS) has proven to be an important tool, enabling the use of large-scale diffusion priors for tasks operating in data-poor domains. Unfortunately, SDS has a number of characteristic artifacts that limit its usefulness in general-purpose applications. In this paper, we make progress toward understanding the behavior of SDS and its variants by viewing them as solving an optimal-cost transport path from a source distribution to a target distribution. Under this new interpretation, these methods seek to transport corrupted images (source) to the natural image distribution (target). We argue that current methods' characteristic artifacts are caused by (1) linear approximation of the optimal path and (2) poor estimates of the source distribution. We show that calibrating the text conditioning of the source distribution can produce high-quality generation and translation results with little extra overhead. Our method can be easily applied across many domains, matching or beating the performance of specialized methods. We demonstrate its utility in text-to-2D, text-based NeRF optimization, translating paintings to real images, optical illusion generation, and 3D sketch-to-real. We compare our method to existing approaches for score distillation sampling and show that it can produce high-frequency details with realistic colors.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "Project webpage: https://sds-bridge.github.io/"
    },
    {
        "paper id": "2406.09493",
        "abstract url": "https://arxiv.org/abs/2406.09493",
        "title": "Validation of human benchmark models for Automated Driving System approval: How competent and careful are they really?",
        "rating": "-1",
        "keywords": [
            [
                "Automated Driving"
            ]
        ],
        "abstract": "Advanced Driver Assistance Systems (ADAS) and Automated Driving Systems (ADS) are expected to improve comfort, productivity and, most importantly, safety for all road users. To ensure that the systems are safe, rules and regulations describing the systems' approval and validation procedures are in effect in Europe. The UNECE Regulation 157 (R157) is one of those. Annex 3 of R157 describes two driver models, representing the performance of a \"competent and careful\" driver, which can be used as benchmarks to determine whether, in certain situations, a crash would be preventable by a human driver. However, these models have not been validated against human behavior in real safety-critical events. Therefore, this study uses counterfactual simulation to assess the performance of the two models when applied to 38 safety-critical cut-in near-crashes from the SHRP2 naturalistic driving study. The results show that the two computational models performed rather differently from the human drivers: one model showed a generally delayed braking reaction compared to the human drivers, causing crashes in three of the original near-crashes. The other model demonstrated, in general, brake onsets substantially earlier than the human drivers, possibly being overly sensitive to lateral perturbations. That is, the first model does not seem to behave as the competent and careful driver it is supposed to represent, while the second seems to be overly careful. Overall, our results show that, if models are to be included in regulations, they need to be substantially improved. We argue that achieving this will require better validation across the scenario types that the models are intended to cover (e.g., cut-in conflicts), a process which should include applying the models counterfactually to near-crashes and validating them against several different safety related metrics.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09546",
        "abstract url": "https://arxiv.org/abs/2406.09546",
        "title": "Q-Mamba: On First Exploration of Vision Mamba for Image Quality Assessment",
        "rating": "-1",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this work, we take the first exploration of the recently popular foundation model, i.e., State Space Model/Mamba, in image quality assessment, aiming at observing and excavating the perception potential in vision Mamba. A series of works on Mamba has shown its significant potential in various fields, e.g., segmentation and classification. However, the perception capability of Mamba has been under-explored. Consequently, we propose Q-Mamba by revisiting and adapting the Mamba model for three crucial IQA tasks, i.e., task-specific, universal, and transferable IQA, which reveals that the Mamba model has obvious advantages compared with existing foundational models, e.g., Swin Transformer, ViT, and CNNs, in terms of perception and computational cost for IQA. To increase the transferability of Q-Mamba, we propose the StylePrompt tuning paradigm, where the basic lightweight mean and variance prompts are injected to assist the task-adaptive transfer learning of pre-trained Q-Mamba for different downstream IQA tasks. Compared with existing prompt tuning strategies, our proposed StylePrompt enables better perception transfer capability with less computational cost. Extensive experiments on multiple synthetic, authentic IQA datasets, and cross IQA datasets have demonstrated the effectiveness of our proposed Q-Mamba.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "17 pages,3 figures"
    },
    {
        "paper id": "2406.09549",
        "abstract url": "https://arxiv.org/abs/2406.09549",
        "title": "Exploring Syntactic Patterns in Urdu: A Deep Dive into Dependency Analysis",
        "rating": "-1",
        "keywords": [
            [
                "grammatical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Parsing is the process of breaking a sentence into its grammatical components and identifying the syntactic structure of the sentence. The syntactically correct sentence structure is achieved by assigning grammatical labels to its constituents using lexicon and syntactic rules. In linguistics, parser is extremely useful due to the number of different applications like name entity recognition, QA systems and information extraction, etc. The two most common techniques used for parsing are phrase structure and dependency Structure. Because Urdu is a low-resource language, there has been little progress in building an Urdu parser. A comparison of several parsers revealed that the dependency parsing approach is better suited for order-free languages such as Urdu. We have made significant progress in parsing Urdu, a South Asian language with a complex morphology. For Urdu dependency parsing, a basic feature model consisting of word location, word head, and dependency relation is employed as a starting point, followed by more complex feature models. The dependency tagset is designed after careful consideration of the complex morphological structure of the Urdu language, word order variation, and lexical ambiguity and it contains 22 tags. Our dataset comprises of sentences from news articles, and we tried to include sentences of different complexity (which is quite challenging), to get reliable results. All experiments are performed using MaltParser, exploring all 9 algorithms and classifiers. We have achieved a 70 percent overall best-labeled accuracy (LA), as well as an 84 percent overall best-unlabeled attachment score (UAS) using the Nivreeager algorithm. The comparison of output data with treebank test data that has been manually parsed is then used to carry out error assessment and to identify the errors produced by the parser.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09579",
        "abstract url": "https://arxiv.org/abs/2406.09579",
        "title": "Hovering Over the Key to Text Input in XR",
        "rating": "-1",
        "keywords": [
            [
                "synthesizing"
            ]
        ],
        "abstract": "Virtual, Mixed, and Augmented Reality (XR) technologies hold immense potential for transforming productivity beyond PC. Therefore there is a critical need for improved text input solutions for XR. However, achieving efficient text input in these environments remains a significant challenge. This paper examines the current landscape of XR text input techniques, focusing on the importance of keyboards (both physical and virtual) as essential tools. We discuss the unique challenges and opportunities presented by XR, synthesizing key trends from existing solutions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09603",
        "abstract url": "https://arxiv.org/abs/2406.09603",
        "title": "Workload Assessment of Human-Machine Interface: A Simulator Study with Psychophysiological Measures",
        "rating": "-1",
        "keywords": [
            [
                "automated driving",
                "vehicle"
            ]
        ],
        "abstract": "Human-machine Interface (HMI) is critical for safety during automated driving, as it serves as the only media between the automated system and human users. To enable a transparent HMI, we first need to know how to evaluate it. However, most of the assessment methods used for HMI designs are subjective and thus not efficient. To bridge the gap, an objective and standardized HMI assessment method is needed, and the first step is to find an objective method for workload measurement for this context. In this study, two psychophysiological measures, electrocardiography (ECG) and electrodermal activity (EDA), were evaluated for their effectiveness in finding differences in mental workload among different HMI designs in a simulator study. Three HMI designs were developed and used. Results showed that both workload measures were able to identify significant differences in objective mental workload when interacting with in-vehicle HMIs. As a first step toward a standardized assessment method, the results could be used as a firm ground for future studies. Marie Sk\u0142odowska-Curie Actions; Innovative Training Network (ITN); SHAPE-IT; Grant number 860410; Publication date: [29 Sep 2023]; DOI: [10.54941/ahfe1004172]",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09609",
        "abstract url": "https://arxiv.org/abs/2406.09609",
        "title": "Hierarchical Control for Vehicle Repositioning in Autonomous Mobility on Demand Systems",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "Balancing passenger demand and vehicle availability is crucial for ensuring the sustainability and effectiveness of urban transportation systems. To address this challenge, we propose a novel hierarchical strategy for the efficient distribution of empty vehicles in urban areas. The proposed approach employs a data-enabled predictive control algorithm to develop a high-level controller, which guides the inter-regional allocation of idle vehicles. This algorithm utilizes historical data on passenger demand and vehicle supply in each region to construct a non-parametric representation of the system, enabling it to determine the optimal number of vehicles to be repositioned or retained in their current regions without modeling the system. At the low level, a coverage control-based controller is designed to provide inter-regional position guidance, determining the desired road intersection each vehicle should target. With the objective of optimizing area coverage, it aligns the vehicle distribution with the demand across different districts within a single region. The effectiveness of the proposed method is validated through simulation experiments on the real road network of Shenzhen, China. The integration of the two layers provides better performance compared to applying either layer in isolation, demonstrating its potential to reduce passenger waiting time and answer more requests, thus promoting the development of more efficient and sustainable transportation systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09623",
        "abstract url": "https://arxiv.org/abs/2406.09623",
        "title": "Search-based versus Sampling-based Robot Motion Planning: A Comparative Study",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Robot motion planning is a challenging domain as it involves dealing with high-dimensional and continuous search space. In past decades, a wide variety of planning algorithms have been developed to tackle this problem, sometimes in isolation without comparing to each other. In this study, we benchmark two such prominent types of algorithms: OMPL's sampling-based RRT-Connect and SMPL's search-based ARA* with motion primitives. To compare these two fundamentally different approaches fairly, we adapt them to ensure the same planning conditions and benchmark them on the same set of planning scenarios. Our findings suggest that sampling-based planners like RRT-Connect show more consistent performance across the board in high-dimensional spaces, whereas search-based planners like ARA* have the capacity to perform significantly better when used with a suitable action-space sampling scheme. Through this study, we hope to showcase the effort required to properly benchmark motion planners from different paradigms thereby contributing to a more nuanced understanding of their capabilities and limitations. The code is available at https://github.com/gsotirchos/benchmarking_planners",
        "subjects": [
            "cs.RO"
        ],
        "comment": "presented at ICAPS 2024 workshop PlanRob"
    },
    {
        "paper id": "2406.09637",
        "abstract url": "https://arxiv.org/abs/2406.09637",
        "title": "Industrial Language-Image Dataset (ILID): Adapting Vision Foundation Models for Industrial Settings",
        "rating": "-1",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the upstream of Large Language Models (LLM) has also encouraged the computer vision community to work on substantial multimodal datasets and train models on a scale in a self-/semi-supervised manner, resulting in Vision Foundation Models (VFM), as, e.g., Contrastive Language-Image Pre-training (CLIP). The models generalize well and perform outstandingly on everyday objects or scenes, even on downstream tasks, tasks the model has not been trained on, while the application in specialized domains, as in an industrial context, is still an open research question. Here, fine-tuning the models or transfer learning on domain-specific data is unavoidable when objecting to adequate performance. In this work, we, on the one hand, introduce a pipeline to generate the Industrial Language-Image Dataset (ILID) based on web-crawled data; on the other hand, we demonstrate effective self-supervised transfer learning and discussing downstream tasks after training on the cheaply acquired ILID, which does not necessitate human labeling or intervention. With the proposed approach, we contribute by transferring approaches from state-of-the-art research around foundation models, transfer learning strategies, and applications to the industrial domain.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Dataset at https://github.com/kenomo/ilid training- and evaluation-related code at https://github.com/kenomo/industrial-clip"
    },
    {
        "paper id": "2406.09640",
        "abstract url": "https://arxiv.org/abs/2406.09640",
        "title": "GPT-Fabric: Folding and Smoothing Fabric by Leveraging Pre-Trained Foundation Models",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Fabric manipulation has applications in folding blankets, handling patient clothing, and protecting items with covers. It is challenging for robots to perform fabric manipulation since fabrics have infinite-dimensional configuration spaces, complex dynamics, and may be in folded or crumpled configurations with severe self-occlusions. Prior work on robotic fabric manipulation relies either on heavily engineered setups or learning-based approaches that create and train on robot-fabric interaction data. In this paper, we propose GPT-Fabric for the canonical tasks of fabric folding and smoothing, where GPT directly outputs an action informing a robot where to grasp and pull a fabric. We perform extensive experiments in simulation to test GPT-Fabric against prior state of the art methods for folding and smoothing. We obtain comparable or better performance to most methods even without explicitly training on a fabric-specific dataset (i.e., zero-shot manipulation). Furthermore, we apply GPT-Fabric in physical experiments over 12 folding and 10 smoothing rollouts. Our results suggest that GPT-Fabric is a promising approach for high-precision fabric manipulation tasks.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Code, prompts, and videos are available at https://tinyurl.com/gptfab"
    },
    {
        "paper id": "2406.09647",
        "abstract url": "https://arxiv.org/abs/2406.09647",
        "title": "OpenAnimalTracks: A Dataset for Animal Track Recognition",
        "rating": "-1",
        "keywords": [
            [
                "biodiversity"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Animal habitat surveys play a critical role in preserving the biodiversity of the land. One of the effective ways to gain insights into animal habitats involves identifying animal footprints, which offers valuable information about species distribution, abundance, and behavior. However, due to the scarcity of animal footprint images, there are no well-maintained public datasets, preventing recent advanced techniques in computer vision from being applied to animal tracking. In this paper, we introduce OpenAnimalTracks dataset, the first publicly available labeled dataset designed to facilitate the automated classification and detection of animal footprints. It contains various footprints from 18 wild animal species. Moreover, we build benchmarks for species classification and detection and show the potential of automated footprint identification with representative classifiers and detection models. We find SwinTransformer achieves a promising classification result, reaching 69.41% in terms of the averaged accuracy. Faster-RCNN achieves mAP of 0.295. We hope our dataset paves the way for automated animal tracking techniques, enhancing our ability to protect and manage biodiversity. Our dataset and code are available at https://github.com/dahlian00/OpenAnimalTracks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICIP 2024. Dataset and code: https://github.com/dahlian00/OpenAnimalTracks"
    },
    {
        "paper id": "2406.09656",
        "abstract url": "https://arxiv.org/abs/2406.09656",
        "title": "RSEND: Retinex-based Squeeze and Excitation Network with Dark Region Detection for Efficient Low Light Image Enhancement",
        "rating": "-1",
        "keywords": [
            [
                "Image Enhancement"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Images captured under low-light scenarios often suffer from low quality. Previous CNN-based deep learning methods often involve using Retinex theory. Nevertheless, most of them cannot perform well in more complicated datasets like LOL-v2 while consuming too much computational resources. Besides, some of these methods require sophisticated training at different stages, making the procedure even more time-consuming and tedious. In this paper, we propose a more accurate, concise, and one-stage Retinex theory based framework, RSEND. RSEND first divides the low-light image into the illumination map and reflectance map, then captures the important details in the illumination map and performs light enhancement. After this step, it refines the enhanced gray-scale image and does element-wise matrix multiplication with the reflectance map. By denoising the output it has from the previous step, it obtains the final result. In all the steps, RSEND utilizes Squeeze and Excitation network to better capture the details. Comprehensive quantitative and qualitative experiments show that our Efficient Retinex model significantly outperforms other CNN-based models, achieving a PSNR improvement ranging from 0.44 dB to 4.2 dB in different datasets and even outperforms transformer-based models in the LOL-v2-real dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09677",
        "abstract url": "https://arxiv.org/abs/2406.09677",
        "title": "SAGA: Synthesis Augmentation with Genetic Algorithms for In-Memory Sequence Optimization",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "The von-Neumann architecture has a bottleneck which limits the speed at which data can be made available for computation. To combat this problem, novel paradigms for computing are being developed. One such paradigm, known as in-memory computing, interleaves computation with the storage of data within the same circuits. MAGIC, or Memristor Aided Logic, is an approach which uses memory circuits which physically perform computation through write operations to memory. Sequencing these operations is a computationally difficult problem which is directly correlated with the cost of solutions using MAGIC based in-memory computation. SAGA models the execution sequences as a topological sorting problem which makes the optimization well-suited for genetic algorithms. We then detail the formation and implementation of these genetic algorithms and evaluate them over a number of open circuit implementations. The memory-footprint needed for evaluating each of these circuits is decreased by up to 52% from existing, greedy-algorithm-based optimization solutions. Over the 10 benchmark circuits evaluated, these modifications lead to an overall improvement in the efficiency of in-memory circuit evaluation of 128% in the best case and 27.5% on average.",
        "subjects": [
            "cs.NE",
            "cs.AR"
        ],
        "comment": "6 pages, 2 Figures, 3 Tables"
    },
    {
        "paper id": "2406.09682",
        "abstract url": "https://arxiv.org/abs/2406.09682",
        "title": "Privacy-preserving Quantification of Non-IID Degree in Federated Learning",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Federated learning (FL) offers a privacy-preserving approach to machine learning for multiple collaborators without sharing raw data. However, the existence of non-independent and non-identically distributed (non-IID) datasets across different clients presents a significant challenge to FL, leading to a sharp drop in accuracy, reduced efficiency, and hindered implementation. To address the non-IID problem, various methods have been proposed, including clustering and personalized FL frameworks. Nevertheless, to date, a formal quantitative definition of the non-IID degree between different clients' datasets is still missing, hindering the clients from comparing and obtaining an overview of their data distributions with other clients. For the first time, this paper proposes a quantitative definition of the non-IID degree in the federated environment by employing the cumulative distribution function (CDF), called Fully Homomorphic Encryption-based Federated Cumulative Distribution Function (FHE-FCDF). This method utilizes cryptographic primitive fully homomorphic encryption to enable clients to estimate the non-IID degree while ensuring privacy preservation. The experiments conducted on the CIFAR-100 non-IID dataset validate the effectiveness of our proposed method.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 8 figures, FL@FM-IJCAI'24"
    },
    {
        "paper id": "2406.09693",
        "abstract url": "https://arxiv.org/abs/2406.09693",
        "title": "Compressed Video Quality Enhancement with Temporal Group Alignment and Fusion",
        "rating": "-1",
        "keywords": [
            [
                "Video Quality Enhancement"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this paper, we propose a temporal group alignment and fusion network to enhance the quality of compressed videos by using the long-short term correlations between frames. The proposed model consists of the intra-group feature alignment (IntraGFA) module, the inter-group feature fusion (InterGFF) module, and the feature enhancement (FE) module. We form the group of pictures (GoP) by selecting frames from the video according to their temporal distances to the target enhanced frame. With this grouping, the composed GoP can contain either long- or short-term correlated information of neighboring frames. We design the IntraGFA module to align the features of frames of each GoP to eliminate the motion existing between frames. We construct the InterGFF module to fuse features belonging to different GoPs and finally enhance the fused features with the FE module to generate high-quality video frames. The experimental results show that our proposed method achieves up to 0.05dB gain and lower complexity compared to the state-of-the-art method.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09696",
        "abstract url": "https://arxiv.org/abs/2406.09696",
        "title": "MoME: Mixture of Multimodal Experts for Cancer Survival Prediction",
        "rating": "-1",
        "keywords": [
            [
                "biomarkers",
                "Survival",
                "Whole Slide",
                "Cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Survival analysis, as a challenging task, requires integrating Whole Slide Images (WSIs) and genomic data for comprehensive decision-making. There are two main challenges in this task: significant heterogeneity and complex inter- and intra-modal interactions between the two modalities. Previous approaches utilize co-attention methods, which fuse features from both modalities only once after separate encoding. However, these approaches are insufficient for modeling the complex task due to the heterogeneous nature between the modalities. To address these issues, we propose a Biased Progressive Encoding (BPE) paradigm, performing encoding and fusion simultaneously. This paradigm uses one modality as a reference when encoding the other. It enables deep fusion of the modalities through multiple alternating iterations, progressively reducing the cross-modal disparities and facilitating complementary interactions. Besides modality heterogeneity, survival analysis involves various biomarkers from WSIs, genomics, and their combinations. The critical biomarkers may exist in different modalities under individual variations, necessitating flexible adaptation of the models to specific scenarios. Therefore, we further propose a Mixture of Multimodal Experts (MoME) layer to dynamically selects tailored experts in each stage of the BPE paradigm. Experts incorporate reference information from another modality to varying degrees, enabling a balanced or biased focus on different modalities during the encoding process. Extensive experimental results demonstrate the superior performance of our method on various datasets, including TCGA-BLCA, TCGA-UCEC and TCGA-LUAD. Codes are available at https://github.com/BearCleverProud/MoME.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "8 + 1/2 pages, early accepted to MICCAI2024"
    },
    {
        "paper id": "2406.09704",
        "abstract url": "https://arxiv.org/abs/2406.09704",
        "title": "Data-Driven Strategy Synthesis for Stochastic Systems with Unknown Nonlinear Disturbances",
        "rating": "-1",
        "keywords": [
            [
                "Synthesis"
            ]
        ],
        "abstract": "In this paper, we introduce a data-driven framework for synthesis of provably-correct controllers for general nonlinear switched systems under complex specifications. The focus is on systems with unknown disturbances whose effects on the dynamics of the system is nonlinear. The specifications are assumed to be given as linear temporal logic over finite traces (LTLf) formulas. Starting from observations of either the disturbance or the state of the system, we first learn an ambiguity set that contains the unknown distribution of the disturbances with a user-defined confidence. Next, we construct a robust Markov decision process (RMDP) as a finite abstraction of the system. By composing the RMDP with the automaton obtained from the LTLf formula and performing optimal robust value iteration on the composed RMDP, we synthesize a strategy that yields a high probability that the uncertain system satisfies the specifications. Our empirical evaluations on systems with a wide variety of disturbances show that the strategies synthesized with our approach lead to high satisfaction probabilities and validate the theoretical guarantees.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08851",
        "abstract url": "https://arxiv.org/abs/2406.08851",
        "title": "Inverse Probability of Treatment Weighting with Deep Sequence Models Enables Accurate treatment effect Estimation from Electronic Health Records",
        "rating": "-1.5",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Observational data have been actively used to estimate treatment effect, driven by the growing availability of electronic health records (EHRs). However, EHRs typically consist of longitudinal records, often introducing time-dependent confoundings that hinder the unbiased estimation of treatment effect. Inverse probability of treatment weighting (IPTW) is a widely used propensity score method since it provides unbiased treatment effect estimation and its derivation is straightforward. In this study, we aim to utilize IPTW to estimate treatment effect in the presence of time-dependent confounding using claims records. Previous studies have utilized propensity score methods with features derived from claims records through feature processing, which generally requires domain knowledge and additional resources to extract information to accurately estimate propensity scores. Deep sequence models, particularly recurrent neural networks and self-attention-based architectures, have demonstrated good performance in modeling EHRs for various downstream tasks. We propose that these deep sequence models can provide accurate IPTW estimation of treatment effect by directly estimating the propensity scores from claims records without the need for feature processing. We empirically demonstrate this by conducting comprehensive evaluations using synthetic and semi-synthetic datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08876",
        "abstract url": "https://arxiv.org/abs/2406.08876",
        "title": "Heuristics for Influence Maximization with Tiered Influence and Activation thresholds",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "The information flows among the people while they communicate through social media websites. Due to the dependency on digital media, a person shares important information or regular updates with friends and family. The set of persons on social media forms a social network. Influence Maximization (IM) is a known problem in social networks. In social networks, information flows from one person to another using an underlying diffusion model. There are two fundamental diffusion models: the Independent Cascade Model (ICM) and the Linear Threshold Model (LTM). In this paper, we study a variant of the IM problem called Minimum Influential Seeds (MINFS) problem proposed by Qiang et al.[16]. It generalizes the classical IM problem with LTM as the diffusion model. Compared to IM, this variant has additional parameters: the influence threshold for each node and the propagation range. The propagation range is a positive integer that specifies how far the information can propagate from a node. A node on the network is not immediately influenced until it receives the same information from enough number of neighbors (influence threshold). Similarly, any node does not forward information until it receives the same information from a sufficient number of neighbors (activation threshold). Once a node becomes activated, it tries to activate or influence its neighbors. The MINFS problem aims to select the minimum number of initial spreader nodes such that all nodes of the graph are influenced. In this paper, we extend the study of the MINFS problem. We propose heuristics that construct seed sets based on the average degree of non-activated nodes, closest first, and backbone-based heaviest path.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08899",
        "abstract url": "https://arxiv.org/abs/2406.08899",
        "title": "ESND: An Embedding-based Framework for Signed Network Dismantling",
        "rating": "-1.5",
        "keywords": [
            [
                "crime"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Network dismantling aims to maximize the disintegration of a network by removing a specific set of nodes or edges and is applied to various tasks in diverse domains, such as cracking down on crime organizations, delaying the propagation of rumors, and blocking the transmission of viruses. Most of the current network dismantling methods are tailored for unsigned networks, which only consider the connection between nodes without evaluating the nature of the relationships, such as friendship/hostility, enhancing/repressing, and trust/distrust. We here propose an embedding-based algorithm, namely ESND, to solve the signed network dismantling problem. The algorithm generally iterates the following four steps, i.e., giant component detection, network embedding, node clustering, and removal node selection. To illustrate the efficacy and stability of ESND, we conduct extensive experiments on six signed network datasets as well as null models, and compare the performance of our method with baselines. Experimental results consistently show that the proposed ESND is superior to the baselines and displays stable performance with the change in the network structure. Additionally, we examine the impact of sign proportions on network robustness via ESND, observing that networks with a high ratio of negative edges are generally easier to dismantle than networks with high positive edges.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08930",
        "abstract url": "https://arxiv.org/abs/2406.08930",
        "title": "Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The progression of deep learning and the widespread adoption of sensors have facilitated automatic multi-view fusion (MVF) about the cardiovascular system (CVS) signals. However, prevalent MVF model architecture often amalgamates CVS signals from the same temporal step but different views into a unified representation, disregarding the asynchronous nature of cardiovascular events and the inherent heterogeneity across views, leading to catastrophic view confusion. Efficient training strategies specifically tailored for MVF models to attain comprehensive representations need simultaneous consideration. Crucially, real-world data frequently arrives with incomplete views, an aspect rarely noticed by researchers. Thus, the View-Centric Transformer (VCT) and Multitask Masked Autoencoder (M2AE) are specifically designed to emphasize the centrality of each view and harness unlabeled data to achieve superior fused representations. Additionally, we systematically define the missing-view problem for the first time and introduce prompt techniques to aid pretrained MVF models in flexibly adapting to various missing-view scenarios. Rigorous experiments involving atrial fibrillation detection, blood pressure estimation, and sleep staging-typical health monitoring tasks-demonstrate the remarkable advantage of our method in MVF compared to prevailing methodologies. Notably, the prompt technique requires finetuning less than 3% of the entire model's data, substantially fortifying the model's resilience to view missing while circumventing the need for complete retraining. The results demonstrate the effectiveness of our approaches, highlighting their potential for practical applications in cardiovascular health monitoring. Codes and models are released at URL.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "16 pages,12 figures"
    },
    {
        "paper id": "2406.08938",
        "abstract url": "https://arxiv.org/abs/2406.08938",
        "title": "Mirror and Preconditioned Gradient Descent in Wasserstein Space",
        "rating": "-1.5",
        "keywords": [
            [
                "biology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As the problem of minimizing functionals on the Wasserstein space encompasses many applications in machine learning, different optimization algorithms on $\\mathbb{R}^d$ have received their counterpart analog on the Wasserstein space. We focus here on lifting two explicit algorithms: mirror descent and preconditioned gradient descent. These algorithms have been introduced to better capture the geometry of the function to minimize and are provably convergent under appropriate (namely relative) smoothness and convexity conditions. Adapting these notions to the Wasserstein space, we prove guarantees of convergence of some Wasserstein-gradient-based discrete-time schemes for new pairings of objective functionals and regularizers. The difficulty here is to carefully select along which curves the functionals should be smooth and convex. We illustrate the advantages of adapting the geometry induced by the regularizer on ill-conditioned optimization tasks, and showcase the improvement of choosing different discrepancies and geometries in a computational biology task of aligning single-cells.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08958",
        "abstract url": "https://arxiv.org/abs/2406.08958",
        "title": "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "Healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Electronic healthcare records are vital for patient safety as they document conditions, plans, and procedures in both free text and medical codes. Language models have significantly enhanced the processing of such records, streamlining workflows and reducing manual data entry, thereby saving healthcare providers significant resources. However, the black-box nature of these models often leaves healthcare professionals hesitant to trust them. State-of-the-art explainability methods increase model transparency but rely on human-annotated evidence spans, which are costly. In this study, we propose an approach to produce plausible and faithful explanations without needing such annotations. We demonstrate on the automated medical coding task that adversarial robustness training improves explanation plausibility and introduce AttInGrad, a new explanation method superior to previous ones. By combining both contributions in a fully unsupervised setup, we produce explanations of comparable quality, or better, to that of a supervised approach. We release our code and model weights.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08959",
        "abstract url": "https://arxiv.org/abs/2406.08959",
        "title": "Beyond Recommendations: From Backward to Forward AI Support of Pilots' Decision-Making Process",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "AI is anticipated to enhance human decision-making in high-stakes domains like aviation, but adoption is often hindered by challenges such as inappropriate reliance and poor alignment with users' decision-making. Recent research suggests that a core underlying issue is the recommendation-centric design of many AI systems, i.e., they give end-to-end recommendations and ignore the rest of the decision-making process. Alternative support paradigms are rare, and it remains unclear how the few that do exist compare to recommendation-centric support. In this work, we aimed to empirically compare recommendation-centric support to an alternative paradigm, continuous support, in the context of diversions in aviation. We conducted a mixed-methods study with 32 professional pilots in a realistic setting. To ensure the quality of our study scenarios, we conducted a focus group with four additional pilots prior to the study. We found that continuous support can support pilots' decision-making in a forward direction, allowing them to think more beyond the limits of the system and make faster decisions when combined with recommendations, though the forward support can be disrupted. Participants' statements further suggest a shift in design goal away from providing recommendations, to supporting quick information gathering. Our results show ways to design more helpful and effective AI decision support that goes beyond end-to-end recommendations.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Accepted to CSCW 2024, to be published in PACM HCI Vol. 8, No. CSCW2"
    },
    {
        "paper id": "2406.08961",
        "abstract url": "https://arxiv.org/abs/2406.08961",
        "title": "SIU: A Million-Scale Structural Small Molecule-Protein Interaction Dataset for Unbiased Bioactivity Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "Bioactivity"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Small molecules play a pivotal role in modern medicine, and scrutinizing their interactions with protein targets is essential for the discovery and development of novel, life-saving therapeutics. The term \"bioactivity\" encompasses various biological effects resulting from these interactions, including both binding and functional responses. The magnitude of bioactivity dictates the therapeutic or toxic pharmacological outcomes of small molecules, rendering accurate bioactivity prediction crucial for the development of safe and effective drugs. However, existing structural datasets of small molecule-protein interactions are often limited in scale and lack systematically organized bioactivity labels, thereby impeding our understanding of these interactions and precise bioactivity prediction. In this study, we introduce a comprehensive dataset of small molecule-protein interactions, consisting of over a million binding structures, each annotated with real biological activity labels. This dataset is designed to facilitate unbiased bioactivity prediction. We evaluated several classical models on this dataset, and the results demonstrate that the task of unbiased bioactivity prediction is challenging yet essential.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08993",
        "abstract url": "https://arxiv.org/abs/2406.08993",
        "title": "Classic GNNs are Strong Baselines: Reassessing GNNs for Node Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Transformers (GTs) have recently emerged as popular alternatives to traditional message-passing Graph Neural Networks (GNNs), due to their theoretically superior expressiveness and impressive performance reported on standard node classification benchmarks, often significantly outperforming GNNs. In this paper, we conduct a thorough empirical analysis to reevaluate the performance of three classic GNN models (GCN, GAT, and GraphSAGE) against GTs. Our findings suggest that the previously reported superiority of GTs may have been overstated due to suboptimal hyperparameter configurations in GNNs. Remarkably, with slight hyperparameter tuning, these classic GNN models achieve state-of-the-art performance, matching or even exceeding that of recent GTs across 17 out of the 18 diverse datasets examined. Additionally, we conduct detailed ablation studies to investigate the influence of various GNN configurations, such as normalization, dropout, residual connections, network depth, and jumping knowledge mode, on node classification performance. Our study aims to promote a higher standard of empirical rigor in the field of graph machine learning, encouraging more accurate comparisons and evaluations of model capabilities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09009",
        "abstract url": "https://arxiv.org/abs/2406.09009",
        "title": "Fredformer: Frequency Debiased Transformer for Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The Transformer model has shown leading performance in time series forecasting. Nevertheless, in some complex scenarios, it tends to learn low-frequency features in the data and overlook high-frequency features, showing a frequency bias. This bias prevents the model from accurately capturing important high-frequency data features. In this paper, we undertook empirical analyses to understand this bias and discovered that frequency bias results from the model disproportionately focusing on frequency features with higher energy. Based on our analysis, we formulate this bias and propose Fredformer, a Transformer-based framework designed to mitigate frequency bias by learning features equally across different frequency bands. This approach prevents the model from overlooking lower amplitude features important for accurate forecasting. Extensive experiments show the effectiveness of our proposed approach, which can outperform other baselines in different real-world time-series datasets. Furthermore, we introduce a lightweight variant of the Fredformer with an attention matrix approximation, which achieves comparable performance but with much fewer parameters and lower computation costs. The code is available at: https://github.com/chenzRG/Fredformer",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "This paper has been accepted by SIGKDD2024"
    },
    {
        "paper id": "2406.09014",
        "abstract url": "https://arxiv.org/abs/2406.09014",
        "title": "Deep learning empowered sensor fusion to improve infant movement classification",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosing",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "There is a recent boom in the development of AI solutions to facilitate and enhance diagnostic procedures for established clinical tools. To assess the integrity of the developing nervous system, the Prechtl general movement assessment (GMA) is recognized for its clinical value in diagnosing neurological impairments in early infancy. GMA has been increasingly augmented through machine learning approaches intending to scale-up its application, circumvent costs in the training of human assessors and further standardize classification of spontaneous motor patterns. Available deep learning tools, all of which are based on single sensor modalities, are however still considerably inferior to that of well-trained human assessors. These approaches are hardly comparable as all models are designed, trained and evaluated on proprietary/silo-data sets. With this study we propose a sensor fusion approach for assessing fidgety movements (FMs) comparing three different sensor modalities (pressure, inertial, and visual sensors). Various combinations and two sensor fusion approaches (late and early fusion) for infant movement classification were tested to evaluate whether a multi-sensor system outperforms single modality assessments. The performance of the three-sensor fusion (classification accuracy of 94.5\\%) was significantly higher than that of any single modality evaluated, suggesting the sensor fusion approach is a promising avenue for automated classification of infant motor patterns. The development of a robust sensor fusion system may significantly enhance AI-based early recognition of neurofunctions, ultimately facilitating automated early detection of neurodevelopmental conditions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09028",
        "abstract url": "https://arxiv.org/abs/2406.09028",
        "title": "From Biased to Unbiased Dynamics: An Infinitesimal Generator Approach",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate learning the eigenfunctions of evolution operators for time-reversal invariant stochastic processes, a prime example being the Langevin equation used in molecular dynamics. Many physical or chemical processes described by this equation involve transitions between metastable states separated by high potential barriers that can hardly be crossed during a simulation. To overcome this bottleneck, data are collected via biased simulations that explore the state space more rapidly. We propose a framework for learning from biased simulations rooted in the infinitesimal generator of the process and the associated resolvent operator. We contrast our approach to more common ones based on the transfer operator, showing that it can provably learn the spectral properties of the unbiased system from biased data. In experiments, we highlight the advantages of our method over transfer operator approaches and recent developments based on generator learning, demonstrating its effectiveness in estimating eigenfunctions and eigenvalues. Importantly, we show that even with datasets containing only a few relevant transitions due to sub-optimal biasing, our approach recovers relevant information about the transition mechanism.",
        "subjects": [
            "cs.LG",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09029",
        "abstract url": "https://arxiv.org/abs/2406.09029",
        "title": "Fair by design: A sociotechnical approach to justifying the fairness of AI-enabled systems across the lifecycle",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "healthcare",
                "clinical"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Fairness is one of the most commonly identified ethical principles in existing AI guidelines, and the development of fair AI-enabled systems is required by new and emerging AI regulation. But most approaches to addressing the fairness of AI-enabled systems are limited in scope in two significant ways: their substantive content focuses on statistical measures of fairness, and they do not emphasize the need to identify and address fairness considerations across the whole AI lifecycle. Our contribution is to present an assurance framework and tool that can enable a practical and transparent method for widening the scope of fairness considerations across the AI lifecycle and move the discussion beyond mere statistical notions of fairness to consider a richer analysis in a practical and context-dependent manner. To illustrate this approach, we first describe and then apply the framework of Trustworthy and Ethical Assurance (TEA) to an AI-enabled clinical diagnostic support system (CDSS) whose purpose is to help clinicians predict the risk of developing hypertension in patients with Type 2 diabetes, a context in which several fairness considerations arise (e.g., discrimination against patient subgroups). This is supplemented by an open-source tool and a fairness considerations map to help facilitate reasoning about the fairness of AI-enabled systems in a participatory way. In short, by using a shared framework for identifying, documenting and justifying fairness considerations, and then using this deliberative exercise to structure an assurance case, research on AI fairness becomes reusable and generalizable for others in the ethical AI community and for sharing best practices for achieving fairness and equity in digital health and healthcare in particular.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "18 pages, 2 figures"
    },
    {
        "paper id": "2406.09031",
        "abstract url": "https://arxiv.org/abs/2406.09031",
        "title": "A Comprehensive Graph Pooling Benchmark: Effectiveness, Robustness and Generalizability",
        "rating": "-1.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph pooling has gained attention for its ability to obtain effective node and graph representations for various downstream tasks. Despite the recent surge in graph pooling approaches, there is a lack of standardized experimental settings and fair benchmarks to evaluate their performance. To address this issue, we have constructed a comprehensive benchmark that includes 15 graph pooling methods and 21 different graph datasets. This benchmark systematically assesses the performance of graph pooling methods in three dimensions, i.e., effectiveness, robustness, and generalizability. We first evaluate the performance of these graph pooling approaches across different tasks including graph classification, graph regression and node classification. Then, we investigate their performance under potential noise attacks and out-of-distribution shifts in real-world scenarios. We also involve detailed efficiency analysis and parameter analysis. Extensive experiments validate the strong capability and applicability of graph pooling approaches in various scenarios, which can provide valuable insights and guidance for deep geometric learning research. The source code of our benchmark is available at https://github.com/goose315/Graph_Pooling_Benchmark.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09130",
        "abstract url": "https://arxiv.org/abs/2406.09130",
        "title": "Time-Series Forecasting for Out-of-Distribution Generalization Using Invariant Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Time-series forecasting (TSF) finds broad applications in real-world scenarios. Due to the dynamic nature of time-series data, it is crucial to equip TSF models with out-of-distribution (OOD) generalization abilities, as historical training data and future test data can have different distributions. In this paper, we aim to alleviate the inherent OOD problem in TSF via invariant learning. We identify fundamental challenges of invariant learning for TSF. First, the target variables in TSF may not be sufficiently determined by the input due to unobserved core variables in TSF, breaking the conventional assumption of invariant learning. Second, time-series datasets lack adequate environment labels, while existing environmental inference methods are not suitable for TSF. To address these challenges, we propose FOIL, a model-agnostic framework that enables timeseries Forecasting for Out-of-distribution generalization via Invariant Learning. FOIL employs a novel surrogate loss to mitigate the impact of unobserved variables. Further, FOIL implements a joint optimization by alternately inferring environments effectively with a multi-head network while preserving the temporal adjacency structure, and learning invariant representations across inferred environments for OOD generalized TSF. We demonstrate that the proposed FOIL significantly improves the performance of various TSF models, achieving gains of up to 85%.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2406.09132",
        "abstract url": "https://arxiv.org/abs/2406.09132",
        "title": "Jacobian-Enhanced Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Jacobian-Enhanced Neural Networks (JENN) are densely connected multi-layer perceptrons, whose training process is modified to predict partial derivatives accurately. Their main benefit is better accuracy with fewer training points compared to standard neural networks. These attributes are particularly desirable in the field of computer-aided design, where there is often the need to replace computationally expensive, physics-based models with fast running approximations, known as surrogate models or meta-models. Since a surrogate emulates the original model accurately in near-real time, it yields a speed benefit that can be used to carry out orders of magnitude more function calls quickly. However, in the special case of gradient-enhanced methods, there is the additional value proposition that partial derivatives are accurate, which is a critical property for one important use-case: surrogate-based optimization. This work derives the complete theory and exemplifies its superiority over standard neural nets for surrogate-based optimization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 5 figures"
    },
    {
        "paper id": "2406.09142",
        "abstract url": "https://arxiv.org/abs/2406.09142",
        "title": "Effects of Antivaccine Tweets on COVID-19 Vaccinations, Cases, and Deaths",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Vaccines were critical in reducing hospitalizations and mortality during the COVID-19 pandemic. Despite their wide availability in the United States, 62% of Americans chose not to be vaccinated during 2021. While online misinformation about COVID-19 is correlated to vaccine hesitancy, little prior work has explored a causal link between real-world exposure to antivaccine content and vaccine uptake. Here we present a compartmental epidemic model that includes vaccination, vaccine hesitancy, and exposure to antivaccine content. We fit the model to observational data to determine that a geographical pattern of exposure to online antivaccine content across US counties is responsible for a pattern of reduced vaccine uptake in the same counties. We find that exposure to antivaccine content on Twitter caused about 750,000 people to refuse vaccination between February and August 2021 in the US, resulting in at least 29,000 additional cases and 430 additional deaths. This work provides a methodology for linking online speech to offline epidemic outcomes. Our findings should inform social media moderation policy as well as public health interventions.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09152",
        "abstract url": "https://arxiv.org/abs/2406.09152",
        "title": "EncCluster: Scalable Functional Encryption in Federated Learning through Weight Clustering and Probabilistic Filters",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) enables model training across decentralized devices by communicating solely local model updates to an aggregation server. Although such limited data sharing makes FL more secure than centralized approached, FL remains vulnerable to inference attacks during model update transmissions. Existing secure aggregation approaches rely on differential privacy or cryptographic schemes like Functional Encryption (FE) to safeguard individual client data. However, such strategies can reduce performance or introduce unacceptable computational and communication overheads on clients running on edge devices with limited resources. In this work, we present EncCluster, a novel method that integrates model compression through weight clustering with recent decentralized FE and privacy-enhancing data encoding using probabilistic filters to deliver strong privacy guarantees in FL without affecting model performance or adding unnecessary burdens to clients. We performed a comprehensive evaluation, spanning various datasets and architectures, to demonstrate EncCluster's scalability across encryption levels. Our findings reveal that EncCluster significantly reduces communication costs - below even conventional FedAvg - and accelerates encryption by more than four times over all baselines; at the same time, it maintains high model accuracy and enhanced privacy assurances.",
        "subjects": [
            "cs.CR",
            "cs.DC",
            "cs.LG"
        ],
        "comment": "21 pages, 4 figures"
    },
    {
        "paper id": "2406.09173",
        "abstract url": "https://arxiv.org/abs/2406.09173",
        "title": "Potion: Towards Poison Unlearning",
        "rating": "-1.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Adversarial attacks by malicious actors on machine learning systems, such as introducing poison triggers into training datasets, pose significant risks. The challenge in resolving such an attack arises in practice when only a subset of the poisoned data can be identified. This necessitates the development of methods to remove, i.e. unlearn, poison triggers from already trained models with only a subset of the poison data available. The requirements for this task significantly deviate from privacy-focused unlearning where all of the data to be forgotten by the model is known. Previous work has shown that the undiscovered poisoned samples lead to a failure of established unlearning methods, with only one method, Selective Synaptic Dampening (SSD), showing limited success. Even full retraining, after the removal of the identified poison, cannot address this challenge as the undiscovered poison samples lead to a reintroduction of the poison trigger in the model. Our work addresses two key challenges to advance the state of the art in poison unlearning. First, we introduce a novel outlier-resistant method, based on SSD, that significantly improves model protection and unlearning performance. Second, we introduce Poison Trigger Neutralisation (PTN) search, a fast, parallelisable, hyperparameter search that utilises the characteristic \"unlearning versus model protection\" trade-off to find suitable hyperparameters in settings where the forget set size is unknown and the retain set is contaminated. We benchmark our contributions using ResNet-9 on CIFAR10 and WideResNet-28x10 on CIFAR100. Experimental results show that our method heals 93.72% of poison compared to SSD with 83.41% and full retraining with 40.68%. We achieve this while also lowering the average model accuracy drop caused by unlearning from 5.68% (SSD) to 1.41% (ours).",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09187",
        "abstract url": "https://arxiv.org/abs/2406.09187",
        "title": "GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The rapid advancement of large language models (LLMs) has catalyzed the deployment of LLM-powered agents across numerous applications, raising new concerns regarding their safety and trustworthiness. Existing methods for enhancing the safety of LLMs are not directly transferable to LLM-powered agents due to their diverse objectives and output modalities. In this paper, we propose GuardAgent, the first LLM agent as a guardrail to other LLM agents. Specifically, GuardAgent oversees a target LLM agent by checking whether its inputs/outputs satisfy a set of given guard requests defined by the users. GuardAgent comprises two steps: 1) creating a task plan by analyzing the provided guard requests, and 2) generating guardrail code based on the task plan and executing the code by calling APIs or using external engines. In both steps, an LLM is utilized as the core reasoning component, supplemented by in-context demonstrations retrieved from a memory module. Such knowledge-enabled reasoning allows GuardAgent to understand various textual guard requests and accurately \"translate\" them into executable code that provides reliable guardrails. Furthermore, GuardAgent is equipped with an extendable toolbox containing functions and APIs and requires no additional LLM training, which underscores its generalization capabilities and low operational overhead. Additionally, we propose two novel benchmarks: an EICU-AC benchmark for assessing privacy-related access control for healthcare agents and a Mind2Web-SC benchmark for safety evaluation for web agents. We show the effectiveness of GuardAgent on these two benchmarks with 98.7% and 90.0% accuracy in moderating invalid inputs and outputs for the two types of agents, respectively. We also show that GuardAgent is able to define novel functions in adaption to emergent LLM agents and guard requests, which underscores its strong generalization capabilities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09194",
        "abstract url": "https://arxiv.org/abs/2406.09194",
        "title": "Bengining overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Iductive Bias",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in machine learning theory showed that interpolation to noisy samples using over-parameterized machine learning algorithms always leads to inconsistency. However, this work surprisingly discovers that interpolated machine learning can exhibit benign overfitting and consistency when using physics-informed learning for supervised tasks governed by partial differential equations (PDEs) describing laws of physics. An analysis provides an asymptotic Sobolev norm learning curve for kernel ridge(less) regression addressing linear inverse problems involving elliptic PDEs. The results reveal that the PDE operators can stabilize variance and lead to benign overfitting for fixed-dimensional problems, contrasting standard regression settings. The impact of various inductive biases introduced by minimizing different Sobolev norms as implicit regularization is also examined. Notably, the convergence rate is independent of the specific (smooth) inductive bias for both ridge and ridgeless regression. For regularized least squares estimators, all (smooth enough) inductive biases can achieve optimal convergence rates when the regularization parameter is properly chosen. The smoothness requirement recovers a condition previously found in the Bayesian setting and extends conclusions to minimum norm interpolation estimators.",
        "subjects": [
            "stat.ML",
            "cs.IT",
            "cs.LG",
            "math.NA",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09207",
        "abstract url": "https://arxiv.org/abs/2406.09207",
        "title": "Investigating potential causes of Sepsis with Bayesian network structure learning",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "Disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Sepsis is a life-threatening and serious global health issue. This study combines knowledge with available hospital data to investigate the potential causes of Sepsis that can be affected by policy decisions. We investigate the underlying causal structure of this problem by combining clinical expertise with score-based, constraint-based, and hybrid structure learning algorithms. A novel approach to model averaging and knowledge-based constraints was implemented to arrive at a consensus structure for causal inference. The structure learning process highlighted the importance of exploring data-driven approaches alongside clinical expertise. This includes discovering unexpected, although reasonable, relationships from a clinical perspective. Hypothetical interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and Diabetes suggest that the presence of any of these risk factors in patients increases the likelihood of Sepsis. This finding, alongside measuring the effect of these risk factors on Sepsis, has potential policy implications. Recognising the importance of prediction in improving Sepsis related health outcomes, the model built is also assessed in its ability to predict Sepsis. The predictions generated by the consensus model were assessed for their accuracy, sensitivity, and specificity. These three indicators all had results around 70%, and the AUC was 80%, which means the causal structure of the model is reasonably accurate given that the models were trained on data available for commissioning purposes only.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09215",
        "abstract url": "https://arxiv.org/abs/2406.09215",
        "title": "On Softmax Direct Preference Optimization for Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recommender systems aim to predict personalized rankings based on user preference data. With the rise of Language Models (LMs), LM-based recommenders have been widely explored due to their extensive world knowledge and powerful reasoning abilities. Most of the LM-based recommenders convert historical interactions into language prompts, pairing with a positive item as the target response and fine-tuning LM with a language modeling loss. However, the current objective fails to fully leverage preference data and is not optimized for personalized ranking tasks, which hinders the performance of LM-based recommenders. Inspired by the current advancement of Direct Preference Optimization (DPO) in human preference alignment and the success of softmax loss in recommendations, we propose Softmax-DPO (S-DPO) to instill ranking information into the LM to help LM-based recommenders distinguish preferred items from negatives, rather than solely focusing on positives. Specifically, we incorporate multiple negatives in user preference data and devise an alternative version of DPO loss tailored for LM-based recommenders, connected to softmax sampling strategies. Theoretically, we bridge S-DPO with the softmax loss over negative sampling and find that it has a side effect of mining hard negatives, which assures its exceptional capabilities in recommendation tasks. Empirically, extensive experiments conducted on three real-world datasets demonstrate the superiority of S-DPO to effectively model user preference and further boost recommendation performance while mitigating the data likelihood decline issue of DPO. Our codes are available at https://github.com/chenyuxin1999/S-DPO.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09288",
        "abstract url": "https://arxiv.org/abs/2406.09288",
        "title": "Zero-Shot Learning Over Large Output Spaces : Utilizing Indirect Knowledge Extraction from Large Language Models",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Extreme Multi-label Learning (XMC) is a task that allocates the most relevant labels for an instance from a predefined label set. Extreme Zero-shot XMC (EZ-XMC) is a special setting of XMC wherein no supervision is provided; only the instances (raw text of the document) and the predetermined label set are given. The scenario is designed to address cold-start problems in categorization and recommendation. Traditional state-of-the-art methods extract pseudo labels from the document title or segments. These labels from the document are used to train a zero-shot bi-encoder model. The main issue with these generated labels is their misalignment with the tagging task. In this work, we propose a framework to train a small bi-encoder model via the feedback from the large language model (LLM), the bi-encoder model encodes the document and labels into embeddings for retrieval. Our approach leverages the zero-shot ability of LLM to assess the correlation between labels and the document instead of using the low-quality labels extracted from the document itself. Our method also guarantees fast inference without the involvement of LLM. The performance of our approach outperforms the SOTA methods on various datasets while retaining a similar training time for large datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09307",
        "abstract url": "https://arxiv.org/abs/2406.09307",
        "title": "A tutorial on fairness in machine learning in healthcare",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "health",
                "healthcare",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "OBJECTIVE: Ensuring that machine learning (ML) algorithms are safe and effective within all patient groups, and do not disadvantage particular patients, is essential to clinical decision making and preventing the reinforcement of existing healthcare inequities. The objective of this tutorial is to introduce the medical informatics community to the common notions of fairness within ML, focusing on clinical applications and implementation in practice. TARGET AUDIENCE: As gaps in fairness arise in a variety of healthcare applications, this tutorial is designed to provide an understanding of fairness, without assuming prior knowledge, to researchers and clinicians who make use of modern clinical data. SCOPE: We describe the fundamental concepts and methods used to define fairness in ML, including an overview of why models in healthcare may be unfair, a summary and comparison of the metrics used to quantify fairness, and a discussion of some ongoing research. We illustrate some of the fairness methods introduced through a case study of mortality prediction in a publicly available electronic health record dataset. Finally, we provide a user-friendly R package for comprehensive group fairness evaluation, enabling researchers and clinicians to assess fairness in their own ML work.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09343",
        "abstract url": "https://arxiv.org/abs/2406.09343",
        "title": "Frameworks, Modeling and Simulations of Misinformation and Disinformation: A Systematic Literature Review",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "The prevalence of misinformation and disinformation poses a significant challenge in today's digital landscape. That is why several methods and tools are proposed to analyze and understand these phenomena from a scientific perspective. To assess how the mis/disinformation is being conceptualized and evaluated in the literature, this paper surveys the existing frameworks, models and simulations of mis/disinformation dynamics by performing a systematic literature review up to 2023. After applying the PRISMA methodology, 57 research papers are inspected to determine (1) the terminology and definitions of mis/disinformation, (2) the methods used to represent mis/disinformation, (3) the primary purpose beyond modeling and simulating mis/disinformation, (4) the context where the mis/disinformation is studied, and (5) the validation of the proposed methods for understanding mis/disinformation. The main findings reveal a consistent essence definition of misinformation and disinformation across studies, with intent as the key distinguishing factor. Research predominantly uses social frameworks, epidemiological models, and belief updating simulations. These studies aim to estimate the effectiveness of mis/disinformation, primarily in health and politics. The preferred validation strategy is to compare methods with real-world data and statistics. Finally, this paper identifies current trends and open challenges in the mis/disinformation research field, providing recommendations for future work agenda.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09358",
        "abstract url": "https://arxiv.org/abs/2406.09358",
        "title": "Understanding Hallucinations in Diffusion Models through Mode Interpolation",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Colloquially speaking, image generation models based upon diffusion processes are frequently said to exhibit \"hallucinations,\" samples that could never occur in the training data. But where do such hallucinations come from? In this paper, we study a particular failure mode in diffusion models, which we term mode interpolation. Specifically, we find that diffusion models smoothly \"interpolate\" between nearby data modes in the training set, to generate samples that are completely outside the support of the original training distribution; this phenomenon leads diffusion models to generate artifacts that never existed in real data (i.e., hallucinations). We systematically study the reasons for, and the manifestation of this phenomenon. Through experiments on 1D and 2D Gaussians, we show how a discontinuous loss landscape in the diffusion model's decoder leads to a region where any smooth approximation will cause such hallucinations. Through experiments on artificial datasets with various shapes, we show how hallucination leads to the generation of combinations of shapes that never existed. Finally, we show that diffusion models in fact know when they go out of support and hallucinate. This is captured by the high variance in the trajectory of the generated sample towards the final few backward sampling process. Using a simple metric to capture this variance, we can remove over 95% of hallucinations at generation time while retaining 96% of in-support samples. We conclude our exploration by showing the implications of such hallucination (and its removal) on the collapse (and stabilization) of recursive training on synthetic data with experiments on MNIST and 2D Gaussians dataset. We release our code at https://github.com/locuslab/diffusion-model-hallucination.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09489",
        "abstract url": "https://arxiv.org/abs/2406.09489",
        "title": "Language-driven Grasp Detection",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Grasp detection is a persistent and intricate challenge with various industrial applications. Recently, many methods and datasets have been proposed to tackle the grasp detection problem. However, most of them do not consider using natural language as a condition to detect the grasp poses. In this paper, we introduce Grasp-Anything++, a new language-driven grasp detection dataset featuring 1M samples, over 3M objects, and upwards of 10M grasping instructions. We utilize foundation models to create a large-scale scene corpus with corresponding images and grasp prompts. We approach the language-driven grasp detection task as a conditional generation problem. Drawing on the success of diffusion models in generative tasks and given that language plays a vital role in this task, we propose a new language-driven grasp detection method based on diffusion models. Our key contribution is the contrastive training objective, which explicitly contributes to the denoising process to detect the grasp pose given the language instructions. We illustrate that our approach is theoretically supportive. The intensive experiments show that our method outperforms state-of-the-art approaches and allows real-world robotic grasping. Finally, we demonstrate our large-scale dataset enables zero-short grasp detection and is a challenging benchmark for future work. Project website: https://airvlab.github.io/grasp-anything/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "19 pages. Accepted to CVPR24"
    },
    {
        "paper id": "2406.09614",
        "abstract url": "https://arxiv.org/abs/2406.09614",
        "title": "Trainability issues in quantum policy gradients",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This research explores the trainability of Parameterized Quantum circuit-based policies in Reinforcement Learning, an area that has recently seen a surge in empirical exploration. While some studies suggest improved sample complexity using quantum gradient estimation, the efficient trainability of these policies remains an open question. Our findings reveal significant challenges, including standard Barren Plateaus with exponentially small gradients and gradient explosion. These phenomena depend on the type of basis-state partitioning and mapping these partitions onto actions. For a polynomial number of actions, a trainable window can be ensured with a polynomial number of measurements if a contiguous-like partitioning of basis-states is employed. These results are empirically validated in a multi-armed bandit environment.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09643",
        "abstract url": "https://arxiv.org/abs/2406.09643",
        "title": "Reinforced Decoder: Towards Training Recurrent Neural Networks for Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recurrent neural network-based sequence-to-sequence models have been extensively applied for multi-step-ahead time series forecasting. These models typically involve a decoder trained using either its previous forecasts or the actual observed values as the decoder inputs. However, relying on self-generated predictions can lead to the rapid accumulation of errors over multiple steps, while using the actual observations introduces exposure bias as these values are unavailable during the extrapolation stage. In this regard, this study proposes a novel training approach called reinforced decoder, which introduces auxiliary models to generate alternative decoder inputs that remain accessible when extrapolating. Additionally, a reinforcement learning algorithm is utilized to dynamically select the optimal inputs to improve accuracy. Comprehensive experiments demonstrate that our approach outperforms representative training methods over several datasets. Furthermore, the proposed approach also exhibits promising performance when generalized to self-attention-based sequence-to-sequence forecasting models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages,8 figures"
    },
    {
        "paper id": "2406.08815",
        "abstract url": "https://arxiv.org/abs/2406.08815",
        "title": "Deep Reinforcement Learning-based Quadcopter Controller: A Practical Approach and Experiments",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Quadcopters have been studied for decades thanks to their maneuverability and capability of operating in a variety of circumstances. However, quadcopters suffer from dynamical nonlinearity, actuator saturation, as well as sensor noise that make it challenging and time consuming to obtain accurate dynamic models and achieve satisfactory control performance. Fortunately, deep reinforcement learning came and has shown significant potential in system modelling and control of autonomous multirotor aerial vehicles, with recent advancements in deployment, performance enhancement, and generalization. In this paper, an end-to-end deep reinforcement learning-based controller for quadcopters is proposed that is secure for real-world implementation, data-efficient, and free of human gain adjustments. First, a novel actor-critic-based architecture is designed to map the robot states directly to the motor outputs. Then, a quadcopter dynamics-based simulator was devised to facilitate the training of the controller policy. Finally, the trained policy is deployed on a real Crazyflie nano quadrotor platform, without any additional fine-tuning process. Experimental results show that the quadcopter exhibits satisfactory performance as it tracks a given complicated trajectory, which demonstrates the effectiveness and feasibility of the proposed method and signifies its capability in filling the simulation-to-reality gap.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "6 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2406.08832",
        "abstract url": "https://arxiv.org/abs/2406.08832",
        "title": "Multiplexed Quantum Communication with Surface and Hypergraph Product Codes",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Connecting multiple processors via quantum interconnect technologies could help to overcome issues of scalability in single-processor quantum computers. Transmission via these interconnects can be performed more efficiently using quantum multiplexing, where information is encoded in high-dimensional photonic degrees of freedom. We explore the effects of multiplexing on logical error rates in surface codes and hypergraph product codes. We show that, although multiplexing makes loss errors more damaging, assigning qubits to photons in an intelligent manner can minimize these effects, and the ability to encode higher-distance codes in a smaller number of photons can result in overall lower logical error rates. This multiplexing technique can also be adapted to quantum communication and multimode quantum memory with high-dimensional qudit systems.",
        "subjects": [
            "quant-ph",
            "cs.NI"
        ],
        "comment": "12 pages + 12-page appendices, 19 figures"
    },
    {
        "paper id": "2406.08833",
        "abstract url": "https://arxiv.org/abs/2406.08833",
        "title": "Harnessing Quantum Entanglement: Comprehensive Strategies for Enhanced Communication and Beyond in Quantum Networks",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum communication represents a revolutionary advancement over classical information theory, which leverages unique quantum mechanics properties like entanglement to achieve unprecedented capabilities in secure and efficient information transmission. Unlike bits in classical communication, quantum communication utilizes qubits in superposition states, allowing for novel information storage and processing. Entanglement, a key quantum phenomenon, enables advanced protocols with enhanced security and processing power. This paper provides a comprehensive overview of quantum communication, emphasizing the role of entanglement in theoretical foundations, practical protocols, experimental progress, and security implications. It contrasts quantum communications potential applications with classical networks, identifying areas where entanglement offers significant advantages. The paper explores the fundamentals of quantum mechanics in communication, the physical realization of quantum information, and the formation of secure quantum networks through entanglement-based strategies like Quantum Key Distribution (QKD) and teleportation. It addresses the challenges of long-distance quantum communication, the role of quantum repeaters in scaling networks, and the conceptualization of interconnected quantum networks. Additionally, it discusses strides towards the Quantum Internet, Quantum Error-Correcting codes, and quantum cryptographys role in ensuring secure communication. By highlighting the role of entanglement, this paper aims to inspire further research and innovation in secure and efficient information exchange within quantum networks.",
        "subjects": [
            "cs.ET",
            "cs.NI",
            "math.QA",
            "quant-ph"
        ],
        "comment": "56 pages, 11 figures, 3 tables"
    },
    {
        "paper id": "2406.08855",
        "abstract url": "https://arxiv.org/abs/2406.08855",
        "title": "Trajectory Planning for Autonomous Driving in Unstructured Scenarios Based on Graph Neural Network and Numerical Optimization",
        "rating": "-2",
        "keywords": [
            [
                "Autonomous Driving",
                "Trajectory",
                "vehicle"
            ],
            [
                "GNN",
                "Graph"
            ]
        ],
        "abstract": "In unstructured environments, obstacles are diverse and lack lane markings, making trajectory planning for intelligent vehicles a challenging task. Traditional trajectory planning methods typically involve multiple stages, including path planning, speed planning, and trajectory optimization. These methods require the manual design of numerous parameters for each stage, resulting in significant workload and computational burden. While end-to-end trajectory planning methods are simple and efficient, they often fail to ensure that the trajectory meets vehicle dynamics and obstacle avoidance constraints in unstructured scenarios. Therefore, this paper proposes a novel trajectory planning method based on Graph Neural Networks (GNN) and numerical optimization. The proposed method consists of two stages: (1) initial trajectory prediction using the GNN, (2) trajectory optimization using numerical optimization. First, the graph neural network processes the environment information and predicts a rough trajectory, replacing traditional path and speed planning. This predicted trajectory serves as the initial solution for the numerical optimization stage, which optimizes the trajectory to ensure compliance with vehicle dynamics and obstacle avoidance constraints. We conducted simulation experiments to validate the feasibility of the proposed algorithm and compared it with other mainstream planning algorithms. The results demonstrate that the proposed method simplifies the trajectory planning process and significantly improves planning efficiency.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08884",
        "abstract url": "https://arxiv.org/abs/2406.08884",
        "title": "The Penalized Inverse Probability Measure for Conformal Classification",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "agricultural"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The deployment of safe and trustworthy machine learning systems, and particularly complex black box neural networks, in real-world applications requires reliable and certified guarantees on their performance. The conformal prediction framework offers such formal guarantees by transforming any point into a set predictor with valid, finite-set, guarantees on the coverage of the true at a chosen level of confidence. Central to this methodology is the notion of the nonconformity score function that assigns to each example a measure of ''strangeness'' in comparison with the previously seen observations. While the coverage guarantees are maintained regardless of the nonconformity measure, the point predictor and the dataset, previous research has shown that the performance of a conformal model, as measured by its efficiency (the average size of the predicted sets) and its informativeness (the proportion of prediction sets that are singletons), is influenced by the choice of the nonconformity score function. The current work introduces the Penalized Inverse Probability (PIP) nonconformity score, and its regularized version RePIP, that allow the joint optimization of both efficiency and informativeness. Through toy examples and empirical results on the task of crop and weed image classification in agricultural robotics, the current work shows how PIP-based conformal classifiers exhibit precisely the desired behavior in comparison with other nonconformity measures and strike a good balance between informativeness and efficiency.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08894",
        "abstract url": "https://arxiv.org/abs/2406.08894",
        "title": "OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth",
                "radiance fields"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in deep learning such as neural radiance fields and implicit neural representations have significantly propelled the field of 3D reconstruction. However, accurately reconstructing objects with complex optical properties, such as metals and glass, remains a formidable challenge due to their unique specular and light-transmission characteristics. To facilitate the development of solutions to these challenges, we introduce the OpenMaterial dataset, comprising 1001 objects made of 295 distinct materials-including conductors, dielectrics, plastics, and their roughened variants- and captured under 723 diverse lighting conditions. To this end, we utilized physics-based rendering with laboratory-measured Indices of Refraction (IOR) and generated high-fidelity multiview images that closely replicate real-world objects. OpenMaterial provides comprehensive annotations, including 3D shape, material type, camera pose, depth, and object mask. It stands as the first large-scale dataset enabling quantitative evaluations of existing algorithms on objects with diverse and challenging materials, thereby paving the way for the development of 3D reconstruction algorithms capable of handling complex material properties.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08915",
        "abstract url": "https://arxiv.org/abs/2406.08915",
        "title": "GluPredKit: Development and User Evaluation of a Standardization Software for Blood Glucose Prediction",
        "rating": "-2",
        "keywords": [
            [
                "biomedical"
            ]
        ],
        "abstract": "Blood glucose prediction is an important component of biomedical technology for managing diabetes with automated insulin delivery systems. Machine learning and deep learning algorithms hold the potential to advance this technology. However, the lack of standardized methodologies impedes direct comparisons of emerging algorithms. This study addresses this challenge by developing GluPredKit, a software platform designed to standardize the training, testing, and comparison of blood glucose prediction algorithms. GluPredKit features a modular, open-source architecture, complemented by a command-line interface, comprehensive documentation, and a video tutorial to enhance usability. To ensure the platform's effectiveness and user-friendliness, we conducted preliminary testing and a user study. In this study, four participants interacted with GluPredKit and provided feedback through the System Usability Scale (SUS) and open-ended questions. The findings indicate that GluPredKit effectively addresses the standardization challenge and offers high usability, facilitating direct comparisons between different algorithms. Additionally, it serves an educational purpose by making advanced methodologies more accessible. Future directions include continuously enhancing the software based on user feedback. We also invite community contributions to further expand GluPredKit with state-of-the-art components and foster a collaborative effort in standardizing blood glucose prediction research, leading to more comparable studies.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "18 pages, 5 figures, submitted to the IEEE-EMBS International Conference on Biomedical and Health Informatics"
    },
    {
        "paper id": "2406.09020",
        "abstract url": "https://arxiv.org/abs/2406.09020",
        "title": "Meta-Learning an Evolvable Developmental Encoding",
        "rating": "-2",
        "keywords": [
            [
                "biological",
                "DNA"
            ]
        ],
        "abstract": "Representations for black-box optimisation methods (such as evolutionary algorithms) are traditionally constructed using a delicate manual process. This is in contrast to the representation that maps DNAs to phenotypes in biological organisms, which is at the hear of biological complexity and evolvability. Additionally, the core of this process is fundamentally the same across nearly all forms of life, reflecting their shared evolutionary origin. Generative models have shown promise in being learnable representations for black-box optimisation but they are not per se designed to be easily searchable. Here we present a system that can meta-learn such representation by directly optimising for a representation's ability to generate quality-diversity. In more detail, we show our meta-learning approach can find one Neural Cellular Automata, in which cells can attend to different parts of a \"DNA\" string genome during development, enabling it to grow different solvable 2D maze structures. We show that the evolved genotype-to-phenotype mappings become more and more evolvable, not only resulting in a faster search but also increasing the quality and diversity of grown artefacts.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "10 pages, 6 Figures, Proceedings of the 2024 Artificial Life Conference"
    },
    {
        "paper id": "2406.09021",
        "abstract url": "https://arxiv.org/abs/2406.09021",
        "title": "Contextual Distillation Model for Diversified Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ]
        ],
        "abstract": "The diversity of recommendation is equally crucial as accuracy in improving user experience. Existing studies, e.g., Determinantal Point Process (DPP) and Maximal Marginal Relevance (MMR), employ a greedy paradigm to iteratively select items that optimize both accuracy and diversity. However, prior methods typically exhibit quadratic complexity, limiting their applications to the re-ranking stage and are not applicable to other recommendation stages with a larger pool of candidate items, such as the pre-ranking and ranking stages. In this paper, we propose Contextual Distillation Model (CDM), an efficient recommendation model that addresses diversification, suitable for the deployment in all stages of industrial recommendation pipelines. Specifically, CDM utilizes the candidate items in the same user request as context to enhance the diversification of the results. We propose a contrastive context encoder that employs attention mechanisms to model both positive and negative contexts. For the training of CDM, we compare each target item with its context embedding and utilize the knowledge distillation framework to learn the win probability of each target item under the MMR algorithm, where the teacher is derived from MMR outputs. During inference, ranking is performed through a linear combination of the recommendation and student model scores, ensuring both diversity and efficiency. We perform offline evaluations on two industrial datasets and conduct online A/B test of CDM on the short-video platform KuaiShou. The considerable enhancements observed in both recommendation quality and diversity, as shown by metrics, provide strong superiority for the effectiveness of CDM.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "accepted by KDD 2024"
    },
    {
        "paper id": "2406.09025",
        "abstract url": "https://arxiv.org/abs/2406.09025",
        "title": "Site-Specific Radio Channel Representation -- Current State and Future Applications",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "industrial"
            ]
        ],
        "abstract": "A site-specific radio channel representation considers the surroundings of the communication system through the environment geometry, such as buildings, vegetation, and mobile objects including their material and surface properties. In this article, we focus on communication technologies for 5G and beyond that are increasingly able to exploit the specific environment geometry for both communication and sensing. We present methods for a site-specific radio channel representation that is spatially consistent, such that mobile transmitters and receivers cause a correlated time-varying channel impulse response. When modelled as random, this channel impulse response has non-stationary statistical properties, i.e., a time-variant Doppler spectrum, power delay profile, K-factor and spatial correlation. A site-specific radio channel representation will enable research into emerging 5G and beyond technologies such as distributed multiple-input multiple-output systems, reconfigurable intelligent surfaces, multi-band communication, and joint communication and sensing. These 5G and beyond technologies will be deployed for a wide range of environments, from dense urban areas to railways, road transportation, industrial automation, and unmanned aerial vehicles.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "7 pages, 5 figures, submitted to the IEEE Communication Magazine"
    },
    {
        "paper id": "2406.09026",
        "abstract url": "https://arxiv.org/abs/2406.09026",
        "title": "Steganalysis on Digital Watermarking: Is Your Defense Truly Impervious?",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Digital watermarking techniques are crucial for copyright protection and source identification of images, especially in the era of generative AI models. However, many existing watermarking methods, particularly content-agnostic approaches that embed fixed patterns regardless of image content, are vulnerable to steganalysis attacks that can extract and remove the watermark with minimal perceptual distortion. In this work, we categorize watermarking algorithms into content-adaptive and content-agnostic ones, and demonstrate how averaging a collection of watermarked images could reveal the underlying watermark pattern. We then leverage this extracted pattern for effective watermark removal under both graybox and blackbox settings, even when the collection contains multiple watermark patterns. For some algorithms like Tree-Ring watermarks, the extracted pattern can also forge convincing watermarks on clean images. Our quantitative and qualitative evaluations across twelve watermarking methods highlight the threat posed by steganalysis to content-agnostic watermarks and the importance of designing watermarking techniques resilient to such analytical attacks. We propose security guidelines calling for using content-adaptive watermarking strategies and performing security evaluation against steganalysis. We also suggest multi-key assignments as potential mitigations against steganalysis vulnerabilities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09039",
        "abstract url": "https://arxiv.org/abs/2406.09039",
        "title": "Language-Driven Closed-Loop Grasping with Model-Predictive Trajectory Replanning",
        "rating": "-2",
        "keywords": [
            [
                "vision language"
            ],
            [
                "6D"
            ],
            [
                "Trajectory"
            ],
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Combining a vision module inside a closed-loop control system for a \\emph{seamless movement} of a robot in a manipulation task is challenging due to the inconsistent update rates between utilized modules. This task is even more difficult in a dynamic environment, e.g., objects are moving. This paper presents a \\emph{modular} zero-shot framework for language-driven manipulation of (dynamic) objects through a closed-loop control system with real-time trajectory replanning and an online 6D object pose localization. We segment an object within $\\SI{0.5}{\\second}$ by leveraging a vision language model via language commands. Then, guided by natural language commands, a closed-loop system, including a unified pose estimation and tracking and online trajectory planning, is utilized to continuously track this object and compute the optimal trajectory in real-time. Our proposed zero-shot framework provides a smooth trajectory that avoids jerky movements and ensures the robot can grasp a non-stationary object. Experiment results exhibit the real-time capability of the proposed zero-shot modular framework for the trajectory optimization module to accurately and efficiently grasp moving objects, i.e., up to \\SI{30}{\\hertz} update rates for the online 6D pose localization module and \\SI{10}{\\hertz} update rates for the receding-horizon trajectory optimization. These advantages highlight the modular framework's potential applications in robotics and human-robot interaction; see the video in https://www.acin.tuwien.ac.at/en/6e64/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "9 pages, 6 figures"
    },
    {
        "paper id": "2406.09040",
        "abstract url": "https://arxiv.org/abs/2406.09040",
        "title": "FacEnhance: Facial Expression Enhancing with Recurrent DDPMs",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial expressions, vital in non-verbal human communication, have found applications in various computer vision fields like virtual reality, gaming, and emotional AI assistants. Despite advancements, many facial expression generation models encounter challenges such as low resolution (e.g., 32x32 or 64x64 pixels), poor quality, and the absence of background details. In this paper, we introduce FacEnhance, a novel diffusion-based approach addressing constraints in existing low-resolution facial expression generation models. FacEnhance enhances low-resolution facial expression videos (64x64 pixels) to higher resolutions (192x192 pixels), incorporating background details and improving overall quality. Leveraging conditional denoising within a diffusion framework, guided by a background-free low-resolution video and a single neutral expression high-resolution image, FacEnhance generates a video incorporating the facial expression from the low-resolution video performed by the individual with background from the neutral image. By complementing lightweight low-resolution models, FacEnhance strikes a balance between computational efficiency and desirable image resolution and quality. Extensive experiments on the MUG facial expression database demonstrate the efficacy of FacEnhance in enhancing low-resolution model outputs to state-of-the-art quality while preserving content and identity consistency. FacEnhance represents significant progress towards resource-efficient, high-fidelity facial expression generation, Renewing outdated low-resolution methods to up-to-date standards.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "submitted to Multimedia Tools and Applications"
    },
    {
        "paper id": "2406.09042",
        "abstract url": "https://arxiv.org/abs/2406.09042",
        "title": "Knowledge Graphs in the Digital Twin: A Systematic Literature Review About the Combination of Semantic Technologies and Simulation in Industrial Automation",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "The ongoing digitization of the industrial sector has reached a pivotal juncture with the emergence of Digital Twins, offering a digital representation of physical assets and processes. One key aspect of those digital representations are simulation models, enabling a deeper insight in the assets current state and its characteristics. This paper asserts that the next evolutionary step in this digitization journey involves the integration of intelligent linkages between diverse simulation models within the Digital Twin framework. Crucially, for the Digital Twin to be a scalable and cost-effective solution, there is a pressing need for automated adaption, (re-)configuration, and generation of simulation models. Recognizing the inherent challenges in achieving such automation, this paper analyses the utilization of knowledge graphs as a potentially very suitable technological solution. Knowledge graphs, acting as interconnected and interrelated databases, provide a means of seamlessly integrating different data sources, facilitating the efficient integration and automated adaption of data and (simulation) models in the Digital Twin. We conducted a comprehensive literature review to analyze the current landscape of knowledge graphs in the context of Digital Twins with focus on simulation models. By addressing the challenges associated with scalability and maintenance, this research contributes to the effective adaption of Digital Twins in the industrial sector, paving the way for enhanced efficiency, adaptability, and resilience in the face of evolving technological landscapes.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09061",
        "abstract url": "https://arxiv.org/abs/2406.09061",
        "title": "Joint Observer Gain and Input Design for Asymptotic Active Fault Diagnosis",
        "rating": "-2",
        "keywords": [
            [
                "Diagnosis"
            ]
        ],
        "abstract": "This paper proposes a joint gain and input design method for observer-based asymptotic active fault diagnosis, which is based on a newly-defined notion named the excluding degree of the origin from a zonotope. Using the excluding degree, a quantitative specification is obtained to characterize the performance of set-based robust fault diagnosis. Furthermore, a single gain design method and a joint gain and input design method are proposed, respectively. This is the first work to achieve a joint observer gain and input design for set-based active fault diagnosis. Compared with the existing methods that design gains and input separately, the proposed joint gain and input design method has advantages to exploit the fault diagnosis potential of observer-based schemes. Finally, several examples are used to illustrate the effectiveness of the proposed methods.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09093",
        "abstract url": "https://arxiv.org/abs/2406.09093",
        "title": "The Observer Effect in Computer Networks",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Network measurement involves an inherent tradeoff between accuracy and overhead; higher accuracy typically comes at the expense of greater measurement overhead (measurement frequency, number of probe packets, etc.). Capturing the \"right\" balance between these two desiderata - high accuracy and low overhead - is a key challenge. However, the manner in which accuracy and overhead are traded off is specific to the measurement method, rendering apples-to-apples comparisons difficult. To address this, we put forth a novel analytical framework for quantifying the accuracy-overhead tradeoff for network measurements. Our framework, inspired by the observer effect in modern physics, introduces the notion of a network observer factor, which formally captures the relation between measurement accuracy and overhead. Using our \"network observer framework\", measurement methods for the same task can be characterized in terms of their network observer factors, allowing for apples-to-apples comparisons. We illustrate the usefulness of our approach by showing how it can be applied to various application domains and validate its conclusions through experimental evaluation.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "This paper is an extended version of \"The Observer Effect in Computer Networks\", which was published in the ACM Applied Networking Research Workshop (ANRW), 2024"
    },
    {
        "paper id": "2406.09104",
        "abstract url": "https://arxiv.org/abs/2406.09104",
        "title": "A nA-Range Area-Efficient Sub-100-ppm/\u00b0C Peaking Current Reference Using Forward Body Biasing in 0.11-$\u03bc$m Bulk and 22-nm FD-SOI",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "In recent years, the development of the Internet of Things (IoT) has prompted the search for nA-range current references that are simultaneously constrained to a small area and robust to process, voltage and temperature variations. Yet, such references have remained elusive, as existing architectures fail to reach a low temperature coefficient (TC) while minimizing silicon area. In this work, we propose a nA-range constant-with-temperature (CWT) peaking current reference, in which a resistor is biased by the threshold voltage difference between two transistors in weak inversion. This bias voltage is lower than in conventional architectures to cut down the silicon area occupied by the resistor and is obtained by forward body biasing one of the two transistors with an ultra-low-power voltage reference so as to reduce its threshold voltage. In addition, the proposed reference includes a circuit to suppress the leakage of parasitic diodes at high temperature, and two simple trimming mechanisms for the reference current and its TC. As the proposed design relies on the body effect, it has been validated in both 0.11-$\u03bc$m bulk and 22-nm fully-depleted silicon-on-insulator, to demonstrate feasibility across different technology types. In post-layout simulation, the 0.11-$\u03bc$m design generates a 5-nA current with a 65-ppm/\u00b0C TC and a 2.84-%/V line sensitivity (LS), while in measurement, the 22-nm design achieves a 1.5-nA current with an 89-ppm/\u00b0C TC and a 0.51-%/V LS. As a result of the low resistor bias voltage, the proposed references occupy a silicon area of 0.00954 mm$^2$ in 0.11 $\u03bc$m (resp. 0.00214 mm$^2$ in 22 nm) at least 1.8$\\times$ (resp. 8.2$\\times$) smaller than fabricated nA-range CWT references, but with a TC improved by 6.1$\\times$ (resp. 4.4$\\times$).",
        "subjects": [
            "cs.AR"
        ],
        "comment": "14 pages, 28 figures"
    },
    {
        "paper id": "2406.09105",
        "abstract url": "https://arxiv.org/abs/2406.09105",
        "title": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance",
        "rating": "-2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "health"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs) have demonstrated outstanding performance in various general multimodal applications such as image recognition and visual reasoning, and have also shown promising potential in specialized domains. However, the application potential of LVLMs in the insurance domain-characterized by rich application scenarios and abundant multimodal data-has not been effectively explored. There is no systematic review of multimodal tasks in the insurance domain, nor a benchmark specifically designed to evaluate the capabilities of LVLMs in insurance. This gap hinders the development of LVLMs within the insurance domain. In this paper, we systematically review and distill multimodal tasks for four representative types of insurance: auto insurance, property insurance, health insurance, and agricultural insurance. We propose INS-MMBench, the first comprehensive LVLMs benchmark tailored for the insurance domain. INS-MMBench comprises a total of 2.2K thoroughly designed multiple-choice questions, covering 12 meta-tasks and 22 fundamental tasks. Furthermore, we evaluate multiple representative LVLMs, including closed-source models such as GPT-4o and open-source models like BLIP-2. This evaluation not only validates the effectiveness of our benchmark but also provides an in-depth performance analysis of current LVLMs on various multimodal tasks in the insurance domain. We hope that INS-MMBench will facilitate the further application of LVLMs in the insurance domain and inspire interdisciplinary development. Our dataset and evaluation code are available at https://github.com/FDU-INS/INS-MMBench.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09143",
        "abstract url": "https://arxiv.org/abs/2406.09143",
        "title": "Generative AI-based Prompt Evolution Engineering Design Optimization With Vision-Language Model",
        "rating": "-2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "3D"
            ],
            [
                "vehicle"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Engineering design optimization requires an efficient combination of a 3D shape representation, an optimization algorithm, and a design performance evaluation method, which is often computationally expensive. We present a prompt evolution design optimization (PEDO) framework contextualized in a vehicle design scenario that leverages a vision-language model for penalizing impractical car designs synthesized by a generative model. The backbone of our framework is an evolutionary strategy coupled with an optimization objective function that comprises a physics-based solver and a vision-language model for practical or functional guidance in the generated car designs. In the prompt evolutionary search, the optimizer iteratively generates a population of text prompts, which embed user specifications on the aerodynamic performance and visual preferences of the 3D car designs. Then, in addition to the computational fluid dynamics simulations, the pre-trained vision-language model is used to penalize impractical designs and, thus, foster the evolutionary algorithm to seek more viable designs. Our investigations on a car design optimization problem show a wide spread of potential car designs generated at the early phase of the search, which indicates a good diversity of designs in the initial populations, and an increase of over 20\\% in the probability of generating practical designs compared to a baseline framework without using a vision-language model. Visual inspection of the designs against the performance results demonstrates prompt evolution as a very promising paradigm for finding novel designs with good optimization performance while providing ease of use in specifying design specifications and preferences via a natural language interface.",
        "subjects": [
            "cs.AI",
            "cs.CE",
            "cs.CV",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "Accepted and to be published in IEEE Congress on Evolutionary Computation (CEC) 2024. Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses"
    },
    {
        "paper id": "2406.09190",
        "abstract url": "https://arxiv.org/abs/2406.09190",
        "title": "Rethinking Waveform for 6G: Harnessing Delay-Doppler Alignment Modulation",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Waveform design has served as a cornerstone for each generation of mobile communication systems. The future sixth-generation (6G) mobile communication networks are expected to employ larger-scale antenna arrays and exploit higher-frequency bands for further boosting data transmission rate and providing ubiquitous wireless sensing. This brings new opportunities and challenges for 6G waveform design. In this article, by leveraging the super spatial resolution of large antenna arrays and the multi-path spatial sparsity of highfrequency wireless channels, we introduce a new approach for waveform design based on the recently proposed delay-Doppler alignment modulation (DDAM). In particular, DDAM makes a paradigm shift of waveform design from the conventional manner of tolerating channel delay and Doppler spreads to actively manipulating them. First, we review the fundamental constraints and performance limitations of orthogonal frequency division multiplexing (OFDM) and introduce new opportunities for 6G waveform design. Next, the motivations and basic principles of DDAM are presented, followed by its various extensions to different wireless system setups. Finally, the main design considerations for DDAM are discussed and the new opportunities for future research are highlighted.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09208",
        "abstract url": "https://arxiv.org/abs/2406.09208",
        "title": "Python-based DSL for generating Verilog model of Synchronous Digital Circuits",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We have designed a Python-based Domain Specific Language (DSL) for modeling synchronous digital circuits. In this DSL, hardware is modeled as a collection of transactions -- running in series, parallel, and loops. When the model is executed by a Python interpreter, synthesizable and behavioural Verilog is generated as output, which can be integrated with other RTL designs or directly used for FPGA and ASIC flows. In this paper, we describe - 1) the language (DSL), which allows users to express computation in series/parallel/loop constructs, with explicit cycle boundaries, 2) the internals of a simple Python implementation to produce synthesizable Verilog, and 3) several design examples and case studies for applications in post-quantum cryptography, stereo-vision, digital signal processing and optimization techniques. In the end, we list ideas to extend this framework.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "9 pages, 13 figures"
    },
    {
        "paper id": "2406.09309",
        "abstract url": "https://arxiv.org/abs/2406.09309",
        "title": "Teleoperation of a robotic manipulator in peri-personal space: a virtual wand approach",
        "rating": "-2",
        "keywords": [
            [
                "6-DoF"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "The paper deals with the well-known problem of teleoperating a robotic arm along six degrees of freedom. The prevailing and most effective approach to this problem involves a direct position-to-position mapping, imposing robotic end-effector movements that mirrors those of the user. In the particular case where the robot stands near the operator, there are alternatives to this approach. Drawing inspiration from head pointers utilized in the 1980s, originally designed to enable drawing with limited head motions for tetraplegic individuals, we propose a \"virtual wand\" mapping. It employs a virtual rigid linkage between the hand and the robot's end-effector. With this approach, rotations produce amplified translations through a lever arm, creating a \"rotation-to-position\" coupling. This approach expands the translation workspace at the expense of a reduced rotation space. We compare the virtual wand approach to the one-to-one position mapping through the realization of 6-DoF reaching tasks. Results indicate that the two different mappings perform comparably well, are equally well-received by users, and exhibit similar motor control behaviors. Nevertheless, the virtual wand mapping is anticipated to outperform in tasks characterized by large translations and minimal effector rotations, whereas direct mapping is expected to demonstrate advantages in large rotations with minimal translations. These results pave the way for new interactions and interfaces, particularly in disability assistance utilizing head movements (instead of hands). Leveraging body parts with substantial rotations could enable the accomplishment of tasks previously deemed infeasible with standard direct coupling interfaces.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to IROS2024"
    },
    {
        "paper id": "2406.09327",
        "abstract url": "https://arxiv.org/abs/2406.09327",
        "title": "Towards AI Lesion Tracking in PET/CT Imaging: A Siamese-based CNN Pipeline applied on PSMA PET/CT Scans",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "CT",
                "cancer",
                "clinical",
                "tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Assessing tumor response to systemic therapies is one of the main applications of PET/CT. Routinely, only a small subset of index lesions out of multiple lesions is analyzed. However, this operator dependent selection may bias the results due to possible significant inter-metastatic heterogeneity of response to therapy. Automated, AI based approaches for lesion tracking hold promise in enabling the analysis of many more lesions and thus providing a better assessment of tumor response. This work introduces a Siamese CNN approach for lesion tracking between PET/CT scans. Our approach is applied on the laborious task of tracking a high number of bone lesions in full-body baseline and follow-up [68Ga]Ga- or [18F]F-PSMA PET/CT scans after two cycles of [177Lu]Lu-PSMA therapy of metastatic castration resistant prostate cancer patients. Data preparation includes lesion segmentation and affine registration. Our algorithm extracts suitable lesion patches and forwards them into a Siamese CNN trained to classify the lesion patch pairs as corresponding or non-corresponding lesions. Experiments have been performed with different input patch types and a Siamese network in 2D and 3D. The CNN model successfully learned to classify lesion assignments, reaching a lesion tracking accuracy of 83 % in its best configuration with an AUC = 0.91. For remaining lesions the pipeline accomplished a re-identification rate of 89 %. We proved that a CNN may facilitate the tracking of multiple lesions in PSMA PET/CT scans. Future clinical studies are necessary if this improves the prediction of the outcome of therapies.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": "25 pages, 9 figures, 3 tables"
    },
    {
        "paper id": "2406.09335",
        "abstract url": "https://arxiv.org/abs/2406.09335",
        "title": "Instance-level quantitative saliency in multiple sclerosis lesion segmentation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "biomarker",
                "MRI"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, explainable methods for artificial intelligence (XAI) have tried to reveal and describe models' decision mechanisms in the case of classification tasks. However, XAI for semantic segmentation and in particular for single instances has been little studied to date. Understanding the process underlying automatic segmentation of single instances is crucial to reveal what information was used to detect and segment a given object of interest. In this study, we proposed two instance-level explanation maps for semantic segmentation based on SmoothGrad and Grad-CAM++ methods. Then, we investigated their relevance for the detection and segmentation of white matter lesions (WML), a magnetic resonance imaging (MRI) biomarker in multiple sclerosis (MS). 687 patients diagnosed with MS for a total of 4043 FLAIR and MPRAGE MRI scans were collected at the University Hospital of Basel, Switzerland. Data were randomly split into training, validation and test sets to train a 3D U-Net for MS lesion segmentation. We observed 3050 true positive (TP), 1818 false positive (FP), and 789 false negative (FN) cases. We generated instance-level explanation maps for semantic segmentation, by developing two XAI methods based on SmoothGrad and Grad-CAM++. We investigated: 1) the distribution of gradients in saliency maps with respect to both input MRI sequences; 2) the model's response in the case of synthetic lesions; 3) the amount of perilesional tissue needed by the model to segment a lesion. Saliency maps (based on SmoothGrad) in FLAIR showed positive values inside a lesion and negative in its neighborhood. Peak values of saliency maps generated for these four groups of volumes presented distributions that differ significantly from one another, suggesting a quantitative nature of the proposed saliency. Contextual information of 7mm around the lesion border was required for their segmentation.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09395",
        "abstract url": "https://arxiv.org/abs/2406.09395",
        "title": "Modeling Ambient Scene Dynamics for Free-view Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Synthesis"
            ],
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a novel method for dynamic free-view synthesis of an ambient scenes from a monocular capture bringing a immersive quality to the viewing experience. Our method builds upon the recent advancements in 3D Gaussian Splatting (3DGS) that can faithfully reconstruct complex static scenes. Previous attempts to extend 3DGS to represent dynamics have been confined to bounded scenes or require multi-camera captures, and often fail to generalize to unseen motions, limiting their practical application. Our approach overcomes these constraints by leveraging the periodicity of ambient motions to learn the motion trajectory model, coupled with careful regularization. We also propose important practical strategies to improve the visual quality of the baseline 3DGS static reconstructions and to improve memory efficiency critical for GPU-memory intensive learning. We demonstrate high-quality photorealistic novel view synthesis of several ambient natural scenes with intricate textures and fine structural elements.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09410",
        "abstract url": "https://arxiv.org/abs/2406.09410",
        "title": "Scene Graph Generation in Large-Size VHR Satellite Imagery: A Large-Scale Dataset and A Context-Aware Approach",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Scene graph generation (SGG) in satellite imagery (SAI) benefits promoting intelligent understanding of geospatial scenarios from perception to cognition. In SAI, objects exhibit great variations in scales and aspect ratios, and there exist rich relationships between objects (even between spatially disjoint objects), which makes it necessary to holistically conduct SGG in large-size very-high-resolution (VHR) SAI. However, the lack of SGG datasets with large-size VHR SAI has constrained the advancement of SGG in SAI. Due to the complexity of large-size VHR SAI, mining triplets <subject, relationship, object> in large-size VHR SAI heavily relies on long-range contextual reasoning. Consequently, SGG models designed for small-size natural imagery are not directly applicable to large-size VHR SAI. To address the scarcity of datasets, this paper constructs a large-scale dataset for SGG in large-size VHR SAI with image sizes ranging from 512 x 768 to 27,860 x 31,096 pixels, named RSG, encompassing over 210,000 objects and more than 400,000 triplets. To realize SGG in large-size VHR SAI, we propose a context-aware cascade cognition (CAC) framework to understand SAI at three levels: object detection (OBD), pair pruning and relationship prediction. As a fundamental prerequisite for SGG in large-size SAI, a holistic multi-class object detection network (HOD-Net) that can flexibly integrate multi-scale contexts is proposed. With the consideration that there exist a huge amount of object pairs in large-size SAI but only a minority of object pairs contain meaningful relationships, we design a pair proposal generation (PPG) network via adversarial reconstruction to select high-value pairs. Furthermore, a relationship prediction network with context-aware messaging (RPCM) is proposed to predict the relationship types of these pairs.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This paper releases a SAI-oriented SGG toolkit with about 30 OBD methods and 10 SGG methods, and develops a benchmark based on RSG where our HOD-Net and RPCM significantly outperform the state-of-the-art methods in both OBD and SGG tasks. The RSG dataset and SAI-oriented toolkit will be made publicly available at https://linlin-dev.github.io/project/RSG"
    },
    {
        "paper id": "2406.09560",
        "abstract url": "https://arxiv.org/abs/2406.09560",
        "title": "Computational generation of tailored radionuclide libraries for alpha-particle and gamma-ray spectrometry",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "Radionuclide identification is a radioanalytical method employed in various scientific disciplines that utilize alpha-particle or gamma-ray spectrometric assays, ranging from astrophysics to nuclear medicine. Radionuclide libraries in conventional radionuclide identification systems are crafted in a manual fashion, accompanying labor-intensive and error-prone user tasks and hindering library customization. This research presents a computational algorithm and the architecture of its dedicated software that can automatically generate tailored radionuclide libraries. Progenitor-progeny recurrence relations were modeled to enable recursive computation of radionuclide subsets. This theoretical concept was incorporated into open-source software called RecurLib and validated against four actinide decay series and twelve radioactive substances, including a uranium-glazed legacy Fiestaware, natural uranium and thorium sources, a $^{226}$Ra sample, and the medical radionuclides $^{225}$Ac, $^{177}$Lu, and $^{99\\text{m}}$Tc. The developed algorithm yielded radionuclide libraries for all the tested specimens within minutes, demonstrating its efficiency and applicability across diverse scenarios. The proposed approach introduces a framework for computerized radionuclide library generation, thereby trivializing library-driven radionuclide identification and facilitating the spectral recognition of unregistered radionuclides in radiation spectrometry.",
        "subjects": [
            "cs.CE",
            "astro-ph.IM",
            "nucl-ex",
            "physics.ins-det"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09608",
        "abstract url": "https://arxiv.org/abs/2406.09608",
        "title": "Human-Machine Interface Evaluation Using EEG in Driving Simulator",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "Automated vehicles are pictured as the future of transportation, and facilitating safer driving is only one of the many benefits. However, due to the constantly changing role of the human driver, users are easily confused and have little knowledge about their responsibilities. Being the bridge between automation and human, the human-machine interface (HMI) is of great importance to driving safety. This study was conducted in a static driving simulator. Three HMI designs were developed, among which significant differences in mental workload using NASA-TLX and the subjective transparency test were found. An electroencephalogram was applied throughout the study to determine if differences in the mental workload could also be found using EEG's spectral power analysis. Results suggested that more studies are required to determine the effectiveness of the spectral power of EEG on mental workload, but the three interface designs developed in this study could serve as a solid basis for future research to evaluate the effectiveness of psychophysiological measures. Marie Sklodowska-Curie Actions; Innovative Training Network (ITN); SHAPE-IT; Grant number 860410; Publication date: [27 July 2023]; DOI: [10.1109/IV55152.2023.10186567]",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09631",
        "abstract url": "https://arxiv.org/abs/2406.09631",
        "title": "Optimal Convex Cover as Collision-free Space Approximation for Trajectory Generation",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory",
                "Flight"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "We propose an online iterative algorithm to find a suitable convex cover to under-approximate the free space for autonomous navigation to delineate Safe Flight Corridors (SFC). The convex cover consists of a set of polytopes such that the union of the polytopes represents obstacle-free space, allowing us to find trajectories for robots that lie within the convex cover. In order to find the SFC that facilitates optimal trajectory generation, we iteratively find overlapping polytopes of maximum volumes that include specified waypoints initialized by a geometric or kinematic planner. Constraints at waypoints appear in two alternating stages of a joint optimization problem, which is solved by a method inspired by the Alternating Direction Method of Multipliers (ADMM) with partially distributed variables. We validate the effectiveness of our proposed algorithm using a range of parameterized environments and show its applications for two-stage motion planning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09662",
        "abstract url": "https://arxiv.org/abs/2406.09662",
        "title": "Learning Language Structures through Grounding",
        "rating": "-2",
        "keywords": [
            [
                "synthesis"
            ],
            [
                "grammar"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Language is highly structured, with syntactic and semantic structures, to some extent, agreed upon by speakers of the same language. With implicit or explicit awareness of such structures, humans can learn and use language efficiently and generalize to sentences that contain unseen words. Motivated by human language learning, in this dissertation, we consider a family of machine learning tasks that aim to learn language structures through grounding. We seek distant supervision from other data sources (i.e., grounds), including but not limited to other modalities (e.g., vision), execution results of programs, and other languages. We demonstrate the potential of this task formulation and advocate for its adoption through three schemes. In Part I, we consider learning syntactic parses through visual grounding. We propose the task of visually grounded grammar induction, present the first models to induce syntactic structures from visually grounded text and speech, and find that the visual grounding signals can help improve the parsing quality over language-only models. As a side contribution, we propose a novel evaluation metric that enables the evaluation of speech parsing without text or automatic speech recognition systems involved. In Part II, we propose two execution-aware methods to map sentences into corresponding semantic structures (i.e., programs), significantly improving compositional generalization and few-shot program synthesis. In Part III, we propose methods that learn language structures from annotations in other languages. Specifically, we propose a method that sets a new state of the art on cross-lingual word alignment. We then leverage the learned word alignments to improve the performance of zero-shot cross-lingual dependency parsing, by proposing a novel substructure-based projection method that preserves structural knowledge learned from the source language.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Ph.D. Thesis"
    },
    {
        "paper id": "2406.09669",
        "abstract url": "https://arxiv.org/abs/2406.09669",
        "title": "Watch the Watcher! Backdoor Attacks on Security-Enhancing Diffusion Models",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "Thanks to their remarkable denoising capabilities, diffusion models are increasingly being employed as defensive tools to reinforce the security of other models, notably in purifying adversarial examples and certifying adversarial robustness. However, the security risks of these practices themselves remain largely unexplored, which is highly concerning. To bridge this gap, this work investigates the vulnerabilities of security-enhancing diffusion models. Specifically, we demonstrate that these models are highly susceptible to DIFF2, a simple yet effective backdoor attack, which substantially diminishes the security assurance provided by such models. Essentially, DIFF2 achieves this by integrating a malicious diffusion-sampling process into the diffusion model, guiding inputs embedded with specific triggers toward an adversary-defined distribution while preserving the normal functionality for clean inputs. Our case studies on adversarial purification and robustness certification show that DIFF2 can significantly reduce both post-purification and certified accuracy across benchmark datasets and models, highlighting the potential risks of relying on pre-trained diffusion models as defensive tools. We further explore possible countermeasures, suggesting promising avenues for future research.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09700",
        "abstract url": "https://arxiv.org/abs/2406.09700",
        "title": "Jointed Tails Enhance Control of Three-dimensional Body Rotation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ]
        ],
        "abstract": "Tails used as inertial appendages induce body rotations of animals and robots, a phenomenon that is governed largely by the ratio of the body and tail moments of inertia. However, vertebrate tails have more degrees of freedom (e.g., number of joints, rotational axes) than most current theoretical models and robotic tails. To understand how morphology affects inertial appendage function, we developed an optimization-based approach that finds the maximally effective tail trajectory and measures error from a target trajectory. For tails of equal total length and mass, increasing the number of equal-length joints increased the complexity of maximally effective tail motions. When we optimized the relative lengths of tail bones while keeping the total tail length, mass, and number of joints the same, this optimization-based approach found that the lengths match the pattern found in the tail bones of mammals specialized for inertial maneuvering. In both experiments, adding joints enhanced the performance of the inertial appendage, but with diminishing returns, largely due to the total control effort constraint. This optimization-based simulation can compare the maximum performance of diverse inertial appendages that dynamically vary in moment of inertia in 3D space, predict inertial capabilities from skeletal data, and inform the design of robotic inertial appendages.",
        "subjects": [
            "cs.RO",
            "physics.bio-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08854",
        "abstract url": "https://arxiv.org/abs/2406.08854",
        "title": "Current applications and potential future directions of reinforcement learning-based Digital Twins in agriculture",
        "rating": "-2.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Digital Twins have gained attention in various industries for simulation, monitoring, and decision-making, relying on ever-improving machine learning models. However, agricultural Digital Twin implementations are limited compared to other industries. Meanwhile, machine learning, particularly reinforcement learning, has shown potential in agricultural applications like optimizing decision-making, task automation, and resource management. A key aspect of Digital Twins is representing physical assets or systems in a virtual environment, which aligns well with reinforcement learning's need for environment representations to learn the best policy for a task. Reinforcement learning in agriculture can thus enable various Digital Twin applications in agricultural domains. This review aims to categorize existing research employing reinforcement learning in agricultural settings by application domains like robotics, greenhouse management, irrigation systems, and crop management, identifying potential future areas for reinforcement learning-based Digital Twins. It also categorizes the reinforcement learning techniques used, including tabular methods, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic algorithms, to overview currently employed models. The review seeks to provide insights into the state-of-the-art in integrating Digital Twins and reinforcement learning in agriculture, identifying gaps and opportunities for future research, and exploring synergies to tackle agricultural challenges and optimize farming, paving the way for more efficient and sustainable farming methodologies.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09263",
        "abstract url": "https://arxiv.org/abs/2406.09263",
        "title": "Generative Inverse Design of Crystal Structures via Diffusion Models with Transformers",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in deep learning have enabled the generation of realistic data by training generative models on large datasets of text, images, and audio. While these models have demonstrated exceptional performance in generating novel and plausible data, it remains an open question whether they can effectively accelerate scientific discovery through the data generation and drive significant advancements across various scientific fields. In particular, the discovery of new inorganic materials with promising properties poses a critical challenge, both scientifically and for industrial applications. However, unlike textual or image data, materials, or more specifically crystal structures, consist of multiple types of variables - including lattice vectors, atom positions, and atomic species. This complexity in data give rise to a variety of approaches for representing and generating such data. Consequently, the design choices of generative models for crystal structures remain an open question. In this study, we explore a new type of diffusion model for the generative inverse design of crystal structures, with a backbone based on a Transformer architecture. We demonstrate our models are superior to previous methods in their versatility for generating crystal structures with desired properties. Furthermore, our empirical results suggest that the optimal conditioning methods vary depending on the dataset.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09346",
        "abstract url": "https://arxiv.org/abs/2406.09346",
        "title": "Scoreformer: A Surrogate Model For Large-Scale Prediction of Docking Scores",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we present ScoreFormer, a novel graph transformer model designed to accurately predict molecular docking scores, thereby optimizing high-throughput virtual screening (HTVS) in drug discovery. The architecture integrates Principal Neighborhood Aggregation (PNA) and Learnable Random Walk Positional Encodings (LRWPE), enhancing the model's ability to understand complex molecular structures and their relationship with their respective docking scores. This approach significantly surpasses traditional HTVS methods and recent Graph Neural Network (GNN) models in both recovery and efficiency due to a wider coverage of the chemical space and enhanced performance. Our results demonstrate that ScoreFormer achieves competitive performance in docking score prediction and offers a substantial 1.65-fold reduction in inference time compared to existing models. We evaluated ScoreFormer across multiple datasets under various conditions, confirming its robustness and reliability in identifying potential drug candidates rapidly.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09606",
        "abstract url": "https://arxiv.org/abs/2406.09606",
        "title": "Cross-Modality Program Representation Learning for Electronic Design Automation with High-Level Synthesis",
        "rating": "-2.5",
        "keywords": [
            [
                "Synthesis"
            ],
            [
                "autonomous driving"
            ],
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, domain-specific accelerators (DSAs) have gained popularity for applications such as deep learning and autonomous driving. To facilitate DSA designs, programmers use high-level synthesis (HLS) to compile a high-level description written in C/C++ into a design with low-level hardware description languages that eventually synthesize DSAs on circuits. However, creating a high-quality HLS design still demands significant domain knowledge, particularly in microarchitecture decisions expressed as \\textit{pragmas}. Thus, it is desirable to automate such decisions with the help of machine learning for predicting the quality of HLS designs, requiring a deeper understanding of the program that consists of original code and pragmas. Naturally, these programs can be considered as sequence data. In addition, these programs can be compiled and converted into a control data flow graph (CDFG). But existing works either fail to leverage both modalities or combine the two in shallow or coarse ways. We propose ProgSG, a model that allows interaction between the source code sequence modality and the graph modality in a deep and fine-grained way. To alleviate the scarcity of labeled designs, a pre-training method is proposed based on a suite of compiler's data flow analysis tasks. Experimental results show that ProgSG reduces the RMSE of design performance predictions by up to $22\\%$, and identifies designs with an average of $1.10\\times$ and $1.26\\times$ (up to $8.17\\times$ and $13.31\\times$) performance improvement in design space exploration (DSE) task compared to HARP and AutoDSE, respectively.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR"
        ],
        "comment": "14 pages, 8 figures. arXiv admin note: text overlap with arXiv:2305.10838"
    },
    {
        "paper id": "2406.09622",
        "abstract url": "https://arxiv.org/abs/2406.09622",
        "title": "DSL-FIQA: Assessing Facial Image Quality via Dual-Set Degradation Learning and Landmark-Guided Transformer",
        "rating": "-2.5",
        "keywords": [
            [
                "Facial"
            ],
            [
                "image restoration",
                "Quality Assessment"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Generic Face Image Quality Assessment (GFIQA) evaluates the perceptual quality of facial images, which is crucial in improving image restoration algorithms and selecting high-quality face images for downstream tasks. We present a novel transformer-based method for GFIQA, which is aided by two unique mechanisms. First, a Dual-Set Degradation Representation Learning (DSL) mechanism uses facial images with both synthetic and real degradations to decouple degradation from content, ensuring generalizability to real-world scenarios. This self-supervised method learns degradation features on a global scale, providing a robust alternative to conventional methods that use local patch information in degradation learning. Second, our transformer leverages facial landmarks to emphasize visually salient parts of a face image in evaluating its perceptual quality. We also introduce a balanced and diverse Comprehensive Generic Face IQA (CGFIQA-40k) dataset of 40K images carefully designed to overcome the biases, in particular the imbalances in skin tone and gender representation, in existing datasets. Extensive analysis and evaluation demonstrate the robustness of our method, marking a significant improvement over prior methods.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "comment": "Accepted by CVPR 2024, Project Page: https://dsl-fiqa.github.io/"
    },
    {
        "paper id": "2406.09680",
        "abstract url": "https://arxiv.org/abs/2406.09680",
        "title": "Heterogeneous Federated Learning with Convolutional and Spiking Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "biologically"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) has emerged as a promising paradigm for training models on decentralized data while safeguarding data privacy. Most existing FL systems, however, assume that all machine learning models are of the same type, although it becomes more likely that different edge devices adopt different types of AI models, including both conventional analogue artificial neural networks (ANNs) and biologically more plausible spiking neural networks (SNNs). This diversity empowers the efficient handling of specific tasks and requirements, showcasing the adaptability and versatility of edge computing platforms. One main challenge of such heterogeneous FL system lies in effectively aggregating models from the local devices in a privacy-preserving manner. To address the above issue, this work benchmarks FL systems containing both convoluntional neural networks (CNNs) and SNNs by comparing various aggregation approaches, including federated CNNs, federated SNNs, federated CNNs for SNNs, federated SNNs for CNNs, and federated CNNs with SNN fusion. Experimental results demonstrate that the CNN-SNN fusion framework exhibits the best performance among the above settings on the MNIST dataset. Additionally, intriguing phenomena of competitive suppression are noted during the convergence process of multi-model FL.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "8 pages, 5 figures, FL@FM-IJCAI'24"
    },
    {
        "paper id": "2406.08827",
        "abstract url": "https://arxiv.org/abs/2406.08827",
        "title": "How Powerful is Graph Filtering for Recommendation",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "It has been shown that the effectiveness of graph convolutional network (GCN) for recommendation is attributed to the spectral graph filtering. Most GCN-based methods consist of a graph filter or followed by a low-rank mapping optimized based on supervised training. However, we show two limitations suppressing the power of graph filtering: (1) Lack of generality. Due to the varied noise distribution, graph filters fail to denoise sparse data where noise is scattered across all frequencies, while supervised training results in worse performance on dense data where noise is concentrated in middle frequencies that can be removed by graph filters without training. (2) Lack of expressive power. We theoretically show that linear GCN (LGCN) that is effective on collaborative filtering (CF) cannot generate arbitrary embeddings, implying the possibility that optimal data representation might be unreachable. To tackle the first limitation, we show close relation between noise distribution and the sharpness of spectrum where a sharper spectral distribution is more desirable causing data noise to be separable from important features without training. Based on this observation, we propose a generalized graph normalization G^2N to adjust the sharpness of spectral distribution in order to redistribute data noise to assure that it can be removed by graph filtering without training. As for the second limitation, we propose an individualized graph filter (IGF) adapting to the different confidence levels of the user preference that interactions can reflect, which is proved to be able to generate arbitrary embeddings. By simplifying LGCN, we further propose a simplified graph filtering (SGFCF) which only requires the top-K singular values for recommendation. Finally, experimental results on four datasets with different density settings demonstrate the effectiveness and efficiency of our proposed methods.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted to KDD'24"
    },
    {
        "paper id": "2406.08898",
        "abstract url": "https://arxiv.org/abs/2406.08898",
        "title": "Computer Vision Approaches for Automated Bee Counting Application",
        "rating": "-3",
        "keywords": [
            [
                "health"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Many application from the bee colony health state monitoring could be efficiently solved using a computer vision techniques. One of such challenges is an efficient way for counting the number of incoming and outcoming bees, which could be used to further analyse many trends, such as the bee colony health state, blooming periods, or for investigating the effects of agricultural spraying. In this paper, we compare three methods for the automated bee counting over two own datasets. The best performing method is based on the ResNet-50 convolutional neural network classifier, which achieved accuracy of 87% over the BUT1 dataset and the accuracy of 93% over the BUT2 dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08963",
        "abstract url": "https://arxiv.org/abs/2406.08963",
        "title": "Weaponizing Disinformation Against Critical Infrastructures",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "crime"
            ]
        ],
        "abstract": "For nearly a decade, disinformation has dominated social debates, with its harmful impacts growing more evident. Episodes like the January 6 United States Capitol attack and the Rohingya genocide exemplify how this phenomenon has been weaponized. While considerable attention has been paid to its impact on societal discourse and minority persecution, there remains a gap in analyzing its role as a malicious hybrid tool targeting critical infrastructures. This article addresses this gap by presenting three case studies: a hypothetical scenario involving the electric grid, an attack on traffic management, and XZ Utils backdoor. Additionally, the study undertakes a criminological analysis to comprehend the criminal profiles driving such attacks, while also assessing their implications from a human rights perspective. The research findings highlight the necessity for comprehensive mitigation strategies encompassing technical solutions and crime prevention measures in order to safeguard critical infrastructures against these emerging threats.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This paper was sent to CPS4CIP 2024"
    },
    {
        "paper id": "2406.09000",
        "abstract url": "https://arxiv.org/abs/2406.09000",
        "title": "A Passwordless MFA Utlizing Biometrics, Proximity and Contactless Communication",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Biometrics",
                "facial"
            ]
        ],
        "abstract": "Despite being more secure and strongly promoted, two-factor (2FA) or multi-factor (MFA) schemes either fail to protect against recent phishing threats such as real-time MITM, controls/relay MITM, malicious browser extension-based phishing attacks, and/or need the users to purchase and carry other hardware for additional account protection. Leveraging the unprecedented popularity of NFC and BLE-enabled smartphones, we explore a new horizon for designing an MFA scheme. This paper introduces an advanced authentication method for user verification that utilizes the user's real-time facial biometric identity, which serves as an inherent factor, together with BLE- NFC-enabled mobile devices, which operate as an ownership factor. We have implemented a prototype authentication system on a BLE-NFC-enabled Android device, and initial threat modeling suggests that it is safe against known phishing attacks. The scheme has been compared with other popular schemes using the Bonneau et al. assessment framework in terms of usability, deployability, and security.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09016",
        "abstract url": "https://arxiv.org/abs/2406.09016",
        "title": "Cross-Modal Learning for Anomaly Detection in Fused Magnesium Smelting Process: Methodology and Benchmark",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fused Magnesium Furnace (FMF) is a crucial industrial equipment in the production of magnesia, and anomaly detection plays a pivotal role in ensuring its efficient, stable, and secure operation. Existing anomaly detection methods primarily focus on analyzing dominant anomalies using the process variables (such as arc current) or constructing neural networks based on abnormal visual features, while overlooking the intrinsic correlation of cross-modal information. This paper proposes a cross-modal Transformer (dubbed FmFormer), designed to facilitate anomaly detection in fused magnesium smelting processes by exploring the correlation between visual features (video) and process variables (current). Our approach introduces a novel tokenization paradigm to effectively bridge the substantial dimensionality gap between the 3D video modality and the 1D current modality in a multiscale manner, enabling a hierarchical reconstruction of pixel-level anomaly detection. Subsequently, the FmFormer leverages self-attention to learn internal features within each modality and bidirectional cross-attention to capture correlations across modalities. To validate the effectiveness of the proposed method, we also present a pioneering cross-modal benchmark of the fused magnesium smelting process, featuring synchronously acquired video and current data for over 2.2 million samples. Leveraging cross-modal learning, the proposed FmFormer achieves state-of-the-art performance in detecting anomalies, particularly under extreme interferences such as current fluctuations and visual occlusion caused by heavy water mist. The presented methodology and benchmark may be applicable to other industrial applications with some amendments. The benchmark will be released at https://github.com/GaochangWu/FMF-Benchmark.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 6 figures, 5 tables. Submitted to IEEE"
    },
    {
        "paper id": "2406.09168",
        "abstract url": "https://arxiv.org/abs/2406.09168",
        "title": "SR-CACO-2: A Dataset for Confocal Fluorescence Microscopy Image Super-Resolution",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Super-Resolution"
            ],
            [
                "biological"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Confocal fluorescence microscopy is one of the most accessible and widely used imaging techniques for the study of biological processes. Scanning confocal microscopy allows the capture of high-quality images from 3D samples, yet suffers from well-known limitations such as photobleaching and phototoxicity of specimens caused by intense light exposure, which limits its use in some applications, especially for living cells. Cellular damage can be alleviated by changing imaging parameters to reduce light exposure, often at the expense of image quality. Machine/deep learning methods for single-image super-resolution (SISR) can be applied to restore image quality by upscaling lower-resolution (LR) images to produce high-resolution images (HR). These SISR methods have been successfully applied to photo-realistic images due partly to the abundance of publicly available data. In contrast, the lack of publicly available data partly limits their application and success in scanning confocal microscopy. In this paper, we introduce a large scanning confocal microscopy dataset named SR-CACO-2 that is comprised of low- and high-resolution image pairs marked for three different fluorescent markers. It allows the evaluation of performance of SISR methods on three different upscaling levels (X2, X4, X8). SR-CACO-2 contains the human epithelial cell line Caco-2 (ATCC HTB-37), and it is composed of 22 tiles that have been translated in the form of 9,937 image patches for experiments with SISR methods. Given the new SR-CACO-2 dataset, we also provide benchmarking results for 15 state-of-the-art methods that are representative of the main SISR families. Results show that these methods have limited success in producing high-resolution textures, indicating that SR-CACO-2 represents a challenging problem. Our dataset, code and pretrained weights are available: https://github.com/sbelharbi/sr-caco-2.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "23 pages, 13 figures"
    },
    {
        "paper id": "2406.09178",
        "abstract url": "https://arxiv.org/abs/2406.09178",
        "title": "AutomaChef: A Physics-informed Demonstration-guided Learning Framework for Granular Material Manipulation",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Physics"
            ]
        ],
        "abstract": "Due to the complex physical properties of granular materials, research on robot learning for manipulating such materials predominantly either disregards the consideration of their physical characteristics or uses surrogate models to approximate their physical properties. Learning to manipulate granular materials based on physical information obtained through precise modelling remains an unsolved problem. In this paper, we propose to address this challenge by constructing a differentiable physics simulator for granular materials based on the Taichi programming language and developing a learning framework accelerated by imperfect demonstrations that are generated via gradient-based optimisation on non-granular materials through our simulator. Experimental results show that our method trains three policies that, when chained, are capable of executing the task of transporting granular materials in both simulated and real-world scenarios, which existing popular deep reinforcement learning models fail to accomplish.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2406.09304",
        "abstract url": "https://arxiv.org/abs/2406.09304",
        "title": "Self-reconfigurable Multifunctional Memristive Nociceptor for Intelligent Robotics",
        "rating": "-3",
        "keywords": [
            [
                "Robotics"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Artificial nociceptors, mimicking human-like stimuli perception, are of significance for intelligent robotics to work in hazardous and dynamic scenarios. One of the most essential characteristics of the human nociceptor is its self-adjustable attribute, which indicates that the threshold of determination of a potentially hazardous stimulus relies on environmental knowledge. This critical attribute has been currently omitted, but it is highly desired for artificial nociceptors. Inspired by these shortcomings, this article presents, for the first time, a Self-Directed Channel (SDC) memristor-based self-reconfigurable nociceptor, capable of perceiving hazardous pressure stimuli under different temperatures and demonstrates key features of tactile nociceptors, including 'threshold,' 'no-adaptation,' and 'sensitization.' The maximum amplification of hazardous external stimuli is 1000%, and its response characteristics dynamically adapt to current temperature conditions by automatically altering the generated modulation schemes for the memristor. The maximum difference ratio of the response of memristors at different temperatures is 500%, and this adaptability closely mimics the functions of biological tactile nociceptors, resulting in accurate danger perception in various conditions. Beyond temperature adaptation, this memristor-based nociceptor has the potential to integrate different sensory modalities by applying various sensors, thereby achieving human-like perception capabilities in real-world environments.",
        "subjects": [
            "physics.app-ph",
            "eess.SP"
        ],
        "comment": "14 pages, 4 figures"
    },
    {
        "paper id": "2406.09313",
        "abstract url": "https://arxiv.org/abs/2406.09313",
        "title": "Less Cybersickness, Please: Demystifying and Detecting Stereoscopic Visual Inconsistencies in VR Apps",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "health"
            ]
        ],
        "abstract": "The quality of Virtual Reality (VR) apps is vital, particularly the rendering quality of the VR Graphical User Interface (GUI). Different from traditional 2D apps, VR apps create a 3D digital scene for users, by rendering two distinct 2D images for the user's left and right eyes, respectively. Stereoscopic visual inconsistency (denoted as \"SVI\") issues, however, undermine the rendering process of the user's brain, leading to user discomfort and even adverse health effects. Such issues commonly exist but remain underexplored. We conduct an empirical analysis on 282 SVI bug reports from 15 VR platforms, summarizing 15 types of manifestations. The empirical analysis reveals that automatically detecting SVI issues is challenging, mainly because: (1) lack of training data; (2) the manifestations of SVI issues are diverse, complicated, and often application-specific; (3) most accessible VR apps are closed-source commercial software. Existing pattern-based supervised classification approaches may be inapplicable or ineffective in detecting the SVI issues. To counter these challenges, we propose an unsupervised black-box testing framework named StereoID to identify the stereoscopic visual inconsistencies, based only on the rendered GUI states. StereoID generates a synthetic right-eye image based on the actual left-eye image and computes distances between the synthetic right-eye image and the actual right-eye image to detect SVI issues. We propose a depth-aware conditional stereo image translator to power the image generation process, which captures the expected perspective shifts between left-eye and right-eye images. We build a large-scale unlabeled VR stereo screenshot dataset with larger than 171K images from 288 real-world VR apps for experiments. After substantial experiments, StereoID demonstrates superior performance for detecting SVI issues in both user reports and wild VR apps.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This work has been accepted at the ACM International Conference on the Foundations of Software Engineering (FSE) 2024, Porto de Galinhas, Brazil. DOI: https://doi.org/10.1145/3660803"
    },
    {
        "paper id": "2406.09389",
        "abstract url": "https://arxiv.org/abs/2406.09389",
        "title": "Sagiri: Low Dynamic Range Image Enhancement with Generative Diffusion Prior",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "Diffusion"
            ],
            [
                "HDR",
                "Image Enhancement"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Capturing High Dynamic Range (HDR) scenery using 8-bit cameras often suffers from over-/underexposure, loss of fine details due to low bit-depth compression, skewed color distributions, and strong noise in dark areas. Traditional LDR image enhancement methods primarily focus on color mapping, which enhances the visual representation by expanding the image's color range and adjusting the brightness. However, these approaches fail to effectively restore content in dynamic range extremes, which are regions with pixel values close to 0 or 255. To address the full scope of challenges in HDR imaging and surpass the limitations of current models, we propose a novel two-stage approach. The first stage maps the color and brightness to an appropriate range while keeping the existing details, and the second stage utilizes a diffusion prior to generate content in dynamic range extremes lost during capture. This generative refinement module can also be used as a plug-and-play module to enhance and complement existing LDR enhancement models. The proposed method markedly improves the quality and details of LDR images, demonstrating superior performance through rigorous experimental validation. The project page is at https://sagiri0208.github.io",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "https://sagiri0208.github.io"
    },
    {
        "paper id": "2406.09485",
        "abstract url": "https://arxiv.org/abs/2406.09485",
        "title": "Integrated Modeling, Verification, and Code Generation for Unmanned Aerial Systems",
        "rating": "-3",
        "keywords": [
            [
                "flight"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Unmanned Aerial Systems (UAS) are currently widely used in safety-critical fields such as industrial production, military operations, and disaster relief. Due to the diversity and complexity of application scenarios, UAS have become increasingly intricate. The challenge of designing and implementing highly reliable UAS while effectively controlling development costs and enhancing efficiency is a pressing issue faced by both academia and industry. Addressing this challenge, this paper aims to investigate an integrated approach to modeling, verification, and code generation for UAS. The paper begins by utilizing Architecture Analysis and Design Language (AADL) to model the UAS, proposing a set of generic UAS models. Based on these models, formal specifications are written to describe the system's safety properties and functions. Finally, the paper introduces a method for generating flight controller code for UAS based on the verified models. Experiments conducted with the proposed method demonstrate its effectiveness in identifying potential vulnerabilities in the UAS during the early design phase and in generating viable flight controller code from the verified models. This approach can enhance the efficiency of designing and verifying high-reliability UAS.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09648",
        "abstract url": "https://arxiv.org/abs/2406.09648",
        "title": "An Intrinsic Vector Heat Network",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Vector fields are widely used to represent and model flows for many science and engineering applications. This paper introduces a novel neural network architecture for learning tangent vector fields that are intrinsically defined on manifold surfaces embedded in 3D. Previous approaches to learning vector fields on surfaces treat vectors as multi-dimensional scalar fields, using traditional scalar-valued architectures to process channels individually, thus fail to preserve fundamental intrinsic properties of the vector field. The core idea of this work is to introduce a trainable vector heat diffusion module to spatially propagate vector-valued feature data across the surface, which we incorporate into our proposed architecture that consists of vector-valued neurons. Our architecture is invariant to rigid motion of the input, isometric deformation, and choice of local tangent bases, and is robust to discretizations of the surface. We evaluate our Vector Heat Network on triangle meshes, and empirically validate its invariant properties. We also demonstrate the effectiveness of our method on the useful industrial application of quadrilateral mesh generation.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08864",
        "abstract url": "https://arxiv.org/abs/2406.08864",
        "title": "Research on Early Warning Model of Cardiovascular Disease Based on Computer Deep Learning",
        "rating": "-3.5",
        "keywords": [
            [
                "Disease",
                "physiological"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This project intends to study a cardiovascular disease risk early warning model based on one-dimensional convolutional neural networks. First, the missing values of 13 physiological and symptom indicators such as patient age, blood glucose, cholesterol, and chest pain were filled and Z-score was standardized. The convolutional neural network is converted into a 2D matrix, the convolution function of 1,3, and 5 is used for the first-order convolution operation, and the Max Pooling algorithm is adopted for dimension reduction. Set the learning rate and output rate. It is optimized by the Adam algorithm. The result of classification is output by a soft classifier. This study was conducted based on Statlog in the UCI database and heart disease database respectively. The empirical data indicate that the forecasting precision of this technique has been enhanced by 11.2%, relative to conventional approaches, while there is a significant improvement in the logarithmic curve fitting. The efficacy and applicability of the novel approach are corroborated through the examination employing a one-dimensional convolutional neural network.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2406.08990",
        "abstract url": "https://arxiv.org/abs/2406.08990",
        "title": "BTS: Building Timeseries Dataset: Empowering Large-Scale Building Analytics",
        "rating": "-3.5",
        "keywords": [
            [
                "health"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Buildings play a crucial role in human well-being, influencing occupant comfort, health, and safety. Additionally, they contribute significantly to global energy consumption, accounting for one-third of total energy usage, and carbon emissions. Optimizing building performance presents a vital opportunity to combat climate change and promote human flourishing. However, research in building analytics has been hampered by the lack of accessible, available, and comprehensive real-world datasets on multiple building operations. In this paper, we introduce the Building TimeSeries (BTS) dataset. Our dataset covers three buildings over a three-year period, comprising more than ten thousand timeseries data points with hundreds of unique ontologies. Moreover, the metadata is standardized using the Brick schema. To demonstrate the utility of this dataset, we performed benchmarks on two tasks: timeseries ontology classification and zero-shot forecasting. These tasks represent an essential initial step in addressing challenges related to interoperability in building analytics. Access to the dataset and the code used for benchmarking are available here: https://github.com/cruiseresearchgroup/DIEF_BTS .",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 2 figures, 9 tables, under review"
    },
    {
        "paper id": "2406.09159",
        "abstract url": "https://arxiv.org/abs/2406.09159",
        "title": "ALPHAGMUT: A Rationale-Guided Alpha Shape Graph Neural Network to Evaluate Mutation Effects",
        "rating": "-3.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "biomarkers",
                "disease"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In silico methods evaluating the mutation effects of missense mutations are providing an important approach for understanding mutations in personal genomes and identifying disease-relevant biomarkers. However, existing methods, including deep learning methods, heavily rely on sequence-aware information, and do not fully leverage the potential of available 3D structural information. In addition, these methods may exhibit an inability to predict mutations in domains difficult to formulate sequence-based embeddings. In this study, we introduce a novel rationale-guided graph neural network AlphaGMut to evaluate mutation effects and to distinguish pathogenic mutations from neutral mutations. We compute the alpha shapes of protein structures to obtain atomic-resolution edge connectivities and map them to an accurate residue-level graph representation. We then compute structural-, topological-, biophysical-, and sequence properties of the mutation sites, which are assigned as node attributes in the graph. These node attributes could effectively guide the graph neural network to learn the difference between pathogenic and neutral mutations using k-hop message passing with a short training period. We demonstrate that AlphaGMut outperforms state-of-the-art methods, including DeepMind's AlphaMissense, in many performance metrics. In addition, AlphaGMut has the advantage of performing well in alignment-free settings, which provides broader prediction coverage and better generalization compared to current methods requiring deep sequence-aware information.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.CG",
            "q-bio.GN"
        ],
        "comment": "2 figures, 2 tables"
    },
    {
        "paper id": "2406.09357",
        "abstract url": "https://arxiv.org/abs/2406.09357",
        "title": "Advancing Graph Generation through Beta Diffusion",
        "rating": "-3.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Graph"
            ],
            [
                "biochemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have demonstrated effectiveness in generating natural images and have been extended to generate diverse data types, including graphs. This new generation of diffusion-based graph generative models has demonstrated significant performance improvements over methods that rely on variational autoencoders or generative adversarial networks. It's important to recognize, however, that most of these models employ Gaussian or categorical diffusion processes, which can struggle with sparse and long-tailed data distributions. In our work, we introduce Graph Beta Diffusion (GBD), a diffusion-based generative model particularly adept at capturing diverse graph structures. GBD utilizes a beta diffusion process, tailored for the sparse and range-bounded characteristics of graph adjacency matrices. Furthermore, we have developed a modulation technique that enhances the realism of the generated graphs by stabilizing the generation of critical graph structures, while preserving flexibility elsewhere. The outstanding performance of GBD across three general graph benchmarks and two biochemical graph benchmarks highlights its capability to effectively capture the complexities of real-world graph data. The code will be made available at https://github.com/YH-UtMSB/Graph_Beta_Diffusion",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09654",
        "abstract url": "https://arxiv.org/abs/2406.09654",
        "title": "Coralai: Intrinsic Evolution of Embodied Neural Cellular Automata Ecosystems",
        "rating": "-3.5",
        "keywords": [
            [
                "survival"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents Coralai, a framework for exploring diverse ecosystems of Neural Cellular Automata (NCA). Organisms in Coralai utilize modular, GPU-accelerated Taichi kernels to interact, enact environmental changes, and evolve through local survival, merging, and mutation operations implemented with HyperNEAT and PyTorch. We provide an exploratory experiment implementing physics inspired by slime mold behavior showcasing the emergence of competition between sessile and mobile organisms, cycles of resource depletion and recovery, and symbiosis between diverse organisms. We conclude by outlining future work to discover simulation parameters through measures of multi-scale complexity and diversity. Code for Coralai is available at https://github.com/aidanbx/coralai , video demos are available at https://www.youtube.com/watch?v=NL8IZQY02-8 .",
        "subjects": [
            "cs.NE",
            "cs.LG",
            "cs.MA"
        ],
        "comment": "3 pages, 2 figures. ALIFE 2024 Copenhagen"
    },
    {
        "paper id": "2406.09098",
        "abstract url": "https://arxiv.org/abs/2406.09098",
        "title": "SciKnowEval: Evaluating Multi-level Scientific Knowledge of Large Language Models",
        "rating": "-4",
        "keywords": [
            [
                "depth"
            ],
            [
                "biology"
            ],
            [
                "chemistry"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The burgeoning utilization of Large Language Models (LLMs) in scientific research necessitates advanced benchmarks capable of evaluating their understanding and application of scientific knowledge comprehensively. To address this need, we introduce the SciKnowEval benchmark, a novel framework that systematically evaluates LLMs across five progressive levels of scientific knowledge: studying extensively, inquiring earnestly, thinking profoundly, discerning clearly, and practicing assiduously. These levels aim to assess the breadth and depth of scientific knowledge in LLMs, including knowledge coverage, inquiry and exploration capabilities, reflection and reasoning abilities, ethic and safety considerations, as well as practice proficiency. Specifically, we take biology and chemistry as the two instances of SciKnowEval and construct a dataset encompassing 50K multi-level scientific problems and solutions. By leveraging this dataset, we benchmark 20 leading open-source and proprietary LLMs using zero-shot and few-shot prompting strategies. The results reveal that despite achieving state-of-the-art performance, the proprietary LLMs still have considerable room for improvement, particularly in addressing scientific computations and applications. We anticipate that SciKnowEval will establish a comprehensive standard for benchmarking LLMs in science research and discovery, and promote the development of LLMs that integrate scientific knowledge with strong safety awareness. The dataset and code are publicly available at https://github.com/hicai-zju/sciknoweval .",
        "subjects": [
            "cs.CL"
        ],
        "comment": "48 pages, 2 figures"
    },
    {
        "paper id": "2406.09260",
        "abstract url": "https://arxiv.org/abs/2406.09260",
        "title": "Deep Transformer Network for Monocular Pose Estimation of Ship-Based UAV",
        "rating": "-4",
        "keywords": [
            [
                "6D"
            ],
            [
                "Vehicle",
                "flight"
            ],
            [
                "navigation"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This paper introduces a deep transformer network for estimating the relative 6D pose of a Unmanned Aerial Vehicle (UAV) with respect to a ship using monocular images. A synthetic dataset of ship images is created and annotated with 2D keypoints of multiple ship parts. A Transformer Neural Network model is trained to detect these keypoints and estimate the 6D pose of each part. The estimates are integrated using Bayesian fusion. The model is tested on synthetic data and in-situ flight experiments, demonstrating robustness and accuracy in various lighting conditions. The position estimation error is approximately 0.8\\% and 1.0\\% of the distance to the ship for the synthetic data and the flight experiments, respectively. The method has potential applications for ship-based autonomous UAV landing and navigation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO",
            "eess.IV"
        ],
        "comment": "23 pages, 25 figures, 3 tables"
    },
    {
        "paper id": "2406.09386",
        "abstract url": "https://arxiv.org/abs/2406.09386",
        "title": "SimGen: Simulator-conditioned Driving Scene Generation",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "autonomous driving"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Controllable synthetic data generation can substantially lower the annotation cost of training data in autonomous driving research and development. Prior works use diffusion models to generate driving images conditioned on the 3D object layout. However, those models are trained on small-scale datasets like nuScenes, which lack appearance and layout diversity. Moreover, the trained models can only generate images based on the real-world layout data from the validation set of the same dataset, where overfitting might happen. In this work, we introduce a simulator-conditioned scene generation framework called SimGen that can learn to generate diverse driving scenes by mixing data from the simulator and the real world. It uses a novel cascade diffusion pipeline to address challenging sim-to-real gaps and multi-condition conflicts. A driving video dataset DIVA is collected to enhance the generative diversity of SimGen, which contains over 147.5 hours of real-world driving videos from 73 locations worldwide and simulated driving data from the MetaDrive simulator. SimGen achieves superior generation quality and diversity while preserving controllability based on the text prompt and the layout pulled from a simulator. We further demonstrate the improvements brought by SimGen for synthetic data augmentation on the BEV detection and segmentation task and showcase its capability in safety-critical data generation. Code, data, and models will be made available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09524",
        "abstract url": "https://arxiv.org/abs/2406.09524",
        "title": "Structure Editor for Building Software Models",
        "rating": "-4",
        "keywords": [
            [
                "Alloy"
            ],
            [
                "grammar"
            ]
        ],
        "abstract": "Alloy is well known a declarative modeling language. A key strength of Alloy is its scenario finding toolset, the Analyzer, which allows users to explore all valid scenarios that adhere to the model's constraints up to a user-provided scope. Despite the Analyzer, Alloy is still difficult for novice users to learn and use. A recent empirical study of over 93,000 new user models reveals that users have trouble from the very start: nearly a third of the models novices write fail to compile. We believe that the issue is that Alloy's grammar and type information is passively relayed to the user despite this information outlining a narrow path for how to compose valid formulas. In this paper, we outline a proof-of-concept for a structure editor for Alloy in which user's build their models using block based inputs, rather than free typing, which by design prevents compilation errors.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09266",
        "abstract url": "https://arxiv.org/abs/2406.09266",
        "title": "SySTeC: A Symmetric Sparse Tensor Compiler",
        "rating": "-5",
        "keywords": [
            [
                "graph"
            ],
            [
                "chemistry"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Symmetric and sparse tensors arise naturally in many domains including linear algebra, statistics, physics, chemistry, and graph theory. Symmetric tensors are equal to their transposes, so in the $n$-dimensional case we can save up to a factor of $n!$ by avoiding redundant operations. Sparse tensors, on the other hand, are mostly zero, and we can save asymptotically by processing only nonzeros. Unfortunately, specializing for both symmetry and sparsity at the same time is uniquely challenging. Optimizing for symmetry requires consideration of $n!$ transpositions of a triangular kernel, which can be complex and error prone. Considering multiple transposed iteration orders and triangular loop bounds also complicates iteration through intricate sparse tensor formats. Additionally, since each combination of symmetry and sparse tensor formats requires a specialized implementation, this leads to a combinatorial number of cases. A compiler is needed, but existing compilers cannot take advantage of both symmetry and sparsity within the same kernel. In this paper, we describe the first compiler which can automatically generate symmetry-aware code for sparse or structured tensor kernels. We introduce a taxonomy for symmetry in tensor kernels, and show how to target each kind of symmetry. Our implementation demonstrates significant speedups ranging from 1.36x for SSYMV to 30.4x for a 5-dimensional MTTKRP over the non-symmetric state of the art.",
        "subjects": [
            "cs.MS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08843",
        "abstract url": "https://arxiv.org/abs/2406.08843",
        "title": "Input-Gen: Guided Generation of Stateful Inputs for Testing, Tuning, and Training",
        "rating": "-10",
        "keywords": [],
        "abstract": "The size and complexity of software applications is increasing at an accelerating pace. Source code repositories (along with their dependencies) require vast amounts of labor to keep them tested, maintained, and up to date. As the discipline now begins to also incorporate automatically generated programs, automation in testing and tuning is required to keep up with the pace - let alone reduce the present level of complexity. While machine learning has been used to understand and generate code in various contexts, machine learning models themselves are trained almost exclusively on static code without inputs, traces, or other execution time information. This lack of training data limits the ability of these models to understand real-world problems in software. In this work we show that inputs, like code, can be generated automatically at scale. Our generated inputs are stateful, and appear to faithfully reproduce the arbitrary data structures and system calls required to rerun a program function. By building our tool within the compiler, it both can be applied to arbitrary programming languages and architectures and can leverage static analysis and transformations for improved performance. Our approach is able to produce valid inputs, including initial memory states, for 90% of the ComPile dataset modules we explored, for a total of 21.4 million executable functions. Further, we find that a single generated input results in an average block coverage of 37%, whereas guided generation of five inputs improves it to 45%.",
        "subjects": [
            "cs.SE",
            "cs.PF",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08844",
        "abstract url": "https://arxiv.org/abs/2406.08844",
        "title": "Equilibrium Selection for Multi-agent Reinforcement Learning: A Unified Framework",
        "rating": "-10",
        "keywords": [],
        "abstract": "While there are numerous works in multi-agent reinforcement learning (MARL), most of them focus on designing algorithms and proving convergence to a Nash equilibrium (NE) or other equilibrium such as coarse correlated equilibrium. However, NEs can be non-unique and their performance varies drastically. Thus, it is important to design algorithms that converge to Nash equilibrium with better rewards or social welfare. In contrast, classical game theory literature has extensively studied equilibrium selection for multi-agent learning in normal-form games, demonstrating that decentralized learning algorithms can asymptotically converge to potential-maximizing or Pareto-optimal NEs. These insights motivate this paper to investigate equilibrium selection in the MARL setting. We focus on the stochastic game model, leveraging classical equilibrium selection results from normal-form games to propose a unified framework for equilibrium selection in stochastic games. The proposed framework is highly modular and can extend various learning rules and their corresponding equilibrium selection results from normal-form games to the stochastic game setting.",
        "subjects": [
            "cs.GT",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08870",
        "abstract url": "https://arxiv.org/abs/2406.08870",
        "title": "MEGA: Maximum-Entropy Genetic Algorithm for Router Nodes Placement in Wireless Mesh Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Over the past decade, Wireless Mesh Networks (WMNs) have seen significant advancements due to their simple deployment, cost-effectiveness, ease of implementation and reliable service coverage. However, despite these advantages, the placement of nodes in WMNs presents a critical challenge that significantly impacts their performance. This issue is recognized as an NP-hard problem, underscoring the necessity of development optimization algorithms, such as heuristic and metaheuristic approaches. This motivates us to develop the Maximum Entropy Genetic Algorithm (MEGA) to address the issue of mesh router node placement in WMNs. To assess the proposed method, we conducted experiments across various scenarios with different settings, focusing on key metrics such as network connectivity and user coverage. The simulation results show a comparison of MEGA with other prominent algorithms, such as the Coyote Optimization Algorithm (COA), Firefly Algorithm (FA), Genetic Algorithm (GA), and Particle Swarm Optimization (PSO), revealing MEGA's effectiveness and usability in determining optimal locations for mesh routers.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted to IEEE Access"
    },
    {
        "paper id": "2406.08871",
        "abstract url": "https://arxiv.org/abs/2406.08871",
        "title": "Superconductor bistable vortex memory for data storage and in-memory computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Superconductor electronics (SCE) is a promising complementary and beyond CMOS technology. However, despite its practical benefits, the realization of SCE logic faces a significant challenge due to the absence of dense and scalable nonvolatile memory designs. While various nonvolatile memory technologies, including Non-destructive readout, vortex transitional memory (VTM), and magnetic memory, have been explored, achieving a superconductor random-access memory (RAM) crossbar array remains challenging. This paper introduces a novel, nonvolatile, high-density, and scalable VTM cell design for SCE applications. Our proposed design addresses scaling issues while boasting zero static power consumption characteristics. Our design leverages current summation, enabling analog multiply-accumulate operations -an essential feature for many in-memory computational tasks. We demonstrate the efficacy of our approach with a 32 x 32 superconductor memory array operating at 20 GHz. This design effectively addresses scaling issues and utilizes current summation that can be used for analog multiply-accumulate operations. Additionally, we showcase the accumulation property of the memory through analog simulations conducted on an 8 x 8 superconductor crossbar array.",
        "subjects": [
            "cond-mat.supr-con",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08875",
        "abstract url": "https://arxiv.org/abs/2406.08875",
        "title": "NICER: A New and Improved Consumed Endurance and Recovery Metric to Quantify Muscle Fatigue of Mid-Air Interactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Natural gestures are crucial for mid-air interaction, but predicting and managing muscle fatigue is challenging. Existing torque-based models are limited in their ability to model above-shoulder interactions and to account for fatigue recovery. We introduce a new hybrid model, NICER, which combines a torque-based approach with a new term derived from the empirical measurement of muscle contraction and a recovery factor to account for decreasing fatigue during rest. We evaluated NICER in a mid-air selection task using two interaction methods with different degrees of perceived fatigue. Results show that NICER can accurately model above-shoulder interactions as well as reflect fatigue recovery during rest periods. Moreover, both interaction methods show a stronger correlation with subjective fatigue measurement (r = 0.978/0.976) than a previous model, Cumulative Fatigue (r = 0.966/ 0.923), confirming that NICER is a powerful analytical tool to predict fatigue across a variety of gesture-based interactive applications.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08879",
        "abstract url": "https://arxiv.org/abs/2406.08879",
        "title": "Modeling Common Cause Failure in Dynamic PRA",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we propose a dynamic model of Common Cause Failures (CCF) that allows to generate common cause events in time. The proposed model is a generalization of Binomial Failure Rate Model (Atwood model) that can generate staggered failures of multiple components due to a common cause. We implement the model using statechart formalism, a similar implementation can be adopted in other modeling languages like Petri Nets or Hybrid Stochastic Automata. The presented model was integrated in a Dynamic PRA study.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08891",
        "abstract url": "https://arxiv.org/abs/2406.08891",
        "title": "Robust Information Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "Beyond effectiveness, the robustness of an information retrieval (IR) system is increasingly attracting attention. When deployed, a critical technology such as IR should not only deliver strong performance on average but also have the ability to handle a variety of exceptional situations. In recent years, research into the robustness of IR has seen significant growth, with numerous researchers offering extensive analyses and proposing myriad strategies to address robustness challenges. In this tutorial, we first provide background information covering the basics and a taxonomy of robustness in IR. Then, we examine adversarial robustness and out-of-distribution (OOD) robustness within IR-specific contexts, extensively reviewing recent progress in methods to enhance robustness. The tutorial concludes with a discussion on the robustness of IR in the context of large language models (LLMs), highlighting ongoing challenges and promising directions for future research. This tutorial aims to generate broader attention to robustness issues in IR, facilitate an understanding of the relevant literature, and lower the barrier to entry for interested researchers and practitioners.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "accepted by SIGIR2024 Tutorial"
    },
    {
        "paper id": "2406.08916",
        "abstract url": "https://arxiv.org/abs/2406.08916",
        "title": "On additive codes over finite fields",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this article we prove a Griesmer type bound for additive codes over finite fields. This new bound gives an upper bound on the length of maximum distance separable (MDS) codes, codes which attain the Singleton bound. We will also consider codes to be MDS if they obtain the fractional Singleton bound, due to Huffman. We prove that this bound in the fractional case can be obtained by codes whose length surpasses the length of the longest known codes in the non-fractional case. We also provide some exhaustive computational results over small fields and dimensions.",
        "subjects": [
            "cs.IT",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08923",
        "abstract url": "https://arxiv.org/abs/2406.08923",
        "title": "Stencil Computations on AMD and Nvidia Graphics Processors: Performance and Tuning Strategies",
        "rating": "-10",
        "keywords": [],
        "abstract": "Over the last ten years, graphics processors have become the de facto accelerator for data-parallel tasks in various branches of high-performance computing, including machine learning and computational sciences. However, with the recent introduction of AMD-manufactured graphics processors to the world's fastest supercomputers, tuning strategies established for previous hardware generations must be re-evaluated. In this study, we evaluate the performance and energy efficiency of stencil computations on modern datacenter graphics processors, and propose a tuning strategy for fusing cache-heavy stencil kernels. The studied cases comprise both synthetic and practical applications, which involve the evaluation of linear and nonlinear stencil functions in one to three dimensions. Our experiments reveal that AMD and Nvidia graphics processors exhibit key differences in both hardware and software, necessitating platform-specific tuning to reach their full computational potential.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "21 pages, 14 figures. Submitted to Concurrency and Computation: Practice and Experience"
    },
    {
        "paper id": "2406.08952",
        "abstract url": "https://arxiv.org/abs/2406.08952",
        "title": "Self-orthogonal flags of codes and translation of flags of algebraic geometry codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "A flag $C_0 \\subsetneq C_1 \\cdots \\subsetneq C_s \\subsetneq {\\mathbb F}_q^n $ of linear codes is said to be self-orthogonal if the duals of the codes in the flag satisfy $C_{i}^\\perp=C_{s-i}$, and it is said to satisfy the isometry-dual property with respect to an isometry vector ${\\bf x}$ if $C_i^\\perp={\\bf x} C_{s-i}$ for $i=1, \\dots, s$. We characterize complete (i.e. $s=n$) flags with the isometry-dual property by means of the existence of a word with non-zero coordinates in a certain linear subspace of ${\\mathbb F}_q^n$. For flags of algebraic geometry (AG) codes we prove a so-called translation property of isometry-dual flags and give a construction of complete self-orthogonal flags, providing examples of self-orthogonal flags over some maximal function fields. At the end we characterize the divisors giving the isometry-dual property and the related isometry vectors showing that for each function field there is only a finite number of isometry vectors and that they are related by cyclic repetitions.",
        "subjects": [
            "cs.IT",
            "math.AG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.08987",
        "abstract url": "https://arxiv.org/abs/2406.08987",
        "title": "Towards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators",
        "rating": "-10",
        "keywords": [],
        "abstract": "Multi-objective optimization problems (MOPs) are prevalent in various real-world applications, necessitating sophisticated solutions that balance conflicting objectives. Traditional evolutionary algorithms (EAs), while effective, often rely on domain-specific expert knowledge and iterative tuning, which can impede innovation when encountering novel MOPs. Very recently, the emergence of Large Language Models (LLMs) has revolutionized software engineering by enabling the autonomous development and refinement of programs. Capitalizing on this advancement, we propose a new LLM-based framework for evolving EA operators, designed to address a wide array of MOPs. This framework facilitates the production of EA operators without the extensive demands for expert intervention, thereby streamlining the design process. To validate the efficacy of our approach, we have conducted extensive empirical studies across various categories of MOPs. The results demonstrate the robustness and superior performance of our LLM-evolved operators.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "14 pages, 5 figures, 5 tables"
    },
    {
        "paper id": "2406.09001",
        "abstract url": "https://arxiv.org/abs/2406.09001",
        "title": "Evaluation of Sparse Acoustic Array Geometries for the Application in Indoor Localization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Angle-of-Arrival estimation technology, with its potential advantages, emerges as an intriguing choice for indoor localization. Notably, it holds the promise of reducing installation costs. In contrast to ToF/TDoA based systems, AoA-based approaches require a reduced number of nodes for effective localization. This characteristic establishes a trade-off between installation costs and the complexity of hardware and software. Moreover, the appeal of acoustic localization is further heightened by its capacity to provide cost-effective hardware solutions while maintaining a high degree of accuracy. Consequently, acoustic AoA estimation technology stands out as a feasible and compelling option in the field of indoor localization. Sparse arrays additionally have the ability to estimate the DoA of more sources than available sensors by placing sensors in a specific geometry. In this contribution, we introduce a measurement platform designed to evaluate various sparse array geometries experimentally. The acoustic microphone array comprises 64 microphones arranged in an 8x8 grid, following an Uniform Rectangular Array (URA) configuration, with a grid spacing of 8.255 mm. This configuration achieves a spatial Nyquist frequency of approximately 20.8 kHz in the acoustic domain at room temperature. Notably, the array exhibits a mean spherical error of 1.26\u00b0 when excluding higher elevation angles. The platform allows for masking sensors to simulate sparse array configurations. We assess four array geometries through simulations and experimental data, identifying the Open-Box and Nested array geometries as robust candidates. Additionally, we demonstrate the array's capability to concurrently estimate the directions of three emitting sources using experimental data, employing waveforms consisting of orthogonal codes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted for review to the IEEE Journal of Indoor and Seamless Positioning and Navigation (J-ISPIN) in April 24"
    },
    {
        "paper id": "2406.09022",
        "abstract url": "https://arxiv.org/abs/2406.09022",
        "title": "Towards Unified AI Models for MU-MIMO Communications: A Tensor Equivariance Framework",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose a unified framework based on equivariance for the design of artificial intelligence (AI)-assisted technologies in multi-user multiple-input-multiple-output (MU-MIMO) systems. We first provide definitions of multidimensional equivariance, high-order equivariance, and multidimensional invariance (referred to collectively as tensor equivariance). On this basis, by investigating the design of precoding and user scheduling, which are key techniques in MU-MIMO systems, we delve deeper into revealing tensor equivariance of the mappings from channel information to optimal precoding tensors, precoding auxiliary tensors, and scheduling indicators, respectively. To model mappings with tensor equivariance, we propose a series of plug-and-play tensor equivariant neural network (TENN) modules, where the computation involving intricate parameter sharing patterns is transformed into concise tensor operations. Building upon TENN modules, we propose the unified tensor equivariance framework that can be applicable to various communication tasks, based on which we easily accomplish the design of corresponding AI-assisted precoding and user scheduling schemes. Simulation results demonstrate that the constructed precoding and user scheduling methods achieve near-optimal performance while exhibiting significantly lower computational complexity and generalization to inputs with varying sizes across multiple dimensions. This validates the superiority of TENN modules and the unified framework.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2406.09037",
        "abstract url": "https://arxiv.org/abs/2406.09037",
        "title": "Evaluating Privacy, Security, and Trust Perceptions in Conversational AI: A Systematic Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Conversational AI (CAI) systems which encompass voice- and text-based assistants are on the rise and have been largely integrated into people's everyday lives. Despite their widespread adoption, users voice concerns regarding privacy, security and trust in these systems. However, the composition of these perceptions, their impact on technology adoption and usage and the relationship between privacy, security and trust perceptions in the CAI context remain open research challenges. This study contributes to the field by conducting a Systematic Literature Review and offers insights into the current state of research on privacy, security and trust perceptions in the context of CAI systems. The review covers application fields and user groups and sheds light on empirical methods and tools used for assessment. Moreover, it provides insights into the reliability and validity of privacy, security and trust scales, as well as extensively investigating the subconstructs of each item as well as additional concepts which are concurrently collected. We point out that the perceptions of trust, privacy and security overlap based on the subconstructs we identified. While the majority of studies investigate one of these concepts, only a few studies were found exploring privacy, security and trust perceptions jointly. Our research aims to inform on directions to develop and use reliable scales for users' privacy, security and trust perceptions and contribute to the development of trustworthy CAI systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "39 pages, 4 figures"
    },
    {
        "paper id": "2406.09053",
        "abstract url": "https://arxiv.org/abs/2406.09053",
        "title": "Joint Channel Estimation and Prediction for Massive MIMO with Frequency Hopping Sounding",
        "rating": "-10",
        "keywords": [],
        "abstract": "In massive multiple-input multiple-output (MIMO) systems, the downlink transmission performance heavily relies on accurate channel state information (CSI). Constrained by the transmitted power, user equipment always transmits sounding reference signals (SRSs) to the base station through frequency hopping, which will be leveraged to estimate uplink CSI and subsequently predict downlink CSI. This paper aims to investigate joint channel estimation and prediction (JCEP) for massive MIMO with frequency hopping sounding (FHS). Specifically, we present a multiple-subband (MS) delay-angle-Doppler (DAD) domain channel model with off-grid basis to tackle the energy leakage problem. Furthermore, we formulate the JCEP problem with FHS as a multiple measurement vector (MMV) problem, facilitating the sharing of common CSI across different subbands. To solve this problem, we propose an efficient Off-Grid-MS hybrid message passing (HMP) algorithm under the constrained Bethe free energy (BFE) framework. Aiming to address the lack of prior CSI in practical scenarios, the proposed algorithm can adaptively learn the hyper-parameters of the channel by minimizing the corresponding terms in the BFE expression. To alleviate the complexity of channel hyper-parameter learning, we leverage the approximations of the off-grid matrices to simplify the off-grid hyper-parameter estimation. Numerical results illustrate that the proposed algorithm can effectively mitigate the energy leakage issue and exploit the common CSI across different subbands, acquiring more accurate CSI compared to state-of-the-art counterparts.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2406.09058",
        "abstract url": "https://arxiv.org/abs/2406.09058",
        "title": "Environment-Aware Codebook Design for RIS-Assisted MU-MISO Communications: Implementation and Performance Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reconfigurable intelligent surface (RIS) provides a new electromagnetic response control solution, which can proactively reshape the characteristics of wireless channel environments. In RIS-assisted communication systems, the acquisition of channel state information (CSI) and the optimization of reflecting coefficients constitute major design challenges. To address these issues, codebook-based solutions have been developed recently, which, however, are mostly environment-agnostic. In this paper, a novel environment-aware codebook protocol is proposed, which can significantly reduce both pilot overhead and computational complexity, while maintaining expected communication performance. Specifically, first of all, a channel training framework is introduced to divide the training phase into several blocks. In each block, we directly estimate the composite end-to-end channel and focus only on the transmit beamforming. Second, we propose an environment-aware codebook generation scheme, which first generates a group of channels based on statistical CSI, and then obtains their corresponding RIS configuration by utilizing the alternating optimization (AO) method offline. In each online training block, the RIS is configured based on the corresponding codeword in the environment-aware codebook, and the optimal codeword resulting in the highest sum rate is adopted for assisting in the downlink data transmission. Third, we analyze the theoretical performance of the environment-aware codebook-based protocol taking into account the channel estimation errors. Finally, numerical simulations are provided to verify our theoretical analysis and the performance of the proposed scheme. In particular, the simulation results demonstrate that our protocol is more competitive than conventional environment-agnostic codebooks.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "36 pages, 12 figures, 2 tables, accepted by IEEE TCOM. arXiv admin note: text overlap with arXiv:2404.00265"
    },
    {
        "paper id": "2406.09065",
        "abstract url": "https://arxiv.org/abs/2406.09065",
        "title": "Engineering Digital Systems for Humanity: Challenges and Opportunities",
        "rating": "-10",
        "keywords": [],
        "abstract": "As testified by new regulations like the European AI act, the worries about the societal impact of (autonomous) software technologies are becoming of public concern. Social and human values, besides the traditional software behaviour and quality, are increasingly recognized as important for sustainability and long-term well-being. In this paper, we identify the macro and technological challenges and opportunities of present and future digital systems that should be engineered for humanity. Our specific perspective in identifying the challenges is to focus on humans and on their role in their co-existence with digital systems. The first challenge considers humans in a proactive role when interacting with the digital systems, i.e., taking initiative in making things happening instead of reacting to events. The second concerns humans having an active role in the interaction with the digital systems i.e., on humans that interact with digital systems as a reaction to events. The third challenge focuses on humans that have a passive role i.e., they experience, enjoy or even suffer the decisions and/or actions of digital systems. Two further transversal challenges are considered: the duality of trust and trustworthiness and the compliance to legislation that both may seriously affect the deployment and use of digital systems.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09066",
        "abstract url": "https://arxiv.org/abs/2406.09066",
        "title": "Impermanent Identifiers: Enhanced Source Code Comprehension and Refactoring",
        "rating": "-10",
        "keywords": [],
        "abstract": "In response to the prevailing challenges in contemporary software development, this article introduces an innovative approach to code augmentation centered around Impermanent Identifiers. The primary goal is to enhance the software development experience by introducing dynamic identifiers that adapt to changing contexts, facilitating more efficient interactions between developers and source code, ultimately advancing comprehension, maintenance, and collaboration in software development. Additionally, this study rigorously evaluates the adoption and acceptance of Impermanent Identifiers within the software development landscape. Through a comprehensive empirical examination, we investigate how developers perceive and integrate this approach into their daily programming practices, exploring perceived benefits, potential barriers, and factors influencing its adoption. In summary, this article charts a new course for code augmentation, proposing Impermanent Identifiers as its cornerstone while assessing their feasibility and acceptance among developers. This interdisciplinary research seeks to contribute to the continuous improvement of software development practices and the progress of code augmentation technology.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "to be published in The Journal of Systems & Software"
    },
    {
        "paper id": "2406.09078",
        "abstract url": "https://arxiv.org/abs/2406.09078",
        "title": "ONNX-to-Hardware Design Flow for Adaptive Neural-Network Inference on FPGAs",
        "rating": "-10",
        "keywords": [],
        "abstract": "The challenges involved in executing neural networks (NNs) at the edge include providing diversity, flexibility, and sustainability. That implies, for instance, supporting evolving applications and algorithms energy-efficiently. Using hardware or software accelerators can deliver fast and efficient computation of the NNs, while flexibility can be exploited to support long-term adaptivity. Nonetheless, handcrafting an NN for a specific device, despite the possibility of leading to an optimal solution, takes time and experience, and that's why frameworks for hardware accelerators are being developed. This work, starting from a preliminary semi-integrated ONNX-to-hardware toolchain [21], focuses on enabling approximate computing leveraging the distinctive ability of the original toolchain to favor adaptivity. The goal is to allow lightweight adaptable NN inference on FPGAs at the edge.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Proceedings of the XXIV International Conference on Embedded Computer Systems: Architectures, Modeling and Simulation (SAMOS), June 29 - July 4, 2024. arXiv admin note: text overlap with arXiv:2309.13321"
    },
    {
        "paper id": "2406.09085",
        "abstract url": "https://arxiv.org/abs/2406.09085",
        "title": "A Symbolic Computing Perspective on Software Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Symbolic mathematical computing systems have served as a canary in the coal mine of software systems for more than sixty years. They have introduced or have been early adopters of programming language ideas such ideas as dynamic memory management, arbitrary precision arithmetic and dependent types. These systems have the feature of being highly complex while at the same time operating in a domain where results are well-defined and clearly verifiable. These software systems span multiple layers of abstraction with concerns ranging from instruction scheduling and cache pressure up to algorithmic complexity of constructions in algebraic geometry. All of the major symbolic mathematical computing systems include low-level code for arithmetic, memory management and other primitives, a compiler or interpreter for a bespoke programming language, a library of high level mathematical algorithms, and some form of user interface. Each of these parts invokes multiple deep issues. We present some lessons learned from this environment and free flowing opinions on topics including: * Portability of software across architectures and decades; * Infrastructure to embrace and infrastructure to avoid; * Choosing base abstractions upon which to build; * How to get the most out of a small code base; * How developments in compilers both to optimise and to validate code have always been and remain of critical importance, with plenty of remaining challenges; * The way in which individuals including in particular Alan Mycroft who has been able to span from hand-crafting Z80 machine code up to the most abstruse high level code analysis techniques are needed, and * Why it is important to teach full-stack thinking to the next generation.",
        "subjects": [
            "cs.SC",
            "cs.MS",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09088",
        "abstract url": "https://arxiv.org/abs/2406.09088",
        "title": "Dyadic obligations: proofs and countermodels via hypersequents",
        "rating": "-10",
        "keywords": [],
        "abstract": "The basic system E of dyadic deontic logic proposed by \u00c5qvist offers a simple solution to contrary-to-duty paradoxes and allows to represent norms with exceptions. We investigate E from a proof-theoretical viewpoint. We propose a hypersequent calculus with good properties, the most important of which is cut-elimination, and the consequent subformula property. The calculus is refined to obtain a decision procedure for E and an effective countermodel computation in case of failure of proof search. Using the refined calculus, we prove that validity in E is Co-NP and countermodels have polynomial size.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09097",
        "abstract url": "https://arxiv.org/abs/2406.09097",
        "title": "Adaptive Actor-Critic Based Optimal Regulation for Drift-Free Uncertain Nonlinear Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a continuous-time adaptive actor-critic reinforcement learning (RL) controller is developed for drift-free nonlinear systems. Practical examples of such systems are image-based visual servoing (IBVS) and wheeled mobile robots (WMR), where the system dynamics includes a parametric uncertainty in the control effectiveness matrix with no drift term. The uncertainty in the input term poses a challenge for developing a continuous-time RL controller using existing methods. In this paper, an actor-critic or synchronous policy iteration (PI)-based RL controller is presented with a concurrent learning (CL)-based parameter update law for estimating the unknown parameters of the control effectiveness matrix. An infinite-horizon value function minimization objective is achieved by regulating the current states to the desired with near-optimal control efforts. The proposed controller guarantees closed-loop stability and simulation results validate the proposed theory using IBVS and WMR examples.",
        "subjects": [
            "eess.SY",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09099",
        "abstract url": "https://arxiv.org/abs/2406.09099",
        "title": "Towards a Function-as-a-Service Choreographic Programming Language: Examples and Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Choreographic Programming (CP) is a language paradigm whereby software artefacts, called choreographies, specify the behaviour of communicating participants. CP is famous for its correctness-by-construction approach to the development of concurrent, distributed systems. In this paper, we illustrate FaaSChal, a proposal for a CP language tailored for the case of serverless Function-as-a-Service (FaaS). In FaaS, developers define a distributed architecture as a collection of stateless functions, leaving to the serverless platform the management of deployment and scaling. We provide a first account of a CP language tailored for the FaaS case via examples that present some of its relevant features, including projection. In addition, we showcase a novel application of CP. We use the choreography as a source to extract information on the infrastructural relations among functions so that we can synthesise policies that strive to minimise their latency while guaranteeing the respect of user-defined constraints.",
        "subjects": [
            "cs.PL",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09150",
        "abstract url": "https://arxiv.org/abs/2406.09150",
        "title": "Reducing the Space Used by the Sieve of Eratosthenes When Factoring",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a version of the sieve of Eratosthenes that can factor all integers $\\le x$ in $O(x \\log\\log x)$ arithmetic operations using at most $O(\\sqrt{x}/\\log\\log x)$ bits of space. This is an improved space bound under the condition that the algorithm takes at most $O(x\\log\\log x)$ time. We also show our algorithm performs well in practice.",
        "subjects": [
            "cs.DS",
            "math.NT"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09192",
        "abstract url": "https://arxiv.org/abs/2406.09192",
        "title": "Joint Power Allocation and Beamforming Design for Active IRS-Aided Directional Modulation Secure Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Since the secrecy rate (SR) performance improvement obtained by secure directional modulation (DM) network is limited, an active intelligent reflective surface (IRS)-assisted DM network is considered to attain a high SR. To address the SR maximization problem, a novel method based on Lagrangian dual transform and closed-form fractional programming algorithm (LDT-CFFP) is proposed, where the solutions to base station (BS) beamforming vectors and IRS reflection coefficient matrix are achieved. However, the computational complexity of LDT-CFFP method is high . To reduce its complexity, a blocked IRS-assisted DM network is designed. To meet the requirements of the network performance, a power allocation (PA) strategy is proposed and adopted in the system. Specifically, the system power between BS and IRS, as well as the transmission power for confidential messages (CM) and artificial noise (AN) from the BS, are allocated separately. Then we put forward null-space projection (NSP) method, maximum-ratio-reflecting (MRR) algorithm and PA strategy (NSP-MRR-PA) to solve the SR maximization problem. The CF solutions to BS beamforming vectors and IRS reflection coefficient matrix are respectively attained via NSP and MRR algorithms. For the PA factors, we take advantage of exhaustive search (ES) algorithm, particle swarm optimization (PSO) and simulated annealing (SA) algorithm to search for the solutions. From simulation results, it is verified that the LDT-CFFP method derives a higher SR gain over NSP-MRR-PA method. For NSP-MRR-PA method, the number of IRS units in each block possesses a significant SR performance. In addition, the application PA strategies, namely ES, PSO, SA methods outperforms the other PA strategies with fixed PA factors.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Directional modulation, active intelligent reflective surface, Lagrangian dual transformation, fractional programming, power allocation"
    },
    {
        "paper id": "2406.09197",
        "abstract url": "https://arxiv.org/abs/2406.09197",
        "title": "A Hybrid Modelling of a Water and Air Injector in a Subsonic Icing Wind Tunnel",
        "rating": "-10",
        "keywords": [],
        "abstract": "The study of droplet generation in wind tunnels in conducting icing experiments is of great importance in determining ice formation on structures or surfaces, where parameters such as Liquid Water Content (LWC) and Median Volumetric Diameter (MVD) play a relevant role. The measurement of these parameters requires specialised instrumentation. In this paper, several experiments have been carried out in a subsonic wind tunnel facility to study the parameters that are part of the icing process in structures. Furthermore, a mathematical modelling of the constituent subsystems of the plant study that allow us to have a comprehensive understanding of the behaviour of the system is developed using techniques based on first principles and machine learning techniques such as regression trees and neural networks. The simulation results show that the implementation of the model manages to obtain prominent expected values of LWC and MVD within the range of values obtained in the real experimental data.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "11 pages, 14 figures"
    },
    {
        "paper id": "2406.09235",
        "abstract url": "https://arxiv.org/abs/2406.09235",
        "title": "Variational Mode Decomposition as Trusted Data Augmentation in ML-based Power System Stability Assessment",
        "rating": "-10",
        "keywords": [],
        "abstract": "Balanced data is required for deep neural networks (DNNs) when learning to perform power system stability assessment. However, power system measurement data contains relatively few events from where power system dynamics can be learnt. To mitigate this imbalance, we propose a novel data augmentation strategy preserving the dynamic characteristics to be learnt. The augmentation is performed using Variational Mode Decomposition. The detrended and the augmented data are tested for distributions similarity using Kernel Maximum Mean Discrepancy test. In addition, the effectiveness of the augmentation methodology is validated via training an Encoder DNN utilizing original data, testing using the augmented data, and evaluating the Encoder's performance employing several metrics.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "To be presented in SYSID 2024"
    },
    {
        "paper id": "2406.09255",
        "abstract url": "https://arxiv.org/abs/2406.09255",
        "title": "Compact Parallel Hash Tables on the GPU",
        "rating": "-10",
        "keywords": [],
        "abstract": "On the GPU, hash table operation speed is determined in large part by cache line efficiency, and state-of-the-art hashing schemes thus divide tables into cache line-sized buckets. This raises the question whether performance can be further improved by increasing the number of entries that fit in such buckets. Known compact hashing techniques have not yet been adapted to the massively parallel setting, nor have they been evaluated on the GPU. We consider a compact version of bucketed cuckoo hashing, and a version of compact iceberg hashing suitable for the GPU. We discuss the tables from a theoretical perspective, and provide an open source implementation of both schemes in CUDA for comparative benchmarking. In terms of performance, the state-of-the-art cuckoo hashing benefits from compactness on lookups and insertions (most experiments show at least 10-20% increase in throughput), and the iceberg table benefits significantly, to the point of being comparable to compact cuckoo hashing--while supporting performant dynamic operation.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09281",
        "abstract url": "https://arxiv.org/abs/2406.09281",
        "title": "Computing congruences of finite inverse semigroups",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we present an algorithm for computing a congruence on an inverse semigroup from a collection of generating pairs. This algorithm uses a myriad of techniques from computational group theory, automata, and the theory of inverse semigroups. An initial implementation of this algorithm outperforms existing implementations by several orders of magnitude.",
        "subjects": [
            "math.GR",
            "cs.DS"
        ],
        "comment": "16 pages, 3 figures"
    },
    {
        "paper id": "2406.09300",
        "abstract url": "https://arxiv.org/abs/2406.09300",
        "title": "Nested Sequents for Quasi-transitive Modal Logics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Previous works by Gor\u00e9, Postniece and Tiu have provided sound and cut-free complete proof systems for modal logics extended with path axioms using the formalism of nested sequent. Our aim is to provide (i) a constructive cut-elimination procedure and (ii) alternative modular formulations for these systems. We present our methodology to achieve these two goals on a subclass of path axioms, namely quasi-transitivity axioms.",
        "subjects": [
            "cs.LO",
            "math.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09302",
        "abstract url": "https://arxiv.org/abs/2406.09302",
        "title": "The reflection complexity of sequences over finite alphabets",
        "rating": "-10",
        "keywords": [],
        "abstract": "In combinatorics on words, the well-studied factor complexity function $\u03c1_{\\bf x}$ of a sequence ${\\bf x}$ over a finite alphabet counts, for any nonnegative integer $n$, the number of distinct length-$n$ factors of ${\\bf x}$. In this paper, we introduce the \\emph{reflection complexity} function $r_{\\bf x}$ to enumerate the factors occurring in a sequence ${\\bf x}$, up to reversing the order of symbols in a word. We introduce and prove results on $r_{\\bf x}$ regarding its growth properties and relationship with other complexity functions. We prove that if ${\\bf x}$ is $k$-automatic, then $r_{\\bf x}$ is computably $k$-regular, and we use the software {\\tt Walnut} to evaluate the reflection complexity of automatic sequences, such as the Thue--Morse sequence. We prove a Morse--Hedlund-type result characterizing eventually periodic sequences in terms of their reflection complexity, and we deduce a characterization of Sturmian sequences. Furthermore, we investigate the reflection complexity of episturmian, $(s+1)$-dimensional billiard, and Rote sequences. There are still many unanswered questions about this measure.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09328",
        "abstract url": "https://arxiv.org/abs/2406.09328",
        "title": "Learnable Fractal Flames",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work presents a differentiable rendering approach that allows latent fractal flame parameters to be learned from image supervision. The approach extends the state-of-the-art in differentiable fractal rendering through support for color images, non-linear generator functions, and multi-fractal compositions. With these additions, differentiable rendering is now a viable tool for the generation of fractal artwork.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09332",
        "abstract url": "https://arxiv.org/abs/2406.09332",
        "title": "RoTipBot: Robotic Handling of Thin and Flexible Objects using Rotatable Tactile Sensors",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces RoTipBot, a novel robotic system for handling thin, flexible objects. Different from previous works that are limited to singulating them using suction cups or soft grippers, RoTipBot can grasp and count multiple layers simultaneously, emulating human handling in various environments. Specifically, we develop a novel vision-based tactile sensor named RoTip that can rotate and sense contact information around its tip. Equipped with two RoTip sensors, RoTipBot feeds multiple layers of thin, flexible objects into the centre between its fingers, enabling effective grasping and counting. RoTip's tactile sensing ensures both fingers maintain good contact with the object, and an adjustment approach is designed to allow the gripper to adapt to changes in the object. Extensive experiments demonstrate the efficacy of the RoTip sensor and the RoTipBot approach. The results show that RoTipBot not only achieves a higher success rate but also grasps and counts multiple layers simultaneously -- capabilities not possible with previous methods. Furthermore, RoTipBot operates up to three times faster than state-of-the-art methods. The success of RoTipBot paves the way for future research in object manipulation using mobilised tactile sensors. All the materials used in this paper are available at \\url{https://sites.google.com/view/rotipbot}.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20 pages, 21 figures"
    },
    {
        "paper id": "2406.09372",
        "abstract url": "https://arxiv.org/abs/2406.09372",
        "title": "Investigation of Adaptive Hotspot-Aware Indexes for Oscillating Write-Heavy and Read-Heavy Workloads -- An Experimental Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "HTAP systems are designed to handle transactional and analytical workloads. Besides a mixed workload at any given time, the workload can also change over time. A popular kind of continuously changing workload is one that oscillates between being write-heavy and being read-heavy. These oscillating workloads can be observed in many applications. Indexes, e.g., the B+-tree and the LSM-Tree cannot perform equally well all the time. Conventional adaptive indexing does not solve this issue either as it focuses on adapting in one direction. This paper investigates how to support oscillating workloads with adaptive indexes that adapt the underlying index structures in both directions. With the observation that real-world datasets are skewed, we focus on optimizing the indexes within the hotspot regions. We encapsulate the adaptation techniques into the Adaptive Hotspot-Aware Tree adaptive index. We compare the indexes and discuss the insights of each adaptation technique. Our investigation highlights the trade-offs of AHA-tree as well as the pros and cons of each design choice. AHA-tree can behave competitively as compared to an LSM-tree for write-heavy transactional workloads. Upon switching to a read-heavy analytical workload, and after some transient adaptation period, AHA-tree can behave as a B+-tree and can match the B+-trees read performance.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09467",
        "abstract url": "https://arxiv.org/abs/2406.09467",
        "title": "\"I see it as a wellspring for my positive and upward journey in life.\": Understanding Current Practices of Assistive Technology's Customized Modification in China",
        "rating": "-10",
        "keywords": [],
        "abstract": "Due to the significant differences in physical conditions and living environments of people with disabilities, standardized assistive technologies (ATs) often fail to meet their needs. Modified AT, especially DIY (Do It Yourself) ATs, are a popular solution in many high-income countries, but there is a lack of documentation for low- and middle-income areas, especially in China, where the culture of philanthropy is undeveloped. To understand the current situation in this paper, we conducted semi-structured interviews with 10 individuals with disabilities using modified ATs and 10 individuals involved in providing these, including family members, standard assistive device manufacturers, and individuals employed for their modification skills, etc. Based on the results of the thematic analysis, we have summarized the general process of modified ATs for people with disabilities in China and the benefits these devices bring. We found that modified ATs not only make the lives of people with disabilities more comfortable and convenient but also bring them confidence, reduce social pressure, and even help them achieve self-realization. Additionally, we summarized the challenges they encountered before, during, and after the modification, including awareness gaps, family resistance, a lack of a business model, and so on. Specifically, we conducted a special case study about the typical business models and challenges currently faced by AT modification organizations in China. Our research provides important design foundations and research insights for the future of universal and personalized production of AT.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09468",
        "abstract url": "https://arxiv.org/abs/2406.09468",
        "title": "Fair and Efficient Completion of Indivisible Goods",
        "rating": "-10",
        "keywords": [],
        "abstract": "We formulate the problem of fair and efficient completion of indivisible goods, defined as follows: Given a partial allocation of indivisible goods among agents, does there exist an allocation of the remaining goods (i.e., a completion) that satisfies fairness and economic efficiency guarantees of interest? We study the computational complexity of the completion problem for prominent fairness and efficiency notions such as envy-freeness up one good (EF1), proportionality up to one good (Prop1), maximin share (MMS), and Pareto optimality (PO), and focus on the class of additive valuations as well as its subclasses such as binary additive and lexicographic valuations. We find that while the completion problem is significantly harder than the standard fair division problem (wherein the initial partial allocation is empty), the consideration of restricted preferences facilitates positive algorithmic results for threshold-based fairness notions (Prop1 and MMS). On the other hand, the completion problem remains computationally intractable for envy-based notions such as EF1 and EF1+PO even under restricted preferences.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09469",
        "abstract url": "https://arxiv.org/abs/2406.09469",
        "title": "Conformance Testing of Relational DBMS Against SQL Specifications",
        "rating": "-10",
        "keywords": [],
        "abstract": "A Relational Database Management System (RDBMS) is one of the fundamental software that supports a wide range of applications, making it critical to identify bugs within these systems. There has been active research on testing RDBMS, most of which employ crash or use metamorphic relations as the oracle. Although existing approaches can detect bugs in RDBMS, they are far from comprehensively evaluating the RDBMS's correctness (i.e., with respect to the semantics of SQL). In this work, we propose a method to test the semantic conformance of RDBMS i.e., whether its behavior respects the intended semantics of SQL. Specifically, we have formally defined the semantics of SQL and implemented them in Prolog. Then, the Prolog implementation serves as the reference RDBMS, enabling differential testing on existing RDBMS. We applied our approach to four widely-used and thoroughly tested RDBMSs, i.e., MySQL, TiDB, SQLite, and DuckDB. In total, our approach uncovered 19 bugs and 11 inconsistencies, which are all related to violating the SQL specification or missing/unclear specification, thereby demonstrating the effectiveness and applicability of our approach.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09531",
        "abstract url": "https://arxiv.org/abs/2406.09531",
        "title": "Brief research of traditional and AI-based models for IMD2 cancellation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Due to the limited isolation of duplexer's stopband transceivers operating in frequency division duplex (FDD) encounter a leakage of the transmitted signal onto the receiving path. Leakage signal with the combination of the second-order nonlinearity of the low noise amplifier (LNA) and receiver down-conversion mixer may lead to second-order intermodulation distortion (IMD2) generation thus greatly reducing the receiver sensitivity. Cancellation of undesirable interferences based on adaptation of traditional models such as memoryless and memory polynomials, spline polynomial based Hammerstein and Wiener-Hammerstein models proved its efficiency in case of well-known nonlinearity nature. On the other hand, currently there is an intensive research in the field of nonlinearity detection by means of neural network (NN) structures. NN-based IMD cancellers are effective in the case of unknown interference content due to their high generalization ability. Therefore, NN approach can provide universal model, which is capable of IMD suppression even in case it is hard to separate intermodulation products generated by LNA, down-conversion mixer or even power amplifier in transmitter path. Nevertheless, such structures suffer from high complexity and can`t be implemented in hardware. Current paper presents low-complexity feed-forward NN-based model, which successfully competes with traditional architectures in terms of computational complexity. The testbench results demonstrate the acceptable performance of provided model, which can be equal to the polynomial nonlinear canceler's performance at a reduced computational cost. Current paper provides performance and required resources comparison of traditional memory polynomial-based scheme and NN-based model for IMD2 cancellation.",
        "subjects": [
            "math.OC",
            "eess.SP"
        ],
        "comment": "8 pages, 4 figures, PIERS conference"
    },
    {
        "paper id": "2406.09537",
        "abstract url": "https://arxiv.org/abs/2406.09537",
        "title": "Analyzing Multifiltering Functions Using Multiparameter Discrete Morse Theory",
        "rating": "-10",
        "keywords": [],
        "abstract": "A multiparameter filtration, or a multifiltration, may in many cases be seen as the collection of sublevel sets of a vector function, which we call a multifiltering function. The main objective of this paper is to obtain a better understanding of such functions through multiparameter discrete Morse (MDM) theory, which is an extension of Morse-Forman theory to vector-valued functions. Notably, we prove algorithmically that any multifiltering function defined on a simplicial complex can always be approximated by a compatible MDM function. Moreover, we define the Pareto set of a discrete multifiltering function and show that the concept links directly to that of critical simplices of a MDM function. Finally, we experiment with these notions using triangular meshes.",
        "subjects": [
            "math.GT",
            "cs.CG"
        ],
        "comment": "43 pages, 18 figures"
    },
    {
        "paper id": "2406.09557",
        "abstract url": "https://arxiv.org/abs/2406.09557",
        "title": "Measure This, Not That: Optimizing the Cost and Model-Based Information Content of Measurements",
        "rating": "-10",
        "keywords": [],
        "abstract": "Model-based design of experiments (MBDoE) is a powerful framework for selecting and calibrating science-based mathematical models from data. This work extends popular MBDoE workflows by proposing a convex mixed integer (non)linear programming (MINLP) problem to optimize the selection of measurements. The solver MindtPy is modified to support calculating the D-optimality objective and its gradient via an external package, \\texttt{SciPy}, using the grey-box module in Pyomo. The new approach is demonstrated in two case studies: estimating highly correlated kinetics from a batch reactor and estimating transport parameters in a large-scale rotary packed bed for CO$_2$ capture. Both case studies show how examining the Pareto-optimal trade-offs between information content measured by A- and D-optimality versus measurement budget offers practical guidance for selecting measurements for scientific experiments.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09577",
        "abstract url": "https://arxiv.org/abs/2406.09577",
        "title": "A New Generation of Intelligent Development Environments",
        "rating": "-10",
        "keywords": [],
        "abstract": "The practice of programming is undergoing a revolution with the introduction of AI assisted development (copilots) and the creation of new programming languages that are designed explicitly for tooling, analysis, and automation. Integrated Development Environments (IDEs) as they are currently conceptualized have not yet responded to these changes. They are still designed around the idea of a human programmer typing textual code into an editor window with the IDE providing assistance via the integration of various tools for syntax highlighting, compilation, debugging, and (maybe) code version control. This paper presents a vision for transforming the IDE from an Integrated Development Environment to an Intelligent Development Environment. The new IDE will be designed around the idea of a human programmer as the manager or curator of a software project who, rather than manually typing in code to implement a solution, will instead use the IDE to direct AI programming agents and/or automated tools to combine existing APIs, packages, and new code to implement the needed features. In this new model, the fundamental roles of the IDE are to 1) facilitate the communication between the human programmer and the AI agents and automated tools and 2) organize the workflow tasks needed to go from requirements gathering to the final tested and validated deployed feature. This paper presents a vision for the new Intelligent Development Environment based on a range of proof-of-concept high-value scenarios we have experimented with and discusses the challenges that remain to realizing these in a cohesive intelligent development experience.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09611",
        "abstract url": "https://arxiv.org/abs/2406.09611",
        "title": "Recy-ctronics: Designing Fully Recyclable Electronics With Varied Form Factors",
        "rating": "-10",
        "keywords": [],
        "abstract": "For today's electronics manufacturing process, the emphasis on stable functionality, durability, and fixed physical forms is designed to ensure long-term usability. However, this focus on robustness and permanence complicates the disassembly and recycling processes, leading to significant environmental repercussions. In this paper, we present three approaches that leverage easily recyclable materials-specifically, polyvinyl alcohol (PVA) and liquid metal (LM)-alongside accessible manufacturing techniques to produce electronic components and systems with versatile form factors. Our work centers on the development of recyclable electronics through three methods: 1) creating sheet electronics by screen printing LM traces on PVA substrates; 2) developing foam-based electronics by immersing mechanically stirred PVA foam into an LM solution; and 3) fabricating recyclable electronic tubes by injecting LM into mold cast PVA tubes, which can then be woven into various structures. To further assess the sustainability of our proposed methods, we conducted a life cycle assessment (LCA) to evaluate the environmental impact of our recyclable electronics in comparison to their conventional counterparts.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09621",
        "abstract url": "https://arxiv.org/abs/2406.09621",
        "title": "Enhancing Knowledge Retrieval with In-Context Learning and Semantic Search through Generative AI",
        "rating": "-10",
        "keywords": [],
        "abstract": "Retrieving and extracting knowledge from extensive research documents and large databases presents significant challenges for researchers, students, and professionals in today's information-rich era. Existing retrieval systems, which rely on general-purpose Large Language Models (LLMs), often fail to provide accurate responses to domain-specific inquiries. Additionally, the high cost of pretraining or fine-tuning LLMs for specific domains limits their widespread adoption. To address these limitations, we propose a novel methodology that combines the generative capabilities of LLMs with the fast and accurate retrieval capabilities of vector databases. This advanced retrieval system can efficiently handle both tabular and non-tabular data, understand natural language user queries, and retrieve relevant information without fine-tuning. The developed model, Generative Text Retrieval (GTR), is adaptable to both unstructured and structured data with minor refinement. GTR was evaluated on both manually annotated and public datasets, achieving over 90% accuracy and delivering truthful outputs in 87% of cases. Our model achieved state-of-the-art performance with a Rouge-L F1 score of 0.98 on the MSMARCO dataset. The refined model, Generative Tabular Text Retrieval (GTR-T), demonstrated its efficiency in large database querying, achieving an Execution Accuracy (EX) of 0.82 and an Exact-Set-Match (EM) accuracy of 0.60 on the Spider dataset, using an open-source LLM. These efforts leverage Generative AI and In-Context Learning to enhance human-text interaction and make advanced AI capabilities more accessible. By integrating robust retrieval systems with powerful LLMs, our approach aims to democratize access to sophisticated AI tools, improving the efficiency, accuracy, and scalability of AI-driven information retrieval and database querying.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09645",
        "abstract url": "https://arxiv.org/abs/2406.09645",
        "title": "Carbon accounting in the Cloud: a methodology for allocating emissions across data center users",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a methodology for allocating energy consumption to multiple users of shared data center machines, infrastructure, and software. Google uses this methodology to provide carbon reporting data for enterprise customers of multiple Google products, including Google Cloud and Workspace. The approach documented here advances the state-of-the-art of large scale Cloud carbon reporting systems. It uses detailed, granular measurement data on machine energy consumption. In addition, it uses physical factors for allocating energy consumption and carbon emissions--preferred by the Greenhouse Gas Protocol's Scope 3 Reporting Standard. Specifically, the approach described here allocates machine energy consumption based on a combination of data center resource reservations and hourly measured resource usage. It also accounts for Google's own internal use of shared software services, reallocating energy use to the users of those shared services. Finally, it uses hourly, location-specific estimates of carbon intensity to precisely measure carbon emissions of users in a global fleet of data centers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09649",
        "abstract url": "https://arxiv.org/abs/2406.09649",
        "title": "SquirrelFS: using the Rust compiler to check file-system crash consistency",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work introduces a new approach to building crash-safe file systems for persistent memory. We exploit the fact that Rust's typestate pattern allows compile-time enforcement of a specific order of operations. We introduce a novel crash-consistency mechanism, Synchronous Soft Updates, that boils down crash safety to enforcing ordering among updates to file-system metadata. We employ this approach to build SquirrelFS, a new file system with crash-consistency guarantees that are checked at compile time. SquirrelFS avoids the need for separate proofs, instead incorporating correctness guarantees into the typestate itself. Compiling SquirrelFS only takes tens of seconds; successful compilation indicates crash consistency, while an error provides a starting point for fixing the bug. We evaluate SquirrelFS against state of the art file systems such as NOVA and WineFS, and find that SquirrelFS achieves similar or better performance on a wide range of benchmarks and applications.",
        "subjects": [
            "cs.OS"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09650",
        "abstract url": "https://arxiv.org/abs/2406.09650",
        "title": "Carbon-Aware End-to-End Data Movement",
        "rating": "-10",
        "keywords": [],
        "abstract": "The latest trends in the adoption of cloud, edge, and distributed computing, as well as a rise in applying AI/ML workloads, have created a need to measure, monitor, and reduce the carbon emissions of these compute-intensive workloads and the associated communication costs. The data movement over networks has considerable carbon emission that has been neglected due to the difficulty in measuring the carbon footprint of a given end-to-end network path. We present a novel network carbon footprint measuring mechanism and propose three ways in which users can optimize scheduling network-intensive tasks to enable carbon savings through shifting tasks in time, space, and overlay networks based on the geographic carbon intensity.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09686",
        "abstract url": "https://arxiv.org/abs/2406.09686",
        "title": "Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Text corpus exploration (TCE) spans the range of exploratory search tasks: it goes beyond simple retrieval to include item discovery and learning about the corpus and topic. Systems support TCE with tools such as similarity-based recommendations and embedding-based spatial maps. However, these tools address specific tasks; current systems lack the flexibility to support the range of tasks encountered in practice and the iterative, multiscale, workflows users employ. In this paper, we provide methods that enhance TCE tools with post hoc explanations and multiscale, comparative designs to provide flexible support for user needs. We introduce salience functions as a mechanism to provide post hoc explanations of similarity, recommendations, and spatial placement. This post hoc strategy allows our approach to complement a variety of underlying algorithms; the salience functions provide both exemplar- and feature-based explanations at scales ranging from individual documents through to the entire corpus. These explanations are incorporated into a set of views that operate at multiple scales. The views use design elements that explicitly support comparison to enable flexible integration. Together, these form an approach that provides a flexible toolset that can address a range of tasks. We demonstrate our approach in a prototype system that enables the exploration of corpora of paper abstracts and newspaper archives. Examples illustrate how our approach enables the system to flexibly support a wide range of tasks and workflows that emerge in user scenarios. A user study confirms that researchers are able to use our system to achieve a variety of tasks.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "comment": "The system is available at: https://pages.graphics.cs.wisc.edu/AbstractsViewer. The user guide (including more examples) is at: https://pages.graphics.cs.wisc.edu/AbstractsViewerDocs/"
    },
    {
        "paper id": "2406.09692",
        "abstract url": "https://arxiv.org/abs/2406.09692",
        "title": "SplineGen: a generative model for B-spline approximation of unorganized points",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a learning-based method to solve the traditional parameterization and knot placement problems in B-spline approximation. Different from conventional heuristic methods or recent AI-based methods, the proposed method does not assume ordered or fixed-size data points as input. There is also no need for manually setting the number of knots. It casts the parameterization and knot placement problems as a sequence-to-sequence translation problem, a generative process automatically determining the number of knots, their placement, parameter values, and their ordering. Once trained, SplineGen demonstrates a notable improvement over existing methods, with a one to two orders of magnitude increase in approximation accuracy on test data.",
        "subjects": [
            "cs.CE",
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09695",
        "abstract url": "https://arxiv.org/abs/2406.09695",
        "title": "Machine learning-based Near-field Emitter Localization via Grouped Hybrid Analog and Digital Massive MIMO Receive Array",
        "rating": "-10",
        "keywords": [],
        "abstract": "A fully-digital massive MIMO receive array is promising to meet the high-resolution requirement of near-field (NF) emitter localization, but it also results in the significantly increasing of hardware costs and algorithm complexity. In order to meet the future demand for green communication while maintaining high performance, the grouped hybrid analog and digital (HAD) structure is proposed for NF DOA estimation, which divides the large-scale receive array into small-scale groups and each group contains several subarrays. Thus the NF direction-of-arrival (DOA) estimation problem is viewed as far-field (FF) within each group, and some existing methods such as MUSIC, Root-MUSIC, ESPRIT, etc., can be adopted. Then by angle calibration, a candidate position set is generated. To eliminate the phase ambiguity arising from the HAD structure and obtain the emitter position, two low-complexity clustering-based methods, minimum sample distance clustering (MSDC) and range scatter diagram (RSD) - angle scatter diagram (ASD)-based DBSCAN (RSD-ASD-DBSCAN), are proposed based on the distribution features of samples in the candidate position set. Then to further improve the localization accuracy, a model-driven regression network (RegNet) is designed, which consists of a multi-layer neural network (MLNN) for false solution elimination and a perceptron for angle fusion. Finally, the Cramer-Rao lower bound (CRLB) of NF emitter localization for the proposed grouped HAD structure is also derived. The simulation results show that the proposed methods can achieve CRLB at different SNR regions, the RegNet has great performance advantages at low SNR regions and the clustering-based methods have much lower complexity.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2406.09701",
        "abstract url": "https://arxiv.org/abs/2406.09701",
        "title": "Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software vulnerabilities pose significant risks to the security and integrity of software systems. Prior studies have proposed a series of approaches to vulnerability detection using deep learning or pre-trained models. However, there is still a lack of vulnerability's detailed explanation for understanding apart from detecting its occurrence. Recently, large language models (LLMs) have shown a remarkable capability in the comprehension of complicated context and content generation, which brings opportunities for the detection and explanation of vulnerabilities of LLMs. In this paper, we conduct a comprehensive study to investigate the capabilities of LLMs in detecting and explaining vulnerabilities and propose LLMVulExp, a framework that utilizes LLMs for vulnerability detection and explanation. Under specialized fine-tuning for vulnerability explanation, LLMVulExp not only detects the types of vulnerabilities in the code but also analyzes the code context to generate the cause, location, and repair suggestions for these vulnerabilities. We find that LLMVulExp can effectively enable the LLMs to perform vulnerability detection (e.g., over 90% F1 score on SeVC dataset) and explanation. We also explore the potential of using advanced strategies such as Chain-of-Thought (CoT) to guide the LLMs concentrating on vulnerability-prone code and achieve promising results.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    }
]