[
    {
        "paper id": "2407.17060",
        "abstract url": "https://arxiv.org/abs/2407.17060",
        "title": "High Efficiency Image Compression for Large Visual-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Visual-Language"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, large visual language models (LVLMs) have shown impressive performance and promising generalization capability in multi-modal tasks, thus replacing humans as receivers of visual information in various application scenarios. In this paper, we pioneer to propose a variable bitrate image compression framework consisting of a pre-editing module and an end-to-end codec to achieve promising rate-accuracy performance for different LVLMs. In particular, instead of optimizing an adaptive pre-editing network towards a particular task or several representative tasks, we propose a new optimization strategy tailored for LVLMs, which is designed based on the representation and discrimination capability with token-level distortion and rank. The pre-editing module and the variable bitrate end-to-end image codec are jointly trained by the losses based on semantic tokens of the large model, which introduce enhanced generalization capability for various data and tasks. {Experimental results demonstrate that the proposed framework could efficiently achieve much better rate-accuracy performance compared to the state-of-the-art coding standard, Versatile Video Coding.} Meanwhile, experiments with multi-modal tasks have revealed the robustness and generalization capability of the proposed framework.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17379",
        "abstract url": "https://arxiv.org/abs/2407.17379",
        "title": "MMRA: A Benchmark for Multi-granularity Multi-image Relational Association",
        "rating": "2",
        "keywords": [
            [
                "visual language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Given the remarkable success that large visual language models (LVLMs) have achieved in image perception tasks, the endeavor to make LVMLs perceive the world like humans is drawing increasing attention. Current multi-modal benchmarks mainly focus on the objective fact or certain topic related potential knowledge within a image, but overlook the associative relations between multiple images. Therefore, we define a multi-image relation association task, and meticulously curate \\textbf{MMRA} benchmark, a \\textbf{M}ulti-granularity \\textbf{M}ulti-image \\textbf{R}elational \\textbf{A}ssociation benchmark, consisted of \\textbf{1026} samples. In order to systematically and comprehensively evaluate mainstream LVLMs, we establish an associational relation system among images that contain \\textbf{11 subtasks} (e.g, UsageSimilarity, SubEvent, etc.) at two granularity levels (i.e., \"\\textbf{image}\" and \"\\textbf{entity}\") according to the relations in ConceptNet. Our experiments demonstrate that, on our MMRA benchmark, current mainstream LVLMs all have their own advantages and disadvantages across different subtasks. It is worth noting that, at the entity level, the performance of all models is worse than that of them at the image level, indicating that the fine-grained multi-image perception task is still challenging for LVLMs. The tasks related to spatial perception are relatively difficult for LVLMs to handle. Furthermore, we find that LVMLs exhibit a good ability to perceive image details, and the key to enhancing their multi-image association capability is to strengthen the reasoning ability of their language model component. All our codes and data are released at htt\\url{https://github.com/Wusiwei0410/MMRA}.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "VLMS, Multi-Image Association"
    },
    {
        "paper id": "2407.17453",
        "abstract url": "https://arxiv.org/abs/2407.17453",
        "title": "$VILA^2$: VILA Augmented VILA",
        "rating": "2",
        "keywords": [
            [
                "Visual language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual language models (VLMs) have rapidly progressed, driven by the success of large language models (LLMs). While model architectures and training infrastructures advance rapidly, data curation remains under-explored. When data quantity and quality become a bottleneck, existing work either directly crawls more raw data from the Internet that does not have a guarantee of data quality or distills from black-box commercial models (e.g., GPT-4V / Gemini) causing the performance upper bounded by that model. In this work, we introduce a novel approach that includes a self-augment step and a specialist-augment step to iteratively improve data quality and model performance. In the self-augment step, a VLM recaptions its own pretraining data to enhance data quality, and then retrains from scratch using this refined dataset to improve model performance. This process can iterate for several rounds. Once self-augmentation saturates, we employ several specialist VLMs finetuned from the self-augmented VLM with domain-specific expertise, to further infuse specialist knowledge into the generalist VLM through task-oriented recaptioning and retraining. With the combined self-augmented and specialist-augmented training, we introduce $VILA^2$ (VILA-augmented-VILA), a VLM family that consistently improves the accuracy on a wide range of tasks over prior art, and achieves new state-of-the-art results on MMMU leaderboard among open-sourced models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17467",
        "abstract url": "https://arxiv.org/abs/2407.17467",
        "title": "CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models",
        "rating": "2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) excel in diverse tasks but often underperform in specialized fields due to limited domain-specific or proprietary corpus. Continual pre-training (CPT) enhances LLM capabilities by imbuing new domain-specific or proprietary knowledge while replaying general corpus to prevent catastrophic forgetting. The data mixture ratio of general corpus and domain-specific corpus, however, has been chosen heuristically, leading to sub-optimal training efficiency in practice. In this context, we attempt to re-visit the scaling behavior of LLMs under the hood of CPT, and discover a power-law relationship between loss, mixture ratio, and training tokens scale. We formalize the trade-off between general and domain-specific capabilities, leading to a well-defined Critical Mixture Ratio (CMR) of general and domain data. By striking the balance, CMR maintains the model's general ability and achieves the desired domain transfer, ensuring the highest utilization of available resources. Therefore, if we value the balance between efficiency and effectiveness, CMR can be consider as the optimal mixture ratio.Through extensive experiments, we ascertain the predictability of CMR, and propose CMR scaling law and have substantiated its generalization. These findings offer practical guidelines for optimizing LLM training in specialized domains, ensuring both general and domain-specific performance while efficiently managing training resources.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17020",
        "abstract url": "https://arxiv.org/abs/2407.17020",
        "title": "EAFormer: Scene Text Segmentation with Edge-Aware Transformers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Scene text segmentation aims at cropping texts from scene images, which is usually used to help generative models edit or remove texts. The existing text segmentation methods tend to involve various text-related supervisions for better performance. However, most of them ignore the importance of text edges, which are significant for downstream applications. In this paper, we propose Edge-Aware Transformers, termed EAFormer, to segment texts more accurately, especially at the edge of texts. Specifically, we first design a text edge extractor to detect edges and filter out edges of non-text areas. Then, we propose an edge-guided encoder to make the model focus more on text edges. Finally, an MLP-based decoder is employed to predict text masks. We have conducted extensive experiments on commonly-used benchmarks to verify the effectiveness of EAFormer. The experimental results demonstrate that the proposed method can perform better than previous methods, especially on the segmentation of text edges. Considering that the annotations of several benchmarks (e.g., COCO_TS and MLT_S) are not accurate enough to fairly evaluate our methods, we have relabeled these datasets. Through experiments, we observe that our method can achieve a higher performance improvement when more accurate annotations are used for training.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2407.17029",
        "abstract url": "https://arxiv.org/abs/2407.17029",
        "title": "Accurate and Efficient Fine-Tuning of Quantized Large Language Models Through Optimal Balance",
        "rating": "1.5",
        "keywords": [
            [
                "Efficient Fine-Tuning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across various domains. However, the enormous number of model parameters makes fine-tuning challenging, significantly limiting their application and deployment. Existing solutions combine parameter quantization with Low-Rank Adaptation (LoRA), greatly reducing memory usage but resulting in noticeable performance degradation. In this paper, we identify an imbalance in fine-tuning quantized pre-trained models: overly complex adapter inputs and outputs versus low effective trainability of the adaptation. We propose Quantized LLMs with Balanced-rank Adaptation (Q-BaRA), which simplifies the adapter inputs and outputs while increasing the adapter's rank to achieve a more suitable balance for fine-tuning quantized LLMs. Additionally, for scenarios where fine-tuned LLMs need to be deployed as low-precision inference models, we introduce Quantization-Aware Fine-tuning with Higher Rank Adaptation (QA-HiRA), which simplifies the adapter inputs and outputs to align with the pre-trained model's block-wise quantization while employing a single matrix to achieve a higher rank. Both Q-BaRA and QA-HiRA are easily implemented and offer the following optimizations: (i) Q-BaRA consistently achieves the highest accuracy compared to baselines and other variants, requiring the same number of trainable parameters and computational effort; (ii) QA-HiRA naturally merges adapter parameters into the block-wise quantized model after fine-tuning, achieving the highest accuracy compared to other methods. We apply our Q-BaRA and QA-HiRA to the LLaMA and LLaMA2 model families and validate their effectiveness across different fine-tuning datasets and downstream scenarios. Code will be made available at \\href{https://github.com/xiaocaigou/qbaraqahira}{https://github.com/xiaocaigou/qbaraqahira}",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17120",
        "abstract url": "https://arxiv.org/abs/2407.17120",
        "title": "Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective",
        "rating": "1.5",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown promise in adapting pre-trained models to sequential tasks while mitigating catastrophic forgetting problem. However, understanding the mechanisms that dictate continual performance in this paradigm remains elusive. To tackle this complexity, we undertake a rigorous analysis of PEFT-CL dynamics to derive relevant metrics for continual scenarios using Neural Tangent Kernel (NTK) theory. With the aid of NTK as a mathematical analysis tool, we recast the challenge of test-time forgetting into the quantifiable generalization gaps during training, identifying three key factors that influence these gaps and the performance of PEFT-CL: training sample size, task-level feature orthogonality, and regularization. To address these challenges, we introduce NTK-CL, a novel framework that eliminates task-specific parameter storage while adaptively generating task-relevant features. Aligning with theoretical guidance, NTK-CL triples the feature representation of each sample, theoretically and empirically reducing the magnitude of both task-interplay and task-specific generalization gaps. Grounded in NTK analysis, our approach imposes an adaptive exponential moving average mechanism and constraints on task-level feature orthogonality, maintaining intra-task NTK forms while attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable parameters with appropriate regularization, NTK-CL achieves state-of-the-art performance on established PEFT-CL benchmarks. This work provides a theoretical foundation for understanding and improving PEFT-CL models, offering insights into the interplay between feature representation, task orthogonality, and generalization, contributing to the development of more efficient continual learning systems.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17261",
        "abstract url": "https://arxiv.org/abs/2407.17261",
        "title": "Embedding-Free Transformer with Inference Spatial Reduction for Efficient Semantic Segmentation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "We present an Encoder-Decoder Attention Transformer, EDAFormer, which consists of the Embedding-Free Transformer (EFT) encoder and the all-attention decoder leveraging our Embedding-Free Attention (EFA) structure. The proposed EFA is a novel global context modeling mechanism that focuses on functioning the global non-linearity, not the specific roles of the query, key and value. For the decoder, we explore the optimized structure for considering the globality, which can improve the semantic segmentation performance. In addition, we propose a novel Inference Spatial Reduction (ISR) method for the computational efficiency. Different from the previous spatial reduction attention methods, our ISR method further reduces the key-value resolution at the inference phase, which can mitigate the computation-performance trade-off gap for the efficient semantic segmentation. Our EDAFormer shows the state-of-the-art performance with the efficient computation compared to the existing transformer-based semantic segmentation models in three public benchmarks, including ADE20K, Cityscapes and COCO-Stuff. Furthermore, our ISR method reduces the computational cost by up to 61% with minimal mIoU performance degradation on Cityscapes dataset. The code is available at https://github.com/hyunwoo137/EDAFormer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2407.17331",
        "abstract url": "https://arxiv.org/abs/2407.17331",
        "title": "Multi-label Cluster Discrimination for Visual Representation Learning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Contrastive Language Image Pre-training (CLIP) has recently demonstrated success across various tasks due to superior feature representation empowered by image-text contrastive learning. However, the instance discrimination method used by CLIP can hardly encode the semantic structure of training data. To handle this limitation, cluster discrimination has been proposed through iterative cluster assignment and classification. Nevertheless, most cluster discrimination approaches only define a single pseudo-label for each image, neglecting multi-label signals in the image. In this paper, we propose a novel Multi-Label Cluster Discrimination method named MLCD to enhance representation learning. In the clustering step, we first cluster the large-scale LAION-400M dataset into one million centers based on off-the-shelf embedding features. Considering that natural images frequently contain multiple visual objects or attributes, we select the multiple closest centers as auxiliary class labels. In the discrimination step, we design a novel multi-label classification loss, which elegantly separates losses from positive classes and negative classes, and alleviates ambiguity on decision boundary. We validate the proposed multi-label cluster discrimination method with experiments on different scales of models and pre-training datasets. Experimental results show that our method achieves state-of-the-art performance on multiple downstream tasks including linear probe, zero-shot classification, and image-text retrieval.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV2024"
    },
    {
        "paper id": "2407.17596",
        "abstract url": "https://arxiv.org/abs/2407.17596",
        "title": "Quality Assured: Rethinking Annotation Strategies in Imaging AI",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper does not describe a novel method. Instead, it studies an essential foundation for reliable benchmarking and ultimately real-world application of AI-based image analysis: generating high-quality reference annotations. Previous research has focused on crowdsourcing as a means of outsourcing annotations. However, little attention has so far been given to annotation companies, specifically regarding their internal quality assurance (QA) processes. Therefore, our aim is to evaluate the influence of QA employed by annotation companies on annotation quality and devise methodologies for maximizing data annotation efficacy. Based on a total of 57,648 instance segmented images obtained from a total of 924 annotators and 34 QA workers from four annotation companies and Amazon Mechanical Turk (MTurk), we derived the following insights: (1) Annotation companies perform better both in terms of quantity and quality compared to the widely used platform MTurk. (2) Annotation companies' internal QA only provides marginal improvements, if any. However, improving labeling instructions instead of investing in QA can substantially boost annotation performance. (3) The benefit of internal QA depends on specific image characteristics. Our work could enable researchers to derive substantially more value from a fixed annotation budget and change the way annotation companies conduct internal QA.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at ECCV 2024, preprint, Computer Vision, Data Annotation"
    },
    {
        "paper id": "2407.17664",
        "abstract url": "https://arxiv.org/abs/2407.17664",
        "title": "SDLNet: Statistical Deep Learning Network for Co-Occurring Object Detection and Identification",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "With the growing advances in deep learning based technologies the detection and identification of co-occurring objects is a challenging task which has many applications in areas such as, security and surveillance. In this paper, we propose a novel framework called SDLNet- Statistical analysis with Deep Learning Network that identifies co-occurring objects in conjunction with base objects in multilabel object categories. The pipeline of proposed work is implemented in two stages: in the first stage of SDLNet we deal with multilabel detectors for discovering labels, and in the second stage we perform co-occurrence matrix analysis. In co-occurrence matrix analysis, we learn co-occurrence statistics by setting base classes and frequently occurring classes, following this we build association rules and generate frequent patterns. The crucial part of SDLNet is recognizing base classes and making consideration for co-occurring classes. Finally, the generated co-occurrence matrix based on frequent patterns will show base classes and their corresponding co-occurring classes. SDLNet is evaluated on two publicly available datasets: Pascal VOC and MS-COCO. The experimental results on these benchmark datasets are reported in Sec 4.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 3 figures, ICMLT-2024. arXiv admin note: text overlap with arXiv:2403.17223"
    },
    {
        "paper id": "2407.17671",
        "abstract url": "https://arxiv.org/abs/2407.17671",
        "title": "Unsqueeze [CLS] Bottleneck to Learn Rich Representations",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Distillation-based self-supervised learning typically leads to more compressed representations due to its radical clustering process and the implementation of a sharper target distribution. To overcome this limitation and preserve more information from input, we introduce UDI, conceptualized as Unsqueezed Distillation-based self-supervised learning (SSL). UDI enriches the learned representation by encouraging multimodal prediction distilled from a consolidated profile of local predictions that are derived via stratified sampling. Our evaluations show that UDI not only promotes semantically meaningful representations at instance level, delivering superior or competitive results to state-of-the-art SSL methods in image classification, but also effectively preserves the nuisance of input, which yields significant improvement in dense prediction tasks, including object detection and segmentation. Additionally, UDI performs competitively in low-shot image classification, improving the scalability of joint-embedding pipelines. Various visualizations and ablation studies are presented to further elucidate the mechanisms behind UDI. Our source code is available at https://github.com/ISL-CV/udi.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2407.17009",
        "abstract url": "https://arxiv.org/abs/2407.17009",
        "title": "Uncertainty-Based Ensemble Learning For Speech Classification",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Speech classification has attracted increasing attention due to its wide applications, particularly in classifying physical and mental states. However, these tasks are challenging due to the high variability in speech signals. Ensemble learning has shown promising results when multiple classifiers are combined to improve performance. With recent advancements in hardware development, combining several models is not a limitation in deep learning research and applications. In this paper, we propose an uncertainty-based ensemble learning approach for speech classification. Specifically, we train a set of base features on the same classifier and quantify the uncertainty of their predictions. The predictions are combined using variants of uncertainty calculation to produce the final prediction. The visualization of the effect of uncertainty and its ensemble learning results show potential improvements in speech classification tasks. The proposed method outperforms single models and conventional ensemble learning methods in terms of unweighted accuracy or weighted accuracy.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Submitted to OCOCOSDA 2024"
    },
    {
        "paper id": "2407.17011",
        "abstract url": "https://arxiv.org/abs/2407.17011",
        "title": "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) exhibit remarkable in-context learning (ICL) capabilities. However, the underlying working mechanism of ICL remains poorly understood. Recent research presents two conflicting views on ICL: One attributes it to LLMs' inherent ability of task recognition, deeming label correctness and shot numbers of demonstrations as not crucial; the other emphasizes the impact of similar examples in the demonstrations, stressing the need for label correctness and more shots. In this work, we provide a Two-Dimensional Coordinate System that unifies both views into a systematic framework. The framework explains the behavior of ICL through two orthogonal variables: whether LLMs can recognize the task and whether similar examples are presented in the demonstrations. We propose the peak inverse rank metric to detect the task recognition ability of LLMs and study LLMs' reactions to different definitions of similarity. Based on these, we conduct extensive experiments to elucidate how ICL functions across each quadrant on multiple representative classification tasks. Finally, we extend our analyses to generation tasks, showing that our coordinate system can also be used to interpret ICL for generation tasks effectively.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17022",
        "abstract url": "https://arxiv.org/abs/2407.17022",
        "title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language model (LLM)-based evaluation pipelines have demonstrated their capability to robustly evaluate machine-generated text. Extending this methodology to assess human-written text could significantly benefit educational settings by providing direct feedback to enhance writing skills, although this application is not straightforward. In this paper, we investigate whether LLMs can effectively assess human-written text for educational purposes. We collected 100 texts from 32 Korean students across 15 types of writing and employed GPT-4-Turbo to evaluate them using grammaticality, fluency, coherence, consistency, and relevance as criteria. Our analyses indicate that LLM evaluators can reliably assess grammaticality and fluency, as well as more objective types of writing, though they struggle with other criteria and types of writing. We publicly release our dataset and feedback.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work In Progress"
    },
    {
        "paper id": "2407.17023",
        "abstract url": "https://arxiv.org/abs/2407.17023",
        "title": "From Internal Conflict to Contextual Adaptation of Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge-intensive language understanding tasks require Language Models (LMs) to integrate relevant context, mitigating their inherent weaknesses, such as incomplete or outdated knowledge. Nevertheless, studies indicate that LMs often ignore the provided context as it can conflict with the pre-existing LM's memory learned during pre-training. Moreover, conflicting knowledge can already be present in the LM's parameters, termed intra-memory conflict. Existing works have studied the two types of knowledge conflicts only in isolation. We conjecture that the (degree of) intra-memory conflicts can in turn affect LM's handling of context-memory conflicts. To study this, we introduce the DYNAMICQA dataset, which includes facts with a temporal dynamic nature where a fact can change with a varying time frequency and disputable dynamic facts, which can change depending on the viewpoint. DYNAMICQA is the first to include real-world knowledge conflicts and provide context to study the link between the different types of knowledge conflicts. With the proposed dataset, we assess the use of uncertainty for measuring the intra-memory conflict and introduce a novel Coherent Persuasion (CP) score to evaluate the context's ability to sway LM's semantic output. Our extensive experiments reveal that static facts, which are unlikely to change, are more easily updated with additional context, relative to temporal and disputable facts.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "22 pages, 15 figures"
    },
    {
        "paper id": "2407.17028",
        "abstract url": "https://arxiv.org/abs/2407.17028",
        "title": "Enhancing Environmental Monitoring through Multispectral Imaging: The WasteMS Dataset for Semantic Segmentation of Lakeside Waste",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Environmental monitoring of lakeside green areas is crucial for environmental protection. Compared to manual inspections, computer vision technologies offer a more efficient solution when deployed on-site. Multispectral imaging provides diverse information about objects under different spectrums, aiding in the differentiation between waste and lakeside lawn environments. This study introduces WasteMS, the first multispectral dataset established for the semantic segmentation of lakeside waste. WasteMS includes a diverse range of waste types in lawn environments, captured under various lighting conditions. We implemented a rigorous annotation process to label waste in images. Representative semantic segmentation frameworks were used to evaluate segmentation accuracy using WasteMS. Challenges encountered when using WasteMS for segmenting waste on lakeside lawns were discussed. The WasteMS dataset is available at https://github.com/zhuqinfeng1999/WasteMS.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17075",
        "abstract url": "https://arxiv.org/abs/2407.17075",
        "title": "SAFETY-J: Evaluating Safety with Critique",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The deployment of Large Language Models (LLMs) in content generation raises significant safety concerns, particularly regarding the transparency and interpretability of content evaluations. Current methods, primarily focused on binary safety classifications, lack mechanisms for detailed critique, limiting their utility for model improvement and user trust. To address these limitations, we introduce SAFETY-J, a bilingual generative safety evaluator for English and Chinese with critique-based judgment. SAFETY-J utilizes a robust training dataset that includes diverse dialogues and augmented query-response pairs to assess safety across various scenarios comprehensively. We establish an automated meta-evaluation benchmark that objectively assesses the quality of critiques with minimal human intervention, facilitating scalable and continuous improvement. Additionally, SAFETY-J employs an iterative preference learning technique to dynamically refine safety assessments based on meta-evaluations and critiques. Our evaluations demonstrate that SAFETY-J provides more nuanced and accurate safety evaluations, thereby enhancing both critique quality and predictive reliability in complex content scenarios. To facilitate further research and application, we open-source SAFETY-J's training protocols, datasets, and code at \\url{https://github.com/GAIR-NLP/Safety-J}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17081",
        "abstract url": "https://arxiv.org/abs/2407.17081",
        "title": "A Survey Forest Diagram : Gain a Divergent Insight View on a Specific Research Topic",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the exponential growth in the number of papers and the trend of AI research, the use of Generative AI for information retrieval and question-answering has become popular for conducting research surveys. However, novice researchers unfamiliar with a particular field may not significantly improve their efficiency in interacting with Generative AI because they have not developed divergent thinking in that field. This study aims to develop an in-depth Survey Forest Diagram that guides novice researchers in divergent thinking about the research topic by indicating the citation clues among multiple papers, to help expand the survey perspective for novice researchers.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DL"
        ],
        "comment": "This paper will submit to IEEE SMC 2024"
    },
    {
        "paper id": "2407.17085",
        "abstract url": "https://arxiv.org/abs/2407.17085",
        "title": "OVR: A Dataset for Open Vocabulary Temporal Repetition Counting in Videos",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a dataset of annotations of temporal repetitions in videos. The dataset, OVR (pronounced as over), contains annotations for over 72K videos, with each annotation specifying the number of repetitions, the start and end time of the repetitions, and also a free-form description of what is repeating. The annotations are provided for videos sourced from Kinetics and Ego4D, and consequently cover both Exo and Ego viewing conditions, with a huge variety of actions and activities. Moreover, OVR is almost an order of magnitude larger than previous datasets for video repetition. We also propose a baseline transformer-based counting model, OVRCounter, that can localise and count repetitions in videos that are up to 320 frames long. The model is trained and evaluated on the OVR dataset, and its performance assessed with and without using text to specify the target class to count. The performance is also compared to a prior repetition counting model. The dataset is available for download at: https://sites.google.com/view/openvocabreps/",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17101",
        "abstract url": "https://arxiv.org/abs/2407.17101",
        "title": "PiPa++: Towards Unification of Domain Adaptive Semantic Segmentation via Self-supervised Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised domain adaptive segmentation aims to improve the segmentation accuracy of models on target domains without relying on labeled data from those domains. This approach is crucial when labeled target domain data is scarce or unavailable. It seeks to align the feature representations of the source domain (where labeled data is available) and the target domain (where only unlabeled data is present), thus enabling the model to generalize well to the target domain. Current image- and video-level domain adaptation have been addressed using different and specialized frameworks, training strategies and optimizations despite their underlying connections. In this paper, we propose a unified framework PiPa++, which leverages the core idea of ``comparing'' to (1) explicitly encourage learning of discriminative pixel-wise features with intraclass compactness and inter-class separability, (2) promote the robust feature learning of the identical patch against different contexts or fluctuations, and (3) enable the learning of temporal continuity under dynamic environments. With the designed task-smart contrastive sampling strategy, PiPa++ enables the mining of more informative training samples according to the task demand. Extensive experiments demonstrate the effectiveness of our method on both image-level and video-level domain adaption benchmarks. Moreover, the proposed method is compatible with other UDA approaches to further improve the performance without introducing extra parameters.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This study is under IEEE TMM review. arXiv admin note: substantial text overlap with arXiv:2211.07609"
    },
    {
        "paper id": "2407.17112",
        "abstract url": "https://arxiv.org/abs/2407.17112",
        "title": "Neural Dueling Bandits",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Contextual dueling bandit is used to model the bandit problems, where a learner's goal is to find the best arm for a given context using observed noisy preference feedback over the selected arms for the past contexts. However, existing algorithms assume the reward function is linear, which can be complex and non-linear in many real-life applications like online recommendations or ranking web search results. To overcome this challenge, we use a neural network to estimate the reward function using preference feedback for the previously selected arms. We propose upper confidence bound- and Thompson sampling-based algorithms with sub-linear regret guarantees that efficiently select arms in each round. We then extend our theoretical results to contextual bandit problems with binary feedback, which is in itself a non-trivial contribution. Experimental results on the problem instances derived from synthetic datasets corroborate our theoretical results.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "Accepted at ICML 2024 Workshop on Foundations of Reinforcement Learning and Control"
    },
    {
        "paper id": "2407.17125",
        "abstract url": "https://arxiv.org/abs/2407.17125",
        "title": "Behavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "One of the major aspects contributing to the striking performance of large language models (LLMs) is the vast amount of factual knowledge accumulated during pre-training. Yet, many LLMs suffer from self-inconsistency, which raises doubts about their trustworthiness and reliability. In this paper, we focus on entity type ambiguity and analyze current state-of-the-art LLMs for their proficiency and consistency in applying their factual knowledge when prompted for entities under ambiguity. To do so, we propose an evaluation protocol that disentangles knowing from applying knowledge, and test state-of-the-art LLMs on 49 entities. Our experiments reveal that LLMs perform poorly with ambiguous prompts, achieving only 80% accuracy. Our results further demonstrate systematic discrepancies in LLM behavior and their failure to consistently apply information, indicating that the models can exhibit knowledge without being able to utilize it, significant biases for preferred readings, as well as self inconsistencies. Our study highlights the importance of handling entity ambiguity in future for more trustworthy LLMs",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17140",
        "abstract url": "https://arxiv.org/abs/2407.17140",
        "title": "RT-DETRv2: Improved Baseline with Bag-of-Freebies for Real-Time Detection Transformer",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this report, we present RT-DETRv2, an improved Real-Time DEtection TRansformer (RT-DETR). RT-DETRv2 builds upon the previous state-of-the-art real-time detector, RT-DETR, and opens up a set of bag-of-freebies for flexibility and practicality, as well as optimizing the training strategy to achieve enhanced performance. To improve the flexibility, we suggest setting a distinct number of sampling points for features at different scales in the deformable attention to achieve selective multi-scale feature extraction by the decoder. To enhance practicality, we propose an optional discrete sampling operator to replace the grid_sample operator that is specific to RT-DETR compared to YOLOs. This removes the deployment constraints typically associated with DETRs. For the training strategy, we propose dynamic data augmentation and scale-adaptive hyperparameters customization to improve performance without loss of speed. Source code and pre-trained models will be available at https://github.com/lyuwenyu/RT-DETR.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17152",
        "abstract url": "https://arxiv.org/abs/2407.17152",
        "title": "XMeCap: Meme Caption Generation with Sub-Image Adaptability",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Humor, deeply rooted in societal meanings and cultural details, poses a unique challenge for machines. While advances have been made in natural language processing, real-world humor often thrives in a multi-modal context, encapsulated distinctively by memes. This paper poses a particular emphasis on the impact of multi-images on meme captioning. After that, we introduce the \\textsc{XMeCap} framework, a novel approach that adopts supervised fine-tuning and reinforcement learning based on an innovative reward model, which factors in both global and local similarities between visuals and text. Our results, benchmarked against contemporary models, manifest a marked improvement in caption generation for both single-image and multi-image memes, as well as different meme categories. \\textsc{XMeCap} achieves an average evaluation score of 75.85 for single-image memes and 66.32 for multi-image memes, outperforming the best baseline by 3.71\\% and 4.82\\%, respectively. This research not only establishes a new frontier in meme-related studies but also underscores the potential of machines in understanding and generating humor in a multi-modal setting.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted to MM 2024"
    },
    {
        "paper id": "2407.17155",
        "abstract url": "https://arxiv.org/abs/2407.17155",
        "title": "FIIH: Fully Invertible Image Hiding for Secure and Robust",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image hiding is the study of techniques for covert storage and transmission, which embeds a secret image into a container image and generates stego image to make it similar in appearance to a normal image. However, existing image hiding methods have a serious problem that the hiding and revealing process cannot be fully invertible, which results in the revealing network not being able to recover the secret image losslessly, which makes it impossible to simultaneously achieve high fidelity and secure transmission of the secret image in an insecure network environment. To solve this problem,this paper proposes a fully invertible image hiding architecture based on invertible neural network,aiming to realize invertible hiding of secret images,which is invertible on both data and network. Based on this ingenious architecture, the method can withstand deep learning based image steganalysis. In addition, we propose a new method for enhancing the robustness of stego images after interference during transmission. Experiments demonstrate that the FIIH proposed in this paper significantly outperforms other state-of-the-art image hiding methods in hiding a single image, and also significantly outperforms other state-of-the-art methods in robustness and security.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17160",
        "abstract url": "https://arxiv.org/abs/2407.17160",
        "title": "A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we are comparing monolingual Wav2Vec 2.0 models with various multilingual models to see whether we could improve speech recognition performance on a unique oral history archive containing a lot of mixed-language sentences. Our main goal is to push forward research on this unique dataset, which is an extremely valuable part of our cultural heritage. Our results suggest that monolingual speech recognition models are, in most cases, superior to multilingual models, even when processing the oral history archive full of mixed-language sentences from non-native speakers. We also performed the same experiments on the public CommonVoice dataset to verify our results. We are contributing to the research community by releasing our pre-trained models to the public.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted to INTERSPEECH2024"
    },
    {
        "paper id": "2407.17172",
        "abstract url": "https://arxiv.org/abs/2407.17172",
        "title": "Speech Editing -- a Summary",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "With the rise of video production and social media, speech editing has become crucial for creators to address issues like mispronunciations, missing words, or stuttering in audio recordings. This paper explores text-based speech editing methods that modify audio via text transcripts without manual waveform editing. These approaches ensure edited audio is indistinguishable from the original by altering the mel-spectrogram. Recent advancements, such as context-aware prosody correction and advanced attention mechanisms, have improved speech editing quality. This paper reviews state-of-the-art methods, compares key metrics, and examines widely used datasets. The aim is to highlight ongoing issues and inspire further research and innovation in speech editing.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17174",
        "abstract url": "https://arxiv.org/abs/2407.17174",
        "title": "NarrationDep: Narratives on Social Media For Automatic Depression Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Social media posts provide valuable insight into the narrative of users and their intentions, including providing an opportunity to automatically model whether a social media user is depressed or not. The challenge lies in faithfully modelling user narratives from their online social media posts, which could potentially be useful in several different applications. We have developed a novel and effective model called \\texttt{NarrationDep}, which focuses on detecting narratives associated with depression. By analyzing a user's tweets, \\texttt{NarrationDep} accurately identifies crucial narratives. \\texttt{NarrationDep} is a deep learning framework that jointly models individual user tweet representations and clusters of users' tweets. As a result, \\texttt{NarrationDep} is characterized by a novel two-layer deep learning model: the first layer models using social media text posts, and the second layer learns semantic representations of tweets associated with a cluster. To faithfully model these cluster representations, the second layer incorporates a novel component that hierarchically learns from users' posts. The results demonstrate that our framework outperforms other comparative models including recently developed models on a variety of datasets.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17193",
        "abstract url": "https://arxiv.org/abs/2407.17193",
        "title": "Unpaired Photo-realistic Image Deraining with Energy-informed Diffusion Model",
        "rating": "1",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "Diffusion",
                "Deraining"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing unpaired image deraining approaches face challenges in accurately capture the distinguishing characteristics between the rainy and clean domains, resulting in residual degradation and color distortion within the reconstructed images. To this end, we propose an energy-informed diffusion model for unpaired photo-realistic image deraining (UPID-EDM). Initially, we delve into the intricate visual-language priors embedded within the contrastive language-image pre-training model (CLIP), and demonstrate that the CLIP priors aid in the discrimination of rainy and clean images. Furthermore, we introduce a dual-consistent energy function (DEF) that retains the rain-irrelevant characteristics while eliminating the rain-relevant features. This energy function is trained by the non-corresponding rainy and clean images. In addition, we employ the rain-relevance discarding energy function (RDEF) and the rain-irrelevance preserving energy function (RPEF) to direct the reverse sampling procedure of a pre-trained diffusion model, effectively removing the rain streaks while preserving the image contents. Extensive experiments demonstrate that our energy-informed model surpasses the existing unpaired learning approaches in terms of both supervised and no-reference metrics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17213",
        "abstract url": "https://arxiv.org/abs/2407.17213",
        "title": "Spectrum-Informed Multistage Neural Networks: Multiscale Function Approximators of Machine Precision",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Deep learning frameworks have become powerful tools for approaching scientific problems such as turbulent flow, which has wide-ranging applications. In practice, however, existing scientific machine learning approaches have difficulty fitting complex, multi-scale dynamical systems to very high precision, as required in scientific contexts. We propose using the novel multistage neural network approach with a spectrum-informed initialization to learn the residue from the previous stage, utilizing the spectral biases associated with neural networks to capture high frequency features in the residue, and successfully tackle the spectral bias of neural networks. This approach allows the neural network to fit target functions to double floating-point machine precision $O(10^{-16})$.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 3 figures, ICML 2024 workshop (AI for Science: Scaling in AI for Scientific Discovery)"
    },
    {
        "paper id": "2407.17227",
        "abstract url": "https://arxiv.org/abs/2407.17227",
        "title": "LEAN-GitHub: Compiling GitHub LEAN repositories for a versatile LEAN prover",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recently, large language models have presented promising results in aiding formal mathematical reasoning. However, their performance is restricted due to the scarcity of formal theorem-proving data, which requires additional effort to be extracted from raw formal language corpora. Meanwhile, a significant amount of human-written formal language corpora remains underutilized. To address this issue, we propose LEAN-GitHub, a dataset consisting of large-scale formal data extracted from almost all Lean 4 repositories on GitHub. After fine-tuning InternLM-math-plus on this dataset, our model achieved accuracies of 48.8% with a single pass and 54.5% with 64 passes on the Lean 4 miniF2F test, surpassing state-of-the-art method at 52%. And it also achieves state-of-the-art on two other Lean 4 benchmarks (ProofNet and Putnam) targeting different fields/levels of math. These results demonstrate that our proposed dataset is beneficial for formal reasoning on a wide range of math topics. We open-source our model at https://GitHub. com/InternLM/InternLM-Math and our data at https://huggingface.co/ datasets/InternLM/Lean-GitHub",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17250",
        "abstract url": "https://arxiv.org/abs/2407.17250",
        "title": "Reduction of Nonlinear Distortion in Condenser Microphones Using a Simple Post-Processing Technique",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we introduce a novel approach for effectively reducing nonlinear distortion in single back-plate condenser microphones, i.e., most MEMS microphones, studio recording condenser microphones, and laboratory measurement microphones. This simple post-processing technique can be easily integrated on an external hardware such as an analog circuit, microcontroller, audio codec, DSP unit, or within the ASIC chip in a case of MEMS microphones. It significantly reduces microphone distortion across its frequency and dynamic range. It relies on a single parameter, which can be derived from either the microphone's physical parameters or a straightforward measurement presented in this paper. An optimal estimate of this parameter achieves the best distortion reduction, whereas overestimating it never increases distortion beyond the original level. The technique was tested on a MEMS microphone. Our findings indicate that for harmonic excitation the proposed technique reduces the second harmonic by approximately 40 dB, leading to a significant reduction in the Total Harmonic Distortion (THD). The efficiency of the distortion reduction technique for more complex signals is demonstrated through two-tone and multitone experiments, where second-order intermodulation products are reduced by at least 20 dB.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "10 pages, 9 figures"
    },
    {
        "paper id": "2407.17291",
        "abstract url": "https://arxiv.org/abs/2407.17291",
        "title": "How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we address the growing issue of misleading charts, a prevalent problem that undermines the integrity of information dissemination. Misleading charts can distort the viewer's perception of data, leading to misinterpretations and decisions based on false information. The development of effective automatic detection methods for misleading charts is an urgent field of research. The recent advancement of multimodal Large Language Models (LLMs) has introduced a promising direction for addressing this challenge. We explored the capabilities of these models in analyzing complex charts and assessing the impact of different prompting strategies on the models' analyses. We utilized a dataset of misleading charts collected from the internet by prior research and crafted nine distinct prompts, ranging from simple to complex, to test the ability of four different multimodal LLMs in detecting over 21 different chart issues. Through three experiments--from initial exploration to detailed analysis--we progressively gained insights into how to effectively prompt LLMs to identify misleading charts and developed strategies to address the scalability challenges encountered as we expanded our detection range from the initial five issues to 21 issues in the final experiment. Our findings reveal that multimodal LLMs possess a strong capability for chart comprehension and critical thinking in data interpretation. There is significant potential in employing multimodal LLMs to counter misleading information by supporting critical thinking and enhancing visualization literacy. This study demonstrates the applicability of LLMs in addressing the pressing concern of misleading charts.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "To be presented at IEEE VIS 2024"
    },
    {
        "paper id": "2407.17336",
        "abstract url": "https://arxiv.org/abs/2407.17336",
        "title": "Cascaded Light Propagation Volumes using Spherical Radial Basis Functions",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a contribution made to one of the newest methods for simulating indirect lighting in dynamic scenes , the cascaded light propagation volumes . Our contribution consists on using Spherical Radial Basis Functions instead of Spherical Harmonic, since the first achieves much better results when many coefficients are used. We explain how to integrate the Spherical Radial Basis Functions with the cascaded light propagation volumes, and evaluate our technique against the same implementation, but with Spherical harmonics.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17348",
        "abstract url": "https://arxiv.org/abs/2407.17348",
        "title": "DexGANGrasp: Dexterous Generative Adversarial Grasping Synthesis for Task-Oriented Manipulation",
        "rating": "1",
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ]
        ],
        "abstract": "We introduce DexGanGrasp, a dexterous grasping synthesis method that generates and evaluates grasps with single view in real time. DexGanGrasp comprises a Conditional Generative Adversarial Networks (cGANs)-based DexGenerator to generate dexterous grasps and a discriminator-like DexEvalautor to assess the stability of these grasps. Extensive simulation and real-world expriments showcases the effectiveness of our proposed method, outperforming the baseline FFHNet with an 18.57% higher success rate in real-world evaluation. We further extend DexGanGrasp to DexAfford-Prompt, an open-vocabulary affordance grounding pipeline for dexterous grasping leveraging Multimodal Large Language Models (MLLMs) and Vision Language Models (VLMs), to achieve task-oriented grasping with successful real-world deployments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2407.17349",
        "abstract url": "https://arxiv.org/abs/2407.17349",
        "title": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (\\texttt{SocraticLLM}), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named \\texttt{SocraticMATH}, which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of \\texttt{SocraticLLM} by comparing it with several strong generative models. The codes and datasets are available on \\url{https://github.com/ECNU-ICALK/SocraticMath}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted By CIKM 2024"
    },
    {
        "paper id": "2407.17354",
        "abstract url": "https://arxiv.org/abs/2407.17354",
        "title": "Deep Spherical Superpixels",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Over the years, the use of superpixel segmentation has become very popular in various applications, serving as a preprocessing step to reduce data size by adapting to the content of the image, regardless of its semantic content. While the superpixel segmentation of standard planar images, captured with a 90\u00b0 field of view, has been extensively studied, there has been limited focus on dedicated methods to omnidirectional or spherical images, captured with a 360\u00b0 field of view. In this study, we introduce the first deep learning-based superpixel segmentation approach tailored for omnidirectional images called DSS (for Deep Spherical Superpixels). Our methodology leverages on spherical CNN architectures and the differentiable K-means clustering paradigm for superpixels, to generate superpixels that follow the spherical geometry. Additionally, we propose to use data augmentation techniques specifically designed for 360\u00b0 images, enabling our model to efficiently learn from a limited set of annotated omnidirectional data. Our extensive validation across two datasets demonstrates that taking into account the inherent circular geometry of such images into our framework improves the segmentation performance over traditional and deep learning-based superpixel methods. Our code is available online.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17383",
        "abstract url": "https://arxiv.org/abs/2407.17383",
        "title": "A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Writing, as an omnipresent form of human communication, permeates nearly every aspect of contemporary life. Consequently, inaccuracies or errors in written communication can lead to profound consequences, ranging from financial losses to potentially life-threatening situations. Spelling mistakes, among the most prevalent writing errors, are frequently encountered due to various factors. This research aims to identify and rectify diverse spelling errors in text using neural networks, specifically leveraging the Bidirectional Encoder Representations from Transformers (BERT) masked language model. To achieve this goal, we compiled a comprehensive dataset encompassing both non-real-word and real-word errors after categorizing different types of spelling mistakes. Subsequently, multiple pre-trained BERT models were employed. To ensure optimal performance in correcting misspelling errors, we propose a combined approach utilizing the BERT masked language model and Levenshtein distance. The results from our evaluation data demonstrate that the system presented herein exhibits remarkable capabilities in identifying and rectifying spelling mistakes, often surpassing existing systems tailored for the Persian language.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "12 pages, 9 figures, 5 tables"
    },
    {
        "paper id": "2407.17385",
        "abstract url": "https://arxiv.org/abs/2407.17385",
        "title": "Causal modelling without counterfactuals and individualised effects",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "The most common approach to causal modelling is the potential outcomes framework due to Neyman and Rubin. In this framework, outcomes of counterfactual treatments are assumed to be well-defined. This metaphysical assumption is often thought to be problematic yet indispensable. The conventional approach relies not only on counterfactuals, but also on abstract notions of distributions and assumptions of independence that are not directly testable. In this paper, we construe causal inference as treatment-wise predictions for finite populations where all assumptions are testable; this means that one can not only test predictions themselves (without any fundamental problem), but also investigate sources of error when they fail. The new framework highlights the model-dependence of causal claims as well as the difference between statistical and scientific inference.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "econ.EM"
        ],
        "comment": "Presented at the Humans, Algorithmic Decision-Making and Society Workshop at ICML 2024"
    },
    {
        "paper id": "2407.17387",
        "abstract url": "https://arxiv.org/abs/2407.17387",
        "title": "PERSONA: A Reproducible Testbed for Pluralistic Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of language models (LMs) necessitates robust alignment with diverse user values. However, current preference optimization approaches often fail to capture the plurality of user opinions, instead reinforcing majority viewpoints and marginalizing minority perspectives. We introduce PERSONA, a reproducible test bed designed to evaluate and improve pluralistic alignment of LMs. We procedurally generate diverse user profiles from US census data, resulting in 1,586 synthetic personas with varied demographic and idiosyncratic attributes. We then generate a large-scale evaluation dataset containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic personas. Leveraging this dataset, we systematically evaluate LM capabilities in role-playing diverse users, verified through human judges, and the establishment of both a benchmark, PERSONA Bench, for pluralistic alignment approaches as well as an extensive dataset to create new and future benchmarks. The full dataset and benchmarks are available here: https://www.synthlabs.ai/research/persona.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17390",
        "abstract url": "https://arxiv.org/abs/2407.17390",
        "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces CovScore, an automatic reference-less methodology for evaluating thematic title sets, extracted from a corpus of documents. While such extraction methods are widely used, evaluating their effectiveness remains an open question. Moreover, some existing practices heavily rely on slow and laborious human annotation procedures. Inspired by recently introduced LLM-based judge methods, we propose a novel methodology that decomposes quality into five main metrics along different aspects of evaluation. This framing simplifies and expedites the manual evaluation process and enables automatic and independent LLM-based evaluation. As a test case, we apply our approach to a corpus of Holocaust survivor testimonies, motivated both by its relevance to title set extraction and by the moral significance of this pursuit. We validate the methodology by experimenting with naturalistic and synthetic title set generation systems and compare their performance with the methodology.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17395",
        "abstract url": "https://arxiv.org/abs/2407.17395",
        "title": "Five reasons against assuming a data-generating distribution in Machine Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Machine Learning research, as most of Statistics, heavily relies on the concept of a data-generating probability distribution. As data points are thought to be sampled from such a distribution, we can learn from observed data about this distribution and, thus, predict future data points drawn from it (with some probability of success). Drawing on scholarship across disciplines, we here argue that this framework is not always a good model. Not only do such true probability distributions not exist; the framework can also be misleading and obscure both the choices made and the goals pursued in machine learning practice. We suggest an alternative framework that focuses on finite populations rather than abstract distributions; while classical learning theory can be left almost unchanged, it opens new opportunities, especially to model sampling. We compile these considerations into five reasons for modelling machine learning -- in some settings -- with finite distributions rather than generative distributions, both to be more faithful to practice and to provide novel theoretical insights.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Presented at the Humans, Algorithmic Decision-Making and Society Workshop at ICML 2024"
    },
    {
        "paper id": "2407.17399",
        "abstract url": "https://arxiv.org/abs/2407.17399",
        "title": "Self-Calibrated Variance-Stabilizing Transformations for Real-World Image Denoising",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Supervised deep learning has become the method of choice for image denoising. It involves the training of neural networks on large datasets composed of pairs of noisy and clean images. However, the necessity of training data that are specific to the targeted application constrains the widespread use of denoising networks. Recently, several approaches have been developed to overcome this difficulty by whether artificially generating realistic clean/noisy image pairs, or training exclusively on noisy images. In this paper, we show that, contrary to popular belief, denoising networks specialized in the removal of Gaussian noise can be efficiently leveraged in favor of real-world image denoising, even without additional training. For this to happen, an appropriate variance-stabilizing transform (VST) has to be applied beforehand. We propose an algorithm termed Noise2VST for the learning of such a model-free VST. Our approach requires only the input noisy image and an off-the-shelf Gaussian denoiser. We demonstrate through extensive experiments the efficiency and superiority of Noise2VST in comparison to existing methods trained in the absence of specific clean/noisy pairs.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17406",
        "abstract url": "https://arxiv.org/abs/2407.17406",
        "title": "Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Syntactic Transformer language models aim to achieve better generalization through simultaneously modeling syntax trees and sentences. While prior work has been focusing on adding constituency-based structures to Transformers, we introduce Dependency Transformer Grammars (DTGs), a new class of Transformer language model with explicit dependency-based inductive bias. DTGs simulate dependency transition systems with constrained attention patterns by modifying attention masks, incorporate the stack information through relative positional encoding, and augment dependency arc representation with a combination of token embeddings and operation embeddings. When trained on a dataset of sentences annotated with dependency trees, DTGs achieve better generalization while maintaining comparable perplexity with Transformer language model baselines. DTGs also outperform recent constituency-based models, showing that dependency can better guide Transformer language models. Our code is released at https://github.com/zhaoyd1/Dep_Transformer_Grammars.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17412",
        "abstract url": "https://arxiv.org/abs/2407.17412",
        "title": "(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale neural networks have demonstrated remarkable performance in different domains like vision and language processing, although at the cost of massive computation resources. As illustrated by compression literature, structural model pruning is a prominent algorithm to encourage model efficiency, thanks to its acceleration-friendly sparsity patterns. One of the key questions of structural pruning is how to estimate the channel significance. In parallel, work on data-centric AI has shown that prompting-based techniques enable impressive generalization of large language models across diverse downstream tasks. In this paper, we investigate a charming possibility - \\textit{leveraging visual prompts to capture the channel importance and derive high-quality structural sparsity}. To this end, we propose a novel algorithmic framework, namely \\texttt{PASS}. It is a tailored hyper-network to take both visual prompts and network weight statistics as input, and output layer-wise channel sparsity in a recurrent manner. Such designs consider the intrinsic channel dependency between layers. Comprehensive experiments across multiple network architectures and six datasets demonstrate the superiority of \\texttt{PASS} in locating good structural sparsity. For example, at the same FLOPs level, \\texttt{PASS} subnetworks achieve $1\\%\\sim 3\\%$ better accuracy on Food101 dataset; or with a similar performance of $80\\%$ accuracy, \\texttt{PASS} subnetworks obtain $0.35\\times$ more speedup than the baselines.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2407.17442",
        "abstract url": "https://arxiv.org/abs/2407.17442",
        "title": "AHMF: Adaptive Hybrid-Memory-Fusion Model for Driver Attention Prediction",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate driver attention prediction can serve as a critical reference for intelligent vehicles in understanding traffic scenes and making informed driving decisions. Though existing studies on driver attention prediction improved performance by incorporating advanced saliency detection techniques, they overlooked the opportunity to achieve human-inspired prediction by analyzing driving tasks from a cognitive science perspective. During driving, drivers' working memory and long-term memory play crucial roles in scene comprehension and experience retrieval, respectively. Together, they form situational awareness, facilitating drivers to quickly understand the current traffic situation and make optimal decisions based on past driving experiences. To explicitly integrate these two types of memory, this paper proposes an Adaptive Hybrid-Memory-Fusion (AHMF) driver attention prediction model to achieve more human-like predictions. Specifically, the model first encodes information about specific hazardous stimuli in the current scene to form working memories. Then, it adaptively retrieves similar situational experiences from the long-term memory for final prediction. Utilizing domain adaptation techniques, the model performs parallel training across multiple datasets, thereby enriching the accumulated driving experience within the long-term memory module. Compared to existing models, our model demonstrates significant improvements across various metrics on multiple public datasets, proving the effectiveness of integrating hybrid memories in driver attention prediction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17459",
        "abstract url": "https://arxiv.org/abs/2407.17459",
        "title": "Hidden or Inferred: Fair Learning-To-Rank with Unknown Demographics",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "As learning-to-rank models are increasingly deployed for decision-making in areas with profound life implications, the FairML community has been developing fair learning-to-rank (LTR) models. These models rely on the availability of sensitive demographic features such as race or sex. However, in practice, regulatory obstacles and privacy concerns protect this data from collection and use. As a result, practitioners may either need to promote fairness despite the absence of these features or turn to demographic inference tools to attempt to infer them. Given that these tools are fallible, this paper aims to further understand how errors in demographic inference impact the fairness performance of popular fair LTR strategies. In which cases would it be better to keep such demographic attributes hidden from models versus infer them? We examine a spectrum of fair LTR strategies ranging from fair LTR with and without demographic features hidden versus inferred to fairness-unaware LTR followed by fair re-ranking. We conduct a controlled empirical investigation modeling different levels of inference errors by systematically perturbing the inferred sensitive attribute. We also perform three case studies with real-world datasets and popular open-source inference methods. Our findings reveal that as inference noise grows, LTR-based methods that incorporate fairness considerations into the learning process may increase bias. In contrast, fair re-ranking strategies are more robust to inference errors. All source code, data, and experimental artifacts of our experimental study are available here: https://github.com/sewen007/hoiltr.git",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": "This paper has been accepted by AAAI/AIES to the AIES 2024 conference"
    },
    {
        "paper id": "2407.17468",
        "abstract url": "https://arxiv.org/abs/2407.17468",
        "title": "WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "While hallucinations of large language models (LLMs) prevail as a major challenge, existing evaluation benchmarks on factuality do not cover the diverse domains of knowledge that the real-world users of LLMs seek information about. To bridge this gap, we introduce WildHallucinations, a benchmark that evaluates factuality. It does so by prompting LLMs to generate information about entities mined from user-chatbot conversations in the wild. These generations are then automatically fact-checked against a systematically curated knowledge source collected from web search. Notably, half of these real-world entities do not have associated Wikipedia pages. We evaluate 118,785 generations from 15 LLMs on 7,919 entities. We find that LLMs consistently hallucinate more on entities without Wikipedia pages and exhibit varying hallucination rates across different domains. Finally, given the same base models, adding a retrieval component only slightly reduces hallucinations but does not eliminate hallucinations.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17469",
        "abstract url": "https://arxiv.org/abs/2407.17469",
        "title": "I Could've Asked That: Reformulating Unanswerable Questions",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "When seeking information from unfamiliar documents, users frequently pose questions that cannot be answered by the documents. While existing large language models (LLMs) identify these unanswerable questions, they do not assist users in reformulating their questions, thereby reducing their overall utility. We curate CouldAsk, an evaluation benchmark composed of existing and new datasets for document-grounded question answering, specifically designed to study reformulating unanswerable questions. We evaluate state-of-the-art open-source and proprietary LLMs on CouldAsk. The results demonstrate the limited capabilities of these models in reformulating questions. Specifically, GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the time, respectively. Error analysis shows that 62% of the unsuccessful reformulations stem from the models merely rephrasing the questions or even generating identical questions. We publicly release the benchmark and the code to reproduce the experiments.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17546",
        "abstract url": "https://arxiv.org/abs/2407.17546",
        "title": "Exploring Domain Robust Lightweight Reward Models based on Router Mechanism",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models have heavily relied on the large reward model from reinforcement learning from human feedback for fine-tuning. However, the use of a single reward model across various domains may not always be optimal, often requiring retraining from scratch when new domain data is introduced. To address these challenges, we explore the utilization of small language models operating in a domain-specific manner based on router mechanisms. Our three approaches are: 1) utilize mixture of experts to form a single reward model by modularizing an internal router and experts, 2) employing external router to select the appropriate reward model from multiple domain-specific models, and 3) the framework reduces parameter size by loading reward models and router adapters onto a single small language model using adapters. Experimental validation underscores the effectiveness of our approach, demonstrating performance comparable to baseline methods while also reducing the total parameter size.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "This paper is accepted for ACL 2024"
    },
    {
        "paper id": "2407.17605",
        "abstract url": "https://arxiv.org/abs/2407.17605",
        "title": "Coupling Speech Encoders with Downstream Text Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present a modular approach to building cascade speech translation (AST) models that guarantees that the resulting model performs no worse than the 1-best cascade baseline while preserving state-of-the-art speech recognition (ASR) and text translation (MT) performance for a given task. Our novel contribution is the use of an ``exporter'' layer that is trained under L2-loss to ensure a strong match between ASR embeddings and the MT token embeddings for the 1-best sequence. The ``exporter'' output embeddings are fed directly to the MT model in lieu of 1-best token embeddings, thus guaranteeing that the resulting model performs no worse than the 1-best cascade baseline, while allowing back-propagation gradient to flow from the MT model into the ASR components. The matched-embeddings cascade architecture provide a significant improvement over its 1-best counterpart in scenarios where incremental training of the MT model is not an option and yet we seek to improve quality by leveraging (speech, transcription, translated transcription) data provided with the AST task. The gain disappears when the MT model is incrementally trained on the parallel text data available with the AST task. The approach holds promise for other scenarios that seek to couple ASR encoders and immutable text models, such at large language models (LLM).",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17628",
        "abstract url": "https://arxiv.org/abs/2407.17628",
        "title": "PEEKABOO: Hiding parts of an image for unsupervised object localization",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Localizing objects in an unsupervised manner poses significant challenges due to the absence of key visual information such as the appearance, type and number of objects, as well as the lack of labeled object classes typically available in supervised settings. While recent approaches to unsupervised object localization have demonstrated significant progress by leveraging self-supervised visual representations, they often require computationally intensive training processes, resulting in high resource demands in terms of computation, learnable parameters, and data. They also lack explicit modeling of visual context, potentially limiting their accuracy in object localization. To tackle these challenges, we propose a single-stage learning framework, dubbed PEEKABOO, for unsupervised object localization by learning context-based representations at both the pixel- and shape-level of the localized objects through image masking. The key idea is to selectively hide parts of an image and leverage the remaining image information to infer the location of objects without explicit supervision. The experimental results, both quantitative and qualitative, across various benchmark datasets, demonstrate the simplicity, effectiveness and competitive performance of our approach compared to state-of-the-art methods in both single object discovery and unsupervised salient object detection tasks. Code and pre-trained models are available at: https://github.com/hasibzunair/peekaboo",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17629",
        "abstract url": "https://arxiv.org/abs/2407.17629",
        "title": "Papilusion at DAGPap24: Paper or Illusion? Detecting AI-generated Scientific Papers",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents Papilusion, an AI-generated scientific text detector developed within the DAGPap24 shared task on detecting automatically generated scientific papers. We propose an ensemble-based approach and conduct ablation studies to analyze the effect of the detector configurations on the performance. Papilusion is ranked 6th on the leaderboard, and we improve our performance after the competition ended, achieving 99.46 (+9.63) of the F1-score on the official test set.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "to appear in \"The 4th Workshop on Scholarly Document Processing @ ACL 2024\" proceedings"
    },
    {
        "paper id": "2407.17678",
        "abstract url": "https://arxiv.org/abs/2407.17678",
        "title": "Efficient LLM Training and Serving with Heterogeneous Context Sharding among Attention Heads",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Existing LLM training and inference frameworks struggle in boosting efficiency with sparsity while maintaining the integrity of context and model architecture. Inspired by the sharding concept in database and the fact that attention parallelizes over heads on accelerators, we propose Sparsely-Sharded (S2) Attention, an attention algorithm that allocates heterogeneous context partitions for different attention heads to divide and conquer. S2-Attention enforces each attention head to only attend to a partition of contexts following a strided sparsity pattern, while the full context is preserved as the union of all the shards. As attention heads are processed in separate thread blocks, the context reduction for each head can thus produce end-to-end speed-up and memory reduction. At inference, LLMs trained with S2-Attention can then take the KV cache reduction as free meals with guaranteed model quality preserve. In experiments, we show S2-Attentioncan provide as much as (1) 25.3X wall-clock attention speed-up over FlashAttention-2, resulting in 6X reduction in end-to-end training time and 10X inference latency, (2) on-par model training quality compared to default attention, (3)perfect needle retrieval accuracy over 32K context window. On top of the algorithm, we build DKernel, an LLM training and inference kernel library that allows users to customize sparsity patterns for their own models. We open-sourced DKerneland make it compatible with Megatron, Pytorch, and vLLM.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2407.17688",
        "abstract url": "https://arxiv.org/abs/2407.17688",
        "title": "Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in executing tasks based on natural language queries. However, these models, trained on curated datasets, inherently embody biases ranging from racial to national and gender biases. It remains uncertain whether these biases impact the performance of LLMs for certain tasks. In this study, we investigate the political biases of LLMs within the stance classification task, specifically examining whether these models exhibit a tendency to more accurately classify politically-charged stances. Utilizing three datasets, seven LLMs, and four distinct prompting schemes, we analyze the performance of LLMs on politically oriented statements and targets. Our findings reveal a statistically significant difference in the performance of LLMs across various politically oriented stance classification tasks. Furthermore, we observe that this difference primarily manifests at the dataset level, with models and prompting schemes showing statistically similar performances across different stance classification datasets. Lastly, we observe that when there is greater ambiguity in the target the statement is directed towards, LLMs have poorer stance classification accuracy. Code & Dataset: http://doi.org/10.5281/zenodo.12938478",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted at ICWSM 2025"
    },
    {
        "paper id": "2407.17695",
        "abstract url": "https://arxiv.org/abs/2407.17695",
        "title": "Enhancing Agent Learning through World Dynamics Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "While large language models (LLMs) have been increasingly deployed across tasks in language understanding and interactive decision-making, their impressive performance is largely due to the comprehensive and in-depth domain knowledge embedded within them. However, the extent of this knowledge can vary across different domains. Existing methods often assume that LLMs already possess such comprehensive and in-depth knowledge of their environment, overlooking potential gaps in their understanding of actual world dynamics. To address this gap, we introduce Discover, Verify, and Evolve (DiVE), a framework that discovers world dynamics from a small number of demonstrations, verifies the correctness of these dynamics, and evolves new, advanced dynamics tailored to the current situation. Through extensive evaluations, we analyze the impact of each component on performance and compare the automatically generated dynamics from DiVE with human-annotated world dynamics. Our results demonstrate that LLMs guided by DiVE can make better decisions, achieving rewards comparable to human players in the Crafter environment.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17716",
        "abstract url": "https://arxiv.org/abs/2407.17716",
        "title": "Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech emotion recognition (SER) systems often struggle in real-world environments, where ambient noise severely degrades their performance. This paper explores a novel approach that exploits prior knowledge of testing environments to maximize SER performance under noisy conditions. To address this task, we propose a text-guided, environment-aware training where an SER model is trained with contaminated speech samples and their paired noise description. We use a pre-trained text encoder to extract the text-based environment embedding and then fuse it to a transformer-based SER model during training and inference. We demonstrate the effectiveness of our approach through our experiment with the MSP-Podcast corpus and real-world additive noise samples collected from the Freesound repository. Our experiment indicates that the text-based environment descriptions processed by a large language model (LLM) produce representations that improve the noise-robustness of the SER system. In addition, our proposed approach with an LLM yields better performance than our environment-agnostic baselines, especially in low signal-to-noise ratio (SNR) conditions. When testing at -5dB SNR level, our proposed method shows better performance than our best baseline model by 31.8 % (arousal), 23.5% (dominance), and 9.5% (valence).",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17738",
        "abstract url": "https://arxiv.org/abs/2407.17738",
        "title": "Enhancing Fine-grained Object Detection in Aerial Images via Orthogonal Mapping",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fine-Grained Object Detection (FGOD) is a critical task in high-resolution aerial image analysis. This letter introduces Orthogonal Mapping (OM), a simple yet effective method aimed at addressing the challenge of semantic confusion inherent in FGOD. OM introduces orthogonal constraints in the feature space by decoupling features from the last layer of the classification branch with a class-wise orthogonal vector basis. This effectively mitigates semantic confusion and enhances classification accuracy. Moreover, OM can be seamlessly integrated into mainstream object detectors. Extensive experiments conducted on three FGOD datasets (FAIR1M, ShipRSImageNet, and MAR20) demonstrate the effectiveness and superiority of the proposed approach. Notably, with just one line of code, OM achieves a 4.08% improvement in mean Average Precision (mAP) over FCOS on the ShipRSImageNet dataset. Codes are released at https://github.com/ZhuHaoranEIS/Orthogonal-FGOD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17744",
        "abstract url": "https://arxiv.org/abs/2407.17744",
        "title": "Balancing Complementarity and Consistency via Delayed Activation in Incomplete Multi-view Clustering",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper study one challenging issue in incomplete multi-view clustering, where valuable complementary information from other views is always ignored. To be specific, we propose a framework that effectively balances Complementarity and Consistency information in Incomplete Multi-view Clustering (CoCo-IMC). Specifically, we design a dual network of delayed activation, which achieves a balance of complementarity and consistency among different views. The delayed activation could enriches the complementarity information that was ignored during consistency learning. Then, we recover the incomplete information and enhance the consistency learning by minimizing the conditional entropy and maximizing the mutual information across different views. This could be the first theoretical attempt to incorporate delayed activation into incomplete data recovery and the balance of complementarity and consistency. We have proved the effectiveness of CoCo-IMC in extensive comparative experiments with 12 state-of-the-art baselines on four publicly available datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.18985",
        "abstract url": "https://arxiv.org/abs/2407.18985",
        "title": "Implementation and Applications of WakeWords Integrated with Speaker Recognition: A Case Study",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper explores the application of artificial intelligence techniques in audio and voice processing, focusing on the integration of wake words and speaker recognition for secure access in embedded systems. With the growing prevalence of voice-activated devices such as Amazon Alexa, ensuring secure and user-specific interactions has become paramount. Our study aims to enhance the security framework of these systems by leveraging wake words for initial activation and speaker recognition to validate user permissions. By incorporating these AI-driven methodologies, we propose a robust solution that restricts system usage to authorized individuals, thereby mitigating unauthorized access risks. This research delves into the algorithms and technologies underpinning wake word detection and speaker recognition, evaluates their effectiveness in real-world applications, and discusses the potential for their implementation in various embedded systems, emphasizing security and user convenience. The findings underscore the feasibility and advantages of employing these AI techniques to create secure, user-friendly voice-activated systems.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21056",
        "abstract url": "https://arxiv.org/abs/2407.21056",
        "title": "What Matters in Explanations: Towards Explainable Fake Review Detection Focusing on Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Customers' reviews and feedback play crucial role on electronic commerce~(E-commerce) platforms like Amazon, Zalando, and eBay in influencing other customers' purchasing decisions. However, there is a prevailing concern that sellers often post fake or spam reviews to deceive potential customers and manipulate their opinions about a product. Over the past decade, there has been considerable interest in using machine learning (ML) and deep learning (DL) models to identify such fraudulent reviews. Unfortunately, the decisions made by complex ML and DL models - which often function as \\emph{black-boxes} - can be surprising and difficult for general users to comprehend. In this paper, we propose an explainable framework for detecting fake reviews with high precision in identifying fraudulent content with explanations and investigate what information matters most for explaining particular decisions by conducting empirical user evaluation. Initially, we develop fake review detection models using DL and transformer models including XLNet and DistilBERT. We then introduce layer-wise relevance propagation (LRP) technique for generating explanations that can map the contributions of words toward the predicted class. The experimental results on two benchmark fake review detection datasets demonstrate that our predictive models achieve state-of-the-art performance and outperform several existing methods. Furthermore, the empirical user evaluation of the generated explanations concludes which important information needs to be considered in generating explanations in the context of fake review identification.",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17007",
        "abstract url": "https://arxiv.org/abs/2407.17007",
        "title": "Pensieve Discuss: Scalable Small-Group CS Tutoring System with AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Small-group tutoring in Computer Science (CS) is effective, but presents the challenge of providing a dedicated tutor for each group and encouraging collaboration among group members at scale. We present Pensieve Discuss, a software platform that integrates synchronous editing for scaffolded programming problems with online human and AI tutors, designed to improve student collaboration and experience during group tutoring sessions. Our semester-long deployment to 800 students in a CS1 course demonstrated consistently high collaboration rates, positive feedback about the AI tutor's helpfulness and correctness, increased satisfaction with the group tutoring experience, and a substantial increase in question volume. The use of our system was preferred over an interface lacking AI tutors and synchronous editing capabilities. Our experiences suggest that small-group tutoring sessions are an important avenue for future research in educational AI.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "6 pages, 7 figures, 4 tables, 1 page of references"
    },
    {
        "paper id": "2407.17032",
        "abstract url": "https://arxiv.org/abs/2407.17032",
        "title": "Gymnasium: A Standard Interface for Reinforcement Learning Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Gymnasium is an open-source library providing an API for reinforcement learning environments. Its main contribution is a central abstraction for wide interoperability between benchmark environments and training algorithms. Gymnasium comes with various built-in environments and utilities to simplify researchers' work along with being supported by most training libraries. This paper outlines the main design decisions for Gymnasium, its key features, and the differences to alternative APIs.",
        "subjects": [
            "cs.LG",
            "cs.DL"
        ],
        "comment": "6 pages, 1 figure, preprint"
    },
    {
        "paper id": "2407.17040",
        "abstract url": "https://arxiv.org/abs/2407.17040",
        "title": "Time Series Imputation with Multivariate Radial Basis Function Neural Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Researchers have been persistently working to address the issue of missing values in time series data. Numerous models have been proposed, striving to estimate the distribution of the data. The Radial Basis Functions Neural Network (RBFNN) has recently exhibited exceptional performance in estimating data distribution. In this paper, we propose a time series imputation model based on RBFNN. Our imputation model learns local information from timestamps to create a continuous function. Additionally, we incorporate time gaps to facilitate learning information considering the missing terms of missing values. We name this model the Missing Imputation Multivariate RBFNN (MIM-RBFNN). However, MIM-RBFNN relies on a local information-based learning approach, which presents difficulties in utilizing temporal information. Therefore, we propose an extension called the Missing Value Imputation Recurrent Neural Network with Continuous Function (MIRNN-CF) using the continuous function generated by MIM-RBFNN. We evaluate the performance using two real-world datasets with non-random missing and random missing patterns, and conduct an ablation study comparing MIM-RBFNN and MIRNN-CF.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17053",
        "abstract url": "https://arxiv.org/abs/2407.17053",
        "title": "Automated Code-centric Software Vulnerability Assessment: How Far Are We? An Empirical Study in C/C++",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Background: The C and C++ languages hold significant importance in Software Engineering research because of their widespread use in practice. Numerous studies have utilized Machine Learning (ML) and Deep Learning (DL) techniques to detect software vulnerabilities (SVs) in the source code written in these languages. However, the application of these techniques in function-level SV assessment has been largely unexplored. SV assessment is increasingly crucial as it provides detailed information on the exploitability, impacts, and severity of security defects, thereby aiding in their prioritization and remediation. Aims: We conduct the first empirical study to investigate and compare the performance of ML and DL models, many of which have been used for SV detection, for function-level SV assessment in C/C++. Method: Using 9,993 vulnerable C/C++ functions, we evaluated the performance of six multi-class ML models and five multi-class DL models for the SV assessment at the function level based on the Common Vulnerability Scoring System (CVSS). We further explore multi-task learning, which can leverage common vulnerable code to predict all SV assessment outputs simultaneously in a single model, and compare the effectiveness and efficiency of this model type with those of the original multi-class models. Results: We show that ML has matching or even better performance compared to the multi-class DL models for function-level SV assessment with significantly less training time. Employing multi-task learning allows the DL models to perform significantly better, with an average of 8-22% increase in Matthews Correlation Coefficient (MCC). Conclusions: We distill the practices of using data-driven techniques for function-level SV assessment in C/C++, including the use of multi-task DL to balance efficiency and effectiveness. This can establish a strong foundation for future work in this area.",
        "subjects": [
            "cs.SE",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "Accepted as a full paper in the technical track at The International Symposium on Empirical Software Engineering and Measurement (ESEM) 2024"
    },
    {
        "paper id": "2407.17065",
        "abstract url": "https://arxiv.org/abs/2407.17065",
        "title": "PatchFinder: A Two-Phase Approach to Security Patch Tracing for Disclosed Vulnerabilities in Open-Source Software",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Open-source software (OSS) vulnerabilities are increasingly prevalent, emphasizing the importance of security patches. However, in widely used security platforms like NVD, a substantial number of CVE records still lack trace links to patches. Although rank-based approaches have been proposed for security patch tracing, they heavily rely on handcrafted features in a single-step framework, which limits their effectiveness. In this paper, we propose PatchFinder, a two-phase framework with end-to-end correlation learning for better-tracing security patches. In the **initial retrieval** phase, we employ a hybrid patch retriever to account for both lexical and semantic matching based on the code changes and the description of a CVE, to narrow down the search space by extracting those commits as candidates that are similar to the CVE descriptions. Afterwards, in the **re-ranking** phase, we design an end-to-end architecture under the supervised fine-tuning paradigm for learning the semantic correlations between CVE descriptions and commits. In this way, we can automatically rank the candidates based on their correlation scores while maintaining low computation overhead. We evaluated our system against 4,789 CVEs from 532 OSS projects. The results are highly promising: PatchFinder achieves a Recall@10 of 80.63% and a Mean Reciprocal Rank (MRR) of 0.7951. Moreover, the Manual Effort@10 required is curtailed to 2.77, marking a 1.94 times improvement over current leading methods. When applying PatchFinder in practice, we initially identified 533 patch commits and submitted them to the official, 482 of which have been confirmed by CVE Numbering Authorities.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "to appear at ISSTA 2024"
    },
    {
        "paper id": "2407.17072",
        "abstract url": "https://arxiv.org/abs/2407.17072",
        "title": "An Efficient Procedure for Computing Bayesian Network Structure Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a globally optimal Bayesian network structure discovery algorithm based on a progressively leveled scoring approach. Bayesian network structure discovery is a fundamental yet NP-hard problem in the field of probabilistic graphical models, and as the number of variables increases, memory usage grows exponentially. The simple and effective method proposed by Silander and Myllym\u00e4ki has been widely applied in this field, as it incrementally calculates local scores to achieve global optimality. However, existing methods that utilize disk storage, while capable of handling networks with a larger number of variables, introduce issues such as latency, fragmentation, and additional overhead associated with disk I/O operations. To avoid these problems, we explore how to further enhance computational efficiency and reduce peak memory usage using only memory. We introduce an efficient hierarchical computation method that requires only a single traversal of all local structures, retaining only the data and information necessary for the current computation, thereby improving efficiency and significantly reducing memory requirements. Experimental results indicate that our method, when using only memory, not only reduces peak memory usage but also improves computational efficiency compared to existing methods, demonstrating good scalability for handling larger networks and exhibiting stable experimental results. Ultimately, we successfully achieved the processing of a Bayesian network with 28 variables using only memory.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17073",
        "abstract url": "https://arxiv.org/abs/2407.17073",
        "title": "Contrastive Learning Is Not Optimal for Quasiperiodic Time Series",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite recent advancements in Self-Supervised Learning (SSL) for time series analysis, a noticeable gap persists between the anticipated achievements and actual performance. While these methods have demonstrated formidable generalization capabilities with minimal labels in various domains, their effectiveness in distinguishing between different classes based on a limited number of annotated records is notably lacking. Our hypothesis attributes this bottleneck to the prevalent use of Contrastive Learning, a shared training objective in previous state-of-the-art (SOTA) methods. By mandating distinctiveness between representations for negative pairs drawn from separate records, this approach compels the model to encode unique record-based patterns but simultaneously neglects changes occurring across the entire record. To overcome this challenge, we introduce Distilled Embedding for Almost-Periodic Time Series (DEAPS) in this paper, offering a non-contrastive method tailored for quasiperiodic time series, such as electrocardiogram (ECG) data. By avoiding the use of negative pairs, we not only mitigate the model's blindness to temporal changes but also enable the integration of a \"Gradual Loss (Lgra)\" function. This function guides the model to effectively capture dynamic patterns evolving throughout the record. The outcomes are promising, as DEAPS demonstrates a notable improvement of +10% over existing SOTA methods when just a few annotated records are presented to fit a Machine Learning (ML) model based on the learned representation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to IJCAI 2024"
    },
    {
        "paper id": "2407.17097",
        "abstract url": "https://arxiv.org/abs/2407.17097",
        "title": "Towards Robust Knowledge Tracing Models via k-Sparse Attention",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Knowledge tracing (KT) is the problem of predicting students' future performance based on their historical interaction sequences. With the advanced capability of capturing contextual long-term dependency, attention mechanism becomes one of the essential components in many deep learning based KT (DLKT) models. In spite of the impressive performance achieved by these attentional DLKT models, many of them are often vulnerable to run the risk of overfitting, especially on small-scale educational datasets. Therefore, in this paper, we propose \\textsc{sparseKT}, a simple yet effective framework to improve the robustness and generalization of the attention based DLKT approaches. Specifically, we incorporate a k-selection module to only pick items with the highest attention scores. We propose two sparsification heuristics : (1) soft-thresholding sparse attention and (2) top-$K$ sparse attention. We show that our \\textsc{sparseKT} is able to help attentional KT models get rid of irrelevant student interactions and have comparable predictive performance when compared to 11 state-of-the-art KT models on three publicly available real-world educational datasets. To encourage reproducible research, we make our data and code publicly available at \\url{https://github.com/pykt-team/pykt-toolkit}\\footnote{We merged our model to the \\textsc{pyKT} benchmark at \\url{https://pykt.org/}.}.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted at SIGIR'2023 (revised version with additional results)"
    },
    {
        "paper id": "2407.17156",
        "abstract url": "https://arxiv.org/abs/2407.17156",
        "title": "Path Following and Stabilisation of a Bicycle Model using a Reinforcement Learning Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the years, complex control approaches have been developed to control the motion of a bicycle. Reinforcement Learning (RL), a branch of machine learning, promises easy deployment of so-called agents. Deployed agents are increasingly considered as an alternative to controllers for mechanical systems. The present work introduces an RL approach to do path following with a virtual bicycle model while simultaneously stabilising it laterally. The bicycle, modelled as the Whipple benchmark model and using multibody system dynamics, has no stabilisation aids. The agent succeeds in both path following and stabilisation of the bicycle model exclusively by outputting steering angles, which are converted into steering torques via a PD controller. Curriculum learning is applied as a state-of-the-art training strategy. Different settings for the implemented RL framework are investigated and compared to each other. The performance of the deployed agents is evaluated using different types of paths and measurements. The ability of the deployed agents to do path following and stabilisation of the bicycle model travelling between 2m/s and 7m/s along complex paths including full circles, slalom manoeuvres, and lane changes is demonstrated. Explanatory methods for machine learning are used to analyse the functionality of a deployed agent and link the introduced RL approach with research in the field of bicycle dynamics.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17163",
        "abstract url": "https://arxiv.org/abs/2407.17163",
        "title": "dlordinal: a Python package for deep ordinal classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "dlordinal is a new Python library that unifies many recent deep ordinal classification methodologies available in the literature. Developed using PyTorch as underlying framework, it implements the top performing state-of-the-art deep learning techniques for ordinal classification problems. Ordinal approaches are designed to leverage the ordering information present in the target variable. Specifically, it includes loss functions, various output layers, dropout techniques, soft labelling methodologies, and other classification strategies, all of which are appropriately designed to incorporate the ordinal information. Furthermore, as the performance metrics to assess novel proposals in ordinal classification depend on the distance between target and predicted classes in the ordinal scale, suitable ordinal evaluation metrics are also included. dlordinal is distributed under the BSD-3-Clause license and is available at https://github.com/ayrna/dlordinal.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17214",
        "abstract url": "https://arxiv.org/abs/2407.17214",
        "title": "Application of Machine Learning and Convex Limiting to Subgrid Flux Modeling in the Shallow-Water Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a combination of machine learning and flux limiting for property-preserving subgrid scale modeling in the context of flux-limited finite volume methods for the one-dimensional shallow-water equations. The numerical fluxes of a conservative target scheme are fitted to the coarse-mesh averages of a monotone fine-grid discretization using a neural network to parametrize the subgrid scale components. To ensure positivity preservation and the validity of local maximum principles, we use a flux limiter that constrains the intermediate states of an equivalent fluctuation form to stay in a convex admissible set. The results of our numerical studies confirm that the proposed combination of machine learning with monolithic convex limiting produces meaningful closures even in scenarios for which the network was not trained.",
        "subjects": [
            "physics.comp-ph",
            "cs.LG",
            "physics.ao-ph",
            "physics.flu-dyn",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17216",
        "abstract url": "https://arxiv.org/abs/2407.17216",
        "title": "An Adaptive Second-order Method for a Class of Nonconvex Nonsmooth Composite Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper explores a specific type of nonconvex sparsity-promoting regularization problems, namely those involving $\\ell_p$-norm regularization, in conjunction with a twice continuously differentiable loss function. We propose a novel second-order algorithm designed to effectively address this class of challenging nonconvex and nonsmooth problems, showcasing several innovative features: (i) The use of an alternating strategy to solve a reweighted $\\ell_1$ regularized subproblem and the subspace approximate Newton step. (ii) The reweighted $\\ell_1$ regularized subproblem relies on a convex approximation to the nonconvex regularization term, enabling a closed-form solution characterized by the soft-thresholding operator. This feature allows our method to be applied to various nonconvex regularization problems. (iii) Our algorithm ensures that the iterates maintain their sign values and that nonzero components are kept away from 0 for a sufficient number of iterations, eventually transitioning to a perturbed Newton method. (iv) We provide theoretical guarantees of global convergence, local superlinear convergence in the presence of the Kurdyka-\u0141ojasiewicz (KL) property, and local quadratic convergence when employing the exact Newton step in our algorithm. We also showcase the effectiveness of our approach through experiments on a diverse set of model prediction problems.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17226",
        "abstract url": "https://arxiv.org/abs/2407.17226",
        "title": "Sublinear Regret for An Actor-Critic Algorithm in Continuous-Time Linear-Quadratic Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions where volatility of the state processes depends on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an actor-critic algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of a novel exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\\frac{3}{4}})$ up to a logarithmic factor. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "42 pages, 4 figures"
    },
    {
        "paper id": "2407.17238",
        "abstract url": "https://arxiv.org/abs/2407.17238",
        "title": "Pretrained Visual Representations in Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Visual reinforcement learning (RL) has made significant progress in recent years, but the choice of visual feature extractor remains a crucial design decision. This paper compares the performance of RL algorithms that train a convolutional neural network (CNN) from scratch with those that utilize pre-trained visual representations (PVRs). We evaluate the Dormant Ratio Minimization (DRM) algorithm, a state-of-the-art visual RL method, against three PVRs: ResNet18, DINOv2, and Visual Cortex (VC). We use the Metaworld Push-v2 and Drawer-Open-v2 tasks for our comparison. Our results show that the choice of training from scratch compared to using PVRs for maximising performance is task-dependent, but PVRs offer advantages in terms of reduced replay buffer size and faster training times. We also identify a strong correlation between the dormant ratio and model performance, highlighting the importance of exploration in visual RL. Our study provides insights into the trade-offs between training from scratch and using PVRs, informing the design of future visual RL algorithms.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17276",
        "abstract url": "https://arxiv.org/abs/2407.17276",
        "title": "SoK: Bridging Trust into the Blockchain. A Systematic Review on On-Chain Identity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The ongoing regulation of blockchain-based services and applications requires the identification of users who are issuing transactions on the blockchain. This systematic review explores the current status, identifies research gaps, and outlines future research directions for establishing trusted and privacy-compliant identities on the blockchain (on-chain identity). A systematic search term was applied across various scientific databases, collecting 2232 potentially relevant research papers. These papers were narrowed down in two methodologically executed steps to 98 and finally to 13 relevant sources. The relevant articles were then systematically analyzed based on a set of screening questions. The results of the selected studies have provided insightful findings on the mechanisms of on-chain identities. On-chain identities are established using zero-knowledge proofs, public key infrastructure/certificates, and web of trust approaches. The technologies and architectures used by the authors are also highlighted. Trust has emerged as a key research gap, manifesting in two ways: firstly, a gap in how to trust the digital identity representation of a physical human; secondly, a gap in how to trust identity providers that issue identity confirmations on-chain. Potential future research avenues are suggested to help fill the current gaps in establishing trust and on-chain identities.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17280",
        "abstract url": "https://arxiv.org/abs/2407.17280",
        "title": "Enhanced Feature Learning via Regularisation: Integrating Neural Networks and Kernel Methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a new method for feature learning and function estimation in supervised learning via regularised empirical risk minimisation. Our approach considers functions as expectations of Sobolev functions over all possible one-dimensional projections of the data. This framework is similar to kernel ridge regression, where the kernel is $\\mathbb{E}_w ( k^{(B)}(w^\\top x,w^\\top x^\\prime))$, with $k^{(B)}(a,b) := \\min(|a|, |b|)1_{ab>0}$ the Brownian kernel, and the distribution of the projections $w$ is learnt. This can also be viewed as an infinite-width one-hidden layer neural network, optimising the first layer's weights through gradient descent and explicitly adjusting the non-linearity and weights of the second layer. We introduce an efficient computation method for the estimator, called Brownian Kernel Neural Network (BKerNN), using particles to approximate the expectation. The optimisation is principled due to the positive homogeneity of the Brownian kernel. Using Rademacher complexity, we show that BKerNN's expected risk converges to the minimal risk with explicit high-probability rates of $O( \\min((d/n)^{1/2}, n^{-1/6}))$ (up to logarithmic factors). Numerical experiments confirm our optimisation intuitions, and BKerNN outperforms kernel ridge regression, and favourably compares to a one-hidden layer neural network with ReLU activations in various settings and real data sets.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17284",
        "abstract url": "https://arxiv.org/abs/2407.17284",
        "title": "A Novel Two-Step Fine-Tuning Pipeline for Cold-Start Active Learning in Text Classification Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This is the first work to investigate the effectiveness of BERT-based contextual embeddings in active learning (AL) tasks on cold-start scenarios, where traditional fine-tuning is infeasible due to the absence of labeled data. Our primary contribution is the proposal of a more robust fine-tuning pipeline - DoTCAL - that diminishes the reliance on labeled data in AL using two steps: (1) fully leveraging unlabeled data through domain adaptation of the embeddings via masked language modeling and (2) further adjusting model weights using labeled data selected by AL. Our evaluation contrasts BERT-based embeddings with other prevalent text representation paradigms, including Bag of Words (BoW), Latent Semantic Indexing (LSI), and FastText, at two critical stages of the AL process: instance selection and classification. Experiments conducted on eight ATC benchmarks with varying AL budgets (number of labeled instances) and number of instances (about 5,000 to 300,000) demonstrate DoTCAL's superior effectiveness, achieving up to a 33% improvement in Macro-F1 while reducing labeling efforts by half compared to the traditional one-step method. We also found that in several tasks, BoW and LSI (due to information aggregation) produce results superior (up to 59% ) to BERT, especially in low-budget scenarios and hard-to-classify tasks, which is quite surprising.",
        "subjects": [
            "cs.LG",
            "cs.DB",
            "cs.IR"
        ],
        "comment": "11 pages, 4 figures, 2 Tables, and 1 algorithm"
    },
    {
        "paper id": "2407.17296",
        "abstract url": "https://arxiv.org/abs/2407.17296",
        "title": "Enhanced SMC$^2$: Leveraging Gradient Information from Differentiable Particle Filters Within Langevin Proposals",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sequential Monte Carlo Squared (SMC$^2$) is a Bayesian method which can infer the states and parameters of non-linear, non-Gaussian state-space models. The standard random-walk proposal in SMC$^2$ faces challenges, particularly with high-dimensional parameter spaces. This study outlines a novel approach by harnessing first-order gradients derived from a Common Random Numbers - Particle Filter (CRN-PF) using PyTorch. The resulting gradients can be leveraged within a Langevin proposal without accept/reject. Including Langevin dynamics within the proposal can result in a higher effective sample size and more accurate parameter estimates when compared with the random-walk. The resulting algorithm is parallelized on distributed memory using Message Passing Interface (MPI) and runs in $\\mathcal{O}(\\log_2N)$ time complexity. Utilizing 64 computational cores we obtain a 51x speed-up when compared to a single core. A GitHub link is given which provides access to the code.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.AP"
        ],
        "comment": "8 pages, 3 images. Accepted to 2024 IEEE International Conference on Multisensor Fusion and Integration (MFI 2024). https://mfi2024.org/. arXiv admin note: text overlap with arXiv:2311.12973"
    },
    {
        "paper id": "2407.17303",
        "abstract url": "https://arxiv.org/abs/2407.17303",
        "title": "MoveLight: Enhancing Traffic Signal Control through Movement-Centric Deep Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces MoveLight, a novel traffic signal control system that enhances urban traffic management through movement-centric deep reinforcement learning. By leveraging detailed real-time data and advanced machine learning techniques, MoveLight overcomes the limitations of traditional traffic signal control methods. It employs a lane-level control approach using the FRAP algorithm to achieve dynamic and adaptive traffic signal control, optimizing traffic flow, reducing congestion, and improving overall efficiency. Our research demonstrates the scalability and effectiveness of MoveLight across single intersections, arterial roads, and network levels. Experimental results using real-world datasets from Cologne and Hangzhou show significant improvements in metrics such as queue length, delay, and throughput compared to existing methods. This study highlights the transformative potential of deep reinforcement learning in intelligent traffic signal control, setting a new standard for sustainable and efficient urban transportation systems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17341",
        "abstract url": "https://arxiv.org/abs/2407.17341",
        "title": "Mathematical Programming Algorithms for Convex Hull Approximation with a Hyperplane Budget",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the following problem in computational geometry: given, in the d-dimensional real space, a set of points marked as positive and a set of points marked as negative, such that the convex hull of the positive set does not intersect the negative set, find K hyperplanes that separate, if possible, all the positive points from the negative ones. That is, we search for a convex polyhedron with at most K faces, containing all the positive points and no negative point. The problem is known in the literature for pure convex polyhedral approximation; our interest stems from its possible applications in constraint learning, where points are feasible or infeasible solutions of a Mixed Integer Program, and the K hyperplanes are linear constraints to be found. We cast the problem as an optimization one, minimizing the number of negative points inside the convex polyhedron, whenever exact separation cannot be achieved. We introduce models inspired by support vector machines and we design two mathematical programming formulations with binary variables. We exploit Dantzig-Wolfe decomposition to obtain extended formulations, and we devise column generation algorithms with ad-hoc pricing routines. We compare computing time and separation error values obtained by all our approaches on synthetic datasets, with number of points from hundreds up to a few thousands, showing our approaches to perform better than existing ones from the literature. Furthermore, we observe that key computational differences arise, depending on whether the budget K is sufficient to completely separate the positive points from the negative ones or not. On 8-dimensional instances (and over), existing convex hull algorithms become computational inapplicable, while our algorithms allow to identify good convex hull approximations in minutes of computation.",
        "subjects": [
            "math.OC",
            "cs.CG",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17356",
        "abstract url": "https://arxiv.org/abs/2407.17356",
        "title": "Gradient-based inference of abstract task representations for generalization in neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Humans and many animals show remarkably adaptive behavior and can respond differently to the same input depending on their internal goals. The brain not only represents the intermediate abstractions needed to perform a computation but also actively maintains a representation of the computation itself (task abstraction). Such separation of the computation and its abstraction is associated with faster learning, flexible decision-making, and broad generalization capacity. We investigate if such benefits might extend to neural networks trained with task abstractions. For such benefits to emerge, one needs a task inference mechanism that possesses two crucial abilities: First, the ability to infer abstract task representations when no longer explicitly provided (task inference), and second, manipulate task representations to adapt to novel problems (task recomposition). To tackle this, we cast task inference as an optimization problem from a variational inference perspective and ground our approach in an expectation-maximization framework. We show that gradients backpropagated through a neural network to a task representation layer are an efficient heuristic to infer current task demands, a process we refer to as gradient-based inference (GBI). Further iterative optimization of the task representation layer allows for recomposing abstractions to adapt to novel situations. Using a toy example, a novel image classifier, and a language model, we demonstrate that GBI provides higher learning efficiency and generalization to novel tasks and limits forgetting. Moreover, we show that GBI has unique advantages such as preserving information for uncertainty estimation and detecting out-of-distribution samples.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17358",
        "abstract url": "https://arxiv.org/abs/2407.17358",
        "title": "Quantile Learn-Then-Test: Quantile-Based Risk Control for Hyperparameter Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The increasing adoption of Artificial Intelligence (AI) in engineering problems calls for the development of calibration methods capable of offering robust statistical reliability guarantees. The calibration of black box AI models is carried out via the optimization of hyperparameters dictating architecture, optimization, and/or inference configuration. Prior work has introduced learn-then-test (LTT), a calibration procedure for hyperparameter optimization (HPO) that provides statistical guarantees on average performance measures. Recognizing the importance of controlling risk-aware objectives in engineering contexts, this work introduces a variant of LTT that is designed to provide statistical guarantees on quantiles of a risk measure. We illustrate the practical advantages of this approach by applying the proposed algorithm to a radio access scheduling problem.",
        "subjects": [
            "cs.IT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17374",
        "abstract url": "https://arxiv.org/abs/2407.17374",
        "title": "Co-designing an AI Impact Assessment Report Template with AI Practitioners and AI Compliance Experts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the evolving landscape of AI regulation, it is crucial for companies to conduct impact assessments and document their compliance through comprehensive reports. However, current reports lack grounding in regulations and often focus on specific aspects like privacy in relation to AI systems, without addressing the real-world uses of these systems. Moreover, there is no systematic effort to design and evaluate these reports with both AI practitioners and AI compliance experts. To address this gap, we conducted an iterative co-design process with 14 AI practitioners and 6 AI compliance experts and proposed a template for impact assessment reports grounded in the EU AI Act, NIST's AI Risk Management Framework, and ISO 42001 AI Management System. We evaluated the template by producing an impact assessment report for an AI-based meeting companion at a major tech company. A user study with 8 AI practitioners from the same company and 5 AI compliance experts from industry and academia revealed that our template effectively provides necessary information for impact assessments and documents the broad impacts of AI systems. Participants envisioned using the template not only at the pre-deployment stage for compliance but also as a tool to guide the design stage of AI uses.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2407.17377",
        "abstract url": "https://arxiv.org/abs/2407.17377",
        "title": "Entropy Reweighted Conformal Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Conformal Prediction (CP) is a powerful framework for constructing prediction sets with guaranteed coverage. However, recent studies have shown that integrating confidence calibration with CP can lead to a degradation in efficiency. In this paper, We propose an adaptive approach that considers the classifier's uncertainty and employs entropy-based reweighting to enhance the efficiency of prediction sets for conformal classification. Our experimental results demonstrate that this method significantly improves efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17437",
        "abstract url": "https://arxiv.org/abs/2407.17437",
        "title": "Nerva: a Truly Sparse Implementation of Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce Nerva, a fast neural network library under development in C++. It supports sparsity by using the sparse matrix operations of Intel's Math Kernel Library (MKL), which eliminates the need for binary masks. We show that Nerva significantly decreases training time and memory usage while reaching equivalent accuracy to PyTorch. We run static sparse experiments with an MLP on CIFAR-10. On high sparsity levels like $99\\%$, the runtime is reduced by a factor of $4\\times$ compared to a PyTorch model using masks. Similar to other popular frameworks such as PyTorch and Keras, Nerva offers a Python interface for users to work with.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "The Nerva library is available at https://github.com/wiegerw/nerva"
    },
    {
        "paper id": "2407.17446",
        "abstract url": "https://arxiv.org/abs/2407.17446",
        "title": "Fractional signature: a generalisation of the signature inspired by fractional calculus",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a novel generalisation of the signature of a path, motivated by fractional calculus, which is able to describe the solutions of linear Caputo controlled FDEs. We also propose another generalisation of the signature, inspired by the previous one, but more convenient to use in machine learning. Finally, we test this last signature in a toy application to the problem of handwritten digit recognition, where significant improvements in accuracy rates are observed compared to those of the original signature.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "9 pages, 1 figure"
    },
    {
        "paper id": "2407.17451",
        "abstract url": "https://arxiv.org/abs/2407.17451",
        "title": "BlueTempNet: A Temporal Multi-network Dataset of Social Interactions in Bluesky Social",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Decentralized social media platforms like Bluesky Social (Bluesky) have made it possible to publicly disclose some user behaviors with millisecond-level precision. Embracing Bluesky's principles of open-source and open-data, we present the first collection of the temporal dynamics of user-driven social interactions. BlueTempNet integrates multiple types of networks into a single multi-network, including user-to-user interactions (following and blocking users) and user-to-community interactions (creating and joining communities). Communities are user-formed groups in custom Feeds, where users subscribe to posts aligned with their interests. Following Bluesky's public data policy, we collect existing Bluesky Feeds, including the users who liked and generated these Feeds, and provide tools to gather users' social interactions within a date range. This data-collection strategy captures past user behaviors and supports the future data collection of user behavior.",
        "subjects": [
            "cs.SI",
            "cs.CY",
            "cs.IR"
        ],
        "comment": "to appear in IEEE Data Description"
    },
    {
        "paper id": "2407.17454",
        "abstract url": "https://arxiv.org/abs/2407.17454",
        "title": "Automated Explanation Selection for Scientific Discovery",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Automated reasoning is a key technology in the young but rapidly growing field of Explainable Artificial Intelligence (XAI). Explanability helps build trust in artificial intelligence systems beyond their mere predictive accuracy and robustness. In this paper, we propose a cycle of scientific discovery that combines machine learning with automated reasoning for the generation and the selection of explanations. We present a taxonomy of explanation selection problems that draws on insights from sociology and cognitive science. These selection criteria subsume existing notions and extend them with new properties.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Composite AI Workshop at ECAI 2024 (accepted for publication)"
    },
    {
        "paper id": "2407.17465",
        "abstract url": "https://arxiv.org/abs/2407.17465",
        "title": "u-$\u03bc$P: The Unit-Scaled Maximal Update Parametrization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Maximal Update Parametrization ($\u03bc$P) aims to make the optimal hyperparameters (HPs) of a model independent of its size, allowing them to be swept using a cheap proxy model rather than the full-size target model. We present a new scheme, u-$\u03bc$P, which improves upon $\u03bc$P by combining it with Unit Scaling, a method for designing models that makes them easy to train in low-precision. The two techniques have a natural affinity: $\u03bc$P ensures that the scale of activations is independent of model size, and Unit Scaling ensures that activations, weights and gradients begin training with a scale of one. This synthesis opens the door to a simpler scheme, whose default values are near-optimal. This in turn facilitates a more efficient sweeping strategy, with u-$\u03bc$P models reaching a lower loss than comparable $\u03bc$P models and working out-of-the-box in FP8.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "48 pages"
    },
    {
        "paper id": "2407.17466",
        "abstract url": "https://arxiv.org/abs/2407.17466",
        "title": "Traversing Pareto Optimal Policies: Provably Efficient Multi-Objective Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper investigates multi-objective reinforcement learning (MORL), which focuses on learning Pareto optimal policies in the presence of multiple reward functions. Despite MORL's significant empirical success, there is still a lack of satisfactory understanding of various MORL optimization targets and efficient learning algorithms. Our work offers a systematic analysis of several optimization targets to assess their abilities to find all Pareto optimal policies and controllability over learned policies by the preferences for different objectives. We then identify Tchebycheff scalarization as a favorable scalarization method for MORL. Considering the non-smoothness of Tchebycheff scalarization, we reformulate its minimization problem into a new min-max-max optimization problem. Then, for the stochastic policy class, we propose efficient algorithms using this reformulation to learn Pareto optimal policies. We first propose an online UCB-based algorithm to achieve an $\\varepsilon$ learning error with an $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ sample complexity for a single given preference. To further reduce the cost of environment exploration under different preferences, we propose a preference-free framework that first explores the environment without pre-defined preferences and then generates solutions for any number of preferences. We prove that it only requires an $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ exploration complexity in the exploration phase and demands no additional exploration afterward. Lastly, we analyze the smooth Tchebycheff scalarization, an extension of Tchebycheff scalarization, which is proved to be more advantageous in distinguishing the Pareto optimal policies from other weakly Pareto optimal policies based on entry values of preference vectors. Furthermore, we extend our algorithms and theoretical analysis to accommodate this optimization target.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "comment": "Initially submitted in May 2024"
    },
    {
        "paper id": "2407.17535",
        "abstract url": "https://arxiv.org/abs/2407.17535",
        "title": "LAMBDA: A Large Model Based Data Agent",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce ``LAMBDA,\" a novel open-source, code-free multi-agent data analysis system that that harnesses the power of large models. LAMBDA is designed to address data analysis challenges in complex data-driven applications through the use of innovatively designed data agents that operate iteratively and generatively using natural language. At the core of LAMBDA are two key agent roles: the programmer and the inspector, which are engineered to work together seamlessly. Specifically, the programmer generates code based on the user's instructions and domain-specific knowledge, enhanced by advanced models. Meanwhile, the inspector debugs the code when necessary. To ensure robustness and handle adverse scenarios, LAMBDA features a user interface that allows direct user intervention in the operational loop. Additionally, LAMBDA can flexibly integrate external models and algorithms through our knowledge integration mechanism, catering to the needs of customized data analysis. LAMBDA has demonstrated strong performance on various machine learning datasets. It has the potential to enhance data science practice and analysis paradigm by seamlessly integrating human and artificial intelligence, making it more accessible, effective, and efficient for individuals from diverse backgrounds. The strong performance of LAMBDA in solving data science problems is demonstrated in several case studies, which are presented at \\url{https://www.polyu.edu.hk/ama/cmfai/lambda.html}.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.SE"
        ],
        "comment": "30 pages, 21 figures and 5 tables"
    },
    {
        "paper id": "2407.17537",
        "abstract url": "https://arxiv.org/abs/2407.17537",
        "title": "A process algebraic framework for multi-agent dynamic epistemic systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper combines the classical model of labeled transition systems with the epistemic model for reasoning about knowledge. The result is a unifying framework for modeling and analyzing multi-agent, knowledge-based, dynamic systems. On the modeling side, we propose a process algebraic, agent-oriented specification language that makes such a framework easy to use for practical purposes. On the verification side, we define a modal logic encompassing temporal and epistemic operators.",
        "subjects": [
            "cs.AI",
            "cs.FL",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17539",
        "abstract url": "https://arxiv.org/abs/2407.17539",
        "title": "Automated transport separation using the neural shifted proper orthogonal decomposition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a neural network-based methodology for the decomposition of transport-dominated fields using the shifted proper orthogonal decomposition (sPOD). Classical sPOD methods typically require an a priori knowledge of the transport operators to determine the co-moving fields. However, in many real-life problems, such knowledge is difficult or even impossible to obtain, limiting the applicability and benefits of the sPOD. To address this issue, our approach estimates both the transport and co-moving fields simultaneously using neural networks. This is achieved by training two sub-networks dedicated to learning the transports and the co-moving fields, respectively. Applications to synthetic data and a wildland fire model illustrate the capabilities and efficiency of this neural sPOD approach, demonstrating its ability to separate the different fields effectively.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "physics.comp-ph",
            "physics.flu-dyn"
        ],
        "comment": "Proceedings not peer-reviewed yet. Code available: https://github.com/MOR-transport/automated_NsPOD"
    },
    {
        "paper id": "2407.17544",
        "abstract url": "https://arxiv.org/abs/2407.17544",
        "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "There has been significant recent interest in harnessing LLMs to control software systems through multi-step reasoning, planning and tool-usage. While some promising results have been obtained, application to specific domains raises several general issues including the control of specialized domain tools, the lack of existing datasets for training and evaluation, and the non-triviality of automated system evaluation and improvement. In this paper, we present a case-study where we examine these issues in the context of a specific domain. Specifically, we present an automated math visualizer and solver system for mathematical pedagogy. The system orchestrates mathematical solvers and math graphing tools to produce accurate visualizations from simple natural language commands. We describe the creation of specialized data-sets, and also develop an auto-evaluator to easily evaluate the outputs of our system by comparing them to ground-truth expressions. We have open sourced the data-sets and code for the proposed system.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17571",
        "abstract url": "https://arxiv.org/abs/2407.17571",
        "title": "Diffusion Models for Multi-Task Generative Modeling",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Diffusion-based generative modeling has been achieving state-of-the-art results on various generation tasks. Most diffusion models, however, are limited to a single-generation modeling. Can we generalize diffusion models with the ability of multi-modal generative training for more generalizable modeling? In this paper, we propose a principled way to define a diffusion model by constructing a unified multi-modal diffusion model in a common diffusion space. We define the forward diffusion process to be driven by an information aggregation from multiple types of task-data, e.g., images for a generation task and labels for a classification task. In the reverse process, we enforce information sharing by parameterizing a shared backbone denoising network with additional modality-specific decoder heads. Such a structure can simultaneously learn to generate different types of multi-modal data with a multi-task loss, which is derived from a new multi-modal variational lower bound that generalizes the standard diffusion model. We propose several multimodal generation settings to verify our framework, including image transition, masked-image training, joint image-label and joint image-representation generative modeling. Extensive experimental results on ImageNet indicate the effectiveness of our framework for various multi-modal generative modeling, which we believe is an important research direction worthy of more future explorations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published as a conference paper at ICLR 2024"
    },
    {
        "paper id": "2407.17616",
        "abstract url": "https://arxiv.org/abs/2407.17616",
        "title": "Pretraining a Neural Operator in Lower Dimensions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has recently been increasing attention towards developing foundational neural Partial Differential Equation (PDE) solvers and neural operators through large-scale pretraining. However, unlike vision and language models that make use of abundant and inexpensive (unlabeled) data for pretraining, these neural solvers usually rely on simulated PDE data, which can be costly to obtain, especially for high-dimensional PDEs. In this work, we aim to Pretrain neural PDE solvers on Lower Dimensional PDEs (PreLowD) where data collection is the least expensive. We evaluated the effectiveness of this pretraining strategy in similar PDEs in higher dimensions. We use the Factorized Fourier Neural Operator (FFNO) due to having the necessary flexibility to be applied to PDE data of arbitrary spatial dimensions and reuse trained parameters in lower dimensions. In addition, our work sheds light on the effect of the fine-tuning configuration to make the most of this pretraining strategy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17631",
        "abstract url": "https://arxiv.org/abs/2407.17631",
        "title": "BLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic Chunking and Hard Example Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Software bugs require developers to exert significant effort to identify and resolve them, often consuming about one-third of their time. Bug localization, the process of pinpointing the exact source code files that need modification, is crucial in reducing this effort. Existing bug localization tools, typically reliant on deep learning techniques, face limitations in cross-project applicability and effectiveness in multi-language environments. Recent advancements with Large Language Models (LLMs) offer detailed representations for bug localization. However, they encounter challenges with limited context windows and mapping accuracy. To address these issues, we propose BLAZE, an approach that employs dynamic chunking and hard example learning. First, BLAZE dynamically segments source code to minimize continuity loss. Then, BLAZE fine-tunes a GPT-based model using challenging bug cases, in order to enhance cross-project and cross-language bug localization. To support the capability of BLAZE, we create the BEETLEBOX dataset, which comprises 26,321 bugs from 29 large and thriving open-source projects across five different programming languages (Java, C++, Python, Go, and JavaScript). Our evaluations of BLAZE on three benchmark datasets BEETLEBOX, SWE-Bench, and Ye et al. demonstrate substantial improvements compared to six state-of-the-art baselines. Specifically, BLAZE achieves up to an increase of 120% in Top 1 accuracy, 144% in Mean Average Precision (MAP), and 100% in Mean Reciprocal Rank (MRR). An extensive ablation study confirms the contributions of our pipeline components to the overall performance enhancement.",
        "subjects": [
            "cs.SE",
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17633",
        "abstract url": "https://arxiv.org/abs/2407.17633",
        "title": "PICA: A Data-driven Synthesis of Peer Instruction and Continuous Assessment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Peer Instruction (PI) and Continuous Assessment(CA) are two distinct educational techniques with extensive research demonstrating their effectiveness. The work herein combines PI and CA in a deliberate and novel manner to pair students together for a PI session in which they collaborate on a CA task. The data used to inform the pairing method is restricted to the most previous CA task students completed independently. The motivation for this data-driven collaborative learning is to improve student learning, communication, and engagement. Quantitative results from an investigation of the method show improved assessment scores on the PI CA tasks, although evidence of a positive effect on subsequent individual CA tasks was not statistically significant as anticipated. However, student perceptions were positive, engagement was high, and students interacted with a broader set of peers than is typical. These qualitative observations, together with extant research on the general benefits of improving student engagement and communication (e.g. improved sense of belonging, increased social capital, etc.), render the method worthy for further research into building and evaluating small student learning communities using student assessment data.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Accepted to RKDE Workshop at ECML-PKDD 2023"
    },
    {
        "paper id": "2407.17645",
        "abstract url": "https://arxiv.org/abs/2407.17645",
        "title": "Hopfield Networks for Asset Allocation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present the first application of modern Hopfield networks to the problem of portfolio optimization. We performed an extensive study based on combinatorial purged cross-validation over several datasets and compared our results to both traditional and deep-learning-based methods for portfolio selection. Compared to state-of-the-art deep-learning methods such as Long-Short Term Memory networks and Transformers, we find that the proposed approach performs on par or better, while providing faster training times and better stability. Our results show that Modern Hopfield Networks represent a promising approach to portfolio optimization, allowing for an efficient, scalable, and robust solution for asset allocation, risk management, and dynamic rebalancing.",
        "subjects": [
            "cs.LG",
            "q-fin.CP",
            "q-fin.PM"
        ],
        "comment": "12 pages, 4 figures"
    },
    {
        "paper id": "2407.17667",
        "abstract url": "https://arxiv.org/abs/2407.17667",
        "title": "Tackling the Problem of Distributional Shifts: Correcting Misspecified, High-Dimensional Data-Driven Priors for Inverse Problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian inference for inverse problems hinges critically on the choice of priors. In the absence of specific prior information, population-level distributions can serve as effective priors for parameters of interest. With the advent of machine learning, the use of data-driven population-level distributions (encoded, e.g., in a trained deep neural network) as priors is emerging as an appealing alternative to simple parametric priors in a variety of inverse problems. However, in many astrophysical applications, it is often difficult or even impossible to acquire independent and identically distributed samples from the underlying data-generating process of interest to train these models. In these cases, corrupted data or a surrogate, e.g. a simulator, is often used to produce training samples, meaning that there is a risk of obtaining misspecified priors. This, in turn, can bias the inferred posteriors in ways that are difficult to quantify, which limits the potential applicability of these models in real-world scenarios. In this work, we propose addressing this issue by iteratively updating the population-level distributions by retraining the model with posterior samples from different sets of observations and showcase the potential of this method on the problem of background image reconstruction in strong gravitational lensing when score-based models are used as data-driven priors. We show that starting from a misspecified prior distribution, the updated distribution becomes progressively closer to the underlying population-level distribution, and the resulting posterior samples exhibit reduced bias after several updates.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.CO",
            "cs.LG"
        ],
        "comment": "17 pages, 15 figures, Submitted to The Astrophysical Journal"
    },
    {
        "paper id": "2407.17677",
        "abstract url": "https://arxiv.org/abs/2407.17677",
        "title": "Women's Participation in Computing: Evolving Research Methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "A 2022 keynote for the ACM History Committee on \"Why SIG History Matters: New Data on Gender Bias in ACM's Founding SIGs 1970-2000\" presented new data describing women's participation as research-article authors in 13 early ACM Special Interest Groups, finding significant growth in women's participation across 1970-2000 and, additionally, remarkable differences in women's participation between the SIGs. That presentation built on several earlier publications that developed a research method for assessing the number of women computer scientists that [a] are chronologically prior to the availability of the Bureau of Labor Statistics (BLS) data on women in the IT workforce; and [b] permit focused investigation of varied sub-fields within computing. This present report expands on these earlier articles, and their evolving research method, connecting them to the ACM SIG Heritage presentation. It also outlines some of the choices and considerations made in developing and refining \"mixed methods\" research (using both quantitative and qualitative approaches) as well as extensions of the research being currently explored.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "13 pages, 6 figures"
    },
    {
        "paper id": "2407.17697",
        "abstract url": "https://arxiv.org/abs/2407.17697",
        "title": "Superior Scoring Rules for Probabilistic Evaluation of Single-Label Multi-Class Classification Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study introduces novel superior scoring rules called Penalized Brier Score (PBS) and Penalized Logarithmic Loss (PLL) to improve model evaluation for probabilistic classification. Traditional scoring rules like Brier Score and Logarithmic Loss sometimes assign better scores to misclassifications in comparison with correct classifications. This discrepancy from the actual preference for rewarding correct classifications can lead to suboptimal model selection. By integrating penalties for misclassifications, PBS and PLL modify traditional proper scoring rules to consistently assign better scores to correct predictions. Formal proofs demonstrate that PBS and PLL satisfy strictly proper scoring rule properties while also preferentially rewarding accurate classifications. Experiments showcase the benefits of using PBS and PLL for model selection, model checkpointing, and early stopping. PBS exhibits a higher negative correlation with the F1 score compared to the Brier Score during training. Thus, PBS more effectively identifies optimal checkpoints and early stopping points, leading to improved F1 scores. Comparative analysis verifies models selected by PBS and PLL achieve superior F1 scores. Therefore, PBS and PLL address the gap between uncertainty quantification and accuracy maximization by encapsulating both proper scoring principles and explicit preference for true classifications. The proposed metrics can enhance model evaluation and selection for reliable probabilistic classification.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "21 Pages, 3 Figures, 3 Tables"
    },
    {
        "paper id": "2407.17712",
        "abstract url": "https://arxiv.org/abs/2407.17712",
        "title": "Improving Online Algorithms via ML Predictions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work we study the problem of using machine-learned predictions to improve the performance of online algorithms. We consider two classical problems, ski rental and non-clairvoyant job scheduling, and obtain new online algorithms that use predictions to make their decisions. These algorithms are oblivious to the performance of the predictor, improve with better predictions, but do not degrade much if the predictions are poor.",
        "subjects": [
            "cs.DS",
            "cs.LG"
        ],
        "comment": "Conference version appeared in Neurips 2018"
    },
    {
        "paper id": "2407.17760",
        "abstract url": "https://arxiv.org/abs/2407.17760",
        "title": "TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autistic individuals often experience difficulties in conveying and interpreting emotional tone and non-literal nuances. Many also mask their communication style to avoid being misconstrued by others, spending considerable time and mental effort in the process. To address these challenges in text-based communication, we present TwIPS, a prototype texting application powered by a large language model (LLM), which can assist users with: a) deciphering tone and meaning of incoming messages, b) ensuring the emotional tone of their message is in line with their intent, and c) coming up with alternate phrasing for messages that could be misconstrued and received negatively by others. We leverage an AI-based simulation and a conversational script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our findings show TwIPS enables a convenient way for participants to seek clarifications, provides a better alternative to tone indicators, and facilitates constructive reflection on writing technique and style. We also examine how autistic users utilize language for self-expression and interpretation in instant messaging, and gather feedback for enhancing our prototype. We conclude with a discussion around balancing user-autonomy with AI-mediation, establishing appropriate trust levels in AI systems, and customization needs if autistic users in the context of AI-assisted communication",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.18982",
        "abstract url": "https://arxiv.org/abs/2407.18982",
        "title": "Low-Latency Privacy-Preserving Deep Learning Design via Secure MPC",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Secure multi-party computation (MPC) facilitates privacy-preserving computation between multiple parties without leaking private information. While most secure deep learning techniques utilize MPC operations to achieve feasible privacy-preserving machine learning on downstream tasks, the overhead of the computation and communication still hampers their practical application. This work proposes a low-latency secret-sharing-based MPC design that reduces unnecessary communication rounds during the execution of MPC protocols. We also present a method for improving the computation of commonly used nonlinear functions in deep learning by integrating multivariate multiplication and coalescing different packets into one to maximize network utilization. Our experimental results indicate that our method is effective in a variety of settings, with a speedup in communication latency of $10\\sim20\\%$.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.DC",
            "cs.LG"
        ],
        "comment": "9 pages, accepted at IJCAI'24 AISafety"
    },
    {
        "paper id": "2407.20266",
        "abstract url": "https://arxiv.org/abs/2407.20266",
        "title": "Accelerating the Low-Rank Decomposed Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Tensor decomposition is a mathematically supported technique for data compression. It consists of applying some kind of a Low Rank Decomposition technique on the tensors or matrices in order to reduce the redundancy of the data. However, it is not a popular technique for compressing the AI models duo to the high number of new layers added to the architecture after decomposition. Although the number of parameters could shrink significantly, it could result in the model be more than twice deeper which could add some latency to the training or inference. In this paper, we present a comprehensive study about how to modify low rank decomposition technique in AI models so that we could benefit from both high accuracy and low memory consumption as well as speeding up the training and inference",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17058",
        "abstract url": "https://arxiv.org/abs/2407.17058",
        "title": "DiffCD: A Symmetric Differentiable Chamfer Distance for Neural Implicit Surface Fitting",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural implicit surfaces can be used to recover accurate 3D geometry from imperfect point clouds. In this work, we show that state-of-the-art techniques work by minimizing an approximation of a one-sided Chamfer distance. This shape metric is not symmetric, as it only ensures that the point cloud is near the surface but not vice versa. As a consequence, existing methods can produce inaccurate reconstructions with spurious surfaces. Although one approach against spurious surfaces has been widely used in the literature, we theoretically and experimentally show that it is equivalent to regularizing the surface area, resulting in over-smoothing. As a more appealing alternative, we propose DiffCD, a novel loss function corresponding to the symmetric Chamfer distance. In contrast to previous work, DiffCD also assures that the surface is near the point cloud, which eliminates spurious surfaces without the need for additional regularization. We experimentally show that DiffCD reliably recovers a high degree of shape detail, substantially outperforming existing work across varying surface complexity and noise levels. Project code is available at https://github.com/linusnie/diffcd.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17064",
        "abstract url": "https://arxiv.org/abs/2407.17064",
        "title": "AI-based Density Recognition",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Learning-based analysis of images is commonly used in the fields of mobility and robotics for safe environmental motion and interaction. This requires not only object recognition but also the assignment of certain properties to them. With the help of this information, causally related actions can be adapted to different circumstances. Such logical interactions can be optimized by recognizing object-assigned properties. Density as a physical property offers the possibility to recognize how heavy an object is, which material it is made of, which forces are at work, and consequently which influence it has on its environment. Our approach introduces an AI-based concept for assigning physical properties to objects through the use of associated images. Based on synthesized data, we derive specific patterns from 2D images using a neural network to extract further information such as volume, material, or density. Accordingly, we discuss the possibilities of property-based feature extraction to improve causally related logics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17083",
        "abstract url": "https://arxiv.org/abs/2407.17083",
        "title": "When Text and Images Don't Mix: Bias-Correcting Language-Image Similarity Scores for Anomaly Detection",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Contrastive Language-Image Pre-training (CLIP) achieves remarkable performance in various downstream tasks through the alignment of image and text input embeddings and holds great promise for anomaly detection. However, our empirical experiments show that the embeddings of text inputs unexpectedly tightly cluster together, far away from image embeddings, contrary to the model's contrastive training objective to align image-text input pairs. We show that this phenomenon induces a `similarity bias' - in which false negative and false positive errors occur due to bias in the similarities between images and the normal label text embeddings. To address this bias, we propose a novel methodology called BLISS which directly accounts for this similarity bias through the use of an auxiliary, external set of text inputs. BLISS is simple, it does not require strong inductive biases about anomalous behaviour nor an expensive training process, and it significantly outperforms baseline methods on benchmark image datasets, even when access to normal data is extremely limited.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17095",
        "abstract url": "https://arxiv.org/abs/2407.17095",
        "title": "MemBench: Memorized Image Trigger Prompt Dataset for Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have achieved remarkable success in Text-to-Image generation tasks, leading to the development of many commercial models. However, recent studies have reported that diffusion models often generate replicated images in train data when triggered by specific prompts, potentially raising social issues ranging from copyright to privacy concerns. To sidestep the memorization, there have been recent studies for developing memorization mitigation methods for diffusion models. Nevertheless, the lack of benchmarks impedes the assessment of the true effectiveness of these methods. In this work, we present MemBench, the first benchmark for evaluating image memorization mitigation methods. Our benchmark includes a large number of memorized image trigger prompts in Stable Diffusion, the most popularly used model nowadays. Furthermore, in contrast to the prior work evaluating mitigation performance only on trigger prompts, we present metrics evaluating on both trigger prompts and general prompts, so that we can see whether mitigation methods address the memorization issue while maintaining performance for general prompts. This is an important development considering the practical applications which previous works have overlooked. Through evaluation on MemBench, we verify that the performance of existing image memorization mitigation methods is still insufficient for application to diffusion models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17119",
        "abstract url": "https://arxiv.org/abs/2407.17119",
        "title": "Automatic Detection and Annotation of Sperm Whale Codas",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "A key technology in sperm whale (Physeter macrocephalus) monitoring is the identification of sperm whale communication signals, known as codas. In this paper we present the first automatic coda detector and annotator. The main innovation in our detector is graph-based clustering, which utilizes the expected similarity between the clicks that make up the coda. Results show detection and accurate annotation at low signal-to-noise ratios, separation between codas and echolocation clicks, and discrimination between codas from simultaneously emitting whales. Using this automatic annotator, insights into the characterization of sperm whale communication are presented. The results include new types of coda signals, analyzes of the distribution of coda types among different whales and for different years, and evidence for synchronization between communicating whales in terms of coda type and coda transmission time. These results indicate a high degree of complexity in the communication system of this cetacean species. To ensure traceability, we share the implementation code of our coda detector.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17162",
        "abstract url": "https://arxiv.org/abs/2407.17162",
        "title": "Context-aware Multi-task Learning for Pedestrian Intent and Trajectory Prediction",
        "rating": "0",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The advancement of socially-aware autonomous vehicles hinges on precise modeling of human behavior. Within this broad paradigm, the specific challenge lies in accurately predicting pedestrian's trajectory and intention. Traditional methodologies have leaned heavily on historical trajectory data, frequently overlooking vital contextual cues such as pedestrian-specific traits and environmental factors. Furthermore, there's a notable knowledge gap as trajectory and intention prediction have largely been approached as separate problems, despite their mutual dependence. To bridge this gap, we introduce PTINet (Pedestrian Trajectory and Intention Prediction Network), which jointly learns the trajectory and intention prediction by combining past trajectory observations, local contextual features (individual pedestrian behaviors), and global features (signs, markings etc.). The efficacy of our approach is evaluated on widely used public datasets: JAAD and PIE, where it has demonstrated superior performance over existing state-of-the-art models in trajectory and intention prediction. The results from our experiments and ablation studies robustly validate PTINet's effectiveness in jointly exploring intention and trajectory prediction for pedestrian behaviour modelling. The experimental evaluation indicates the advantage of using global and local contextual features for pedestrian trajectory and intention prediction. The effectiveness of PTINet in predicting pedestrian behavior paves the way for the development of automated systems capable of seamlessly interacting with pedestrians in urban settings.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17170",
        "abstract url": "https://arxiv.org/abs/2407.17170",
        "title": "Domain Generalized Recaptured Screen Image Identification Using SWIN Transformer",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "An increasing number of classification approaches have been developed to address the issue of image rebroadcast and recapturing, a standard attack strategy in insurance frauds, face spoofing, and video piracy. However, most of them neglected scale variations and domain generalization scenarios, performing poorly in instances involving domain shifts, typically made worse by inter-domain and cross-domain scale variances. To overcome these issues, we propose a cascaded data augmentation and SWIN transformer domain generalization framework (DAST-DG) in the current research work Initially, we examine the disparity in dataset representation. A feature generator is trained to make authentic images from various domains indistinguishable. This process is then applied to recaptured images, creating a dual adversarial learning setup. Extensive experiments demonstrate that our approach is practical and surpasses state-of-the-art methods across different databases. Our model achieves an accuracy of approximately 82\\% with a precision of 95\\% on high-variance datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 10 figures, 9 tables"
    },
    {
        "paper id": "2407.17229",
        "abstract url": "https://arxiv.org/abs/2407.17229",
        "title": "LPGen: Enhancing High-Fidelity Landscape Painting Generation through Diffusion Model",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating landscape paintings expands the possibilities of artistic creativity and imagination. Traditional landscape painting methods involve using ink or colored ink on rice paper, which requires substantial time and effort. These methods are susceptible to errors and inconsistencies and lack precise control over lines and colors. This paper presents LPGen, a high-fidelity, controllable model for landscape painting generation, introducing a novel multi-modal framework that integrates image prompts into the diffusion model. We extract its edges and contours by computing canny edges from the target landscape image. These, along with natural language text prompts and drawing style references, are fed into the latent diffusion model as conditions. We implement a decoupled cross-attention strategy to ensure compatibility between image and text prompts, facilitating multi-modal image generation. A decoder generates the final image. Quantitative and qualitative analyses demonstrate that our method outperforms existing approaches in landscape painting generation and exceeds the current state-of-the-art. The LPGen network effectively controls the composition and color of landscape paintings, generates more accurate images, and supports further research in deep learning-based landscape painting generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17272",
        "abstract url": "https://arxiv.org/abs/2407.17272",
        "title": "DenseTrack: Drone-based Crowd Tracking via Density-aware Motion-appearance Synergy",
        "rating": "0",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "Drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Drone-based crowd tracking faces difficulties in accurately identifying and monitoring objects from an aerial perspective, largely due to their small size and close proximity to each other, which complicates both localization and tracking. To address these challenges, we present the Density-aware Tracking (DenseTrack) framework. DenseTrack capitalizes on crowd counting to precisely determine object locations, blending visual and motion cues to improve the tracking of small-scale objects. It specifically addresses the problem of cross-frame motion to enhance tracking accuracy and dependability. DenseTrack employs crowd density estimates as anchors for exact object localization within video frames. These estimates are merged with motion and position information from the tracking network, with motion offsets serving as key tracking cues. Moreover, DenseTrack enhances the ability to distinguish small-scale objects using insights from the visual-language model, integrating appearance with motion cues. The framework utilizes the Hungarian algorithm to ensure the accurate matching of individuals across frames. Demonstrated on DroneCrowd dataset, our approach exhibits superior performance, confirming its effectiveness in scenarios captured by drones.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17274",
        "abstract url": "https://arxiv.org/abs/2407.17274",
        "title": "Revolutionizing Text-to-Image Retrieval as Autoregressive Token-to-Voken Generation",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image retrieval is a fundamental task in multimedia processing, aiming to retrieve semantically relevant cross-modal content. Traditional studies have typically approached this task as a discriminative problem, matching the text and image via the cross-attention mechanism (one-tower framework) or in a common embedding space (two-tower framework). Recently, generative cross-modal retrieval has emerged as a new research line, which assigns images with unique string identifiers and generates the target identifier as the retrieval target. Despite its great potential, existing generative approaches are limited due to the following issues: insufficient visual information in identifiers, misalignment with high-level semantics, and learning gap towards the retrieval target. To address the above issues, we propose an autoregressive voken generation method, named AVG. AVG tokenizes images into vokens, i.e., visual tokens, and innovatively formulates the text-to-image retrieval task as a token-to-voken generation problem. AVG discretizes an image into a sequence of vokens as the identifier of the image, while maintaining the alignment with both the visual information and high-level semantics of the image. Additionally, to bridge the learning gap between generative training and the retrieval target, we incorporate discriminative training to modify the learning direction during token-to-voken training. Extensive experiments demonstrate that AVG achieves superior results in both effectiveness and efficiency.",
        "subjects": [
            "cs.MM",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2407.17310",
        "abstract url": "https://arxiv.org/abs/2407.17310",
        "title": "LangOcc: Self-Supervised Open Vocabulary Occupancy Estimation via Volume Rendering",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D",
                "voxel"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The 3D occupancy estimation task has become an important challenge in the area of vision-based autonomous driving recently. However, most existing camera-based methods rely on costly 3D voxel labels or LiDAR scans for training, limiting their practicality and scalability. Moreover, most methods are tied to a predefined set of classes which they can detect. In this work we present a novel approach for open vocabulary occupancy estimation called LangOcc, that is trained only via camera images, and can detect arbitrary semantics via vision-language alignment. In particular, we distill the knowledge of the strong vision-language aligned encoder CLIP into a 3D occupancy model via differentiable volume rendering. Our model estimates vision-language aligned features in a 3D voxel grid using only images. It is trained in a self-supervised manner by rendering our estimations back to 2D space, where ground-truth features can be computed. This training mechanism automatically supervises the scene geometry, allowing for a straight-forward and powerful training method without any explicit geometry supervision. LangOcc outperforms LiDAR-supervised competitors in open vocabulary occupancy by a large margin, solely relying on vision-based training. We also achieve state-of-the-art results in self-supervised semantic occupancy estimation on the Occ3D-nuScenes dataset, despite not being limited to a specific set of categories, thus demonstrating the effectiveness of our proposed vision-language training.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17339",
        "abstract url": "https://arxiv.org/abs/2407.17339",
        "title": "Preliminary study on artificial intelligence methods for cybersecurity threat detection in computer networks based on raw data packets",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Most of the intrusion detection methods in computer networks are based on traffic flow characteristics. However, this approach may not fully exploit the potential of deep learning algorithms to directly extract features and patterns from raw packets. Moreover, it impedes real-time monitoring due to the necessity of waiting for the processing pipeline to complete and introduces dependencies on additional software components. In this paper, we investigate deep learning methodologies capable of detecting attacks in real-time directly from raw packet data within network traffic. We propose a novel approach where packets are stacked into windows and separately recognised, with a 2D image representation suitable for processing with computer vision models. Our investigation utilizes the CIC IDS-2017 dataset, which includes both benign traffic and prevalent real-world attacks, providing a comprehensive foundation for our research.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "Submitted to Computer Science Journal"
    },
    {
        "paper id": "2407.17353",
        "abstract url": "https://arxiv.org/abs/2407.17353",
        "title": "Scalify: scale propagation for efficient low-precision LLM training",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Low-precision formats such as float8 have been introduced in machine learning accelerated hardware to improve computational efficiency for large language models training and inference. Nevertheless, adoption by the ML community has been slowed down by the complex, and sometimes brittle, techniques required to match higher precision training accuracy. In this work, we present Scalify, a end-to-end scale propagation paradigm for computational graphs, generalizing and formalizing existing tensor scaling methods. Experiment results show that Scalify supports out-of-the-box float8 matrix multiplication and gradients representation, as well as float16 optimizer state storage. Our JAX implementation of Scalify is open-sourced at https://github.com/graphcore-research/jax-scalify",
        "subjects": [
            "cs.LG"
        ],
        "comment": "11 pages, 5 figures, ICML 2024 WANT workshop"
    },
    {
        "paper id": "2407.17365",
        "abstract url": "https://arxiv.org/abs/2407.17365",
        "title": "ViPer: Visual Personalization of Generative Models via Individual Preference Learning",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Different users find different images generated for the same prompt desirable. This gives rise to personalized image generation which involves creating images aligned with an individual's visual preference. Current generative models are, however, unpersonalized, as they are tuned to produce outputs that appeal to a broad audience. Using them to generate images aligned with individual users relies on iterative manual prompt engineering by the user which is inefficient and undesirable. We propose to personalize the image generation process by first capturing the generic preferences of the user in a one-time process by inviting them to comment on a small selection of images, explaining why they like or dislike each. Based on these comments, we infer a user's structured liked and disliked visual attributes, i.e., their visual preference, using a large language model. These attributes are used to guide a text-to-image model toward producing images that are tuned towards the individual user's visual preference. Through a series of user studies and large language model guided evaluations, we demonstrate that the proposed method results in generations that are well aligned with individual users' visual preferences.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page at https://viper.epfl.ch/"
    },
    {
        "paper id": "2407.17409",
        "abstract url": "https://arxiv.org/abs/2407.17409",
        "title": "Generation of Training Data from HD Maps in the Lanelet2 Framework",
        "rating": "0",
        "keywords": [
            [
                "automated driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Using HD maps directly as training data for machine learning tasks has seen a massive surge in popularity and shown promising results, e.g. in the field of map perception. Despite that, a standardized HD map framework supporting all parts of map-based automated driving and training label generation from map data does not exist. Furthermore, feeding map perception models with map data as part of the input during real-time inference is not addressed by the research community. In order to fill this gap, we presentlanelet2_ml_converter, an integrated extension to the HD map framework Lanelet2, widely used in automated driving systems by academia and industry. With this addition Lanelet2 unifies map based automated driving, machine learning inference and training, all from a single source of map data and format. Requirements for a unified framework are analyzed and the implementation of these requirements is described. The usability of labels in state of the art machine learning is demonstrated with application examples from the field of map perception. The source code is available embedded in the Lanelet2 framework under https://github.com/fzi-forschungszentrum-informatik/Lanelet2/tree/feature_ml_converter",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17418",
        "abstract url": "https://arxiv.org/abs/2407.17418",
        "title": "3D Gaussian Splatting: Survey, Technologies, Challenges, and Opportunities",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3DGS) has emerged as a prominent technique with the potential to become a mainstream method for 3D representations. It can effectively transform multi-view images into explicit 3D Gaussian representations through efficient training, and achieve real-time rendering of novel views. This survey aims to analyze existing 3DGS-related works from multiple intersecting perspectives, including related tasks, technologies, challenges, and opportunities. The primary objective is to provide newcomers with a rapid understanding of the field and to assist researchers in methodically organizing existing technologies and challenges. Specifically, we delve into the optimization, application, and extension of 3DGS, categorizing them based on their focuses or motivations. Additionally, we summarize and classify nine types of technical modules and corresponding improvements identified in existing works. Based on these analyses, we further examine the common challenges and technologies across various tasks, proposing potential research opportunities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17430",
        "abstract url": "https://arxiv.org/abs/2407.17430",
        "title": "A Comprehensive Review and Taxonomy of Audio-Visual Synchronization Techniques for Realistic Speech Animation",
        "rating": "0",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "facial"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "In many applications, synchronizing audio with visuals is crucial, such as in creating graphic animations for films or games, translating movie audio into different languages, and developing metaverse applications. This review explores various methodologies for achieving realistic facial animations from audio inputs, highlighting generative and adaptive models. Addressing challenges like model training costs, dataset availability, and silent moment distributions in audio data, it presents innovative solutions to enhance performance and realism. The research also introduces a new taxonomy to categorize audio-visual synchronization methods based on logistical aspects, advancing the capabilities of virtual assistants, gaming, and interactive digital media.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17447",
        "abstract url": "https://arxiv.org/abs/2407.17447",
        "title": "Fluent Student-Teacher Redteaming",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Many publicly available language models have been safety tuned to reduce the likelihood of toxic or liability-inducing text. Users or security analysts attempt to jailbreak or redteam these models with adversarial prompts which cause compliance with requests. One attack method is to apply discrete optimization techniques to the prompt. However, the resulting attack strings are often gibberish text, easily filtered by defenders due to high measured perplexity, and may fail for unseen tasks and/or well-tuned models. In this work, we improve existing algorithms (primarily GCG and BEAST) to develop powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our technique centers around a new distillation-based approach that encourages the victim model to emulate a toxified finetune, either in terms of output probabilities or internal activations. To encourage human-fluent attacks, we add a multi-model perplexity penalty and a repetition penalty to the objective. We also enhance optimizer strength by allowing token insertions, token swaps, and token deletions and by using longer attack sequences. The resulting process is able to reliably jailbreak the most difficult target models with prompts that appear similar to human-written prompts. On Advbench we achieve attack success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while maintaining model-measured perplexity $<33$; we achieve $95$% attack success for Phi-3, though with higher perplexity. We also find a universally-optimized single fluent prompt that induces $>88$% compliance on previously unseen tasks across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17449",
        "abstract url": "https://arxiv.org/abs/2407.17449",
        "title": "Looking at Model Debiasing through the Lens of Anomaly Detection",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "It is widely recognized that deep neural networks are sensitive to bias in the data. This means that during training these models are likely to learn spurious correlations between data and labels, resulting in limited generalization abilities and low performance. In this context, model debiasing approaches can be devised aiming at reducing the model's dependency on such unwanted correlations, either leveraging the knowledge of bias information or not. In this work, we focus on the latter and more realistic scenario, showing the importance of accurately predicting the bias-conflicting and bias-aligned samples to obtain compelling performance in bias mitigation. On this ground, we propose to conceive the problem of model bias from an out-of-distribution perspective, introducing a new bias identification method based on anomaly detection. We claim that when data is mostly biased, bias-conflicting samples can be regarded as outliers with respect to the bias-aligned distribution in the feature space of a biased model, thus allowing for precisely detecting them with an anomaly detection method. Coupling the proposed bias identification approach with bias-conflicting data upsampling and augmentation in a two-step strategy, we reach state-of-the-art performance on synthetic and real benchmark datasets. Ultimately, our proposed approach shows that the data bias issue does not necessarily require complex debiasing methods, given that an accurate bias identification procedure is defined.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "15 pages, 7 figures"
    },
    {
        "paper id": "2407.17457",
        "abstract url": "https://arxiv.org/abs/2407.17457",
        "title": "CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition",
        "rating": "0",
        "keywords": [
            [
                "RGB-D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present a new algorithm, Cross-Source-Context Place Recognition (CSCPR), for RGB-D indoor place recognition that integrates global retrieval and reranking into a single end-to-end model. Unlike prior approaches that primarily focus on the RGB domain, CSCPR is designed to handle the RGB-D data. We extend the Context-of-Clusters (CoCs) for handling noisy colorized point clouds and introduce two novel modules for reranking: the Self-Context Cluster (SCC) and Cross Source Context Cluster (CSCC), which enhance feature representation and match query-database pairs based on local features, respectively. We also present two new datasets, ScanNetIPR and ARKitIPR. Our experiments demonstrate that CSCPR significantly outperforms state-of-the-art models on these datasets by at least 36.5% in Recall@1 at ScanNet-PR dataset and 44% in new datasets. Code and datasets will be released.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17460",
        "abstract url": "https://arxiv.org/abs/2407.17460",
        "title": "SoNIC: Safe Social Navigation with Adaptive Conformal Inference and Constrained Reinforcement Learning",
        "rating": "0",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) has enabled social robots to generate trajectories without human-designed rules or interventions, which makes it more effective than hard-coded systems for generalizing to complex real-world scenarios. However, social navigation is a safety-critical task that requires robots to avoid collisions with pedestrians while previous RL-based solutions fall short in safety performance in complex environments. To enhance the safety of RL policies, to the best of our knowledge, we propose the first algorithm, SoNIC, that integrates adaptive conformal inference (ACI) with constrained reinforcement learning (CRL) to learn safe policies for social navigation. More specifically, our method augments RL observations with ACI-generated nonconformity scores and provides explicit guidance for agents to leverage the uncertainty metrics to avoid safety-critical areas by incorporating safety constraints with spatial relaxation. Our method outperforms state-of-the-art baselines in terms of both safety and adherence to social norms by a large margin and demonstrates much stronger robustness to out-of-distribution scenarios. Our code and video demos are available on our project website: https://sonic-social-nav.github.io/.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Project website: https://sonic-social-nav.github.io/"
    },
    {
        "paper id": "2407.17545",
        "abstract url": "https://arxiv.org/abs/2407.17545",
        "title": "Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Anomaly detection in computational workflows is critical for ensuring system reliability and security. However, traditional rule-based methods struggle to detect novel anomalies. This paper leverages large language models (LLMs) for workflow anomaly detection by exploiting their ability to learn complex data patterns. Two approaches are investigated: 1) supervised fine-tuning (SFT), where pre-trained LLMs are fine-tuned on labeled data for sentence classification to identify anomalies, and 2) in-context learning (ICL) where prompts containing task descriptions and examples guide LLMs in few-shot anomaly detection without fine-tuning. The paper evaluates the performance, efficiency, generalization of SFT models, and explores zero-shot and few-shot ICL prompts and interpretability enhancement via chain-of-thought prompting. Experiments across multiple workflow datasets demonstrate the promising potential of LLMs for effective anomaly detection in complex executions.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "12 pages, 14 figures, paper is accepted by SC'24, source code, see: https://github.com/PoSeiDon-Workflows/LLM_AD"
    },
    {
        "paper id": "2407.17630",
        "abstract url": "https://arxiv.org/abs/2407.17630",
        "title": "Revising the Problem of Partial Labels from the Perspective of CNNs' Robustness",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Convolutional neural networks (CNNs) have gained increasing popularity and versatility in recent decades, finding applications in diverse domains. These remarkable achievements are greatly attributed to the support of extensive datasets with precise labels. However, annotating image datasets is intricate and complex, particularly in the case of multi-label datasets. Hence, the concept of partial-label setting has been proposed to reduce annotation costs, and numerous corresponding solutions have been introduced. The evaluation methods for these existing solutions have been primarily based on accuracy. That is, their performance is assessed by their predictive accuracy on the test set. However, we insist that such an evaluation is insufficient and one-sided. On one hand, since the quality of the test set has not been evaluated, the assessment results are unreliable. On the other hand, the partial-label problem may also be raised by undergoing adversarial attacks. Therefore, incorporating robustness into the evaluation system is crucial. For this purpose, we first propose two attack models to generate multiple partial-label datasets with varying degrees of label missing rates. Subsequently, we introduce a lightweight partial-label solution using pseudo-labeling techniques and a designed loss function. Then, we employ D-Score to analyze both the proposed and existing methods to determine whether they can enhance robustness while improving accuracy. Extensive experimental results demonstrate that while certain methods may improve accuracy, the enhancement in robustness is not significant, and in some cases, it even diminishes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17663",
        "abstract url": "https://arxiv.org/abs/2407.17663",
        "title": "Explaining the Model, Protecting Your Data: Revealing and Mitigating the Data Privacy Risks of Post-Hoc Model Explanations via Membership Inference",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Predictive machine learning models are becoming increasingly deployed in high-stakes contexts involving sensitive personal data; in these contexts, there is a trade-off between model explainability and data privacy. In this work, we push the boundaries of this trade-off: with a focus on foundation models for image classification fine-tuning, we reveal unforeseen privacy risks of post-hoc model explanations and subsequently offer mitigation strategies for such risks. First, we construct VAR-LRT and L1/L2-LRT, two new membership inference attacks based on feature attribution explanations that are significantly more successful than existing explanation-leveraging attacks, particularly in the low false-positive rate regime that allows an adversary to identify specific training set members with confidence. Second, we find empirically that optimized differentially private fine-tuning substantially diminishes the success of the aforementioned attacks, while maintaining high model accuracy. We carry out a systematic empirical investigation of our 2 new attacks with 5 vision transformer architectures, 5 benchmark datasets, 4 state-of-the-art post-hoc explanation methods, and 4 privacy strength settings.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "ICML 2024 Workshop on the Next Generation of AI Safety"
    },
    {
        "paper id": "2407.17686",
        "abstract url": "https://arxiv.org/abs/2407.17686",
        "title": "Transformers on Markov Data: Constant Depth Suffices",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Attention-based transformers have been remarkably successful at modeling generative processes across various domains and modalities. In this paper, we study the behavior of transformers on data drawn from \\kth Markov processes, where the conditional distribution of the next symbol in a sequence depends on the previous $k$ symbols observed. We observe a surprising phenomenon empirically which contradicts previous findings: when trained for sufficiently long, a transformer with a fixed depth and $1$ head per layer is able to achieve low test loss on sequences drawn from \\kth Markov sources, even as $k$ grows. Furthermore, this low test loss is achieved by the transformer's ability to represent and learn the in-context conditional empirical distribution. On the theoretical side, our main result is that a transformer with a single head and three layers can represent the in-context conditional empirical distribution for \\kth Markov sources, concurring with our empirical observations. Along the way, we prove that \\textit{attention-only} transformers with $O(\\log_2(k))$ layers can represent the in-context conditional empirical distribution by composing induction heads to track the previous $k$ symbols in the sequence. These results provide more insight into our current understanding of the mechanisms by which transformers learn to capture context, by understanding their behavior on Markov sources.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.IT",
            "stat.ML"
        ],
        "comment": "29 pages, 10 figures"
    },
    {
        "paper id": "2407.17734",
        "abstract url": "https://arxiv.org/abs/2407.17734",
        "title": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "clinical",
                "pathological"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "The advent of vision-language models fosters the interactive conversations between AI-enabled models and humans. Yet applying these models into clinics must deal with daunting challenges around large-scale training data, financial, and computational resources. Here we propose a cost-effective instruction learning framework for conversational pathology named as CLOVER. CLOVER only trains a lightweight module and uses instruction tuning while freezing the parameters of the large language model. Instead of using costly GPT-4, we propose well-designed prompts on GPT-3.5 for building generation-based instructions, emphasizing the utility of pathological knowledge derived from the Internet source. To augment the use of instructions, we construct a high-quality set of template-based instructions in the context of digital pathology. From two benchmark datasets, our findings reveal the strength of hybrid-form instructions in the visual question-answer in pathology. Extensive results show the cost-effectiveness of CLOVER in answering both open-ended and closed-ended questions, where CLOVER outperforms strong baselines that possess 37 times more training parameters and use instruction data generated from GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot learning in the external clinical dataset. These findings demonstrate that cost-effective modeling of CLOVER could accelerate the adoption of rapid conversational applications in the landscape of digital pathology.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17757",
        "abstract url": "https://arxiv.org/abs/2407.17757",
        "title": "CRASH: Crash Recognition and Anticipation System Harnessing with Context-Aware and Temporal Focus Attentions",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurately and promptly predicting accidents among surrounding traffic agents from camera footage is crucial for the safety of autonomous vehicles (AVs). This task presents substantial challenges stemming from the unpredictable nature of traffic accidents, their long-tail distribution, the intricacies of traffic scene dynamics, and the inherently constrained field of vision of onboard cameras. To address these challenges, this study introduces a novel accident anticipation framework for AVs, termed CRASH. It seamlessly integrates five components: object detector, feature extractor, object-aware module, context-aware module, and multi-layer fusion. Specifically, we develop the object-aware module to prioritize high-risk objects in complex and ambiguous environments by calculating the spatial-temporal relationships between traffic agents. In parallel, the context-aware is also devised to extend global visual information from the temporal to the frequency domain using the Fast Fourier Transform (FFT) and capture fine-grained visual features of potential objects and broader context cues within traffic scenes. To capture a wider range of visual cues, we further propose a multi-layer fusion that dynamically computes the temporal dependencies between different scenes and iteratively updates the correlations between different visual features for accurate and timely accident prediction. Evaluated on real-world datasets--Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D) datasets--our model surpasses existing top baselines in critical evaluation metrics like Average Precision (AP) and mean Time-To-Accident (mTTA). Importantly, its robustness and adaptability are particularly evident in challenging driving scenarios with missing or limited training data, demonstrating significant potential for application in real-world autonomous driving systems.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20268",
        "abstract url": "https://arxiv.org/abs/2407.20268",
        "title": "Utilizing Generative Adversarial Networks for Image Data Augmentation and Classification of Semiconductor Wafer Dicing Induced Defects",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In semiconductor manufacturing, the wafer dicing process is central yet vulnerable to defects that significantly impair yield - the proportion of defect-free chips. Deep neural networks are the current state of the art in (semi-)automated visual inspection. However, they are notoriously known to require a particularly large amount of data for model training. To address these challenges, we explore the application of generative adversarial networks (GAN) for image data augmentation and classification of semiconductor wafer dicing induced defects to enhance the variety and balance of training data for visual inspection systems. With this approach, synthetic yet realistic images are generated that mimic real-world dicing defects. We employ three different GAN variants for high-resolution image synthesis: Deep Convolutional GAN (DCGAN), CycleGAN, and StyleGAN3. Our work-in-progress results demonstrate that improved classification accuracies can be obtained, showing an average improvement of up to 23.1 % from 65.1 % (baseline experiment) to 88.2 % (DCGAN experiment) in balanced accuracy, which may enable yield optimization in production.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "Accepted for: 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)"
    },
    {
        "paper id": "2407.17033",
        "abstract url": "https://arxiv.org/abs/2407.17033",
        "title": "Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep Gaussian processes (DGPs) provide a robust paradigm for Bayesian deep learning. In DGPs, a set of sparse integration locations called inducing points are selected to approximate the posterior distribution of the model. This is done to reduce computational complexity and improve model efficiency. However, inferring the posterior distribution of inducing points is not straightforward. Traditional variational inference approaches to posterior approximation often lead to significant bias. To address this issue, we propose an alternative method called Denoising Diffusion Variational Inference (DDVI) that uses a denoising diffusion stochastic differential equation (SDE) to generate posterior samples of inducing variables. We rely on score matching methods for denoising diffusion model to approximate score functions with a neural network. Furthermore, by combining classical mathematical theory of SDEs with the minimization of KL divergence between the approximate and true processes, we propose a novel explicit variational lower bound for the marginal likelihood function of DGP. Through experiments on various datasets and comparisons with baseline methods, we empirically demonstrate the effectiveness of DDVI for posterior inference of inducing points for DGP models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17070",
        "abstract url": "https://arxiv.org/abs/2407.17070",
        "title": "Curriculum Negative Mining For Temporal Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Temporal networks are effective in capturing the evolving interactions of networks over time, such as social networks and e-commerce networks. In recent years, researchers have primarily concentrated on developing specific model architectures for Temporal Graph Neural Networks (TGNNs) in order to improve the representation quality of temporal nodes and edges. However, limited attention has been given to the quality of negative samples during the training of TGNNs. When compared with static networks, temporal networks present two specific challenges for negative sampling: positive sparsity and positive shift. Positive sparsity refers to the presence of a single positive sample amidst numerous negative samples at each timestamp, while positive shift relates to the variations in positive samples across different timestamps. To robustly address these challenges in training TGNNs, we introduce Curriculum Negative Mining (CurNM), a model-aware curriculum learning framework that adaptively adjusts the difficulty of negative samples. Within this framework, we first establish a dynamically updated negative pool that balances random, historical, and hard negatives to address the challenges posed by positive sparsity. Secondly, we implement a temporal-aware negative selection module that focuses on learning from the disentangled factors of recently active edges, thus accurately capturing shifting preferences. Extensive experiments on 12 datasets and 3 TGNNs demonstrate that our method outperforms baseline methods by a significant margin. Additionally, thorough ablation studies and parameter sensitivity experiments verify the usefulness and robustness of our approach. Our code is available at https://github.com/zziyue83/CurNM.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17200",
        "abstract url": "https://arxiv.org/abs/2407.17200",
        "title": "Generalization Bounds of Surrogate Policies for Combinatorial Optimization Problems",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A recent stream of structured learning approaches has improved the practical state of the art for a range of combinatorial optimization problems with complex objectives encountered in operations research. Such approaches train policies that chain a statistical model with a surrogate combinatorial optimization oracle to map any instance of the problem to a feasible solution. The key idea is to exploit the statistical distribution over instances instead of dealing with instances separately. However learning such policies by risk minimization is challenging because the empirical risk is piecewise constant in the parameters, and few theoretical guarantees have been provided so far. In this article, we investigate methods that smooth the risk by perturbing the policy, which eases optimization and improves generalization. Our main contribution is a generalization bound that controls the perturbation bias, the statistical learning error, and the optimization error. Our analysis relies on the introduction of a uniform weak property, which captures and quantifies the interplay of the statistical model and the surrogate combinatorial optimization oracle. This property holds under mild assumptions on the statistical model, the surrogate optimization, and the instance data distribution. We illustrate the result on a range of applications such as stochastic vehicle scheduling. In particular, such policies are relevant for contextual stochastic optimization and our results cover this case.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC",
            "stat.ME"
        ],
        "comment": "10 pages main document, 3 pages supplement"
    },
    {
        "paper id": "2407.17206",
        "abstract url": "https://arxiv.org/abs/2407.17206",
        "title": "Take a Step and Reconsider: Sequence Decoding for Self-Improved Neural Combinatorial Optimization",
        "rating": "-0.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The constructive approach within Neural Combinatorial Optimization (NCO) treats a combinatorial optimization problem as a finite Markov decision process, where solutions are built incrementally through a sequence of decisions guided by a neural policy network. To train the policy, recent research is shifting toward a 'self-improved' learning methodology that addresses the limitations of reinforcement learning and supervised approaches. Here, the policy is iteratively trained in a supervised manner, with solutions derived from the current policy serving as pseudo-labels. The way these solutions are obtained from the policy determines the quality of the pseudo-labels. In this paper, we present a simple and problem-independent sequence decoding method for self-improved learning based on sampling sequences without replacement. We incrementally follow the best solution found and repeat the sampling process from intermediate partial solutions. By modifying the policy to ignore previously sampled sequences, we force it to consider only unseen alternatives, thereby increasing solution diversity. Experimental results for the Traveling Salesman and Capacitated Vehicle Routing Problem demonstrate its strong performance. Furthermore, our method outperforms previous NCO approaches on the Job Shop Scheduling Problem.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted at ECAI-2024"
    },
    {
        "paper id": "2407.17211",
        "abstract url": "https://arxiv.org/abs/2407.17211",
        "title": "Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles",
        "rating": "-0.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. We design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% (just below the 86% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-o has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.",
        "subjects": [
            "cs.AI",
            "cs.NI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17396",
        "abstract url": "https://arxiv.org/abs/2407.17396",
        "title": "Systematic Reasoning About Relational Domains With Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Developing models that can learn to reason is a notoriously challenging problem. We focus on reasoning in relational domains, where the use of Graph Neural Networks (GNNs) seems like a natural choice. However, previous work on reasoning with GNNs has shown that such models tend to fail when presented with test examples that require longer inference chains than those seen during training. This suggests that GNNs lack the ability to generalize from training examples in a systematic way, which would fundamentally limit their reasoning abilities. A common solution is to instead rely on neuro-symbolic methods, which are capable of reasoning in a systematic way by design. Unfortunately, the scalability of such methods is often limited and they tend to rely on overly strong assumptions, e.g.\\ that queries can be answered by inspecting a single relational path. In this paper, we revisit the idea of reasoning with GNNs, showing that systematic generalization is possible as long as the right inductive bias is provided. In particular, we argue that node embeddings should be treated as epistemic states and that GNN should be parameterised accordingly. We propose a simple GNN architecture which is based on this view and show that it is capable of achieving state-of-the-art results. We furthermore introduce a benchmark which requires models to aggregate evidence from multiple relational paths. We show that existing neuro-symbolic approaches fail on this benchmark, whereas our considered GNN model learns to reason accurately.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "10+16 pages, 2+7 figures, 4+9 tables. Preprint under review. Comments welcome"
    },
    {
        "paper id": "2407.17413",
        "abstract url": "https://arxiv.org/abs/2407.17413",
        "title": "$A^*$ for Graphs of Convex Sets",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present a novel algorithm that fuses the existing convex-programming based approach with heuristic information to find optimality guarantees and near-optimal paths for the Shortest Path Problem in the Graph of Convex Sets (SPP-GCS). Our method, inspired by $A^*$, initiates a best-first-like procedure from a designated subset of vertices and iteratively expands it until further growth is neither possible nor beneficial. Traditionally, obtaining solutions with bounds for an optimization problem involves solving a relaxation, modifying the relaxed solution to a feasible one, and then comparing the two solutions to establish bounds. However, for SPP-GCS, we demonstrate that reversing this process can be more advantageous, especially with Euclidean travel costs. In other words, we initially employ $A^*$ to find a feasible solution for SPP-GCS, then solve a convex relaxation restricted to the vertices explored by $A^*$ to obtain a relaxed solution, and finally, compare the solutions to derive bounds. We present numerical results to highlight the advantages of our algorithm over the existing approach in terms of the sizes of the convex programs solved and computation time.",
        "subjects": [
            "math.OC",
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17611",
        "abstract url": "https://arxiv.org/abs/2407.17611",
        "title": "Adaptive Training of Grid-Dependent Physics-Informed Kolmogorov-Arnold Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a robust framework for solving Partial Differential Equations (PDEs) by approximating their solutions via neural networks and imposing physics-based constraints on the loss function. Traditionally, Multilayer Perceptrons (MLPs) are the neural network of choice, and significant progress has been made in optimizing their training. Recently, Kolmogorov-Arnold Networks (KANs) were introduced as a viable alternative, with the potential of offering better interpretability and efficiency while requiring fewer parameters. In this paper, we present a fast JAX-based implementation of grid-dependent Physics-Informed Kolmogorov-Arnold Networks (PIKANs) for solving PDEs. We propose an adaptive training scheme for PIKANs, incorporating known MLP-based PINN techniques, introducing an adaptive state transition scheme to avoid loss function peaks between grid updates, and proposing a methodology for designing PIKANs with alternative basis functions. Through comparative experiments we demonstrate that these adaptive features significantly enhance training efficiency and solution accuracy. Our results illustrate the effectiveness of PIKANs in improving performance for PDE solutions, highlighting their potential as a superior alternative in scientific and engineering applications.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17622",
        "abstract url": "https://arxiv.org/abs/2407.17622",
        "title": "Towards Neural Network based Cognitive Models of Dynamic Decision-Making by Humans",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Modelling human cognitive processes in dynamic decision-making tasks has been an endeavor in AI for a long time. Some initial works have attempted to utilize neural networks (and large language models) but often assume one common model for all humans and aim to emulate human behavior in aggregate. However, behavior of each human is distinct, heterogeneous and relies on specific past experiences in specific tasks. To that end, we build on a well known model of cognition, namely Instance Based Learning (IBL), that posits that decisions are made based on similar situations encountered in the past. We propose two new attention based neural network models to model human decision-making in dynamic settings. We experiment with two distinct datasets gathered from human subject experiment data, one focusing on detection of phishing email by humans and another where humans act as attackers in a cybersecurity setting and decide on an attack option. We conduct extensive experiments with our two neural network models, IBL, and GPT3.5, and demonstrate that one of our neural network models achieves the best performance in representing human decision-making. We find an interesting trend that all models predict a human's decision better if that human is better at the task. We also explore explanation of human decisions based on what our model considers important in prediction. Overall, our work yields promising results for further use of neural networks in cognitive modelling of human decision making. Our code is available at https://github.com/shshnkreddy/NCM-HDM.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17642",
        "abstract url": "https://arxiv.org/abs/2407.17642",
        "title": "SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Predicting traffic accidents is the key to sustainable city management, which requires effective address of the dynamic and complex spatiotemporal characteristics of cities. Current data-driven models often struggle with data sparsity and typically overlook the integration of diverse urban data sources and the high-order dependencies within them. Additionally, they frequently rely on predefined topologies or weights, limiting their adaptability in spatiotemporal predictions. To address these issues, we introduce the Spatiotemporal Multiview Adaptive HyperGraph Learning (SMA-Hyper) model, a dynamic deep learning framework designed for traffic accident prediction. Building on previous research, this innovative model incorporates dual adaptive spatiotemporal graph learning mechanisms that enable high-order cross-regional learning through hypergraphs and dynamic adaptation to evolving urban data. It also utilises contrastive learning to enhance global and local data representations in sparse datasets and employs an advance attention mechanism to fuse multiple views of accident data and urban functional features, thereby enriching the contextual understanding of risk factors. Extensive testing on the London traffic accident dataset demonstrates that the SMA-Hyper model significantly outperforms baseline models across various temporal horizons and multistep outputs, affirming the effectiveness of its multiview fusion and adaptive learning strategies. The interpretability of the results further underscores its potential to improve urban traffic management and safety by leveraging complex spatiotemporal urban data, offering a scalable framework adaptable to diverse urban environments.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17672",
        "abstract url": "https://arxiv.org/abs/2407.17672",
        "title": "Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Federated machine learning enables model training across multiple clients while maintaining data privacy. Vertical Federated Learning (VFL) specifically deals with instances where the clients have different feature sets of the same samples. As federated learning models aim to improve efficiency and adaptability, innovative neural network architectures like Spiking Neural Networks (SNNs) are being leveraged to enable fast and accurate processing at the edge. SNNs, known for their efficiency over Artificial Neural Networks (ANNs), have not been analyzed for their applicability in VFL, thus far. In this paper, we investigate the benefits and trade-offs of using SNN models in a vertical federated learning setting. We implement two different federated learning architectures -- with model splitting and without model splitting -- that have different privacy and performance implications. We evaluate the setup using CIFAR-10 and CIFAR-100 benchmark datasets along with SNN implementations of VGG9 and ResNET classification models. Comparative evaluations demonstrate that the accuracy of SNN models is comparable to that of traditional ANNs for VFL applications, albeit significantly more energy efficient.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17710",
        "abstract url": "https://arxiv.org/abs/2407.17710",
        "title": "Revisiting Machine Unlearning with Dimensional Alignment",
        "rating": "-0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine unlearning, an emerging research topic focusing on compliance with data privacy regulations, enables trained models to remove the information learned from specific data. While many existing methods indirectly address this issue by intentionally injecting incorrect supervisions, they can drastically and unpredictably alter the decision boundaries and feature spaces, leading to training instability and undesired side effects. To fundamentally approach this task, we first analyze the changes in latent feature spaces between original and retrained models, and observe that the feature representations of samples not involved in training are closely aligned with the feature manifolds of previously seen samples in training. Based on these findings, we introduce a novel evaluation metric for machine unlearning, coined dimensional alignment, which measures the alignment between the eigenspaces of the forget and retain set samples. We employ this metric as a regularizer loss to build a robust and stable unlearning framework, which is further enhanced by integrating a self-distillation loss and an alternating training scheme. Our framework effectively eliminates information from the forget set and preserves knowledge from the retain set. Lastly, we identify critical flaws in established evaluation metrics for machine unlearning, and introduce new evaluation tools that more accurately reflect the fundamental goals of machine unlearning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17754",
        "abstract url": "https://arxiv.org/abs/2407.17754",
        "title": "DualFed: Enjoying both Generalization and Personalization in Federated Learning via Hierachical Representations",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In personalized federated learning (PFL), it is widely recognized that achieving both high model generalization and effective personalization poses a significant challenge due to their conflicting nature. As a result, existing PFL methods can only manage a trade-off between these two objectives. This raises an interesting question: Is it feasible to develop a model capable of achieving both objectives simultaneously? Our paper presents an affirmative answer, and the key lies in the observation that deep models inherently exhibit hierarchical architectures, which produce representations with various levels of generalization and personalization at different stages. A straightforward approach stemming from this observation is to select multiple representations from these layers and combine them to concurrently achieve generalization and personalization. However, the number of candidate representations is commonly huge, which makes this method infeasible due to high computational costs.To address this problem, we propose DualFed, a new method that can directly yield dual representations correspond to generalization and personalization respectively, thereby simplifying the optimization task. Specifically, DualFed inserts a personalized projection network between the encoder and classifier. The pre-projection representations are able to capture generalized information shareable across clients, and the post-projection representations are effective to capture task-specific information on local clients. This design minimizes the mutual interference between generalization and personalization, thereby achieving a win-win situation. Extensive experiments show that DualFed can outperform other FL methods. Code is available at https://github.com/GuogangZhu/DualFed.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "Accepted by ACM MutltiMedia 2024"
    },
    {
        "paper id": "2407.18278",
        "abstract url": "https://arxiv.org/abs/2407.18278",
        "title": "Talking Wikidata: Communication patterns and their impact on community engagement in collaborative knowledge graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "We study collaboration patterns of Wikidata, one of the world's largest collaborative knowledge graph communities. Wikidata lacks long-term engagement with a small group of priceless members, 0.8%, to be responsible for 80% of contributions. Therefore, it is essential to investigate their behavioural patterns and find ways to enhance their contributions and participation. Previous studies have highlighted the importance of discussions among contributors in understanding these patterns. To investigate this, we analyzed all the discussions on Wikidata and used a mixed methods approach, including statistical tests, network analysis, and text and graph embedding representations. Our research showed that the interactions between Wikidata editors form a small world network where the content of a post influences the continuity of conversations. We also found that the account age of Wikidata members and their conversations are significant factors in their long-term engagement with the project. Our findings can benefit the Wikidata community by helping them improve their practices to increase contributions and enhance long-term participation.",
        "subjects": [
            "cs.SI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17030",
        "abstract url": "https://arxiv.org/abs/2407.17030",
        "title": "Applications of Multi-Agent Deep Reinforcement Learning Communication in Network Management: A Survey",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving"
            ]
        ],
        "abstract": "With the advancement of artificial intelligence technology, the automation of network management, also known as Autonomous Driving Networks (ADN), is gaining widespread attention. The network management has shifted from traditional homogeneity and centralization to heterogeneity and decentralization. Multi-agent deep reinforcement learning (MADRL) allows agents to make decisions based on local observations independently. This approach is in line with the needs of automation and has garnered significant attention from academia and industry. In a distributed environment, information interaction between agents can effectively address the non-stationarity problem of multiple agents and promote cooperation. Therefore, in this survey, we first examined the application of MADRL in network management, including specific application fields such as traffic engineering, wireless network access, power control, and network security. Then, we conducted a detailed analysis of communication behavior between agents, including communication schemes, communication content construction, communication object selection, message processing, and communication constraints. Finally, we discussed the open issues and future research directions of agent communication in MADRL for future network management and ADN applications.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17035",
        "abstract url": "https://arxiv.org/abs/2407.17035",
        "title": "Q-Ground: Image Quality Grounding with Large Multi-modality Models",
        "rating": "-1",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances of large multi-modality models (LMM) have greatly improved the ability of image quality assessment (IQA) method to evaluate and explain the quality of visual content. However, these advancements are mostly focused on overall quality assessment, and the detailed examination of local quality, which is crucial for comprehensive visual understanding, is still largely unexplored. In this work, we introduce Q-Ground, the first framework aimed at tackling fine-scale visual quality grounding by combining large multi-modality models with detailed visual quality analysis. Central to our contribution is the introduction of the QGround-100K dataset, a novel resource containing 100k triplets of (image, quality text, distortion segmentation) to facilitate deep investigations into visual quality. The dataset comprises two parts: one with human-labeled annotations for accurate quality assessment, and another labeled automatically by LMMs such as GPT4V, which helps improve the robustness of model training while also reducing the costs of data collection. With the QGround-100K dataset, we propose a LMM-based method equipped with multi-scale feature learning to learn models capable of performing both image quality answering and distortion segmentation based on text prompts. This dual-capability approach not only refines the model's understanding of region-aware image quality but also enables it to interactively respond to complex, text-based queries about image quality and specific distortions. Q-Ground takes a step towards sophisticated visual quality analysis in a finer scale, establishing a new benchmark for future research in the area. Codes and dataset are available at https://github.com/Q-Future/Q-Ground.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ACM Multimedia 2024 (Oral)"
    },
    {
        "paper id": "2407.17051",
        "abstract url": "https://arxiv.org/abs/2407.17051",
        "title": "Number of Subgraphs and Their Converses in Tournaments and New Digraph Polynomials",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "An oriented graph $D$ is converse invariant if, for any tournament $T$, the number of copies of $D$ in $T$ is equal to that of its converse $-D$. El Sahili and Ghazo Hanna [J. Graph Theory 102 (2023), 684-701] showed that any oriented graph $D$ with maximum degree at most 2 is converse invariant. They proposed a question: Can we characterize all converse invariant oriented graphs? In this paper, we introduce a digraph polynomial and employ it to give a necessary condition for an oriented graph to be converse invariant. This polynomial serves as a cornerstone in proving all the results presented in this paper. In particular, we characterize all orientations of trees with diameter at most 3 that are converse invariant. We also show that all orientations of regular graphs are not converse invariant if $D$ and $-D$ have different degree sequences. In addition, in contrast to the findings of El Sahili and Ghazo Hanna, we prove that every connected graph $G$ with maximum degree at least $3$, admits an orientation $D$ of $G$ such that $D$ is not converse invariant. We pose one conjecture.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17057",
        "abstract url": "https://arxiv.org/abs/2407.17057",
        "title": "Efffcient Sensing Parameter Estimation with Direct Clutter Mitigation in Perceptive Mobile Networks",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "In this work, we investigate sensing parameter estimation in the presence of clutter in perceptive mobile networks (PMNs) that integrate radar sensing into mobile communications. Performing clutter suppression before sensing parameter estimation is generally desirable as the number of sensing parameters can be signiffcantly reduced. However, existing methods require high-complexity clutter mitigation and sensing parameter estimation, where clutter is ffrstly identiffed and then removed. In this correspondence, we propose a much simpler but more effective method by incorporating a clutter cancellation mechanism in formulating a sparse signal model for sensing parameter estimation. In particular, clutter mitigation is performed directly on the received signals and the unitary approximate message passing (UAMP) is leveraged to exploit the common support for sensing parameter estimation in the formulated sparse signal recovery problem. Simulation results show that, compared to state-of-theart methods, the proposed method delivers signiffcantly better performance while with substantially reduced complexity.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17114",
        "abstract url": "https://arxiv.org/abs/2407.17114",
        "title": "A Self-Supervised Image Registration Approach for Measuring Local Response Patterns in Metastatic Ovarian Cancer",
        "rating": "-1",
        "keywords": [
            [
                "survival",
                "Cancer",
                "disease",
                "pathological",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "High-grade serous ovarian carcinoma (HGSOC) is characterised by significant spatial and temporal heterogeneity, typically manifesting at an advanced metastatic stage. A major challenge in treating advanced HGSOC is effectively monitoring localised change in tumour burden across multiple sites during neoadjuvant chemotherapy (NACT) and predicting long-term pathological response and overall patient survival. In this work, we propose a self-supervised deformable image registration algorithm that utilises a general-purpose image encoder for image feature extraction to co-register contrast-enhanced computerised tomography scan images acquired before and after neoadjuvant chemotherapy. This approach addresses challenges posed by highly complex tumour deformations and longitudinal lesion matching during treatment. Localised tumour changes are calculated using the Jacobian determinant maps of the registration deformation at multiple disease sites and their macroscopic areas, including hypo-dense (i.e., cystic/necrotic), hyper-dense (i.e., calcified), and intermediate density (i.e., soft tissue) portions. A series of experiments is conducted to understand the role of a general-purpose image encoder and its application in quantifying change in tumour burden during neoadjuvant chemotherapy in HGSOC. This work is the first to demonstrate the feasibility of a self-supervised image registration approach in quantifying NACT-induced localised tumour changes across the whole disease burden of patients with complex multi-site HGSOC, which could be used as a potential marker for ovarian cancer patient's long-term pathological response and survival.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17126",
        "abstract url": "https://arxiv.org/abs/2407.17126",
        "title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Health"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Extracting social determinants of health (SDoH) from unstructured medical notes depends heavily on labor-intensive annotations, which are typically task-specific, hampering reusability and limiting sharing. In this study we introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM) method leveraging contrastive examples and concise instructions to extract SDoH without relying on extensive medical annotations or costly human intervention. It achieved tenfold and twentyfold reductions in time and cost respectively, and superior consistency with human annotators measured by Cohen's kappa of up to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the strengths of both, ensuring high accuracy and computational efficiency while consistently maintaining 0.90+ AUROC scores. Testing across three distinct datasets has confirmed its robustness and accuracy. This study highlights the potential of leveraging LLMs to revolutionize medical note classification, demonstrating their capability to achieve highly accurate classifications with significantly reduced time and cost.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17150",
        "abstract url": "https://arxiv.org/abs/2407.17150",
        "title": "SimCT: A Simple Consistency Test Protocol in LLMs Development Lifecycle",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we report our efforts to advance the standard operation procedure of developing Large Language Models (LLMs) or LLMs-based systems or services in industry. We introduce the concept of Large Language Model Development Lifecycle (LDLC) and then highlight the importance of consistency test in ensuring the delivery quality. The principled solution of consistency test, however, is usually overlooked by industrial practitioners and not urgent in academia, and current practical solutions are insufficiently rigours and labor-intensive. We thus propose a simple yet effective consistency test protocol, named SimCT. SimCT is mainly to proactively check the consistency across different development stages of \"bare metal\" LLMs or associated services without accessing the model artifacts, in an attempt to expedite the delivery by reducing the back-and-forth alignment communications among multiple teams involved in different development stages. Specifically, SimCT encompasses response-wise and model-wise tests. We implement the protocol with LightGBM and Student's t-test for two components respectively, and perform extensive experiments to substantiate the effectiveness of SimCT and the involved components.",
        "subjects": [
            "cs.CL",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17157",
        "abstract url": "https://arxiv.org/abs/2407.17157",
        "title": "Establishing Truly Causal Relationship Between Whole Slide Image Predictions and Diagnostic Evidence Subregions in Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "Whole Slide",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the field of deep learning-driven Whole Slide Image (WSI) classification, Multiple Instance Learning (MIL) has gained significant attention due to its ability to be trained using only slide-level diagnostic labels. Previous MIL researches have primarily focused on enhancing feature aggregators for globally analyzing WSIs, but overlook a causal relationship in diagnosis: model's prediction should ideally stem solely from regions of the image that contain diagnostic evidence (such as tumor cells), which usually occupy relatively small areas. To address this limitation and establish the truly causal relationship between model predictions and diagnostic evidence regions, we propose Causal Inference Multiple Instance Learning (CI-MIL). CI-MIL integrates feature distillation with a novel patch decorrelation mechanism, employing a two-stage causal inference approach to distill and process patches with high diagnostic value. Initially, CI-MIL leverages feature distillation to identify patches likely containing tumor cells and extracts their corresponding feature representations. These features are then mapped to random Fourier feature space, where a learnable weighting scheme is employed to minimize inter-feature correlations, effectively reducing redundancy from homogenous patches and mitigating data bias. These processes strengthen the causal relationship between model predictions and diagnostically relevant regions, making the prediction more direct and reliable. Experimental results demonstrate that CI-MIL outperforms state-of-the-art methods. Additionally, CI-MIL exhibits superior interpretability, as its selected regions demonstrate high consistency with ground truth annotations, promising more reliable diagnostic assistance for pathologists.",
        "subjects": [
            "cs.CV",
            "q-bio.TO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17167",
        "abstract url": "https://arxiv.org/abs/2407.17167",
        "title": "Zero-Shot vs. Few-Shot Multi-Speaker TTS Using Pre-trained Czech SpeechT5 Model",
        "rating": "-1",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we experimented with the SpeechT5 model pre-trained on large-scale datasets. We pre-trained the foundation model from scratch and fine-tuned it on a large-scale robust multi-speaker text-to-speech (TTS) task. We tested the model capabilities in a zero- and few-shot scenario. Based on two listening tests, we evaluated the synthetic audio quality and the similarity of how synthetic voices resemble real voices. Our results showed that the SpeechT5 model can generate a synthetic voice for any speaker using only one minute of the target speaker's data. We successfully demonstrated the high quality and similarity of our synthetic voices on publicly known Czech politicians and celebrities.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Accepted to TSD2024"
    },
    {
        "paper id": "2407.17181",
        "abstract url": "https://arxiv.org/abs/2407.17181",
        "title": "Trans2Unet: Neural fusion for Nuclei Semantic Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Nuclei segmentation, despite its fundamental role in histopathological image analysis, is still a challenge work. The main challenge of this task is the existence of overlapping areas, which makes separating independent nuclei more complicated. In this paper, we propose a new two-branch architecture by combining the Unet and TransUnet networks for nuclei segmentation task. In the proposed architecture, namely Trans2Unet, the input image is first sent into the Unet branch whose the last convolution layer is removed. This branch makes the network combine features from different spatial regions of the input image and localizes more precisely the regions of interest. The input image is also fed into the second branch. In the second branch, which is called TransUnet branch, the input image will be divided into patches of images. With Vision transformer (ViT) in architecture, TransUnet can serve as a powerful encoder for medical image segmentation tasks and enhance image details by recovering localized spatial information. To boost up Trans2Unet efficiency and performance, we proposed to infuse TransUnet with a computational-efficient variation called \"Waterfall\" Atrous Spatial Pooling with Skip Connection (WASP-KC) module, which is inspired by the \"Waterfall\" Atrous Spatial Pooling (WASP) module. Experiment results on the 2018 Data Science Bowl benchmark show the effectiveness and performance of the proposed architecture while compared with previous segmentation models.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "ICCAIS 2022"
    },
    {
        "paper id": "2407.17183",
        "abstract url": "https://arxiv.org/abs/2407.17183",
        "title": "Robust Point Cloud Registration in Robotic Inspection with Locally Consistent Gaussian Mixture Model",
        "rating": "-1",
        "keywords": [
            [
                "Point Cloud"
            ]
        ],
        "abstract": "In robotic inspection of aviation parts, achieving accurate pairwise point cloud registration between scanned and model data is essential. However, noise and outliers generated in robotic scanned data can compromise registration accuracy. To mitigate this challenge, this article proposes a probability-based registration method utilizing Gaussian Mixture Model (GMM) with local consistency constraint. This method converts the registration problem into a model fitting one, constraining the similarity of posterior distributions between neighboring points to enhance correspondence robustness. We employ the Expectation Maximization algorithm iteratively to find optimal rotation matrix and translation vector while obtaining GMM parameters. Both E-step and M-step have closed-form solutions. Simulation and actual experiments confirm the method's effectiveness, reducing root mean square error by 20% despite the presence of noise and outliers. The proposed method excels in robustness and accuracy compared to existing methods.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "12 pages, 14 figures"
    },
    {
        "paper id": "2407.17190",
        "abstract url": "https://arxiv.org/abs/2407.17190",
        "title": "Fusing LLMs and KGs for Formal Causal Reasoning behind Financial Risk Contagion",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Financial risks trend to spread from one entity to another, ultimately leading to systemic risks. The key to preventing such risks lies in understanding the causal chains behind risk contagion. Despite this, prevailing approaches primarily emphasize identifying risks, overlooking the underlying causal analysis of risk. To address such an issue, we propose a Risk Contagion Causal Reasoning model called RC2R, which uses the logical reasoning capabilities of large language models (LLMs) to dissect the causal mechanisms of risk contagion grounded in the factual and expert knowledge embedded within financial knowledge graphs (KGs). At the data level, we utilize financial KGs to construct causal instructions, empowering LLMs to perform formal causal reasoning on risk propagation and tackle the \"causal parrot\" problem of LLMs. In terms of model architecture, we integrate a fusion module that aligns tokens and nodes across various granularities via multi-scale contrastive learning, followed by the amalgamation of textual and graph-structured data through soft prompt with cross multi-head attention mechanisms. To quantify risk contagion, we introduce a risk pathway inference module for calculating risk scores for each node in the graph. Finally, we visualize the risk contagion pathways and their intensities using Sankey diagrams, providing detailed causal explanations. Comprehensive experiments on financial KGs and supply chain datasets demonstrate that our model outperforms several state-of-the-art models in prediction performance and out-of-distribution (OOD) generalization capabilities. We will make our dataset and code publicly accessible to encourage further research and development in this field.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17197",
        "abstract url": "https://arxiv.org/abs/2407.17197",
        "title": "ALPI: Auto-Labeller with Proxy Injection for 3D Object Detection using 2D Labels Only",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "3D object detection plays a crucial role in various applications such as autonomous vehicles, robotics and augmented reality. However, training 3D detectors requires a costly precise annotation, which is a hindrance to scaling annotation to large datasets. To address this challenge, we propose a weakly supervised 3D annotator that relies solely on 2D bounding box annotations from images, along with size priors. One major problem is that supervising a 3D detection model using only 2D boxes is not reliable due to ambiguities between different 3D poses and their identical 2D projection. We introduce a simple yet effective and generic solution: we build 3D proxy objects with annotations by construction and add them to the training dataset. Our method requires only size priors to adapt to new classes. To better align 2D supervision with 3D detection, our method ensures depth invariance with a novel expression of the 2D losses. Finally, to detect more challenging instances, our annotator follows an offline pseudo-labelling scheme which gradually improves its 3D pseudo-labels. Extensive experiments on the KITTI dataset demonstrate that our method not only performs on-par or above previous works on the Car category, but also achieves performance close to fully supervised methods on more challenging classes. We further demonstrate the effectiveness and robustness of our method by being the first to experiment on the more challenging nuScenes dataset. We additionally propose a setting where weak labels are obtained from a 2D detector pre-trained on MS-COCO instead of human annotations.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17205",
        "abstract url": "https://arxiv.org/abs/2407.17205",
        "title": "The Sketchfab 3D Creative Commons Collection (S3D3C)",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The technology to capture, create, and use three-dimensional (3D) models has become increasingly accessible in recent years. With increasing numbers of use cases for 3D models and collections of rapidly increasing size, better methods to analyze the content of 3D models are required. While previously proposed 3D model collections for research purposes exist, these often contain only untextured geometry and are typically designed for a specific application, which limits their use in quantitative evaluations of modern 3D model analysis methods. In this paper, we introduce the Sketchfab 3D Creative Commons Collection (S3D3C), a new 3D model research collection consisting of 40,802 creative commons licensed models downloaded from the 3D model platform Sketchfab. By including popular freely available models with a wide variety of technical properties, such as textures, materials, and animations, we enable its use in the evaluation of state-of-the-art geometry-based and view-based 3D model analysis and retrieval techniques.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17209",
        "abstract url": "https://arxiv.org/abs/2407.17209",
        "title": "Nonverbal Immediacy Analysis in Education: A Multimodal Computational Model",
        "rating": "-1",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel computational approach for analyzing nonverbal social behavior in educational settings. Integrating multimodal behavioral cues, including facial expressions, gesture intensity, and spatial dynamics, the model assesses the nonverbal immediacy (NVI) of teachers from RGB classroom videos. A dataset of 400 30-second video segments from German classrooms was constructed for model training and validation. The gesture intensity regressor achieved a correlation of 0.84, the perceived distance regressor 0.55, and the NVI model 0.44 with median human ratings. The model demonstrates the potential to provide a valuable support in nonverbal behavior assessment, approximating the accuracy of individual human raters. Validated against both questionnaire data and trained observer ratings, our models show moderate to strong correlations with relevant educational outcomes, indicating their efficacy in reflecting effective teaching behaviors. This research advances the objective assessment of nonverbal communication behaviors, opening new pathways for educational research.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "12 pages, 3 figures. Camera-ready version for the SAB 2024: 17th International Conference on the Simulation of Adaptive Behavior"
    },
    {
        "paper id": "2407.17230",
        "abstract url": "https://arxiv.org/abs/2407.17230",
        "title": "Improving ICD coding using Chapter based Named Entities and Attentional Models",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in natural language processing (NLP) have led to automation in various domains. However, clinical NLP often relies on benchmark datasets that may not reflect real-world scenarios accurately. Automatic ICD coding, a vital NLP task, typically uses outdated and imbalanced datasets like MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4 and 0.7 due to many false positives. Our research introduces an enhanced approach to ICD coding that improves F1 scores by using chapter-based named entities and attentional models. This method categorizes discharge summaries into ICD-9 Chapters and develops attentional models with chapter-specific data, eliminating the need to consider external data for code identification. For categorization, we use Chapter-IV to de-bias and influence key entities and weights without neural networks, creating accurate thresholds and providing interpretability for human validation. Post-validation, we develop attentional models for three frequent and three non-frequent codes from Chapter-IV using Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and 0.81 from these models demonstrate significant performance improvements in ICD coding.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "10 Pages"
    },
    {
        "paper id": "2407.17237",
        "abstract url": "https://arxiv.org/abs/2407.17237",
        "title": "Near-Field Integrated Sensing and Communication with Extremely Large-Scale Antenna Array",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper studies a near-field integrated sensing and communication (ISAC) system with extremely large-scale antenna array (ELAA), in which a base station (BS) deployed with enormous number of antennas transmits wireless signals to communicate with multiple communication users (CUs) and simultaneously uses the echo signals to localize multiple point targets in the three-dimension (3D) space. To balance the performance tradeoff between communication and target localization, we design the transmit covariance matrix at the BS to optimize the localization performance while ensuring the signal-to-interference-plus-noise ratio (SINR) constraints at individual CUs. In particular, we formulate three design problems by considering different 3D localization performance metrics, including minimizing the sum Cram\u00e9r-Rao bound (CRB), maximizing the minimum target illumination power, and maximizing the minimum target echo signal power. Although the three design problems are non-convex in general, we obtain their global optimal solutions via the technique of semi-definite relaxation (SDR). It is shown that the three problems have low-rank solution structures depending on the sensing and communication channel matrices, helping reduce the complexity of the SDR-based solutions. Interestingly, we find that in the special case with a single collocated target/CU present towards the middle of a symmetric uniform planar array (UPA), the optimal solutions to the three problems become identical to the SINR-maximization design and have a closed form, while in other cases they can be different in general. Besides, when the target/CU moves away from the transmitter/receiver, the CRB may first decrease and then increase. These two phenomena differ from those in the far-field. Numerical results show the benefits of the proposed designs for near-field ISAC, by exploiting the beam focusing capabilities of ELAA.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages (14 pages for Arxiv..), 31 figures, submitted for journal publication"
    },
    {
        "paper id": "2407.17265",
        "abstract url": "https://arxiv.org/abs/2407.17265",
        "title": "SCIsegV2: A Universal Tool for Segmentation of Intramedullary Lesions in Spinal Cord Injury",
        "rating": "-1",
        "keywords": [
            [
                "biomarkers",
                "MRI",
                "lesion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Spinal cord injury (SCI) is a devastating incidence leading to permanent paralysis and loss of sensory-motor functions potentially resulting in the formation of lesions within the spinal cord. Imaging biomarkers obtained from magnetic resonance imaging (MRI) scans can predict the functional recovery of individuals with SCI and help choose the optimal treatment strategy. Currently, most studies employ manual quantification of these MRI-derived biomarkers, which is a subjective and tedious task. In this work, we propose (i) a universal tool for the automatic segmentation of intramedullary SCI lesions, dubbed \\texttt{SCIsegV2}, and (ii) a method to automatically compute the width of the tissue bridges from the segmented lesion. Tissue bridges represent the spared spinal tissue adjacent to the lesion, which is associated with functional recovery in SCI patients. The tool was trained and validated on a heterogeneous dataset from 7 sites comprising patients from different SCI phases (acute, sub-acute, and chronic) and etiologies (traumatic SCI, ischemic SCI, and degenerative cervical myelopathy). Tissue bridges quantified automatically did not significantly differ from those computed manually, suggesting that the proposed automatic tool can be used to derive relevant MRI biomarkers. \\texttt{SCIsegV2} and the automatic tissue bridges computation are open-source and available in Spinal Cord Toolbox (v6.4 and above) via the \\texttt{sct\\_deepseg -task seg\\_sc\\_lesion\\_t2w\\_sci} and \\texttt{sct\\_analyze\\_lesion} functions, respectively.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted at MICCAI AMAI 2024 workshop"
    },
    {
        "paper id": "2407.17267",
        "abstract url": "https://arxiv.org/abs/2407.17267",
        "title": "M4: Multi-Proxy Multi-Gate Mixture of Experts Network for Multiple Instance Learning in Histopathology Image Analysis",
        "rating": "-1",
        "keywords": [
            [
                "biomarkers",
                "whole slide",
                "tumor",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multiple instance learning (MIL) has been successfully applied for whole slide images (WSIs) analysis in computational pathology, enabling a wide range of prediction tasks from tumor subtyping to inferring genetic mutations and multi-omics biomarkers. However, existing MIL methods predominantly focus on single-task learning, resulting in not only overall low efficiency but also the overlook of inter-task relatedness. To address these issues, we proposed an adapted architecture of Multi-gate Mixture-of-experts with Multi-proxy for Multiple instance learning (M4), and applied this framework for simultaneous prediction of multiple genetic mutations from WSIs. The proposed M4 model has two main innovations: (1) utilizing a mixture of experts with multiple gating strategies for multi-genetic mutation prediction on a single pathological slide; (2) constructing multi-proxy expert network and gate network for comprehensive and effective modeling of pathological image information. Our model achieved significant improvements across five tested TCGA datasets in comparison to current state-of-the-art single-task methods. The code is available at:https://github.com/Bigyehahaha/M4.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "25pages,5figures"
    },
    {
        "paper id": "2407.17273",
        "abstract url": "https://arxiv.org/abs/2407.17273",
        "title": "Component Matching as a Graph Matching Problem",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "The development of an IT strategy and ensuring that it is the best possible one for business is a key problem many organizations face. This problem is that of linking business architecture to IT architecture in general and application architecture specifically. In our earlier work we proposed Category theory as the formal language to unify the business and IT worlds with the ability to represent the concepts and relations between the two in a unified way. We used rCOS as the underlying model for the specification of interfaces, contracts, and components. The concept of pseudo-category was then utilized to represent the business and application architecture specifications and the relationships contained within. Contracts are used for the specification of both IT and Business architecture components. The linkages between them is now established using the matching of the business component contracts with the application component contracts. Typically, the matching was based on manual process, in this paper we extend the work by considering automated component matching process. In this paper we provide implementation of the matching process using graph matching.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "7 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:2406.05483"
    },
    {
        "paper id": "2407.17287",
        "abstract url": "https://arxiv.org/abs/2407.17287",
        "title": "Software Defined Vehicles for Development of Deterministic Services",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "With modern vehicles evolving with more features, services, complex systems, with more sensors, actuators, and processing units, it is essential to think about vehicles not only as means of transportation that may tend towards full autonomy, but also as adaptive objects, that suit themselves to the needs of occupants. Vehicular services can be developed to support these adaptations. However, the increasing complexity of vehicular service development, even with current standardizations and best practices and guidelines, are insufficient to tackle the high complexity of development, with expectations of up to 1 (U.S.) billion lines of code for a fully (level 5) autonomous vehicle. Within this survey, the paradigm of Deterministic Software Defined Vehicles is explored towards increasing the quality and easiness of the development of services for automotive. Towards this, a proposed vision with four pillars is also provided: the deterministic network configurator, the data layer configurator, and the hypervisor configurator and the vehicle abstraction layer, all coordinated by a software orchestrator.",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17319",
        "abstract url": "https://arxiv.org/abs/2407.17319",
        "title": "Exploring Commercial Vehicle Detouring Patterns through the Application of Probe Trajectory Data",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory",
                "Vehicle"
            ]
        ],
        "abstract": "Understanding motorist detouring behavior is critical for both traffic operations and planning applications. However, measuring real-world detouring behavior is challenging due to the need to track the movement of individual vehicles. Recent developments in high-resolution vehicle trajectory data have enabled transportation professionals to observe real-world detouring behaviors without the need to install and maintain hardware such as license plate reading cameras. This paper investigates the feasibility of vehicle probe trajectory data to capture commercial motor vehicle (CMV) detouring behavior under three unique case studies. Before doing so, a validation analysis was conducted to investigate the ability of CMV probe trajectory data to represent overall CMV volumes at well-calibrated count stations near virtual weigh stations (VWS) in Maryland. The validation analysis showed strong positive correlations (above 0.75) at all VWS stations. Upon validating the data, a methodology was applied to assess CMV detour behaviors associated with CMV enforcement activities, congestion avoidance, and incident induced temporary road closures.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "Presented at Transportation Research Board Annual Meeting 2024. Presentation number: TRBAM-24-02157"
    },
    {
        "paper id": "2407.17328",
        "abstract url": "https://arxiv.org/abs/2407.17328",
        "title": "DarSwin-Unet: Distortion Aware Encoder-Decoder Architecture",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Wide-angle fisheye images are becoming increasingly common for perception tasks in applications such as robotics, security, and mobility (e.g. drones, avionics). However, current models often either ignore the distortions in wide-angle images or are not suitable to perform pixel-level tasks. In this paper, we present an encoder-decoder model based on a radial transformer architecture that adapts to distortions in wide-angle lenses by leveraging the physical characteristics defined by the radial distortion profile. In contrast to the original model, which only performs classification tasks, we introduce a U-Net architecture, DarSwin-Unet, designed for pixel level tasks. Furthermore, we propose a novel strategy that minimizes sparsity when sampling the image for creating its input tokens. Our approach enhances the model capability to handle pixel-level tasks in wide-angle fisheye images, making it more effective for real-world applications. Compared to other baselines, DarSwin-Unet achieves the best results across different datasets, with significant gains when trained on bounded levels of distortions (very low, low, medium, and high) and tested on all, including out-of-distribution distortions. We demonstrate its performance on depth estimation and show through extensive experiments that DarSwin-Unet can perform zero-shot adaptation to unseen distortions of different wide-angle lenses.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17344",
        "abstract url": "https://arxiv.org/abs/2407.17344",
        "title": "Label Alignment and Reassignment with Generalist Large Language Model for Enhanced Cross-Domain Named Entity Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Named Entity Recognition"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Named entity recognition on the in-domain supervised and few-shot settings have been extensively discussed in the NLP community and made significant progress. However, cross-domain NER, a more common task in practical scenarios, still poses a challenge for most NER methods. Previous research efforts in that area primarily focus on knowledge transfer such as correlate label information from source to target domains but few works pay attention to the problem of label conflict. In this study, we introduce a label alignment and reassignment approach, namely LAR, to address this issue for enhanced cross-domain named entity recognition, which includes two core procedures: label alignment between source and target domains and label reassignment for type inference. The process of label reassignment can significantly be enhanced by integrating with an advanced large-scale language model such as ChatGPT. We conduct an extensive range of experiments on NER datasets involving both supervised and zero-shot scenarios. Empirical experimental results demonstrate the validation of our method with remarkable performance under the supervised and zero-shot out-of-domain settings compared to SOTA methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 pages, 4 figures"
    },
    {
        "paper id": "2407.17346",
        "abstract url": "https://arxiv.org/abs/2407.17346",
        "title": "Insider Threats Mitigation: Role of Penetration Testing",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Conventional security solutions are insufficient to address the urgent cybersecurity challenge posed by insider attacks. While a great deal of research has been done in this area, our systematic literature analysis attempts to give readers a thorough grasp of penetration testing's role in reducing insider risks. We aim to arrange and integrate the body of knowledge on insider threat prevention by using a grounded theory approach for a thorough literature review. This analysis classifies and evaluates the approaches used in penetration testing today, including how well they uncover and mitigate insider threats and how well they work in tandem with other security procedures. Additionally, we look at how penetration testing is used in different industries, present case studies with real-world implementations, and discuss the obstacles and constraints that businesses must overcome. This study aims to improve the knowledge of penetration testing as a critical part of insider threat defense, helping to create more comprehensive and successful security policies.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17361",
        "abstract url": "https://arxiv.org/abs/2407.17361",
        "title": "MuST: Multi-Scale Transformers for Surgical Phase Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Surgical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Phase recognition in surgical videos is crucial for enhancing computer-aided surgical systems as it enables automated understanding of sequential procedural stages. Existing methods often rely on fixed temporal windows for video analysis to identify dynamic surgical phases. Thus, they struggle to simultaneously capture short-, mid-, and long-term information necessary to fully understand complex surgical procedures. To address these issues, we propose Multi-Scale Transformers for Surgical Phase Recognition (MuST), a novel Transformer-based approach that combines a Multi-Term Frame encoder with a Temporal Consistency Module to capture information across multiple temporal scales of a surgical video. Our Multi-Term Frame Encoder computes interdependencies across a hierarchy of temporal scales by sampling sequences at increasing strides around the frame of interest. Furthermore, we employ a long-term Transformer encoder over the frame embeddings to further enhance long-term reasoning. MuST achieves higher performance than previous state-of-the-art methods on three different public benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17376",
        "abstract url": "https://arxiv.org/abs/2407.17376",
        "title": "Distance Reconstruction of Sparse Random Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "In the distance query model, we are given access to the vertex set of a $n$-vertex graph $G$, and an oracle that takes as input two vertices and returns the distance between these two vertices in $G$. We study how many queries are needed to reconstruct the edge set of $G$ when $G$ is sampled according to the $G(n,p)$ Erd\u0151s-Renyi-Gilbert distribution. Our approach applies to a large spectrum of values for $p$ starting slightly above the connectivity threshold: $p \\geq \\frac{2000 \\log n}{n}$. We show that there exists an algorithm that reconstructs $G \\sim G(n,p)$ using $O( \u0394^2 n \\log n )$ queries in expectation, where $\u0394$ is the expected average degree of $G$. In particular, for $p \\in [\\frac{2000 \\log n}{n}, \\frac{\\log^2 n}{n}]$ the algorithm uses $O(n \\log^5 n)$ queries.",
        "subjects": [
            "math.CO",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17378",
        "abstract url": "https://arxiv.org/abs/2407.17378",
        "title": "PrevPredMap: Exploring Temporal Modeling with Previous Predictions for Online Vectorized HD Map Construction",
        "rating": "-1",
        "keywords": [
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Temporal information is crucial for detecting occluded instances. Existing temporal representations have progressed from BEV or PV features to more compact query features. Compared to these aforementioned features, predictions offer the highest level of abstraction, providing explicit information. In the context of online vectorized HD map construction, this unique characteristic of predictions is potentially advantageous for long-term temporal modeling and the integration of map priors. This paper introduces PrevPredMap, a pioneering temporal modeling framework that leverages previous predictions for constructing online vectorized HD maps. We have meticulously crafted two essential modules for PrevPredMap: the previous-predictions-based query generator and the dynamic-position-query decoder. Specifically, the previous-predictions-based query generator is designed to separately encode different types of information from previous predictions, which are then effectively utilized by the dynamic-position-query decoder to generate current predictions. Furthermore, we have developed a dual-mode strategy to ensure PrevPredMap's robust performance across both single-frame and temporal modes. Extensive experiments demonstrate that PrevPredMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets. Code will be available at https://github.com/pnnnnnnn/PrevPredMap.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17438",
        "abstract url": "https://arxiv.org/abs/2407.17438",
        "title": "HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "avatar"
            ],
            [
                "trajectory",
                "SLAM"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Human image animation involves generating videos from a character photo, allowing user control and unlocking potential for video and movie production. While recent approaches yield impressive results using high-quality training data, the inaccessibility of these datasets hampers fair and transparent benchmarking. Moreover, these approaches prioritize 2D human motion and overlook the significance of camera motions in videos, leading to limited control and unstable video generation. To demystify the training data, we present HumanVid, the first large-scale high-quality dataset tailored for human image animation, which combines crafted real-world and synthetic data. For the real-world data, we compile a vast collection of copyright-free real-world videos from the internet. Through a carefully designed rule-based filtering strategy, we ensure the inclusion of high-quality videos, resulting in a collection of 20K human-centric videos in 1080P resolution. Human and camera motion annotation is accomplished using a 2D pose estimator and a SLAM-based method. For the synthetic data, we gather 2,300 copyright-free 3D avatar assets to augment existing available 3D assets. Notably, we introduce a rule-based camera trajectory generation method, enabling the synthetic pipeline to incorporate diverse and precise camera motion annotation, which can rarely be found in real-world data. To verify the effectiveness of HumanVid, we establish a baseline model named CamAnimate, short for Camera-controllable Human Animation, that considers both human and camera motions as conditions. Through extensive experimentation, we demonstrate that such simple baseline training on our HumanVid achieves state-of-the-art performance in controlling both human pose and camera motions, setting a new benchmark. Code and data will be publicly available at https://github.com/zhenzhiwang/HumanVid/.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "camera controllable human image animation, a dataset and a baseline"
    },
    {
        "paper id": "2407.17470",
        "abstract url": "https://arxiv.org/abs/2407.17470",
        "title": "SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation. Unlike previous methods that rely on separately trained generative models for video generation and novel view synthesis, we design a unified diffusion model to generate novel view videos of dynamic 3D objects. Specifically, given a monocular reference video, SV4D generates novel views for each video frame that are temporally consistent. We then use the generated novel view videos to optimize an implicit 4D representation (dynamic NeRF) efficiently, without the need for cumbersome SDS-based optimization used in most prior works. To train our unified novel view video generation model, we curated a dynamic 3D object dataset from the existing Objaverse dataset. Extensive experimental results on multiple datasets and user studies demonstrate SV4D's state-of-the-art performance on novel-view video synthesis as well as 4D generation compared to prior works.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://sv4d.github.io/"
    },
    {
        "paper id": "2407.17619",
        "abstract url": "https://arxiv.org/abs/2407.17619",
        "title": "The Power of Graph Sparsification in the Continual Release Model",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "The graph continual release model of differential privacy seeks to produce differentially private solutions to graph problems under a stream of updates where new private solutions are released after each update. Streaming graph algorithms in the non-private literature also produce (approximately) accurate solutions when provided updates in a stream, but they additionally try to achieve two other goals: 1) output vertex or edge subsets as approximate solutions to the problem (not just real-valued estimates) and 2) use space that is sublinear in the number of edges or the number of vertices. Thus far, all previously known edge-differentially private algorithms for graph problems in the continual release setting do not meet the above benchmarks. Instead, they require computing exact graph statistics on the input [SLMVC18, FHO21, JSW24]. In this paper, we leverage sparsification to address the above shortcomings. Our edge-differentially private algorithms use sublinear space with respect to the number of edges in the graph while some also achieve sublinear space in the number of vertices in the graph. In addition, for most of our problems, we also output differentially private vertex subsets. We make novel use of assorted sparsification techniques from the non-private streaming and static graph algorithms literature and achieve new results in the sublinear space, continual release setting for a variety of problems including densest subgraph, $k$-core decomposition, maximum matching, and vertex cover. In addition to our edge-differential privacy results, we use graph sparsification based on arboricity to obtain a set of results in the node-differential privacy setting, illustrating a new connection between sparsification and privacy beyond minimizing space. We conclude with polynomial additive error lower bounds for edge-privacy in the fully dynamic setting.",
        "subjects": [
            "cs.DS",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17620",
        "abstract url": "https://arxiv.org/abs/2407.17620",
        "title": "CoMoTo: Unpaired Cross-Modal Lesion Distillation Improves Breast Lesion Detection in Tomosynthesis",
        "rating": "-1",
        "keywords": [
            [
                "Lesion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Digital Breast Tomosynthesis (DBT) is an advanced breast imaging modality that offers superior lesion detection accuracy compared to conventional mammography, albeit at the trade-off of longer reading time. Accelerating lesion detection from DBT using deep learning is hindered by limited data availability and huge annotation costs. A possible solution to this issue could be to leverage the information provided by a more widely available modality, such as mammography, to enhance DBT lesion detection. In this paper, we present a novel framework, CoMoTo, for improving lesion detection in DBT. Our framework leverages unpaired mammography data to enhance the training of a DBT model, improving practicality by eliminating the need for mammography during inference. Specifically, we propose two novel components, Lesion-specific Knowledge Distillation (LsKD) and Intra-modal Point Alignment (ImPA). LsKD selectively distills lesion features from a mammography teacher model to a DBT student model, disregarding background features. ImPA further enriches LsKD by ensuring the alignment of lesion features within the teacher before distilling knowledge to the student. Our comprehensive evaluation shows that CoMoTo is superior to traditional pretraining and image-level KD, improving performance by 7% Mean Sensitivity under low-data setting. Our code is available at https://github.com/Muhammad-Al-Barbary/CoMoTo .",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "ADSMI @ MICCAI 2024"
    },
    {
        "paper id": "2407.17624",
        "abstract url": "https://arxiv.org/abs/2407.17624",
        "title": "Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings",
        "rating": "-1",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have been shown to perform well for many downstream tasks. Transfer learning can enable LLMs to acquire skills that were not targeted during pre-training. In financial contexts, LLMs can sometimes beat well-established benchmarks. This paper investigates how well LLMs perform in the task of forecasting corporate credit ratings. We show that while LLMs are very good at encoding textual information, traditional methods are still very competitive when it comes to encoding numeric and multimodal data. For our task, current LLMs perform worse than a more traditional XGBoost architecture that combines fundamental and macroeconomic data with high-density text-based embedding features.",
        "subjects": [
            "q-fin.RM",
            "cs.CL",
            "q-fin.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17636",
        "abstract url": "https://arxiv.org/abs/2407.17636",
        "title": "IgnitionInnovators at \"Discharge Me!\": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents our proposed approach to the Discharge Me! shared task, collocated with the 23th Workshop on Biomedical Natural Language Processing (BioNLP). In this work, we develop an LLM-based framework for solving the Discharge Summary Documentation (DSD) task, i.e., generating the two critical target sections `Brief Hospital Course' and `Discharge Instructions' in the discharge summary. By streamlining the recent instruction-finetuning process on LLMs, we explore several prompting strategies for optimally adapting LLMs to specific generation task of DSD. Experimental results show that providing a clear output structure, complimented by a set of comprehensive Chain-of-Thoughts (CoT) questions, effectively improves the model's reasoning capability, and thereby, enhancing the structural correctness and faithfulness of clinical information in the generated text. Source code is available at: https://github.com/antangrocket1312/Discharge_LLM",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by BioNLP2024 Workshop"
    },
    {
        "paper id": "2407.17638",
        "abstract url": "https://arxiv.org/abs/2407.17638",
        "title": "Time Matters: Examine Temporal Effects on Biomedical Language Models",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Time roots in applying language models for biomedical applications: models are trained on historical data and will be deployed for new or future data, which may vary from training data. While increasing biomedical tasks have employed state-of-the-art language models, there are very few studies have examined temporal effects on biomedical models when data usually shifts across development and deployment. This study fills the gap by statistically probing relations between language model performance and data shifts across three biomedical tasks. We deploy diverse metrics to evaluate model performance, distance methods to measure data drifts, and statistical methods to quantify temporal effects on biomedical language models. Our study shows that time matters for deploying biomedical language models, while the degree of performance degradation varies by biomedical tasks and statistical quantification approaches. We believe this study can establish a solid benchmark to evaluate and assess temporal effects on deploying biomedical language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accept to AMIA 2024 Annual Symposium"
    },
    {
        "paper id": "2407.17651",
        "abstract url": "https://arxiv.org/abs/2407.17651",
        "title": "PARS3: Parallel Sparse Skew-Symmetric Matrix-Vector Multiplication with Reverse Cuthill-McKee Reordering",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Sparse matrices, as prevalent primitive of various scientific computing algorithms, persist as a bottleneck in processing. A skew-symmetric matrix flips signs of symmetric pairs in a symmetric matrix. Our work, Parallel 3-Way Banded Skew-Symmetric Sparse Matrix-Vector Multiplication, equally improves parallel symmetric SpMV kernels with a different perspective than the common literature trends, by manipulating the form of matrix in a preprocessing step to accelerate the repeated computations of iterative solvers. We effectively use Reverse Cuthill-McKee (RCM) reordering algorithm to transform a sparse skew-symmetrix matrix into a band matrix, then efficiently parallelize it by splitting the band structure into 3 different parts by considering its local sparsity. Our proposed method with RCM is novel in the sense that it is the first implementation of parallel skew-symmetric SpMV kernels. Our enhancements in SpMV and findings are valuable with significant strong scalings of up to 19x over the serial compressed SpMV implementation. We overperform a heuristic-based graph-coloring approach with synchronization phases in implementing parallel symmetric SpMVs. Our approach also naturally applies to parallel sparse symmetric SpMVs, that can inspire widespread SpMV solutions to adapt presented optimizations in this paper.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17657",
        "abstract url": "https://arxiv.org/abs/2407.17657",
        "title": "My Ontologist: Evaluating BFO-Based AI for Definition Support",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Generative artificial intelligence (AI), exemplified by the release of GPT-3.5 in 2022, has significantly advanced the potential applications of large language models (LLMs), including in the realms of ontology development and knowledge graph creation. Ontologies, which are structured frameworks for organizing information, and knowledge graphs, which combine ontologies with actual data, are essential for enabling interoperability and automated reasoning. However, current research has largely overlooked the generation of ontologies extending from established upper-level frameworks like the Basic Formal Ontology (BFO), risking the creation of non-integrable ontology silos. This study explores the extent to which LLMs, particularly GPT-4, can support ontologists trained in BFO. Through iterative development of a specialized GPT model named \"My Ontologist,\" we aimed to generate BFO-conformant ontologies. Initial versions faced challenges in maintaining definition conventions and leveraging foundational texts effectively. My Ontologist 3.0 showed promise by adhering to structured rules and modular ontology suites, yet the release of GPT-4o disrupted this progress by altering the model's behavior. Our findings underscore the importance of aligning LLM-generated ontologies with top-level standards and highlight the complexities of integrating evolving AI capabilities in ontology engineering.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17683",
        "abstract url": "https://arxiv.org/abs/2407.17683",
        "title": "RL-augmented MPC Framework for Agile and Robust Bipedal Footstep Locomotion Planning and Control",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper proposes an online bipedal footstep planning strategy that combines model predictive control (MPC) and reinforcement learning (RL) to achieve agile and robust bipedal maneuvers. While MPC-based foot placement controllers have demonstrated their effectiveness in achieving dynamic locomotion, their performance is often limited by the use of simplified models and assumptions. To address this challenge, we develop a novel foot placement controller that leverages a learned policy to bridge the gap between the use of a simplified model and the more complex full-order robot system. Specifically, our approach employs a unique combination of an ALIP-based MPC foot placement controller for sub-optimal footstep planning and the learned policy for refining footstep adjustments, enabling the resulting footstep policy to capture the robot's whole-body dynamics effectively. This integration synergizes the predictive capability of MPC with the flexibility and adaptability of RL. We validate the effectiveness of our framework through a series of experiments using the full-body humanoid robot DRACO 3. The results demonstrate significant improvements in dynamic locomotion performance, including better tracking of a wide range of walking speeds, enabling reliable turning and traversing challenging terrains while preserving the robustness and stability of the walking gaits compared to the baseline ALIP-based MPC approach.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2407.17689",
        "abstract url": "https://arxiv.org/abs/2407.17689",
        "title": "SAM-MIL: A Spatial Contextual Aware Multiple Instance Learning Approach for Whole Slide Image Classification",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "Whole Slide",
                "Cancer"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multiple Instance Learning (MIL) represents the predominant framework in Whole Slide Image (WSI) classification, covering aspects such as sub-typing, diagnosis, and beyond. Current MIL models predominantly rely on instance-level features derived from pretrained models such as ResNet. These models segment each WSI into independent patches and extract features from these local patches, leading to a significant loss of global spatial context and restricting the model's focus to merely local features. To address this issue, we propose a novel MIL framework, named SAM-MIL, that emphasizes spatial contextual awareness and explicitly incorporates spatial context by extracting comprehensive, image-level information. The Segment Anything Model (SAM) represents a pioneering visual segmentation foundational model that can capture segmentation features without the need for additional fine-tuning, rendering it an outstanding tool for extracting spatial context directly from raw WSIs. Our approach includes the design of group feature extraction based on spatial context and a SAM-Guided Group Masking strategy to mitigate class imbalance issues. We implement a dynamic mask ratio for different segmentation categories and supplement these with representative group features of categories. Moreover, SAM-MIL divides instances to generate additional pseudo-bags, thereby augmenting the training set, and introduces consistency of spatial context across pseudo-bags to further enhance the model's performance. Experimental results on the CAMELYON-16 and TCGA Lung Cancer datasets demonstrate that our proposed SAM-MIL model outperforms existing mainstream methods in WSIs classification. Our open-source implementation code is is available at https://github.com/FangHeng/SAM-MIL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by ACM Multimedia 2024"
    },
    {
        "paper id": "2407.17705",
        "abstract url": "https://arxiv.org/abs/2407.17705",
        "title": "ALMRR: Anomaly Localization Mamba on Industrial Textured Surface with Feature Reconstruction and Refinement",
        "rating": "-1",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised anomaly localization on industrial textured images has achieved remarkable results through reconstruction-based methods, yet existing approaches based on image reconstruction and feature reconstruc-tion each have their own shortcomings. Firstly, image-based methods tend to reconstruct both normal and anomalous regions well, which lead to over-generalization. Feature-based methods contain a large amount of distin-guishable semantic information, however, its feature structure is redundant and lacks anomalous information, which leads to significant reconstruction errors. In this paper, we propose an Anomaly Localization method based on Mamba with Feature Reconstruction and Refinement(ALMRR) which re-constructs semantic features based on Mamba and then refines them through a feature refinement module. To equip the model with prior knowledge of anomalies, we enhance it by adding artificially simulated anomalies to the original images. Unlike image reconstruction or repair, the features of synthesized defects are repaired along with those of normal areas. Finally, the aligned features containing rich semantic information are fed in-to the refinement module to obtain the anomaly map. Extensive experiments have been conducted on the MVTec-AD-Textured dataset and other real-world industrial dataset, which has demonstrated superior performance com-pared to state-of-the-art (SOTA) methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17726",
        "abstract url": "https://arxiv.org/abs/2407.17726",
        "title": "Multi-modal Data Binding for Survival Analysis Modeling with Incomplete Data and Annotations",
        "rating": "-1",
        "keywords": [
            [
                "Survival",
                "cancer"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Survival analysis stands as a pivotal process in cancer treatment research, crucial for predicting patient survival rates accurately. Recent advancements in data collection techniques have paved the way for enhancing survival predictions by integrating information from multiple modalities. However, real-world scenarios often present challenges with incomplete data, particularly when dealing with censored survival labels. Prior works have addressed missing modalities but have overlooked incomplete labels, which can introduce bias and limit model efficacy. To bridge this gap, we introduce a novel framework that simultaneously handles incomplete data across modalities and censored survival labels. Our approach employs advanced foundation models to encode individual modalities and align them into a universal representation space for seamless fusion. By generating pseudo labels and incorporating uncertainty, we significantly enhance predictive accuracy. The proposed method demonstrates outstanding prediction accuracy in two survival analysis tasks on both employed datasets. This innovative approach overcomes limitations associated with disparate modalities and improves the feasibility of comprehensive survival analysis using multiple large foundation models.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted by MICCAI 2024"
    },
    {
        "paper id": "2407.17727",
        "abstract url": "https://arxiv.org/abs/2407.17727",
        "title": "Distributed Memory Approximate Message Passing",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Approximate message passing (AMP) algorithms are iterative methods for signal recovery in noisy linear systems. In some scenarios, AMP algorithms need to operate within a distributed network. To address this challenge, the distributed extensions of AMP (D-AMP, FD-AMP) and orthogonal/vector AMP (D-OAMP/D-VAMP) were proposed, but they still inherit the limitations of centralized algorithms. In this letter, we propose distributed memory AMP (D-MAMP) to overcome the IID matrix limitation of D-AMP/FD-AMP, as well as the high complexity and heavy communication cost of D-OAMP/D-VAMP. We introduce a matrix-by-vector variant of MAMP tailored for distributed computing. Leveraging this variant, D-MAMP enables each node to execute computations utilizing locally available observation vectors and transform matrices. Meanwhile, global summations of locally updated results are conducted through message interaction among nodes. For acyclic graphs, D-MAMP converges to the same mean square error performance as the centralized MAMP.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to the IEEE Journal"
    },
    {
        "paper id": "2407.17730",
        "abstract url": "https://arxiv.org/abs/2407.17730",
        "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In contemporary society, the issue of psychological health has become increasingly prominent, characterized by the diversification, complexity, and universality of mental disorders. Cognitive Behavioral Therapy (CBT), currently the most influential and clinically effective psychological treatment method with no side effects, has limited coverage and poor quality in most countries. In recent years, researches on the recognition and intervention of emotional disorders using large language models (LLMs) have been validated, providing new possibilities for psychological assistance therapy. However, are LLMs truly possible to conduct cognitive behavioral therapy? Many concerns have been raised by mental health experts regarding the use of LLMs for therapy. Seeking to answer this question, we collected real CBT corpus from online video websites, designed and conducted a targeted automatic evaluation framework involving the evaluation of emotion tendency of generated text, structured dialogue pattern and proactive inquiry ability. For emotion tendency, we calculate the emotion tendency score of the CBT dialogue text generated by each model. For structured dialogue pattern, we use a diverse range of automatic evaluation metrics to compare speaking style, the ability to maintain consistency of topic and the use of technology in CBT between different models . As for inquiring to guide the patient, we utilize PQA (Proactive Questioning Ability) metric. We also evaluated the CBT ability of the LLM after integrating a CBT knowledge base to explore the help of introducing additional knowledge to enhance the model's CBT counseling ability. Four LLM variants with excellent performance on natural language processing are evaluated, and the experimental result shows the great potential of LLMs in psychological counseling realm, especially after combining with other technological means.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17737",
        "abstract url": "https://arxiv.org/abs/2407.17737",
        "title": "Control Informed Design of the IAC Autonomous Racecar for Operation at the Dynamic Envelope",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ]
        ],
        "abstract": "This article introduces the hardware-software co-design of the control system for an autonomy-enabled formula-style high-speed racecar that will be utilized as the deployment platform for high-level autonomy in the first ever head-to-head driverless race called the Indy Autonomous Challenge. The embedded control system needs to facilitate autonomous functionality, including perception, localization, and by-wire actuation, at high speeds and dynamic limits of the vehicle. Rapid maneuvering during the race, however, excites transient dynamics of the vehicle and the actuators. Compared to current autonomous driving focused on highway cruising and urban traffic, transient vehicle control imposes new challenges to the algorithm and system design. The presented work introduces the cascaded control structure employed by the IAC prototype to fully exploit the time scale separation between different control tasks. It is demonstrated by example way how the model-based control strategies and simulation are utilized to inform the decisions in the actuation, computation, perception, and software pipeline design decisions for the first-of-its-kind IAC racecar.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 6 figures, 2021 IEEE International Conference on Robotics and Automation, Workshop on Opportunities and Challenges with Autonomous Racing"
    },
    {
        "paper id": "2407.17745",
        "abstract url": "https://arxiv.org/abs/2407.17745",
        "title": "Beyond Entity Alignment: Towards Complete Knowledge Graph Alignment via Entity-Relation Synergy",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge Graph Alignment (KGA) aims to integrate knowledge from multiple sources to address the limitations of individual Knowledge Graphs (KGs) in terms of coverage and depth. However, current KGA models fall short in achieving a ``complete'' knowledge graph alignment. Existing models primarily emphasize the linkage of cross-graph entities but overlook aligning relations across KGs, thereby providing only a partial solution to KGA. The semantic correlations embedded in relations are largely overlooked, potentially restricting a comprehensive understanding of cross-KG signals. In this paper, we propose to conceptualize relation alignment as an independent task and conduct KGA by decomposing it into two distinct but highly correlated sub-tasks: entity alignment and relation alignment. To capture the mutually reinforcing correlations between these objectives, we propose a novel Expectation-Maximization-based model, EREM, which iteratively optimizes both sub-tasks. Experimental results on real-world datasets demonstrate that EREM consistently outperforms state-of-the-art models in both entity alignment and relation alignment tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17755",
        "abstract url": "https://arxiv.org/abs/2407.17755",
        "title": "Enhancing Eye Disease Diagnosis with Deep Learning and Synthetic Data Augmentation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "Disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the focus is on improving the diagnosis of diabetic retinopathy (DR) using machine learning and deep learning technologies. Researchers have explored various approaches, including the use of high-definition medical imaging, AI-driven algorithms such as convolutional neural networks (CNNs) and generative adversarial networks (GANs). Among all the available tools, CNNs have emerged as a preferred tool due to their superior classification accuracy and efficiency. Although the accuracy of CNNs is comparatively better but it can be improved by introducing some hybrid models by combining various machine learning and deep learning models. Therefore, in this paper, an ensemble learning technique is proposed for early detection and management of DR with higher accuracy. The proposed model is tested on the APTOS dataset and it is showing supremacy on the validation accuracy ($99\\%)$ in comparison to the previous models. Hence, the model can be helpful for early detection and treatment of the DR, thereby enhancing the overall quality of care for affected individuals.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 7 figures, 2 Tables"
    },
    {
        "paper id": "2407.17761",
        "abstract url": "https://arxiv.org/abs/2407.17761",
        "title": "Towards the Blockchain Massive Adoption with Permissionless Storage",
        "rating": "-1",
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "Blockchain technology emerged with the advent of Bitcoin and rapidly developed over the past few decades, becoming widely accepted and known by the public. However, in the past decades, the massive adoption of blockchain technology has yet to come. Rather than the scalability issue, the blockchain application is challenged by its expensive usage cost. However, the high cost of blockchain usage is deeply connected with the blockchain consensus and security mechanism. The permissionless blockchain must maintain its high cost for security against the 51% Attack. Chain users indirectly cover the cost as coins are appointed for blockchain usage fees. This conflict prevents the massive adoption of blockchain. Thus, blockchain must be improved to solve those problems: 1. The cost of blockchain usage should be low enough. 2. The blockchain should remain decentralized. 3. The scalability of blockchain must meet the demand. In my thesis, new approaches are applied to solve the issues above. The key contribution is the discovery of the useful PoW. It extends the Nakamoto PoW with another usage of file data encoding during the same Nakamoto Consensus computation to prove honest data preservation. Based on this theory, a permissionless storage network is proposed as the new security engine for the blockchain. It bridges the high blockchain security cost to the storage users with real demands who are willing to pay for the storage resource. On the other hand, the chain users can benefit from the low transaction fee. Meanwhile, we also provide a scalability solution to shard the blockchain. It enables high TPS and keeps decentralization. The solutions in this thesis provide the answers to all the dependencies of the massive adoption.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17766",
        "abstract url": "https://arxiv.org/abs/2407.17766",
        "title": "Strategic Pseudo-Goal Perturbation for Deadlock-Free Multi-Agent Navigation in Social Mini-Games",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "This work introduces a Strategic Pseudo-Goal Perturbation (SPGP) technique, a novel approach to resolve deadlock situations in multi-agent navigation scenarios. Leveraging the robust framework of Safety Barrier Certificates, our method integrates a strategic perturbation mechanism that guides agents through social mini-games where deadlock and collision occur frequently. The method adopts a strategic calculation process where agents, upon encountering a deadlock select a pseudo goal within a predefined radius around the current position to resolve the deadlock among agents. The calculation is based on controlled strategic algorithm, ensuring that deviation towards pseudo-goal is both purposeful and effective in resolution of deadlock. Once the agent reaches the pseudo goal, it resumes the path towards the original goal, thereby enhancing navigational efficiency and safety. Experimental results demonstrates SPGP's efficacy in reducing deadlock instances and improving overall system throughput in variety of multi-agent navigation scenarios.",
        "subjects": [
            "cs.MA",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.18986",
        "abstract url": "https://arxiv.org/abs/2407.18986",
        "title": "TERIME: An improved RIME algorithm with enhanced exploration and exploitation for robust parameter extraction of photovoltaic models",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "Parameter extraction of photovoltaic (PV) models is crucial for the planning, optimization, and control of PV systems. Although some methods using meta-heuristic algorithms have been proposed to determine these parameters, the robustness of solutions obtained by these methods faces great challenges when the complexity of the PV model increases. The unstable results will affect the reliable operation and maintenance strategies of PV systems. In response to this challenge, an improved RIME algorithm with enhanced exploration and exploitation is proposed for robust and accurate parameter identification for various PV models. Specifically, the differential evolution mutation operator is integrated in the exploration phase to enhance the population diversity. Meanwhile, a new exploitation strategy incorporating randomization and neighborhood strategies simultaneously is developed to maintain the balance of exploitation width and depth. The improved RIME algorithm is applied to estimate the optimal parameters of the single-diode model (SDM), double-diode model (DDM), and triple-diode model (TDM) combined with the Lambert-W function for three PV cell and module types including RTC France, Photo Watt-PWP 201 and S75. According to the statistical analysis in 100 runs, the TEIMRE achieves more accurate and robust parameter estimations than other techniques to various PV models in varying environmental conditions. All of our source codes are publicly available at https://github.com/dirge1/TERIME.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21054",
        "abstract url": "https://arxiv.org/abs/2407.21054",
        "title": "Sentiment Reasoning for Healthcare",
        "rating": "-1",
        "keywords": [
            [
                "Healthcare"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Transparency in AI decision-making is crucial in healthcare due to the severe consequences of errors, and this is important for building trust among AI and users in sentiment analysis task. Incorporating reasoning capabilities helps Large Language Models (LLMs) understand human emotions within broader contexts, handle nuanced and ambiguous language, and infer underlying sentiments that may not be explicitly stated. In this work, we introduce a new task - Sentiment Reasoning - for both speech and text modalities, along with our proposed multimodal multitask framework and dataset. Our study showed that rationale-augmented training enhances model performance in sentiment classification across both human transcript and ASR settings. Also, we found that the generated rationales typically exhibit different vocabularies compared to human-generated rationales, but maintain similar semantics. All code, data (English-translated and Vietnamese) and models are published online: https://github.com/leduckhai/MultiMed",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Preprint, 18 pages"
    },
    {
        "paper id": "2407.21055",
        "abstract url": "https://arxiv.org/abs/2407.21055",
        "title": "Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have exhibited remarkable proficiency in natural language understanding, prompting extensive exploration of their potential applications across diverse domains. In the medical domain, open-source LLMs have demonstrated moderate efficacy following domain-specific fine-tuning; however, they remain substantially inferior to proprietary models such as GPT-4 and GPT-3.5. These open-source models encounter limitations in the comprehensiveness of domain-specific knowledge and exhibit a propensity for 'hallucinations' during text generation. To mitigate these issues, researchers have implemented the Retrieval-Augmented Generation (RAG) approach, which augments LLMs with background information from external knowledge bases while preserving the model's internal parameters. However, document noise can adversely affect performance, and the application of RAG in the medical field remains in its nascent stages. This study presents the Bailicai framework: a novel integration of retrieval-augmented generation with large language models optimized for the medical domain. The Bailicai framework augments the performance of LLMs in medicine through the implementation of four sub-modules. Experimental results demonstrate that the Bailicai approach surpasses existing medical domain LLMs across multiple medical benchmarks and exceeds the performance of GPT-3.5. Furthermore, the Bailicai method effectively attenuates the prevalent issue of hallucinations in medical applications of LLMs and ameliorates the noise-related challenges associated with traditional RAG techniques when processing irrelevant or pseudo-relevant documents.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21057",
        "abstract url": "https://arxiv.org/abs/2407.21057",
        "title": "Multi-group Uncertainty Quantification for Long-form Text Generation",
        "rating": "-1",
        "keywords": [
            [
                "biography"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "While large language models are rapidly moving towards consumer-facing applications, they are often still prone to factual errors and hallucinations. In order to reduce the potential harms that may come from these errors, it is important for users to know to what extent they can trust an LLM when it makes a factual claim. To this end, we study the problem of uncertainty quantification of factual correctness in long-form natural language generation. Given some output from a large language model, we study both uncertainty at the level of individual claims contained within the output (via calibration) and uncertainty across the entire output itself (via conformal prediction). Moreover, we invoke multicalibration and multivalid conformal prediction to ensure that such uncertainty guarantees are valid both marginally and across distinct groups of prompts. Using the task of biography generation, we demonstrate empirically that having access to and making use of additional group attributes for each prompt improves both overall and group-wise performance. As the problems of calibration, conformal prediction, and their multi-group counterparts have not been extensively explored previously in the context of long-form text generation, we consider these empirical results to form a benchmark for this setting.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.16890",
        "abstract url": "https://arxiv.org/abs/2407.16890",
        "title": "Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence",
        "rating": "-1.5",
        "keywords": [
            [
                "drone"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "In this essay, I argue that explicit ethical machines, whose moral principles are inferred through a bottom-up approach, are unable to replicate human-like moral reasoning and cannot be considered moral agents. By utilizing Alan Turing's theory of computation, I demonstrate that moral reasoning is computationally intractable by these machines due to the halting problem. I address the frontiers of machine ethics by formalizing moral problems into 'algorithmic moral questions' and by exploring moral psychology's dual-process model. While the nature of Turing Machines theoretically allows artificial agents to engage in recursive moral reasoning, critical limitations are introduced by the halting problem, which states that it is impossible to predict with certainty whether a computational process will halt. A thought experiment involving a military drone illustrates this issue, showing that an artificial agent might fail to decide between actions due to the halting problem, which limits the agent's ability to make decisions in all instances, undermining its moral agency.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17021",
        "abstract url": "https://arxiv.org/abs/2407.17021",
        "title": "The EU-US Data Privacy Framework: Is the Dragon Eating its Own Tail?",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "healthcare"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The European Commission adequacy decision on the EU US Data Privacy Framework, adopted on July 10th, 2023, marks a crucial moment in transatlantic data protection. Following an Executive Order issued by President Biden in October 2022, this decision confirms that the United States meets European Union standards for personal data protection. The decision extends to all transfers from the European Economic Area to US entities participating in the framework, promoting privacy rights while facilitating data exchange. Key aspects include oversight of US public authorities access to transferred data, the introduction of a dual tier redress mechanism, and granting new rights to EU individuals, encompassing data access and rectification. However, the framework presents both promise and challenges in health data transfers. While streamlining exchange and aligning legal standards, it grapples with the complexities of divergent privacy laws. The recent bill for the introduction of a US federal privacy law emphasizes the urgent need for ongoing reform. Lingering concerns persist regarding the framework resilience, especially amid potential legal battles before the Court of Justice of the EU. The history of transatlantic data transfers between the EU and the US is riddled with vulnerabilities, reminiscent of the Ouroboros, an ancient symbol of a serpent or dragon eating its own tail, hinting at the looming possibility of the framework facing invalidation once again. This article delves into the main requirements of the framework and offers insights on how healthcare organizations can navigate it effectively.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17117",
        "abstract url": "https://arxiv.org/abs/2407.17117",
        "title": "EverAdapt: Continuous Adaptation for Dynamic Machine Fault Diagnosis Environments",
        "rating": "-1.5",
        "keywords": [
            [
                "Diagnosis"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised Domain Adaptation (UDA) has emerged as a key solution in data-driven fault diagnosis, addressing domain shift where models underperform in changing environments. However, under the realm of continually changing environments, UDA tends to underperform on previously seen domains when adapting to new ones - a problem known as catastrophic forgetting. To address this limitation, we introduce the EverAdapt framework, specifically designed for continuous model adaptation in dynamic environments. Central to EverAdapt is a novel Continual Batch Normalization (CBN), which leverages source domain statistics as a reference point to standardize feature representations across domains. EverAdapt not only retains statistical information from previous domains but also adapts effectively to new scenarios. Complementing CBN, we design a class-conditional domain alignment module for effective integration of target domains, and a Sample-efficient Replay strategy to reinforce memory retention. Experiments on real-world datasets demonstrate EverAdapt superiority in maintaining robust fault diagnosis in dynamic environments. Our code is available: https://github.com/mohamedr002/EverAdapt",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17129",
        "abstract url": "https://arxiv.org/abs/2407.17129",
        "title": "Mapping the individual, social, and biospheric impacts of Foundation Models",
        "rating": "-1.5",
        "keywords": [
            [
                "biospheric"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Responding to the rapid roll-out and large-scale commercialization of foundation models, large language models, and generative AI, an emerging body of work is shedding light on the myriad impacts these technologies are having across society. Such research is expansive, ranging from the production of discriminatory, fake and toxic outputs, and privacy and copyright violations, to the unjust extraction of labor and natural resources. The same has not been the case in some of the most prominent AI governance initiatives in the global north like the UK's AI Safety Summit and the G7's Hiroshima process, which have influenced much of the international dialogue around AI governance. Despite the wealth of cautionary tales and evidence of algorithmic harm, there has been an ongoing over-emphasis within the AI governance discourse on technical matters of safety and global catastrophic or existential risks. This narrowed focus has tended to draw attention away from very pressing social and ethical challenges posed by the current brute-force industrialization of AI applications. To address such a visibility gap between real-world consequences and speculative risks, this paper offers a critical framework to account for the social, political, and environmental dimensions of foundation models and generative AI. We identify 14 categories of risks and harms and map them according to their individual, social, and biospheric impacts. We argue that this novel typology offers an integrative perspective to address the most urgent negative impacts of foundation models and their downstream applications. We conclude with recommendations on how this typology could be used to inform technical and normative interventions to advance responsible AI.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "ACM Conference on Fairness, Accountability, and Transparency (FAccT '24). Association for Computing Machinery, New York, NY, USA, 776-796"
    },
    {
        "paper id": "2407.17164",
        "abstract url": "https://arxiv.org/abs/2407.17164",
        "title": "Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "health",
                "diagnosing"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Integrating deep neural networks with the Hawkes process has significantly improved predictive capabilities in finance, health informatics, and information technology. Nevertheless, these models often face challenges in real-world settings, particularly due to substantial label noise. This issue is of significant concern in the medical field, where label noise can arise from delayed updates in electronic medical records or misdiagnoses, leading to increased prediction risks. Our research indicates that deep Hawkes process models exhibit reduced robustness when dealing with label noise, particularly when it affects both event types and timing. To address these challenges, we first investigate the influence of label noise in approximated intensity functions and present a novel framework, the Robust Deep Hawkes Process (RDHP), to overcome the impact of label noise on the intensity function of Hawkes models, considering both the events and their occurrences. We tested RDHP using multiple open-source benchmarks with synthetic noise and conducted a case study on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting with inherent label noise. The results demonstrate that RDHP can effectively perform classification and regression tasks, even in the presence of noise related to events and their timing. To the best of our knowledge, this is the first study to successfully address both event and time label noise in deep Hawkes process models, offering a promising solution for medical applications, specifically in diagnosing OSAHS.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "ECAI2024"
    },
    {
        "paper id": "2407.17165",
        "abstract url": "https://arxiv.org/abs/2407.17165",
        "title": "Explainable Artificial Intelligence Techniques for Irregular Temporal Classification of Multidrug Resistance Acquisition in Intensive Care Unit Patients",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Antimicrobial Resistance represents a significant challenge in the Intensive Care Unit (ICU), where patients are at heightened risk of Multidrug-Resistant (MDR) infections-pathogens resistant to multiple antimicrobial agents. This study introduces a novel methodology that integrates Gated Recurrent Units (GRUs) with advanced intrinsic and post-hoc interpretability techniques for detecting the onset of MDR in patients across time. Within interpretability methods, we propose Explainable Artificial Intelligence (XAI) approaches to handle irregular Multivariate Time Series (MTS), introducing Irregular Time Shapley Additive Explanations (IT-SHAP), a modification of Shapley Additive Explanations designed for irregular MTS with Recurrent Neural Networks focused on temporal outputs. Our methodology aims to identify specific risk factors associated with MDR in ICU patients. GRU with Hadamard's attention demonstrated high initial specificity and increasing sensitivity over time, correlating with increased nosocomial infection risks during prolonged ICU stays. XAI analysis, enhanced by Hadamard attention and IT-SHAP, identified critical factors such as previous non-resistant cultures, specific antibiotic usage patterns, and hospital environment dynamics. These insights suggest that early detection of at-risk patients can inform interventions such as preventive isolation and customized treatments, significantly improving clinical outcomes. The proposed GRU model for temporal classification achieved an average Receiver Operating Characteristic Area Under the Curve of 78.27 +- 1.26 over time, indicating strong predictive performance. In summary, this study highlights the clinical utility of our methodology, which combines predictive accuracy with interpretability, thereby facilitating more effective healthcare interventions by professionals.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17182",
        "abstract url": "https://arxiv.org/abs/2407.17182",
        "title": "Solving the Electrical Impedance Tomography Problem with a DeepONet Type Neural Network: Theory and Application",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we consider the non-invasive medical imaging modality of Electrical Impedance Tomography, where the problem is to recover the conductivity in a medium from a set of data that arises out of a current-to-voltage map (Neumann-to-Dirichlet operator) defined on the boundary of the medium. We formulate this inverse problem as an operator-learning problem where the goal is to learn the implicitly defined operator-to-function map between the space of Neumann-to-Dirichlet operators to the space of admissible conductivities. Subsequently, we use an operator-learning architecture, popularly called DeepONets, to learn this operator-to-function map. Thus far, most of the operator learning architectures have been implemented to learn operators between function spaces. In this work, we generalize the earlier works and use a DeepONet to actually {learn an operator-to-function} map. We provide a Universal Approximation Theorem type result which guarantees that this implicitly defined operator-to-function map between the space of Neumann-to-Dirichlet operator to the space of conductivity function can be approximated to an arbitrary degree using such a DeepONet. Furthermore, we provide a computational implementation of our proposed approach and compare it against a standard baseline. We show that the proposed approach achieves good reconstructions and outperforms the baseline method in our experiments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17195",
        "abstract url": "https://arxiv.org/abs/2407.17195",
        "title": "Surrogate-guided optimization in quantum networks",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose an optimization algorithm to improve the design and performance of quantum communication networks. When physical architectures become too complex for analytical methods, numerical simulation becomes essential to study quantum network behavior. Although highly informative, these simulations involve complex numerical functions without known analytical forms, making traditional optimization techniques that assume continuity, differentiability, or convexity inapplicable. Additionally, quantum network simulations are computationally demanding, rendering global approaches like Simulated Annealing or genetic algorithms, which require extensive function evaluations, impractical. We introduce a more efficient optimization workflow using machine learning models, which serve as surrogates for a given objective function. We demonstrate the effectiveness of our approach by applying it to three well-known optimization problems in quantum networking: quantum memory allocation for multiple network nodes, tuning an experimental parameter in all physical links of a quantum entanglement switch, and finding efficient protocol settings within a large asymmetric quantum network. The solutions found by our algorithm consistently outperform those obtained with our baseline approaches -- Simulated Annealing and Bayesian optimization -- in the allotted time limit by up to 18\\% and 20\\%, respectively. Our framework thus allows for more comprehensive quantum network studies, integrating surrogate-assisted optimization with existing quantum network simulators.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "20 pages (including supplementary notes), 12 figures"
    },
    {
        "paper id": "2407.17246",
        "abstract url": "https://arxiv.org/abs/2407.17246",
        "title": "Channel-Aware Low-Rank Adaptation in Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The balance between model capacity and generalization has been a key focus of recent discussions in long-term time series forecasting. Two representative channel strategies are closely associated with model expressivity and robustness, including channel independence (CI) and channel dependence (CD). The former adopts individual channel treatment and has been shown to be more robust to distribution shifts, but lacks sufficient capacity to model meaningful channel interactions. The latter is more expressive for representing complex cross-channel dependencies, but is prone to overfitting. To balance the two strategies, we present a channel-aware low-rank adaptation method to condition CD models on identity-aware individual components. As a plug-in solution, it is adaptable for a wide range of backbone architectures. Extensive experiments show that it can consistently and significantly improve the performance of both CI and CD models with demonstrated efficiency and flexibility. The code is available at https://github.com/tongnie/C-LoRA.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by CIKM 2024, short research paper track"
    },
    {
        "paper id": "2407.17333",
        "abstract url": "https://arxiv.org/abs/2407.17333",
        "title": "Global and Local Confidence Based Fraud Detection Graph Neural Network",
        "rating": "-1.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "anomaly detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents the Global and Local Confidence Graph Neural Network (GLC-GNN), an innovative approach to graph-based anomaly detection that addresses the challenges of heterophily and camouflage in fraudulent activities. By introducing a prototype to encapsulate the global features of a graph and calculating a Global Confidence (GC) value for each node, GLC-GNN effectively distinguishes between benign and fraudulent nodes. The model leverages GC to generate attention values for message aggregation, enhancing its ability to capture both homophily and heterophily. Through extensive experiments on four open datasets, GLC-GNN demonstrates superior performance over state-of-the-art models in accuracy and convergence speed, while maintaining a compact model size and expedited training process. The integration of global and local confidence measures in GLC-GNN offers a robust solution for detecting anomalies in graphs, with significant implications for fraud detection across diverse domains.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17404",
        "abstract url": "https://arxiv.org/abs/2407.17404",
        "title": "Grammar-based Game Description Generation using Large Language Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Grammar"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "To lower the barriers to game design development, automated game design, which generates game designs through computational processes, has been explored. In automated game design, machine learning-based techniques such as evolutionary algorithms have achieved success. Benefiting from the remarkable advancements in deep learning, applications in computer vision and natural language processing have progressed in level generation. However, due to the limited amount of data in game design, the application of deep learning has been insufficient for tasks such as game description generation. To pioneer a new approach for handling limited data in automated game design, we focus on the in-context learning of large language models (LLMs). LLMs can capture the features of a task from a few demonstration examples and apply the capabilities acquired during pre-training. We introduce the grammar of game descriptions, which effectively structures the game design space, into the LLMs' reasoning process. Grammar helps LLMs capture the characteristics of the complex task of game description generation. Furthermore, we propose a decoding method that iteratively improves the generated output by leveraging the grammar. Our experiments demonstrate that this approach performs well in generating game descriptions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17458",
        "abstract url": "https://arxiv.org/abs/2407.17458",
        "title": "EuroCropsML: A Time Series Benchmark Dataset For Few-Shot Crop Type Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "remote sensing",
                "agricultural"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce EuroCropsML, an analysis-ready remote sensing machine learning dataset for time series crop type classification of agricultural parcels in Europe. It is the first dataset designed to benchmark transnational few-shot crop type classification algorithms that supports advancements in algorithmic development and research comparability. It comprises 706 683 multi-class labeled data points across 176 classes, featuring annual time series of per-parcel median pixel values from Sentinel-2 L1C data for 2021, along with crop type labels and spatial coordinates. Based on the open-source EuroCrops collection, EuroCropsML is publicly available on Zenodo.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 5 figures"
    },
    {
        "paper id": "2407.17543",
        "abstract url": "https://arxiv.org/abs/2407.17543",
        "title": "Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "skin lesions",
                "lesion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "The influence of bias in datasets on the fairness of model predictions is a topic of ongoing research in various fields. We evaluate the performance of skin lesion classification using ResNet-based CNNs, focusing on patient sex variations in training data and three different learning strategies. We present a linear programming method for generating datasets with varying patient sex and class labels, taking into account the correlations between these variables. We evaluated the model performance using three different learning strategies: a single-task model, a reinforcing multi-task model, and an adversarial learning scheme. Our observations include: 1) sex-specific training data yields better results, 2) single-task models exhibit sex bias, 3) the reinforcement approach does not remove sex bias, 4) the adversarial model eliminates sex bias in cases involving only female patients, and 5) datasets that include male patients enhance model performance for the male subgroup, even when female patients are the majority. To generalise these findings, in future research, we will examine more demographic attributes, like age, and other possibly confounding factors, such as skin colour and artefacts in the skin lesions. We make all data and models available on GitHub.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "Submitted to MICCAI 2024"
    },
    {
        "paper id": "2407.17618",
        "abstract url": "https://arxiv.org/abs/2407.17618",
        "title": "Productive self/vulnerable body: self-tracking, overworking culture, and conflicted data practices",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Self-tracking, the collection, analysis, and interpretation of personal data, signifies an individualized way of health governance as people are demanded to build a responsible self by internalizing norms. However, the technological promises often bear conflicts with various social factors such as a strenuous schedule, a lack of motivation, stress, and anxieties, which fail to deliver health outcomes. To re-problematize the phenomenon, this paper situates self-tracking in an overworking culture in China and draws on semi structured and in depth interviews with overworking individuals to reveal the patterns in users interactions and interpretations with self-tracking data. It builds on the current literature of self-tracking and engages with theories from Science and Technology Studies, especially sociomaterial assemblages (Lupton 2016) and technological mediation (Verbeek 2005), to study self-tracking in a contextualized way which connects the micro (data reading, visualization, and affective elements in design) with the macro (work and workplaces, socioeconomic and political background) contexts of self-tracking. Drawing on investigation of the social context that users of self-tracking technologies internalize, reflect, or resist, the paper argues that the productivity and value oriented assumptions and workplace culture shape the imaginary of intensive (and sometimes impossible) self-care and health, an involution of competence embedded in the technological design and users affective experiences. Users respond by enacting different design elements and social contexts to frame two distinctive data practices of self-tracking.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17623",
        "abstract url": "https://arxiv.org/abs/2407.17623",
        "title": "SAfEPaTh: A System-Level Approach for Efficient Power and Thermal Estimation of Convolutional Neural Network Accelerator",
        "rating": "-1.5",
        "keywords": [
            [
                "Thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The design of energy-efficient, high-performance, and reliable Convolutional Neural Network (CNN) accelerators involves significant challenges due to complex power and thermal management issues. This paper introduces SAfEPaTh, a novel system-level approach for accurately estimating power and temperature in tile-based CNN accelerators. By addressing both steady-state and transient-state scenarios, SAfEPaTh effectively captures the dynamic effects of pipeline bubbles in interlayer pipelines, utilizing real CNN workloads for comprehensive evaluation. Unlike traditional methods, it eliminates the need for circuit-level simulations or on-chip measurements. Our methodology leverages TANIA, a cutting-edge hybrid digital-analog tile-based accelerator featuring analog-in-memory computing cores alongside digital cores. Through rigorous simulation results using the ResNet18 model, we demonstrate SAfEPaTh's capability to accurately estimate power and temperature within 500 seconds, encompassing CNN model accelerator mapping exploration and detailed power and thermal estimations. This efficiency and accuracy make SAfEPaTh an invaluable tool for designers, enabling them to optimize performance while adhering to stringent power and thermal constraints. Furthermore, SAfEPaTh's adaptability extends its utility across various CNN models and accelerator architectures, underscoring its broad applicability in the field. This study contributes significantly to the advancement of energy-efficient and reliable CNN accelerator designs, addressing critical challenges in dynamic power and thermal management.",
        "subjects": [
            "cs.LG",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17679",
        "abstract url": "https://arxiv.org/abs/2407.17679",
        "title": "Instagram versus women of color: Why are women of color protesting Instagram's algorithmic changes?",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Instagram has been appropriated by communities for several contemporary social struggles, often translating into real world action. Likewise, women of color (WOC) have used it to protest, share information and support one another through its various affordances. However, Instagram is known to have frequent updates, and recently the updates have been more drastic. The newest update changed the recommendation algorithm such that it showed video-oriented content (reels) from unknown accounts over static media from a user's own network. Several marginalized communities, and especially WOC resisted this change and others that led to it. Due to the backlash, Instagram rolled back its changes. Drawing from past HCI work on digital platforms for marginalised communities, I propose a qualitative study informed by the open research strategy to understand why WOC are resisting these changes, and eventually provide implications for design that can help implement changes in a more inclusive manner.",
        "subjects": [
            "cs.CY",
            "cs.SI"
        ],
        "comment": "5 pages, Workshop ACM CHI 2023"
    },
    {
        "paper id": "2407.17687",
        "abstract url": "https://arxiv.org/abs/2407.17687",
        "title": "Overcome the Difficulties of NSGA-II via Truthful Crowding Distance with Theoretical Guarantees",
        "rating": "-1.5",
        "keywords": [
            [
                "survival"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The NSGA-II is proven to encounter difficulties for more than two objectives, and the deduced reason is the crowding distance computed by regarding the different objectives independently. The recent theoretical efficiency of the NSGA-III and the SMS-EMOA also supports the deduced reason as both algorithms consider the dependencies of objectives in the second criterion after the non-dominated sorting but with complicated structure or difficult computation. However, there is still a question of whether a simple modification of the original crowding distance can help. This paper proposes such a variant, called truthful crowding distance. This variant inherits the simple structure of summing the component for each objective. For each objective, it first sorts the set of solutions in order of descending objective values, and uses the smallest normalized L1 distance between the current solution and solutions in the earlier positions of the sorted list as the component. Summing up all components gives the value of truthful crowding distance. We call this NSGA-II variant by NSGA-II-T that replaces the original crowding distance with the truthful one, and that sequentially updates the crowding distance value after each removal. We prove that the NSGA-II-T can efficiently cover the full Pareto front for many-objective mOneMinMax and mOJZJ, in contrast to the exponential runtime of the original NSGA-II. Besides, we also prove that it theoretically achieves a slightly better approximation of the Pareto front for OneMinMax than the original NSGA-II with sequential survival selection. Besides, it is the first NSGA-II variant with a simple structure that performs well for many objectives with theoretical guarantees.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17721",
        "abstract url": "https://arxiv.org/abs/2407.17721",
        "title": "A Two-Stage Imaging Framework Combining CNN and Physics-Informed Neural Networks for Full-Inverse Tomography: A Case Study in Electrical Impedance Tomography (EIT)",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-Informed Neural Networks (PINNs) are a machine learning technique for solving partial differential equations (PDEs) by incorporating PDEs as loss terms in neural networks and minimizing the loss function during training. Tomographic imaging, a method to reconstruct internal properties from external measurement data, is highly complex and ill-posed, making it an inverse problem. Recently, PINNs have shown significant potential in computational fluid dynamics (CFD) and have advantages in solving inverse problems. However, existing research has primarily focused on semi-inverse Electrical Impedance Tomography (EIT), where internal electric potentials are accessible. The practical full inverse EIT problem, where only boundary voltage measurements are available, remains challenging. To address this, we propose a two-stage hybrid learning framework combining Convolutional Neural Networks (CNNs) and PINNs to solve the full inverse EIT problem. This framework integrates data-driven and model-driven approaches, combines supervised and unsupervised learning, and decouples the forward and inverse problems within the PINN framework in EIT. Stage I: a U-Net constructs an end-to-end mapping from boundary voltage measurements to the internal potential distribution using supervised learning. Stage II: a Multilayer Perceptron (MLP)-based PINN takes the predicted internal potentials as input to solve for the conductivity distribution through unsupervised learning.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17731",
        "abstract url": "https://arxiv.org/abs/2407.17731",
        "title": "Optimal Trade and Industrial Policies in the Global Economy: A Deep Learning Framework",
        "rating": "-1.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a deep learning framework, DL-opt, designed to efficiently solve for optimal policies in quantifiable general equilibrium trade models. DL-opt integrates (i) a nested fixed point (NFXP) formulation of the optimization problem, (ii) automatic implicit differentiation to enhance gradient descent for solving unilateral optimal policies, and (iii) a best-response dynamics approach for finding Nash equilibria. Utilizing DL-opt, we solve for non-cooperative tariffs and industrial subsidies across 7 economies and 44 sectors, incorporating sectoral external economies of scale. Our quantitative analysis reveals significant sectoral heterogeneity in Nash policies: Nash industrial subsidies increase with scale elasticities, whereas Nash tariffs decrease with trade elasticities. Moreover, we show that global dual competition, involving both tariffs and industrial subsidies, results in lower tariffs and higher welfare outcomes compared to a global tariff war. These findings highlight the importance of considering sectoral heterogeneity and policy combinations in understanding global economic competition.",
        "subjects": [
            "econ.GN",
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17767",
        "abstract url": "https://arxiv.org/abs/2407.17767",
        "title": "Online Learning for Autonomous Management of Intent-based 6G Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "6G"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The growing complexity of networks and the variety of future scenarios with diverse and often stringent performance requirements call for a higher level of automation. Intent-based management emerges as a solution to attain high level of automation, enabling human operators to solely communicate with the network through high-level intents. The intents consist of the targets in the form of expectations (i.e., latency expectation) from a service and based on the expectations the required network configurations should be done accordingly. It is almost inevitable that when a network action is taken to fulfill one intent, it can cause negative impacts on the performance of another intent, which results in a conflict. In this paper, we aim to address the conflict issue and autonomous management of intent-based networking, and propose an online learning method based on the hierarchical multi-armed bandits approach for an effective management. Thanks to this hierarchical structure, it performs an efficient exploration and exploitation of network configurations with respect to the dynamic network conditions. We show that our algorithm is an effective approach regarding resource allocation and satisfaction of intent expectations.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20258",
        "abstract url": "https://arxiv.org/abs/2407.20258",
        "title": "An Efficient and Flexible Deep Learning Method for Signal Delineation via Keypoints Estimation",
        "rating": "-1.5",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Learning (DL) methods have been used for electrocardiogram (ECG) processing in a wide variety of tasks, demonstrating good performance compared with traditional signal processing algorithms. These methods offer an efficient framework with a limited need for apriori data pre-processing and feature engineering. While several studies use this approach for ECG signal delineation, a significant gap persists between the expected and the actual outcome. Existing methods rely on a sample-to-sample classifier. However, the clinical expected outcome consists of a set of onset, offset, and peak for the different waves that compose each R-R interval. To align the actual with the expected output, it is necessary to incorporate post-processing algorithms. This counteracts two of the main advantages of DL models, since these algorithms are based on assumptions and slow down the method's performance. In this paper, we present Keypoint Estimation for Electrocardiogram Delineation (KEED), a novel DL model designed for keypoint estimation, which organically offers an output aligned with clinical expectations. By standing apart from the conventional sample-to-sample classifier, we achieve two benefits: (i) Eliminate the need for additional post-processing, and (ii) Establish a flexible framework that allows the adjustment of the threshold value considering the sensitivity-specificity tradeoff regarding the particular clinical requirements. The proposed method's performance is compared with state-of-the-art (SOTA) signal processing methods. Remarkably, KEED significantly outperforms despite being optimized with an extremely limited annotated data. In addition, KEED decreases the inference time by a factor ranging from 52x to 703x.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "Accepted to ICSIP 2024"
    },
    {
        "paper id": "2407.20265",
        "abstract url": "https://arxiv.org/abs/2407.20265",
        "title": "COEFF-KANs: A Paradigm to Address the Electrolyte Field with KANs",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "To reduce the experimental validation workload for chemical researchers and accelerate the design and optimization of high-energy-density lithium metal batteries, we aim to leverage models to automatically predict Coulombic Efficiency (CE) based on the composition of liquid electrolytes. There are mainly two representative paradigms in existing methods: machine learning and deep learning. However, the former requires intelligent input feature selection and reliable computational methods, leading to error propagation from feature estimation to model prediction, while the latter (e.g. MultiModal-MoLFormer) faces challenges of poor predictive performance and overfitting due to limited diversity in augmented data. To tackle these issues, we propose a novel method COEFF (COlumbic EFficiency prediction via Fine-tuned models), which consists of two stages: pre-training a chemical general model and fine-tuning on downstream domain data. Firstly, we adopt the publicly available MoLFormer model to obtain feature vectors for each solvent and salt in the electrolyte. Then, we perform a weighted average of embeddings for each token across all molecules, with weights determined by the respective electrolyte component ratios. Finally, we input the obtained electrolyte features into a Multi-layer Perceptron or Kolmogorov-Arnold Network to predict CE. Experimental results on a real-world dataset demonstrate that our method achieves SOTA for predicting CE compared to all baselines. Data and code used in this work will be made publicly available after the paper is published.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2407.17003",
        "abstract url": "https://arxiv.org/abs/2407.17003",
        "title": "Progressive Query Refinement Framework for Bird's-Eye-View Semantic Segmentation from Surrounding Images",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Expressing images with Multi-Resolution (MR) features has been widely adopted in many computer vision tasks. In this paper, we introduce the MR concept into Bird's-Eye-View (BEV) semantic segmentation for autonomous driving. This introduction enhances our model's ability to capture both global and local characteristics of driving scenes through our proposed residual learning. Specifically, given a set of MR BEV query maps, the lowest resolution query map is initially updated using a View Transformation (VT) encoder. This updated query map is then upscaled and merged with a higher resolution query map to undergo further updates in a subsequent VT encoder. This process is repeated until the resolution of the updated query map reaches the target. Finally, the lowest resolution map is added to the target resolution to generate the final query map. During training, we enforce both the lowest and final query maps to align with the ground-truth BEV semantic map to help our model effectively capture the global and local characteristics. We also propose a visual feature interaction network that promotes interactions between features across images and across feature levels, thus highly contributing to the performance improvement. We evaluate our model on a large-scale real-world dataset. The experimental results show that our model outperforms the SOTA models in terms of IoU metric. Codes are available at https://github.com/d1024choi/ProgressiveQueryRefineNet",
        "subjects": [
            "cs.CV"
        ],
        "comment": "IROS 2024"
    },
    {
        "paper id": "2407.17024",
        "abstract url": "https://arxiv.org/abs/2407.17024",
        "title": "LLM-Generated Tips Rival Expert-Created Tips in Helping Students Answer Quantum-Computing Questions",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Individual teaching is among the most successful ways to impart knowledge. Yet, this method is not always feasible due to large numbers of students per educator. Quantum computing serves as a prime example facing this issue, due to the hype surrounding it. Alleviating high workloads for teachers, often accompanied with individual teaching, is crucial for continuous high quality education. Therefore, leveraging Large Language Models (LLMs) such as GPT-4 to generate educational content can be valuable. We conducted two complementary studies exploring the feasibility of using GPT-4 to automatically generate tips for students. In the first one students (N=46) solved four multiple-choice quantum computing questions with either the help of expert-created or LLM-generated tips. To correct for possible biases towards LLMs, we introduced two additional conditions, making some participants believe that they were given expert-created tips, when they were given LLM-generated tips and vice versa. Our second study (N=23) aimed to directly compare the LLM-generated and expert-created tips, evaluating their quality, correctness and helpfulness, with both experienced educators and students participating. Participants in our second study found that the LLM-generated tips were significantly more helpful and pointed better towards relevant concepts than the expert-created tips, while being more prone to be giving away the answer. While participants in the first study performed significantly better in answering the quantum computing questions when given tips labeled as LLM-generated, even if they were created by an expert. This phenomenon could be a placebo effect induced by the participants' biases for LLM-generated content. Ultimately, we find that LLM-generated tips are good enough to be used instead of expert tips in the context of quantum computing basics.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17039",
        "abstract url": "https://arxiv.org/abs/2407.17039",
        "title": "Integrated Sensing and Communication with Nested Array: Beam Pattern and Performance Analysis",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Towards the upcoming 6G wireless networks, integrated sensing and communication (ISAC) has been identified as one of the typical usage scenarios. To further enhance the performance of ISAC, increasing the number of antennas as well as array aperture is one of the effective approaches. However, simply increasing the number of antennas will increase the cost of radio frequency chains and power consumption. To address this issue, in this paper, we consider an uplink ISAC system with nested array deployed at the base station. Nested array is a classic sparse array architecture that is able to enlarge the array aperture without increasing the number of physical antennas. While nested array for wireless sensing has been extensively studied, its potential for ISAC system has not been fully exploited. To fill this gap, in this paper, we provide the beam pattern analysis of nested arrays, and derive the closed-form expressions for the three beam pattern metrics, namely, the main lobe beam width, peak-to-local-minimum ratio, and prominent side lobes height. Extensive simulation results are provided to show that compared with conventional uniform arrays, nested arrays can achieve higher communication performance for densely located users while maintaining its advantage of sensing.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2407.17078",
        "abstract url": "https://arxiv.org/abs/2407.17078",
        "title": "Active Loop Closure for OSM-guided Robotic Mapping in Large-Scale Urban Environments",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "The autonomous mapping of large-scale urban scenes presents significant challenges for autonomous robots. To mitigate the challenges, global planning, such as utilizing prior GPS trajectories from OpenStreetMap (OSM), is often used to guide the autonomous navigation of robots for mapping. However, due to factors like complex terrain, unexpected body movement, and sensor noise, the uncertainty of the robot's pose estimates inevitably increases over time, ultimately leading to the failure of robotic mapping. To address this issue, we propose a novel active loop closure procedure, enabling the robot to actively re-plan the previously planned GPS trajectory. The method can guide the robot to re-visit the previous places where the loop-closure detection can be performed to trigger the back-end optimization, effectively reducing errors and uncertainties in pose estimation. The proposed active loop closure mechanism is implemented and embedded into a real-time OSM-guided robot mapping framework. Empirical results on several large-scale outdoor scenarios demonstrate its effectiveness and promising performance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17115",
        "abstract url": "https://arxiv.org/abs/2407.17115",
        "title": "Reinforced Prompt Personalization for Recommendation with Large Language Models",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Designing effective prompts can empower LLMs to understand user preferences and provide recommendations by leveraging LLMs' intent comprehension and knowledge utilization capabilities. However, existing research predominantly concentrates on task-wise prompting, developing fixed prompt templates composed of four patterns (i.e., role-playing, history records, reasoning guidance, and output format) and applying them to all users for a given task. Although convenient, task-wise prompting overlooks individual user differences, leading to potential mismatches in capturing user preferences. To address it, we introduce the concept of instance-wise prompting to personalize discrete prompts for individual users and propose Reinforced Prompt Personalization (RPP) to optimize the four patterns in prompts using multi-agent reinforcement learning (MARL). To boost efficiency, RPP formulates prompt personalization as selecting optimal sentences holistically across the four patterns, rather than optimizing word-by-word. To ensure the quality of prompts, RPP meticulously crafts diverse expressions for each of the four patterns, considering multiple analytical perspectives for specific recommendation tasks. In addition to RPP, our proposal of RPP+ aims to enhance the scalability of action space by dynamically refining actions with LLMs throughout the iterative process. We evaluate the effectiveness of RPP/RPP+ in ranking tasks over various datasets. Experimental results demonstrate the superiority of RPP/RPP+ over traditional recommender models, few-shot methods, and other prompt-based methods, underscoring the significance of instance-wise prompting for LLMs in recommendation tasks and validating the effectiveness of RPP/RPP+. Our code is available at https://github.com/maowenyu-11/RPP.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17139",
        "abstract url": "https://arxiv.org/abs/2407.17139",
        "title": "A Reduced Order Model conditioned on monitoring features for estimation and uncertainty quantification in engineered systems",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Reduced Order Models (ROMs) form essential tools across engineering domains by virtue of their function as surrogates for computationally intensive digital twinning simulators. Although purely data-driven methods are available for ROM construction, schemes that allow to retain a portion of the physics tend to enhance the interpretability and generalization of ROMs. However, physics-based techniques can adversely scale when dealing with nonlinear systems that feature parametric dependencies. This study introduces a generative physics-based ROM that is suited for nonlinear systems with parametric dependencies and is additionally able to quantify the confidence associated with the respective estimates. A main contribution of this work is the conditioning of these parametric ROMs to features that can be derived from monitoring measurements, feasibly in an online fashion. This is contrary to most existing ROM schemes, which remain restricted to the prescription of the physics-based, and usually a priori unknown, system parameters. Our work utilizes conditional Variational Autoencoders to continuously map the required reduction bases to a feature vector extracted from limited output measurements, while additionally allowing for a probabilistic assessment of the ROM-estimated Quantities of Interest. An auxiliary task using a neural network-based parametrization of suitable probability distributions is introduced to re-establish the link with physical model parameters. We verify the proposed scheme on a series of simulated case studies incorporating effects of geometric and material nonlinearity under parametric dependencies related to system properties and input load characteristics.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17204",
        "abstract url": "https://arxiv.org/abs/2407.17204",
        "title": "The Questionable Influence of Entanglement in Quantum Optimisation Algorithms",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The performance of the Variational Quantum Eigensolver (VQE) is promising compared to other quantum algorithms, but also depends significantly on the appropriate design of the underlying quantum circuit. Recent research by Bowles, Ahmend \\& Schuld, 2024 [1] raises questions about the effectiveness of entanglement in circuits for quantum machine learning algorithms. In our paper we want to address questions about the effectiveness of state preparation via Hadamard gates and entanglement via CNOT gates in the realm of quantum optimisation. We have constructed a total of eight different circuits, varying in implementation details, solving a total of 100 randomly generated MaxCut problems. Our results show no improvement with Hadamard gates applied at the beginning of the circuits. Furthermore, also entanglement shows no positive effect on the solution quality in our small scale experiments. In contrast, the investigated circuits that used entanglement generally showed lower, as well as deteriorating results when the number of circuit layers is increased. Based on our results, we hypothesise that entanglement can play a coordinating role, such that changes in individual parameters are distributed across multiple qubits in quantum circuits, but that this positive effect can quickly be overdosed and turned negative. The verification of this hypothesis represents a challenge for future research and can have a considerable influence on the development of new hybrid algorithms.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "7 pages, 3 figures"
    },
    {
        "paper id": "2407.17207",
        "abstract url": "https://arxiv.org/abs/2407.17207",
        "title": "Solving The Travelling Salesman Problem Using A Single Qubit",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "The travelling salesman problem (TSP) is a popular NP-hard-combinatorial optimization problem that requires finding the optimal way for a salesman to travel through different cities once and return to the initial city. The existing methods of solving TSPs on quantum systems are either gate-based or binary variable-based encoding. Both approaches are resource-expensive in terms of the number of qubits while performing worse compared to existing classical algorithms even for small-size problems. We present an algorithm that solves an arbitrary TSP using a single qubit by invoking the principle of quantum parallelism. The cities are represented as quantum states on the Bloch sphere while the preparation of superposition states allows us to traverse multiple paths at once. The underlying framework of our algorithm is a quantum version of the classical Brachistochrone approach. Optimal control methods are employed to create a selective superposition of the quantum states to find the shortest route of a given TSP. The numerical simulations solve a sample of four to nine cities for which exact solutions are obtained. The algorithm can be implemented on any quantum platform capable of efficiently rotating a qubit and allowing state tomography measurements. For the TSP problem sizes considered in this work, our algorithm is more resource-efficient and accurate than existing quantum algorithms with the potential for scalability. A potential speed-up of polynomial time over classical algorithms is discussed.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "math.OC"
        ],
        "comment": "17 pages, 9 figures"
    },
    {
        "paper id": "2407.17256",
        "abstract url": "https://arxiv.org/abs/2407.17256",
        "title": "Critical Infrastructure Security: Penetration Testing and Exploit Development Perspectives",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "Critical infrastructure refers to essential physical and cyber systems vital to the functioning and stability of societies and economies. These systems include key sectors such as healthcare, energy, and water supply, which are crucial for societal and economic stability and are increasingly becoming prime targets for malicious actors, including state-sponsored hackers, seeking to disrupt national security and economic stability. This paper reviews literature on critical infrastructure security, focusing on penetration testing and exploit development. It explores four main questions: the characteristics of critical infrastructure, the role and challenges of penetration testing, methodologies of exploit development, and the contribution of these practices to security and resilience. The findings of this paper reveal inherent vulnerabilities in critical infrastructure and sophisticated threats posed by cyber adversaries. Penetration testing is highlighted as a vital tool for identifying and addressing security weaknesses, allowing organizations to fortify their defenses. Additionally, understanding exploit development helps anticipate and mitigate potential threats, leading to more robust security measures. The review underscores the necessity of continuous and proactive security assessments, advocating for integrating penetration testing and exploit development into regular security protocols. By doing so, organizations can preemptively identify and mitigate risks, enhancing the overall resilience of critical infrastructure. The paper concludes by emphasizing the need for ongoing research and collaboration between the public and private sectors to develop innovative solutions for the evolving cyber threat landscape. This comprehensive review aims to provide a foundational understanding of critical infrastructure security and guide future research and practices.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17259",
        "abstract url": "https://arxiv.org/abs/2407.17259",
        "title": "Spatial Conceptual Modeling: Anchoring Knowledge in the Real World",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "This paper introduces the concept of spatial conceptual modeling, which allows anchoring mental world knowledge in the physical world using augmented reality technologies. For a first formal characterization, we describe a mapping from the spatial information concepts location, field, object, network, and event, as used in spatial computing, to conceptual modeling concepts using the FDMM formalism. This allows to identify necessary adaptations at the metamodeling level to make the approach applicable to arbitrary types of spatial conceptual modeling languages. Finally, possible application areas of spatial conceptual modeling in the medical domain, manufacturing and engineering, physical IT architectures and smart homes, supply chain management and logistics, civil engineering, and smart cities and cultural heritage are discussed.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17269",
        "abstract url": "https://arxiv.org/abs/2407.17269",
        "title": "Advanced Penetration Testing for Enhancing 5G Security",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Advances in fifth-generation (5G) networks enable unprecedented reliability, speed, and connectivity compared to previous mobile networks. These advancements can revolutionize various sectors by supporting applications requiring real-time data processing. However, the rapid deployment and integration of 5G networks bring security concerns that must be addressed to operate these infrastructures safely. This paper reviews penetration testing approaches for identifying security vulnerabilities in 5G networks. Penetration testing is an ethical hacking technique used to simulate a network's security posture in the event of cyberattacks. This review highlights the capabilities, advantages, and limitations of recent 5G-targeting security tools for penetration testing. It examines ways adversaries exploit vulnerabilities in 5G networks, covering tactics and strategies targeted at 5G features. A key topic explored is the comparison of penetration testing methods for 5G and earlier generations. The article delves into the unique characteristics of 5G, including massive MIMO, edge computing, and network slicing, and how these aspects require new penetration testing methods. Understanding these differences helps develop more effective security solutions tailored to 5G networks. Our research also indicates that 5G penetration testing should use a multithreaded approach for addressing current security challenges. Furthermore, this paper includes case studies illustrating practical challenges and limitations in real-world applications of penetration testing in 5G networks. A comparative analysis of penetration testing tools for 5G networks highlights their effectiveness in mitigating vulnerabilities, emphasizing the need for advanced security measures against evolving cyber threats in 5G deployment.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17275",
        "abstract url": "https://arxiv.org/abs/2407.17275",
        "title": "Reacting on human stubbornness in human-machine trajectory planning",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "In this paper, a method for a cooperative trajectory planning between a human and an automation is extended by a behavioral model of the human. This model can characterize the stubbornness of the human, which measures how strong the human adheres to his preferred trajectory. Accordingly, a static model is introduced indicating a link between the force in haptically coupled human-robot interactions and humans's stubbornness. The introduced stubbornness parameter enables an application-independent reaction of the automation for the cooperative trajectory planning. Simulation results in the context of human-machine cooperation in a care application show that the proposed behavioral model can quantitatively estimate the stubbornness of the interacting human, enabling a more targeted adaptation of the automation to the human behavior.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17305",
        "abstract url": "https://arxiv.org/abs/2407.17305",
        "title": "Continual Learning in Bio-plausible Spiking Neural Networks with Hebbian and Spike Timing Dependent Plasticity: A Survey and Perspective",
        "rating": "-2",
        "keywords": [
            [
                "Bio-plausible"
            ]
        ],
        "abstract": "Recently, the use bio-plausible learning techniques such as Hebbian and Spike-Timing-Dependent Plasticity (STDP) have drawn significant attention for the design of compute-efficient AI systems that can continuously learn on-line at the edge. A key differentiating factor regarding this emerging class of neuromorphic continual learning system lies in the fact that learning must be carried using a data stream received in its natural order, as opposed to conventional gradient-based offline training where a static training dataset is assumed available a priori and randomly shuffled to make the training set independent and identically distributed (i.i.d). In contrast, the emerging class of neuromorphic continual learning systems covered in this survey must learn to integrate new information on the fly in a non-i.i.d manner, which makes these systems subject to catastrophic forgetting. In order to build the next generation of neuromorphic AI systems that can continuously learn at the edge, a growing number of research groups are studying the use of bio-plausible Hebbian neural network architectures and Spiking Neural Networks (SNNs) equipped with STDP learning. However, since this research field is still emerging, there is a need for providing a holistic view of the different approaches proposed in literature so far. To this end, this survey covers a number of recent works in the field of neuromorphic continual learning; provides background theory to help interested researchers to quickly learn the key concepts; and discusses important future research questions in light of the different works covered in this paper. It is hoped that this survey will contribute towards future research in the field of neuromorphic continual learning.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17314",
        "abstract url": "https://arxiv.org/abs/2407.17314",
        "title": "Edge-Cloud Continuum Orchestration of Critical Services: A Smart-City Approach",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Smart-city services are typically developed as closed systems within each city's vertical, communicating and interacting with cloud services while remaining isolated within each provider's domain. With the emergence of 5G private domains and the introduction of new M2M services focusing on autonomous systems, there is a shift from the cloud-based approach to a distributed edge computing paradigm, in a \\textit{continuum} orchestration. However, an essential component is missing. Current orchestration tools, designed for cloud-based deployments, lack robust workload isolation, fail to meet timing constraints, and are not tailored to the resource-constrained nature of edge devices. Therefore, new orchestration methods are needed to support MEC environments. The work presented in this paper addresses this gap. Based on the real needs of a smart-city testbed - the Aveiro Living Lab-, we developed a set of orchestration components to facilitate the seamless orchestration of both cloud and edge-based services, encompassing both critical and non-critical services. This work extends the current Kubernetes orchestration platform to include a novel location-specific resource definition, a custom scheduler to accommodate real-time and legacy services, continuous service monitoring to detect sub-optimal states, and a refined load balancing mechanism that prioritizes the fastest response times.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17324",
        "abstract url": "https://arxiv.org/abs/2407.17324",
        "title": "Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diagnosis",
                "MRI",
                "Disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Dementia, a debilitating neurological condition affecting millions worldwide, presents significant diagnostic challenges. In this work, we introduce a novel methodology for the classification of demented and non-demented elderly patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach features a unique technique for selectively processing MRI slices, focusing on the most relevant brain regions and excluding less informative sections. This methodology is complemented by a confidence-based classification committee composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and Dem3D EfficientNet. These models work synergistically to enhance decision-making accuracy, leveraging their collective strengths. Tested on the Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore, validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset confirmed the robustness and generalizability of our approach. The use of explainable AI (XAI) techniques and comprehensive ablation studies further substantiate the effectiveness of our techniques, providing insights into the decision-making process and the importance of our methodology. This research offers a significant advancement in dementia diagnosis, providing a highly accurate and efficient tool for clinical applications.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17325",
        "abstract url": "https://arxiv.org/abs/2407.17325",
        "title": "Noise-Aware Distributed Quantum Approximate Optimization Algorithm on Near-term Quantum Hardware",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "This paper introduces a noise-aware distributed Quantum Approximate Optimization Algorithm (QAOA) tailored for execution on near-term quantum hardware. Leveraging a distributed framework, we address the limitations of current Noisy Intermediate-Scale Quantum (NISQ) devices, which are hindered by limited qubit counts and high error rates. Our approach decomposes large QAOA problems into smaller subproblems, distributing them across multiple Quantum Processing Units (QPUs) to enhance scalability and performance. The noise-aware strategy incorporates error mitigation techniques to optimize qubit fidelity and gate operations, ensuring reliable quantum computations. We evaluate the efficacy of our framework using the HamilToniQ Benchmarking Toolkit, which quantifies the performance across various quantum hardware configurations. The results demonstrate that our distributed QAOA framework achieves significant improvements in computational speed and accuracy, showcasing its potential to solve complex optimization problems efficiently in the NISQ era. This work sets the stage for advanced algorithmic strategies and practical quantum system enhancements, contributing to the broader goal of achieving quantum advantage.",
        "subjects": [
            "quant-ph",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17398",
        "abstract url": "https://arxiv.org/abs/2407.17398",
        "title": "3D Question Answering for City Scene Understanding",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D multimodal question answering (MQA) plays a crucial role in scene understanding by enabling intelligent agents to comprehend their surroundings in 3D environments. While existing research has primarily focused on indoor household tasks and outdoor roadside autonomous driving tasks, there has been limited exploration of city-level scene understanding tasks. Furthermore, existing research faces challenges in understanding city scenes, due to the absence of spatial semantic information and human-environment interaction information at the city level.To address these challenges, we investigate 3D MQA from both dataset and method perspectives. From the dataset perspective, we introduce a novel 3D MQA dataset named City-3DQA for city-level scene understanding, which is the first dataset to incorporate scene semantic and human-environment interactive tasks within the city. From the method perspective, we propose a Scene graph enhanced City-level Understanding method (Sg-CityU), which utilizes the scene graph to introduce the spatial semantic. A new benchmark is reported and our proposed Sg-CityU achieves accuracy of 63.94 % and 63.76 % in different settings of City-3DQA. Compared to indoor 3D MQA methods and zero-shot using advanced large language models (LLMs), Sg-CityU demonstrates state-of-the-art (SOTA) performance in robustness and generalization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17536",
        "abstract url": "https://arxiv.org/abs/2407.17536",
        "title": "Improved symbolic drum style classification with grammar-based hierarchical representations",
        "rating": "-2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "grammar"
            ],
            [
                "music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Deep learning models have become a critical tool for analysis and classification of musical data. These models operate either on the audio signal, e.g. waveform or spectrogram, or on a symbolic representation, such as MIDI. In the latter, musical information is often reduced to basic features, i.e. durations, pitches and velocities. Most existing works then rely on generic tokenization strategies from classical natural language processing, or matrix representations, e.g. piano roll. In this work, we evaluate how enriched representations of symbolic data can impact deep models, i.e. Transformers and RNN, for music style classification. In particular, we examine representations that explicitly incorporate musical information implicitly present in MIDI-like encodings, such as rhythmic organization, and show that they outperform generic tokenization strategies. We introduce a new tree-based representation of MIDI data built upon a context-free musical grammar. We show that this grammar representation accurately encodes high-level rhythmic information and outperforms existing encodings on the GrooveMIDI Dataset for drumming style classification, while being more compact and parameter-efficient.",
        "subjects": [
            "cs.SD",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "International Society for Music Information Retrieval Conference 2024, Nov 2024, San Francisco, United States"
    },
    {
        "paper id": "2407.17540",
        "abstract url": "https://arxiv.org/abs/2407.17540",
        "title": "Wavelet-based Autoencoder and EfficientNet for Schizophrenia Detection from EEG Signals",
        "rating": "-2",
        "keywords": [
            [
                "diagnosis",
                "EEG"
            ]
        ],
        "abstract": "Schizophrenia (SZ) is a complex mental disorder that necessitates accurate and timely diagnosis for effective treatment. Traditional methods for SZ classification often struggle to capture transient EEG features and face high computational complexity. This study proposes a convolutional autoencoder (CAE) to address these challenges by reducing dimensionality and computational complexity. Additionally, we introduce a novel approach utilizing spectral scalograms (SS) combined with EfficientNet (ENB) architectures. The SS, obtained through continuous wavelet transform, reveals temporal and spectral information of EEG signals, aiding in the identification of transient features. ENB models, through transfer learning (TL), extract discriminative features and improve SZ classification accuracy. Experimental evaluation on a comprehensive dataset demonstrates the efficacy of our approach, achieving a five-fold mean cross-validation accuracy of 98.5\\% using CAE with a soft voting classifier and 99\\% employing SS with the ENB7 model. These results suggest the potential of our methods to enhance SZ diagnosis, surpassing traditional deep learning (DL) and TL techniques. By leveraging CAE and ENBs, this research offers a robust framework for objective SZ classification, promoting early intervention and improved patient outcomes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17626",
        "abstract url": "https://arxiv.org/abs/2407.17626",
        "title": "Competitive Perimeter Defense in Tree Environments",
        "rating": "-2",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "We consider a perimeter defense problem in a rooted full tree graph environment in which a single defending vehicle seeks to defend a set of specified vertices, termed as the perimeter from mobile intruders that enter the environment through the tree's leaves. We adopt the technique of competitive analysis to characterize the performance of an online algorithm for the defending vehicle. We first derive fundamental limits on the performance of any online algorithm relative to that of an optimal offline algorithm. Specifically, we give three fundamental conditions for finite, 2, and 3/2 competitive ratios in terms of the environment parameters. We then design and analyze three classes of online algorithms that have provably finite competitiveness under varying environmental parameter regimes. Finally, we give a numerical visualization of these regimes to better show the comparative strengths and weaknesses of each algorithm.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2407.17641",
        "abstract url": "https://arxiv.org/abs/2407.17641",
        "title": "Regular language quantum states",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We introduce regular language states, a family of quantum many-body states. They are built from a special class of formal languages, called regular, which has been thoroughly studied in the field of computer science. They can be understood as the superposition of all the words in a regular language and encompass physically relevant states such as the GHZ-, W- or Dicke-states. By leveraging the theory of regular languages, we develop a theoretical framework to describe them. First, we express them in terms of matrix product states, providing efficient criteria to recognize them. We then develop a canonical form which allows us to formulate a fundamental theorem for the equivalence of regular language states, including under local unitary operations. We also exploit the theory of tensor networks to find an efficient criterion to determine when regular languages are shift-invariant.",
        "subjects": [
            "quant-ph",
            "cs.FL"
        ],
        "comment": "12 pages, 1 figure"
    },
    {
        "paper id": "2407.17673",
        "abstract url": "https://arxiv.org/abs/2407.17673",
        "title": "CRASAR-U-DROIDs: A Large Scale Benchmark Dataset for Building Alignment and Damage Assessment in Georectified sUAS Imagery",
        "rating": "-2",
        "keywords": [
            [
                "Robot"
            ],
            [
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This document presents the Center for Robot Assisted Search And Rescue - Uncrewed Aerial Systems - Disaster Response Overhead Inspection Dataset (CRASAR-U-DROIDs) for building damage assessment and spatial alignment collected from small uncrewed aerial systems (sUAS) geospatial imagery. This dataset is motivated by the increasing use of sUAS in disaster response and the lack of previous work in utilizing high-resolution geospatial sUAS imagery for machine learning and computer vision models, the lack of alignment with operational use cases, and with hopes of enabling further investigations between sUAS and satellite imagery. The CRASAR-U-DRIODs dataset consists of fifty-two (52) orthomosaics from ten (10) federally declared disasters (Hurricane Ian, Hurricane Ida, Hurricane Harvey, Hurricane Idalia, Hurricane Laura, Hurricane Michael, Musset Bayou Fire, Mayfield Tornado, Kilauea Eruption, and Champlain Towers Collapse) spanning 67.98 square kilometers (26.245 square miles), containing 21,716 building polygons and damage labels, and 7,880 adjustment annotations. The imagery was tiled and presented in conjunction with overlaid building polygons to a pool of 130 annotators who provided human judgments of damage according to the Joint Damage Scale. These annotations were then reviewed via a two-stage review process in which building polygon damage labels were first reviewed individually and then again by committee. Additionally, the building polygons have been aligned spatially to precisely overlap with the imagery to enable more performant machine learning models to be trained. It appears that CRASAR-U-DRIODs is the largest labeled dataset of sUAS orthomosaic imagery.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "16 Pages, 7 Figures, 6 Tables"
    },
    {
        "paper id": "2407.17676",
        "abstract url": "https://arxiv.org/abs/2407.17676",
        "title": "Empowering the Quantum Cloud User with QRIO",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum computing is moving swiftly from theoretical to practical applications, making it crucial to establish a significant quantum advantage. Despite substantial investments, access to quantum devices is still limited, with users facing issues like long wait times and inefficient resource management. Unlike the mature cloud solutions for classical computing, quantum computing lacks effective infrastructure for resource optimization. We propose a Quantum Resource Infrastructure Orchestrator (QRIO), a state-of-the-art cloud resource manager built on Kubernetes that is tailored to quantum computing. QRIO seeks to democratize access to quantum devices by providing customizable, user-friendly, open-source resource management. QRIO's design aims to ensure equitable access, optimize resource utilization, and support diverse applications, thereby speeding up innovation and making quantum computing more accessible and efficient to a broader user base. In this paper, we discuss QRIO's various features and evaluate its capability in several representative usecases.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "To appear at the IEEE International Symposium on Workload Characterization, 2024"
    },
    {
        "paper id": "2407.17691",
        "abstract url": "https://arxiv.org/abs/2407.17691",
        "title": "Design, Key Techniques and System-Level Simulation for NB-IoT Networks",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "IoT"
            ]
        ],
        "abstract": "Narrowband Internet of Things (NB-IoT) is a promising technology designated specially by the 3rd Generation Partnership Project (3GPP) to meet the growing demand of massive machine-type communications (mMTC). More and more industrial companies choose NB-IoT network as the solution to mMTC due to its unique design and technical specification released by 3GPP. In order to evaluate the performance of NB-IoT network, we design a system-level simulation for NB-IoT network in this paper. In particular, the structure of system-level simulator are divided into four parts, i.e., initialization, pre-generation, main simulation loop and post-processing. Moreover, three key techniques are developed in the implementation of NB-IoT network by accounting for enhanced coverage, massive connection and low-power consumption. Simulation results demonstrate the cumulative distribution function curves of signal-to-interference-and-noise ratio are fully compliant with industrial standard, and the performance of throughput explains how NB-IoT network realize massive connection at the cost of data rate.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17762",
        "abstract url": "https://arxiv.org/abs/2407.17762",
        "title": "Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "bioterrorism",
                "medical",
                "disease"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Rapid development of disease detection models using computer vision is crucial in responding to medical emergencies, such as epidemics or bioterrorism events. Traditional data collection methods are often too slow in these scenarios, requiring innovative approaches for quick, reliable model generation from minimal data. Our study introduces a novel approach by constructing a comprehensive computer vision model to detect Mpox lesions using only synthetic data. Initially, these models generated a diverse set of synthetic images representing Mpox lesions on various body parts (face, back, chest, leg, neck, arm) across different skin tones as defined by the Fitzpatrick scale (fair, brown, dark skin). Subsequently, we trained and tested a vision model with this synthetic dataset to evaluate the diffusion models' efficacy in producing high-quality training data and its impact on the vision model's medical image recognition performance. The results were promising; the vision model achieved a 97% accuracy rate, with 96% precision and recall for Mpox cases, and similarly high metrics for normal and other skin disorder cases, demonstrating its ability to correctly identify true positives and minimize false positives. The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and other skin disorders, reflecting a balanced precision-recall relationship, thus ensuring reliability and robustness in its predictions. Our proposed SynthVision methodology indicates the potential to develop accurate computer vision models with minimal data input for future medical emergencies.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 4 figures, 1 table"
    },
    {
        "paper id": "2407.17765",
        "abstract url": "https://arxiv.org/abs/2407.17765",
        "title": "Utilizing Blockchain and Smart Contracts for Enhanced Fraud Prevention and Minimization in Health Insurance through Multi-Signature Claim Processing",
        "rating": "-2",
        "keywords": [
            [
                "medical",
                "Health",
                "Healthcare"
            ]
        ],
        "abstract": "Healthcare insurance provides financial support to access medical services for patients while ensuring timely and guaranteed payment for providers. Insurance fraud poses a significant challenge to insurance companies and policyholders, leading to increased costs and compromised healthcare treatment and service delivery. Most frauds, like phantom billing, upcoding, and unbundling, happen due to the lack of required entity participation. Also, claim activities are not transparent and accountable. Fraud can be prevented and minimized by involving every entity and making actions transparent and accountable. This paper proposes a blockchain-powered smart contract-based insurance claim processing mechanism to prevent and minimize fraud in response to this prevailing issue. All entities patients, providers, and insurance companies actively participate in the claim submission, approval, and acknowledgment process through a multi-signature technique. Also, every activity is captured and recorded in the blockchain using smart contracts to make every action transparent and accountable so that no entity can deny its actions and responsibilities. Blockchains' immutable storage property and strong integrity guarantee that recorded activities are not modified. As healthcare systems and insurance companies continue to deal with fraud challenges, this proposed approach holds the potential to significantly reduce fraudulent activities, ultimately benefiting both insurers and policyholders.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "2024 IEEE 4th International Conference on Emerging Trends in Networks and Computer Communications (ETNCC 2024"
    },
    {
        "paper id": "2407.20264",
        "abstract url": "https://arxiv.org/abs/2407.20264",
        "title": "Beam Focusing for Near-Field Multi-User Localization",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Extremely large-scale antenna arrays are poised to play a pivotal role in sixth-generation (6G) networks. Utilizing such arrays often results in a near-field spherical wave transmission environment, enabling the generation of focused beams, which introduces new degrees of freedom for wireless localization. In this paper, we consider a beam-focusing design for localizing multiple sources in the radiating near-field. Our formulation accommodates various expected types of implementations of large antenna arrays, including hybrid analog/digital architectures and dynamic metasurface antennas (DMAs). We consider a direct localization estimation method exploiting curvature-of-arrival of impinging spherical wavefront to obtain user positions. In this regard, we adopt a two-stage approach configuring the array to optimize near-field positioning. In the first step, we focus only on adjusting the array coefficients to minimize the estimation error. We obtain a closed-form approximate solution based on projection and the better one based on the Riemann gradient algorithm. We then extend this approach to simultaneously localize and focus the beams via a sub-optimal iterative approach that does not rely on such knowledge. The simulation results show that near-field localization accuracy based on a hybrid array or DMA can achieve performance close to that of fully digital arrays at a lower cost, and DMAs can attain better performance than hybrid solutions with the same aperture.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures"
    },
    {
        "paper id": "2407.17161",
        "abstract url": "https://arxiv.org/abs/2407.17161",
        "title": "Quantum Supervised Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in quantum computing have positioned it as a prospective solution for tackling intricate computational challenges, with supervised learning emerging as a promising domain for its application. Despite this potential, the field of quantum machine learning is still in its early stages, and there persists a level of skepticism regarding a possible near-term quantum advantage. This paper aims to provide a classical perspective on current quantum algorithms for supervised learning, effectively bridging traditional machine learning principles with advancements in quantum machine learning. Specifically, this study charts a research trajectory that diverges from the predominant focus of quantum machine learning literature, originating from the prerequisites of classical methodologies and elucidating the potential impact of quantum approaches. Through this exploration, our objective is to deepen the understanding of the convergence between classical and quantum methods, thereby laying the groundwork for future advancements in both domains and fostering the involvement of classical practitioners in the field of quantum machine learning.",
        "subjects": [
            "cs.LG",
            "quant-ph"
        ],
        "comment": "16 pages, 3 figures, 1 table"
    },
    {
        "paper id": "2407.17329",
        "abstract url": "https://arxiv.org/abs/2407.17329",
        "title": "Low dimensional representation of multi-patient flow cytometry datasets using optimal transport for minimal residual disease detection in leukemia",
        "rating": "-2.5",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "cancer",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Representing and quantifying Minimal Residual Disease (MRD) in Acute Myeloid Leukemia (AML), a type of cancer that affects the blood and bone marrow, is essential in the prognosis and follow-up of AML patients. As traditional cytological analysis cannot detect leukemia cells below 5\\%, the analysis of flow cytometry dataset is expected to provide more reliable results. In this paper, we explore statistical learning methods based on optimal transport (OT) to achieve a relevant low-dimensional representation of multi-patient flow cytometry measurements (FCM) datasets considered as high-dimensional probability distributions. Using the framework of OT, we justify the use of the K-means algorithm for dimensionality reduction of multiple large-scale point clouds through mean measure quantization by merging all the data into a single point cloud. After this quantization step, the visualization of the intra and inter-patients FCM variability is carried out by embedding low-dimensional quantized probability measures into a linear space using either Wasserstein Principal Component Analysis (PCA) through linearized OT or log-ratio PCA of compositional data. Using a publicly available FCM dataset and a FCM dataset from Bordeaux University Hospital, we demonstrate the benefits of our approach over the popular kernel mean embedding technique for statistical learning from multiple high-dimensional probability distributions. We also highlight the usefulness of our methodology for low-dimensional projection and clustering patient measurements according to their level of MRD in AML from FCM. In particular, our OT-based approach allows a relevant and informative two-dimensional representation of the results of the FlowSom algorithm, a state-of-the-art method for the detection of MRD in AML using multi-patient FCM.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17417",
        "abstract url": "https://arxiv.org/abs/2407.17417",
        "title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?",
        "rating": "-2.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this paper, we first investigate the effectiveness of watermarking LLMs as a deterrent against the generation of copyrighted texts. Through theoretical analysis and empirical evaluation, we demonstrate that incorporating watermarks into LLMs significantly reduces the likelihood of generating copyrighted content, thereby addressing a critical concern in the deployment of LLMs. Additionally, we explore the impact of watermarking on Membership Inference Attacks (MIAs), which aim to discern whether a sample was part of the pretraining dataset and may be used to detect copyright violations. Surprisingly, we find that watermarking adversely affects the success rate of MIAs, complicating the task of detecting copyrighted text in the pretraining dataset. Finally, we propose an adaptive technique to improve the success rate of a recent MIA under watermarking. Our findings underscore the importance of developing adaptive methods to study critical problems in LLMs with potential legal implications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 6 figures"
    },
    {
        "paper id": "2407.17441",
        "abstract url": "https://arxiv.org/abs/2407.17441",
        "title": "Gender disparities in the dissemination and acquisition of scientific knowledge",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "physics"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Recent research has challenged the widespread belief that gender inequities in academia would disappear simply by increasing the number of women. More complex causes might be at play, embodied in the networked structure of scientific collaborations. Here, we aim to understand the structural inequality between male and female scholars in the dissemination of scientific knowledge. We use a large-scale dataset of academic publications from the American Physical Society (APS) to build a time-varying network of collaborations from 1970 to 2020. We model knowledge dissemination as a contagion process in which scientists become informed based on the propagation of knowledge through their collaborators. We quantify the fairness of the system in terms of how women acquire and diffuse knowledge compared to men. Our results indicate that knowledge acquisition and diffusion are slower for women than expected. We find that the main determinant of women's disadvantage is the gap in the cumulative number of collaborators, highlighting how time creates structural disadvantages that contribute to marginalize women in physics. Our work sheds light on how the dynamics of scientific collaborations shape gender disparities in knowledge dissemination and calls for a deeper understanding on how to intervene to improve fairness and diversity in the scientific community.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17703",
        "abstract url": "https://arxiv.org/abs/2407.17703",
        "title": "Context-aware knowledge graph framework for traffic speed forecasting using graph neural network",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Human mobility is intricately influenced by urban contexts spatially and temporally, constituting essential domain knowledge in understanding traffic systems. While existing traffic forecasting models primarily rely on raw traffic data and advanced deep learning techniques, incorporating contextual information remains underexplored due to the lack of effective integration frameworks and the complexity of urban contexts. This study proposes a novel context-aware knowledge graph (CKG) framework to enhance traffic speed forecasting by effectively modeling spatial and temporal contexts. Employing a relation-dependent integration strategy, the framework generates context-aware representations from the spatial and temporal units of CKG to capture spatio-temporal dependencies of urban contexts. A CKG-GNN model, combining the CKG, dual-view multi-head self-attention (MHSA), and graph neural network (GNN), is then designed to predict traffic speed using these context-aware representations. Our experiments demonstrate that CKG's configuration significantly influences embedding performance, with ComplEx and KG2E emerging as optimal for embedding spatial and temporal units, respectively. The CKG-GNN model surpasses benchmark models, achieving an average MAE of $3.46\\pm0.01$ and a MAPE of $14.76\\pm0.09\\%$ for traffic speed predictions from 10 to 120 minutes. The dual-view MHSA analysis reveals the crucial role of relation-dependent features from the context-based view and the model's ability to prioritize recent time slots in prediction from the sequence-based view. The CKG framework's model-agnostic nature suggests its potential applicability in various applications of intelligent transportation systems. Overall, this study underscores the importance of incorporating domain-specific contexts into traffic forecasting and merging context-aware knowledge graphs with neural networks to enhance accuracy.",
        "subjects": [
            "cs.LG",
            "physics.soc-ph"
        ],
        "comment": "13 pages, 4 figures"
    },
    {
        "paper id": "2407.17722",
        "abstract url": "https://arxiv.org/abs/2407.17722",
        "title": "Text-Driven Neural Collaborative Filtering Model for Paper Source Tracing",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Identifying significant references within the complex interrelations of a citation knowledge graph is challenging, which encompasses connections through citations, authorship, keywords, and other relational attributes. The Paper Source Tracing (PST) task seeks to automate the identification of pivotal references for given scholarly articles utilizing advanced data mining techniques. In the KDD CUP 2024, we design a recommendation-based framework tailored for the PST task. This framework employs the Neural Collaborative Filtering (NCF) model to generate final predictions. To process the textual attributes of the papers and extract input features for the model, we utilize SciBERT, a pre-trained language model. According to the experimental results, our method achieved a score of 0.37814 on the Mean Average Precision (MAP) metric, outperforming baseline models and ranking 11th among all participating teams. The source code is publicly available at https://github.com/MyLove-XAB/KDDCupFinal.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "KDD CUP 2024 OAG-Challenges, Paper Source Tracing, Technical Report of Team AoboSama @ KDD CUP 2024. August 25--29, 2024. Barcelona, Spain"
    },
    {
        "paper id": "2407.17723",
        "abstract url": "https://arxiv.org/abs/2407.17723",
        "title": "Your Graph Recommender is Provably a Single-view Graph Contrastive Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph recommender (GR) is a type of graph neural network (GNNs) encoder that is customized for extracting information from the user-item interaction graph. Due to its strong performance on the recommendation task, GR has gained significant attention recently. Graph contrastive learning (GCL) is also a popular research direction that aims to learn, often unsupervised, GNNs with certain contrastive objectives. As a general graph representation learning method, GCLs have been widely adopted with the supervised recommendation loss for joint training of GRs. Despite the intersection of GR and GCL research, theoretical understanding of the relationship between the two fields is surprisingly sparse. This vacancy inevitably leads to inefficient scientific research. In this paper, we aim to bridge the gap between the field of GR and GCL from the perspective of encoders and loss functions. With mild assumptions, we theoretically show an astonishing fact that graph recommender is equivalent to a commonly-used single-view graph contrastive model. Specifically, we find that (1) the classic encoder in GR is essentially a linear graph convolutional network with one-hot inputs, and (2) the loss function in GR is well bounded by a single-view GCL loss with certain hyperparameters. The first observation enables us to explain crucial designs of GR models, e.g., the removal of self-loop and nonlinearity. And the second finding can easily prompt many cross-field research directions. We empirically show a remarkable result that the recommendation loss and the GCL loss can be used interchangeably. The fact that we can train GR models solely with the GCL loss is particularly insightful, since before this work, GCLs were typically viewed as unsupervised methods that need fine-tuning. We also discuss some potential future works inspired by our theory.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17044",
        "abstract url": "https://arxiv.org/abs/2407.17044",
        "title": "The Rise of UAV Fleet Technologies for Emergency Wireless Communications in Harsh Environments",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "For unforeseen emergencies, such as natural disasters and pandemic events, it is highly demanded to cope with the explosive growth of mobile data traffic in extremely critical environments. An Unmanned aerial vehicle (UAV) fleet is an effective way to facilitate the Emergency wireless COmmunication NETwork (EcoNet). In this article, a MUlti-tier Heterogeneous UAV Network (MuHun), which is with different UAV fleets in different altitudes, is proposed to flexibly serve various emergencies. We refresh the key performance indicators of full coverage, network capacity, low latency, and energy efficiency in harsh environments. Then, we present the special challenges regarding shadowing-dominated complex channel model, energy supply limited short-endurance, various communication mechanisms coexistence, and communication island for underground users in UAV-based EcoNet, followed by the MuHun-based EcoNet architecture and its advantages. Furthermore, some potential solutions such as the new hybrid-channel adapted resource allocation, reconfigurable intelligent surface assisted UAV communications, competitive heterogenous-networks, and magnetic induction based air-to-ground/underground communications are discussed to effectively achieve full coverage, high capacity, high energy efficiency, and diverse qualities of services for EcoNets in harsh environments.",
        "subjects": [
            "cs.ET",
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17108",
        "abstract url": "https://arxiv.org/abs/2407.17108",
        "title": "Quanv4EO: Empowering Earth Observation by means of Quanvolutional Neural Networks",
        "rating": "-3",
        "keywords": [
            [
                "remotely sensed"
            ],
            [
                "quantum"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "A significant amount of remotely sensed data is generated daily by many Earth observation (EO) spaceborne and airborne sensors over different countries of our planet. Different applications use those data, such as natural hazard monitoring, global climate change, urban planning, and more. Many challenges are brought by the use of these big data in the context of remote sensing applications. In recent years, employment of machine learning (ML) and deep learning (DL)-based algorithms have allowed a more efficient use of these data but the issues in managing, processing, and efficiently exploiting them have even increased since classical computers have reached their limits. This article highlights a significant shift towards leveraging quantum computing techniques in processing large volumes of remote sensing data. The proposed Quanv4EO model introduces a quanvolution method for preprocessing multi-dimensional EO data. First its effectiveness is demonstrated through image classification tasks on MNIST and Fashion MNIST datasets, and later on, its capabilities on remote sensing image classification and filtering are shown. Key findings suggest that the proposed model not only maintains high precision in image classification but also shows improvements of around 5\\% in EO use cases compared to classical approaches. Moreover, the proposed framework stands out for its reduced parameter size and the absence of training quantum kernels, enabling better scalability for processing massive datasets. These advancements underscore the promising potential of quantum computing in addressing the limitations of classical algorithms in remote sensing applications, offering a more efficient and effective alternative for image data classification and analysis.",
        "subjects": [
            "eess.IV",
            "cs.ET",
            "quant-ph"
        ],
        "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2407.17186",
        "abstract url": "https://arxiv.org/abs/2407.17186",
        "title": "Semantic Vehicle-to-Everything (V2X) Communications Towards 6G",
        "rating": "-3",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "Semantic Communication (SEM-COM) has emerged as one of the disruptive technologies facilitating the evolution towards sixth-generation (6G) wireless networks. This article presents the potential of SEM-COM to transform Vehicle-to-Everything (V2X) communications, with a particular emphasis on its ability to enhance communication efficiency and intelligence. We discuss the core components and metrics that characterize SEM-COM, providing insights into its operational framework within the context of V2X communications. We illustrate the applicability and practicality of SEM-COM through real-world vehicular use cases, demonstrate the potential of SEM-COM to enhance aspects of intelligent mobility, such as communication efficiency and decision-making. Finally, the article identifies key open research questions for SEM-COM V2X, pointing to areas that require further exploration and thus setting a foundation for future work in this evolving domain.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2407.17219",
        "abstract url": "https://arxiv.org/abs/2407.17219",
        "title": "Graph Neural Networks: A suitable Alternative to MLPs in Latent 3D Medical Image Classification?",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent studies have underscored the capabilities of natural imaging foundation models to serve as powerful feature extractors, even in a zero-shot setting for medical imaging data. Most commonly, a shallow multi-layer perceptron (MLP) is appended to the feature extractor to facilitate end-to-end learning and downstream prediction tasks such as classification, thus representing the de facto standard. However, as graph neural networks (GNNs) have become a practicable choice for various tasks in medical research in the recent past, we direct attention to the question of how effective GNNs are compared to MLP prediction heads for the task of 3D medical image classification, proposing them as a potential alternative. In our experiments, we devise a subject-level graph for each volumetric dataset instance. Therein latent representations of all slices in the volume, encoded through a DINOv2 pretrained vision transformer (ViT), constitute the nodes and their respective node features. We use public datasets to compare the classification heads numerically and evaluate various graph construction and graph convolution methods in our experiments. Our findings show enhancements of the GNN in classification performance and substantial improvements in runtime compared to an MLP prediction head. Additional robustness evaluations further validate the promising performance of the GNN, promoting them as a suitable alternative to traditional MLP classification heads. Our code is publicly available at: https://github.com/compai-lab/2024-miccai-grail-kiechle",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at MICCAI 2024 - GRAIL Workshop"
    },
    {
        "paper id": "2407.17234",
        "abstract url": "https://arxiv.org/abs/2407.17234",
        "title": "Intent-guided Heterogeneous Graph Contrastive Learning for Recommendation",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Contrastive Learning (CL)-based recommender systems have gained prominence in the context of Heterogeneous Graph (HG) due to their capacity to enhance the consistency of representations across different views. However, existing frameworks often neglect the fact that user-item interactions within HG are governed by diverse latent intents (e.g., brand preferences or demographic characteristics of item audiences), which are pivotal in capturing fine-grained relations. The exploration of these underlying intents, particularly through the lens of meta-paths in HGs, presents us with two principal challenges: i) How to integrate CL with intents; ii) How to mitigate noise from meta-path-driven intents. To address these challenges, we propose an innovative framework termed Intent-guided Heterogeneous Graph Contrastive Learning (IHGCL), which designed to enhance CL-based recommendation by capturing the intents contained within meta-paths. Specifically, the IHGCL framework includes: i) a meta-path-based Dual Contrastive Learning (DCL) approach to effectively integrate intents into the recommendation, constructing intent-intent contrast and intent-interaction contrast; ii) a Bottlenecked AutoEncoder (BAE) that combines mask propagation with the information bottleneck principle to significantly reduce noise perturbations introduced by meta-paths. Empirical evaluations conducted across six distinct datasets demonstrate the superior performance of our IHGCL framework relative to conventional baseline methods. Our model implementation is available at https://github.com/wangyu0627/IHGCL.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "14pages, 11figures"
    },
    {
        "paper id": "2407.17253",
        "abstract url": "https://arxiv.org/abs/2407.17253",
        "title": "The impact of differences in facial features between real speakers and 3D face models on synthesized lip motions",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "facial"
            ]
        ],
        "abstract": "Lip motion accuracy is important for speech intelligibility, especially for users who are hard of hearing or second language learners. A high level of realism in lip movements is also required for the game and film production industries. 3D morphable models (3DMMs) have been widely used for facial analysis and animation. However, factors that could influence their use in facial animation, such as the differences in facial features between recorded real faces and animated synthetic faces, have not been given adequate attention. This paper investigates the mapping between real speakers and similar and non-similar 3DMMs and the impact on the resulting 3D lip motion. Mouth height and mouth width are used to determine face similarity. The results show that mapping 2D videos of real speakers with low mouth heights to 3D heads that correspond to real speakers with high mouth heights, or vice versa, generates less good 3D lip motion. It is thus important that such a mismatch is considered when using a 2D recording of a real actor's lip movements to control a 3D synthetic character.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "21 pages, 17 figures"
    },
    {
        "paper id": "2407.17321",
        "abstract url": "https://arxiv.org/abs/2407.17321",
        "title": "Energy Efficiency Optimization in Integrated Satellite-Terrestrial UAV-Enabled Cell-Free Massive MIMO",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "UAV",
                "Satellite"
            ]
        ],
        "abstract": "Integrating cell-free massive MIMO (CF-mMIMO) into satellite-unmanned aerial vehicle (UAV) networks offers an effective solution for enhancing connectivity. In this setup, UAVs serve as access points (APs) of a terrestrial CF-mMIMO network extending the satellite network capabilities, thereby ensuring robust, high-quality communication links. In this work, we propose a successive convex approximation algorithm for maximizing the downlink energy efficiency (EE) at the UAVs under per-UAV power budget and user quality-of-service constraints. We derive a closed-form expression for the EE that accounts for maximum-ratio transmission and statistical channel knowledge at the users. Simulation results show the effectiveness of the proposed algorithm in maximizing the EE at the UAV layer. Moreover, we observe that a few tens of UAVs transmitting with a fine-tuned power are sufficient to empower the service of satellite networks and significantly increase the spectral efficiency.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Paper accepted for presentation at SPAWC, Lucca (Italy), September 10-13, 2024. \u00a9 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses"
    },
    {
        "paper id": "2407.17380",
        "abstract url": "https://arxiv.org/abs/2407.17380",
        "title": "2D and 3D Deep Learning Models for MRI-based Parkinson's Disease Classification: A Comparative Analysis of Convolutional Kolmogorov-Arnold Networks, Convolutional Neural Networks, and Graph Convolutional Networks",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "diagnosis",
                "MRI",
                "Disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Early and accurate diagnosis of Parkinson's Disease (PD) remains challenging. This study compares deep learning architectures for MRI-based PD classification, introducing the first three-dimensional (3D) implementation of Convolutional Kolmogorov-Arnold Networks (ConvKANs), a new approach that combines convolution layers with adaptive, spline-based activations. We evaluated Convolutional Neural Networks (CNNs), ConvKANs, and Graph Convolutional Networks (GCNs) using three open-source datasets; a total of 142 participants (75 with PD and 67 age-matched healthy controls). For 2D analysis, we extracted 100 axial slices centred on the midbrain from each T1-weighted scan. For 3D analysis, we used the entire volumetric scans. ConvKANs integrate learnable B-spline functions with convolutional layers. GCNs represent MRI data as graphs, theoretically capturing structural relationships that may be overlooked by traditional approaches. Interpretability visualizations, including the first ConvKAN spline activation maps, and projections of graph node embeddings, were depicted. ConvKANs demonstrated high performance across datasets and dimensionalities, achieving the highest 2D AUROC (0.98) in one dataset and matching CNN peak 3D performance (1.00). CNN models performed well, while GCN models improved in 3D analyses, reaching up to 0.97 AUROC. 3D implementations yielded higher AUROC values compared to 2D counterparts across all models. ConvKAN implementation shows promise for MRI analysis in PD classification, particularly in the context of early diagnosis. The improvement in 3D analyses highlights the value of volumetric data in capturing subtle PD-related changes. While MRI is not currently used for PD diagnosis, these findings suggest its potential as a component of a multimodal diagnostic approach, especially for early detection.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "q-bio.QM"
        ],
        "comment": "19 Pages, 5 figures"
    },
    {
        "paper id": "2407.17392",
        "abstract url": "https://arxiv.org/abs/2407.17392",
        "title": "Sampling-Based Hierarchical Trajectory Planning for Formation Flight",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory",
                "Flight"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Formation flight of unmanned aerial vehicles (UAVs) poses significant challenges in terms of safety and formation keeping, particularly in cluttered environments. However, existing methods often struggle to simultaneously satisfy these two critical requirements. To address this issue, this paper proposes a sampling-based trajectory planning method with a hierarchical structure for formation flight in dense obstacle environments. To ensure reliable local sensing information sharing among UAVs, each UAV generates a safe flight corridor (SFC), which is transmitted to the leader UAV. Subsequently, a sampling-based formation guidance path generation method is designed as the front-end strategy, steering the formation to fly in the desired shape safely with the formation connectivity provided by the SFCs. Furthermore, a model predictive path integral (MPPI) based distributed trajectory optimization method is developed as the back-end part, which ensures the smoothness, safety and dynamics feasibility of the executable trajectory. To validate the efficiency of the developed algorithm, comprehensive simulation comparisons are conducted. The supplementary simulation video can be seen at https://www.youtube.com/watch?v=xSxbUN0tn1M.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17432",
        "abstract url": "https://arxiv.org/abs/2407.17432",
        "title": "An FPGA-Based Open-Source Hardware-Software Framework for Side-Channel Security Research",
        "rating": "-3",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "IoT",
                "FPGA"
            ]
        ],
        "abstract": "Attacks based on side-channel analysis (SCA) pose a severe security threat to modern computing platforms, further exacerbated on IoT devices by their pervasiveness and handling of private and critical data. Designing SCA-resistant computing platforms requires a significant additional effort in the early stages of the IoT devices' life cycle, which is severely constrained by strict time-to-market deadlines and tight budgets. This manuscript introduces a hardware-software framework meant for SCA research on FPGA targets. It delivers an IoT-class system-on-chip (SoC) that includes a RISC-V CPU, provides observability and controllability through an ad-hoc debug infrastructure to facilitate SCA attacks and evaluate the platform's security, and streamlines the deployment of SCA countermeasures through dedicated hardware and software features such as a DFS actuator and FreeRTOS support. The open-source release of the framework includes the SoC, the scripts to configure the computing platform, compile a target application, and assess the SCA security, as well as a suite of state-of-the-art SCA attacks and countermeasures. The goal is to foster its adoption and novel developments in the field, empowering designers and researchers to focus on studying SCA countermeasures and attacks while relying on a sound and stable hardware-software platform as the foundation for their research.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2407.17464",
        "abstract url": "https://arxiv.org/abs/2407.17464",
        "title": "Toward human-centered shared autonomy AI paradigms for human-robot teaming in healthcare",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "healthcare"
            ]
        ],
        "abstract": "With recent advancements in AI and computation tools, intelligent paradigms emerged to empower different fields such as healthcare robots with new capabilities. Advanced AI robotic algorithms (e.g., reinforcement learning) can be trained and developed to autonomously make individual decisions to achieve a desired and usually fixed goal. However, such independent decisions and goal achievements might not be ideal for a healthcare robot that usually interacts with a dynamic end-user or a patient. In such a complex human-robot interaction (teaming) framework, the dynamic user continuously wants to be involved in decision-making as well as introducing new goals while interacting with their present environment in real-time. To address this challenge, an adaptive shared autonomy AI paradigm is required to be developed for the two interactive agents (Human & AI agents) with a foundation based on human-centered factors to avoid any possible ethical issues and guarantee no harm to humanity.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2407.17617",
        "abstract url": "https://arxiv.org/abs/2407.17617",
        "title": "Adaptive Robot Detumbling of a Non-Rigid Satellite",
        "rating": "-3",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "The challenge of satellite stabilization, particularly those with uncertain flexible dynamics, has become a pressing concern in control and robotics. These uncertainties, especially the dynamics of a third-party client satellite, significantly complicate the stabilization task. This paper introduces a novel adaptive detumbling method to handle non-rigid satellites with unknown motion dynamics (translation and rotation). The distinctive feature of our approach is that we model the non-rigid tumbling satellite as a two-link serial chain with unknown stiffness and damping in contrast to previous detumbling research works which consider the satellite a rigid body. We develop a novel adaptive robotics approach to detumble the satellite by using two space tugs as servicer despite the uncertain dynamics in the post-capture case. Notably, the stiffness properties and other physical parameters, including the mass and inertia of the two links, remain unknown to the servicer. Our proposed method addresses the challenges in detumbling tasks and paves the way for advanced manipulation of non-rigid satellites with uncertain dynamics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been accepted by the 63rd IEEE Conference on Decision and Control(CDC2024) as a regular paper"
    },
    {
        "paper id": "2407.17709",
        "abstract url": "https://arxiv.org/abs/2407.17709",
        "title": "PGD-VIO: An Accurate Plane-Aided Visual-Inertial Odometry with Graph-Based Drift Suppression",
        "rating": "-3",
        "keywords": [
            [
                "RGBD",
                "Depth"
            ],
            [
                "navigation"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "Generally, high-level features provide more geometrical information compared to point features, which can be exploited to further constrain motions. Planes are commonplace in man-made environments, offering an active means to reduce drift, due to their extensive spatial and temporal observability. To make full use of planar information, we propose a novel visual-inertial odometry (VIO) using an RGBD camera and an inertial measurement unit (IMU), effectively integrating point and plane features in an extended Kalman filter (EKF) framework. Depth information of point features is leveraged to improve the accuracy of point triangulation, while plane features serve as direct observations added into the state vector. Notably, to benefit long-term navigation,a novel graph-based drift detection strategy is proposed to search overlapping and identical structures in the plane map so that the cumulative drift is suppressed subsequently. The experimental results on two public datasets demonstrate that our system outperforms state-of-the-art methods in localization accuracy and meanwhile generates a compact and consistent plane map, free of expensive global bundle adjustment and loop closing techniques.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17087",
        "abstract url": "https://arxiv.org/abs/2407.17087",
        "title": "Assessing Non-Nested Configurations of Multifidelity Machine Learning for Quantum-Chemical Properties",
        "rating": "-3.5",
        "keywords": [
            [
                "chemistry",
                "Chemical"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multifidelity machine learning (MFML) for quantum chemical (QC) properties has seen strong development in the recent years. The method has been shown to reduce the cost of generating training data for high-accuracy low-cost ML models. In such a set-up, the ML models are trained on molecular geometries and some property of interest computed at various computational chemistry accuracies, or fidelities. These are then combined in training the MFML models. In some multifidelity models, the training data is required to be nested, that is the same molecular geometries are included to calculate the property across all the fidelities. In these multifidelity models, the requirement of a nested configuration restricts the kind of sampling that can be performed while selection training samples at different fidelities. This work assesses the use of non-nested training data for two of these multifidelity methods, namely MFML and optimized MFML (o-MFML). The assessment is carried out for the prediction of ground state energies and first vertical excitation energies of a diverse collection of molecules of the CheMFi dataset. Results indicate that the MFML method still requires a nested structure of training data across the fidelities. However, the o-MFML method shows promising results for non-nested multifidelity training data with model errors comparable to the nested configurations.",
        "subjects": [
            "physics.chem-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17228",
        "abstract url": "https://arxiv.org/abs/2407.17228",
        "title": "A Hybrid Federated Kernel Regularized Least Squares Algorithm",
        "rating": "-3.5",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "attacks"
            ],
            [
                "biosamples",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning is becoming an increasingly viable and accepted strategy for building machine learning models in critical privacy-preserving scenarios such as clinical settings. Often, the data involved is not limited to clinical data but also includes additional omics features (e.g. proteomics). Consequently, data is distributed not only across hospitals but also across omics centers, which are labs capable of generating such additional features from biosamples. This scenario leads to a hybrid setting where data is scattered both in terms of samples and features. In this hybrid setting, we present an efficient reformulation of the Kernel Regularized Least Squares algorithm, introduce two variants and validate them using well-established datasets. Lastly, we discuss security measures to defend against possible attacks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17236",
        "abstract url": "https://arxiv.org/abs/2407.17236",
        "title": "Statistical Batch-Based Bearing Fault Detection",
        "rating": "-3.5",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the domain of rotating machinery, bearings are vulnerable to different mechanical faults, including ball, inner, and outer race faults. Various techniques can be used in condition-based monitoring, from classical signal analysis to deep learning methods. Based on the complex working conditions of rotary machines, multivariate statistical process control charts such as Hotelling's $T^2$ and Squared Prediction Error are useful for providing early warnings. However, these methods are rarely applied to condition monitoring of rotating machinery due to the univariate nature of the datasets. In the present paper, we propose a multivariate statistical process control-based fault detection method that utilizes multivariate data composed of Fourier transform features extracted for fixed-time batches. Our approach makes use of the multidimensional nature of Fourier transform characteristics, which record more detailed information about the machine's status, in an effort to enhance early defect detection and diagnosis. Experiments with varying vibration measurement locations (Fan End, Drive End), fault types (ball, inner, and outer race faults), and motor loads (0-3 horsepower) are used to validate the suggested approach. The outcomes illustrate our method's effectiveness in fault detection and point to possible broader uses in industrial maintenance.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17674",
        "abstract url": "https://arxiv.org/abs/2407.17674",
        "title": "Synthetic High-resolution Cryo-EM Density Maps with Generative Adversarial Networks",
        "rating": "-3.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "GAN"
            ],
            [
                "biology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generating synthetic cryogenic electron microscopy (cryo-EM) 3D density maps from molecular structures has potential important applications in structural biology. Yet existing simulation-based methods cannot mimic all the complex features present in experimental maps, such as secondary structure elements. As an alternative, we propose struc2mapGAN, a novel data-driven method that employs a generative adversarial network (GAN) to produce high-resolution experimental-like density maps from molecular structures. More specifically, struc2mapGAN uses a U-Net++ architecture as the generator, with an additional L1 loss term and further processing of raw experimental maps to enhance learning efficiency. While struc2mapGAN can promptly generate maps after training, we demonstrate that it outperforms existing simulation-based methods for a wide array of tested maps and across various evaluation metrics. Our code is available at https://github.com/chenwei-zhang/struc2mapGAN.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17706",
        "abstract url": "https://arxiv.org/abs/2407.17706",
        "title": "Investigating and Mitigating Barren Plateaus in Variational Quantum Circuits: A Survey",
        "rating": "-3.5",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, variational quantum circuits (VQCs) have been widely explored to advance quantum circuits against classic models on various domains, such as quantum chemistry and quantum machine learning. Similar to classic machine-learning models, VQCs can be optimized through gradient-based approaches. However, the gradient variance of VQCs may dramatically vanish as the number of qubits or layers increases. This issue, a.k.a. Barren Plateaus (BPs), seriously hinders the scaling of VQCs on large datasets. To mitigate the exponential gradient vanishing, extensive efforts have been devoted to tackling this issue through diverse strategies. In this survey, we conduct a systematic literature review of recent works from both investigation and mitigation perspectives. Besides, we propose a new taxonomy to categorize most existing mitigation strategies. At last, we provide insightful discussion for future directions of BPs.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "preprint, under review. Please feel free to reach out if your work fits within our scope"
    },
    {
        "paper id": "2407.20267",
        "abstract url": "https://arxiv.org/abs/2407.20267",
        "title": "A Large Encoder-Decoder Family of Foundation Models For Chemical Language",
        "rating": "-3.5",
        "keywords": [
            [
                "Chemical"
            ],
            [
                "quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large-scale pre-training methodologies for chemical language models represent a breakthrough in cheminformatics. These methods excel in tasks such as property prediction and molecule generation by learning contextualized representations of input tokens through self-supervised learning on large unlabeled corpora. Typically, this involves pre-training on unlabeled data followed by fine-tuning on specific tasks, reducing dependence on annotated datasets and broadening chemical language representation understanding. This paper introduces a large encoder-decoder chemical foundation models pre-trained on a curated dataset of 91 million SMILES samples sourced from PubChem, which is equivalent to 4 billion of molecular tokens. The proposed foundation model supports different complex tasks, including quantum property prediction, and offer flexibility with two main variants (289M and $8\\times289M$). Our experiments across multiple benchmark datasets validate the capacity of the proposed model in providing state-of-the-art results for different tasks. We also provide a preliminary assessment of the compositionality of the embedding space as a prerequisite for the reasoning tasks. We demonstrate that the produced latent space is separable compared to the state-of-the-art with few-shot learning capabilities.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.chem-ph"
        ],
        "comment": "14 pages, 3 figures, 14 tables"
    },
    {
        "paper id": "2407.17312",
        "abstract url": "https://arxiv.org/abs/2407.17312",
        "title": "Physical Adversarial Attack on Monocular Depth Estimation via Shape-Varying Patches",
        "rating": "-4",
        "keywords": [
            [
                "Depth"
            ],
            [
                "autonomous driving"
            ],
            [
                "Attack"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Adversarial attacks against monocular depth estimation (MDE) systems pose significant challenges, particularly in safety-critical applications such as autonomous driving. Existing patch-based adversarial attacks for MDE are confined to the vicinity of the patch, making it difficult to affect the entire target. To address this limitation, we propose a physics-based adversarial attack on monocular depth estimation, employing a framework called Attack with Shape-Varying Patches (ASP), aiming to optimize patch content, shape, and position to maximize effectiveness. We introduce various mask shapes, including quadrilateral, rectangular, and circular masks, to enhance the flexibility and efficiency of the attack. Furthermore, we propose a new loss function to extend the influence of the patch beyond the overlapping regions. Experimental results demonstrate that our attack method generates an average depth error of 18 meters on the target car with a patch area of 1/9, affecting over 98\\% of the target area.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17572",
        "abstract url": "https://arxiv.org/abs/2407.17572",
        "title": "CityX: Controllable Procedural Content Generation for Unbounded 3D Cities",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "industrial"
            ],
            [
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Generating a realistic, large-scale 3D virtual city remains a complex challenge due to the involvement of numerous 3D assets, various city styles, and strict layout constraints. Existing approaches provide promising attempts at procedural content generation to create large-scale scenes using Blender agents. However, they face crucial issues such as difficulties in scaling up generation capability and achieving fine-grained control at the semantic layout level. To address these problems, we propose a novel multi-modal controllable procedural content generation method, named CityX, which enhances realistic, unbounded 3D city generation guided by multiple layout conditions, including OSM, semantic maps, and satellite images. Specifically, the proposed method contains a general protocol for integrating various PCG plugins and a multi-agent framework for transforming instructions into executable Blender actions. Through this effective framework, CityX shows the potential to build an innovative ecosystem for 3D scene generation by bridging the gap between the quality of generated assets and industrial requirements. Extensive experiments have demonstrated the effectiveness of our method in creating high-quality, diverse, and unbounded cities guided by multi-modal conditions. Our project page: https://cityx-lab.github.io.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17647",
        "abstract url": "https://arxiv.org/abs/2407.17647",
        "title": "An Energy-Efficient Artefact Detection Accelerator on FPGAs for Hyper-Spectral Satellite Imagery",
        "rating": "-4",
        "keywords": [
            [
                "FPGAs"
            ],
            [
                "remote sensing",
                "Satellite"
            ]
        ],
        "abstract": "Hyper-Spectral Imaging (HSI) is a crucial technique for analysing remote sensing data acquired from Earth observation satellites. The rich spatial and spectral information obtained through HSI allows for better characterisation and exploration of the Earth's surface over traditional techniques like RGB and Multi-Spectral imaging on the downlinked image data at ground stations. Sometimes, these images do not contain meaningful information due to the presence of clouds or other artefacts, limiting their usefulness. Transmission of such artefact HSI images leads to wasteful use of already scarce energy and time costs required for communication. While detecting such artefacts before transmitting the HSI image is desirable, the computational complexity of these algorithms and the limited power budget on satellites (especially CubeSats) are key constraints. This paper presents an unsupervised learning-based convolutional autoencoder (CAE) model for artefact identification of acquired HSI images at the satellite and a deployment architecture on AMD's Zynq Ultrascale FPGAs. The model is trained and tested on widely used HSI image datasets: Indian Pines, Salinas Valley, the University of Pavia and the Kennedy Space Center. For deployment, the model is quantised to 8-bit precision, fine-tuned using the Vitis-AI framework and integrated as a subordinate accelerator using AMD's Deep-Learning Processing Units (DPU) instance on the Zynq device. Our tests show that the model can process each spectral band in an HSI image in 4 ms, 2.6x better than INT8 inference on Nvidia's Jetson platform & 1.27x better than SOTA artefact detectors. Our model also achieves an f1-score of 92.8% and FPR of 0% across the dataset, while consuming 21.52 mJ per HSI image, 3.6x better than INT8 Jetson inference & 7.5x better than SOTA artefact detectors, making it a viable architecture for deployment in CubeSats.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17696",
        "abstract url": "https://arxiv.org/abs/2407.17696",
        "title": "Satellite Internet of Things Research Report",
        "rating": "-4",
        "keywords": [
            [
                "IoT"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Satellite IoT is an emerging technology that combines the advantages of satellite communication and IoT, providing global coverage, high reliability, and flexible networking. It has a wide range of applications in various fields, including smart agriculture, smart transportation, smart cities, environmental monitoring, and emergency response. With the continuous development of satellite communication, IoT, edge computing, cloud computing, AI, and ML technology, satellite IoT will play an increasingly important role in the future, supporting the digital transformation and sustainable development of society.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17756",
        "abstract url": "https://arxiv.org/abs/2407.17756",
        "title": "Preliminary Results of Neuromorphic Controller Design and a Parkinson's Disease Dataset Building for Closed-Loop Deep Brain Stimulation",
        "rating": "-4",
        "keywords": [
            [
                "biomarkers",
                "medical",
                "Disease",
                "physiological"
            ],
            [
                "FPGA"
            ]
        ],
        "abstract": "Parkinson's Disease afflicts millions of individuals globally. Emerging as a promising brain rehabilitation therapy for Parkinson's Disease, Closed-loop Deep Brain Stimulation (CL-DBS) aims to alleviate motor symptoms. The CL-DBS system comprises an implanted battery-powered medical device in the chest that sends stimulation signals to the brains of patients. These electrical stimulation signals are delivered to targeted brain regions via electrodes, with the magnitude of stimuli adjustable. However, current CL-DBS systems utilize energy-inefficient approaches, including reinforcement learning, fuzzy interface, and field-programmable gate array (FPGA), among others. These approaches make the traditional CL-DBS system impractical for implanted and wearable medical devices. This research proposes a novel neuromorphic approach that builds upon Leaky Integrate and Fire neuron (LIF) controllers to adjust the magnitude of DBS electric signals according to the various severities of PD patients. Our neuromorphic controllers, on-off LIF controller, and dual LIF controller, successfully reduced the power consumption of CL-DBS systems by 19% and 56%, respectively. Meanwhile, the suppression efficiency increased by 4.7% and 6.77%. Additionally, to address the data scarcity of Parkinson's Disease symptoms, we built Parkinson's Disease datasets that include the raw neural activities from the subthalamic nucleus at beta oscillations, which are typical physiological biomarkers for Parkinson's Disease.",
        "subjects": [
            "cs.NE",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17654",
        "abstract url": "https://arxiv.org/abs/2407.17654",
        "title": "Generative Learning for Simulation of Vehicle Faults",
        "rating": "-4.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "health"
            ],
            [
                "forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop a novel generative model to simulate vehicle health and forecast faults, conditioned on practical operational considerations. The model, trained on data from the US Army's Predictive Logistics program, aims to support predictive maintenance. It forecasts faults far enough in advance to execute a maintenance intervention before a breakdown occurs. The model incorporates real-world factors that affect vehicle health. It also allows us to understand the vehicle's condition by analyzing operating data, and characterizing each vehicle into discrete states. Importantly, the model predicts the time to first fault with high accuracy. We compare its performance to other models and demonstrate its successful training.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17094",
        "abstract url": "https://arxiv.org/abs/2407.17094",
        "title": "Resource Allocation for 5G-UAV Based Emergency Wireless Communications",
        "rating": "-5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "5G"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "For unforeseen natural disasters, such as earthquakes, hurricanes, and floods, etc., the traditional communication infrastructure is unavailable or seriously disrupted along with persistent secondary disasters. Under such circumstances, it is highly demanded to deploy emergency wireless communication (EWC) networks to restore connectivity in accident/incident areas. The emerging fifth-generation (5G)/beyond-5G (B5G) wireless communication system, like unmanned aerial vehicle (UAV) assisted networks and intelligent reflecting surface (IRS) based communication systems, are expected to be designed or re-farmed for supporting temporary high quality communications in post-disaster areas. However, the channel characteristics of post-disaster areas quickly change as the secondary disaster resulted topographical changes, imposing new but critical challenges for EWC networks. In this paper, we propose a novel heterogeneous $\\mathcal{F}$ composite fading channel model for EWC networks which accurately models and characterizes the composite fading channel with reflectors, path-loss exponent, fading, and shadowing parameters in 5G-UAV based EWC networks. Based on the model, we develop the optimal power allocation scheme with the simple closed-form expression and the numerical results based optimal joint bandwidth-power allocation scheme. We derive the corresponding capacities and compare the energy efficiency between IRS and traditional relay based 5G-UAVs. Numerical results show that the new heterogeneous Fisher-Snedecor $\\mathcal{F}$ composite fading channel adapted resource allocation schemes can achieve higher capacity and energy efficiency than those of traditional channel model adapted resource allocation schemes, thus providing better communications service for post-disaster areas.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17013",
        "abstract url": "https://arxiv.org/abs/2407.17013",
        "title": "Towards Indirect Data-Driven Predictive Control for Heating Phase of Thermoforming Process",
        "rating": "-10",
        "keywords": [],
        "abstract": "Shaping thermoplastic sheets into three-dimensional products is challenging since overheating results in failed manufactured parts and wasted material. To this end, we propose an indirect data-driven predictive control approach using Model Predictive Control (MPC) capable of handling temperature constraints and heating-power saturation while delivering enhanced precision, overshoot control, and settling times compared to state-of-the-art methods. We employ a Non-linear Auto-Regressive with Exogenous inputs (NARX) model to define a linear control-oriented model at each operating point. Using a high-fidelity simulator, several simulation studies have been conducted to evaluate the proposed method's robustness and performance under parametric uncertainty, indicating overshoot and average steady-state error less than $2^\\circ \\mathrm{C}$ and $0.7^\\circ \\mathrm{C}$ ($7^\\circ \\mathrm{C}$ and $2^\\circ \\mathrm{C}$) for the nominal (worst-case) scenario. Finally, we applied the proposed method to a lab-scale thermoforming platform, resulting in a close response to the simulation analysis with overshoot and average steady-state error metrics less than $5.3^\\circ \\mathrm{C}$ and $1^\\circ \\mathrm{C}$, respectively.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17038",
        "abstract url": "https://arxiv.org/abs/2407.17038",
        "title": "Cultural influence on RE activities: An extended analysis of state of the art",
        "rating": "-10",
        "keywords": [],
        "abstract": "Designing mobile software that aligns with cultural contexts is crucial for optimizing human-computer interaction. Considering cultural influences is essential not only for the actual set of functional/non-functional requirements, but also for the whole Requirement Engineering (RE) process. Without a clear understanding of cultural influences on RE activities, it's hardly possible to elaborate a correct and complete set of requirements. This research explores the impact of national culture on RE-related activities based on recent studies. We conducted a Systematic Literature Review (SLR) of studies published in 2019-2023 and compared them to an older SLR covering 2000-2018. We identified 17 relevant studies, extracted 33 cultural influences impacting RE activities, and mapped them to the Hofstede model, widely used for cultural analysis in software development research. Our work highlights the critical role of national culture in RE activities, summarizes current research trends, and helps practitioners consider cultural influences for mobile app/software development.",
        "subjects": [
            "cs.SE",
            "cs.HC"
        ],
        "comment": "Preprint. Accepted to the 26th International Conference on Mobile Human-Computer Interaction (MOBILEHCI Adjunct '24), September 30-October 3, 2024, Melbourne, Australia. ACM Digital Library. Final version to be published by ACM Digital Library (In Press)"
    },
    {
        "paper id": "2407.17045",
        "abstract url": "https://arxiv.org/abs/2407.17045",
        "title": "NewsUnfold: Creating a News-Reading Application That Indicates Linguistic Media Bias and Collects Feedback",
        "rating": "-10",
        "keywords": [],
        "abstract": "Media bias is a multifaceted problem, leading to one-sided views and impacting decision-making. A way to address digital media bias is to detect and indicate it automatically through machine-learning methods. However, such detection is limited due to the difficulty of obtaining reliable training data. Human-in-the-loop-based feedback mechanisms have proven an effective way to facilitate the data-gathering process. Therefore, we introduce and test feedback mechanisms for the media bias domain, which we then implement on NewsUnfold, a news-reading web application to collect reader feedback on machine-generated bias highlights within online news articles. Our approach augments dataset quality by significantly increasing inter-annotator agreement by 26.31% and improving classifier performance by 2.49%. As the first human-in-the-loop application for media bias, the feedback mechanism shows that a user-centric approach to media bias data collection can return reliable data while being scalable and evaluated as easy to use. NewsUnfold demonstrates that feedback mechanisms are a promising strategy to reduce data collection expenses and continuously update datasets to changes in context.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17076",
        "abstract url": "https://arxiv.org/abs/2407.17076",
        "title": "The Analytic Stockwell Transform and its Zeros",
        "rating": "-10",
        "keywords": [],
        "abstract": "A recent original line of research in time--frequency analysis has shifted the interest in energy maxima toward zeros. Initially motivated by the intriguing uniform spread of the zeros of the spectrogram of white noise, it has led to fruitful theoretical developments combining probability theory, complex analysis and signal processing. In this vein, the present work proposes a characterization of the zeros of the Stockwell Transform of white noise, which consists in an hybrid time--frequency multiresolution representation. First of all, an analytic version of the Stockwell Transform is designed. Then, analyticity is leveraged to establish a connection with the hyperbolic Gaussian Analytic Function, whose zero set is invariant under the isometries of the Poincar\u00e9 disk. Finally, the theoretical spatial statistics of the zeros of the hyperbolic Gaussian Analytic Function and the empirical statistics of the zeros the Analytic Stockwell Transform of white noise are compared through intensive Monte Carlo simulations, supporting the established connection. A publicly available documented Python toolbox accompanies this work.",
        "subjects": [
            "eess.SP",
            "math.MG",
            "math.PR",
            "stat.OT"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17086",
        "abstract url": "https://arxiv.org/abs/2407.17086",
        "title": "AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "While Swarm User Interfaces (SUIs) have succeeded in enriching tangible interaction experiences, their limitations in autonomous action planning have hindered the potential for personalized and dynamic interaction generation in tabletop games. Based on the AI-Gadget Kit we developed, this paper explores how to integrate LLM-driven agents within tabletop games to enable SUIs to execute complex interaction tasks. After defining the design space of this kit, we elucidate the method for designing agents that can extend the meta-actions of SUIs to complex motion planning. Furthermore, we introduce an add-on prompt method that simplifies the design process for four interaction behaviors and four interaction relationships in tabletop games. Lastly, we present several application scenarios that illustrate the potential of AI-Gadget Kit to construct personalized interaction in SUI tabletop games. We expect to use our work as a case study to inspire research on multi-agent-driven SUI for other scenarios with complex interaction tasks.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17104",
        "abstract url": "https://arxiv.org/abs/2407.17104",
        "title": "A simple hybrid linear and non-linear interpolation finite element for adaptive cracking elements method",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cracking Elements Method (CEM) is a numerical tool to simulate quasi-brittle fractures, which does not need remeshing, nodal enrichment, or complicated crack tracking strategy. The cracking elements used in the CEM can be considered as a special type of finite element implemented in the standard finite element frameworks. One disadvantage of CEM is that it uses nonlinear interpolation of the displacement field (Q8 or T6 elements), introducing more nodes and consequent computing efforts than the cases with elements using linear interpolation of the displacement field. Aiming at solving this problem, we propose a simple hybrid linear and non-linear interpolation finite element for adaptive cracking elements method in this work. A simple strategy is proposed for treating the elements with $p$ edge nodes $p\\in\\left[0,n\\right]$ and $n$ being the edge number of the element. Only a few codes are needed. Then, by only adding edge and center nodes on the elements experiencing cracking and keeping linear interpolation of the displacement field for the elements outside the cracking domain, the number of total nodes was reduced almost to half of the case using the conventional cracking elements. Numerical investigations prove that the new approach inherits all the advantages of CEM with greatly improved computing efficiency.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "It is very useful for FEM researchers"
    },
    {
        "paper id": "2407.17111",
        "abstract url": "https://arxiv.org/abs/2407.17111",
        "title": "News Ninja: Gamified Annotation of Linguistic Bias in Online News",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent research shows that visualizing linguistic bias mitigates its negative effects. However, reliable automatic detection methods to generate such visualizations require costly, knowledge-intensive training data. To facilitate data collection for media bias datasets, we present News Ninja, a game employing data-collecting game mechanics to generate a crowdsourced dataset. Before annotating sentences, players are educated on media bias via a tutorial. Our findings show that datasets gathered with crowdsourced workers trained on News Ninja can reach significantly higher inter-annotator agreements than expert and crowdsourced datasets with similar data quality. As News Ninja encourages continuous play, it allows datasets to adapt to the reception and contextualization of news over time, presenting a promising strategy to reduce data collection expenses, educate players, and promote long-term bias mitigation.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17127",
        "abstract url": "https://arxiv.org/abs/2407.17127",
        "title": "A quantitative probabilistic relational Hoare logic",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce eRHL, a program logic for reasoning about relational expectation properties of pairs of probabilistic programs. eRHL is quantitative, i.e., its pre- and post-conditions take values in the extended non-negative reals. Thanks to its quantitative assertions, eRHL overcomes randomness alignment restrictions from prior logics, including PRHL, a popular relational program logic used to reason about security of cryptographic constructions, and apRHL, a variant of PRHL for differential privacy. As a result, eRHL is the first relational probabilistic program logic to be supported by non-trivial soundness and completeness results for all almost surely terminating programs. We show that eRHL is sound and complete with respect to program equivalence, statistical distance, and differential privacy. We also show that every PRHL judgment is valid iff it is provable in eRHL. We showcase the practical benefits of eRHL with examples that are beyond reach of PRHL and apRHL.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17166",
        "abstract url": "https://arxiv.org/abs/2407.17166",
        "title": "The Architectural Refinement of \u03bcD3TN: Toward a Software-Defined DTN Protocol Stack",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper provides a comprehensive overview of the uD3TN project's development, detailing its transformation into a flexible and modular software implementation of the Delay-/Disruption-Tolerant Networking (DTN) Bundle Protocol. Originating from uPCN, designed for microcontrollers, uD3TN has undergone significant architectural refinement to increase flexibility, compatibility, and performance across various DTN applications. Key developments include achieving platform independence, supporting multiple Bundle Protocol versions concurrently, introducing abstract Convergence Layer Adapter (CLA) interfaces, and developing the so called Application Agent Protocol (AAP) for interaction with the application layer. Additional enhancements, informed by field tests, include Bundle-in-Bundle Encapsulation and exploring a port to the Rust programming language, indicating the project's ongoing adaptation to practical needs. The paper also introduces the Generic Bundle Forwarding Interface and AAPv2, showcasing the latest innovations in the project. Moreover, it provides a comparison of uD3TN's architecture with the Interplanetary Overlay Network (ION) protocol stack, highlighting some general architectural principles at the foundation of DTN protocol implementations.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17169",
        "abstract url": "https://arxiv.org/abs/2407.17169",
        "title": "KnowTD-An Actionable Knowledge Representation System for Thermodynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "We demonstrate that thermodynamic knowledge acquired by humans can be transferred to computers so that the machine can use it to solve thermodynamic problems and produce explainable solutions with a guarantee of correctness. The actionable knowledge representation system that we have created for this purpose is called KnowTD. It is based on an ontology of thermodynamics that represents knowledge of thermodynamic theory, material properties, and thermodynamic problems. The ontology is coupled with a reasoner that sets up the problem to be solved based on user input, extracts the correct, pertinent equations from the ontology, solves the resulting mathematical problem, and returns the solution to the user, together with an explanation of how it was obtained. KnowTD is presently limited to simple thermodynamic problems, similar to those discussed in an introductory course in Engineering Thermodynamics. This covers the basic theory and working principles of thermodynamics. KnowTD is designed in a modular way and is easily extendable.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "This document is the unedited Author's version of a Submitted Work that was subsequently accepted for publication in the Journal of Chemical Information and Modeling, copyright \\c{opyright} 2024 The Authors, published by American Chemical Society after peer review. To access the final edited and published work see https://pubs.acs.org/doi/full/10.1021/acs.jcim.4c00647"
    },
    {
        "paper id": "2407.17201",
        "abstract url": "https://arxiv.org/abs/2407.17201",
        "title": "MoULDyS: Monitoring of Autonomous Systems in the Presence of Uncertainties",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce MoULDyS, that implements efficient offline and online monitoring algorithms of black-box cyber-physical systems w.r.t. safety properties. MoULDyS takes as input an uncertain log (with noisy and missing samples), as well as a bounding model in the form of an uncertain linear system; this latter model plays the role of an over-approximation so as to reduce the number of false alarms. MoULDyS is Python-based and available under the GNU General Public License v3.0 (gpl-3.0). We further provide easy-to-use scripts to recreate the results of two case studies introduced in an earlier work.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This is the author version of the manuscript of the same name published in Science of Computer Programming"
    },
    {
        "paper id": "2407.17208",
        "abstract url": "https://arxiv.org/abs/2407.17208",
        "title": "Simple Grid Polygon Online Exploration Revisited",
        "rating": "-10",
        "keywords": [],
        "abstract": "Due to some significantly contradicting research results, we reconsider the problem of the online exploration of a simple grid cell environment. In this model an agent attains local information about the direct four-neigbourship of a current grid cell and can also successively build a map of all detected cells. Beginning from a starting cell at the boundary of the environment, the agent has to visit any cell of the grid environment and finally has to return to its starting position. The performance of an online strategy is given by competitive analysis. We compare the number of overall cell visits (number of steps) of an online strategy to the number of such visits in the optimal offline solution under full information of the environment in advance. The corresponding worst-case ratio gives the competitive ratio. The aforementioned contradiction among two publications turns out to be as follows: There is a journal publication that claims to present an optimal competitive strategy with ratio 7/6 and a former conference paper that presents a lower bound of 20/17. In this note we extract the flaw in the upper bound and also present a new slightly improved and (as we think) simplified general lower bound of 13/11.",
        "subjects": [
            "cs.CG",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17215",
        "abstract url": "https://arxiv.org/abs/2407.17215",
        "title": "Formalizing UML State Machines for Automated Verification -- A Survey",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Unified Modeling Language (UML) is a standard for modeling dynamic systems. UML behavioral state machines are used for modeling the dynamic behavior of object-oriented designs. The UML specification, maintained by the Object Management Group (OMG), is documented in natural language (in contrast to formal language). The inherent ambiguity of natural languages may introduce inconsistencies in the resulting state machine model. Formalizing UML state machine specification aims at solving the ambiguity problem and at providing a uniform view to software designers and developers. Such a formalization also aims at providing a foundation for automatic verification of UML state machine models, which can help to find software design vulnerabilities at an early stage and reduce the development cost. We provide here a comprehensive survey of existing work from 1997 to 2021 related to formalizing UML state machine semantics for the purpose of conducting model checking at the design stage.",
        "subjects": [
            "cs.SE",
            "cs.LO"
        ],
        "comment": "This is the author version of the manuscript of the same name published in ACM Computing Surveys"
    },
    {
        "paper id": "2407.17240",
        "abstract url": "https://arxiv.org/abs/2407.17240",
        "title": "Ranking Plausible Patches by Historic Feature Frequencies",
        "rating": "-10",
        "keywords": [],
        "abstract": "Automated program repair (APR) techniques have achieved conspicuous progress, and are now capable of producing genuinely correct fixes in scenarios that were well beyond their capabilities only a few years ago. Nevertheless, even when an APR technique can find a correct fix for a bug, it still runs the risk of ranking the fix lower than other patches that are plausible (they pass all available tests) but incorrect. This can seriously hurt the technique's practical effectiveness, as the user will have to peruse a larger number of patches before finding the correct one. This paper presents PrevaRank, a technique that ranks plausible patches produced by any APR technique according to their feature similarity with historic programmer-written fixes for similar bugs. PrevaRank implements simple heuristics, which help make it scalable and applicable to any APR tool that produces plausible patches. In our experimental evaluation, after training PrevaRank on the fix history of 81 open-source Java projects, we used it to rank patches produced by 8 Java APR tools on 168 Defects4J bugs. PrevaRank consistently improved the ranking of correct fixes: for example, it ranked a correct fix within the top-3 positions in 27% more cases than the original tools did. Other experimental results indicate that PrevaRank works robustly with a variety of APR tools and bugs, with negligible overhead.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17257",
        "abstract url": "https://arxiv.org/abs/2407.17257",
        "title": "An MDP-Based Approach for Distribution System Control with PV Generation and Battery Storage",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes a decision-making approach for the control of distribution systems with distributed energy resources (DERs) equipped with photovoltaic (PV) units and battery energy storage systems (BESS). The objective is to minimize the total operational cost of the distribution system while satisfying the system operating constraints. The method is based on the discrete-time finite-horizon Markov Decision Process (MDP) framework. Different aspects of the operation of the distribution system operation are considered, such as the possibilities of curtailment of PV generation, managing battery storage, reactive power injection, load shedding, and providing a flexibility service for the transmission system. The model is tested for the IEEE 33-bus system with two added DERs and the study cases involve various unexpected events. The experimental results show that this method enables the attainment of relatively low total cost values compared to the reference deterministic approach. The benefits of applying this approach are particularly evident when there is a significant difference between the predicted and actual PV power generation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "2024 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)"
    },
    {
        "paper id": "2407.17277",
        "abstract url": "https://arxiv.org/abs/2407.17277",
        "title": "From Data to Predictive Control: A Framework for Stochastic Linear Systems with Output Measurements",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce data to predictive control, D2PC, a framework to facilitate the design of robust and predictive controllers from data. The proposed framework is designed for discrete-time stochastic linear systems with output measurements and provides a principled design of a predictive controller based on data. The framework starts with a parameter identification method based on the Expectation-Maximization algorithm, which incorporates pre-defined structural constraints. Additionally, we provide an asymptotically correct method to quantify uncertainty in parameter estimates. Next, we develop a strategy to synthesize robust dynamic output-feedback controllers tailored to the derived uncertainty characterization. Finally, we introduce a predictive control scheme that guarantees recursive feasibility and satisfaction of chance constraints. This framework marks a significant advancement in integrating data into robust and predictive control schemes. We demonstrate the efficacy of D2PC through a numerical example involving a $10$-dimensional spring-mass-damper system.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "Code link: https://github.com/haldunbalim/D2PC"
    },
    {
        "paper id": "2407.17279",
        "abstract url": "https://arxiv.org/abs/2407.17279",
        "title": "Analysis of Scalable Anomalous Reflectors through Ray Tracing and Measurements",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this study, we elaborate on the concept of scalable anomalous reflector (AR) to analyze the angular response, frequency response, and spatial scalability of a designed AR across a broad range of angles and frequencies. We utilize theoretical models and ray tracing simulations to investigate the communication performance of two different-sized scalable finite ARs, one smaller configuration with 48 x 48 array of unit cells and the other constructed by combining four smaller ARs to form a larger array with 96 x 96 unit cells. To validate the developed theoretical approach, we conducted measurements in an auditorium to evaluate the received power through an AR link at different angles and frequencies. In addition, models of scalable deflectors are implemented in the MATLAB ray tracer to simulate the measurement scenario. The results from theoretical calculations and ray tracing simulations achieve good agreement with measurement results.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "9 pages, 12 figures"
    },
    {
        "paper id": "2407.17289",
        "abstract url": "https://arxiv.org/abs/2407.17289",
        "title": "Static and Dynamic Verification of OCaml Programs: The Gospel Ecosystem (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present our work on the collaborative use of dynamic and static analysis tools for the verification of software written in the OCaml language. We build upon Gospel, a specification language for OCaml that can be used both in dynamic and static analyses. We employ Ortac, for runtime assertion checking, and Cameleer and CFML for the deductive verification of OCaml code. We report on the use of such tools to build a case study of collaborative analysis of a non-trivial OCaml program. This shows how these tools nicely complement each others, while at the same highlights the differences when writing specification targeting dynamic or static analysis methods.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17311",
        "abstract url": "https://arxiv.org/abs/2407.17311",
        "title": "The Magnificent Seven Challenges and Opportunities in Domain-Specific Accelerator Design for Autonomous Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The end of Moore's Law and Dennard Scaling has combined with advances in agile hardware design to foster a golden age of domain-specific acceleration. However, this new frontier of computing opportunities is not without pitfalls. As computer architects approach unfamiliar domains, we have seen common themes emerge in the challenges that can hinder progress in the development of useful acceleration. In this work, we present the Magnificent Seven Challenges in domain-specific accelerator design that can guide adventurous architects to contribute meaningfully to novel application domains. Although these challenges appear across domains ranging from ML to genomics, we examine them through the lens of autonomous systems as a motivating example in this work. To that end, we identify opportunities for the path forward in a successful domain-specific accelerator design from these challenges.",
        "subjects": [
            "cs.AR",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Presented at DAC 2024"
    },
    {
        "paper id": "2407.17316",
        "abstract url": "https://arxiv.org/abs/2407.17316",
        "title": "Lossy Data Compression By Adaptive Mesh Coarsening",
        "rating": "-10",
        "keywords": [],
        "abstract": "Today's scientific simulations, for example in the high-performance exascale sector, produce huge amounts of data. Due to limited I/O bandwidth and available storage space, there is the necessity to reduce scientific data of high performance computing applications. Error-bounded lossy compression has been proven to be an effective approach tackling the trade-off between accuracy and storage space. Within this work, we are exploring and discussing error-bounded lossy compression solely based on adaptive mesh refinement techniques. This compression technique is not only easily integrated into existing adaptive mesh refinement applications but also suits as a general lossy compression approach for arbitrary data in form of multi-dimensional arrays, irrespective of the data type. Moreover, these techniques permit the exclusion of regions of interest and even allows for nested error domains during the compression. The described data compression technique is presented exemplary on ERA5 data.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17332",
        "abstract url": "https://arxiv.org/abs/2407.17332",
        "title": "A Systematic Analytical Design Procedure for Distributed Amplifiers",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we present a simple while comprehensive analytical design procedure for distributed amplifiers. Distributed amplifiers are attractive for designers due to their wideband capability. When designing a distributed amplifier, the first question that comes to mind is how wide the bandwidth can be. This paper answers this question by using the self-matching and low-pass properties of a distributed amplifier. Self-matching property of a distributed power amplifier is an interesting point that distinguishes it from other types of power amplifiers that are usually based on input and output matching networks. Here the estimation of the bandwidth of a distributed amplifier structure is discussed. The equations that are used in this paper can bring good insight and they can assist designers. Furthermore, we have explained the frequency behavior of a tapered distributed amplifier analytically for the first time. In order to validate the approach presented here, we have used published designs including our previously published design as practical examples. The flowchart of the design procedure is also provided.",
        "subjects": [
            "cs.ET",
            "eess.SY",
            "physics.app-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17364",
        "abstract url": "https://arxiv.org/abs/2407.17364",
        "title": "Reliability on QR codes and Reed-Solomon codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study addresses the use of Reed-Solomon error correction codes in QR codes to enhance resilience against failures. To fully grasp this approach, a basic cryptographic context is provided, necessary for understanding Reed-Solomon codes. The study begins by defining a code and explores key outcomes for codes with additional properties, such as linearity. The theoretical framework is further developed with specific definitions and examples of Reed-Solomon codes, presented as a particular variant of BCH codes. Additionally, the structure of QR codes is analyzed, encompassing different versions and how data is represented in the form of black and white pixels within an image. Finally, an inherent vulnerability of Reed-Solomon Codes, and particularly of QR codes, related to selective manipulation of modules is examined. This vulnerability leverages the error correction mechanisms present in Reed-Solomon codes.",
        "subjects": [
            "cs.IT",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17367",
        "abstract url": "https://arxiv.org/abs/2407.17367",
        "title": "De Bruijn Sequences with Minimum Discrepancy",
        "rating": "-10",
        "keywords": [],
        "abstract": "The discrepancy of a binary string is the maximum (absolute) difference between the number of ones and the number of zeroes over all possible substrings of the given binary string. In this note we determine the minimal discrepancy that a binary de Bruijn sequence of order $n$ can achieve, which is $n$. This was an open problem until now. We give an algorithm that constructs a binary de Bruijn sequence with minimal discrepancy. A slight modification of this algorithm deals with arbitrary alphabets and yields de Bruijn sequences of order $n$ with discrepancy at most $1$ above the trivial lower bound $n$.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17391",
        "abstract url": "https://arxiv.org/abs/2407.17391",
        "title": "Tutorial: Object as a Service (OaaS) Serverless Cloud Computing Paradigm",
        "rating": "-10",
        "keywords": [],
        "abstract": "While the first generation of cloud computing systems mitigated the job of system administrators, the next generation of cloud computing systems is emerging to mitigate the burden for cloud developers -- facilitating the development of cloud-native applications. This paradigm shift is primarily happening by offering higher-level serverless abstractions, such as Function as a Service (FaaS). Although FaaS has successfully abstracted developers from the cloud resource management details, it falls short in abstracting the management of both data (i.e., state) and the non-functional aspects, such as Quality of Service (QoS) requirements. The lack of such abstractions implies developer intervention and is counterproductive to the objective of mitigating the burden of cloud-native application development. To further streamline cloud-native application development, we present Object-as-a-Service (OaaS) -- a serverless paradigm that borrows the object-oriented programming concepts to encapsulate application logic and data in addition to non-functional requirements into a single deployment package, thereby streamlining provider-agnostic cloud-native application development. We realized the OaaS paradigm through the development of an open-source platform called Oparaca. In this tutorial, we will present the concept and design of the OaaS paradigm and its implementation -- the Oparaca platform. Then, we give a tutorial on developing and deploying the application on the Oparaca platform and discuss its benefits and its optimal configurations to avoid potential overheads.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17394",
        "abstract url": "https://arxiv.org/abs/2407.17394",
        "title": "Towards Practical Finite Sample Bounds for Motion Planning in TAMP",
        "rating": "-10",
        "keywords": [],
        "abstract": "When using sampling-based motion planners, such as PRMs, in configuration spaces, it is difficult to determine how many samples are required for the PRM to find a solution consistently. This is relevant in Task and Motion Planning (TAMP), where many motion planning problems must be solved in sequence. We attempt to solve this problem by proving an upper bound on the number of samples that are sufficient, with high probability, to find a solution by drawing on prior work in deterministic sampling and sample complexity theory. We also introduce a numerical algorithm to compute a tighter number of samples based on the proof of the sample complexity theorem we apply to derive our bound. Our experiments show that our numerical bounding algorithm is tight within two orders of magnitude on planar planning problems and becomes looser as the problem's dimensionality increases. When deployed as a heuristic to schedule samples in a TAMP planner, we also observe planning time improvements in planar problems. While our experiments show much work remains to tighten our bounds, the ideas presented in this paper are a step towards a practical sample bound.",
        "subjects": [
            "cs.RO",
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17431",
        "abstract url": "https://arxiv.org/abs/2407.17431",
        "title": "ProvenanceWidgets: A Library of UI Control Elements to Track and Dynamically Overlay Analytic Provenance",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present ProvenanceWidgets, a Javascript library of UI control elements such as radio buttons, checkboxes, and dropdowns to track and dynamically overlay a user's analytic provenance. These in situ overlays not only save screen space but also minimize the amount of time and effort needed to access the same information from elsewhere in the UI. In this paper, we discuss how we design modular UI control elements to track how often and how recently a user interacts with them and design visual overlays showing an aggregated summary as well as a detailed temporal history. We demonstrate the capability of ProvenanceWidgets by recreating three prior widget libraries: (1) Scented Widgets, (2) Phosphor objects, and (3) Dynamic Query Widgets. We also evaluated its expressiveness and conducted case studies with visualization developers to evaluate its effectiveness. We find that ProvenanceWidgets enables developers to implement custom provenance-tracking applications effectively. ProvenanceWidgets is available as open-source software at https://github.com/ProvenanceWidgets to help application developers build custom provenance-based systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "11 pages, 8 figures. To appear in IEEE VIS 2024"
    },
    {
        "paper id": "2407.17435",
        "abstract url": "https://arxiv.org/abs/2407.17435",
        "title": "Joint Transmit and Jamming Power Optimization for Secrecy in Energy Harvesting Networks: A Reinforcement Learning Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we address the problem of joint allocation of transmit and jamming power at the source and destination, respectively, to enhance the long-term cumulative secrecy performance of an energy-harvesting wireless communication system until it stops functioning in the presence of an eavesdropper. The source and destination have energy-harvesting devices with limited battery capacities. The destination also has a full-duplex transceiver to transmit jamming signals for secrecy. We frame the problem as an infinite-horizon Markov decision process (MDP) problem and propose a reinforcement learning-based optimal joint power allocation (OJPA) algorithm that employs a policy iteration (PI) algorithm. Since the optimal algorithm is computationally expensive, we develop a low-complexity sub-optimal joint power allocation (SJPA) algorithm, namely, reduced state joint power allocation (RSJPA). Two other SJPA algorithms, the greedy algorithm (GA) and the naive algorithm (NA), are implemented as benchmarks. In addition, the OJPA algorithm outperforms the individual power allocation (IPA) algorithms termed individual transmit power allocation (ITPA) and individual jamming power allocation (IJPA), where the transmit and jamming powers, respectively, are optimized individually. The results show that the OJPA algorithm is also more energy efficient. Simulation results show that the OJPA algorithm significantly improves the secrecy performance compared to all SJPA algorithms. The proposed RSJPA algorithm achieves nearly optimal performance with significantly less computational complexity marking it the balanced choice between the complexity and the performance. We find that the computational time for the RSJPA algorithm is around 75 percent less than the OJPA algorithm.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17440",
        "abstract url": "https://arxiv.org/abs/2407.17440",
        "title": "Generative AI in Evidence-Based Software Engineering: A White Paper",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context. In less than a year practitioners and researchers witnessed a rapid and wide implementation of Generative Artificial Intelligence. The daily availability of new models proposed by practitioners and researchers has enabled quick adoption. Textual GAIs capabilities enable researchers worldwide to explore new generative scenarios simplifying and hastening all timeconsuming text generation and analysis tasks. Motivation. The exponentially growing number of publications in our field with the increased accessibility to information due to digital libraries makes conducting systematic literature reviews and mapping studies an effort and timeinsensitive task Stemmed from this challenge we investigated and envisioned the role of GAIs in evidencebased software engineering. Future Directions. Based on our current investigation we will follow up the vision with the creation and empirical validation of a comprehensive suite of models to effectively support EBSE researchers",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17569",
        "abstract url": "https://arxiv.org/abs/2407.17569",
        "title": "On Approximately Strategy-Proof Tournament Rules for Collusions of Size at Least Three",
        "rating": "-10",
        "keywords": [],
        "abstract": "A tournament organizer must select one of $n$ possible teams as the winner of a competition after observing all $\\binom{n}{2}$ matches between them. The organizer would like to find a tournament rule that simultaneously satisfies the following desiderata. It must be Condorcet-consistent (henceforth, CC), meaning it selects as the winner the unique team that beats all other teams (if one exists). It must also be strongly non-manipulable for groups of size $k$ at probability $\u03b1$ (henceforth, k-SNM-$\u03b1$), meaning that no subset of $\\leq k$ teams can fix the matches among themselves in order to increase the chances any of it's members being selected by more than $\u03b1$. Our contributions are threefold. First, wee consider a natural generalization of the Randomized Single Elimination Bracket rule from [Schneider et al. 2017] to $d$-ary trees and provide upper bounds to its manipulability. Then, we propose a novel tournament rule that is CC and 3-SNM-1/2, a strict improvement upon the concurrent work of [Dinev and Weinberg, 2022] who proposed a CC and 3-SNM-31/60 rule. Finally, we initiate the study of reductions among tournament rules.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17576",
        "abstract url": "https://arxiv.org/abs/2407.17576",
        "title": "Time-Shifted Alternating Gelfand-Pinsker Coding for Broadcast Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "A coding scheme for broadcast channels (BCs) is proposed that shifts the users' code blocks by different amounts of time and applies alternating Gelfand-Pinsker encoding. The scheme achieves all rate tuples in Marton's region for two receiver BCs without time-sharing or rate-splitting. Simulations with short polar codes show that the method reduces the gap to capacity as compared to time-sharing.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 3 figures; as presented at ISIT 2024"
    },
    {
        "paper id": "2407.17579",
        "abstract url": "https://arxiv.org/abs/2407.17579",
        "title": "Envisioning New Futures of Positive Social Technology: Beyond Paradigms of Fixing, Protecting, and Preventing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Social technology research today largely focuses on mitigating the negative impacts of technology and, therefore, often misses the potential of technology to enhance human connections and well-being. However, we see a potential to shift towards a holistic view of social technology's impact on human flourishing. We introduce Positive Social Technology (Positech), a framework that shifts emphasis toward leveraging social technologies to support and augment human flourishing. This workshop is organized around three themes relevant to Positech: 1) \"Exploring Relevant and Adjacent Research\" to define and widen the Positech scope with insights from related fields, 2) \"Projecting the Landscape of Positech\" for participants to outline the domain's key aspects and 3) \"Envisioning the Future of Positech,\" anchored around strategic planning towards a sustainable research community. Ultimately, this workshop will serve as a platform to shift the narrative of social technology research towards a more positive, human-centric approach. It will foster research that goes beyond fixing technologies to protect humans from harm, to also pursue enriching human experiences and connections through technology.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17582",
        "abstract url": "https://arxiv.org/abs/2407.17582",
        "title": "Authenticated partial correction over AV-MACs: toward characterization and coding",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study $\u03b3$ partial correction over a $t$-user arbitrarily varying multiple-access channel (AV-MAC). We first present necessary channel conditions for the $\u03b3$ partially correcting authentication capacity region to have nonempty interior. We then give a block length extension scheme which preserves positive rate tuples from a short code with zero probability of $\u03b3$ partial correction error, noting that the flexibility of $\u03b3$ partial correction prevents pure codeword concatenation from being successful. Finally, we offer a case study of a particular AV-MAC satisfying the necessary conditions for partial correction.",
        "subjects": [
            "cs.IT",
            "math.CO"
        ],
        "comment": "8 pages, submitted for publication"
    },
    {
        "paper id": "2407.17598",
        "abstract url": "https://arxiv.org/abs/2407.17598",
        "title": "Harnessing DRL for URLLC in Open RAN: A Trade-off Exploration",
        "rating": "-10",
        "keywords": [],
        "abstract": "The advent of Ultra-Reliable Low Latency Communication (URLLC) alongside the emergence of Open RAN (ORAN) architectures presents unprecedented challenges and opportunities in Radio Resource Management (RRM) for next-generation communication systems. This paper presents a comprehensive trade-off analysis of Deep Reinforcement Learning (DRL) approaches designed to enhance URLLC performance within ORAN's flexible and dynamic framework. By investigating various DRL strategies for optimising RRM parameters, we explore the intricate balance between reliability, latency, and the newfound adaptability afforded by ORAN principles. Through extensive simulation results, our study compares the efficacy of different DRL models in achieving URLLC objectives in an ORAN context, highlighting the potential of DRL to navigate the complexities introduced by ORAN. The proposed study provides valuable insights into the practical implementation of DRL-based RRM solutions in ORAN-enabled wireless networks. It sheds light on the benefits and challenges of integrating DRL and ORAN for URLLC enhancements. Our findings contribute to the ongoing discourse on advancements in URLLC and ORAN, offering a roadmap for future research to pursue efficient, reliable, and flexible communication systems.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "The manuscript is currently being reviewed by IEEE Communications Magazine"
    },
    {
        "paper id": "2407.17643",
        "abstract url": "https://arxiv.org/abs/2407.17643",
        "title": "Robust Iterative Learning for Collaborative Road Profile Estimation and Active Suspension Control in Connected Vehicles",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents the development of a new collaborative road profile estimation and active suspension control framework in connected vehicles, where participating vehicles iteratively refine the road profile estimation and enhance suspension control performance through an iterative learning scheme. Specifically, we develop a robust iterative learning approach to tackle the heterogeneity and model uncertainties in participating vehicles, which are important for practical implementations. In addition, the framework can be adopted as an add-on system to augment existing suspension control schemes. Comprehensive numerical studies are performed to evaluate and validate the proposed framework.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17675",
        "abstract url": "https://arxiv.org/abs/2407.17675",
        "title": "Drawing ellipses and elliptical arcs with piecewise cubic B\u00e9zier curve approximations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This tutorial describes how to use piecewise cubic B\u00e9zier curves to draw arbitrarily oriented ellipses and elliptical arcs. The geometric principles discussed here result in strikingly simple interfaces for graphics functions that can draw (approximate) circles, ellipses, and arcs of circles and ellipses. C++ source code listings are included for these functions. Their code size can be relatively small because they are designed to be used with a graphics library or platform that draws B\u00e9zier curves, and the library or platform is tasked with the actual rendering of the curves.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "8 figures"
    },
    {
        "paper id": "2407.17681",
        "abstract url": "https://arxiv.org/abs/2407.17681",
        "title": "DesignChecker: Visual Design Support for Blind and Low Vision Web Developers",
        "rating": "-10",
        "keywords": [],
        "abstract": "Blind and low vision (BLV) developers create websites to share knowledge and showcase their work. A well-designed website can engage audiences and deliver information effectively, yet it remains challenging for BLV developers to review their web designs. We conducted interviews with BLV developers (N=9) and analyzed 20 websites created by BLV developers. BLV developers created highly accessible websites but wanted to assess the usability of their websites for sighted users and follow the design standards of other websites. They also encountered challenges using screen readers to identify illegible text, misaligned elements, and inharmonious colors. We present DesignChecker, a browser extension that helps BLV developers improve their web designs. With DesignChecker, users can assess their current design by comparing it to visual design guidelines, a reference website of their choice, or a set of similar websites. DesignChecker also identifies the specific HTML elements that violate design guidelines and suggests CSS changes for improvements. Our user study participants (N=8) recognized more visual design errors than using their typical workflow and expressed enthusiasm about using DesignChecker in the future.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Conditionally Accepted to UIST 2024"
    },
    {
        "paper id": "2407.17684",
        "abstract url": "https://arxiv.org/abs/2407.17684",
        "title": "Semi-Compressed CRYSTALS-Kyber",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate the communication overhead of the Kyber, which has recently been standardized by the National Institute of Standards and Technology (NIST). Given the same decryption failure rate (DFR) and security argument, we show it is feasible to reduce the communication overhead of the Kyber by 54%. The improvement is based on two technologies: ciphertext quantization and plaintext encoding. First, we prove that the Lloyd-Max quantization is optimal to minimize the decryption decoding noise. The original Kyber compression function is not optimal. Second, we propose an encoding scheme, which combines Pulse-Amplitude Modulation (PAM), Gray mapping, and a binary error correcting code. An explicit expression for the DFR is derived. The minimum possible communication overhead is also derived. Finally, we demonstrate that with the Lloyd-Max quantization, 8-PAM, Gray mapping, and a shortened binary BCH(768,638,13) code, the proposed scheme encapsulates 638 bits (e.g., 2.5 AES keys) in a single ciphertext.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "17 pages, 1 figure"
    },
    {
        "paper id": "2407.17699",
        "abstract url": "https://arxiv.org/abs/2407.17699",
        "title": "SOK: Blockchain for Provenance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Provenance, which traces data from its creation to manipulation, is crucial for ensuring data integrity, reliability, and trustworthiness. It is valuable for single-user applications, collaboration within organizations, and across organizations. Blockchain technology has become a popular choice for implementing provenance due to its distributed, transparent, and immutable nature. Numerous studies on blockchain designs are specifically dedicated to provenance, and specialize in this area. Our goal is to provide a new perspective in blockchain based provenance field by identifying the challenges faced and suggesting future research directions. In this paper, we categorize the problem statement into three main research questions to investigate key issues comprehensively and propose a new outlook on the use of blockchains. The first focuses on challenges in non-collaborative, single-source environments, the second examines implications in collaborative environments and different domains such as supply chain, scientific collaboration and digital forensic, and the last one analyzes communication and data exchange challenges between organizations using different blockchains. The interconnected nature of these research questions ensures a thorough exploration of provenance requirements, leading to more effective and secure systems. After analyzing the requirements of provenance in different environments, we provide future design considerations for provenance-based blockchains, including blockchain type, query mechanisms, provenance capture methods, and domain-specific considerations. We also discuss future work and possible extensions in this field.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17743",
        "abstract url": "https://arxiv.org/abs/2407.17743",
        "title": "A Proposal for a Debugging Learning Support Environment for Undergraduate Students Majoring in Computer Science",
        "rating": "-10",
        "keywords": [],
        "abstract": "In software development, encountering bugs is inevitable. However, opportunities to learn more about bug removal are limited. When students perform debugging tasks, they often use print statements because students do not know how to use a debugger or have never used one.In this study, among various debugging methods, we focused on debugging using breakpoints. We implemented a function in Scratch, a visual programming language, that allows for self-learning of correct breakpoint placement and systematic debugging procedures.In this paper, we discuss experimental results that clarify the changes that occur in subjects when they learn debugging in Scratch.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.17758",
        "abstract url": "https://arxiv.org/abs/2407.17758",
        "title": "Speed-enhanced Subdomain Adaptation Regression for Long-term Stable Neural Decoding in Brain-computer Interfaces",
        "rating": "-10",
        "keywords": [],
        "abstract": "Brain-computer interfaces (BCIs) offer a means to convert neural signals into control signals, providing a potential restoration of movement for people with paralysis. Despite their promise, BCIs face a significant challenge in maintaining decoding accuracy over time due to neural nonstationarities. However, the decoding accuracy of BCI drops severely across days due to the neural data drift. While current recalibration techniques address this issue to a degree, they often fail to leverage the limited labeled data, to consider the signal correlation between two days, or to perform conditional alignment in regression tasks. This paper introduces a novel approach to enhance recalibration performance. We begin with preliminary experiments that reveal the temporal patterns of neural signal changes and identify three critical elements for effective recalibration: global alignment, conditional speed alignment, and feature-label consistency. Building on these insights, we propose the Speed-enhanced Subdomain Adaptation Regression (SSAR) framework, integrating semi-supervised learning with domain adaptation techniques in regression neural decoding. SSAR employs Speed-enhanced Subdomain Alignment (SeSA) for global and speed conditional alignment of similarly labeled data, with Contrastive Consistency Constraint (CCC) to enhance the alignment of SeSA by reinforcing feature-label consistency through contrastive learning. Our comprehensive set of experiments, both qualitative and quantitative, substantiate the superior recalibration performance and robustness of SSAR.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20262",
        "abstract url": "https://arxiv.org/abs/2407.20262",
        "title": "A Neural-Network-Embedded Equivalent Circuit Model for Lithium-ion Battery State Estimation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Equivalent Circuit Model(ECM)has been widelyused in battery modeling and state estimation because of itssimplicity, stability and interpretability.However, ECM maygenerate large estimation errors in extreme working conditionssuch as freezing environmenttemperature andcomplexcharging/discharging behaviors,in whichscenariostheelectrochemical characteristics of the battery become extremelycomplex and nonlinear.In this paper,we propose a hybridbattery model by embeddingneural networks as 'virtualelectronic components' into the classical ECM to enhance themodel nonlinear-fitting ability and adaptability. First, thestructure of the proposed hybrid model is introduced, where theembedded neural networks are targeted to fit the residuals of theclassical ECM,Second, an iterative offline training strategy isdesigned to train the hybrid model by merging the battery statespace equation into the neural network loss function. Last, thebattery online state of charge (SOC)estimation is achieved basedon the proposed hybrid model to demonstrate its applicationvalue,Simulation results based on a real-world battery datasetshow that the proposed hybrid model can achieve 29%-64%error reduction for $OC estimation under different operatingconditions at varying environment temperatures.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "8 pages"
    }
]